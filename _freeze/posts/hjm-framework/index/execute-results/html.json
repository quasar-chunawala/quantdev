{
  "hash": "1716e5547fe746f20d8677556bcfa8d7",
  "result": {
    "engine": "jupyter",
    "markdown": "---\ntitle: \"The HJM Framework\"\nauthor: \"Quasar\"\ndate: \"2025-01-29\"\ncategories: [Rates Modelling]      \nimage: \"image.jpg\"\ntoc: true\ntoc-depth: 3\nformat:\n    html:\n        code-tools: true\n        code-block-border-left: true\n        code-annotations: below\n        highlight-style: pygments\n---\n\n\n\n\n# The HJM Framework\n\n## Introduction\n\nEarly interest rate modelling was based on specifying some dynamics for the instantaneous short rate process $r(t)$. Some classical short-rate models are : the Vasicek (1977) model, the Dothan (1978) model, the Cox, Ingersoll and Ross(1985) model and the Exponential-Vasicek model. These are all equilibrium, *endogenous term-structure models*, meaning that the current yield curve $P(t,T)$ is an output of the model rather than an input of the model. \n\nIn a *no-arbitrage (exogenous)* model, today's term structure of interest rates is an input. This means that you always get your yield curve back from the model and is independent of the parameters, so this is extremely powerful. This means that we take the observed actual rates while constructing the model and estimate the unobserved rates. \n\nThe HJM framework described a clear path from equilibrium towards term-structure models.\n\n## Equilibrium versus Term-Structure Models\n\nHistorically, equilibrium models start with assumptions about economic variables and derive a process for the short rate, which means that the current term structure of interest rates is an output, rather than an input to the model. Such models are also called *endogenous* models. \n\nThe Vasicek model has the short-rate dynamics:\n\n$$\n\\begin{align*}\ndr(t) = \\lambda(\\theta - r(t))dt + \\eta dW(t)\n\\end{align*}\n$${#eq-vasicek-model}\n\n::: {#28fda795 .cell execution_count=1}\n``` {.python .cell-code code-fold=\"true\" code-summary=\"Show the code\"}\nfrom aleatory.processes import Vasicek\nprocess = Vasicek(theta=1, mu=3, sigma=0.5);\nfig = process.draw(n=200, N=200, envelope=True, colormap=\"cool\")\n```\n\n::: {.cell-output .cell-output-display}\n![](index_files/figure-html/cell-2-output-1.png){width=583 height=471}\n:::\n:::\n\n\nI generated these beautiful visualizations using the python library [`aleatory`](https://github.com/quantgirluk/aleatory), maintained by one of my favorite quants [Dialid Santiago](https://quantgirl.blog).\n\nTo simulate this model, we need to calibrate this model to the yield curve. Obviously, we need to choose the values of the parameters $\\lambda$, $\\theta$, $\\eta$ such that the yield curve will be recovered. Very likely, there will be not enough flexibility with $3$ parameters to fit to the yield curve, which is built by tens or hundreds of market instruments. Here, we have only $3$ degrees of freedom. \n\nOf course, we can also consider models where the model parameters $\\lambda$, $\\theta$ and $\\eta$ are time-dependent, and they have a term-structure to have more flexibility. But, that's an issue, because actually we need to perform calibration. Calibration means that we need to optimize a target function. We take the yield curve or zero-coupon bond quotes from the market and we calibrate using Levenberg-Marquardt or any other optimization routine and we find those time-dependent parameters. This can be very computationally expensive. \n\nHowever, in term-structure models, the model parameter e.g. $\\theta$ is directly given in terms of market instruments. There is no need to perform any calibration to fit the yield curve. \n\nWe can still use calibration to fit other model parameters e.g. mean reversion $\\lambda$ or $\\eta$ to market instruments such as swaptions. But, we don't need to do it for fitting to the yield curve.\n\nFitting to the yield curve is a necessary condition, when it comes to arbitrage. If we cannot fit to the yield curve, there is no point to fit to anything else. We are already generating arbitrage on $\\Delta$. It means that, if we have an exotic derivative, our model may fit nicely to the exotic derivative prices, but we didn't calibrate the model to the yield curve. So, the sensitivity of the generated yield curve to simple instruments is completely off.\n\nThe Cox-Ingersoll and Ross(CIR) model has the short-rate dynamics:\n\n$$\n\\begin{align*}\ndr(t) = \\lambda(\\theta - r(t))dt + \\gamma \\sqrt{r(t)}dW(t)\n\\end{align*}\n$${#eq-cox-ingersoll-ross-model}\n\n::: {#a161e38a .cell execution_count=2}\n``` {.python .cell-code code-fold=\"true\" code-summary=\"Show the code\"}\nfrom aleatory.processes import CIRProcess\nprocess = CIRProcess(theta=1.0, mu=2.0, sigma=1.0, initial=10.0, T=3.0)\nfig = process.draw(n=200, N=200, envelope=False, colormap=\"summer\")\n```\n\n::: {.cell-output .cell-output-display}\n![](index_files/figure-html/cell-3-output-1.png){width=579 height=471}\n:::\n:::\n\n\n## The HJM Framework\n\nThe Heath-Jarrow-Morton framework is a global framework for describing all the interest rate models. It gives a whole different perspective on how to look at interest rate models. \n\nIt represents a class of models that are derived by directly modeling the dynamics of *instantaneous forward rates*. The framework constitutes the foundation of interest rate models as it provides an explicit relation between the volatility of the forward-rates and arbitrage-free drift. \n\nBoth the standard short-rate and LIBOR market models can be derived in the HJM framework, however, in general. The HJM models are non-Markovian, so only a number of models with a closed-form solution exist.\n\n",
    "supporting": [
      "index_files"
    ],
    "filters": [],
    "includes": {}
  }
}