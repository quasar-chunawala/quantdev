{
  "hash": "c4cc208a7362799470116bd226b5e081",
  "result": {
    "markdown": "---\ntitle: Pythonic code\nauthor: Quasar\ndate: '2025-11-21'\ncategories:\n  - Python\nimage: python.svg\ntoc: true\ntoc-depth: 3\n---\n\n# Pythonic code\n\n## Context Managers\n\nContext managers are a very useful feature in Python. Most of the time, we see contet managers around resource management. For example, in situations, when we open files, we want to make sure they are closed after processing (so we do not leak file descriptors). Or, if we open a connection to a service (or even a socket), we also want to be sure to close it accordingly. In all of these cases, you would normally have to remember to free all of the resources that were allocated and that is just thinking about the best case - there could be also be exceptions and error handling. Handling all possible combinations and execution paths of our program makes it harder. There is a elegant Pythonic way of handling this.\n\n```python\nwith open(filename) as fd:\n    process_file(fd)\n```\n\nThe `with` statement (PEP-43) enters the context manager. In this case, the `open` function implements the context manager protocol, which means that the file will be automatically closed when the block is finished, even if an exception occurred.\n\nContext managers consist of two magic methods `__enter__` and `__exit__`. On the first line of the context manager, the `with` statement will call the first method, `__enter__`, and whatever this method returns will be assigned to the variable after `as`. This is optional - we don't really need to return anything specific on the `__enter__` method, even if we do, there is still no strict reason to assign it to a variable if it is not needed.\n\nAfter this line is executed, the code enters a new context, where any other Python code can be run. After the last statement on the block is finished, the context will be exited, meaning that Python will call the `__exit__` method of the original context manager object we first invoked. \n\nIf there is an exception or error inside the context manager block, the `__exit__` method will still be called, which makes it convenient for safely cleaning up the conditions. In fact, this method receives the exceptions that was triggered on the block in case we want to handle it in a custom fashion. \n\nContext managers are a good way of seperating concerns and isolating parts of the code that should be kept independent, because if we mix them, then the logic will become harder to maintain. \n\nAs an example, consider a situation where we want to run a backup of our database with a script. The caveat is that the backup is offline, which means that we can only do it while the database is not running, and for this we have to stop it. After running the backup, we want to be sure that we start the process again, regardless of how the backup itself went. \n\nInstead of creating a monolithic function to do this, we can tackle this issue with context managers:\n\n```python\ndef stop_database():\n    run(\"systemctl stop postgresql.service\")\n\ndef start_database():\n    run(\"systemctl start postgresql.service\")\n\nclass DBHandler:\n    def __enter__(self):\n        stop_database()\n        return self\n    \n    def __exit__(self, exc_type, ex_value, ex_traceback):\n        start_database()\n    \ndef db_backup():\n    run(\"pg_dump database\")\n\ndef main():\n    with DBHandler():\n        db_backup()\n```\n\n### Implementing context managers\n\nIn general, we can implement context managers like the one in the previous example. All we need is just a class that implements the `__enter__` and `__exit__` magic methods, and then that object will be able to support the context manager protocol. While this is the most common way for context managers to be implemented, it is not the only one. \n\nThe `contextlib` module in the Python standard library contains a lot of helper functions and objects to implement context managers or use ones already provided that can help us write more compact code. \n\nLets start by looking at the `contextmanager` decorator. \n\nWhen the `contextlib.contextmanager` decorator is applied to a function, it converts the code on that function into a context manager. The function in question has to be a particular kind of function called a `generator` function, which will separate statements into what is going to be on `__enter__` and `__exit__` magic methods respectively. \n\nThe equivalent code in the previous example can be written as:\n\n```python\nimport contextlib\n\n@contextlib.contextmanager\ndef db_handler():\n    try:\n        stop_database()\n        yield\n    finally:\n        start_database()\n\nwith db_handler():\n    db_backup()\n```\n\nHere, we define the `generator` function and apply the `@contextlib.contextmanager` decorator to it. The function contains a `yield` statement, which makes it a generator function. Details on generators are not important at this point. All we need to know, is when the decorator is applied, everything before the `yield` statement will be run as if it were part of the `__enter__` method. Then the yielded value is going to be the result of the context manager evaluation (what `__enter__` would return and what would be assigned to the variable if we chose to assign it like `as x:` - in this case nothing is yielded). \n\nAt the `yield` statement, the `generator` function is suspended, and the context manager is entered, where, again we run the backup code for our database. After this completes, the execution resumes, so we can consider every line that comes after the `yield` statement will be part of `__exit__` logic. \n\nWriting context managers like this has the advantage that it is easier to refactor existing functions, reuse code and in general a good idea when we need a context manager that doesn't belong to a particular object. \n\nUsing context managers is considered idiomatic. \n\n## Comprehensions and assignment expressions\n\nThe use of comprehensions is recommended to create data-structures in a single instruction, instead of multiple operations. For example, if we wanted to create a list with calculations over some numbers in it, instead of:\n\n```python\nnumbers = []\nfor i in range(10):\n    numbers.append(run_calculation(i))\n```\n\nwe could do:\n\n```python\nnumbers = [run_calculation(i) for i in range(10)]\n```\n\nThe introduction of assignment expressions in [PEP-572](https://www.python.org/dev/peps/pep-0572/) is also very useful. \n\n```python\n# Compute partial sums in a list comprehension\ntotal = 0\npartial_sums = [total := total + v for v in values]\nprint(\"Total:\", total)\n```\n\nThe `:=` operator is informally known as the walrus operator.\n\n### Using the walrus operator\n\nIn this example, the assignment expression helps avoid calling `len()` twice:\n\n::: {.cell execution_count=1}\n``` {.python .cell-code}\na = list(range(1,16))\nif (n := len(a)) > 10:\n    print(f\"List is too long ({n} elements, expected <= 10)\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nList is too long (15 elements, expected <= 10)\n```\n:::\n:::\n\n\nThe operator is also useful with `while` loops that compute a value to test loop termination and then need that value again in the body of the loop.\n\n```python\nwhile (block := f.read(256)) != ' ':\n    process(block)\n```\n\nA subexpression can be shared between a comprehension filter and its output.\n\n::: {.cell execution_count=2}\n``` {.python .cell-code}\n# Share a subexpression between a comprehension filter clause and its output\ndef f(x):\n    if x % 2 == 0:\n        return x**2\n    else:\n        return None\n\ndata = [1, 2, 3, 4, 5]\nfiltered_data = [y for x in data if (y := f(x)) is not None]\nfiltered_data\n```\n\n::: {.cell-output .cell-output-display execution_count=2}\n```\n[4, 16]\n```\n:::\n:::\n\n\nUnparenthesized assignment expressions are prohibited at the top level of an expression statement.\n\nKeep in mind however, that a more compact code does not always mean better better code. If to write a one-liner, we have to create a convoluted expression, then its not worth it, and we would be better off using a naive approach. This is related to the *Keep it simple, stupid*(KISS) principle. \n\nAnother good reason for using assignment expressions in general is the performance considerations. If we have to use a function as part of our transformation logic, we don't want to call that more than is necessary. Assigning the result of the function to a temporary identifier is a good optimization technique. \n\n## Properties, attributes and different types of methods for objects\n\nAll of the properties and functions of object are `public` in Python, which is different from other languages where properties can have the access specifier `public`, `private` and `protected`. That is, there is no point in preventing the caller from invoking any attributes an object has. \n\nThere is no strict enforcement, but there are some conventions. An attribute that starts with an underscore is meant to be `private` to that object, and we expect that no external agent calls it (but again nothing preventing this).\n\n### Underscores in Python\n\nThere are some conventions and implementation details that make use of underscores in Python, which is an interesting topic in itself that's worthy of analysis. \n\nLike I mentioned, by default, all attributes of an object in python are `public`. Consider the following example :\n\n::: {.cell execution_count=3}\n``` {.python .cell-code}\nclass Point:\n    def __init__(self, x_value, y_value):\n        self._x_value = x_value\n        self._y_value = y_value\n\np1 = Point(1.0, 2.0)\np1.__dict__\n```\n\n::: {.cell-output .cell-output-display execution_count=3}\n```\n{'_x_value': 1.0, '_y_value': 2.0}\n```\n:::\n:::\n\n\nAttributes that start with an underscore must be respected as `private` and not called externally. Using a single underscore prefix is the Pythonic way of clearly delimiting the interface of the object.\n\nNote that, using too many internal methods and attributes could be a sign that a class has too many tasks and doesn't comply with the single responsibility princple. \n\nThere is however, a common misconception that some attributes and methods can actually be made `private`. This is again a misconception. Let us imagine that the `x_value` and `y_value` attributes are defined with a leading double underscore instead.\n\n```python\nclass Point:\n    def __init__(self, x_value : float, y_value : FloatingPointError):\n        self.__x_value = x_value\n        self._y_value = y_value\n\n    def scale(self, scale_factor : float):\n        self.__x_value *= scale_factor\n        self._y_value *= scale_factor\n\n\np1 = Point(1.0, 2.0)\np1.scale(2.0)\np1.__x_value\n```\n\nOutput:\n```shell\n--------------------------------------------------------------------------\nAttributeError                            Traceback (most recent call last)\nCell In[7], line 13\n     11 p1 = Point(1.0, 2.0)\n     12 p1.scale(2.0)\n---> 13 p1.__x_value\n\nAttributeError: 'Point' object has no attribute '__x_value'\n```\n\nSome developers use this method to hide some attributes, thinking that `x_value` is now `private` and that no other object can modify it. Now, take a look at the exception that it raised when trying to access `__x_value`. It's `AttributeError` saying that it doesn't exist. It doesn't say something like *this is private*,\n\nWhat's actually happening is that with the double underscores, Python creates a different name for the attribute (this is called as name mangling). What it does is create the attribute with the following name instead `<class_name>__<attribute_name>`. In this case the attribute named `Point__x_value` will be created. \n\n::: {.cell execution_count=4}\n``` {.python .cell-code}\np1.__dict__\n```\n\n::: {.cell-output .cell-output-display execution_count=4}\n```\n{'_x_value': 1.0, '_y_value': 2.0}\n```\n:::\n:::\n\n\nThe idea of a double underscore in Python is completely different. It was created as a means to override different methods of a class that is going to be extended several times. Double underscores are a non-Pythonic approach. If you need to defined attributes as `private`, use a single underscore and respect the Pythonic convention that it is a `private` attribute.\n\n### Properties\n\nTypically, in object-oriented design we create objects to represent an abstraction over an entity of the problem domain. In this sense, objects can encapsulate the behavior or data. And more often than not, the accuracy of the data determines if an object can be created or not. That is to say, entities can exist for certain values of the data only, and incorrect values should not be allowed. \n\nThat is, why we create validation methods, typically to be used in `setter` operations. However, in Python, we can encapsulate the `setter` and `getter` methods more compactly using `properties`. \n\nConsider the example of a geographical system that needs to deal with coordinates. There is only a certain range of values for which the latitude and the longitude make sense. Outside of those values, a coordinate cannot exist.\n\n::: {.cell execution_count=5}\n``` {.python .cell-code}\nclass Coordinate:\n    def __init__(self, lat: float, long: float) -> None:\n        self._latitude = self._longitude = None\n        self.latitude = lat\n        self.longitude = long\n\n    @property\n    def latitude(self) -> float:\n        return self._latitude\n\n    @latitude.setter\n    def latitude(self, lat_value: float) -> None:\n        if lat_value not in range(-90, 90 + 1):\n            raise ValueError(f\"{lat_value} is an invalid value for latitude\")\n\n        self._latitude = lat_value\n\n    @property\n    def longitude(self)->float:\n        return self._longitude\n\n    @longitude.setter\n    def longitude(self, long_value:float) -> None:\n        if long_value not in range(-180, 180+1):\n            raise ValueError(f\"{lat_value} is an invalid value for longitude\")\n\n        self._longitude = long_value\n```\n:::\n\n\n## Using `dataclasses`\n\nA `dataclass` is a class that exists primarily to store values which are accessible by attribute lookup and not complex logic. There is a common boilerplate when it comes to initialization of such objects, which is to declare in the `__init__` method all attributes that the object will have, and then set that to internal variables.\n\n```python\nclass Point:\n    def __init__(self, x:float, y:float) -> None:\n        self._x = x\n        self._y = y\n\n```\n\nSince Python 3.7 we can simplify this by using the `dataclasses` module, which was introduced in [PEP-557](https://peps.python.org/pep-0557/#rationale). We'll review this module briefly to understand how it helps us write compact code.\n\nThe module provides a `@dataclass` decorator objectr which when applied to a class, it'll take all the class attributes with annotations and treat them as instance attributes, as if they were declared in the initialization method. When using this method, it will automatically generate the `__init__` method on the class. \n\nAdditionally, this module provides a `field` object that will help us define particular traits for some of the attributes.\n\n::: {.cell execution_count=6}\n``` {.python .cell-code}\nfrom dataclasses import dataclass, field\n\n@dataclass\nclass VanillaOptionQuote:\n    strike : float\n    spot : float\n    implied_vol : float \n    underlying : str \n    time_to_maturity : float = field(default=1.0)\n```\n:::\n\n\nThe `Field` objects describe each field. These objects are created internally and are returned by the `fields()` module-level method. Users should never instantiate a `Field` object directly. Its documented attributes are:\n\n- `name`: Name of the field\n- `type`: The type of the field\n- `default`: If provided, this will be th default value for this field.\n- `default_factory`: If provided, it must be a zero-argument callable that will be called when a default value is needed for this field.\n- `init`: If `true`(default), this field is included as a parameter in the generated `__init__` method. \n- `__repr__` : If `true`(default), this field is included in the string returned by `__repr__` method.\n\nA good use-case for dataclass would be all those places when we need to use objects as data-containers or wrappers. \n\n### Immutable `dataclass`\n\nIt is not possible to create truly immutable Python objects. However, by passing `frozen=True` to the `@dataclass` decorator you can emulate immutability. In that case, Data Classes will add `__setattr__` and `__delattr__` methods to the class. These methods will raise a `FrozenInstanceError` when invoked.\n\n### Why not just use `attrs`?\n\n- `attrs` moves faster than could be accomodated if it were moved to the standard library.\n- `attrs` supports additional features not being proposed here : validators, converters, metadata etc.\n\n## Iterable objects\n\nIn python, we have objects that can be iterated by default. For example, lists, sets, tuples and dictionaries can not only hold data in the structure, but also be iterated over a `for` loop to get those values repeatedly. \n\nHowever, the built-in `iterable` objects are not the only kind we can have in a `for` loop. We can also create our own iterable, with the logic we define for iteration. \n\nIn order to achieve this, we rely again on magic methods. Iteration works in Python by its own protocol(namely the `iterator` protocol). When you try to iterate an object in the form `for e in my_collection:...`, at a high-level, Python checks for:\n\n- If the object contains one of the iterator methods -  `__next__` or `__iter__`.\n- If the object is a sequence and has `__len__` and `__get_item__`\n\n### Creating iterable objects\n\n::: {.cell execution_count=7}\n``` {.python .cell-code}\nfrom datetime import timedelta\nimport datetime as dt\n\nclass DateRange:\n    \"\"\"An iterable that contains its own iterator object.\"\"\"\n    def __init__(self, start_date: dt.date, end_date: dt.date):\n        self._start_date = start_date\n        self._end_date = end_date\n        self._present_date = start_date\n\n    def __iter__(self):\n        return self\n\n    def __next__(self):\n        if self._present_date >= self._end_date:\n            raise StopIteration()\n\n        today = self._present_date\n        self._present_date += timedelta(days=1)\n        return today\n\nfor day in DateRange(dt.date(2026,1,1), dt.date(2026, 1, 8)):\n    print(f\"{day}\")        \n```\n\n::: {.cell-output .cell-output-stdout}\n```\n2026-01-01\n2026-01-02\n2026-01-03\n2026-01-04\n2026-01-05\n2026-01-06\n2026-01-07\n```\n:::\n:::\n\n\n### The basic mechanics \n\nHere, the `for` loop starts a new iteration over our object. At this point Python will call the `iter()` function on it, which in turn will call the `__iter__` magic method. On this method, it is decided to return `self`, indicating that the object is an `iterable` itself. Every step of the loop calls the `next()` function on this object, which delegates to `__next__` method. When there is nothing else to produce, we have to signal this to Python by raising `StopIteration` exception. \n\n::: {.cell execution_count=8}\n``` {.python .cell-code}\nr = DateRange(dt.date(2026,1,1), dt.date(2026, 1, 8))\nprint(next(r))\nprint(next(r))\nprint(next(r))\nprint(next(r))\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n2026-01-01\n2026-01-02\n2026-01-03\n2026-01-04\n```\n:::\n:::\n\n\nThis example works, but it has a small problem - once exhausted, the `iterable` will continue to be empty, hence raising `StopIteration`.\n\nIf there are two or more consecutive `for` loops, only the first one will work, while the second one will remain empty. Because, there is only one shared iteration state. We should separate out the iterator from the iterable.\n\n## Creating sequences\n\nMaybe our object does not define the `__iter__()` method, but we still want to be able to iterate over it. If `__iter__` is not defined on the object, the `iter()` function will look for the presence of `__getitem__`, and if this is not found, it will raise `TypeError`.\n\nA sequence is an object that implements `__len__` and `__getitem__` magic methods and expects to be able to get the elements it contains, one at a time, in order, starting at $0$ as the first index. This means that you should be careful in the logic so that you correctly implement `__get_item__` to expect this type of index, or the iteration will not work. \n\nThe example from the previous section had the advantage that it uses less memory. This means that it is only holding one date at a time and knows how to produce the days one by one. However, it has the drawback that if we want to get to the `n`th element, we have no way to do so but iterate $n$ times. until we reach it. This is a typical trade-off in CS between memory and CPU usage.\n\nThe implementation with an `iterable` will use memory, but take $O(n)$ time, whereas implementing a sequence will use more(because we have to hold everything at once),but supports indexing in constant time. \n\n::: {.cell execution_count=9}\n``` {.python .cell-code}\nclass DateRangeSequence:\n    def __init__(self, start_date : dt.date, end_date:dt.date):\n        self._start_date = start_date\n        self._end_date = end_date\n        self._range = self._create_range()\n\n    def _create_range(self):\n        days = []\n        current_date = self._start_date\n        while current_date < self._end_date:\n            days.append(current_date)\n            current_date += timedelta(days=1)\n\n        return days\n    \n    def __getitem__(self, day_idx):\n        return self._range[day_idx]\n\n    def __len__(self):\n        return len(self._range)\n\ns1 = DateRangeSequence(dt.date(2026,1,1), dt.date(2026,1,6))\nfor day in s1:\n    print(day)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n2026-01-01\n2026-01-02\n2026-01-03\n2026-01-04\n2026-01-05\n```\n:::\n:::\n\n\n## Container objects\n\nContainers are objects that implement a `__contains__` method(that usually returns a `boolean` value). This method is called in the presence of the python keyword `in`.\n\n::: {.cell execution_count=10}\n``` {.python .cell-code}\nfrom dataclasses import dataclass\n\n@dataclass\nclass Interval:\n    left_end_point : float \n    right_end_point : float\n    exclude_right_end : bool = True\n\n    def __contains__(self, x_value : float):\n        if self.exclude_right_end:\n            return self.left_end_point <= x_value and x_value < self.right_end_point \n        else:\n            return self.left_end_point <= x_value and x_value <= self.right_end_point \n\ninterval = Interval(0.0,1.0)\nprint(f\"Is 0.5 contained in the interval [0,1) : {0.5 in interval}\")\nprint(f\"Is 1.0 contained in the interval [0,1) : {1.0 in interval}\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nIs 0.5 contained in the interval [0,1) : True\nIs 1.0 contained in the interval [0,1) : False\n```\n:::\n:::\n\n\n## Dynamic attributes\n\nIt is possible to control the way attributes are obtained from objects by means of the `__getattr__` magic method. When we call something like `<my_object>.<my_attribute>`, Python will look at `<my_attribute>` in the dictionary of the object, calling `__get_attribute__`. If this is not found (that is, the object does not have the attribute we are looking for), then the extra method `__getattr__` is called, passing in the name of the attribute as a parameter.\n\nBy receiving this value, we can control the way things should be returned to our objects. We can even create new attributes on the fly.\n\n::: {.cell execution_count=11}\n``` {.python .cell-code}\nclass DynamicAttributes:\n    def __init__(self, attribute):\n        self.attribute = attribute\n    \n    def __getattr__(self, attr):\n        if attr.startswith(\"fallback_\"):\n            name = attr.replace(\"fallback_\", \"\")\n            return f\"[fallback resolved] {name}\"\n    \n        raise AttributeError(f\"{self.__class__.__name__} has no attribute {attr}\")\n```\n:::\n\n\n## Callable objects\n\n::: {.cell execution_count=12}\n``` {.python .cell-code}\nfrom collections import defaultdict\n\nclass CallCount:\n    def __init__(self):\n        self._counts = defaultdict(int)\n\n    def __call__(self, argument):\n        self._counts[argument] += 1\n        return self._counts[argument]\n\ncall_count = CallCount()\nprint(call_count(\"Hello\"))\nprint(call_count(\"World\"))\nprint(call_count(\"Hello\"))\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n1\n1\n2\n```\n:::\n:::\n\n\n## Python `collections.abc` module\n\nThe best way to implement these methods is to declare our class to inherit from the corresponding class defined in the `collections.abc` module.\n\nThese interfaces provide the methods that need to be implemented, so it'll make it easier for you to define the class correctly.\n\nWith practice and experience, you become more fluent with these features of Python, until it becomes second nature for you wrap the logic you're writing behind abstractions with nice and small interfaces. Give it enough time, and you'll naturally think of having small, clean interfaces in your programs.\n\n## Caveats\n\n### Mutable default arguments\n\nDon't use mutable objects as the default arguments of functions. \n\n",
    "supporting": [
      "index_files"
    ],
    "filters": [],
    "includes": {}
  }
}