{
  "hash": "0457397d4a68a083e21df084dceede26",
  "result": {
    "markdown": "---\ntitle: Coroutines\nauthor: Quasar\ndate: '2025-11-12'\ncategories:\n  - C++\nimage: cpp.jpg\ntoc: true\ntoc-depth: 3\n---\n\n## Coroutines {.unnumbered}\n\nYou've likely heard about this new C++20 feature, **coroutines**. I think that this is a really important subject and there are several cool use-cases for coroutines. A coroutine in the simplest terms is just a function that you can pause in the middle. Imagine that you are executing a function top-down and then just at some point in between, you'd like to say, I am going to hit the pause button here; going to return the control back to the caller. At a later point the caller will decide to resume the execution of the function right where you left off. Unlike a function therefore, coroutines are always stateful - you atleast need to remember where you left off in the function body. Usually, you also need to remember more than this; you need to remember the values of all of the local variables were at the point where you paused. As a consequence, *you can think of the coroutine you are calling not as a function in the classical sense of the term, but more like a factory function that actually returns the coroutine object back to you. And this coroutine object is the one that holds all the state, and which you can resume to continue the computation at a future time*.\n\n::: {.cell execution_count=1}\n``` {.python .cell-code}\n%load_ext itikz\n```\n:::\n\n\nCoroutines can simplify our code! Coroutines are a great tool, when it comes to implementing parsers.\n\nCompared to functions, the control flow of coroutines looks as follows:\n\n:::{.text-center}\n\n::: {.cell execution_count=2}\n``` {.python .cell-code code-fold=\"true\" code-summary=\"Show the code\"}\n%%itikz --temp-dir --tex-packages=tikz --tikz-libraries=arrows.meta --implicit-standalone\n\\begin{tikzpicture}[scale=1.5]\n\\draw[blue, rounded corners] (0,0) rectangle (3,5);\n\\node(A) at (1.5,4.75) {Caller};\n\\node(B) at (1.5,3.50) {};\n\\node(C) at (1.5,3.20) {};\n\\node(call) at (2.20,4.20) {call};\n\\node(D) at (1.5,0.20) {};\n\\node(F) at (5.5,4.75) {Function};\n\\node(Func) at (5.55,4.50) {};\n\\node(Return) at (5.55,0.25) {};\n\\node(return_back) at (6.2,0.50) {\\texttt{return}};\n\\draw[dashed, -{Stealth[length=3mm]}] (A) -- (B);\n\\draw[dashed, -{Stealth[length=3mm]}] (B) -- (Func);\n\\draw[dashed, -{Stealth[length=3mm]}] (Func) -- (Return);\n\\draw[dashed, -{Stealth[length=3mm]}] (Return) -- (C);\n\\draw[dashed, -{Stealth[length=3mm]}] (C) -- (D);\n\\draw[blue, rounded corners] (4,0) rectangle (7,5);\n\\end{tikzpicture}\n```\n\n::: {.cell-output .cell-output-display execution_count=2}\n![](index_files/figure-html/cell-3-output-1.svg){}\n:::\n:::\n\n\nFig. Functions - control flow\n:::\n\n:::{.text-center}\n\n::: {.cell execution_count=3}\n``` {.python .cell-code code-fold=\"true\" code-summary=\"Show the code\"}\n%%itikz --temp-dir --tex-packages=tikz --tikz-libraries=arrows.meta --implicit-standalone\n\\begin{tikzpicture}[scale=1.5]\n\\draw[blue, rounded corners] (0,0) rectangle (3,7);\n\\node(F) at (5.5,6.75) {Coroutine};\n\\node(A) at (1.5,6.75) {Caller};\n\\node(B) at (1.5,5.50) {};\n\\node(coro_A) at (5.55,6.50) {};\n\\node(coro_B) at (5.55,5.20) {};\n\\node(suspend_1) at (4.75,5.70) {suspend};\n\\node(coyield_1) at (6.50,5.25) {\\texttt{co\\_yield}};\n\\node(call_1) at (2.20,6.20) {call};\n\\node(C) at (1.5,5.20) {};\n\\node(D) at (1.5,3.70) {};\n\\node(coro_C) at (5.55,3.70) {};\n\\node(resume_1) at (4.75,4.10) {resume};\n\\node(coro_D) at (5.55,2.20) {};\n\\node(suspend_2) at (4.75,2.70) {suspend};\n\\node(coyield_2) at (6.50,2.25) {\\texttt{co\\_yield}};\n\\node(E) at (1.5, 2.20) {};\n\\node(F) at (1.5, 1.25) {};\n\\node(resume_2) at (4.75,1.55) {resume};\n\\node(coro_F) at (5.55, 1.25) {};\n\\node(coro_G) at (5.55, 0.25) {};\n\\node(return_back) at (6.2,0.25) {\\texttt{co\\_return}};\n\\node(H) at (1.5, 0.25) {};\n\\draw[dashed, -{Stealth[length=3mm]}] (A) -- (B);\n\\draw[dashed, -{Stealth[length=3mm]}] (B) -- (coro_A);\n\\draw[dashed, -{Stealth[length=3mm]}] (coro_A) -- (coro_B);\n\\draw[dashed, -{Stealth[length=3mm]}] (coro_B) -- (C);\n\\draw[dashed, -{Stealth[length=3mm]}] (C) -- (D);\n\\draw[dashed, -{Stealth[length=3mm]}] (D) -- (coro_C);\n\\draw[dashed, -{Stealth[length=3mm]}] (coro_C) -- (coro_D);\n\\draw[dashed, -{Stealth[length=3mm]}] (coro_D) -- (E);\n\\draw[dashed, -{Stealth[length=3mm]}] (E) -- (F);\n\\draw[dashed, -{Stealth[length=3mm]}] (F) -- (coro_F);\n\\draw[dashed, -{Stealth[length=3mm]}] (coro_F) -- (coro_G);\n\\draw[dashed, -{Stealth[length=3mm]}] (coro_G) -- (H);\n\\draw[blue, rounded corners] (4,0) rectangle (7,7);\n\\end{tikzpicture}\n```\n\n::: {.cell-output .cell-output-display execution_count=3}\n![](index_files/figure-html/cell-4-output-1.svg){}\n:::\n:::\n\n\nFig. Coroutines - control flow\n:::\n\nCoroutine frames (state of all the local variables at the point where you paused) may be stored on the stack or on the dynamic heap. C++ implements the latter approach - stackless coroutines.\n\nWhen using coroutines, we are talking about cooperative multi-tasking. As a quick 101, in preemptive multitasking, a special hardware timer interrupt is sent to the CPU periodically, the register state of the currently running process is saved to the main memory (in a data-structure called the process context) and the OS kernel acquires control of the CPU. The OS scheduler uses a scheduling policy such as round-robin to schedule another process from the process queue, copies its context from main memory to the CPU registers and transfers control to it. This is called a context switch. In cooperative multitasking, each process/thread, once running decides for how long to keep the CPU, and (crucially) when it is time to give it up so that another thread can use it.\n\n### A simple example {.unnumbered}\n\nLet's start with a simple example. Let's say, you want to compute the Fibonacci sequence. First thing, that you'd do, is code up a function `fibo(int)` that returns a sequence in a vector.\n\n```cpp\n// Returns a vector containing the \n// first n elements of the Fibonacci \n// series: \n// 1, 1, 2, 3, 5, 8, 13, 21, ...\nstd::vector<int> fibo(int n)\n{\n    std::vector<int> results{};\n    int a_prev{1}, a_curr{1};\n    int a_next{0};\n    results.push_back(a_prev);\n    results.push_back(a_curr);\n    for(int i=2;i<=n;++i)\n    {\n        a_next = a_prev + a_curr;\n        results.push_back(a_next);\n        a_prev = a_curr;\n        a_curr = a_next;\n    }\n\n    return results;\n}\n```\n\nThis naive implementation has a number of disadvantages. For example, this function will always require $O(n)$ storage. Fibonacci has a simple recursive equation, but if I have a complex computation, and I am only ever processing the numbers sequentially one at a time, then it makes no sense to pay for the entire $O(n)$ storage. Another problem is that, if you are dealing with an infinite range, then it becomes a lot harder to handle.\n\nA different way of implementing this would be as follows. Instead of our function returning a range in a `vector`, we are just going to return a `generator` object; this `generator` object has then a `next()` member function and then every call to the `next()` member function gives us back the next number in the sequence.\n\n```cpp\nstruct FiboGenerator\n{\n    // Successive calls to next()  \n    // return the numbers from the \n    // Fibonacci series\n    int next();\n}\n\n// Returns a new FiboGenerator object\n// that will start from the first \n// Fibonacci number\nFiboGenerator makeFiboGenerator();\n```\n\nThe interesting question is: Is `makeFiboGenerator()` a coroutine? And we really can't tell - it's an implementation detail. All we see is an interface. This is actually the most important thing about coroutines. From the outside, they just look and behave like functions. From the outside, there is no way to tell, whether they've been implemented using a coroutine or not. The only thing that we need to know as the user of this function is the interface of the object `FiboGenerator`.\n\n### The coroutine return type {.unnumbered}\n\nThe initial call to the coroutine function will produce this return object of a certain `ReturnType` and hand it back to the caller. The interface of this type is what is going to determine what the coroutine is capable of. Since coroutines are super-flexible, we can do a whole lot with this return object. If you have some coroutine, and you want to understand what it's doing, the first thing you should look at is the `ReturnType`, and what it's interface is. The important thing here is, we design this `ReturnType`. If you are writing a coroutine, you can decide, what goes into this interface.\n\n### How to turn a function into a coroutine? {.unnumbered}\n\nThe compiler looks for one of the three keywords in the implementation: `co_yield`, `co_await` and `co_return`.\n\n| Keyword | Action | State |\n|---------|--------|-------|\n| `co_yield` | Output | Suspended |\n| `co_return` | Output | Ended |\n| `co_await` | Input | Suspended |\n\n: Coroutine keywords and their effects\n\nIn the preceding table, we see that after `co_yield` and `co_await`, the coroutine suspends itself and after `co_return`, it is terminated (`co_return` is the equivalent of the `return` statement in the C++ function).\n\nA classical function starts executing when it's called and normally terminates with a `return` statement or just when the function's end is reached. A function runs from the beginning to end. It may call another function (or even itself if it is recursive) and it may throw exceptions or have different return points. But it always runs from the beginning to the end.\n\nA coroutine is different. A coroutine is a function that can suspend itself. The flow for a coroutine may be like the following pseudo-code:\n\n```cpp\nReturnType coroutine(){\n    do_something();\n    co_yield;\n    do_something_else();\n    co_yield;\n    do_more_work();\n    co_return;\n}\n```\n\nYou should think of the coroutine function not as a function in the classical sense, but rather as a factory function that returns a coroutine object and this coroutine object is the one that holds all the state, and one which you can resume to continue the computation later on.\n\n### Use-cases for coroutines {.unnumbered}\n\n**Asynchronous computation.** Suppose we are tasked with designing a simple echo server. We listen for incoming data from a client socket and we simply send it back to the client. At some point in our code for the echo server, we will have a piece of logic like below:\n\n```cpp\nvoid session(Socket sock){\n    char buffer[1024];\n    int len = sock.read({buffer});\n    sock.write({buffer,len});\n    log(buffer);\n}\n```\n\nWe create a `buffer`, then call the `read` that reads packets from the NIC and stores them in the buffer. The return value `len` will tell us how many bytes we read. Then, we shrink the `buffer` - we create a smaller one with `len` bytes and we write it back. Finally, we perform some logging. If we run it, it will probably work, but we certainly don't want to write a server like this. Say one of the clients requests communication and we are in a session. They say, they are ready to send the data, so we are blocking on the `read`, but maybe they send us this data in 2 minutes, or 5 minutes or even more. And other clients keep waiting.\n\nWhat we could do is start this session and run it in a separate thread. And this would work, because if this thread is blocked, and if there are other threads in this server, they would run in exchange during the wait time. If we have a threadpool, we'll just grab a thread from the threadpool, tell whatever system manages the pool to run this `session(Socket)` function there.\n\nThis solution is still far from ideal. These are operating system emulated threads and the OS will have to manage which threads get CPU time. It will have to preempt one thread, run another. This preemption will occur at random moments, when we least expect it. We could have data-races and likely require protection of a critical section/resource using mutexes.\n\nOne alternative is to use an asynchronous framework and rewrite our code as follows:\n\n```cpp\nvoid session(Socket sock){\n    struct State{ Socket sock; char buffer[1024]; };\n    \n    // Heap allocate the state\n    auto state = std::make_shared<State>(sock, buffer);\n\n    auto on_read_finished_callback = /* ... */\n\n    // Perform an asynchronous read \n    state->socket.async_read( state->buffer, \n                             on_read_finished_callback );\n}\n```\n\nThe `async_read()` call is a request to the framework, which says that we are interested in data being read to our buffer at some point convenient to the client. When this succeeds, call our `on_read_finished_callback`. So, we are just making this association at this point and the server can move on to doing other stuff.\n\nThe `read` operation may fail for a number of reasons, so a good approach would be supply two arguments to the `on_read_finished_callback`: (i) An error code (ii) The number of bytes received, if there were no errors. We can try to implement it, by checking the error-code.\n\n```cpp\nvoid session(Socket sock){\n    struct State{ Socket sock; char buffer[1024]; };\n    \n    // Heap allocate the state\n    auto state = std::make_shared<State>(sock, buffer);\n\n    auto on_read_finished_callback = [&state](\n        error_code ec, \n        size_t len\n    )\n    {\n        auto done = /* ... */\n        if(!ec)\n        {\n            // Perform an asynchronous write\n            state->socket.async_write( \n                state->buffer, \n                done \n            );    \n        }\n    }\n\n    // Perform an asynchronous read \n    state->socket.async_read( state->buffer, \n                             on_read_finished_callback );\n}\n```\n\nNow, we don't have exception handling, because we have spread our logic over a number of callbacks. We are only left with `if` statements. If the reading all went fine, we can write the data back by shrinking the buffer, requesting that the `write` is performed at some time, not necessarily now - maybe later. When this `write` is performed, we would like to call another callback `done`. We don't wait until this callback is called or `write` is performed. At this point, we just make an association. It is possible, that at a future time, the `write` succeeds and then the callback `done` is called. So, we have to define it.\n\n```cpp\nvoid session(Socket sock){\n    struct State{ Socket sock; char buffer[1024]; };\n    \n    // Heap allocate the state\n    auto state = std::make_shared<State>(sock, buffer);\n\n    auto on_read_finished_callback = [state](\n        error_code ec, \n        size_t len\n    )\n    {\n        auto done = [state](error_code ec, size_t len)\n        {\n            if(!ec)\n                log();\n        }\n        if(!ec)\n        {\n            // Perform an asynchronous write\n            state->socket.async_write( \n                state->buffer, \n                done \n            );    \n        }\n    }\n\n    // Perform an asynchronous read \n    state->socket.async_read( state->buffer, \n                             on_read_finished_callback );\n}\n```\n\n`done` has a similar structure. It takes two arguments - the error code that tells if the `write` went fine and the number of bytes written `len`. If there were no errors on `write` and everything went fine, we can do the logging. Implicitly, \n\nSo, the `session` makes two associations: \n\n$$\n\\begin{align*}\n\\text{On finishing read} &\\mapsto \\texttt{on\\_finished\\_read\\_callback} \\\\\n\\text{On finishing write} &\\mapsto \\texttt{done} \\\\\n\\text{Accepting a new client connection} &\\mapsto \\texttt{session}\n\\end{align*}\n$$\n\nAnd implicitly there is a third association even though we cannot see it here - this entire function `session` is most likely a callback, in response to an event like $\\text{On client connection established}$. So, the server will be many different associations of events to callbacks at different levels. \n\nPay attention to the `state`. We said that, we wanted to allocate it on the heap and manage it through a `shared_ptr`. We pass this `shared_ptr<State>` by value to every single callback. This way, I make sure that the last one who touches this session turns off the lights and deallocates `state`. \n\nWhile this is a toy-example, in real production code, there can be a long sequence of steps and calling lambdas inside lambdas can obfuscate the meaning of the code. We already see a weird inversion of control flow, when reading the code.\n\nOne thing to note before I go to coroutines is that, even though those things happen asynchronously, there is a sequence to it, that is not violated. We only perform a `write` when we know that the `read` has succeeded. We only perform the `log` after the `write` has succeeded. \n\n$$\n\\texttt{read} \\to \\texttt{write} \\to \\texttt{log}\n$$\n\nAs an application programmer we determine, when we yield control to the system other sessions. It's not that the system pre-empts this task. \n\nA coroutine implementation of the same echo'ing session would look like this:\n\n```cpp\nTask<void> session(Socket sock){\n    char buffer[1024];\n    int len = co_await sock.async_read({buffer});\n    co_await sock.async_write({buffer,len});\n    log(buffer);\n}\n```\n\nThis looks very similar to the sequential code, except that we use this `co_await` keyword. You have clear indication of the points where the coroutine will be suspended. Also, note that previously the function `session` returned `void`. Now, we are returning something - a `Task<void>`. This will be a handle to the coroutine and it's how the outside world will be communicating with the coroutine. \n\n**Suspended computation**. A second use-case is that coroutines support lazy evaluation. Just as in the fibonacci example, sometimes we want to avoid doing unecessary evaluation. Lazy evaluation doesn't do any work unless it's absolutely necessary. This can also potentially make your code more efficient. Lazy evaluation also supports programming with infinite lists. \n\n## The smallest coroutine\n\nThe following code is the simplest implementation of a coroutine:\n\n```cpp\n#include <coroutine>\nvoid coro_func(){\n    co_return;\n}\n\nint main(){\n    coro_func();\n}\n```\n\n[Compiler Explorer](https://compiler-explorer.com/z/W3GoWPoEs)\n\nOur first coroutine will just return nothing. It will not do anything else. Sadly, the preceding code is too simple for a functional coroutine and it will not compile. When compiling with `gcc 15.2`, we get the following error:\n\n```shell\n<source>: In function 'void coro_func()':\n<source>:4:5: error: unable to find the promise type for this coroutine\n    4 |     co_return;\n      |     ^~~~~~~~~\n```\n\nLooking at C++ reference, we see that the return type of a coroutine must define a type named `promise_type`. Following the reference advice, we can write a new version of our coroutine.\n\n```cpp\n#include <coroutine>\nstruct Task\n{\n    struct promise_type\n    {\n\n    };\n};\n\nTask coro_func(){\n    co_return;\n}\n\nint main(){\n    coro_func();\n}\n```\n[Compiler Explorer](https://compiler-explorer.com/z/G957defsr)\n\n",
    "supporting": [
      "index_files"
    ],
    "filters": [],
    "includes": {}
  }
}