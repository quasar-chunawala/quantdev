---
title: "Basic thread-safe stack and queue"
author: "Quasar"
date: "2025-02-23"
categories: [C++]      
image: "cpp.jpg"
toc: true
toc-depth: 3
format:
    html:
        code-tools: true
        code-block-border-left: true
        code-annotations: below
        highlight-style: pygments
---

# Basic thread-safe stack and queue

We can use C++ synchronization primitives to implement a basic thread-safe stack and queue.

## Thread-safe stack

### Implementation Notes


```cpp
#include <iostream>
#include <stack>
#include <algorithm>
#include <thread>
#include <mutex>
#include <memory>
#include <type_traits>
#include <concepts>
#include <shared_mutex>

namespace dev {
   
    template<typename T>
    
    class threadsafe_stack {
    public:

        using Mutex = std::shared_mutex;

        /* Constructors */
        
        // Default constructor
        threadsafe_stack() {}

        /*
        * This stack is copy-constructible. The copy constructor locks the mutex in the 
        * source object and then copies the internal stack.
        */
        threadsafe_stack(const threadsafe_stack& other) {
            std::unique_lock<Mutex> lck(other.mtx);
            m_stack = other.m_stack;
        }

        // Copy assignment
        threadsafe_stack& operator=(const threadsafe_stack& other) = delete;

        ~threadsafe_stack() = default;

        /*
        * pop() is a wrapper over std::stack<T>::top() and std::stack<T>::pop().
        * This interface avoids any race conditions that occur between calls to top()
        * and pop().
        */
        std::shared_ptr<T> pop()
        {
            std::unique_lock<Mutex> lck(mtx);
            if (m_stack.empty())
                throw std::exception("Exception - pop() invoked on an empty stack!");

            auto result = std::make_shared<T>(std::move(m_stack.top()));
            m_stack.pop();
            return result;
        }

        void pop(T& result)
        {
            std::unique_lock<Mutex> lck(mtx);
            if (m_stack.empty())
                throw std::exception("Exception - pop() invoked on an empty stack");

            result = std::move(m_stack.top());
            m_stack.pop();
        }

        void push(T value)
        {
            std::unique_lock<Mutex> lck(mtx);
            m_stack.push(std::move(value));
        }

        int size() {
            std::shared_lock<Mutex> lck(mtx);
            return m_stack.size();
        }

        /* 
        * Acquire a std::shared_lock<Mtx> on the mutex, so multiple
        * readers can read the stack.
        */
        bool empty() {
            std::shared_lock<Mutex> lck(mtx);
            return m_stack.empty();
        }

    private:
        std::stack<T> m_stack;
        Mutex mtx;
    };
}

int main()
{
    dev::threadsafe_stack<int> stck;
    
    std::thread writer1(
        [&stck]() {
            for (int i{ 1 };i <= 1000;++i) {
                stck.push(i);
            }
        }
    );

    std::thread writer2(
        [&stck]() {
            for (int i{ 1001 };i <= 2000;++i) {
                stck.push(i);
            }
        }
    );

    writer1.join();
    writer2.join();

    std::cout << "\n" << "Stack size = " << stck.size();
}
```

## Producer-consumer problem

In the *producer-consumer problem*, we have two classes of threads, producers and consumers and a buffer containing a fixed number of slots. A producer thread attempts to put something into the next empty buffer slot, a consumer thread attempts to take something out of the next occupied buffer slot. The synchronization conditions are that producers cannot proceed unless there are empty slots and consumers cannot proceed unless there are occupied slots. The problem occurs because of the different rates at which producers deposit and consumers exhaust data.

This is a classic, but frequently occurring synchronization problem. For example, the heart of the implementation of UNIX pipes is an instance of this problem.

Consider a single, fixed-size buffer as if it were connected end-to-end, such that the oldest entry is processed first. This is a circular FIFO queue.

What do we use SPSC FIFO queues for? In the industry, you often have a pipeline of processes. For example, you have one thread reading from sockets, another thread that handles the messages from the sockets and maybe processes them and produces a result and a third thread writes a response to the network. Those can be connected by SPSC FIFO queues. There's a couple of advantages to this. All these advantages and disadvantages are subject to measurement, so always measure. It may improve the throughput over just a single thread doing all $3$ of these operations, in fact, I'll be surprised if it didn't. It also should improve the resiliency of the application to spikes in message traffic. Some of the disadvantages are that you have to manage 3 threads and it probably uses more memory, because each of the FIFO queues needs place to store its messages.

We all have come across circular FIFO queues. We usually have two cursors - `rear` and `front`. Items are pushed to the `rear` of the queue and popped off the `front` of the queue.

![Circular FIFO Queue](circular_fifo_queue.jpg){fig-align="center" width=40% height=40%}

When we `push(42)` into the FIFO queue, the `rear` cursor is incremented and each time we `pop()`, the `front` cursor is incremented. When the `front` cursor and the `rear` cursor are no longer equal, the FIFO queue is no longer empty. Eventually, we push so many values in, that the FIFO queue fills up. At this point, the `rear` cursor is `capacity` greater than the `front` cursor.

The FIFO queue empty and queue full conditions use the remainder operator `%`. Division uses $20$ to $30$ cycles so it is a bit expensive. Another approach is to constrain the buffer size to an integral power of $2$, and use the bitwise `&` operator and that's a $1$ cycle operation. 

