[
  {
    "objectID": "sell_side_quant_critical_path.html",
    "href": "sell_side_quant_critical_path.html",
    "title": "Sell-side quant",
    "section": "",
    "text": "It’s crucial to set clear and very concrete career goals early on. Rather than passively waiting for guidance or instructions, actively figure out what you aspire to achieve, network strategically and proactively to gather information. People who take more risks and more initiatives are more successful over the years - maybe still so after survivorship bias been adjusted.\nIf you are an aspiring quantitative researcher, cultivate an active puzzle-solving and game-solving culture. My advice for preparing is to stay curious, approach brain teasers as problem-solving exercises rather than stressful tests, and perhaps find (or start one!) a university club with like-minded peers to practice and share ideas. Do math early and often. Learn how to code early!"
  },
  {
    "objectID": "sell_side_quant_critical_path.html#sell-side-quant-interviews",
    "href": "sell_side_quant_critical_path.html#sell-side-quant-interviews",
    "title": "Sell-side quant",
    "section": "Sell-side Quant Interviews",
    "text": "Sell-side Quant Interviews\nSell-side quant interviews test fluid intelligence, the ability to use logic and intuition to crack quant puzzles. The bar for these interviews is certainly high, there is almost zero tolerance for mistakes. Most interviews consist of four stages:\n\nGeneral brain-teasers and puzzles\nMath puzzles\nProgramming/Algorithmic thinking skills (C++ language features, STL, Python)\nDeal Economics"
  },
  {
    "objectID": "sell_side_quant_critical_path.html#quant-forums",
    "href": "sell_side_quant_critical_path.html#quant-forums",
    "title": "Sell-side quant",
    "section": "Quant Forums",
    "text": "Quant Forums\n\nQuantNet run by Andy Nguyen\nquant.stackexchange.com\nWilmott Forums\nr/quant on reddit\nMathematics and Finance server on Discord.\n\nQuantNet is an extremely useful forum for aspirants looking to apply to a top school or break into the field. The collective knowledge and network connections on this website go a long way in reducing the information assymetry. QN also publishes university rankings each year, offering detailed insights into placement and admission stats."
  },
  {
    "objectID": "sell_side_quant_critical_path.html#books",
    "href": "sell_side_quant_critical_path.html#books",
    "title": "Sell-side quant",
    "section": "Books",
    "text": "Books\nI suggest a critical path for learning basic financial mathematics and topics useful for front-office desk-quant roles at banks.\n\nWarmup\n\nThe Primer series of books authored by Dan Stefanica sold by FEPress.\nThe Concepts and Practice of Mathematical Finance by Mark Joshi.\nStochastic Calculus for Finance, Volume I by Steven Shreve.\n\n\n\nFundamentals\n\nUnderstanding Analysis(UA) by Stephen Abbott\nLinear Algebra Done Right(LADR), by Sheldon Axler\nIntroduction to Probability, by Joe Blitzstein\nVector calculus, S.J. Colley\nLinear Analysis, by Kreider, Kuller, Ostberg and Perkins(KKOP)\n\nHere are my unofficial solutions to Stephen Abbott’s Understanding Analysis.\nKKOP was suggested to me by Daniel Duffy, it remains, to date, a favorite introductory text on differential equations.\n\n\nIntermediate\n\nAn introduction to Partial Differential Equations, Strauss\nNumerical methods for Computational finance, Daniel Duffy\nProbability Foundations, lectures taught by Dr. Krishna Jagannathan\n\n\n\nStochastic Calculus\n\nA first course in Stochastic Calculus by Louis Pierre Arguin\nArbitrage Theory in Continuous Time by Bjork.\n\nI really like LP’s book, for it, interleaves rigor and intuition, written by a quant and trader.\nBjork reads really well. As an economist, he explains important results such as Fundamental Theorems of Asset Pricing (FTAP), Girsanov theorem, change of measure with such clarity."
  },
  {
    "objectID": "sell_side_quant_critical_path.html#blog-rolls",
    "href": "sell_side_quant_critical_path.html#blog-rolls",
    "title": "Sell-side quant",
    "section": "Blog-rolls",
    "text": "Blog-rolls\n\nChase the devil"
  },
  {
    "objectID": "posts/ranges_and_views/index.html",
    "href": "posts/ranges_and_views/index.html",
    "title": "C++ Ranges",
    "section": "",
    "text": "A range is a programmatic abstraction for a sequence of elements, bounded by two iterators(one to the first element of the sequence and one to the last element).\nContainers such as std::vector, std::list and std::map are concrete implementations of the range abstraction. The standard algorithms are generic. They are container agnostic. They know nothing about std::vector, std::map or std::list. They handle range abstractions with the help of a pair of iterators. However, this has a shortcoming: we always need a begin() and end() iterator from a container. Here are some examples:\n// sort a vector\nstd::vector v{1, 2, 3, 4, 5};\nstd::sort(v.begin(), v.end());\n\n// count the even numbers of an array\nstd::array&lt;int, 5&gt;a{1, 5, 3, 2, 4};\nauto even_count = std::count_if(\n    a.begin(),\n    a.end(),\n    [](int const n){ return n % 2 == 0; }\n);\nThere are few cases when we only need to process a part of the container’s elements. In the vast majority of the cases, we need to write v.begin() and v.end() over and over again. Ideally, we would prefer to shorten all this and be able to write the following:\n// sort a vector\nstd::vector v{1, 2, 3, 4, 5};\nstd::sort(v.begin(), v.end());\n\n// count the even numbers of an array\nstd::array&lt;int, 5&gt;a{1, 5, 3, 2, 4};\nauto even_count = std::count_if(\n    a.begin(),\n    a.end(),\n    [](int const n){ return n % 2 == 0; }\n);\nOn the other hand, we often need to compose multiple operations together. Most of the time that involves many operations and code that is too verbose even when using standard algorithms. Consider the following example: given a sequence of integers, we want to print to the console the square of all even numbers, except the first two, in descending order of their value (not their position in the sequence). There are multiple ways to solve this problem. Here is one possible solution:\nstd::vector&lt;int&gt; v{1, 5, 3, 2, 8, 7, 6, 4};\n\n// copy only the even elements\nstd::vector&lt;int&gt; temp;\nstd::copy_if(v.begin(), v.end(), std::back_inserter(temp), [](int n){\n    return n % 2 == 0;\n});\n\n// sort the elements\nstd::sort(temp.begin(), temp.end(), [](int a, int b){ return a &gt; b; });\n\n// remove the first two\ntemp.erase(temp.begin() + temp.size() - 2, temp.end());\n\n// transform the elements\nstd::transform(temp.begin(), temp.end(), [](int const n){ return n*n; });\n\n// print each element\nstd::for_each(temp.begin(), temp.end(), [](int n){ std::println(\"{}, n\"); });\nWhile anyone familiar with standard algorithms can read this code, there are several downsides. Its a lot of code to write and also requires a temporary container with repetitive calls to begin() and end(). All of the computation is done eagerly, so the intermediate results of each step are held in memory.\nMost people would easily understand the following version of the previous code and also prefer to write it as such:\nstd::vector&lt;int&gt; v{1, 5, 3, 2, 8, 7, 6, 4};\n\nusing std::ranges = stdr;\nusing std::ranges::views = stdv;\n\nstdr::sort(v);\n\nauto r = v  | filter([](int n) { return n % 2 == 0; })\n            | drop(2)\n            | reverse\n            | transform([](int n){ return n*n; });\nThis is what the C++20 standard provides with the help of the ranges library. This has two main components:\n\nRange algorithms, which enable us to operate on concrete ranges (standard containers or ranges) and not on abstract ranges delimited by a pair of iterators\nViews or range adapters, which represent non-owning iterable sequences. They enable us to compose operations more easily such as in the last example.\n\n\n\n\nThe term range refers to an abstraction that defines a sequence of elements bounded by start and end iterators. A range, therefore, represents an iterable sequence of elements. However, such a sequence can be defined in several ways:\n\nWith a begin iterator and an end sentinel. Such a sequence is iterated from beginning to the end. A sentinel is an object that indicates the end of the sequence. It can have the same type as the iuterator type or it can be of a differnt type.\nWith a start object and a size(number of elements), representing a so-called counted sequence. Such a sequence is iterated \\(N\\) times (where $N represents the size) from the start.\nWith a start and a predicate, representing a so-called conditionally termninated sequence. Such a sequence is iterated from the start until the predicate returns false.\nWith only a start value, representing a so-called unbounded sequence. Such a sequence can be iterated indefinitely.\n\nAll these kinds of iterable sequences are considered ranges. Because a range is an abstraction, the C++20 library defines a series a of concepts to describe the requirements for range types. These are available in the &lt;ranges&gt; header and the std::ranges namespace. The following table presents a list of range concepts:\n\n\n\n\n\n\n\nName\nDescription\n\n\n\n\nrange\nDefines the requires for a type R to be a range by provdiding a begin iterator and an end sentinel. The iterator and the sentinel can be of different types.\n\n\nborrowed_range\nDefines the requirements for a type R so that a function can take an object of this type by value and return iterators obtained from this object without the danger of dangling.\n\n\nsized_range\nDefines the requirements for a type R to be a range that knows its size in constant time.\n\n\ncommon_range\nDefines the requirements for a type R to be a range whose iterator and sentinel types are equal.\n\n\nview\nDefines the requirements of type R that is a range to have constant-time, copy, move and assignment opertions.\n\n\nviewable_range\nDefines the requirements for a range type R to be convertible to a view.\n\n\n\nOther range concepts such as input_range, output_range, forward_range, bidirectional_range, random_access_range, contiguous_range are modeled after the corresponding iterator concepts.\nA view is a lightweight object that applies the transformation only when a new element is requested(iterated) and not hen the view is created. Its key feature is lazy evaluation. It is like a stream. So, views are lightweight objects, with non-owning semantics. They don’t own the underlying data.\nThere is a series of views provided with C++20 and new views have also been included in C++23. Views are available by including the &lt;ranges&gt; header under the std::ranges namespace, for example, std::ranges::iota_view.\nThe iota view is part of a special category of views called factories. These factories are views over newly generated ranges. The following factories are available in the ranges library:\n\n\n\n\n\n\n\n\nType\nVariable\nDescription\n\n\n\n\nranges::empty_view\nranges::views::empty\nGenerates a view with no elements of T type\n\n\nranges::single_view\nranges::views::single\nGenerates a view with a single element of a T type\n\n\nranges::iota_view\nranges::views::iota\nGenerates a view of a sequence of consecutive elements, from a start value to an end value (a bounded view) or indefinitely (an unbounded view)\n\n\nranges::basic_iostream_view\nranges::views::istream\nGenerates a view of the sequence of elements by applying the operator &gt;&gt; repeatedly\n\n\n\nHere is a quick example for using iota:\n// using iota_view\nnamespace stdr = std::ranges;\nnamespace stdv = std::views;\n\nfor(auto i : stdr::iota_view(1,10))\n    std::print(\"{}, \", i);\n\n// using stdv::iota\nfor(auto i : stdv::iota(1,10))\n    std::print(\"{}, \", i);\nIf you are wondering why empty_view and single_view are useful, the answer should not be hard to find. These are useful in template code that handles ranges where empty ranges or ranges with one element are valid inputs. you don’t want multiple overloads of a function template for handling these special cases; instead, you can pass an empty_view or single_view range. The following snippets show several examples of using these factories.\n#include &lt;print&gt;\n#include &lt;ranges&gt;\n\n// namespace alias\nnamespace stdr = std::ranges;\nnamespace stdv = std::views;\n\nint main()\n{\n    constexpr stdr::empty_view&lt;int&gt; ev;\n    static_assert(stdr::empty(ev));\n    static_assert(stdr::size(ev) == 0);\n    static_assert(stdr::data(ev) == nullptr);\n\n    constexpr stdr::single_view&lt;int&gt; sv{42};\n    static_assert(!stdr::empty(sv));\n    static_assert(stdr::size(sv) == 1);\n    static_assert(*stdr::data(sv) == 42);\n    return 0;\n}\nCompiler Explorer\nFor the iota_view, we have already seen a couple of examples with a bounded view. The next snippet shows again an example not only using a bounded view generated with iota but also an unbounded view, also generated with iota:\n#include &lt;print&gt;\n#include &lt;ranges&gt;\n#include &lt;algorithm&gt;\n\nnamespace stdr = std::ranges;\nnamespace stdv = std::views;\n\nint main(){\n    auto v1 = stdv::iota(1,10);\n    stdr::for_each(v1,[](int n){\n        std::println(\"{}\", n);\n    });\n\n    auto v2 =   stdv::iota(1)\n                | stdv::take(9);\n\n    stdr::for_each(v2,[](int n){\n        std::println(\"{}\", n);\n    });                \n    return 0;\n}\nCompiler Explorer\nThe last example utilizes another view called take_view. This produces a view of the first \\(N\\) elements (in my example \\(9\\)) of another view (in my example, the unbounded view produced by iota). I will discuss more on this shortly.\nThere are other standard views that I implore you to check out on cppreference.com. I tried out a few toy examples below:\n#include &lt;iostream&gt;\n#include &lt;print&gt;\n#include &lt;ranges&gt;\n#include &lt;vector&gt;\n#include &lt;algorithm&gt;\n#include &lt;string_view&gt;\n#include &lt;iomanip&gt;\n#include &lt;tuple&gt;\n\nnamespace stdr = std::ranges;\nnamespace stdv = std::views;\n\nvoid print(auto data, std::string_view label){\n    std::cout &lt;&lt; \"\\n\" &lt;&lt; label &lt;&lt; \": \";\n    stdr::for_each(data,[](int n){\n        std::print(\"{}, \", n);\n    });\n}\n\nint main(){\n    auto data = stdr::iota_view(1,9);\n\n    // filter_view \n    // Only include elements satisfying a predicate\n    auto filter_data = data | stdv::filter([](int n){\n        return n % 3 == 0;\n    });\n    print(filter_data, \"filter\");\n\n    // transform_view\n    // Applies a mapping element-wise\n    auto squares = data | stdv::transform([](int n){\n        return n * n;\n    });\n    print(squares, \"squares\");\n\n    // take_view\n    // Grab the first N elements\n    auto first_ten = data | stdv::take(10);\n    print(first_ten, \"first_ten\");\n\n    // take_while_view\n    // Grab all elements starting with the first\n    // until an element is found that no longer \n    // satisfies the predicate\n    auto take_while_rslt = data | stdv::take_while([](int n){\n        return n &lt;= 5;\n    });\n    print(take_while_rslt, \"take_while_rslt\");\n\n    // drop_view \n    // skip the first N elements\n    auto drop_rslt = data | stdv::drop(3);\n    print(drop_rslt, \"drop_rslt\");\n\n    // drop_while_view\n    // skip elements until predicate is not met\n    auto drop_while_rslt = data | stdv::drop_while([](int n){\n        return n &lt;= 3;\n    });\n    print(drop_while_rslt, \"drop_while_rslt\");\n\n    // join_view\n    // Provides a view of a sequence generated by\n    // flattening multiple ranges\n    using namespace std::literals;\n    auto strings = {\n        \"C++ \"sv, \"is \"sv, \"a \"sv, \"general-purpose \"sv,\n        \"and \"sv, \"multi-paradigm \"sv, \"programming \"sv,\n        \"language\"sv\n        };\n    auto join_result = stdv::join(strings);\n    std::cout &lt;&lt; \"\\n\" &lt;&lt; \"join_result: \";\n    for(const char c: join_result)\n        std::cout &lt;&lt; c;\n\n    // join_with_view\n    // Provides a view of a sequence generated by \n    // flattening multiple ranges with a delimiter \n    // inserted between the elements of the view.\n    std::vector&lt;std::vector&lt;int&gt;&gt; rngs = {{1,2},{3,4},{5,6}};\n    auto join_with_rslt = rngs | stdv::join_with(',');\n    \n    // split_view\n    // Provides view of a sequence of ranges produced\n    // by splitting a range on a specified delimiter.\n    constexpr auto words{\"Hey,^_^C++^_^23^_^ranges^_^are^_^awesome!\"sv};\n    constexpr auto delim{\"^_^\"sv};\n    auto split_rslt = words | stdv::split(delim);\n\n    // reverse_view\n    // Provides a view of the elements of the \n    // underlying range in reverse order\n    auto reverse_rslt = stdv::reverse(data);\n    print(reverse_rslt, \"reverse_rslt\");\n\n    // keys_view, values_view and elements_view \n    // Provide a view by projecting the first, \n    // second and nth element respectively\n    // from a range of tuples.\n    const std::vector&lt;std::tuple&lt;std::string, double, bool&gt;&gt; quark_mass_charge\n    {\n        // name, MeV/c², has positive electric-charge:\n        {\"up\", 2.3, true}, {\"down\", 4.8, false},\n        {\"charm\", 1275, true}, {\"strange\", 95, false},\n        {\"top\", 173'210, true}, {\"bottom\", 4'180, false},\n    };\n\n    std::cout &lt;&lt; \"\\nQuark name:  | \";\n    auto names = stdv::keys(quark_mass_charge);\n    for(auto name : names)\n        std::cout &lt;&lt; std::setw(9) &lt;&lt; name &lt;&lt; \"|\";\n\n    std::cout &lt;&lt; \"\\nMass:        | \";    \n    auto masses = stdv::values(quark_mass_charge);\n    for(auto mass : masses)\n        std::cout &lt;&lt; std::setw(9) &lt;&lt; mass &lt;&lt; \"|\";\n\n    std::cout &lt;&lt; \"\\nCharge:      | \";    \n    auto charges = stdv::elements&lt;2&gt;(quark_mass_charge);\n    for(auto charge : charges)\n        std::cout &lt;&lt; std::setw(9) &lt;&lt; charge &lt;&lt; \"|\";        \n\n    // zip_view\n    // Create a view of tuples from the elements\n    // of an array of integers and a vector of\n    // doubles\n    std::array&lt;int, 4&gt; a{1, 2, 3, 4};\n    std::vector&lt;double&gt; v{10.0, 20.0, 30.0};\n    std::cout &lt;&lt; \"\\nzip_result: \";\n    for(auto z : stdv::zip(a, v))\n        std::print(\"{} \", z);\n\n    // zip_transform \n    // Create a view with the multiplied elements\n    // of an array of integers and vector of doubles\n    std::cout &lt;&lt; \"\\nzip_transform_result: \";\n    for(auto z : stdv::zip_transform(\n        std::multiplies&lt;double&gt;(), a, v\n    ))\n        std::print(\"{} \", z);\n\n    // adjacent_view\n    // Print the pairs of adjacent elements of a\n    // sequence of integers\n    std::cout &lt;&lt; \"\\nadjacent_result: \";\n    for(auto i : v | stdv::adjacent&lt;3&gt;)\n        std::print(\"{} \", i);\n\n    return 0;\n}\nCompiler Explorer\n\n\n\nThe standard library provides over a hundred general-purpose algorithms. Most of these algorithms have a new constrained version in std::ranges namespace. These algorithms are found in the &lt;algorithm&gt;, &lt;numeric&gt; and &lt;memory&gt; header.\n\nThey have the same name as the existing algorithms.\nThey have overloads that allow you to specify a range, either with a begin iterator and an end sentinel, or as a single range argument.\nThey have modified return types that provide more information about the execution.\nThey support projections to apply to the processed elements. A projection is an entity that can be invoked. It can be a pointer to a member function, a lambda expression, or a function pointer. Such a projection is applied to the range element before the algorithm logic uses the element.\n\nFrom cppreference.com, the rangified version of the copy_if algorithm has the following overloads:\ntemplate&lt; std::input_iterator I, std::sentinel_for&lt;I&gt; S, std::weakly_incrementable O,\n          class Proj = std::identity,\n          std::indirect_unary_predicate&lt;std::projected&lt;I, Proj&gt;&gt; Pred &gt;\nrequires std::indirectly_copyable&lt;I, O&gt;\nconstexpr copy_if_result&lt;I, O&gt;\n    copy_if( I first, S last, O result, Pred pred, Proj proj = {} );\ntemplate&lt; ranges::input_range R, std::weakly_incrementable O,\n          class Proj = std::identity,\n          std::indirect_unary_predicate&lt;\n              std::projected&lt;ranges::iterator_t&lt;R&gt;, Proj&gt;&gt; Pred &gt;\nrequires std::indirectly_copyable&lt;ranges::iterator_t&lt;R&gt;, O&gt;\nconstexpr copy_if_result&lt;ranges::borrowed_iterator_t&lt;R&gt;, O&gt;\n    copy_if( R&& r, O result, Pred pred, Proj proj = {} );\nThe signatures may look cryptic, but it’s easy to code up a few quick examples.\n#include &lt;iostream&gt;\n#include &lt;ranges&gt;\n#include &lt;algorithm&gt;\n#include &lt;vector&gt;\n\nnamespace stdr = std::ranges;\nnamespace stdv = std::ranges::views;\n\nint main()\n{\n    std::vector&lt;int&gt; v{1, 1, 2, 3, 5, 8, 13};\n    std::vector&lt;int&gt; o;\n\n    auto filter_odd = [](int n){ return n % 2 == 1; };\n    auto e1 = stdr::copy_if(v, std::back_inserter(o), filter_odd);\n\n    int arr[] = {1, 1, 2, 3, 5, 8, 13 };\n    auto e2 = stdr::copy_if(arr,\n        std::back_inserter(o), filter_odd\n    );\n\n    auto rng = stdr::iota_view(1,10);\n    auto e3 = stdr::copy_if(r, std::back_inserter(o), filter_odd);\n    return 0;\n}\nCompiler Explorer\nThese examples show two things: how to copy elements from a std::vector object and an array and how to copy elements from a view(a range adaptor). What they don’t show is projections. I’ll explore some examples on this shortly.\nOther constrained algorithms like all_of, any_of, none_of, find, find_if, copy, copy_if, move, copy_backward, move_backward, fill, fill_n, transform, sample, fold_left, fold_right are very useful in coding.\nA projection is an invocable entity. It’s basically a function adaptor. It affects the predicate, providing a way to perform function composition. It does not provide a way to change the algorithm. For instance, let’s say we have the following type:\nLet’s say we have the following type:\nstruct Point{\n    double x;\n    double y;\n};\nAlso, for the purpose of the explanation, let’s consider the following sequence of points:\nstd::vector&lt;Point&gt; points{\n    {1.0, 1.0},\n    {-1.0, 1.0},\n    {1.0, -1.0},\n    {-1.0, -1.0}\n}\nProjects allow us to perform composition on the predicate. For instance, let’s say we want to copy to a second vector all points below the \\(x\\)-axis (having a negative \\(y\\)-coordinate). We can code up the following:\nstd::vector&lt;Point&gt; points_below_x_axis;\nstdr::copy_if(points,\n    std::back_inserter(points_below_x_axis),\n    [](const Point& point){\n        return point.x &lt; 0;\n    }\n);\nHowever, we can also write equivalently:\nstd::vector&lt;Point&gt; points_below_x_axis;\nstdr::copy_if(points,\n    std::back_inserter(points_below_x_axis),\n    [](const Point& point){\n        return x &lt; 0;\n    },\n    &Point::x\n);\nThe projection, in this example, is the pointer-to-member expression &Point::x that is applied to each Point element before executing the predicate (which is a lambda expression). This is useful when already have reusable function objects/lambda expressions and you don’t want to write another one for passing different types.\n\n\n\nThe standard library contains a series of range adaptors that can be used for solving many different tasks. However, there are situations where we’d like to write our own custom randge adaptor."
  },
  {
    "objectID": "posts/ranges_and_views/index.html#what-is-a-range",
    "href": "posts/ranges_and_views/index.html#what-is-a-range",
    "title": "C++ Ranges",
    "section": "",
    "text": "A range is a programmatic abstraction for a sequence of elements, bounded by two iterators(one to the first element of the sequence and one to the last element).\nContainers such as std::vector, std::list and std::map are concrete implementations of the range abstraction. The standard algorithms are generic. They are container agnostic. They know nothing about std::vector, std::map or std::list. They handle range abstractions with the help of a pair of iterators. However, this has a shortcoming: we always need a begin() and end() iterator from a container. Here are some examples:\n// sort a vector\nstd::vector v{1, 2, 3, 4, 5};\nstd::sort(v.begin(), v.end());\n\n// count the even numbers of an array\nstd::array&lt;int, 5&gt;a{1, 5, 3, 2, 4};\nauto even_count = std::count_if(\n    a.begin(),\n    a.end(),\n    [](int const n){ return n % 2 == 0; }\n);\nThere are few cases when we only need to process a part of the container’s elements. In the vast majority of the cases, we need to write v.begin() and v.end() over and over again. Ideally, we would prefer to shorten all this and be able to write the following:\n// sort a vector\nstd::vector v{1, 2, 3, 4, 5};\nstd::sort(v.begin(), v.end());\n\n// count the even numbers of an array\nstd::array&lt;int, 5&gt;a{1, 5, 3, 2, 4};\nauto even_count = std::count_if(\n    a.begin(),\n    a.end(),\n    [](int const n){ return n % 2 == 0; }\n);\nOn the other hand, we often need to compose multiple operations together. Most of the time that involves many operations and code that is too verbose even when using standard algorithms. Consider the following example: given a sequence of integers, we want to print to the console the square of all even numbers, except the first two, in descending order of their value (not their position in the sequence). There are multiple ways to solve this problem. Here is one possible solution:\nstd::vector&lt;int&gt; v{1, 5, 3, 2, 8, 7, 6, 4};\n\n// copy only the even elements\nstd::vector&lt;int&gt; temp;\nstd::copy_if(v.begin(), v.end(), std::back_inserter(temp), [](int n){\n    return n % 2 == 0;\n});\n\n// sort the elements\nstd::sort(temp.begin(), temp.end(), [](int a, int b){ return a &gt; b; });\n\n// remove the first two\ntemp.erase(temp.begin() + temp.size() - 2, temp.end());\n\n// transform the elements\nstd::transform(temp.begin(), temp.end(), [](int const n){ return n*n; });\n\n// print each element\nstd::for_each(temp.begin(), temp.end(), [](int n){ std::println(\"{}, n\"); });\nWhile anyone familiar with standard algorithms can read this code, there are several downsides. Its a lot of code to write and also requires a temporary container with repetitive calls to begin() and end(). All of the computation is done eagerly, so the intermediate results of each step are held in memory.\nMost people would easily understand the following version of the previous code and also prefer to write it as such:\nstd::vector&lt;int&gt; v{1, 5, 3, 2, 8, 7, 6, 4};\n\nusing std::ranges = stdr;\nusing std::ranges::views = stdv;\n\nstdr::sort(v);\n\nauto r = v  | filter([](int n) { return n % 2 == 0; })\n            | drop(2)\n            | reverse\n            | transform([](int n){ return n*n; });\nThis is what the C++20 standard provides with the help of the ranges library. This has two main components:\n\nRange algorithms, which enable us to operate on concrete ranges (standard containers or ranges) and not on abstract ranges delimited by a pair of iterators\nViews or range adapters, which represent non-owning iterable sequences. They enable us to compose operations more easily such as in the last example."
  },
  {
    "objectID": "posts/ranges_and_views/index.html#understanding-range-concepts-and-views",
    "href": "posts/ranges_and_views/index.html#understanding-range-concepts-and-views",
    "title": "C++ Ranges",
    "section": "",
    "text": "The term range refers to an abstraction that defines a sequence of elements bounded by start and end iterators. A range, therefore, represents an iterable sequence of elements. However, such a sequence can be defined in several ways:\n\nWith a begin iterator and an end sentinel. Such a sequence is iterated from beginning to the end. A sentinel is an object that indicates the end of the sequence. It can have the same type as the iuterator type or it can be of a differnt type.\nWith a start object and a size(number of elements), representing a so-called counted sequence. Such a sequence is iterated \\(N\\) times (where $N represents the size) from the start.\nWith a start and a predicate, representing a so-called conditionally termninated sequence. Such a sequence is iterated from the start until the predicate returns false.\nWith only a start value, representing a so-called unbounded sequence. Such a sequence can be iterated indefinitely.\n\nAll these kinds of iterable sequences are considered ranges. Because a range is an abstraction, the C++20 library defines a series a of concepts to describe the requirements for range types. These are available in the &lt;ranges&gt; header and the std::ranges namespace. The following table presents a list of range concepts:\n\n\n\n\n\n\n\nName\nDescription\n\n\n\n\nrange\nDefines the requires for a type R to be a range by provdiding a begin iterator and an end sentinel. The iterator and the sentinel can be of different types.\n\n\nborrowed_range\nDefines the requirements for a type R so that a function can take an object of this type by value and return iterators obtained from this object without the danger of dangling.\n\n\nsized_range\nDefines the requirements for a type R to be a range that knows its size in constant time.\n\n\ncommon_range\nDefines the requirements for a type R to be a range whose iterator and sentinel types are equal.\n\n\nview\nDefines the requirements of type R that is a range to have constant-time, copy, move and assignment opertions.\n\n\nviewable_range\nDefines the requirements for a range type R to be convertible to a view.\n\n\n\nOther range concepts such as input_range, output_range, forward_range, bidirectional_range, random_access_range, contiguous_range are modeled after the corresponding iterator concepts.\nA view is a lightweight object that applies the transformation only when a new element is requested(iterated) and not hen the view is created. Its key feature is lazy evaluation. It is like a stream. So, views are lightweight objects, with non-owning semantics. They don’t own the underlying data.\nThere is a series of views provided with C++20 and new views have also been included in C++23. Views are available by including the &lt;ranges&gt; header under the std::ranges namespace, for example, std::ranges::iota_view.\nThe iota view is part of a special category of views called factories. These factories are views over newly generated ranges. The following factories are available in the ranges library:\n\n\n\n\n\n\n\n\nType\nVariable\nDescription\n\n\n\n\nranges::empty_view\nranges::views::empty\nGenerates a view with no elements of T type\n\n\nranges::single_view\nranges::views::single\nGenerates a view with a single element of a T type\n\n\nranges::iota_view\nranges::views::iota\nGenerates a view of a sequence of consecutive elements, from a start value to an end value (a bounded view) or indefinitely (an unbounded view)\n\n\nranges::basic_iostream_view\nranges::views::istream\nGenerates a view of the sequence of elements by applying the operator &gt;&gt; repeatedly\n\n\n\nHere is a quick example for using iota:\n// using iota_view\nnamespace stdr = std::ranges;\nnamespace stdv = std::views;\n\nfor(auto i : stdr::iota_view(1,10))\n    std::print(\"{}, \", i);\n\n// using stdv::iota\nfor(auto i : stdv::iota(1,10))\n    std::print(\"{}, \", i);\nIf you are wondering why empty_view and single_view are useful, the answer should not be hard to find. These are useful in template code that handles ranges where empty ranges or ranges with one element are valid inputs. you don’t want multiple overloads of a function template for handling these special cases; instead, you can pass an empty_view or single_view range. The following snippets show several examples of using these factories.\n#include &lt;print&gt;\n#include &lt;ranges&gt;\n\n// namespace alias\nnamespace stdr = std::ranges;\nnamespace stdv = std::views;\n\nint main()\n{\n    constexpr stdr::empty_view&lt;int&gt; ev;\n    static_assert(stdr::empty(ev));\n    static_assert(stdr::size(ev) == 0);\n    static_assert(stdr::data(ev) == nullptr);\n\n    constexpr stdr::single_view&lt;int&gt; sv{42};\n    static_assert(!stdr::empty(sv));\n    static_assert(stdr::size(sv) == 1);\n    static_assert(*stdr::data(sv) == 42);\n    return 0;\n}\nCompiler Explorer\nFor the iota_view, we have already seen a couple of examples with a bounded view. The next snippet shows again an example not only using a bounded view generated with iota but also an unbounded view, also generated with iota:\n#include &lt;print&gt;\n#include &lt;ranges&gt;\n#include &lt;algorithm&gt;\n\nnamespace stdr = std::ranges;\nnamespace stdv = std::views;\n\nint main(){\n    auto v1 = stdv::iota(1,10);\n    stdr::for_each(v1,[](int n){\n        std::println(\"{}\", n);\n    });\n\n    auto v2 =   stdv::iota(1)\n                | stdv::take(9);\n\n    stdr::for_each(v2,[](int n){\n        std::println(\"{}\", n);\n    });                \n    return 0;\n}\nCompiler Explorer\nThe last example utilizes another view called take_view. This produces a view of the first \\(N\\) elements (in my example \\(9\\)) of another view (in my example, the unbounded view produced by iota). I will discuss more on this shortly.\nThere are other standard views that I implore you to check out on cppreference.com. I tried out a few toy examples below:\n#include &lt;iostream&gt;\n#include &lt;print&gt;\n#include &lt;ranges&gt;\n#include &lt;vector&gt;\n#include &lt;algorithm&gt;\n#include &lt;string_view&gt;\n#include &lt;iomanip&gt;\n#include &lt;tuple&gt;\n\nnamespace stdr = std::ranges;\nnamespace stdv = std::views;\n\nvoid print(auto data, std::string_view label){\n    std::cout &lt;&lt; \"\\n\" &lt;&lt; label &lt;&lt; \": \";\n    stdr::for_each(data,[](int n){\n        std::print(\"{}, \", n);\n    });\n}\n\nint main(){\n    auto data = stdr::iota_view(1,9);\n\n    // filter_view \n    // Only include elements satisfying a predicate\n    auto filter_data = data | stdv::filter([](int n){\n        return n % 3 == 0;\n    });\n    print(filter_data, \"filter\");\n\n    // transform_view\n    // Applies a mapping element-wise\n    auto squares = data | stdv::transform([](int n){\n        return n * n;\n    });\n    print(squares, \"squares\");\n\n    // take_view\n    // Grab the first N elements\n    auto first_ten = data | stdv::take(10);\n    print(first_ten, \"first_ten\");\n\n    // take_while_view\n    // Grab all elements starting with the first\n    // until an element is found that no longer \n    // satisfies the predicate\n    auto take_while_rslt = data | stdv::take_while([](int n){\n        return n &lt;= 5;\n    });\n    print(take_while_rslt, \"take_while_rslt\");\n\n    // drop_view \n    // skip the first N elements\n    auto drop_rslt = data | stdv::drop(3);\n    print(drop_rslt, \"drop_rslt\");\n\n    // drop_while_view\n    // skip elements until predicate is not met\n    auto drop_while_rslt = data | stdv::drop_while([](int n){\n        return n &lt;= 3;\n    });\n    print(drop_while_rslt, \"drop_while_rslt\");\n\n    // join_view\n    // Provides a view of a sequence generated by\n    // flattening multiple ranges\n    using namespace std::literals;\n    auto strings = {\n        \"C++ \"sv, \"is \"sv, \"a \"sv, \"general-purpose \"sv,\n        \"and \"sv, \"multi-paradigm \"sv, \"programming \"sv,\n        \"language\"sv\n        };\n    auto join_result = stdv::join(strings);\n    std::cout &lt;&lt; \"\\n\" &lt;&lt; \"join_result: \";\n    for(const char c: join_result)\n        std::cout &lt;&lt; c;\n\n    // join_with_view\n    // Provides a view of a sequence generated by \n    // flattening multiple ranges with a delimiter \n    // inserted between the elements of the view.\n    std::vector&lt;std::vector&lt;int&gt;&gt; rngs = {{1,2},{3,4},{5,6}};\n    auto join_with_rslt = rngs | stdv::join_with(',');\n    \n    // split_view\n    // Provides view of a sequence of ranges produced\n    // by splitting a range on a specified delimiter.\n    constexpr auto words{\"Hey,^_^C++^_^23^_^ranges^_^are^_^awesome!\"sv};\n    constexpr auto delim{\"^_^\"sv};\n    auto split_rslt = words | stdv::split(delim);\n\n    // reverse_view\n    // Provides a view of the elements of the \n    // underlying range in reverse order\n    auto reverse_rslt = stdv::reverse(data);\n    print(reverse_rslt, \"reverse_rslt\");\n\n    // keys_view, values_view and elements_view \n    // Provide a view by projecting the first, \n    // second and nth element respectively\n    // from a range of tuples.\n    const std::vector&lt;std::tuple&lt;std::string, double, bool&gt;&gt; quark_mass_charge\n    {\n        // name, MeV/c², has positive electric-charge:\n        {\"up\", 2.3, true}, {\"down\", 4.8, false},\n        {\"charm\", 1275, true}, {\"strange\", 95, false},\n        {\"top\", 173'210, true}, {\"bottom\", 4'180, false},\n    };\n\n    std::cout &lt;&lt; \"\\nQuark name:  | \";\n    auto names = stdv::keys(quark_mass_charge);\n    for(auto name : names)\n        std::cout &lt;&lt; std::setw(9) &lt;&lt; name &lt;&lt; \"|\";\n\n    std::cout &lt;&lt; \"\\nMass:        | \";    \n    auto masses = stdv::values(quark_mass_charge);\n    for(auto mass : masses)\n        std::cout &lt;&lt; std::setw(9) &lt;&lt; mass &lt;&lt; \"|\";\n\n    std::cout &lt;&lt; \"\\nCharge:      | \";    \n    auto charges = stdv::elements&lt;2&gt;(quark_mass_charge);\n    for(auto charge : charges)\n        std::cout &lt;&lt; std::setw(9) &lt;&lt; charge &lt;&lt; \"|\";        \n\n    // zip_view\n    // Create a view of tuples from the elements\n    // of an array of integers and a vector of\n    // doubles\n    std::array&lt;int, 4&gt; a{1, 2, 3, 4};\n    std::vector&lt;double&gt; v{10.0, 20.0, 30.0};\n    std::cout &lt;&lt; \"\\nzip_result: \";\n    for(auto z : stdv::zip(a, v))\n        std::print(\"{} \", z);\n\n    // zip_transform \n    // Create a view with the multiplied elements\n    // of an array of integers and vector of doubles\n    std::cout &lt;&lt; \"\\nzip_transform_result: \";\n    for(auto z : stdv::zip_transform(\n        std::multiplies&lt;double&gt;(), a, v\n    ))\n        std::print(\"{} \", z);\n\n    // adjacent_view\n    // Print the pairs of adjacent elements of a\n    // sequence of integers\n    std::cout &lt;&lt; \"\\nadjacent_result: \";\n    for(auto i : v | stdv::adjacent&lt;3&gt;)\n        std::print(\"{} \", i);\n\n    return 0;\n}\nCompiler Explorer"
  },
  {
    "objectID": "posts/lambda_functions/index.html",
    "href": "posts/lambda_functions/index.html",
    "title": "Lambda Functions",
    "section": "",
    "text": "I’ve got my hands on the C++ lambda story by Bartłomiej Filipek and wanted to try out a few of the examples."
  },
  {
    "objectID": "posts/lambda_functions/index.html#core-definitions",
    "href": "posts/lambda_functions/index.html#core-definitions",
    "title": "Lambda Functions",
    "section": "Core Definitions",
    "text": "Core Definitions\nThe core definition from the C++ standard from expr.prim.lambda#2 says:\n\nThe evaluation of a lambda-expression results in a prvalue temporary. This temporary is called the closure object.\n\nFrom the above definition, we can understand that the compiler generates a unique wrapper class (closure type) from a lambda expression.\nConsider the following code snip:\n#include &lt;cmath&gt;\n\nauto cum_normal_cdf = [](double x){\n    return 0.5 * (1.0 - std::erf(-x/std::sqrt(2.0)))\n}\nCppInsights reveals that the C++ compiler creates the following class, where the function call operator () is overloaded.\nclass __lambda_4_23\n{\n  public: \n  inline /*constexpr */ double operator()(double x) const\n  {\n    return 0.5 * (1.0 - erf(-x / sqrt(2.0)));\n  }  \n\n  /* ... */\n};\n\n__lambda_4_23 cum_normal_cdf = __lambda_4_23{};"
  },
  {
    "objectID": "posts/lambda_functions/index.html#constructors-and-copying",
    "href": "posts/lambda_functions/index.html#constructors-and-copying",
    "title": "Lambda Functions",
    "section": "Constructors and copying",
    "text": "Constructors and copying\nIn the specification of the feature at expr.prim.lambda, we can also read the following:\n\nThe closure-type associated with a lambda expression has a deleted default constructor and a deleted copy assignment operator.\n\nThat’s why you cannot write:\ndouble x{10}, y{20};\nauto foo = [&x, &y]{ ++x; ++y; };\ndecltype(foo) fooCopy;\nCompiler Explorer\n&lt;source&gt;: In function 'int main()':\n&lt;source&gt;:9:19: error: use of deleted function 'main()::&lt;lambda()&gt;::&lt;lambda&gt;()'\n    9 |     decltype(foo) fooCopy;\n      |                   ^~~~~~~\n&lt;source&gt;:5:23: note: a lambda closure type has a deleted default constructor\n    5 |     auto foo = [&x, &y] {\n      |                       ^\n&lt;source&gt;:9:19: note: use '-fdiagnostics-all-candidates' to display considered candidates\n    9 |     decltype(foo) fooCopy;\n      |  \nHowever, we can copy lambdas:\n#include &lt;cmath&gt;\n#include &lt;print&gt;\n#include &lt;type_traits&gt;\n\nusing Point = std::pair&lt;double, double&gt;;\n\nint main() {\n    auto distance = [](Point x, Point y) noexcept {\n        return sqrt(pow((x.first - y.first), 2) +\n                    pow((x.second - y.second), 2));\n    };\n\n    Point p{3.0, 4.0};\n    Point origin{0.0, 0.0};\n    std::print(\"Distance to (3,4) from the origin = {}\", distance(p, origin));\n\n    auto distance_copy = distance;\n    static_assert(std::is_same_v&lt;decltype(distance), decltype(distance_copy)&gt;);\n    return 0;\n}\nCompiler Explorer"
  },
  {
    "objectID": "posts/lambda_functions/index.html#captures",
    "href": "posts/lambda_functions/index.html#captures",
    "title": "Lambda Functions",
    "section": "Captures",
    "text": "Captures\nThe [] does not only introduce the lambda but also holds the list of captured variables. It’s called the capture clause. By capturing a variable from outside the scope of the lambda, you create a non-static data member in the closure type. Then, inside the lambda body, you can access it.\nThe syntax for captures in C++11 are:\n\n\nTable 1: Lambda capture syntax in C++\n\n\n\n\n\n\nSyntax\nDescription\n\n\n\n\n[&]\nCapture by reference all automatic storage duration variables declared in the reaching scope.\n\n\n[=]\nCapture by value (create a copy) all automatic storage duration variables declared in the reaching scope.\n\n\n[x, &y]\nCapture x by value, capture y by reference\n\n\n[args...]\nCapture a template argument pack all by value\n\n\n[&args...]\nCapture a template argument pack all by reference\n\n\n[this]\nCaptures the this pointer inside the member function\n\n\n\n\nNote that for [=] and [&] cases, the compiler generates data members for all used variables inside the lambda body. This is a convenient syntax where you don’t want to explicitly mention which variables you capture.\n\nThe mutable keyword\nBy default the operator() of the closure type is marked as const and you cannot modify the captured variables inside the body of the lambda. If you want to change this behavior, you need to add the mutable keyword after the parameter list. This syntax removes the const from the call operator declaration in the closure type.\nIf you have a simple lambda expression with a mutable:\nint x{1};\nauto foo = [x]() mutable { ++x; };\nIt will be expanded into the following function object:\nstruct __lambda_x1 {\n    void operator()() { ++x; }\n    int x;\n};\nThe call operator can change the value of the member-fields(capture variables).\n#include &lt;iostream&gt;\n\nint main() {\n    const auto print = [](const char* str, int x, int y) {\n        std::cout &lt;&lt; str &lt;&lt; \": \" &lt;&lt; x &lt;&lt; \" \" &lt;&lt; y &lt;&lt; \"\\n\";\n    };\n\n    int x{1}, y{1};\n    print(\"in main\", x, y);\n    auto foo = [x, y, &print]() mutable {\n        ++x;\n        ++y;\n        print(\"in foo\", x, y);\n    };\n    foo();\n    print(\"in main()\", x, y);\n    return 0;\n}\nCompiler Explorer\nOutput:\nin main: 1 1\nin foo: 2 2\nin main(): 1 1\nIn the above example, we can change the values of x and y. Since those are only the copies of x and y from the enclosing scope, we don’t see their new values after foo is invoked.\nOn the other hand, if you capture by reference, you don’t need to apply the mutable keyword to modify the value. This is because the captured data members are references which means that you cannot rebound them to a new object anyway, but you can change the referenced values.\n#include &lt;iostream&gt;\n\nint main() {\n    int x{1};\n    std::cout &lt;&lt; x &lt;&lt; \"\\n\";\n    const auto foo = [&x]() noexcept { ++x; };\n    foo();\n    std::cout &lt;&lt; x &lt;&lt; \"\\n\";\n    return 0;\n}\nCompiler Explorer\nOutput:\nProgram stdout\n1\n2\nIn the above example, the lambda is not specified with mutable but it can change the referenced value.\nOne important thing is that when you apply mutable, then you canot mark your resulting closure object with const as it prevents you from invoking the lambda!\nint x{10};\nconst auto lam = [x]() mutable { ++x; };\n// lam(); // compile eror\nThe last line won’t compile as we cannot call a non-const member function on a const object.\n\n\nCapturing Global Variables\nIf you have a global variable and you use [=] in your lambda, you might think that your global object is also captured by value. But, it’s not.\n#include &lt;iostream&gt;\n\nint global{10};\n\nint main() {\n    std::cout &lt;&lt; global &lt;&lt; \"\\n\";\n    auto foo = [=]() mutable noexcept { ++global; };\n    foo();\n    std::cout &lt;&lt; global &lt;&lt; \"\\n\";\n    const auto increaseGlobal = []() noexcept { ++global; };\n    increaseGlobal();\n    std::cout &lt;&lt; global &lt;&lt; \"\\n\";\n    const auto moreIncreaseGlobal = [global]() noexcept { ++global; };\n    moreIncreaseGlobal();\n    std::cout &lt;&lt; global &lt;&lt; \"\\n\";\n}\nCompiler Explorer\nOutput:\n10\n11\n12\n13\nIn the above example, we have defined a static variable global and then used it with several lambdas defined in the main() function. If you run the code, then no matter the way you captgure, it will always point to the global object, and no local copies will be created.\nLine 13 of the code causes the compiler to generate the following warning:\nsource&gt;: In function 'int main()':\n&lt;source&gt;:13:38: warning: capture of variable 'global' with non-automatic storage duration\n   13 |     const auto moreIncreaseGlobal = [global]() noexcept { ++global; };\nIt’s because only variables with automatic storage duration can be captured.\nIf you use [=] explicitly, the compiler won’t help you and it generates an error.\n\n\nCapturing static variables\nSimilar to capturing global variables, you’ll get the same issues with static objects:\n#include &lt;iostream&gt;\n\nvoid bar() {\n    static int static_int{10};\n    std::cout &lt;&lt; static_int &lt;&lt; \"\\n\";\n    auto foo = [=]() mutable noexcept { ++static_int; };\n    foo();\n    std::cout &lt;&lt; static_int &lt;&lt; \"\\n\";\n    const auto increase = []() noexcept { ++static_int; };\n    increase();\n    std::cout &lt;&lt; static_int &lt;&lt; \"\\n\";\n    const auto moreIncrease = [static_int]() noexcept { ++static_int; };\n    moreIncrease();\n    std::cout &lt;&lt; static_int &lt;&lt; \"\\n\";\n}\n\nint main() {\n    bar();\n    return 0;\n}\nCompiler Explorer\n10\n11\n12\n13\n\n\nCaturing a class member and the this pointer\nThings get a bit more complicated where you’re in a class member function and you want to capture a data member. Since all non-static data members are related to the this pointer, it also has to be stored somewhere.\n#include &lt;iostream&gt;\n\nstruct Baz{\n    void foo(){\n        const auto lam = [s](){ std::cout &lt;&lt; s; };\n        lam();\n    }\n\n    std::string s;\n};\n\nint main()\n{\n    Baz b;\n    b.foo();\n}\nCompiler Explorer\nThe code tries to capture s which is a data-member. But the compiler will emit the following message:\n&lt;source&gt;: In member function 'void Baz::foo()':\n&lt;source&gt;:5:27: error: capture of non-variable 'Baz::s'\n    5 |         const auto lam = [s]() { std::cout &lt;&lt; s; };\n      |                           ^\n&lt;source&gt;:9:17: note: 'std::string Baz::s' declared here\n    9 |     std::string s;\n      |                 ^\n&lt;source&gt;: In lambda function:\n&lt;source&gt;:5:47: error: 'this' was not captured for this lambda function\n    5 |         const auto lam = [s]() { std::cout &lt;&lt; s; };\nTo solve this issue, we have to capture the this pointer. Then, we have access to the data members. We can updaten the code to:\n#include &lt;iostream&gt;\n\nstruct Baz{\n    void foo(){\n        const auto lam = [this](){ std::cout &lt;&lt; s; };\n        lam();\n    }\n\n    std::string s;\n};\n\nint main()\n{\n    Baz b;\n    b.foo();\n}\nCompiler Explorer\nThere are no compiler errors now.\nWe can also use [=] or [&] to capture this. They both have the same effect in C++11/14. Note that, we captured this by value to a pointer. That’s why we have access to the initial data-member and not its copy.\nThe value of the value-captured variable is the value at the time the lambda is defined - not when it is used. The value of a ref-captured variable is the value when the lambda is used - not when it is defined.\nThe C++ closures do not extend the lifetimes of the captured references. We must be sure that the capture variable still lives when the lambda is invoked.\n\n\nMoveable-only objects\nIf you have an object that is moveable only(for example a unique_ptr), then we can move the object into a member of the closure type:\n#include &lt;iostream&gt;\n#include &lt;memory&gt;\n#include &lt;utility&gt;\n\nint main() {\n    std::unique_ptr&lt;int&gt; p = std::make_unique&lt;int&gt;(10);\n    std::cout &lt;&lt; \"Before definition pointer in main(): \" &lt;&lt; p.get() &lt;&lt; \"\\n\";\n    const auto bar = [ptr = std::move(p)] {\n        std::cout &lt;&lt; \"pointer in lambda: \" &lt;&lt; ptr.get() &lt;&lt; \"\\n\";\n        std::cout &lt;&lt; \"value in lambda: \" &lt;&lt; *ptr &lt;&lt; \"\\n\";\n    };\n\n    std::cout &lt;&lt; \"After definition pointer in main(): \" &lt;&lt; p.get() &lt;&lt; \"\\n\";\n    bar();\n}\nCompiler Explorer\nOutput:\nBefore definition pointer in main(): 0x209772b0\nAfter definition pointer in main(): 0\npointer in lambda: 0x209772b0\nvalue in lambda: 10\n\n\nPreserving const\nIf you capture a const variable, then the const-ness is preserved:\n#include &lt;iostream&gt;\n#include &lt;type_traits&gt;\n\nint main(){\n    const int x{10};\n    auto foo = [x]() mutable{\n        std::cout &lt;&lt; std::is_const&lt;decltype(x)&gt;::value &lt;&lt; \"\\n\";\n        x = 11;\n    }\n\n    foo();\n}\nCompiler Explorer\nThis code will not compile.\n&lt;source&gt;: In lambda function:\n&lt;source&gt;:9:15: error: assignment of read-only variable 'x'\n    9 |             x = 11;\n      |             ~~^~~~\n&lt;source&gt;: In function 'int main()':\n&lt;source&gt;:12:5: error: expected ',' or ';' before 'foo'\n   12 |     foo();\n      |     ^~~\n\n\nCapturing a parameter pack\nWe can also leverage captures with variadic templates. The compiler expands the pack into a list of non-static data members whihc might be handy, if you want to use lambda in templated code.\n#include &lt;iostream&gt;\n#include &lt;tuple&gt;\n\ntemplate &lt;class... Args&gt;\nvoid captureTest(Args... args) {\n    const auto lambda = [args...] {\n        const auto tup = std::make_tuple(args...);\n        std::cout &lt;&lt; \"tuple size: \" &lt;&lt; std::tuple_size&lt;decltype(tup)&gt;::value\n                  &lt;&lt; \"\\n\";\n        std::cout &lt;&lt; \"tuple 1st: \" &lt;&lt; std::get&lt;0&gt;(tup) &lt;&lt; \"\\n\";\n    };\n    lambda();\n}\n\nint main() {\n    captureTest(1, 2, 3, 4);\n    captureTest(\"Hello World\", 10.0f);\n}\nCompiler Explorer\nOutput:\ntuple size: 4\ntuple 1st: 1\ntuple size: 2\ntuple 1st: Hello World"
  },
  {
    "objectID": "posts/lambda_functions/index.html#return-type",
    "href": "posts/lambda_functions/index.html#return-type",
    "title": "Lambda Functions",
    "section": "Return Type",
    "text": "Return Type\nIn most cases, you can skip the return type of the lambda and the compiler will deduce the typename for you. The compiler is able to deduce the return type as long as all of your return statements are of the same type."
  },
  {
    "objectID": "posts/lambda_functions/index.html#iife---immediately-invoked-functional-expression",
    "href": "posts/lambda_functions/index.html#iife---immediately-invoked-functional-expression",
    "title": "Lambda Functions",
    "section": "IIFE - Immediately Invoked Functional Expression",
    "text": "IIFE - Immediately Invoked Functional Expression\nIn most of the examples, we’ve seen so far, notice that we defined ht lambda and then immediately called it later. However, you can also invoke a lambda immediately.\n#include &lt;iostream&gt;\n\nint main(){\n    int x{1}, y{1};\n    [&]() noexcept { ++x; ++y; }();     // call\n    std::cout &lt;&lt; x &lt;&lt; \", \" &lt;&lt; y;\n}"
  },
  {
    "objectID": "posts/lambda_functions/index.html#default-parameters-for-lambda-functions",
    "href": "posts/lambda_functions/index.html#default-parameters-for-lambda-functions",
    "title": "Lambda Functions",
    "section": "Default parameters for lambda functions",
    "text": "Default parameters for lambda functions\nLet’s start with smaller updates. In C++14, you can use default parameters in a lambda function definition.\n#include &lt;iostream&gt;\n\nint main()\n{\n    const auto lam = [](int x = 10){ std::cout &lt;&lt; x &lt;&lt; \"\\n\"; };\n    lam();\n    lam(100);\n}\nCompiler Explorer"
  },
  {
    "objectID": "posts/lambda_functions/index.html#captures-with-an-initialiser",
    "href": "posts/lambda_functions/index.html#captures-with-an-initialiser",
    "title": "Lambda Functions",
    "section": "Captures with an initialiser",
    "text": "Captures with an initialiser\nWe recall that, in a lambda expression, we can capture variables form the outside scope. The compiler expands that capture syntax and creates corresponding non-static data members in the closure type.\nIn C++14, you can create new data-members and initialize them in the capture clause. Then, you can access those variables inside the lambda. It’s called capture with an initialiser or another name for this feature is generalized lambda capture.\n#include &lt;iostream&gt;\n\nint main(){\n    int x{30};\n    int y{12};\n    const auto foo = [z = x + y]{ std::cout &lt;&lt; z &lt;&lt; \"\\n\"; };\n    x = 0;\n    y = 0;\n    foo();\n}\nCompiler Explorer\nOutput:\n42\nKeep in mind, that the new variable is initialized at the place where you define the lambda and not where you invoke it.\nCreating variables through an initialiser is also flexible, since you can, for example, create references to variables from outside scope.\n#include &lt;iostream&gt;\n\nint main() {\n    int x{30};\n    const auto foo = [&z = x]() { std::cout &lt;&lt; z &lt;&lt; \"\\n\"; };\n    foo();\n    x = 0;\n    foo();\n}\nOutput:\n30\n0\n\nLimitations\nNote, that while you can capture by reference with an initialiser, it’s not possible to write rvalue reference &&. So, the below code would be invalid.\n[&&z = x]   //invalid syntax!\n\n\nOne gotcha with std::function\nHaving a moveable-only captured variable in a lambda makes the closure object not copyable. This might be an issue if you want to store such a lambda in std::function which accepts only copyable copy objects."
  },
  {
    "objectID": "posts/lambda_functions/index.html#optimisation",
    "href": "posts/lambda_functions/index.html#optimisation",
    "title": "Lambda Functions",
    "section": "Optimisation",
    "text": "Optimisation\nAnother idea is to use capture initialisers as a potential optimisation technique. Rather than computing some value every time, we invoke a lambda, we can compute it once in. the initialiser:\n#include &lt;algorithm&gt;\n#include &lt;iostream&gt;\n#include &lt;string&gt;\n#include &lt;vector&gt;\n\nint main()\n{\n    using namespace std::string_literals;\n    const std::vector&lt;std::string&gt; vs = {\n        \"apple\", \"orange\",\n        \"foobar\", \"lemon\"\n    };\n    const auto prefix = \"foo\"s;\n\n    auto result = std::find_if(vs.begin(), vs.end(),\n        [&prefix](const std::string& s){\n            return s == prefix + \"bar\"s;\n        }\n    );\n\n    if(result != vs.end())\n        std::cout &lt;&lt; prefix &lt;&lt; \"-something found!\\n\";\n\n    result = std:find_if(vs.begin(), vs.end(),\n        [savedString = prefix + \"bar\"s](const std::string& s){\n            return s == savedString;\n        }\n    );\n\n    if(result != vs.end())\n        std::cout &lt;&lt; prefix &lt;&lt; \"-something found!\\n\";\n\n    return 0;\n}\nThe code above shows two calls to std::find_if. In the first scernario, we capture prefix and compare the input value against prefix + \"bar\"s. Everytime the lambda is invokes, a temporary value that stores the sum of those strings has to be created and computed.\nThe second call to find_if shows an optimisation: we create a captured variable savedString that computes the sum of the strings. then, we can safely refer to it in the lambda body. The sum of the strings will run only once and not with every invocation of the lambda."
  },
  {
    "objectID": "posts/lambda_functions/index.html#capturing-a-class-data-member",
    "href": "posts/lambda_functions/index.html#capturing-a-class-data-member",
    "title": "Lambda Functions",
    "section": "Capturing a class data member",
    "text": "Capturing a class data member\nAn initialiser can also be used to capture data members without worrying about *this pointer. We can capgture a copy of a data member and not bother with dangling references.\n#include &lt;algorithm&gt;\n#include &lt;iostream&gt;\n\nstruct Baz{\n    auto foo() const{\n        return [s=s]{ std::cout &lt;&lt; s &lt;&lt; \"\\n\"; };\n    }\n\n    std::string s;\n};\n\nint main()\n{\n    const auto f1 = Baz{\"abc\"}.foo();\n    const auto f2 = Baz{\"xyz\"}.foo();\n    f1();\n    f2();\n}\nCompiler Explorer"
  },
  {
    "objectID": "posts/lambda_functions/index.html#generic-lambdas",
    "href": "posts/lambda_functions/index.html#generic-lambdas",
    "title": "Lambda Functions",
    "section": "Generic Lambdas",
    "text": "Generic Lambdas\nThe early specification of lambda expressions allowed us to create anonymous function objects (closure types) and pass them to various generic algorithms from the standard library. However, closures were not generic on their own. For example, you couldn’t specify a template parameter as a lambda parameter.\nFortunately, since C++14, the Standard introduced generic lambdas and now we can write:\nconst auto foo = [](auto x, int y){ std::print(\"{}, {}\", x, y); };\nfoo(10, 1)\nfoo(10.1234, 2);\nfoo(\"hello world\",3);\nPlease notice auto x as a parameter to the lambda. This is equivalent to using a template declaration in the call operator of the closure type:\nstruct{\n    template&lt;typename T&gt;\n    void operator()(Tx, int y) const{\n        std::print(\"{}, {}\", x, y);\n    }\n} someInstance;\nIf there are more auto arguments, then the code expands to separate template parameters:\nconst auto fooDouble = [](auto x, auto y){ /*...*/ };\nexpands into:\nstruct{\n    template&lt;typename T, typenname U&gt;\n    void operator()(Tx, U y) const{\n        /* ... */\n    }\n} someInstance;"
  },
  {
    "objectID": "posts/lambda_functions/index.html#variadic-generic-arguments",
    "href": "posts/lambda_functions/index.html#variadic-generic-arguments",
    "title": "Lambda Functions",
    "section": "Variadic Generic Arguments",
    "text": "Variadic Generic Arguments\nIf we need more function parameters, then we can also go variadic.\n#include &lt;iostream&gt;\n\ntemplate &lt;typename T&gt;\nauto sum(T x) {\n    return x;\n}\n\ntemplate &lt;typename T1, typename... T&gt;\nauto sum(T1 s, T... ts) {\n    return s + sum(ts...);\n}\n\nint main() {\n    const auto sumLambda = [](auto... args) {\n        std::cout &lt;&lt; \"sum of: \" &lt;&lt; sizeof...(args) &lt;&lt; \" numbers\\n\";\n        return sum(args...);\n    };\n\n    std::cout &lt;&lt; sumLambda(1.1, 2.2, 3.3, 4.4, 5.5, 6.6, 7.7, 8.8, 9.9);\n}\nCompiler Explorer"
  },
  {
    "objectID": "posts/lambda_functions/index.html#perfect-forwarding-with-generic-lambdas",
    "href": "posts/lambda_functions/index.html#perfect-forwarding-with-generic-lambdas",
    "title": "Lambda Functions",
    "section": "Perfect forwarding with generic lambdas",
    "text": "Perfect forwarding with generic lambdas\nWith generic lambdas, we’re not restricted to using auto x, we can add any qualifiers as with other auto variables such as auto&, const auto& or auto&&. One of the handy use cases is that we can specify auto&& x which becomes a forwarding(universal) reference.\n#include &lt;print&gt;\n#include &lt;string&gt;\n\nvoid foo(const std::string& ) { std::println(\"foo(const string&)\"); }\nvoid foo(std::string&&)  { std::println(\"foo(std::string&&)\"); } \n\nint main()\n{\n    const auto callFoo = [](auto&& str){\n        std::println(\"Calling foo() on: {}\", str);\n        foo(std::forward&lt;decltype(str)&gt;(str));\n    };\n\n    const std::string str = \"Hello World\";\n    callFoo(str);\n    callFoo(\"Helo World Ref Ref\");\n}\nCompiler Explorer\nOutput:\nCalling foo() on: Hello World\nfoo(const string&)\nCalling foo() on: Helo World Ref Ref\nfoo(std::string&&)"
  },
  {
    "objectID": "posts/lambda_functions/index.html#overloaded-pattern",
    "href": "posts/lambda_functions/index.html#overloaded-pattern",
    "title": "Lambda Functions",
    "section": "Overloaded pattern",
    "text": "Overloaded pattern\nIt might be surprising to see, but you can derive from a lambda! Since the compiler expands a lambda expression into a function object with operator(), we can inherit from this type.\n#include &lt;print&gt;\n\ntemplate&lt;typename Callable&gt;\nclass ComplexFn : public Callable{\n    explicit ComplexFn(Callable f) : Callable(f){}\n};\n\ntemplate&lt;typename Callable&gt;\nComplexFn&lt;Callable&gt; MakeComplexFunctionObject(Callable&& callable){\n    return ComplexFn&lt;Callable&gt;(std::forward&lt;Callable&gt;(callable));\n}\n\nint main()\n{\n    const auto func = MakeComplexFunctionObject(\n        []{\n            std::println(\"Hello, complex function object!\");\n        }\n    );\n    func(); \n}\nIn the example, there’s the ComplexFn class which derives from Callable which is a template parameter. If we want to derive from a lambda, we need to do a little trick, as we cannot spell out the exact type of the closure type(unless we wrap it into a std::function). That’s why, we need the MakeComplexFnObject function that can perform template argument deduction and get the type of the lambda closure.\nThe ComplexFn apart from it’s name is just a simple wrapper without much of a use. Are there any use-cases for such code patterns?\nWe can extend the code above and inherit from two lambdas and create an overloaded set:\n#include &lt;print&gt;\n\ntemplate &lt;typename TCall, typename UCall&gt;\nclass SimpleOverloaded : public TCall, UCall {\n   public:\n    SimpleOverloaded(TCall tf, UCall uf) : TCall(tf), UCall(uf) {}\n\n    using TCall::operator();\n    using UCall::operator();\n};\n\ntemplate &lt;typename TCall, typename UCall&gt;\nSimpleOverloaded&lt;TCall, UCall&gt; MakeOverloaded(TCall&& tf, UCall&& uf) {\n    return SimpleOverloaded&lt;TCall, UCall&gt;(std::forward&lt;TCall&gt;(tf),\n                                          std::forward&lt;UCall&gt;(uf));\n}\n\nint main() {\n    const auto func = MakeOverloaded([](int) { std::println(\"Int!\"); },\n                                     [](float) { std::println(\"Float!\"); });\n\n    func(10);\n    func(10.0f);\n}\nCompiler Explorer\nThis time we have more code and we derive from two template parameters, but we also need to expose their call operators explicitly. It’s because when looking for the correct function overload, the compiler requires the candidates to be in the same scope.\nNow, how about using a variable number of base classes, which means a variable number of lambdas?"
  },
  {
    "objectID": "posts/lambda_functions/index.html#deriving-from-multiple-lambdas",
    "href": "posts/lambda_functions/index.html#deriving-from-multiple-lambdas",
    "title": "Lambda Functions",
    "section": "Deriving from multiple lambdas",
    "text": "Deriving from multiple lambdas\nIn C++17, we have a handy pattern for this:\n#include &lt;print&gt;\n\ntemplate &lt;class... Ts&gt;\nstruct overloaded : Ts... {\n    using Ts::operator()...;\n};\n\ntemplate &lt;class... Ts&gt;\noverloaded(Ts...) -&gt; overloaded&lt;Ts...&gt;;\n\nint main() {\n    const auto test = overloaded{\n        [](const int& i) { std::println(\"int: {}\", i); },\n        [](const float& f) { std::println(\"float: {}\", f); },\n        [](const std::string& i) { std::println(\"string: {}\", i); },\n    };\n\n    test(\"10.0f\");\n}\nCompiler Explorer\nLet’s deep-dive into the basic mechanics of this pattern. It benefits from three features:\n\nPack expansions in using declarations.\nCustom template argument deduction rules - that allows converting a list of lambda objects into a list of base classes for the overloaded class. (not needed in C++20!)\nExtension to aggregate initialisation - before C++17, you couldn’t aggregate initialise type that derives from other types.\n\nThe using declaration is important for bringing the function call operator - operator() into the same scope of the overloaded structure. In C++17, we got a syntax that supports variadic templates, which was not possible in the previous revisions of the language.\nLet’s try and understand the remaining features:\n\nCustom Template Argument Deduction Rules\nWe derive from lambdas, and then we expose their operator() as we saw in the previous section. But, how can we create objects of this overload type?\nAs you know, there’s no way to know up-front, the type of the lambda, as compiler has to generate some unique typename for each of them. For example, we cannot just write:\noverload&lt;LambdaType1, LambdaType2&gt; myOverload{...}\nThe only way that could work would be some make function (as template argument deduction works for function templates):\ntemplate&lt;typename... T&gt;\nconstexpr auto make_overloader(T&&... t){\n    return overloaded&lt;T...&gt;{std::forward&lt;T&gt;(t)...};\n}\nWith the template argument deduction rules that were added in C++17, we can simplify the creation of common template types and the make_overloader function is not needed. For simple types, we can write:\nstd::pair strDouble{ std::string{\"Hello\"}, 10.0 };\nThere’s also the option to define custom deduction guides. The standard library uses a lot of them, for exmaple, for std::array:\ntemplate&lt;class T, class... U&gt;\nstd::array(T,U...) -&gt; array&lt;T, 1 + sizeof...(U)&gt;;\nand the above rules allows us to write:\nstd::array test{1, 2, 3, 4, 5};\nFor the overloaded pattern, we can specify a custom deduction guide:\ntemplate&lt;class... Ts&gt; overloaded(Ts...) -&gt; overloaded&lt;Ts...&gt;;\n\n\nExtension to aggregate initialisation\nThe functionality is relatively straightforward: we can now aggregate initialise a type that derives from other types. From the specification:\n\nAn aggregate is an array or a class with: - no user-provided, explicit or inherited constructors - no private or protected non-static data members - no virtual functions - no virtual, private or protected base classes.\n\nFor example:\nstruct base1{ int b1, b2 = 32; };\n\nstruct base2{\n    base2(){\n        b3 = 64;\n    }\n\n    int b3;\n};\n\nstruct derived : base1, base2{\n    int d;\n}\n\nderived d1{{1,2}, {}, 4};\nderived d2{{}, {}, 4};"
  },
  {
    "objectID": "posts/objects-pointers-and-references/index.html",
    "href": "posts/objects-pointers-and-references/index.html",
    "title": "Objects, Pointers and References",
    "section": "",
    "text": "An object is something that has a lifetime and occupies storage. Even a humble int is an object, but a function is not.\nA pointer is a typed address. It associates a type with what is found at some memory location.\nPointers allow us to do arithmetic, but that’s legitimately seen as a dangerous operation, as it can take us to arbitrary locations. Accessing the contents of arbitrary addresses is just asking for trouble.\nC++ has special types for pointer manipulation:\n\nvoid* means address with no specific type semantics. A void* is an address with no associated type. All pointers are implicitly convertible to void* ; an informal way to read this is all pointers regardless of type are addresses. The converse does not hold. For example, it’s not true that all addresses are implicitly convertible to int pointers.\nchar* means pointer to a byte. Due to the C language roots of C++, a char* can alias any address in memory (the char type regardless of its name, which evocates character, really means byte in C and by extension in C++). There is an ongoing effort in C++ to to give char the meaning of character.\nstd::byte* is the new pointer to a byte, atleast since C++17. The long term intent of std::byte* is to replace char* in those functions that do byte-per-byte manipulation or addressing, but since there’s so much code that uses char* to that effect, this will take time.\n\n\n\nA string literal is a character sequence enclosed within double quotes.\n\"this is a string\"\nA string literal contains one more character than it appears to have; it is terminated by the \\0 null termination character (having integer value 0). For example,\nsizeof(\"Bohr\") == 5\nThe type of a string literal is array of appropriate number of const characters, so \"Bohr\" is of type const char[5].\nIn C and older C++ code, you could assign a string literal to a non-const char*.\nModifying string literals is undefined behavior. In practice, the implementation can for instance store the string literal in read-only memory, such as the .rodata segment on Linux.\nvoid f()\n{\n    //char* p = \"Cauchy\";       // error, since C++11\n    const char* s = \"Cauchy\";   // ok\n    //s[4] = 'e';               // error, assignment to const\n}\nHaving string literals as immutable is not only obvious but also allows implementations to do significant optimizations in the way string literals are stored and accessed.\nIf we want a string that we are guaranteed to be able to modify, we must place the characters in a non-const array.\nchar p[] = \"Schwarz\";   // p is an array of 8 char\np[0] = 's';             // ok\nA string literal is statically allocated so it is safe to return one from a function. It is an lvalue.\nWhether two identical strings are allocated as one array, or as two is implementation defined. For example:\nconst char* p = \"Carl Friedrich Gauss\";\nconst char* q = \"Carl Friedrich Gauss\";\nif(p == q)\n    std::cout &lt;&lt; \"\\n\" &lt;&lt; \"one!\";        // Implementation defined\nNote that, == compares addresses (pointer values) when applied to pointers, and not the objects pointed to.\n\n\n\nObserve the code snippet below. What is printed?\n#include &lt;iostream&gt;\n\nint main()\n{\n    // string literals\n    char s1[] = {'h','e','l','l','o', '\\0'};\n    char s2[] = \"hello\";\n    const char* s3 = \"world\";\n\n    std::cout &lt;&lt; \"s1 = \" &lt;&lt; s1 &lt;&lt; \"\\n\";\n    std::cout &lt;&lt; \"s2 = \" &lt;&lt; s2 &lt;&lt; \"\\n\";\n    std::cout &lt;&lt; \"s3 = \" &lt;&lt; s3 &lt;&lt; \"\\n\";\n\n    const char* c[] = {\n        \"C++\", \"is\", \"a\", \"general\", \"purpose\", \n        \"programming\", \"language\"\n    };\n\n    std::cout &lt;&lt; \"c + 0 : \" &lt;&lt; (c) &lt;&lt; \"\\n\";\n    std::cout &lt;&lt; \"c + 1 : \" &lt;&lt; (c + 1) &lt;&lt; \"\\n\";\n    std::cout &lt;&lt; \"c + 2 : \" &lt;&lt; (c + 2) &lt;&lt; \"\\n\";\n    std::cout &lt;&lt; \"c + 3 : \" &lt;&lt; (c + 3) &lt;&lt; \"\\n\";                           \n\n    std::cout &lt;&lt; \"c[0] : \" &lt;&lt; c[0] &lt;&lt; \"\\n\";\n    std::cout &lt;&lt; \"c[1] : \" &lt;&lt; c[1] &lt;&lt; \"\\n\";\n    std::cout &lt;&lt; \"c[2] : \" &lt;&lt; c[2] &lt;&lt; \"\\n\";\n    std::cout &lt;&lt; \"c[3] : \" &lt;&lt; *(c + 3) &lt;&lt; \"\\n\";\n\n    const char** cp[] = { c + 2, c + 3, c, c + 1 };\n    const char*** cpp = cp;\n    \n\n    std::cout &lt;&lt; *cpp[1] &lt;&lt; ' ';\n    std::cout &lt;&lt; *(*(*(cpp + 2) + 2) + 3) &lt;&lt; ' ';\n    std::cout &lt;&lt; (*cpp)[-1] &lt;&lt; ' ';\n    std::cout &lt;&lt; *(cpp + 3)[-1] &lt;&lt; std::endl;\n    return 0;\n}\nCompiler Explorer\n\n\n\nWhich of the following can be used to print the address of a char variable?\nchar ch = 'A';\nstd::cout &lt;&lt; ???;    // print address of ch\n\n&ch[0]\n(char*)&ch\n(void*)&ch\n&ch\n\n&ch is of type char*. The &lt;&lt; operator for std::cout has an overload for char* that interprets it as a pointer to a null-terminated C-style string, so it attempts to print characters starting from the address of ch until it encounters a null terminator (\\0).\nA pointer has to be able address all memory space. On 64-bit architecture, sizeof(T*) is therefore, \\(8\\) bytes = \\(64\\) bits.\nvoid f(int* pi)\n{\n    void* pv = pi;  // ok : implicit conversion of `int*` to `void*`\n    // *pv;         // error: can't dereference void*\n    ++pv;           // error: can't increment void*\n    \n    int* pi2 = static_cast&lt;int*&gt;(pv);   // explicit conversion back to `int*`\n    //double* pd1 = pv;                   // error\n    //double* pd2 = pi;                   // error\n    double* pd3 = static_cast&lt;double*&gt;(pv); // unsafe\n}\nIn general, it is not safe to use a pointer that has been converted to a type that differs from the type of the object pointed to.\nThe primary use for void* is for passing pointers to functions that are not allowed to make assumptions about the type of the object and for returning untyped objects from functions.\n\n\n\nUse the spiral rule, when reading pointer declarations. Start at the inner-most level and work your way outwards spiralling in a counter-clockwise direction.\ndouble (*ptr)[5];   // Pointer to array of 5 double(s)\ndouble* ptr[5];     // ptr is an array of pointers to double of size 5\n\n\n\nTrying to dereference a null pointer is an error. On most platforms, it generally causes a signal, usually SIGSEGV (see Signals).\nchar *foo = NULL;\nc = *foo;    /* This causes a signal and terminates.  */\nLikewise a pointer that has the wrong alignment for the target data type (on most types of computer), or points to a part of memory that has not been allocated in the process’s address space.\n\n\n\nTwo pointer values are equal if they point to the same memory address or they are both nullptr. Ordering comparisons such as &gt; and &gt;= operate on pointers by converting them to unsigned integers.\n\n\n\nIn C++, pointers and arrays are closely related. The name of the array holds the starting address of the array can be used as a pointer to the initial element.\nint v[] = {1,2,3,4};\nint* p1 = v;        // pointer to initial element\nint* p2 = &v[0];    // pointer to initial element\nint* p3 = v+4;      // pointer to one beyond the last element\nTaking a pointer to the element one beyond the end of an array is guaranteed to work. This is important for many algorithms. However, since such a pointer does not in fact point to an element of the array, it should not be used for dereferencing, reading or writing values.\nThe result of taking the address of the element before the initial element or beyond one-past-the-last element is undefined and should be avoided.\nFor example:\n// int* p4 = v - 1;    // before the beginning, undefined\n// int* p5 = v + 7;    // beyond the end, undefined\n\n\n\nEfficient and elegant access to arrays and similar data-structures is the key to many algorithms. Access can be achieved either through pointer to an array plus an integer index or through a pointer to an element.\nvoid fi(char* v)\n{\n    for(int i{0}; v[i]!=0; ++i)\n    {\n        std::cout &lt;&lt; v[i];\n    }\n} \n\nvoid fp(char* v)\n{\n    for(char* p{v}; *p!=0; ++p)\n    {\n        std::cout &lt;&lt; *p;\n    }\n}\nSubscripting a built-in array is defined in terms of pointer operations + and *. For every built-in array a and integer j within the range of a, we have:\na[j] == *(&a[0]+j) == *(a+j) == *(j + a) == j[a]\nIt usually surprises people to find that a[j] == j[a]. For example, 3[\"Texas\"] == \"Texas\"[3] == 'a'. Although such cleverness has no place in production code, from an interview perspective its good to know these low-level equivalences.\nThe result of applying the arithmetic operators +, -, ++ or -- to pointers depends on the type of the object pointed to. When an arithmetic operator is applied to a pointer p of type T*, p is assumed to point to an element of an array of objects of type T; p+1 points to the next element of that array, p-1 points to the previous element. This implies that the integer value of p+1 will be sizeof(T) larger than the integer value of p.\n#include &lt;iostream&gt;\ntemplate &lt;typename T&gt;\nint byte_diff(T* p, T* q) {\n    return reinterpret_cast&lt;char*&gt;(q) - reinterpret_cast&lt;char*&gt;(p);\n}\n\nint main() {\n    int vi[10] = {};\n    short vs[10] = {};\n    std::cout &lt;&lt; byte_diff(&vi[1], &vi[2]) &lt;&lt; \" bytes diff\" &lt;&lt; \"\\n\";\n    std::cout &lt;&lt; byte_diff(&vs[1], &vs[2]) &lt;&lt; \" bytes diff\" &lt;&lt; \"\\n\";\n    return 0;\n}\nCompiler Explorer\nSubtraction of pointers is defined only when both pointers point to elements of the same array. When subtracting a p pointer from another pointer q, q-p is the number of array elements in the sequence [p:q). One can add an integer to a pointer or subtract an integer from a pointer, in both cases, the result is a pointer value. If that value does not point to an element of the same array as the original array or one beyond, the result of using that value is UB.\nint v1[10];\nint v2[10];\n\nint i1 = &v1[5] - &v1[3];   // i1 = 2\n//int i2 = &v1[5] - &v2[3];   // UB\n\nint* p1 = v2 + 2;   // p1 = &v2[2]\n//int* p2 = v2 - 2;   // UB\nComplicated pointer arithmetic is usually unnecessary and best avoided. Addition of pointers makes no sense and is not allowed.\nArrays are not self-describing because the number of elements of an array is not guaranteed to be stored with the array. This implies that to traverse an array that does not contain a terminator, the way C-style strings do, we must somehow supply the elements. ## Precedence of operators\nThe precedence of operators in C++ is:\n\n\n\nOperators\nDescription\n\n\n\n\n[] () . -&gt;\nPostfix operators, left-to-right\n\n\nx++ x--\nPostfix, left-to-right\n\n\n++x --x * &\nPrefix, right-to-left\n\n\n* / %\nMultiplicative\n\n\n+ -\nAdditive\n\n\n\n\n\nint arr[] = {10, 20, 30};\nint *p = arr;\nint x = *p++;   // x = 10, p now points to arr[1]\nConsider the expression *ptr++ . Post-increment ++ has a higher precedence than the dereference operator *, so it’s parsed as *(ptr++). ptr++ returns the old value that ptr pointed to, but moves ptr forward at a future time. ### Example 2\nint arr[] = {10, 20, 30};\nint *p = arr;\nint x = *++p;   // p moves to arr[1], then x = 20\nConsider the expression *++p. Both the dereference operator * and pre-increment ++ are prefix operators and have the same precedence. Since, they have right-to-left associativity, we read them right-to-left. *++p is parsed as *(++p). ### Example 3\nint arr[] = {10, 20, 30};\nint *p = arr;\n++*p;          // arr[0] becomes 11, p unchanged\nConsider the expression ++*p. Using right-to-left associativity rule, we first dereference and then increment. ## Challenge puzzle\nint arr[5] = {10, 20, 30, 40, 50};\nint *p = arr + 2;\nint *q = arr + 4;\n\n// What are the values of:\n// a) p - q\n// b) q - p\n// c) *p++\n// d) *++p (after the previous operation)\nCompiler Explorer p - q evaluates to \\(-2\\), q - p evaluates to \\(2\\).\n\n\n\n\nint x = 10;\nint *p = &x;\nint **pp = &p;\n\n// What happens with each line?\n**pp = 20;\n*pp = nullptr;\n// Can you still access x? What's its value?\nCompiler Explorer After the line *pp=20, the variable x has been assigned a new value 20. *p = nullptr will reset the value in pointer variable p to a nullptr. We cannot access the contents of the variable x through the pointer variables p and pp.\n\n\n\nObserve the code snippet below. What is printed?\n// Headers\nint main()\n{ \n    const char* str[] = { \"AAAAA\", \"BBBBB\", \"CCCCC\", \"DDDDD\" }; \n    const char** sptr[] = { str + 3, str + 2, str + 1, str }; \n    const char*** pp; \n    pp = sptr; \n    ++pp; \n    std::cout &lt;&lt; **++pp + 2; \n}\nInitially, pp is incremented to point to the address of sptr[1].\nIn the order of precedence, from high to low, we have:\n\n* dereference and ++ pre-increment operator (Right-to-left)\n+ - Addition binary operator (Left-to-right)\n\nSo, **++pp + 2 would be parsed as *(*(+pp)) + 2. Thus, pp is now incremented to point to the address of str+1. Then, it is dereferenced twice to yield the string literal BBBBB which is a char*. Finally, an offset of 2, will print the text BBB. ## Passing C-style arrays\nArrays cannot be directly passed by value. Instead, an array is as a pointer to its first element.\ndouble vec_norm(double* vec, std::size_t n)\n{\n    double sum_of_squares{0.0};  \n    for(int i{0}; i&lt;n; ++i)\n    {\n        sum_of_squares += vec[i];\n    }\n    \n    return sqrt(sum_of_squares);\n}\nMulti-dimensional arrays can be passed in a similar fashion.\ndouble frobenius_norm(double* mat, std::size_t num_rows, std::size_t num_cols)\n{\n    double sum_of_squares{0.0};  \n    for(int i{0}; i&lt;m; ++i)\n    {\n        for(int j{0}; j&lt;n; ++j)\n        {\n            sum_of_squares += mat[i][j];\n        }\n    }\n    \n    return sqrt(sum_of_squares);\n}\n\n\n\nThe C++ language supports two families of indirections: pointers and references. A reference can be seen as an alias for an existing entity. We deliberately did not use the word object, since one could refer to a function and we already know that a function is not an object.\nPointers are objects. As such they occupy storage. References, on the other hand, are not objects, they do not use any storage of their own.\nThe sizeof operator applied to a reference, will yield the size of whatever it refers to. In C++, a reference is always bound to an object and remains bound to that object until the end of the reference’s lifetime. A pointer, on the other hand, can point to numerous distinct objects during its lifetime.\nAnother difference between pointers and references is that, contrary to the situation, there is no such thing as reference arithmetic. This makes references safer than pointers.\n\n\n\nWe saw earlier that in C++, an object has a type and an address. It occupies a region of storage from the beginning of it’s construction to the end of it’s destruction.\n\n\nIn C++, generally speaking, automatic objects are destructed at the end of their scope in a well-defined order. Static(global) objects are destructed on program termination in a somewhat well-defined order. Dynamically allocated objects are destroyed when your program says so.\nLet’s examine some aspects of object lifetime with the following very simple program:\n#include &lt;string&gt;\n#include &lt;print&gt;\n#include &lt;format&gt;\n\nstruct X{\n    std::string s;\n    X(std::string_view s) : s{ s }\n    {\n        std::print(\"X::X({})\\n\", s);\n    }\n\n    ~X(){\n        std::print(\"~X::X() for {}\\n\", s);\n    }\n};\n\nX glob{ \"glob\" };\n\nvoid g(){\n    X xg{ \"g()\" };\n}\n\nint main()\n{\n    X* p0 = new X{ \"p0\" };\n    [[maybe_unused]] X* p1 = new X{ \"p1\" }; // will leak\n    X xmain{ \"main()\" };\n    g();\n    delete p0;\n    // oops, forgot to delete p1\n    return 0;\n}\nCompiler Explorer\nWhen executed, the program will print the following:\nX::X(glob)\nX::X(p0)\nX::X(p1)\nX::X(main())\nX::X(g())\n~X::X() for g()\n~X::X() for p0\n~X::X() for main()\n~X::X() for glob\nThe fact that the number of constructors and destructors do not match is a sign that we did something wrong. More specifically, in this example, we manually created an object (pointed to by p1) with the operator new but never manually destructed that object afterward. This is a memory leak.\n\n\n\n\nSince each object occupies storage, the space associated with an object is an important(if low-level) property of C++ types. For example, look at the following code:\nclass B;    // fporward declaraion: there will be a class B\n            // at some point in the future\n            \nvoid f(B*); // fine, we know what NB is, even if don't know the details yet,\n            // and all object addresses are of the same size\n\nclass D : B{};  // oops! This is the definition of class D. To determine\n                // sizeof(D), we have to know how big sizeof(B) is and what\n                // a B object contains since a D is a B\nIn the above example, trying to define the D class would not compile. This is because in order to create aD object, the compiler needs to reserve enough space for a D object, but a D object is also a B object and as such we cannot kn ow the size of a D object without knowing the size of B object.\nThe size of an object or equivalently of a type can be obtained through the sizeof operator. This operator yields a compile-time, non-zero unsigned integral value corresponding to the number of bytes required to store an object.\n#include &lt;print&gt;\n\nint main(){\n    char c;\n    // a  char precisely occupies one byte of storage, per\n    // standard wording\n    static_assert(sizeof(c) == 1);\n\n    struct Tiny{};\n    // all C++ types occupy non-zero bytes of storage by \n    // definition, even if they are empty like type Tiny\n    static_assert(sizeof(Tiny) == 1);\n}\nIn the preceding example, the Tiny class is empty because it has no data-member. A class could have member functions and still be empty.\nA C++ object always occupies atleast one byte of storage, even in the case of empty classes such as Tiny. That’s because if the object’s size was zero, that object could be at the same memory location as its immediate neighbor, which would be somewhat hard to reason about.\nC++ differs from many other languages in that it does not standardize the size of all fundamental types. For example, sizeof(int) can yield different values depending on the compiler and the platform. Still there are rules concerning the size of objects:\n\nThe size reported by operator sizeof for objects of type signed char, unsigned char and char is \\(1\\), and the same goes for sizeof(std::byte) as each of these types can be used to represent a single byte.\nThe standard specifies a minimum width for the fundamental types:\n\nSigned Integer Types : Signed integers are represented in two’s complement form. The rules of binary arithmetic are the same for two’s complement as the standard base-2 representation. Hence, the same binary adder hardware circuits can be used for signed integer addition.\n\n\n\n\n\nType\nMinimum width \\(N\\)\n\n\n\n\nsigned char\n\\(1\\) byte\n\n\nshort\n\\(2\\) bytes\n\n\nint\n\\(2\\) bytes\n\n\nlong\n\\(4\\) bytes\n\n\nlong long\n\\(8\\) bytes\n\n\n\n\nFor each of the signed integer types, there exists the corresponding, but different, standard unsigned integer types. An unsigned integer type has the same width \\(N\\) as the corresponding unsigned integer type. The range of representable values for an unsigned type is \\(0\\) to \\(2^N - 1\\). Arithmetic for the unsigned type is performed modulo \\(2^N\\). Unsigned arithmetic does not overflow. Each value \\(x\\) of an unsigned integer type with \\(N\\) has a unique representation \\(x = x_0 2^0 + x_1 2^1 + \\ldots + x_{N-1}2^{N-1}\\), where each coefficient \\(x_i\\) is either \\(0\\) or \\(1\\): this is called the base-2 representation of \\(x\\).\nThe size occupied by an object of any struct or class cannot be less than the sum of the size of its data-members.\n\n\n\nConsider the following code snippet:\nclass X{};\nclass Y : X{   // private inheritance\n    char c;\n};\n\nint main()\n{\n    Y y;\n    static_assert(sizeof(Y) == 1);\n    return 0;\n}\nCompiler Explorer Since the base class is empty, and objects of the derived class Y occupy atleast one byte of storage, the base class can be flattened, when creating objects of the derived class Y. Note that, since the presence of X in Y is an implementation detail, not something that participates in the interface of class Y, I used private inheritance.\n\n\n\n\nstruct X{\n    char c;     // atleast 1 byte\n    short s;    // atleast 2 bytes\n    int i;      // atleast 2 bytes\n    long long ll;  // atleast 8 bytes\n};\n\nint main(){\n    static_assert(sizeof(X) &gt;= 13);\n}\nWe know that sizeof(X) will be atleast \\(13\\) bytes. In practice however, sizeof(X) is likely to be equal to \\(32\\) bytes. This might seem surprising at first, but it’s a logical consequence of something called alignment.\nThe alignment of an object tells us where that object can be placed in memory. The char type has an alignment of \\(1\\), and as such one can place a char object literally anywhere (as long as one can access that memory). short has an alignment of 2. If a type has an alignment \\(n\\), then objects of that type must be placed at an address that is a multiple of \\(n\\).\nThe alignment has to be a strictly positive power of \\(2\\).\nThe C++ language offers two operators related to alignment: - The alignof operator, which yields the natural alignment of a type T or of an object of that type. - The alignas operator, which lets the programmers impose the alignment of an object. this is often useful, when playing tricks with memory(as we will), or when interfacing wit with exotic hardware. Of course, alignas can only reasonably increase the natural alignment of a type T, not reduce it.\nFor some fundamental type T, we can expect the assertion sizeof(T) is equal to alignof(T) to hold, but that assertion does not generalize to composite types. For example, consider again the struct X:\nstruct X{\n    char c;     // alignof(c) == 1\n    short s;    // alignof(s) == 2\n    int i;      // alignof(i) == 4 (most probable)\n    long long ll;  // alignof(ll) == 8 (most probable)\n};\nGenerally, speaking for a composite type, the alignment will correspond to the worst alignment of the data members. Here, worst means biggest. For struct X, the worst-aligned data member is type long long, and as such X objects will be aligned on \\(8\\)-byte boundaries, so it can be placed at an address \\(8\\), \\(16\\), \\(24\\) and so forth. It is highly probable sizeof(X) == 16 bytes.\nOffset  Content\n------  -------\n  0     | c  |  (char, 1 byte)\n        +----+\n  1     |pad |  (padding, 1 byte)\n        +----+\n  2     | s  |  (short, 2 bytes)\n  3     |    |\n        +----+\n  4     | i  |  (int, 4 bytes)\n  5     |    |\n  6     |    |\n  7     |    |\n        +----+\n  8     | ll |  (long long, 8 bytes)\n  9     |    |\n 10     |    |\n 11     |    |\n 12     |    |\n 13     |    |\n 14     |    |\n 15     |    |\n        +----+\nNow, that we know about alignment, just changing the order of the elements in a struct can affect memory consumption. We should always code structs in the order of largest to smallest data-members."
  },
  {
    "objectID": "posts/objects-pointers-and-references/index.html#string-literals",
    "href": "posts/objects-pointers-and-references/index.html#string-literals",
    "title": "Objects, Pointers and References",
    "section": "",
    "text": "A string literal is a character sequence enclosed within double quotes.\n\"this is a string\"\nA string literal contains one more character than it appears to have; it is terminated by the \\0 null termination character (having integer value 0). For example,\nsizeof(\"Bohr\") == 5\nThe type of a string literal is array of appropriate number of const characters, so \"Bohr\" is of type const char[5].\nIn C and older C++ code, you could assign a string literal to a non-const char*.\nModifying string literals is undefined behavior. In practice, the implementation can for instance store the string literal in read-only memory, such as the .rodata segment on Linux.\nvoid f()\n{\n    //char* p = \"Cauchy\";       // error, since C++11\n    const char* s = \"Cauchy\";   // ok\n    //s[4] = 'e';               // error, assignment to const\n}\nHaving string literals as immutable is not only obvious but also allows implementations to do significant optimizations in the way string literals are stored and accessed.\nIf we want a string that we are guaranteed to be able to modify, we must place the characters in a non-const array.\nchar p[] = \"Schwarz\";   // p is an array of 8 char\np[0] = 's';             // ok\nA string literal is statically allocated so it is safe to return one from a function. It is an lvalue.\nWhether two identical strings are allocated as one array, or as two is implementation defined. For example:\nconst char* p = \"Carl Friedrich Gauss\";\nconst char* q = \"Carl Friedrich Gauss\";\nif(p == q)\n    std::cout &lt;&lt; \"\\n\" &lt;&lt; \"one!\";        // Implementation defined\nNote that, == compares addresses (pointer values) when applied to pointers, and not the objects pointed to."
  },
  {
    "objectID": "posts/objects-pointers-and-references/index.html#challenge-puzzle",
    "href": "posts/objects-pointers-and-references/index.html#challenge-puzzle",
    "title": "Objects, Pointers and References",
    "section": "",
    "text": "Observe the code snippet below. What is printed?\n#include &lt;iostream&gt;\n\nint main()\n{\n    // string literals\n    char s1[] = {'h','e','l','l','o', '\\0'};\n    char s2[] = \"hello\";\n    const char* s3 = \"world\";\n\n    std::cout &lt;&lt; \"s1 = \" &lt;&lt; s1 &lt;&lt; \"\\n\";\n    std::cout &lt;&lt; \"s2 = \" &lt;&lt; s2 &lt;&lt; \"\\n\";\n    std::cout &lt;&lt; \"s3 = \" &lt;&lt; s3 &lt;&lt; \"\\n\";\n\n    const char* c[] = {\n        \"C++\", \"is\", \"a\", \"general\", \"purpose\", \n        \"programming\", \"language\"\n    };\n\n    std::cout &lt;&lt; \"c + 0 : \" &lt;&lt; (c) &lt;&lt; \"\\n\";\n    std::cout &lt;&lt; \"c + 1 : \" &lt;&lt; (c + 1) &lt;&lt; \"\\n\";\n    std::cout &lt;&lt; \"c + 2 : \" &lt;&lt; (c + 2) &lt;&lt; \"\\n\";\n    std::cout &lt;&lt; \"c + 3 : \" &lt;&lt; (c + 3) &lt;&lt; \"\\n\";                           \n\n    std::cout &lt;&lt; \"c[0] : \" &lt;&lt; c[0] &lt;&lt; \"\\n\";\n    std::cout &lt;&lt; \"c[1] : \" &lt;&lt; c[1] &lt;&lt; \"\\n\";\n    std::cout &lt;&lt; \"c[2] : \" &lt;&lt; c[2] &lt;&lt; \"\\n\";\n    std::cout &lt;&lt; \"c[3] : \" &lt;&lt; *(c + 3) &lt;&lt; \"\\n\";\n\n    const char** cp[] = { c + 2, c + 3, c, c + 1 };\n    const char*** cpp = cp;\n    \n\n    std::cout &lt;&lt; *cpp[1] &lt;&lt; ' ';\n    std::cout &lt;&lt; *(*(*(cpp + 2) + 2) + 3) &lt;&lt; ' ';\n    std::cout &lt;&lt; (*cpp)[-1] &lt;&lt; ' ';\n    std::cout &lt;&lt; *(cpp + 3)[-1] &lt;&lt; std::endl;\n    return 0;\n}\nCompiler Explorer"
  },
  {
    "objectID": "posts/objects-pointers-and-references/index.html#challenge-puzzle-1",
    "href": "posts/objects-pointers-and-references/index.html#challenge-puzzle-1",
    "title": "Objects, Pointers and References",
    "section": "",
    "text": "Which of the following can be used to print the address of a char variable?\nchar ch = 'A';\nstd::cout &lt;&lt; ???;    // print address of ch\n\n&ch[0]\n(char*)&ch\n(void*)&ch\n&ch\n\n&ch is of type char*. The &lt;&lt; operator for std::cout has an overload for char* that interprets it as a pointer to a null-terminated C-style string, so it attempts to print characters starting from the address of ch until it encounters a null terminator (\\0).\nA pointer has to be able address all memory space. On 64-bit architecture, sizeof(T*) is therefore, \\(8\\) bytes = \\(64\\) bits.\nvoid f(int* pi)\n{\n    void* pv = pi;  // ok : implicit conversion of `int*` to `void*`\n    // *pv;         // error: can't dereference void*\n    ++pv;           // error: can't increment void*\n    \n    int* pi2 = static_cast&lt;int*&gt;(pv);   // explicit conversion back to `int*`\n    //double* pd1 = pv;                   // error\n    //double* pd2 = pi;                   // error\n    double* pd3 = static_cast&lt;double*&gt;(pv); // unsafe\n}\nIn general, it is not safe to use a pointer that has been converted to a type that differs from the type of the object pointed to.\nThe primary use for void* is for passing pointers to functions that are not allowed to make assumptions about the type of the object and for returning untyped objects from functions."
  },
  {
    "objectID": "posts/objects-pointers-and-references/index.html#pointer-declarations",
    "href": "posts/objects-pointers-and-references/index.html#pointer-declarations",
    "title": "Objects, Pointers and References",
    "section": "",
    "text": "Use the spiral rule, when reading pointer declarations. Start at the inner-most level and work your way outwards spiralling in a counter-clockwise direction.\ndouble (*ptr)[5];   // Pointer to array of 5 double(s)\ndouble* ptr[5];     // ptr is an array of pointers to double of size 5"
  },
  {
    "objectID": "posts/objects-pointers-and-references/index.html#dereferencing-null-pointers",
    "href": "posts/objects-pointers-and-references/index.html#dereferencing-null-pointers",
    "title": "Objects, Pointers and References",
    "section": "",
    "text": "Trying to dereference a null pointer is an error. On most platforms, it generally causes a signal, usually SIGSEGV (see Signals).\nchar *foo = NULL;\nc = *foo;    /* This causes a signal and terminates.  */\nLikewise a pointer that has the wrong alignment for the target data type (on most types of computer), or points to a part of memory that has not been allocated in the process’s address space."
  },
  {
    "objectID": "posts/objects-pointers-and-references/index.html#pointer-comparisons",
    "href": "posts/objects-pointers-and-references/index.html#pointer-comparisons",
    "title": "Objects, Pointers and References",
    "section": "",
    "text": "Two pointer values are equal if they point to the same memory address or they are both nullptr. Ordering comparisons such as &gt; and &gt;= operate on pointers by converting them to unsigned integers."
  },
  {
    "objectID": "posts/objects-pointers-and-references/index.html#pointers-into-arrays",
    "href": "posts/objects-pointers-and-references/index.html#pointers-into-arrays",
    "title": "Objects, Pointers and References",
    "section": "",
    "text": "In C++, pointers and arrays are closely related. The name of the array holds the starting address of the array can be used as a pointer to the initial element.\nint v[] = {1,2,3,4};\nint* p1 = v;        // pointer to initial element\nint* p2 = &v[0];    // pointer to initial element\nint* p3 = v+4;      // pointer to one beyond the last element\nTaking a pointer to the element one beyond the end of an array is guaranteed to work. This is important for many algorithms. However, since such a pointer does not in fact point to an element of the array, it should not be used for dereferencing, reading or writing values.\nThe result of taking the address of the element before the initial element or beyond one-past-the-last element is undefined and should be avoided.\nFor example:\n// int* p4 = v - 1;    // before the beginning, undefined\n// int* p5 = v + 7;    // beyond the end, undefined"
  },
  {
    "objectID": "posts/objects-pointers-and-references/index.html#navigating-arrays",
    "href": "posts/objects-pointers-and-references/index.html#navigating-arrays",
    "title": "Objects, Pointers and References",
    "section": "",
    "text": "Efficient and elegant access to arrays and similar data-structures is the key to many algorithms. Access can be achieved either through pointer to an array plus an integer index or through a pointer to an element.\nvoid fi(char* v)\n{\n    for(int i{0}; v[i]!=0; ++i)\n    {\n        std::cout &lt;&lt; v[i];\n    }\n} \n\nvoid fp(char* v)\n{\n    for(char* p{v}; *p!=0; ++p)\n    {\n        std::cout &lt;&lt; *p;\n    }\n}\nSubscripting a built-in array is defined in terms of pointer operations + and *. For every built-in array a and integer j within the range of a, we have:\na[j] == *(&a[0]+j) == *(a+j) == *(j + a) == j[a]\nIt usually surprises people to find that a[j] == j[a]. For example, 3[\"Texas\"] == \"Texas\"[3] == 'a'. Although such cleverness has no place in production code, from an interview perspective its good to know these low-level equivalences.\nThe result of applying the arithmetic operators +, -, ++ or -- to pointers depends on the type of the object pointed to. When an arithmetic operator is applied to a pointer p of type T*, p is assumed to point to an element of an array of objects of type T; p+1 points to the next element of that array, p-1 points to the previous element. This implies that the integer value of p+1 will be sizeof(T) larger than the integer value of p.\n#include &lt;iostream&gt;\ntemplate &lt;typename T&gt;\nint byte_diff(T* p, T* q) {\n    return reinterpret_cast&lt;char*&gt;(q) - reinterpret_cast&lt;char*&gt;(p);\n}\n\nint main() {\n    int vi[10] = {};\n    short vs[10] = {};\n    std::cout &lt;&lt; byte_diff(&vi[1], &vi[2]) &lt;&lt; \" bytes diff\" &lt;&lt; \"\\n\";\n    std::cout &lt;&lt; byte_diff(&vs[1], &vs[2]) &lt;&lt; \" bytes diff\" &lt;&lt; \"\\n\";\n    return 0;\n}\nCompiler Explorer\nSubtraction of pointers is defined only when both pointers point to elements of the same array. When subtracting a p pointer from another pointer q, q-p is the number of array elements in the sequence [p:q). One can add an integer to a pointer or subtract an integer from a pointer, in both cases, the result is a pointer value. If that value does not point to an element of the same array as the original array or one beyond, the result of using that value is UB.\nint v1[10];\nint v2[10];\n\nint i1 = &v1[5] - &v1[3];   // i1 = 2\n//int i2 = &v1[5] - &v2[3];   // UB\n\nint* p1 = v2 + 2;   // p1 = &v2[2]\n//int* p2 = v2 - 2;   // UB\nComplicated pointer arithmetic is usually unnecessary and best avoided. Addition of pointers makes no sense and is not allowed.\nArrays are not self-describing because the number of elements of an array is not guaranteed to be stored with the array. This implies that to traverse an array that does not contain a terminator, the way C-style strings do, we must somehow supply the elements. ## Precedence of operators\nThe precedence of operators in C++ is:\n\n\n\nOperators\nDescription\n\n\n\n\n[] () . -&gt;\nPostfix operators, left-to-right\n\n\nx++ x--\nPostfix, left-to-right\n\n\n++x --x * &\nPrefix, right-to-left\n\n\n* / %\nMultiplicative\n\n\n+ -\nAdditive\n\n\n\n\n\nint arr[] = {10, 20, 30};\nint *p = arr;\nint x = *p++;   // x = 10, p now points to arr[1]\nConsider the expression *ptr++ . Post-increment ++ has a higher precedence than the dereference operator *, so it’s parsed as *(ptr++). ptr++ returns the old value that ptr pointed to, but moves ptr forward at a future time. ### Example 2\nint arr[] = {10, 20, 30};\nint *p = arr;\nint x = *++p;   // p moves to arr[1], then x = 20\nConsider the expression *++p. Both the dereference operator * and pre-increment ++ are prefix operators and have the same precedence. Since, they have right-to-left associativity, we read them right-to-left. *++p is parsed as *(++p). ### Example 3\nint arr[] = {10, 20, 30};\nint *p = arr;\n++*p;          // arr[0] becomes 11, p unchanged\nConsider the expression ++*p. Using right-to-left associativity rule, we first dereference and then increment. ## Challenge puzzle\nint arr[5] = {10, 20, 30, 40, 50};\nint *p = arr + 2;\nint *q = arr + 4;\n\n// What are the values of:\n// a) p - q\n// b) q - p\n// c) *p++\n// d) *++p (after the previous operation)\nCompiler Explorer p - q evaluates to \\(-2\\), q - p evaluates to \\(2\\)."
  },
  {
    "objectID": "posts/objects-pointers-and-references/index.html#challenge-puzzle-2",
    "href": "posts/objects-pointers-and-references/index.html#challenge-puzzle-2",
    "title": "Objects, Pointers and References",
    "section": "",
    "text": "int x = 10;\nint *p = &x;\nint **pp = &p;\n\n// What happens with each line?\n**pp = 20;\n*pp = nullptr;\n// Can you still access x? What's its value?\nCompiler Explorer After the line *pp=20, the variable x has been assigned a new value 20. *p = nullptr will reset the value in pointer variable p to a nullptr. We cannot access the contents of the variable x through the pointer variables p and pp."
  },
  {
    "objectID": "posts/objects-pointers-and-references/index.html#challenge-puzzle-3",
    "href": "posts/objects-pointers-and-references/index.html#challenge-puzzle-3",
    "title": "Objects, Pointers and References",
    "section": "",
    "text": "Observe the code snippet below. What is printed?\n// Headers\nint main()\n{ \n    const char* str[] = { \"AAAAA\", \"BBBBB\", \"CCCCC\", \"DDDDD\" }; \n    const char** sptr[] = { str + 3, str + 2, str + 1, str }; \n    const char*** pp; \n    pp = sptr; \n    ++pp; \n    std::cout &lt;&lt; **++pp + 2; \n}\nInitially, pp is incremented to point to the address of sptr[1].\nIn the order of precedence, from high to low, we have:\n\n* dereference and ++ pre-increment operator (Right-to-left)\n+ - Addition binary operator (Left-to-right)\n\nSo, **++pp + 2 would be parsed as *(*(+pp)) + 2. Thus, pp is now incremented to point to the address of str+1. Then, it is dereferenced twice to yield the string literal BBBBB which is a char*. Finally, an offset of 2, will print the text BBB. ## Passing C-style arrays\nArrays cannot be directly passed by value. Instead, an array is as a pointer to its first element.\ndouble vec_norm(double* vec, std::size_t n)\n{\n    double sum_of_squares{0.0};  \n    for(int i{0}; i&lt;n; ++i)\n    {\n        sum_of_squares += vec[i];\n    }\n    \n    return sqrt(sum_of_squares);\n}\nMulti-dimensional arrays can be passed in a similar fashion.\ndouble frobenius_norm(double* mat, std::size_t num_rows, std::size_t num_cols)\n{\n    double sum_of_squares{0.0};  \n    for(int i{0}; i&lt;m; ++i)\n    {\n        for(int j{0}; j&lt;n; ++j)\n        {\n            sum_of_squares += mat[i][j];\n        }\n    }\n    \n    return sqrt(sum_of_squares);\n}"
  },
  {
    "objectID": "posts/objects-pointers-and-references/index.html#references",
    "href": "posts/objects-pointers-and-references/index.html#references",
    "title": "Objects, Pointers and References",
    "section": "",
    "text": "The C++ language supports two families of indirections: pointers and references. A reference can be seen as an alias for an existing entity. We deliberately did not use the word object, since one could refer to a function and we already know that a function is not an object.\nPointers are objects. As such they occupy storage. References, on the other hand, are not objects, they do not use any storage of their own.\nThe sizeof operator applied to a reference, will yield the size of whatever it refers to. In C++, a reference is always bound to an object and remains bound to that object until the end of the reference’s lifetime. A pointer, on the other hand, can point to numerous distinct objects during its lifetime.\nAnother difference between pointers and references is that, contrary to the situation, there is no such thing as reference arithmetic. This makes references safer than pointers."
  },
  {
    "objectID": "posts/objects-pointers-and-references/index.html#understanding-the-fundamental-properties-of-objects",
    "href": "posts/objects-pointers-and-references/index.html#understanding-the-fundamental-properties-of-objects",
    "title": "Objects, Pointers and References",
    "section": "",
    "text": "We saw earlier that in C++, an object has a type and an address. It occupies a region of storage from the beginning of it’s construction to the end of it’s destruction.\n\n\nIn C++, generally speaking, automatic objects are destructed at the end of their scope in a well-defined order. Static(global) objects are destructed on program termination in a somewhat well-defined order. Dynamically allocated objects are destroyed when your program says so.\nLet’s examine some aspects of object lifetime with the following very simple program:\n#include &lt;string&gt;\n#include &lt;print&gt;\n#include &lt;format&gt;\n\nstruct X{\n    std::string s;\n    X(std::string_view s) : s{ s }\n    {\n        std::print(\"X::X({})\\n\", s);\n    }\n\n    ~X(){\n        std::print(\"~X::X() for {}\\n\", s);\n    }\n};\n\nX glob{ \"glob\" };\n\nvoid g(){\n    X xg{ \"g()\" };\n}\n\nint main()\n{\n    X* p0 = new X{ \"p0\" };\n    [[maybe_unused]] X* p1 = new X{ \"p1\" }; // will leak\n    X xmain{ \"main()\" };\n    g();\n    delete p0;\n    // oops, forgot to delete p1\n    return 0;\n}\nCompiler Explorer\nWhen executed, the program will print the following:\nX::X(glob)\nX::X(p0)\nX::X(p1)\nX::X(main())\nX::X(g())\n~X::X() for g()\n~X::X() for p0\n~X::X() for main()\n~X::X() for glob\nThe fact that the number of constructors and destructors do not match is a sign that we did something wrong. More specifically, in this example, we manually created an object (pointed to by p1) with the operator new but never manually destructed that object afterward. This is a memory leak."
  },
  {
    "objectID": "posts/objects-pointers-and-references/index.html#object-size-alignment-and-padding",
    "href": "posts/objects-pointers-and-references/index.html#object-size-alignment-and-padding",
    "title": "Objects, Pointers and References",
    "section": "",
    "text": "Since each object occupies storage, the space associated with an object is an important(if low-level) property of C++ types. For example, look at the following code:\nclass B;    // fporward declaraion: there will be a class B\n            // at some point in the future\n            \nvoid f(B*); // fine, we know what NB is, even if don't know the details yet,\n            // and all object addresses are of the same size\n\nclass D : B{};  // oops! This is the definition of class D. To determine\n                // sizeof(D), we have to know how big sizeof(B) is and what\n                // a B object contains since a D is a B\nIn the above example, trying to define the D class would not compile. This is because in order to create aD object, the compiler needs to reserve enough space for a D object, but a D object is also a B object and as such we cannot kn ow the size of a D object without knowing the size of B object.\nThe size of an object or equivalently of a type can be obtained through the sizeof operator. This operator yields a compile-time, non-zero unsigned integral value corresponding to the number of bytes required to store an object.\n#include &lt;print&gt;\n\nint main(){\n    char c;\n    // a  char precisely occupies one byte of storage, per\n    // standard wording\n    static_assert(sizeof(c) == 1);\n\n    struct Tiny{};\n    // all C++ types occupy non-zero bytes of storage by \n    // definition, even if they are empty like type Tiny\n    static_assert(sizeof(Tiny) == 1);\n}\nIn the preceding example, the Tiny class is empty because it has no data-member. A class could have member functions and still be empty.\nA C++ object always occupies atleast one byte of storage, even in the case of empty classes such as Tiny. That’s because if the object’s size was zero, that object could be at the same memory location as its immediate neighbor, which would be somewhat hard to reason about.\nC++ differs from many other languages in that it does not standardize the size of all fundamental types. For example, sizeof(int) can yield different values depending on the compiler and the platform. Still there are rules concerning the size of objects:\n\nThe size reported by operator sizeof for objects of type signed char, unsigned char and char is \\(1\\), and the same goes for sizeof(std::byte) as each of these types can be used to represent a single byte.\nThe standard specifies a minimum width for the fundamental types:\n\nSigned Integer Types : Signed integers are represented in two’s complement form. The rules of binary arithmetic are the same for two’s complement as the standard base-2 representation. Hence, the same binary adder hardware circuits can be used for signed integer addition.\n\n\n\n\n\nType\nMinimum width \\(N\\)\n\n\n\n\nsigned char\n\\(1\\) byte\n\n\nshort\n\\(2\\) bytes\n\n\nint\n\\(2\\) bytes\n\n\nlong\n\\(4\\) bytes\n\n\nlong long\n\\(8\\) bytes\n\n\n\n\nFor each of the signed integer types, there exists the corresponding, but different, standard unsigned integer types. An unsigned integer type has the same width \\(N\\) as the corresponding unsigned integer type. The range of representable values for an unsigned type is \\(0\\) to \\(2^N - 1\\). Arithmetic for the unsigned type is performed modulo \\(2^N\\). Unsigned arithmetic does not overflow. Each value \\(x\\) of an unsigned integer type with \\(N\\) has a unique representation \\(x = x_0 2^0 + x_1 2^1 + \\ldots + x_{N-1}2^{N-1}\\), where each coefficient \\(x_i\\) is either \\(0\\) or \\(1\\): this is called the base-2 representation of \\(x\\).\nThe size occupied by an object of any struct or class cannot be less than the sum of the size of its data-members.\n\n\n\nConsider the following code snippet:\nclass X{};\nclass Y : X{   // private inheritance\n    char c;\n};\n\nint main()\n{\n    Y y;\n    static_assert(sizeof(Y) == 1);\n    return 0;\n}\nCompiler Explorer Since the base class is empty, and objects of the derived class Y occupy atleast one byte of storage, the base class can be flattened, when creating objects of the derived class Y. Note that, since the presence of X in Y is an implementation detail, not something that participates in the interface of class Y, I used private inheritance."
  },
  {
    "objectID": "posts/objects-pointers-and-references/index.html#alignment",
    "href": "posts/objects-pointers-and-references/index.html#alignment",
    "title": "Objects, Pointers and References",
    "section": "",
    "text": "struct X{\n    char c;     // atleast 1 byte\n    short s;    // atleast 2 bytes\n    int i;      // atleast 2 bytes\n    long long ll;  // atleast 8 bytes\n};\n\nint main(){\n    static_assert(sizeof(X) &gt;= 13);\n}\nWe know that sizeof(X) will be atleast \\(13\\) bytes. In practice however, sizeof(X) is likely to be equal to \\(32\\) bytes. This might seem surprising at first, but it’s a logical consequence of something called alignment.\nThe alignment of an object tells us where that object can be placed in memory. The char type has an alignment of \\(1\\), and as such one can place a char object literally anywhere (as long as one can access that memory). short has an alignment of 2. If a type has an alignment \\(n\\), then objects of that type must be placed at an address that is a multiple of \\(n\\).\nThe alignment has to be a strictly positive power of \\(2\\).\nThe C++ language offers two operators related to alignment: - The alignof operator, which yields the natural alignment of a type T or of an object of that type. - The alignas operator, which lets the programmers impose the alignment of an object. this is often useful, when playing tricks with memory(as we will), or when interfacing wit with exotic hardware. Of course, alignas can only reasonably increase the natural alignment of a type T, not reduce it.\nFor some fundamental type T, we can expect the assertion sizeof(T) is equal to alignof(T) to hold, but that assertion does not generalize to composite types. For example, consider again the struct X:\nstruct X{\n    char c;     // alignof(c) == 1\n    short s;    // alignof(s) == 2\n    int i;      // alignof(i) == 4 (most probable)\n    long long ll;  // alignof(ll) == 8 (most probable)\n};\nGenerally, speaking for a composite type, the alignment will correspond to the worst alignment of the data members. Here, worst means biggest. For struct X, the worst-aligned data member is type long long, and as such X objects will be aligned on \\(8\\)-byte boundaries, so it can be placed at an address \\(8\\), \\(16\\), \\(24\\) and so forth. It is highly probable sizeof(X) == 16 bytes.\nOffset  Content\n------  -------\n  0     | c  |  (char, 1 byte)\n        +----+\n  1     |pad |  (padding, 1 byte)\n        +----+\n  2     | s  |  (short, 2 bytes)\n  3     |    |\n        +----+\n  4     | i  |  (int, 4 bytes)\n  5     |    |\n  6     |    |\n  7     |    |\n        +----+\n  8     | ll |  (long long, 8 bytes)\n  9     |    |\n 10     |    |\n 11     |    |\n 12     |    |\n 13     |    |\n 14     |    |\n 15     |    |\n        +----+\nNow, that we know about alignment, just changing the order of the elements in a struct can affect memory consumption. We should always code structs in the order of largest to smallest data-members."
  },
  {
    "objectID": "posts/generators_iterators_and_asynchronous_programming/index.html",
    "href": "posts/generators_iterators_and_asynchronous_programming/index.html",
    "title": "Generators, iterators and asynchronous programming",
    "section": "",
    "text": "%load_ext itikz\n\nA generator is a function that uses the yield keyword to return an item. When a generator function is called, it returns a generator object, which is a type of iterator. Here is a simple generator, that produces a sequence of numbers:\n\ndef number_generator(n):\n    for i in range(n):\n        yield i\n\ngen = number_generator(1_000_000)\n\nprint(next(gen))\nprint(next(gen))\nprint(next(gen))\n\n0\n1\n2\n\n\nThe state of the generator is saved between yield calls. The state of generator is the state of the local variables when the generator is suspended. This allows it to resume where it left off.\nThe main use of generators is to save memory - instead of having a very large list of elements in memory, holding everything at once, we have an object that knows how to produce each particular element, one at a time. This enables lazy computations of heavy objects in memory."
  },
  {
    "objectID": "posts/generators_iterators_and_asynchronous_programming/index.html#iteration-process",
    "href": "posts/generators_iterators_and_asynchronous_programming/index.html#iteration-process",
    "title": "Generators, iterators and asynchronous programming",
    "section": "Iteration process",
    "text": "Iteration process\nWe start with an initial interval \\([a,b]\\), such that the function values \\(f(a)\\) and \\(f(b)\\) are of opposite sign.\nStep 1. We calculate the midpoint \\(m = (a + b)/2\\).\nStep 2. Case I. If \\(f(a)\\) and \\(f(m)\\) have the same signs, the root must be in the right half \\([m,b]\\). So, we set \\(a=m\\).\nCase II. If \\(f(m)\\) and \\(f(b)\\) have the same signs, the root must be in the left half \\([a,m]\\). So, we set \\(b=m\\).\nWe iteratively perform steps (1) and (2) until the absolute or relative error is within a certain tolerance \\(\\epsilon\\).\n\n\n\nShow the code\n%%itikz --temp-dir --tex-packages=tikz --tikz-libraries=backgrounds --implicit-standalone\n\n% Scenario 1: Root in left half\n\\begin{tikzpicture}[scale=1.2, background rectangle/.style={fill=white}, show background rectangle]\n    % Axes\n    \\draw[-&gt;] (-0.5,0) -- (5,0) node[right] {$x$};\n    \\draw[-&gt;] (0,-2.5) -- (0,2.5) node[above] {$y$};\n    \n    % Points\n    \\coordinate (a) at (0.5,0);\n    \\coordinate (b) at (4.5,0);\n    \\coordinate (m) at (2.5,0);\n    \n    % Function curve (convex)\n    \\draw[thick, blue, domain=0.5:4.5, samples=100] \n        plot (\\x, {0.3*(\\x-1.5)*(\\x-1.5) - 1.2});\n    \n    % Vertical lines and points\n    \\draw[dashed] (0.5,0) -- (0.5,{0.3*(0.5-1.5)*(0.5-1.5) - 1.2});\n    \\draw[dashed] (2.5,0) -- (2.5,{0.3*(2.5-1.5)*(2.5-1.5) - 1.2});\n    \\draw[dashed] (4.5,0) -- (4.5,{0.3*(4.5-1.5)*(4.5-1.5) - 1.2});\n    \n    % Function values\n    \\fill[red] (0.5,{0.3*(0.5-1.5)*(0.5-1.5) - 1.2}) circle (2pt) \n        node[below left] {$f(a) &lt; 0$};\n    \\fill[red] (2.5,{0.3*(2.5-1.5)*(2.5-1.5) - 1.2}) circle (2pt) \n        node[below right] {$f(m) &lt; 0$};\n    \\fill[red] (4.5,{0.3*(4.5-1.5)*(4.5-1.5) - 1.2}) circle (2pt) \n        node[above right] {$f(b) &gt; 0$};\n    \n    % x-axis labels\n    \\fill (0.5,0) circle (1.5pt) node[below] {$a$};\n    \\fill (2.5,0) circle (1.5pt) node[below] {$m$};\n    \\fill (4.5,0) circle (1.5pt) node[below] {$b$};\n    \n    % Root indicator\n    \\draw[thick, red] (2.5,-0.3) -- (4.5,-0.3);\n    \\node[red] at (3.5,-0.6) {Root in $[m, b]$};\n    \n    % Title\n    \\node[align=center] at (2.5,3) {\\textbf{Scenario 1:} $f(a)$ and $f(m)$ have same sign};\n    \\node[align=center] at (2.5,2.5) {New interval: $[m, b]$};\n\\end{tikzpicture}\n\n\n\n\n\n\n\n\n\nShow the code\n%%itikz --temp-dir --tex-packages=tikz --tikz-libraries=backgrounds --implicit-standalone\n\\begin{tikzpicture}[scale=1.2, background rectangle/.style={fill=white}, show background rectangle]\n    % Axes\n    \\draw[-&gt;] (-0.5,0) -- (5,0) node[right] {$x$};\n    \\draw[-&gt;] (0,-2.5) -- (0,2.5) node[above] {$y$};\n    \n    % Points\n    \\coordinate (a) at (0.5,0);\n    \\coordinate (b) at (4.5,0);\n    \\coordinate (m) at (2.5,0);\n    \n    % Function curve (convex)\n    \\draw[thick, blue, domain=0.5:4.5, samples=100] \n        plot (\\x, {0.3*(\\x-3.5)*(\\x-3.5) - 1.2});\n    \n    % Vertical lines and points\n    \\draw[dashed] (0.5,0) -- (0.5,{0.3*(0.5-3.5)*(0.5-3.5) - 1.2});\n    \\draw[dashed] (2.5,0) -- (2.5,{0.3*(2.5-3.5)*(2.5-3.5) - 1.2});\n    \\draw[dashed] (4.5,0) -- (4.5,{0.3*(4.5-3.5)*(4.5-3.5) - 1.2});\n    \n    % Function values\n    \\fill[red] (0.5,{0.3*(0.5-3.5)*(0.5-3.5) - 1.2}) circle (2pt) \n        node[above left] {$f(a) &gt; 0$};\n    \\fill[red] (2.5,{0.3*(2.5-3.5)*(2.5-3.5) - 1.2}) circle (2pt) \n        node[above right] {$f(m) &lt; 0$};\n    \\fill[red] (4.5,{0.3*(4.5-3.5)*(4.5-3.5) - 1.2}) circle (2pt) \n        node[below right] {$f(b) &lt; 0$};\n    \n    % x-axis labels\n    \\fill (0.5,0) circle (1.5pt) node[below] {$a$};\n    \\fill (2.5,0) circle (1.5pt) node[below] {$m$};\n    \\fill (4.5,0) circle (1.5pt) node[below] {$b$};\n    \n    % Root indicator\n    \\draw[thick, red] (0.5,-0.3) -- (2.5,-0.3);\n    \\node[red] at (1.5,-0.6) {Root in $[a, m]$};\n\n    \n    % Title\n    \\node[align=center] at (2.5,3) {\\textbf{Scenario 2:} $f(m)$ and $f(b)$ have same sign};\n    \\node[align=center] at (2.5,2.5) {New interval: $[a, m]$};\n\\end{tikzpicture}\n\n\n\n\n\n\nA call option is the right to buy an asset at a future time \\(T\\), at a pre-determined price \\(K\\). A put option is the right to sell an asset at a future time \\(T\\), at a pre-determined price \\(K\\).\nVanilla options have two quote conventions - they can be quoted in terms of a price (in dollar terms) or in terms of the implied volatility. The Black-Scholes analytic formula used as a converter to convert an implied-vol quote to a price.\nLet \\(\\sigma\\) be the market-implied volatility of the option. Then, the call option price is given by:\n\\[\nC_{BS}(\\sigma) = S_t \\Phi(d_{+}) - K e^{-r(T-t)}\\Phi(d_{-})\n\\]\nwhere\n\\[\nd_{\\pm} = \\frac{\\log(S_t/K) + (r \\pm \\sigma^2/2)(T-t)}{\\sigma \\sqrt{T-t}}\n\\]\nConversely, if we have the observed marker option quote \\(C_{BS}\\), we can backout the implied volatility \\(\\sigma\\), by solving for the root of the above equation.\nThus, we can define\n\\[\nf(\\sigma) = S_t \\Phi(d_{+}) - K e^{-r(T-t)}\\Phi(d_{-}) - C_{BS}\n\\]\nand find the root of \\(f\\). Assume that the root lies in the interval \\([0,1]\\).\n\nimport math\nfrom typing import Callable\n\ndef d_plus(S, K, T, r, sigma):\n    \"\"\"d+ term of the Black formula\"\"\"\n    return (math.log(S / K) + (r + sigma**2/2) * T)/(sigma * math.sqrt(T))\n\ndef d_minus(S, K, T, r, sigma):\n    \"\"\"d- term of the Black formula\"\"\"\n    return (math.log(S / K) + (r - sigma**2/2) * T)/(sigma * math.sqrt(T))\n\ndef norm_cdf(x : float):\n    \"\"\"An approximation to standard normal CDF.\"\"\"\n    k = 1.0/(1.0 + 0.2316419*x);\n    k_sum = k*(0.319381530 + k*(-0.356563782 + k*(1.781477937 + k*(-1.821255978 + 1.330274429*k))));\n\n    if x &gt;= 0.0:\n        return (1.0 - (1.0/(pow(2*3.14159,0.5)))*math.exp(-0.5*x*x) * k_sum);\n    else:\n        return 1.0 - norm_cdf(-x);\n  \n\ndef call_option_price(\n    S : float, K : float, r: float, T: float, sigma: float\n):\n    \"\"\"The price of European vanilla call option.\"\"\"\n    d_1 = d_plus(S, K, T, r, sigma)\n    d_2 = d_minus(S, K, T, r, sigma)\n    return S * norm_cdf(d_1) - K * math.exp(-r * T) * norm_cdf(d_2)\n\nclass BisectionSolver:\n    \"\"\"A solver that iteratively halves the search interval\"\"\"\n    def __init__(self, y_target: float,\n    a: float,\n    b: float,\n    epsilon: float,\n    g : callable):\n    \n        self.y_target = y_target\n        self.a = a\n        self.b = b\n        self.epsilon = epsilon\n        self.g = g\n        self.m = 0.5 * (self.a + self.b)\n        self.y = g(self.m)\n        self.i = 1\n\n    def __iter__(self):\n        \"\"\"Return the iterator object (self)\"\"\"\n        return self\n    \n    def __next__(self):\n        \"\"\"Advance one step to generate the next iterate\"\"\"\n        if abs(self.y - self.y_target) &lt; self.epsilon:\n            raise StopIteration\n    \n        if self.y - self.y_target &lt; 0:\n            self.a = self.m\n\n        if self.y - self.y_target &gt; 0:\n            self.b = self.m\n\n        m = self.m\n        i = self.i\n        self.i += 1\n        self.m = 0.5 * (self.a + self.b)\n        self.y = self.g(self.m)\n        return (i,m)\n\nif __name__ == \"__main__\":\n    S=100\n    K=100\n    r=0.05\n    T=1.0\n    market_quote = 10.450577973198428\n\n    def g(sigma: float):\n        return call_option_price(S, K, r, T, sigma)\n\n    solver = BisectionSolver(market_quote, 0.0, 1.0, 0.5e-5, g)\n    \n    for iter in solver:\n        i, root = iter\n        print(f\"Iteration# : {i}, root estimate : {root}\")\n\nIteration# : 1, root estimate : 0.5\nIteration# : 2, root estimate : 0.25\nIteration# : 3, root estimate : 0.125\nIteration# : 4, root estimate : 0.1875\nIteration# : 5, root estimate : 0.21875\nIteration# : 6, root estimate : 0.203125\nIteration# : 7, root estimate : 0.1953125\nIteration# : 8, root estimate : 0.19921875\nIteration# : 9, root estimate : 0.201171875\nIteration# : 10, root estimate : 0.2001953125\nIteration# : 11, root estimate : 0.19970703125\nIteration# : 12, root estimate : 0.199951171875\nIteration# : 13, root estimate : 0.2000732421875\nIteration# : 14, root estimate : 0.20001220703125\nIteration# : 15, root estimate : 0.199981689453125\nIteration# : 16, root estimate : 0.1999969482421875\nIteration# : 17, root estimate : 0.20000457763671875\nIteration# : 18, root estimate : 0.20000076293945312\nIteration# : 19, root estimate : 0.1999988555908203\nIteration# : 20, root estimate : 0.19999980926513672\nIteration# : 21, root estimate : 0.20000028610229492\n\n\nWe see that a \\(1\\)-year call option struck at \\(K=100\\) with the underlying spot at \\(100\\), annualised interest rate \\(r=0.05\\) with market price \\(C_{BS}=10.45\\) corresponds to an implied volatility of \\(\\sigma_{BS}=0.20\\).\nWhile this toy solver uses the Bisection algorithm, the bisection method has a slow rate of convergence. The Brent-Dekker algorithm is considered the industry standard for root finding.\nMany numerical solvers for finding roots, finding solutions of ODEs and PDEs are iterative in nature."
  },
  {
    "objectID": "posts/exploring_futures_and_promises/index.html",
    "href": "posts/exploring_futures_and_promises/index.html",
    "title": "Creating a tiny C++ Task Library",
    "section": "",
    "text": "A future is an object that represents some undetermined result of a task that will be completed sometime in the future. A promise is the provider of that result.\nThe std::promise and std::future pair implements a one-short producer-consumer channel with the promise as the producer and the future as the consumer. The consumer (std::future) can can block until the result of the producer (std::promise) is available.\nMany modern programming languages provide similar asynchronous approaches, such as Python(with the asyncio library), Scala(in the scala.concurrent library), Rust(in its standard library std or crates such as promising_future).\nThe basic principle behind achieving asynchronous execution using promises and futures is that a function we want to run to generate a result is executed in the background, using a new thread or the current one, and a future object is used by the initial thread to retrieve the result computed by the function. This result value will be stored when the function finishes, so meanwhile, the future acts as a placeholder. The asynchronous function will use a promise object to store the result in the future with no need for explicit synchronization mechanisms between the initial thread and the background one. When the value is needed by the initial thread, it will be retrieved from the future object. If the value is still not ready, the initial thread of execution will be blocked until the future becomes ready.\nUsing promises and futures improves responsiveness by offloading computations and provides a structured approach to handling asynchronous operations compared to threads and callbacks.\n\n\n\n\nA promise holds a shared state. The shared state is a memory area that stores the completion status, synchronization mechanisms, and a pointer to the result. It ensures proper communication and synchronization between a promise and a future by enabling the promise to store either a result or an exception, signal when it’s complete and allowing the future to access the result, blocking if the promise is not yet ready. The promise can update its shared state using the following operations:\n\nMake ready. The promise stores the result in the shared state and makes the state of the promise to become ready unblocking any thread waiting on a future associated with the promise.\nRelease. The promise releases its reference to the shared state, which will be destroyed if this is the last reference.\nAbandon. The promise stores an exception of type std::future_error with error code std::future_errc::broken_promise making the shared state ready and then releasing it.\n\nThe value of a promise can be set using the std::promise function set_value() and an exception by using the set_exception() function. The result is stored atomically in the promise’s shared state, making its state ready. Let’s see an example:\n// Ref: Asynchronous programming with C++\n//Javier Reguara Salgado\nauto threadFunc = [](std::promise&lt;int&gt; prom){\n    try{\n        int result = func();\n        prom.set_value(result);\n    }catch(std::exception& ex){\n        prom.set_exception(ex);\n    }\n}\n\nstd::promise&lt;int&gt; prom;\nstd::jthread t(thread_func, std::move(prom));\nset_value() can throw a std::future_error exception if the promise has no shared state (error code set to no_state) or the shared state has already a storedd result.\nset_value() can also be used without specifying a value. In that case, it simply makes the state ready. That can be used as a barrier, as we will see later in this blog post.\n\n\n\nFutures are defined in the &lt;future&gt; header file as std::future.\nAs we saw earlier, a future is the consumer side of the communication channel. It provides access to the result stored by the promise.\nA std::future object must be created from std::promise object by calling get_future() or through a std::packaged_task object or a call to the std::async function.\nstd::promise&lt;int&gt; prom;\nstd::future&lt;int&gt; fut = prom.get_future();\nLike promises, futures can be moved but not copied for the smae reasons. To reference the same shared state from multiple futures, we need to use shared futures.\nThe get() method can be used to retrieve the result. If the shared state is still not ready, this call will block internally calling wait(). When the shared state becomes ready, the result value is returned. If an exceptionwas sttored in the shared state, that exception will be retrhrown:\ntry{\n    int result = fut.get()\n    std::cout &lt;&lt; \"Result from thread:\" &lt;&lt; result;\n}catch(const std::exception& ex){\n    std::cerr &lt;&lt; \"Exception : \" &lt;&lt; ex.what() &lt;&lt; \"\\n\";\n}\nAfter calling the get() method, valid() will return false. If for some reason get() is called when valid() is false, the behavior is undefined, but the C++ standard recommends that a std::future_error exception is thrown with the std::future_errc::no_state error code.\nWhen a future is destroyed, it releases it shared state reference. If that were the last reference, the shared state would be destroyed.\n\n\n\n\n#include &lt;algorithm&gt;\n#include &lt;chrono&gt;\n#include &lt;future&gt;\n#include &lt;thread&gt;\n#include &lt;vector&gt;\n#include &lt;print&gt;\n\nusing namespace std::chrono_literals;\n\nint main(){\n    std::promise&lt;std::vector&lt;int&gt;&gt; user_list_promise;\n    std::promise&lt;std::vector&lt;int&gt;&gt; orders_promise;\n\n    auto fetch_users_ready = user_list_promise.get_future();\n    auto fetch_orders_ready = orders_promise.get_future();\n\n    std::jthread user_list_thread([&](){\n        std::vector&lt;int&gt; userList{};\n        for(int i{1}; i&lt;=5; ++i){\n            userList.push_back(i);\n            std::this_thread::sleep_for(std::chrono::milliseconds(100));\n        }\n        user_list_promise.set_value(userList);\n    });\n\n    std::jthread orders_thread([&](){\n        std::vector&lt;int&gt; orders{};\n        for(int i{1}; i&lt;=10; ++i){\n            orders.push_back(i);\n            std::this_thread::sleep_for(std::chrono::milliseconds(100));\n        }\n        orders_promise.set_value(orders);\n    });\n\n    fetch_users_ready.wait();\n    fetch_orders_ready.wait();\n\n    auto users = fetch_users_ready.get();\n    auto orders = fetch_orders_ready.get();\n\n    std::println(\"Users = {}\", users);\n    std::println(\"Orders = {}\", orders);\n    return 0;\n}\nCompiler Explorer\n\n\n\nAs we saw earlier, std::future is only moveable, thus only one future object can refer to a particular asynchronous result. On the other hand, std::shared_future is copyable, so several shared future objects can refer to the same shared state.\nThere, std::shared_future allows thread-safe access from different threads to the same shared state. Shared futures can be useful for sharing the result of a computationally intensive task among multiple consumers or interested parties, reducing computation. Also, they can be used to notify events or as a synchronization mechanism where multiple threads must wait for the completion of a single task. The interface of std::shared_object is the same as the one for std::future. A shared_future object is created using the .share() function on the future.\n\n\n\nPromises and futures can be chained together to perform multiple asynchronous operations sequentially. We can have elaborate data-processing pipelines where one future’s result becoimes the input for the next operation’s promise. This allows for composing complex asynchronous workflows where the output of one task feeds into the next.\nAlso, we can allow branching in the pipeline and keep some tasks switched off until needed. This can be done using futures with deferred execution.\nGenerally speaking tasks make up a DAG(Directed acyclic graph). Thus, a task library must consist of two parts : an API to specify the task DAG and a scheduler that actually executes the DAG.\nLet’s try to create the following task graph:\n\n\n\n\ngraph LR\n  Task-1[Task-1] --&gt; Task-2[Task-2]\n  Task-2 --&gt; Task-3[Task-3]\n  Task-2 --&gt; Task-4[Task-4]\n  Task-3 --&gt; Aggregate[Aggregate results]\n  Task-4 --&gt; Aggregate\n\n\n\n\n\nWe start by defining a template class called Task that accepts a callable as a template argument, defining the function to execute. This class will also allow us to create tasks that share a future with dependent ones.\n#include &lt;vector&gt;\n#include &lt;cstdint&gt;\n#include &lt;print&gt;\n\n#define sync_cout std::osyncstream(std::cout)\n\nclass GraphWalker;\n\ntemplate&lt;typename Func&gt;\nclass Task{\n\n    public:\n    Task(int id, Func& func)\n    : m_id{ id }\n    , m_func{ func }\n    {\n        sync_cout &lt;&lt; \"\\n\"\n                  &lt;&lt; \"Task \" &lt;&lt; id &lt;&lt; \" constructed \";\n    }\n\n    Task(const Task& other)\n    : m_id{ other.m_id }\n    , m_func{ other.m_func }\n    {}\n\n    uint64_t get_id(){\n        return m_id;\n    }\n\n    private:\n    u64_t m_id;\n    Func m_func;\n    std::promise&lt;void&gt; m_promise;\n\n};\n\nstruct Node{\n    Task task;\n    std::vector&lt;Node*&gt; child_nodes;\n};"
  },
  {
    "objectID": "posts/exploring_futures_and_promises/index.html#the-basic-mechanics",
    "href": "posts/exploring_futures_and_promises/index.html#the-basic-mechanics",
    "title": "Creating a tiny C++ Task Library",
    "section": "",
    "text": "A promise holds a shared state. The shared state is a memory area that stores the completion status, synchronization mechanisms, and a pointer to the result. It ensures proper communication and synchronization between a promise and a future by enabling the promise to store either a result or an exception, signal when it’s complete and allowing the future to access the result, blocking if the promise is not yet ready. The promise can update its shared state using the following operations:\n\nMake ready. The promise stores the result in the shared state and makes the state of the promise to become ready unblocking any thread waiting on a future associated with the promise.\nRelease. The promise releases its reference to the shared state, which will be destroyed if this is the last reference.\nAbandon. The promise stores an exception of type std::future_error with error code std::future_errc::broken_promise making the shared state ready and then releasing it.\n\nThe value of a promise can be set using the std::promise function set_value() and an exception by using the set_exception() function. The result is stored atomically in the promise’s shared state, making its state ready. Let’s see an example:\n// Ref: Asynchronous programming with C++\n//Javier Reguara Salgado\nauto threadFunc = [](std::promise&lt;int&gt; prom){\n    try{\n        int result = func();\n        prom.set_value(result);\n    }catch(std::exception& ex){\n        prom.set_exception(ex);\n    }\n}\n\nstd::promise&lt;int&gt; prom;\nstd::jthread t(thread_func, std::move(prom));\nset_value() can throw a std::future_error exception if the promise has no shared state (error code set to no_state) or the shared state has already a storedd result.\nset_value() can also be used without specifying a value. In that case, it simply makes the state ready. That can be used as a barrier, as we will see later in this blog post.\n\n\n\nFutures are defined in the &lt;future&gt; header file as std::future.\nAs we saw earlier, a future is the consumer side of the communication channel. It provides access to the result stored by the promise.\nA std::future object must be created from std::promise object by calling get_future() or through a std::packaged_task object or a call to the std::async function.\nstd::promise&lt;int&gt; prom;\nstd::future&lt;int&gt; fut = prom.get_future();\nLike promises, futures can be moved but not copied for the smae reasons. To reference the same shared state from multiple futures, we need to use shared futures.\nThe get() method can be used to retrieve the result. If the shared state is still not ready, this call will block internally calling wait(). When the shared state becomes ready, the result value is returned. If an exceptionwas sttored in the shared state, that exception will be retrhrown:\ntry{\n    int result = fut.get()\n    std::cout &lt;&lt; \"Result from thread:\" &lt;&lt; result;\n}catch(const std::exception& ex){\n    std::cerr &lt;&lt; \"Exception : \" &lt;&lt; ex.what() &lt;&lt; \"\\n\";\n}\nAfter calling the get() method, valid() will return false. If for some reason get() is called when valid() is false, the behavior is undefined, but the C++ standard recommends that a std::future_error exception is thrown with the std::future_errc::no_state error code.\nWhen a future is destroyed, it releases it shared state reference. If that were the last reference, the shared state would be destroyed."
  },
  {
    "objectID": "posts/exploring_futures_and_promises/index.html#a-quick-working-example",
    "href": "posts/exploring_futures_and_promises/index.html#a-quick-working-example",
    "title": "Creating a tiny C++ Task Library",
    "section": "",
    "text": "#include &lt;algorithm&gt;\n#include &lt;chrono&gt;\n#include &lt;future&gt;\n#include &lt;thread&gt;\n#include &lt;vector&gt;\n#include &lt;print&gt;\n\nusing namespace std::chrono_literals;\n\nint main(){\n    std::promise&lt;std::vector&lt;int&gt;&gt; user_list_promise;\n    std::promise&lt;std::vector&lt;int&gt;&gt; orders_promise;\n\n    auto fetch_users_ready = user_list_promise.get_future();\n    auto fetch_orders_ready = orders_promise.get_future();\n\n    std::jthread user_list_thread([&](){\n        std::vector&lt;int&gt; userList{};\n        for(int i{1}; i&lt;=5; ++i){\n            userList.push_back(i);\n            std::this_thread::sleep_for(std::chrono::milliseconds(100));\n        }\n        user_list_promise.set_value(userList);\n    });\n\n    std::jthread orders_thread([&](){\n        std::vector&lt;int&gt; orders{};\n        for(int i{1}; i&lt;=10; ++i){\n            orders.push_back(i);\n            std::this_thread::sleep_for(std::chrono::milliseconds(100));\n        }\n        orders_promise.set_value(orders);\n    });\n\n    fetch_users_ready.wait();\n    fetch_orders_ready.wait();\n\n    auto users = fetch_users_ready.get();\n    auto orders = fetch_orders_ready.get();\n\n    std::println(\"Users = {}\", users);\n    std::println(\"Orders = {}\", orders);\n    return 0;\n}\nCompiler Explorer"
  },
  {
    "objectID": "posts/exploring_futures_and_promises/index.html#shared-futures",
    "href": "posts/exploring_futures_and_promises/index.html#shared-futures",
    "title": "Creating a tiny C++ Task Library",
    "section": "",
    "text": "As we saw earlier, std::future is only moveable, thus only one future object can refer to a particular asynchronous result. On the other hand, std::shared_future is copyable, so several shared future objects can refer to the same shared state.\nThere, std::shared_future allows thread-safe access from different threads to the same shared state. Shared futures can be useful for sharing the result of a computationally intensive task among multiple consumers or interested parties, reducing computation. Also, they can be used to notify events or as a synchronization mechanism where multiple threads must wait for the completion of a single task. The interface of std::shared_object is the same as the one for std::future. A shared_future object is created using the .share() function on the future."
  },
  {
    "objectID": "posts/exploring_futures_and_promises/index.html#creating-a-tiny-c-task-library",
    "href": "posts/exploring_futures_and_promises/index.html#creating-a-tiny-c-task-library",
    "title": "Creating a tiny C++ Task Library",
    "section": "",
    "text": "Promises and futures can be chained together to perform multiple asynchronous operations sequentially. We can have elaborate data-processing pipelines where one future’s result becoimes the input for the next operation’s promise. This allows for composing complex asynchronous workflows where the output of one task feeds into the next.\nAlso, we can allow branching in the pipeline and keep some tasks switched off until needed. This can be done using futures with deferred execution.\nGenerally speaking tasks make up a DAG(Directed acyclic graph). Thus, a task library must consist of two parts : an API to specify the task DAG and a scheduler that actually executes the DAG.\nLet’s try to create the following task graph:\n\n\n\n\ngraph LR\n  Task-1[Task-1] --&gt; Task-2[Task-2]\n  Task-2 --&gt; Task-3[Task-3]\n  Task-2 --&gt; Task-4[Task-4]\n  Task-3 --&gt; Aggregate[Aggregate results]\n  Task-4 --&gt; Aggregate\n\n\n\n\n\nWe start by defining a template class called Task that accepts a callable as a template argument, defining the function to execute. This class will also allow us to create tasks that share a future with dependent ones.\n#include &lt;vector&gt;\n#include &lt;cstdint&gt;\n#include &lt;print&gt;\n\n#define sync_cout std::osyncstream(std::cout)\n\nclass GraphWalker;\n\ntemplate&lt;typename Func&gt;\nclass Task{\n\n    public:\n    Task(int id, Func& func)\n    : m_id{ id }\n    , m_func{ func }\n    {\n        sync_cout &lt;&lt; \"\\n\"\n                  &lt;&lt; \"Task \" &lt;&lt; id &lt;&lt; \" constructed \";\n    }\n\n    Task(const Task& other)\n    : m_id{ other.m_id }\n    , m_func{ other.m_func }\n    {}\n\n    uint64_t get_id(){\n        return m_id;\n    }\n\n    private:\n    u64_t m_id;\n    Func m_func;\n    std::promise&lt;void&gt; m_promise;\n\n};\n\nstruct Node{\n    Task task;\n    std::vector&lt;Node*&gt; child_nodes;\n};"
  },
  {
    "objectID": "posts/memory_barriers/index.html",
    "href": "posts/memory_barriers/index.html",
    "title": "Memory Barriers",
    "section": "",
    "text": "Atomic operations are indivisible. An atomic operation is any operation that is guaranteed to execute as a single transaction. At a low-level, atomic operations are special hardware instructions.\n\n%load_ext itikz\n\nThe itikz extension is already loaded. To reload it, use:\n  %reload_ext itikz\n\n\nConsider a shared variable counter initialized to 0. The assembly instructions for incrementing this counter show that it requires multiple CPU instructions: load the value from memory into a register, add 1 to the register, and store the result back to memory. This multi-step process creates opportunities for race conditions in multi-threaded code.\nUsing atomic types and operations solves this problem by using special CPU instructions like lock add that guarantee the entire operation completes as a single, indivisible unit.\n// Incrementing a counter        \nint counter {0};\n\nint main(){\n    counter++;\n    return 0;\n}\n\n\n\ncounter:\n        .zero   4\nmain:\n        push    rbp\n        mov     rbp, rsp\n        mov     eax, DWORD PTR counter[rip]\n        add     eax, 1\n        mov     DWORD PTR counter[rip], eax\n        mov     eax, 0\n        pop     rbp\n        ret\n\n\n\nUsing atomic types and operations:\n#include &lt;atomic&gt;\nstd::atomic&lt;int&gt; counter {0};\n\nint main(){\n    counter++;\n    return 0;\n}\nGenerated Assembly:\nlock add DWORD PTR counter[rip], 1\nAtomic operations allow threads to read, modify and write indivisibly and can also be used as synchronization primitives. Atomic operations must be provided by the CPU (as in the lock add instruction).\n\n\n\nExplicit reads and writes:\nstd::atomic&lt;T&gt; x;\nT y = x.load();     // Same as T y = x;\nx.store(y);         // Same as x = y;\nAtomic exchange:\nT z = x.exchange(y);    // Atomically: z = x; x = y;\nexchange is an atomic swap - a read-modify-write done atomically. It reads the old value, replaces it with the new value and guarantees that nobody can get in there in between.\n\n\n\nCompare-and-swap (conditional exchange):\nbool success = x.compare_exchange_strong(y,z);  // T& y\n// var.compare_exchange_strong(expected,desired);\n// If x == y, x = z and return true\n// Otherwise, set y = x and return false\n\n\n\nCompare-and-swap (CAS) is used in most lock-free algorithms. Consider this example of atomic increment with CAS. Pretty much every lock-free algorithm is centered around a loop like this. We want to increment x. First, we read the atomic value and store it in a local x0. We hope nobody got to x before us, that x hasn’t changed. If that’s true, we change it atomically to the desired value (which could be an increment, decrement, multiplication by 2, etc.). If nobody else changed x, we did our increment atomically. CAS returns true and the loop ends.\nIf somebody did change x, CAS fails and returns false. The changed value of x is updated in x0, so we don’t have to read again. We continue to the next iteration and keep trying, until our compare-and-swap beats everyone else’s and gets that increment in.\nstd::atomic&lt;int&gt; x{0};\nint x0 = x.load();     // [1] \nwhile(!x.compare_exchange_swap(x0, x0 + 1)){}  // [2]\n\n\n\nFor integer T:\nstd::atomic&lt;int&gt; x;\nx.fetch_add(y);     // Same as x += y;\nfetch_add() doesn’t just add atomically. It increments atomically, but also returns the old value (the fetch part). So it returns the old value and adds the increment, all atomically.\nAlso available: fetch_sub, fetch_and(), fetch_or() and fetch_xor().\nNote: If you have multiple atomic operations, their composition is not atomic.\n\n\n\nAtomic operations are lock-free, maybe even wait-free. It doesn’t mean they don’t wait on each other. Atomic operations do wait for cache-line access.\n\n\n\nShow the code\n%%itikz --temp-dir --tex-packages=tikz --tikz-libraries=arrows.meta --implicit-standalone\n\n\\tikzset{every picture/.style={line width=0.75pt}} %set default line width to 0.75pt        \n\n\\begin{tikzpicture}[x=0.75pt,y=0.75pt,yscale=-1.5,xscale=1.5,font=\\Large]\n%uncomment if require: \\path (0,249); %set diagram left start at 0, and has height of 249\n\n%Rounded Rect [id:dp7226624209327404] \n\\draw  [fill={rgb, 255:red, 181; green, 212; blue, 244 }  ,fill opacity=1 ] (115,43.47) .. controls (115,33.82) and (122.82,26) .. (132.47,26) -- (505.03,26) .. controls (514.68,26) and (522.5,33.82) .. (522.5,43.47) -- (522.5,95.88) .. controls (522.5,105.52) and (514.68,113.34) .. (505.03,113.34) -- (132.47,113.34) .. controls (122.82,113.34) and (115,105.52) .. (115,95.88) -- cycle ;\n%Rounded Rect [id:dp404929071772297] \n\\draw  [fill={rgb, 255:red, 181; green, 212; blue, 244 }  ,fill opacity=1 ] (113,158.47) .. controls (113,148.82) and (120.82,141) .. (130.47,141) -- (503.03,141) .. controls (512.68,141) and (520.5,148.82) .. (520.5,158.47) -- (520.5,210.88) .. controls (520.5,220.52) and (512.68,228.34) .. (503.03,228.34) -- (130.47,228.34) .. controls (120.82,228.34) and (113,220.52) .. (113,210.88) -- cycle ;\n%Rounded Rect [id:dp8165659276958122] \n\\draw  [fill={rgb, 255:red, 251; green, 247; blue, 204 }  ,fill opacity=1 ] (151,62) .. controls (151,57.58) and (154.58,54) .. (159,54) -- (300.5,54) .. controls (304.92,54) and (308.5,57.58) .. (308.5,62) -- (308.5,86) .. controls (308.5,90.42) and (304.92,94) .. (300.5,94) -- (159,94) .. controls (154.58,94) and (151,90.42) .. (151,86) -- cycle ;\n%Rounded Rect [id:dp5545605907049965] \n\\draw  [fill={rgb, 255:red, 251; green, 247; blue, 204 }  ,fill opacity=1 ] (325,61) .. controls (325,56.58) and (328.58,53) .. (333,53) -- (474.5,53) .. controls (478.92,53) and (482.5,56.58) .. (482.5,61) -- (482.5,85) .. controls (482.5,89.42) and (478.92,93) .. (474.5,93) -- (333,93) .. controls (328.58,93) and (325,89.42) .. (325,85) -- cycle ;\n%Rounded Rect [id:dp9918614693760329] \n\\draw  [fill={rgb, 255:red, 251; green, 247; blue, 204 }  ,fill opacity=1 ] (144,176) .. controls (144,171.58) and (147.58,168) .. (152,168) -- (293.5,168) .. controls (297.92,168) and (301.5,171.58) .. (301.5,176) -- (301.5,200) .. controls (301.5,204.42) and (297.92,208) .. (293.5,208) -- (152,208) .. controls (147.58,208) and (144,204.42) .. (144,200) -- cycle ;\n%Rounded Rect [id:dp9032232500910276] \n\\draw  [fill={rgb, 255:red, 251; green, 247; blue, 204 }  ,fill opacity=1 ] (332,176) .. controls (332,171.58) and (335.58,168) .. (340,168) -- (481.5,168) .. controls (485.92,168) and (489.5,171.58) .. (489.5,176) -- (489.5,200) .. controls (489.5,204.42) and (485.92,208) .. (481.5,208) -- (340,208) .. controls (335.58,208) and (332,204.42) .. (332,200) -- cycle ;\n\n% Text Node\n\\draw (263,31) node [anchor=north west][inner sep=0.75pt]   [align=left] {\\texttt{std::atomic&lt;int&gt; x;}};\n% Text Node\n\\draw (257,146) node [anchor=north west][inner sep=0.75pt]   [align=left] {\\texttt{std::atomic&lt;int&gt; x[2];}};\n% Text Node\n\\draw (231.33,63.33) node {Thread-1};\n% Text Node\n\\draw (410,64) node {Thread-2};\n% Text Node\n\\draw (221.33,180) node {Thread-1};\n% Text Node\n\\draw (414,180) node {Thread-2};\n% Text Node\n\\draw (231.71,82) node {++x;};\n% Text Node\n\\draw (410.38,80.67) node {++x;};\n% Text Node\n\\draw (228.08,198) node {++x[0];};\n% Text Node\n\\draw (419.58,196.67) node {++x[1];};\n% Text Node\n\\draw (214.67,13.33) node {Accessing shared variable};\n% Text Node\n\\draw (212.67,127.33) node {Accessing Non-shared variable};\n\n\n\\end{tikzpicture}\n\n\n\n\n\nFig. Functions - control flow\n\nLet’s compare atomic increment of an atomic variable versus increment two atomic variables that are different. That is, the worker thread \\(t0\\) works on an atomic variable x[0] and the worker thread \\(t1\\) works on the atomic variable x[1]. That way, they don’t have to wait on each other. Let’s run a benchmark for different number of threads. Let’s run the benchmark for different number of threads. It’s basically the same thing - we see no difference between the two. Can we conclude that atomic operations don’t wait on each other from this?\n\n\n\n\nTwo threads incrementing a shared variable atomically vs two threads work on different atomic variables\n\n\n\nBenchmark                                        Time         CPU\n------------------------------------------------------------------------\nBM_SharedAtomicIncrement/1/real_time         0.558 ms    0.015 ms\nBM_SharedAtomicIncrement/2/real_time          2.56 ms    0.044 ms\nBM_SharedAtomicIncrement/4/real_time          5.40 ms    0.096 ms\nBM_SharedAtomicIncrement/8/real_time          10.6 ms    0.218 ms\nBM_SharedAtomicIncrement/16/real_time         22.9 ms    0.401 ms\nBM_SharedAtomicIncrement/32/real_time         48.4 ms     1.14 ms\nBM_SeparateAtomicIncrement/1/real_time       0.556 ms    0.016 ms\nBM_SeparateAtomicIncrement/2/real_time        2.74 ms    0.033 ms\nBM_SeparateAtomicIncrement/4/real_time        5.74 ms    0.081 ms\nBM_SeparateAtomicIncrement/8/real_time        11.2 ms    0.244 ms\nBM_SeparateAtomicIncrement/16/real_time       23.9 ms    0.403 ms\nBM_SeparateAtomicIncrement/32/real_time       26.6 ms     1.23 ms\n\n\nCan we conclude that atomic operations don’t wait on each other? Not necessarily!\nIt is highly likely, that data elements in relatively close memory locations are accessed over a short period of time. This is typical, for example, when traversing an array, or performing matrix multiplication. To optimize performance, a chunk of data called the cache line trickles up and down through the cache from the main memory to the CPU and back, instead of just the request data-item. On x86, the cache line size is \\(64\\)-bytes.\nWhat’s actually happening is that the two atomic operations are in the same cache-line. On x86, the whole cache line trickles up and down from main memory to the on-board CPU cache and back. Even if you want one variable from the cache line, the entire 64-byte chunk will go up and down. If two different CPUs want two different variables within the same cache-line, they need to wait, as if it was the same variable. You don’t get lower granularity than 64-bytes on x86.\n\n\n\nShow the code\n%%itikz --temp-dir --tex-packages=tikz --tikz-libraries=arrows.meta --implicit-standalone\n\\tikzset{every picture/.style={line width=0.75pt}} %set default line width to 0.75pt        \n\n\\begin{tikzpicture}[x=0.75pt,y=0.75pt,yscale=-2.1,xscale=2.1,font=\\Large]\n%uncomment if require: \\path (0,379); %set diagram left start at 0, and has height of 379\n\n%Rounded Rect [id:dp27460933128570264] \n\\draw  [fill={rgb, 255:red, 181; green, 212; blue, 244 }  ,fill opacity=1 ] (38.5,45.45) .. controls (38.5,39.13) and (43.63,34) .. (49.95,34) -- (296.05,34) .. controls (302.37,34) and (307.5,39.13) .. (307.5,45.45) -- (307.5,79.8) .. controls (307.5,86.12) and (302.37,91.25) .. (296.05,91.25) -- (49.95,91.25) .. controls (43.63,91.25) and (38.5,86.12) .. (38.5,79.8) -- cycle ;\n%Rounded Rect [id:dp6820620708533545] \n\\draw  [fill={rgb, 255:red, 181; green, 212; blue, 244 }  ,fill opacity=1 ] (335,127.87) .. controls (335,124.63) and (337.63,122) .. (340.87,122) -- (586.63,122) .. controls (589.87,122) and (592.5,124.63) .. (592.5,127.87) -- (592.5,145.48) .. controls (592.5,148.72) and (589.87,151.34) .. (586.63,151.34) -- (340.87,151.34) .. controls (337.63,151.34) and (335,148.72) .. (335,145.48) -- cycle ;\n%Rounded Rect [id:dp9973874025957986] \n\\draw  [fill={rgb, 255:red, 181; green, 212; blue, 244 }  ,fill opacity=1 ] (44,127.87) .. controls (44,124.63) and (46.63,122) .. (49.87,122) -- (295.63,122) .. controls (298.87,122) and (301.5,124.63) .. (301.5,127.87) -- (301.5,145.48) .. controls (301.5,148.72) and (298.87,151.34) .. (295.63,151.34) -- (49.87,151.34) .. controls (46.63,151.34) and (44,148.72) .. (44,145.48) -- cycle ;\n%Rounded Rect [id:dp9732688461749553] \n\\draw  [fill={rgb, 255:red, 252; green, 246; blue, 153 }  ,fill opacity=1 ] (46.33,309.12) .. controls (46.33,303.9) and (50.56,299.67) .. (55.78,299.67) -- (586.38,299.67) .. controls (591.6,299.67) and (595.83,303.9) .. (595.83,309.12) -- (595.83,337.47) .. controls (595.83,342.69) and (591.6,346.92) .. (586.38,346.92) -- (55.78,346.92) .. controls (50.56,346.92) and (46.33,342.69) .. (46.33,337.47) -- cycle ;\n%Straight Lines [id:da9504358299662848] \n\\draw    (276.08,339.92) -- (383.58,339.92) ;\n\\draw [shift={(386.58,339.92)}, rotate = 180] [fill={rgb, 255:red, 0; green, 0; blue, 0 }  ][line width=0.08]  [draw opacity=0] (8.93,-4.29) -- (0,0) -- (8.93,4.29) -- cycle    ;\n\\draw [shift={(273.08,339.92)}, rotate = 0] [fill={rgb, 255:red, 0; green, 0; blue, 0 }  ][line width=0.08]  [draw opacity=0] (8.93,-4.29) -- (0,0) -- (8.93,4.29) -- cycle    ;\n%Rounded Rect [id:dp1128018396464796] \n\\draw  [fill={rgb, 255:red, 181; green, 212; blue, 244 }  ,fill opacity=1 ] (329.5,45.45) .. controls (329.5,39.13) and (334.63,34) .. (340.95,34) -- (587.05,34) .. controls (593.37,34) and (598.5,39.13) .. (598.5,45.45) -- (598.5,79.8) .. controls (598.5,86.12) and (593.37,91.25) .. (587.05,91.25) -- (340.95,91.25) .. controls (334.63,91.25) and (329.5,86.12) .. (329.5,79.8) -- cycle ;\n%Straight Lines [id:da8059041144370804] \n\\draw [color={rgb, 255:red, 74; green, 83; blue, 226 }  ,draw opacity=1 ]   (378.92,154.25) -- (378.92,182.25) ;\n\\draw [shift={(378.92,151.25)}, rotate = 90] [fill={rgb, 255:red, 74; green, 83; blue, 226 }  ,fill opacity=1 ][line width=0.08]  [draw opacity=0] (8.93,-4.29) -- (0,0) -- (8.93,4.29) -- cycle    ;\n%Rounded Rect [id:dp591399533303866] \n\\draw  [fill={rgb, 255:red, 181; green, 212; blue, 244 }  ,fill opacity=1 ] (335.67,189.2) .. controls (335.67,185.96) and (338.29,183.33) .. (341.54,183.33) -- (587.3,183.33) .. controls (590.54,183.33) and (593.17,185.96) .. (593.17,189.2) -- (593.17,206.81) .. controls (593.17,210.05) and (590.54,212.68) .. (587.3,212.68) -- (341.54,212.68) .. controls (338.29,212.68) and (335.67,210.05) .. (335.67,206.81) -- cycle ;\n%Rounded Rect [id:dp5591689579874568] \n\\draw  [fill={rgb, 255:red, 181; green, 212; blue, 244 }  ,fill opacity=1 ] (44.67,189.2) .. controls (44.67,185.96) and (47.29,183.33) .. (50.54,183.33) -- (296.3,183.33) .. controls (299.54,183.33) and (302.17,185.96) .. (302.17,189.2) -- (302.17,206.81) .. controls (302.17,210.05) and (299.54,212.68) .. (296.3,212.68) -- (50.54,212.68) .. controls (47.29,212.68) and (44.67,210.05) .. (44.67,206.81) -- cycle ;\n%Rounded Rect [id:dp4165838369572783] \n\\draw  [fill={rgb, 255:red, 181; green, 212; blue, 244 }  ,fill opacity=1 ] (44.67,245.87) .. controls (44.67,242.63) and (47.29,240) .. (50.54,240) -- (586.46,240) .. controls (589.71,240) and (592.33,242.63) .. (592.33,245.87) -- (592.33,263.48) .. controls (592.33,266.72) and (589.71,269.34) .. (586.46,269.34) -- (50.54,269.34) .. controls (47.29,269.34) and (44.67,266.72) .. (44.67,263.48) -- cycle ;\n%Straight Lines [id:da7083107764900278] \n\\draw [color={rgb, 255:red, 74; green, 83; blue, 226 }  ,draw opacity=1 ]   (92.99,215.67) -- (92.92,240.92) ;\n\\draw [shift={(93,212.67)}, rotate = 90.17] [fill={rgb, 255:red, 74; green, 83; blue, 226 }  ,fill opacity=1 ][line width=0.08]  [draw opacity=0] (8.93,-4.29) -- (0,0) -- (8.93,4.29) -- cycle    ;\n%Straight Lines [id:da028317245941649194] \n\\draw [color={rgb, 255:red, 74; green, 83; blue, 226 }  ,draw opacity=1 ]   (93.66,153.67) -- (93.58,182.25) ;\n\\draw [shift={(93.67,150.67)}, rotate = 90.15] [fill={rgb, 255:red, 74; green, 83; blue, 226 }  ,fill opacity=1 ][line width=0.08]  [draw opacity=0] (8.93,-4.29) -- (0,0) -- (8.93,4.29) -- cycle    ;\n%Straight Lines [id:da8360791510647615] \n\\draw [color={rgb, 255:red, 74; green, 83; blue, 226 }  ,draw opacity=1 ]   (92.33,93.67) -- (92.25,122.25) ;\n\\draw [shift={(92.33,90.67)}, rotate = 90.15] [fill={rgb, 255:red, 74; green, 83; blue, 226 }  ,fill opacity=1 ][line width=0.08]  [draw opacity=0] (8.93,-4.29) -- (0,0) -- (8.93,4.29) -- cycle    ;\n%Straight Lines [id:da620625708639835] \n\\draw [color={rgb, 255:red, 74; green, 83; blue, 226 }  ,draw opacity=1 ]   (378.25,213.58) -- (378.25,241.58) ;\n\\draw [shift={(378.25,210.58)}, rotate = 90] [fill={rgb, 255:red, 74; green, 83; blue, 226 }  ,fill opacity=1 ][line width=0.08]  [draw opacity=0] (8.93,-4.29) -- (0,0) -- (8.93,4.29) -- cycle    ;\n%Straight Lines [id:da911476849461266] \n\\draw [color={rgb, 255:red, 74; green, 83; blue, 226 }  ,draw opacity=1 ]   (305.58,270.92) -- (305.58,298.92) ;\n\\draw [shift={(305.58,267.92)}, rotate = 90] [fill={rgb, 255:red, 74; green, 83; blue, 226 }  ,fill opacity=1 ][line width=0.08]  [draw opacity=0] (8.93,-4.29) -- (0,0) -- (8.93,4.29) -- cycle    ;\n%Straight Lines [id:da6168210047920039] \n\\draw [color={rgb, 255:red, 74; green, 83; blue, 226 }  ,draw opacity=1 ]   (377.58,94.25) -- (377.58,122.25) ;\n\\draw [shift={(377.58,91.25)}, rotate = 90] [fill={rgb, 255:red, 74; green, 83; blue, 226 }  ,fill opacity=1 ][line width=0.08]  [draw opacity=0] (8.93,-4.29) -- (0,0) -- (8.93,4.29) -- cycle    ;\n%Straight Lines [id:da45709411556658486] \n\\draw [color={rgb, 255:red, 144; green, 19; blue, 254 }  ,draw opacity=1 ]   (243.58,91.25) -- (243.58,119.25) ;\n\\draw [shift={(243.58,122.25)}, rotate = 270] [fill={rgb, 255:red, 144; green, 19; blue, 254 }  ,fill opacity=1 ][line width=0.08]  [draw opacity=0] (8.93,-4.29) -- (0,0) -- (8.93,4.29) -- cycle    ;\n%Straight Lines [id:da1624871748247504] \n\\draw [color={rgb, 255:red, 144; green, 19; blue, 254 }  ,draw opacity=1 ]   (244.25,152.58) -- (244.25,180.58) ;\n\\draw [shift={(244.25,183.58)}, rotate = 270] [fill={rgb, 255:red, 144; green, 19; blue, 254 }  ,fill opacity=1 ][line width=0.08]  [draw opacity=0] (8.93,-4.29) -- (0,0) -- (8.93,4.29) -- cycle    ;\n%Straight Lines [id:da951312301312835] \n\\draw [color={rgb, 255:red, 144; green, 19; blue, 254 }  ,draw opacity=1 ]   (245.67,211.33) -- (244.99,237.25) ;\n\\draw [shift={(244.92,240.25)}, rotate = 271.49] [fill={rgb, 255:red, 144; green, 19; blue, 254 }  ,fill opacity=1 ][line width=0.08]  [draw opacity=0] (8.93,-4.29) -- (0,0) -- (8.93,4.29) -- cycle    ;\n%Straight Lines [id:da5598487398669117] \n\\draw [color={rgb, 255:red, 144; green, 19; blue, 254 }  ,draw opacity=1 ]   (351,270.67) -- (350.93,295.92) ;\n\\draw [shift={(350.92,298.92)}, rotate = 270.17] [fill={rgb, 255:red, 144; green, 19; blue, 254 }  ,fill opacity=1 ][line width=0.08]  [draw opacity=0] (8.93,-4.29) -- (0,0) -- (8.93,4.29) -- cycle    ;\n%Straight Lines [id:da18143538236339274] \n\\draw [color={rgb, 255:red, 144; green, 19; blue, 254 }  ,draw opacity=1 ]   (547.58,91.25) -- (547.58,119.25) ;\n\\draw [shift={(547.58,122.25)}, rotate = 270] [fill={rgb, 255:red, 144; green, 19; blue, 254 }  ,fill opacity=1 ][line width=0.08]  [draw opacity=0] (8.93,-4.29) -- (0,0) -- (8.93,4.29) -- cycle    ;\n%Straight Lines [id:da11843933303452991] \n\\draw [color={rgb, 255:red, 144; green, 19; blue, 254 }  ,draw opacity=1 ]   (547.58,151.25) -- (547.58,179.25) ;\n\\draw [shift={(547.58,182.25)}, rotate = 270] [fill={rgb, 255:red, 144; green, 19; blue, 254 }  ,fill opacity=1 ][line width=0.08]  [draw opacity=0] (8.93,-4.29) -- (0,0) -- (8.93,4.29) -- cycle    ;\n%Straight Lines [id:da21016027697626216] \n\\draw [color={rgb, 255:red, 144; green, 19; blue, 254 }  ,draw opacity=1 ]   (546.92,211.25) -- (546.92,239.25) ;\n\\draw [shift={(546.92,242.25)}, rotate = 270] [fill={rgb, 255:red, 144; green, 19; blue, 254 }  ,fill opacity=1 ][line width=0.08]  [draw opacity=0] (8.93,-4.29) -- (0,0) -- (8.93,4.29) -- cycle    ;\n\n% Text Node\n\\draw (52,42) node [anchor=north west][inner sep=0.75pt]  [xscale=2,yscale=2] [align=left] {\\textit{CPU Core-1}};\n% Text Node\n\\draw (342,40) node [anchor=north west][inner sep=0.75pt]  [xscale=2,yscale=2] [align=left] {\\textit{CPU Core-2}};\n% Text Node\n\\draw  [color={rgb, 255:red, 184; green, 233; blue, 134 }  ,draw opacity=1 ][fill={rgb, 255:red, 233; green, 229; blue, 229 }  ,fill opacity=1 ][line width=2.25]   (58.13,124.25) -- (169.13,124.25) -- (169.13,149.25) -- (58.13,149.25) -- cycle  ;\n\\draw (113.63,136.75) node  [xscale=2,yscale=2] [align=left] {\\begin{minipage}[lt]{72.93pt}\\setlength\\topsep{0pt}\nx[0],x[1],...\n\\end{minipage}};\n% Text Node\n\\draw (210,128) node [anchor=north west][inner sep=0.75pt]  [xscale=2,yscale=2] [align=left] {\\textit{L1 Cache}};\n% Text Node\n\\draw (500,127.5) node [anchor=north west][inner sep=0.75pt]  [xscale=2,yscale=2] [align=left] {\\textit{L1 Cache}};\n% Text Node\n\\draw (470.33,302.67) node [anchor=north west][inner sep=0.75pt]  [xscale=2,yscale=2] [align=left] {\\textit{Main Memory}};\n% Text Node\n\\draw (298.33,344.17) node [anchor=north west][inner sep=0.75pt]  [xscale=2,yscale=2] [align=left] {\\textit{64-bytes}};\n% Text Node\n\\draw (170.83,312.17) node [anchor=north west][inner sep=0.75pt]  [xscale=2,yscale=2] [align=left] {\\textit{Cache line}};\n% Text Node\n\\draw (179.83,68.63) node  [xscale=2,yscale=2] [align=left] {\\begin{minipage}[lt]{48.73pt}\\setlength\\topsep{0pt}\n++x[0];\n\\end{minipage}};\n% Text Node\n\\draw (467.67,68.13) node  [xscale=2,yscale=2] [align=left] {\\begin{minipage}[lt]{41.71pt}\\setlength\\topsep{0pt}\n++x[1];\n\\end{minipage}};\n% Text Node\n\\draw  [color={rgb, 255:red, 184; green, 233; blue, 134 }  ,draw opacity=1 ][fill={rgb, 255:red, 233; green, 229; blue, 229 }  ,fill opacity=1 ][line width=2.25]   (349.63,123.75) -- (460.63,123.75) -- (460.63,148.75) -- (349.63,148.75) -- cycle  ;\n\\draw (405.13,136.25) node  [xscale=2,yscale=2] [align=left] {\\begin{minipage}[lt]{72.93pt}\\setlength\\topsep{0pt}\nx[0],x[1],...\n\\end{minipage}};\n% Text Node\n\\draw  [color={rgb, 255:red, 184; green, 233; blue, 134 }  ,draw opacity=1 ][fill={rgb, 255:red, 233; green, 229; blue, 229 }  ,fill opacity=1 ][line width=2.25]   (278.63,305.92) -- (389.63,305.92) -- (389.63,330.92) -- (278.63,330.92) -- cycle  ;\n\\draw (334.13,318.42) node  [xscale=2,yscale=2] [align=left] {\\begin{minipage}[lt]{72.93pt}\\setlength\\topsep{0pt}\nx[0],x[1],...\n\\end{minipage}};\n% Text Node\n\\draw  [color={rgb, 255:red, 184; green, 233; blue, 134 }  ,draw opacity=1 ][fill={rgb, 255:red, 233; green, 229; blue, 229 }  ,fill opacity=1 ][line width=2.25]   (58.79,185.58) -- (169.79,185.58) -- (169.79,210.58) -- (58.79,210.58) -- cycle  ;\n\\draw (114.29,198.08) node  [xscale=2,yscale=2] [align=left] {\\begin{minipage}[lt]{72.93pt}\\setlength\\topsep{0pt}\nx[0],x[1],...\n\\end{minipage}};\n% Text Node\n\\draw (210.67,189.33) node [anchor=north west][inner sep=0.75pt]  [xscale=2,yscale=2] [align=left] {\\textit{L2 Cache}};\n% Text Node\n\\draw (500.83,189.5) node [anchor=north west][inner sep=0.75pt]  [xscale=2,yscale=2] [align=left] {\\textit{L2 Cache}};\n% Text Node\n\\draw  [color={rgb, 255:red, 184; green, 233; blue, 134 }  ,draw opacity=1 ][fill={rgb, 255:red, 233; green, 229; blue, 229 }  ,fill opacity=1 ][line width=2.25]   (350.29,185.08) -- (461.29,185.08) -- (461.29,210.08) -- (350.29,210.08) -- cycle  ;\n\\draw (405.79,197.58) node  [xscale=2,yscale=2] [align=left] {\\begin{minipage}[lt]{72.93pt}\\setlength\\topsep{0pt}\nx[0],x[1],...\n\\end{minipage}};\n% Text Node\n\\draw  [color={rgb, 255:red, 184; green, 233; blue, 134 }  ,draw opacity=1 ][fill={rgb, 255:red, 233; green, 229; blue, 229 }  ,fill opacity=1 ][line width=2.25]   (276.13,241.58) -- (387.13,241.58) -- (387.13,266.58) -- (276.13,266.58) -- cycle  ;\n\\draw (331.63,254.08) node  [xscale=2,yscale=2] [align=left] {\\begin{minipage}[lt]{72.93pt}\\setlength\\topsep{0pt}\nx[0],x[1],...\n\\end{minipage}};\n% Text Node\n\\draw (500.33,246.67) node [anchor=north west][inner sep=0.75pt]  [xscale=2,yscale=2] [align=left] {\\textit{L3 Cache}};\n\n\n\\end{tikzpicture}\n\n\n\n\n\n\nAtomic operations do wait on each other! In particular, write-operations do. Read operations scale near-perfectly.\nIf I put the variables on separate cache-lines, then there is no problem and the CPUs don’t have to wait on anything. We can prove it with a benchmark.\nBenchmark                            Time         CPU\n------------------------------------------------------------------------\nBM_Shared/1/real_time            0.561 ms    0.015 ms\nBM_Shared/2/real_time             3.25 ms    0.054 ms\nBM_Shared/4/real_time             6.07 ms    0.061 ms\nBM_Shared/8/real_time             10.6 ms    0.240 ms\nBM_Shared/16/real_time            22.9 ms    0.384 ms\nBM_Shared/32/real_time            51.4 ms    0.944 ms\nBM_Shared/64/real_time             103 ms     2.67 ms\nBM_FalseShared/1/real_time       0.578 ms    0.016 ms\nBM_FalseShared/2/real_time        2.98 ms    0.037 ms\nBM_FalseShared/4/real_time        6.18 ms    0.065 ms\nBM_FalseShared/8/real_time        10.6 ms    0.234 ms\nBM_FalseShared/16/real_time       13.5 ms    0.386 ms\nBM_FalseShared/32/real_time       26.7 ms     1.21 ms\nBM_FalseShared/64/real_time       37.0 ms     2.36 ms\nBM_NonShared/1/real_time         0.576 ms    0.015 ms\nBM_NonShared/2/real_time         0.591 ms    0.028 ms\nBM_NonShared/4/real_time         0.632 ms    0.051 ms\nBM_NonShared/8/real_time         0.598 ms    0.102 ms\nBM_NonShared/16/real_time         1.05 ms    0.225 ms\nBM_NonShared/32/real_time         1.81 ms    0.701 ms\nBM_NonShared/64/real_time         3.21 ms     1.28 ms\nAtomic operations have to wait for cache line access. This is the price of data sharing without race conditions. Modifying different locations on the same cache line still incurs a run-time penalty, a phenomenon known as false sharing. To avoid false sharing, we should align per-thread data to separate cache lines. Atomic operations do wait on each other, particularly write operations. However, read-only operations can scale near-perfectly when properly designed.\n\n\n\n\nC++ provides two versions of CAS - weak and strong.\n// Strong CAS\nx.compare_exchange_strong(old_x, new_x);\n/* \nif (x == old_x)\n{\n    x = new_x;\n    return true;\n}else{\n    old_x = x;\n    return false;\n}\n*/\nx.compare_exchange_weak(old_x, new_x) is essentially the same thing, but can spuriously fail and return false, even if x == old_x."
  },
  {
    "objectID": "posts/memory_barriers/index.html#introduction-to-atomic-operations",
    "href": "posts/memory_barriers/index.html#introduction-to-atomic-operations",
    "title": "Memory Barriers",
    "section": "",
    "text": "Atomic operations are indivisible. An atomic operation is any operation that is guaranteed to execute as a single transaction. At a low-level, atomic operations are special hardware instructions.\n\n%load_ext itikz\n\nThe itikz extension is already loaded. To reload it, use:\n  %reload_ext itikz\n\n\nConsider a shared variable counter initialized to 0. The assembly instructions for incrementing this counter show that it requires multiple CPU instructions: load the value from memory into a register, add 1 to the register, and store the result back to memory. This multi-step process creates opportunities for race conditions in multi-threaded code.\nUsing atomic types and operations solves this problem by using special CPU instructions like lock add that guarantee the entire operation completes as a single, indivisible unit.\n// Incrementing a counter        \nint counter {0};\n\nint main(){\n    counter++;\n    return 0;\n}"
  },
  {
    "objectID": "posts/memory_barriers/index.html#generated-assembly---non-atomic",
    "href": "posts/memory_barriers/index.html#generated-assembly---non-atomic",
    "title": "Memory Barriers",
    "section": "",
    "text": "counter:\n        .zero   4\nmain:\n        push    rbp\n        mov     rbp, rsp\n        mov     eax, DWORD PTR counter[rip]\n        add     eax, 1\n        mov     DWORD PTR counter[rip], eax\n        mov     eax, 0\n        pop     rbp\n        ret"
  },
  {
    "objectID": "posts/memory_barriers/index.html#atomic-increment",
    "href": "posts/memory_barriers/index.html#atomic-increment",
    "title": "Memory Barriers",
    "section": "",
    "text": "Using atomic types and operations:\n#include &lt;atomic&gt;\nstd::atomic&lt;int&gt; counter {0};\n\nint main(){\n    counter++;\n    return 0;\n}\nGenerated Assembly:\nlock add DWORD PTR counter[rip], 1\nAtomic operations allow threads to read, modify and write indivisibly and can also be used as synchronization primitives. Atomic operations must be provided by the CPU (as in the lock add instruction)."
  },
  {
    "objectID": "posts/memory_barriers/index.html#operations-on-stdatomict",
    "href": "posts/memory_barriers/index.html#operations-on-stdatomict",
    "title": "Memory Barriers",
    "section": "",
    "text": "Explicit reads and writes:\nstd::atomic&lt;T&gt; x;\nT y = x.load();     // Same as T y = x;\nx.store(y);         // Same as x = y;\nAtomic exchange:\nT z = x.exchange(y);    // Atomically: z = x; x = y;\nexchange is an atomic swap - a read-modify-write done atomically. It reads the old value, replaces it with the new value and guarantees that nobody can get in there in between."
  },
  {
    "objectID": "posts/memory_barriers/index.html#compare-and-swap-cas",
    "href": "posts/memory_barriers/index.html#compare-and-swap-cas",
    "title": "Memory Barriers",
    "section": "",
    "text": "Compare-and-swap (conditional exchange):\nbool success = x.compare_exchange_strong(y,z);  // T& y\n// var.compare_exchange_strong(expected,desired);\n// If x == y, x = z and return true\n// Otherwise, set y = x and return false"
  },
  {
    "objectID": "posts/memory_barriers/index.html#why-is-cas-so-special",
    "href": "posts/memory_barriers/index.html#why-is-cas-so-special",
    "title": "Memory Barriers",
    "section": "",
    "text": "Compare-and-swap (CAS) is used in most lock-free algorithms. Consider this example of atomic increment with CAS. Pretty much every lock-free algorithm is centered around a loop like this. We want to increment x. First, we read the atomic value and store it in a local x0. We hope nobody got to x before us, that x hasn’t changed. If that’s true, we change it atomically to the desired value (which could be an increment, decrement, multiplication by 2, etc.). If nobody else changed x, we did our increment atomically. CAS returns true and the loop ends.\nIf somebody did change x, CAS fails and returns false. The changed value of x is updated in x0, so we don’t have to read again. We continue to the next iteration and keep trying, until our compare-and-swap beats everyone else’s and gets that increment in.\nstd::atomic&lt;int&gt; x{0};\nint x0 = x.load();     // [1] \nwhile(!x.compare_exchange_swap(x0, x0 + 1)){}  // [2]"
  },
  {
    "objectID": "posts/memory_barriers/index.html#additional-atomic-operations",
    "href": "posts/memory_barriers/index.html#additional-atomic-operations",
    "title": "Memory Barriers",
    "section": "",
    "text": "For integer T:\nstd::atomic&lt;int&gt; x;\nx.fetch_add(y);     // Same as x += y;\nfetch_add() doesn’t just add atomically. It increments atomically, but also returns the old value (the fetch part). So it returns the old value and adds the increment, all atomically.\nAlso available: fetch_sub, fetch_and(), fetch_or() and fetch_xor().\nNote: If you have multiple atomic operations, their composition is not atomic."
  },
  {
    "objectID": "posts/memory_barriers/index.html#do-atomic-operations-wait-on-each-other",
    "href": "posts/memory_barriers/index.html#do-atomic-operations-wait-on-each-other",
    "title": "Memory Barriers",
    "section": "",
    "text": "Atomic operations are lock-free, maybe even wait-free. It doesn’t mean they don’t wait on each other. Atomic operations do wait for cache-line access.\n\n\n\nShow the code\n%%itikz --temp-dir --tex-packages=tikz --tikz-libraries=arrows.meta --implicit-standalone\n\n\\tikzset{every picture/.style={line width=0.75pt}} %set default line width to 0.75pt        \n\n\\begin{tikzpicture}[x=0.75pt,y=0.75pt,yscale=-1.5,xscale=1.5,font=\\Large]\n%uncomment if require: \\path (0,249); %set diagram left start at 0, and has height of 249\n\n%Rounded Rect [id:dp7226624209327404] \n\\draw  [fill={rgb, 255:red, 181; green, 212; blue, 244 }  ,fill opacity=1 ] (115,43.47) .. controls (115,33.82) and (122.82,26) .. (132.47,26) -- (505.03,26) .. controls (514.68,26) and (522.5,33.82) .. (522.5,43.47) -- (522.5,95.88) .. controls (522.5,105.52) and (514.68,113.34) .. (505.03,113.34) -- (132.47,113.34) .. controls (122.82,113.34) and (115,105.52) .. (115,95.88) -- cycle ;\n%Rounded Rect [id:dp404929071772297] \n\\draw  [fill={rgb, 255:red, 181; green, 212; blue, 244 }  ,fill opacity=1 ] (113,158.47) .. controls (113,148.82) and (120.82,141) .. (130.47,141) -- (503.03,141) .. controls (512.68,141) and (520.5,148.82) .. (520.5,158.47) -- (520.5,210.88) .. controls (520.5,220.52) and (512.68,228.34) .. (503.03,228.34) -- (130.47,228.34) .. controls (120.82,228.34) and (113,220.52) .. (113,210.88) -- cycle ;\n%Rounded Rect [id:dp8165659276958122] \n\\draw  [fill={rgb, 255:red, 251; green, 247; blue, 204 }  ,fill opacity=1 ] (151,62) .. controls (151,57.58) and (154.58,54) .. (159,54) -- (300.5,54) .. controls (304.92,54) and (308.5,57.58) .. (308.5,62) -- (308.5,86) .. controls (308.5,90.42) and (304.92,94) .. (300.5,94) -- (159,94) .. controls (154.58,94) and (151,90.42) .. (151,86) -- cycle ;\n%Rounded Rect [id:dp5545605907049965] \n\\draw  [fill={rgb, 255:red, 251; green, 247; blue, 204 }  ,fill opacity=1 ] (325,61) .. controls (325,56.58) and (328.58,53) .. (333,53) -- (474.5,53) .. controls (478.92,53) and (482.5,56.58) .. (482.5,61) -- (482.5,85) .. controls (482.5,89.42) and (478.92,93) .. (474.5,93) -- (333,93) .. controls (328.58,93) and (325,89.42) .. (325,85) -- cycle ;\n%Rounded Rect [id:dp9918614693760329] \n\\draw  [fill={rgb, 255:red, 251; green, 247; blue, 204 }  ,fill opacity=1 ] (144,176) .. controls (144,171.58) and (147.58,168) .. (152,168) -- (293.5,168) .. controls (297.92,168) and (301.5,171.58) .. (301.5,176) -- (301.5,200) .. controls (301.5,204.42) and (297.92,208) .. (293.5,208) -- (152,208) .. controls (147.58,208) and (144,204.42) .. (144,200) -- cycle ;\n%Rounded Rect [id:dp9032232500910276] \n\\draw  [fill={rgb, 255:red, 251; green, 247; blue, 204 }  ,fill opacity=1 ] (332,176) .. controls (332,171.58) and (335.58,168) .. (340,168) -- (481.5,168) .. controls (485.92,168) and (489.5,171.58) .. (489.5,176) -- (489.5,200) .. controls (489.5,204.42) and (485.92,208) .. (481.5,208) -- (340,208) .. controls (335.58,208) and (332,204.42) .. (332,200) -- cycle ;\n\n% Text Node\n\\draw (263,31) node [anchor=north west][inner sep=0.75pt]   [align=left] {\\texttt{std::atomic&lt;int&gt; x;}};\n% Text Node\n\\draw (257,146) node [anchor=north west][inner sep=0.75pt]   [align=left] {\\texttt{std::atomic&lt;int&gt; x[2];}};\n% Text Node\n\\draw (231.33,63.33) node {Thread-1};\n% Text Node\n\\draw (410,64) node {Thread-2};\n% Text Node\n\\draw (221.33,180) node {Thread-1};\n% Text Node\n\\draw (414,180) node {Thread-2};\n% Text Node\n\\draw (231.71,82) node {++x;};\n% Text Node\n\\draw (410.38,80.67) node {++x;};\n% Text Node\n\\draw (228.08,198) node {++x[0];};\n% Text Node\n\\draw (419.58,196.67) node {++x[1];};\n% Text Node\n\\draw (214.67,13.33) node {Accessing shared variable};\n% Text Node\n\\draw (212.67,127.33) node {Accessing Non-shared variable};\n\n\n\\end{tikzpicture}\n\n\n\n\n\nFig. Functions - control flow\n\nLet’s compare atomic increment of an atomic variable versus increment two atomic variables that are different. That is, the worker thread \\(t0\\) works on an atomic variable x[0] and the worker thread \\(t1\\) works on the atomic variable x[1]. That way, they don’t have to wait on each other. Let’s run a benchmark for different number of threads. Let’s run the benchmark for different number of threads. It’s basically the same thing - we see no difference between the two. Can we conclude that atomic operations don’t wait on each other from this?\n\n\n\n\nTwo threads incrementing a shared variable atomically vs two threads work on different atomic variables\n\n\n\nBenchmark                                        Time         CPU\n------------------------------------------------------------------------\nBM_SharedAtomicIncrement/1/real_time         0.558 ms    0.015 ms\nBM_SharedAtomicIncrement/2/real_time          2.56 ms    0.044 ms\nBM_SharedAtomicIncrement/4/real_time          5.40 ms    0.096 ms\nBM_SharedAtomicIncrement/8/real_time          10.6 ms    0.218 ms\nBM_SharedAtomicIncrement/16/real_time         22.9 ms    0.401 ms\nBM_SharedAtomicIncrement/32/real_time         48.4 ms     1.14 ms\nBM_SeparateAtomicIncrement/1/real_time       0.556 ms    0.016 ms\nBM_SeparateAtomicIncrement/2/real_time        2.74 ms    0.033 ms\nBM_SeparateAtomicIncrement/4/real_time        5.74 ms    0.081 ms\nBM_SeparateAtomicIncrement/8/real_time        11.2 ms    0.244 ms\nBM_SeparateAtomicIncrement/16/real_time       23.9 ms    0.403 ms\nBM_SeparateAtomicIncrement/32/real_time       26.6 ms     1.23 ms\n\n\nCan we conclude that atomic operations don’t wait on each other? Not necessarily!\nIt is highly likely, that data elements in relatively close memory locations are accessed over a short period of time. This is typical, for example, when traversing an array, or performing matrix multiplication. To optimize performance, a chunk of data called the cache line trickles up and down through the cache from the main memory to the CPU and back, instead of just the request data-item. On x86, the cache line size is \\(64\\)-bytes.\nWhat’s actually happening is that the two atomic operations are in the same cache-line. On x86, the whole cache line trickles up and down from main memory to the on-board CPU cache and back. Even if you want one variable from the cache line, the entire 64-byte chunk will go up and down. If two different CPUs want two different variables within the same cache-line, they need to wait, as if it was the same variable. You don’t get lower granularity than 64-bytes on x86.\n\n\n\nShow the code\n%%itikz --temp-dir --tex-packages=tikz --tikz-libraries=arrows.meta --implicit-standalone\n\\tikzset{every picture/.style={line width=0.75pt}} %set default line width to 0.75pt        \n\n\\begin{tikzpicture}[x=0.75pt,y=0.75pt,yscale=-2.1,xscale=2.1,font=\\Large]\n%uncomment if require: \\path (0,379); %set diagram left start at 0, and has height of 379\n\n%Rounded Rect [id:dp27460933128570264] \n\\draw  [fill={rgb, 255:red, 181; green, 212; blue, 244 }  ,fill opacity=1 ] (38.5,45.45) .. controls (38.5,39.13) and (43.63,34) .. (49.95,34) -- (296.05,34) .. controls (302.37,34) and (307.5,39.13) .. (307.5,45.45) -- (307.5,79.8) .. controls (307.5,86.12) and (302.37,91.25) .. (296.05,91.25) -- (49.95,91.25) .. controls (43.63,91.25) and (38.5,86.12) .. (38.5,79.8) -- cycle ;\n%Rounded Rect [id:dp6820620708533545] \n\\draw  [fill={rgb, 255:red, 181; green, 212; blue, 244 }  ,fill opacity=1 ] (335,127.87) .. controls (335,124.63) and (337.63,122) .. (340.87,122) -- (586.63,122) .. controls (589.87,122) and (592.5,124.63) .. (592.5,127.87) -- (592.5,145.48) .. controls (592.5,148.72) and (589.87,151.34) .. (586.63,151.34) -- (340.87,151.34) .. controls (337.63,151.34) and (335,148.72) .. (335,145.48) -- cycle ;\n%Rounded Rect [id:dp9973874025957986] \n\\draw  [fill={rgb, 255:red, 181; green, 212; blue, 244 }  ,fill opacity=1 ] (44,127.87) .. controls (44,124.63) and (46.63,122) .. (49.87,122) -- (295.63,122) .. controls (298.87,122) and (301.5,124.63) .. (301.5,127.87) -- (301.5,145.48) .. controls (301.5,148.72) and (298.87,151.34) .. (295.63,151.34) -- (49.87,151.34) .. controls (46.63,151.34) and (44,148.72) .. (44,145.48) -- cycle ;\n%Rounded Rect [id:dp9732688461749553] \n\\draw  [fill={rgb, 255:red, 252; green, 246; blue, 153 }  ,fill opacity=1 ] (46.33,309.12) .. controls (46.33,303.9) and (50.56,299.67) .. (55.78,299.67) -- (586.38,299.67) .. controls (591.6,299.67) and (595.83,303.9) .. (595.83,309.12) -- (595.83,337.47) .. controls (595.83,342.69) and (591.6,346.92) .. (586.38,346.92) -- (55.78,346.92) .. controls (50.56,346.92) and (46.33,342.69) .. (46.33,337.47) -- cycle ;\n%Straight Lines [id:da9504358299662848] \n\\draw    (276.08,339.92) -- (383.58,339.92) ;\n\\draw [shift={(386.58,339.92)}, rotate = 180] [fill={rgb, 255:red, 0; green, 0; blue, 0 }  ][line width=0.08]  [draw opacity=0] (8.93,-4.29) -- (0,0) -- (8.93,4.29) -- cycle    ;\n\\draw [shift={(273.08,339.92)}, rotate = 0] [fill={rgb, 255:red, 0; green, 0; blue, 0 }  ][line width=0.08]  [draw opacity=0] (8.93,-4.29) -- (0,0) -- (8.93,4.29) -- cycle    ;\n%Rounded Rect [id:dp1128018396464796] \n\\draw  [fill={rgb, 255:red, 181; green, 212; blue, 244 }  ,fill opacity=1 ] (329.5,45.45) .. controls (329.5,39.13) and (334.63,34) .. (340.95,34) -- (587.05,34) .. controls (593.37,34) and (598.5,39.13) .. (598.5,45.45) -- (598.5,79.8) .. controls (598.5,86.12) and (593.37,91.25) .. (587.05,91.25) -- (340.95,91.25) .. controls (334.63,91.25) and (329.5,86.12) .. (329.5,79.8) -- cycle ;\n%Straight Lines [id:da8059041144370804] \n\\draw [color={rgb, 255:red, 74; green, 83; blue, 226 }  ,draw opacity=1 ]   (378.92,154.25) -- (378.92,182.25) ;\n\\draw [shift={(378.92,151.25)}, rotate = 90] [fill={rgb, 255:red, 74; green, 83; blue, 226 }  ,fill opacity=1 ][line width=0.08]  [draw opacity=0] (8.93,-4.29) -- (0,0) -- (8.93,4.29) -- cycle    ;\n%Rounded Rect [id:dp591399533303866] \n\\draw  [fill={rgb, 255:red, 181; green, 212; blue, 244 }  ,fill opacity=1 ] (335.67,189.2) .. controls (335.67,185.96) and (338.29,183.33) .. (341.54,183.33) -- (587.3,183.33) .. controls (590.54,183.33) and (593.17,185.96) .. (593.17,189.2) -- (593.17,206.81) .. controls (593.17,210.05) and (590.54,212.68) .. (587.3,212.68) -- (341.54,212.68) .. controls (338.29,212.68) and (335.67,210.05) .. (335.67,206.81) -- cycle ;\n%Rounded Rect [id:dp5591689579874568] \n\\draw  [fill={rgb, 255:red, 181; green, 212; blue, 244 }  ,fill opacity=1 ] (44.67,189.2) .. controls (44.67,185.96) and (47.29,183.33) .. (50.54,183.33) -- (296.3,183.33) .. controls (299.54,183.33) and (302.17,185.96) .. (302.17,189.2) -- (302.17,206.81) .. controls (302.17,210.05) and (299.54,212.68) .. (296.3,212.68) -- (50.54,212.68) .. controls (47.29,212.68) and (44.67,210.05) .. (44.67,206.81) -- cycle ;\n%Rounded Rect [id:dp4165838369572783] \n\\draw  [fill={rgb, 255:red, 181; green, 212; blue, 244 }  ,fill opacity=1 ] (44.67,245.87) .. controls (44.67,242.63) and (47.29,240) .. (50.54,240) -- (586.46,240) .. controls (589.71,240) and (592.33,242.63) .. (592.33,245.87) -- (592.33,263.48) .. controls (592.33,266.72) and (589.71,269.34) .. (586.46,269.34) -- (50.54,269.34) .. controls (47.29,269.34) and (44.67,266.72) .. (44.67,263.48) -- cycle ;\n%Straight Lines [id:da7083107764900278] \n\\draw [color={rgb, 255:red, 74; green, 83; blue, 226 }  ,draw opacity=1 ]   (92.99,215.67) -- (92.92,240.92) ;\n\\draw [shift={(93,212.67)}, rotate = 90.17] [fill={rgb, 255:red, 74; green, 83; blue, 226 }  ,fill opacity=1 ][line width=0.08]  [draw opacity=0] (8.93,-4.29) -- (0,0) -- (8.93,4.29) -- cycle    ;\n%Straight Lines [id:da028317245941649194] \n\\draw [color={rgb, 255:red, 74; green, 83; blue, 226 }  ,draw opacity=1 ]   (93.66,153.67) -- (93.58,182.25) ;\n\\draw [shift={(93.67,150.67)}, rotate = 90.15] [fill={rgb, 255:red, 74; green, 83; blue, 226 }  ,fill opacity=1 ][line width=0.08]  [draw opacity=0] (8.93,-4.29) -- (0,0) -- (8.93,4.29) -- cycle    ;\n%Straight Lines [id:da8360791510647615] \n\\draw [color={rgb, 255:red, 74; green, 83; blue, 226 }  ,draw opacity=1 ]   (92.33,93.67) -- (92.25,122.25) ;\n\\draw [shift={(92.33,90.67)}, rotate = 90.15] [fill={rgb, 255:red, 74; green, 83; blue, 226 }  ,fill opacity=1 ][line width=0.08]  [draw opacity=0] (8.93,-4.29) -- (0,0) -- (8.93,4.29) -- cycle    ;\n%Straight Lines [id:da620625708639835] \n\\draw [color={rgb, 255:red, 74; green, 83; blue, 226 }  ,draw opacity=1 ]   (378.25,213.58) -- (378.25,241.58) ;\n\\draw [shift={(378.25,210.58)}, rotate = 90] [fill={rgb, 255:red, 74; green, 83; blue, 226 }  ,fill opacity=1 ][line width=0.08]  [draw opacity=0] (8.93,-4.29) -- (0,0) -- (8.93,4.29) -- cycle    ;\n%Straight Lines [id:da911476849461266] \n\\draw [color={rgb, 255:red, 74; green, 83; blue, 226 }  ,draw opacity=1 ]   (305.58,270.92) -- (305.58,298.92) ;\n\\draw [shift={(305.58,267.92)}, rotate = 90] [fill={rgb, 255:red, 74; green, 83; blue, 226 }  ,fill opacity=1 ][line width=0.08]  [draw opacity=0] (8.93,-4.29) -- (0,0) -- (8.93,4.29) -- cycle    ;\n%Straight Lines [id:da6168210047920039] \n\\draw [color={rgb, 255:red, 74; green, 83; blue, 226 }  ,draw opacity=1 ]   (377.58,94.25) -- (377.58,122.25) ;\n\\draw [shift={(377.58,91.25)}, rotate = 90] [fill={rgb, 255:red, 74; green, 83; blue, 226 }  ,fill opacity=1 ][line width=0.08]  [draw opacity=0] (8.93,-4.29) -- (0,0) -- (8.93,4.29) -- cycle    ;\n%Straight Lines [id:da45709411556658486] \n\\draw [color={rgb, 255:red, 144; green, 19; blue, 254 }  ,draw opacity=1 ]   (243.58,91.25) -- (243.58,119.25) ;\n\\draw [shift={(243.58,122.25)}, rotate = 270] [fill={rgb, 255:red, 144; green, 19; blue, 254 }  ,fill opacity=1 ][line width=0.08]  [draw opacity=0] (8.93,-4.29) -- (0,0) -- (8.93,4.29) -- cycle    ;\n%Straight Lines [id:da1624871748247504] \n\\draw [color={rgb, 255:red, 144; green, 19; blue, 254 }  ,draw opacity=1 ]   (244.25,152.58) -- (244.25,180.58) ;\n\\draw [shift={(244.25,183.58)}, rotate = 270] [fill={rgb, 255:red, 144; green, 19; blue, 254 }  ,fill opacity=1 ][line width=0.08]  [draw opacity=0] (8.93,-4.29) -- (0,0) -- (8.93,4.29) -- cycle    ;\n%Straight Lines [id:da951312301312835] \n\\draw [color={rgb, 255:red, 144; green, 19; blue, 254 }  ,draw opacity=1 ]   (245.67,211.33) -- (244.99,237.25) ;\n\\draw [shift={(244.92,240.25)}, rotate = 271.49] [fill={rgb, 255:red, 144; green, 19; blue, 254 }  ,fill opacity=1 ][line width=0.08]  [draw opacity=0] (8.93,-4.29) -- (0,0) -- (8.93,4.29) -- cycle    ;\n%Straight Lines [id:da5598487398669117] \n\\draw [color={rgb, 255:red, 144; green, 19; blue, 254 }  ,draw opacity=1 ]   (351,270.67) -- (350.93,295.92) ;\n\\draw [shift={(350.92,298.92)}, rotate = 270.17] [fill={rgb, 255:red, 144; green, 19; blue, 254 }  ,fill opacity=1 ][line width=0.08]  [draw opacity=0] (8.93,-4.29) -- (0,0) -- (8.93,4.29) -- cycle    ;\n%Straight Lines [id:da18143538236339274] \n\\draw [color={rgb, 255:red, 144; green, 19; blue, 254 }  ,draw opacity=1 ]   (547.58,91.25) -- (547.58,119.25) ;\n\\draw [shift={(547.58,122.25)}, rotate = 270] [fill={rgb, 255:red, 144; green, 19; blue, 254 }  ,fill opacity=1 ][line width=0.08]  [draw opacity=0] (8.93,-4.29) -- (0,0) -- (8.93,4.29) -- cycle    ;\n%Straight Lines [id:da11843933303452991] \n\\draw [color={rgb, 255:red, 144; green, 19; blue, 254 }  ,draw opacity=1 ]   (547.58,151.25) -- (547.58,179.25) ;\n\\draw [shift={(547.58,182.25)}, rotate = 270] [fill={rgb, 255:red, 144; green, 19; blue, 254 }  ,fill opacity=1 ][line width=0.08]  [draw opacity=0] (8.93,-4.29) -- (0,0) -- (8.93,4.29) -- cycle    ;\n%Straight Lines [id:da21016027697626216] \n\\draw [color={rgb, 255:red, 144; green, 19; blue, 254 }  ,draw opacity=1 ]   (546.92,211.25) -- (546.92,239.25) ;\n\\draw [shift={(546.92,242.25)}, rotate = 270] [fill={rgb, 255:red, 144; green, 19; blue, 254 }  ,fill opacity=1 ][line width=0.08]  [draw opacity=0] (8.93,-4.29) -- (0,0) -- (8.93,4.29) -- cycle    ;\n\n% Text Node\n\\draw (52,42) node [anchor=north west][inner sep=0.75pt]  [xscale=2,yscale=2] [align=left] {\\textit{CPU Core-1}};\n% Text Node\n\\draw (342,40) node [anchor=north west][inner sep=0.75pt]  [xscale=2,yscale=2] [align=left] {\\textit{CPU Core-2}};\n% Text Node\n\\draw  [color={rgb, 255:red, 184; green, 233; blue, 134 }  ,draw opacity=1 ][fill={rgb, 255:red, 233; green, 229; blue, 229 }  ,fill opacity=1 ][line width=2.25]   (58.13,124.25) -- (169.13,124.25) -- (169.13,149.25) -- (58.13,149.25) -- cycle  ;\n\\draw (113.63,136.75) node  [xscale=2,yscale=2] [align=left] {\\begin{minipage}[lt]{72.93pt}\\setlength\\topsep{0pt}\nx[0],x[1],...\n\\end{minipage}};\n% Text Node\n\\draw (210,128) node [anchor=north west][inner sep=0.75pt]  [xscale=2,yscale=2] [align=left] {\\textit{L1 Cache}};\n% Text Node\n\\draw (500,127.5) node [anchor=north west][inner sep=0.75pt]  [xscale=2,yscale=2] [align=left] {\\textit{L1 Cache}};\n% Text Node\n\\draw (470.33,302.67) node [anchor=north west][inner sep=0.75pt]  [xscale=2,yscale=2] [align=left] {\\textit{Main Memory}};\n% Text Node\n\\draw (298.33,344.17) node [anchor=north west][inner sep=0.75pt]  [xscale=2,yscale=2] [align=left] {\\textit{64-bytes}};\n% Text Node\n\\draw (170.83,312.17) node [anchor=north west][inner sep=0.75pt]  [xscale=2,yscale=2] [align=left] {\\textit{Cache line}};\n% Text Node\n\\draw (179.83,68.63) node  [xscale=2,yscale=2] [align=left] {\\begin{minipage}[lt]{48.73pt}\\setlength\\topsep{0pt}\n++x[0];\n\\end{minipage}};\n% Text Node\n\\draw (467.67,68.13) node  [xscale=2,yscale=2] [align=left] {\\begin{minipage}[lt]{41.71pt}\\setlength\\topsep{0pt}\n++x[1];\n\\end{minipage}};\n% Text Node\n\\draw  [color={rgb, 255:red, 184; green, 233; blue, 134 }  ,draw opacity=1 ][fill={rgb, 255:red, 233; green, 229; blue, 229 }  ,fill opacity=1 ][line width=2.25]   (349.63,123.75) -- (460.63,123.75) -- (460.63,148.75) -- (349.63,148.75) -- cycle  ;\n\\draw (405.13,136.25) node  [xscale=2,yscale=2] [align=left] {\\begin{minipage}[lt]{72.93pt}\\setlength\\topsep{0pt}\nx[0],x[1],...\n\\end{minipage}};\n% Text Node\n\\draw  [color={rgb, 255:red, 184; green, 233; blue, 134 }  ,draw opacity=1 ][fill={rgb, 255:red, 233; green, 229; blue, 229 }  ,fill opacity=1 ][line width=2.25]   (278.63,305.92) -- (389.63,305.92) -- (389.63,330.92) -- (278.63,330.92) -- cycle  ;\n\\draw (334.13,318.42) node  [xscale=2,yscale=2] [align=left] {\\begin{minipage}[lt]{72.93pt}\\setlength\\topsep{0pt}\nx[0],x[1],...\n\\end{minipage}};\n% Text Node\n\\draw  [color={rgb, 255:red, 184; green, 233; blue, 134 }  ,draw opacity=1 ][fill={rgb, 255:red, 233; green, 229; blue, 229 }  ,fill opacity=1 ][line width=2.25]   (58.79,185.58) -- (169.79,185.58) -- (169.79,210.58) -- (58.79,210.58) -- cycle  ;\n\\draw (114.29,198.08) node  [xscale=2,yscale=2] [align=left] {\\begin{minipage}[lt]{72.93pt}\\setlength\\topsep{0pt}\nx[0],x[1],...\n\\end{minipage}};\n% Text Node\n\\draw (210.67,189.33) node [anchor=north west][inner sep=0.75pt]  [xscale=2,yscale=2] [align=left] {\\textit{L2 Cache}};\n% Text Node\n\\draw (500.83,189.5) node [anchor=north west][inner sep=0.75pt]  [xscale=2,yscale=2] [align=left] {\\textit{L2 Cache}};\n% Text Node\n\\draw  [color={rgb, 255:red, 184; green, 233; blue, 134 }  ,draw opacity=1 ][fill={rgb, 255:red, 233; green, 229; blue, 229 }  ,fill opacity=1 ][line width=2.25]   (350.29,185.08) -- (461.29,185.08) -- (461.29,210.08) -- (350.29,210.08) -- cycle  ;\n\\draw (405.79,197.58) node  [xscale=2,yscale=2] [align=left] {\\begin{minipage}[lt]{72.93pt}\\setlength\\topsep{0pt}\nx[0],x[1],...\n\\end{minipage}};\n% Text Node\n\\draw  [color={rgb, 255:red, 184; green, 233; blue, 134 }  ,draw opacity=1 ][fill={rgb, 255:red, 233; green, 229; blue, 229 }  ,fill opacity=1 ][line width=2.25]   (276.13,241.58) -- (387.13,241.58) -- (387.13,266.58) -- (276.13,266.58) -- cycle  ;\n\\draw (331.63,254.08) node  [xscale=2,yscale=2] [align=left] {\\begin{minipage}[lt]{72.93pt}\\setlength\\topsep{0pt}\nx[0],x[1],...\n\\end{minipage}};\n% Text Node\n\\draw (500.33,246.67) node [anchor=north west][inner sep=0.75pt]  [xscale=2,yscale=2] [align=left] {\\textit{L3 Cache}};\n\n\n\\end{tikzpicture}\n\n\n\n\n\n\nAtomic operations do wait on each other! In particular, write-operations do. Read operations scale near-perfectly.\nIf I put the variables on separate cache-lines, then there is no problem and the CPUs don’t have to wait on anything. We can prove it with a benchmark.\nBenchmark                            Time         CPU\n------------------------------------------------------------------------\nBM_Shared/1/real_time            0.561 ms    0.015 ms\nBM_Shared/2/real_time             3.25 ms    0.054 ms\nBM_Shared/4/real_time             6.07 ms    0.061 ms\nBM_Shared/8/real_time             10.6 ms    0.240 ms\nBM_Shared/16/real_time            22.9 ms    0.384 ms\nBM_Shared/32/real_time            51.4 ms    0.944 ms\nBM_Shared/64/real_time             103 ms     2.67 ms\nBM_FalseShared/1/real_time       0.578 ms    0.016 ms\nBM_FalseShared/2/real_time        2.98 ms    0.037 ms\nBM_FalseShared/4/real_time        6.18 ms    0.065 ms\nBM_FalseShared/8/real_time        10.6 ms    0.234 ms\nBM_FalseShared/16/real_time       13.5 ms    0.386 ms\nBM_FalseShared/32/real_time       26.7 ms     1.21 ms\nBM_FalseShared/64/real_time       37.0 ms     2.36 ms\nBM_NonShared/1/real_time         0.576 ms    0.015 ms\nBM_NonShared/2/real_time         0.591 ms    0.028 ms\nBM_NonShared/4/real_time         0.632 ms    0.051 ms\nBM_NonShared/8/real_time         0.598 ms    0.102 ms\nBM_NonShared/16/real_time         1.05 ms    0.225 ms\nBM_NonShared/32/real_time         1.81 ms    0.701 ms\nBM_NonShared/64/real_time         3.21 ms     1.28 ms\nAtomic operations have to wait for cache line access. This is the price of data sharing without race conditions. Modifying different locations on the same cache line still incurs a run-time penalty, a phenomenon known as false sharing. To avoid false sharing, we should align per-thread data to separate cache lines. Atomic operations do wait on each other, particularly write operations. However, read-only operations can scale near-perfectly when properly designed."
  },
  {
    "objectID": "posts/memory_barriers/index.html#strong-vs-weak-compare-and-swap",
    "href": "posts/memory_barriers/index.html#strong-vs-weak-compare-and-swap",
    "title": "Memory Barriers",
    "section": "",
    "text": "C++ provides two versions of CAS - weak and strong.\n// Strong CAS\nx.compare_exchange_strong(old_x, new_x);\n/* \nif (x == old_x)\n{\n    x = new_x;\n    return true;\n}else{\n    old_x = x;\n    return false;\n}\n*/\nx.compare_exchange_weak(old_x, new_x) is essentially the same thing, but can spuriously fail and return false, even if x == old_x."
  },
  {
    "objectID": "posts/memory_barriers/index.html#memory-barriers---introduction",
    "href": "posts/memory_barriers/index.html#memory-barriers---introduction",
    "title": "Memory Barriers",
    "section": "Memory Barriers - Introduction",
    "text": "Memory Barriers - Introduction\nIt’s good to understand about atomic variables, but its not enough by a mile. Memory barriers go hand-in-hand with C++ atomics. Memory barriers control how changes to memory made by one CPU core become visible to other CPU cores. Without memory barriers, there is no guarantee of visibility whatsoever. Imagine you have two CPUs, both modifying a variable x in their on-chip caches. The main memory doesn’t have to change at all! There is no guarantee that anybody can see anything.\nFor example, CPU-1 cache might have x = 42, CPU-2 cache might have x = 17, while Main Memory still shows x = 0 (stale/unchanged). The problem is that each CPU sees its own value. Memory is unchanged, and there is no coherence between the cores."
  },
  {
    "objectID": "posts/memory_barriers/index.html#memory-barriers-in-c",
    "href": "posts/memory_barriers/index.html#memory-barriers-in-c",
    "title": "Memory Barriers",
    "section": "Memory Barriers in C++",
    "text": "Memory Barriers in C++\nC++ memory barriers are modifiers on atomic operations.\nExample:\nstd::atomic&lt;int&gt; x;\nx.store(1, std::memory_order_release);\nThis implies that we have put a release memory barrier on that store."
  },
  {
    "objectID": "posts/memory_barriers/index.html#no-barriers---stdmemory_order_relaxed",
    "href": "posts/memory_barriers/index.html#no-barriers---stdmemory_order_relaxed",
    "title": "Memory Barriers",
    "section": "No Barriers - std::memory_order_relaxed",
    "text": "No Barriers - std::memory_order_relaxed\nNo memory barrier means that we can reorder reads and writes any way we want. We have an atomic x variable and a, b and c are non-atomic variables. No memory order means I can reorder reads and writes anywhere I want.\nWe have an atomic store to x in the middle. In the program order, I write to a, then I write to b, then I write to c and then I write to x. In the actual order, anything is possible. There are no restrictions whatsoever. This in C++ stamdard is called std::memory_order_relaxed. There are no guarantees here.\n\n\n\n\nReads and writes can be reordered arbitrarily. No guarantees."
  },
  {
    "objectID": "posts/memory_barriers/index.html#acquire-barrier",
    "href": "posts/memory_barriers/index.html#acquire-barrier",
    "title": "Memory Barriers",
    "section": "Acquire Barrier",
    "text": "Acquire Barrier\nAn acquire barrier is a half-barrier that acts as a one-way gate. Nothing that was after the load can move in front of it, but anything that was before can move after. Acquire barrier guarantees that all memory operations scheduled after the barrier in the program order become visible after the barrier. This applies to all operations - not just all reads or all writes, but both reads and writes. Furthermore, this applies to all operations, not just operations on the atomic variable, but literally all memory operations. Reads and writes cannot be reordered from after to before the barrier.\n\n\n\n\nAnything that was after cannot be moved to before the load."
  },
  {
    "objectID": "posts/memory_barriers/index.html#release-barrier",
    "href": "posts/memory_barriers/index.html#release-barrier",
    "title": "Memory Barriers",
    "section": "Release Barrier",
    "text": "Release Barrier\nA release barrier is the reverse of an acquire barrier. Nothing that was before the barrier can move after, but anything that is after can move in front of the store.\n\n\n\n\nAnything that was before cannot be moved to after the store."
  },
  {
    "objectID": "posts/memory_barriers/index.html#acquire-release-protocol",
    "href": "posts/memory_barriers/index.html#acquire-release-protocol",
    "title": "Memory Barriers",
    "section": "Acquire-Release Protocol",
    "text": "Acquire-Release Protocol\nAcquire and release barriers are often used together. Thread t1 writes atomic variable x with a release barrier. Thread t2 reads atomic variable x with an acquire barrier. On the acquire side, all memory reads done after the acquire barrier in t2 in program order have to be done after the barrier in actual execution order. On the release side, all memory writes done before the release barrier in t1 in program order have to be done before the barrier in actual execution order.\nThe result is that all memory writes that happen in t1 before the barrier become visible in thread t2 after the barrier. Thread 1 prepares data (does some writes) then releases (publishes) it by updating atomic variable x. Thread 2 acquires atomic variable x and the data is guaranteed to be visible. It’s important to note that it has to be the same atomic variable x for this synchronization to work."
  },
  {
    "objectID": "posts/memory_barriers/index.html#challenge-question",
    "href": "posts/memory_barriers/index.html#challenge-question",
    "title": "Memory Barriers",
    "section": "Challenge question",
    "text": "Challenge question\nObserve the following code snippet. What is the output of lines (q) and (s)?\n// Thread-1\nx.store(1, std::memory_order_relaxed);\ny.store(2, std::memory_order_release);\nx.store(3, std::memory_order_relaxed);\nz.store(4, std::memory_order_release);\nx.store(5, std::memory_order_relaxed);\n\n//Thread-2\nwhile(y.load(std::memory_order_acquire)!=2){}   // p\nstd::cout &lt;&lt; x.load(std::memory_order_relaxed); // q\nwhile(z.load(std::memory_order_acquire)!=4){}   // r\nstd::cout &lt;&lt; x.load(std::memory_order_relaxed); // s\nFor more such questions, visit getcracked.io"
  },
  {
    "objectID": "posts/memory_barriers/index.html#references",
    "href": "posts/memory_barriers/index.html#references",
    "title": "Memory Barriers",
    "section": "References",
    "text": "References\n\n\nC++ atomics, from basic to advanced by Fedor Pikus (CppCon 2017)\n“C++ Concurrency in Action” by Anthony Williams\n“The Art of Multiprocessor Programming” by Herlihy and Shavit"
  },
  {
    "objectID": "posts/discrete-probability-and-counting-puzzles/index.html",
    "href": "posts/discrete-probability-and-counting-puzzles/index.html",
    "title": "Discrete probability and counting puzzles",
    "section": "",
    "text": "Example 1 We flip a fair coin until we obtain our first heads. If the first heads occurs on the \\(k\\)-th flip, we are given \\(k\\) balls. We put them into 3 bins labeled 1, 2, and 3 at random. Find the probability that none of the three bins are empty.\n\nSolution.\nLet \\(A_k\\) be the event that the first head occurs on the \\(k\\)th flip. So, we are interested in the sequence \\(\\underbrace{T \\ldots T}_{(k-1)\\text{-tails}}H\\). We have:\n\\[\n\\mathbb{P}(A_k) = \\left(\\frac{1}{2}\\right)^{k-1} \\cdot \\frac{1}{2} = \\frac{1}{2^k}\n\\]\n\nExample 2 Imagine you have \\(4\\) \\(6\\)-sided dice. What is the probability that you roll a different number on each die?\n\nSolution.\n\\[\np = \\frac{6\\cdot 5 \\cdot 4 \\cdot 3}{6^4}\n\\]\n\nExample 3 What is the probability of flipping exactly \\(5\\) heads when flipping \\(10\\) fair coins?\n\nSolution.\n\\[\nP(k = 5) = {10 \\choose 5} \\frac{1}{2^{10}}\n\\]\n\nExample 4 Two players are at deuce in a tennis match — player \\(1\\) has \\(60\\) percent of winning the point and player \\(2\\) has \\(40\\) percent chance. What are the odds of player 1 winning?\n\nSolution\nWhen a game is at the 40-40 mark, a player still needs two clear points to win the game. We can quickly draw the following state diagram to represent the game (it is a discrete-time markov chain).\n\n\n\nWinning the game\n\n\nLet the state \\(s_1 \\stackrel{def}{=}\\) the two players are 40-40. And the state \\(s_3 \\stackrel{def}{=}\\) player \\(1\\) wins. The states \\(3\\) and \\(5\\) are absorbing states. Let \\(p_{13}\\) be the hitting probability of state \\(3\\) from state \\(1\\). We have:\n\\[\n\\begin{align*}\np_{13} &= 0.6 p_{23} + 0.4 p_{43}\\\\\np_{23} &= 0.6 (1) + 0.4p_{13}\\\\\np_{43} &= 0.6p_{13} + 0.4(0)\n\\end{align*}\n\\]\nIt turns out that \\(p_{13} = \\frac{9}{13}\\).\n\nExample 5 You have a plate of spaghetti in front of you (no sauce!). You pick two ends and tie them together. Then you pick two more ends and tie them together. Continue until there are no free ends left. If there were \\(n\\) spaghettis originally, what is the probability that you now have a single giant loop consisting of all the spaghettis?\n\nLet \\(p_n\\) be the probability of a single giant loop. \\(n\\) spaghettis have \\(2n\\) free ends. In each of the \\(n\\) trials, you pick \\(2\\) ends. At the start, the probability that you don’t tie a sphagetti to itself is\n\\[\n\\frac{2n}{2n} \\cdot \\frac{2n - 2}{2n - 1} = \\frac{2n - 2}{2n - 1}\n\\]\nAfter the first draw, we have reduced the problem to \\((n-1)\\) spaghetti strands and \\(2n-2\\) free ends. So, the probability of no-loops is:\n\\[\np_n =  \\frac{2n - 2}{2n - 1} \\cdot p_{n-1}\n\\]\nExtending this to \\(k=(n-1)\\) trials: \\[\n\\begin{align*}\np_n &= \\frac{2n - 2}{2n - 1} \\cdot \\frac{2n-4}{2n-3} \\cdots \\frac{2}{1}\\\\\n&= 2^{n-1} \\frac{(n-1)!}{(2n-1)(2n-3)\\cdots 1}\\\\\n&= 2^{n-1} \\frac{2^n n! (n-1)!}{(2n)(2n-1)(2n-2)(2n-3) \\cdots 1}\\\\\n&= 2^{2n-1} \\frac{n! (n-1)!}{(2n)!}\\\\\n\\end{align*}\n\\]\n\nExample 6 An electronic safe has a three digit passcode. You are given three constraints regarding the code. Firstly, the code is not an odd number. Secondly, the code does not contain the number six. Lastly, one of the digits appears more than once. How many possible three digit entries satisfy these three requirements?\n\nSolution.\nSince it’s a \\(3\\)-digit electronic passcode to a safe, \\(0\\) is a valid first digit. The last digit must be one of \\(0,2,4,8\\). The first digit must be one of \\(\\{0,1,2,\\ldots,5,7,8,9\\}\\). The middle digit must be must be one of \\(\\{0,1,2,\\ldots,5,7,8,9\\}\\)\nCase I. The first two digits are identical.\nThere are \\(9 \\times 1 \\times 4 = 36\\) such distinguishable codes.\nCase II. The last two digits are identical.\nThere are \\(9 \\times 1 \\times 4 = 36\\) such distinguishable codes.\nCase III. The first and the third digits are identical.\nThere are \\(1 \\times 9 \\times 4 = 36\\) such distinguishable codes.\nAlso, \\(000\\), \\(222\\), \\(444\\) and \\(888\\) have been overcounted \\(3\\) times. They should be accounted for only once. Hence, the number of possible three digit entries satisfying the above requirements are \\(108 - 8 = 100\\).\n\nExample 7 Suppose we roll \\(5\\) standard fair dice and sum the faces of the largest \\(3\\) values showing. Find the probability that the sum is \\(18\\).\n\nSolution.\nTo reach a sum of \\(18\\) on the largest three die faces, we must get atleast \\(3\\) sixes in \\(5\\) dice rolls.\nDefine success as getting a \\(6\\) on a die, \\(p = \\frac{1}{6}\\), \\(q=\\frac{5}{6}\\) and let \\(X\\) be the number of sixes in \\(5\\) die rolls.\n\\[\n\\begin{align*}\nP(X \\ge 3) &= 1 - (P(X=0) + P(X=1) + P(X=2))\\\\\n&= 1 - \\left(\\frac{5}{6}\\right)^5 - {5 \\choose 1} \\left(\\frac{1}{6}\\right)\\left(\\frac{5}{6}\\right)^4 - {5 \\choose 2} \\left(\\frac{1}{6}\\right)^2\\left(\\frac{5}{6}\\right)^3\\\\\n&= \\frac{23}{648}\n\\end{align*}\n\\]\n\nExample 8 Consider a \\(2023 \\times 2023\\) grid. The grid squares from the middle row are shaded in. What is the probability that a randomly selected rectangle contains at least one shaded square?\n\nSolution.\nLet’s solve this puzzle for a smaller \\(5 \\times 5\\) grid. A rectangle is always determined by a choice of a pair of vertical grid lines and a pair of horizonal grid lines.\n\n\n\nRectangles\n\n\nThe number of horizontal and vertical grid lines are \\(6\\). So, the total number of rectangles are \\({6 \\choose 2} \\times {6 \\choose 2}\\).\nIn order to pick rectangle that includes atleast one shaded square, one of the grid lines must chosen from the top \\(3\\) horizontal grid lines and the second grid line must be chosen from the bottom \\(3\\) horizontal grid lines. That yields \\({3 \\choose 1}^2\\) pairs of horizontal grid lines. There are no restrictions on the vertical grid lines so there are \\({6 \\choose 2}\\) pairs of vertical grid lines. Hence, the number of favorable rectangles are \\(3^2 \\times {6 \\choose 2}\\).\nGeneralizing, the desired probability for a \\((2n-1) \\times (2n-1)\\) grid is:\n\\[\n\\begin{align*}\np_{2n-1} &= \\frac{n^2 \\cdot {2n \\choose 2}}{{2n \\choose 2}^2} \\\\\n&= \\frac{n^2 }{{2n \\choose 2}} \\\\\n&= \\frac{2n^2}{(2n)(2n-1)}\\\\\n&= \\frac{n}{2n-1}\n\\end{align*}\n\\]\nSo, \\(p_{2023} = \\frac{1012}{2023} \\approx 0.5\\).\n\nExample 9 How many paths are there where you can only move up or right one unit at each step that go from \\((0, 0)\\) to \\((5, 3)\\) without crossing the line \\(y = x\\)? You are allowed to touch it.\n\nWe are interested in those paths where each vertice on the trajectory has \\(x\\) coordinate greater than or equal to the \\(y\\)- coordinate.\n\nExample 10 How many paths are there where you can only move up or right one unit at each step that go from \\((0, 0)\\) to \\((5, 3)\\) without crossing the line \\(y = x\\)? You are allowed to touch it.\n\n\nExample 11 Imagine 3 pairs of socks (6 total) labeled \\(\\{1,1,2,2,3,3\\}\\). Define a satisfactory pair as any pair of individual socks such that their numbers differ by a maximum of 1 (i.e. 2 3 is a satisfactory pair). In this game, drawing without replacement, what is the probability that a player will draw three satisfactory pairs of socks?\n\nSolution.\nLabel the socks as\n\\[\n\\{a_1, a_2, b_1, b_2, c_1, c_2\\}\n\\]\nArrangements with \\(3\\) satisfactory pairs are only obtained, if there are no pairs where a 1-sock is paired with a 3-sock. Let us find the number of arrangements, where there is atleast \\(1\\) pair containing a 1-sock paired with a 3-sock.\nThe number of distinguishable arrangements where the first pair has a 1-sock paired with a 3-sock are given as follows. There are \\(2\\) possible choices for the 1-sock, \\(2\\) possible choices for the \\(3\\)-sock, \\(2\\) possible arrangements within this pair. For each such choice, there are \\(4!\\) choices for second and third pairs of socks. So, the result is \\(2 \\times 2 \\times 2 \\times 4! = 192\\). By similar arguments, the number of arrangements with the second pair/third pair containing a 1-sock and 3-sock are \\(192\\) each. So, the total number of distinct arrangements are \\(192 \\times 3 = 576\\).\nHowever, we overcounted the arrangements that have two (\\(1\\)-sock,\\(3\\)-sock) pairs. The number of arrangements where the first and second pair are (\\(1\\)-sock,\\(3\\)-sock) pairs is \\(2 \\times 2 \\times 2 \\times 1 \\times 2 = 16\\). The three pairs can be arrangement amongst themselves in \\(3! = 6\\) ways. So, the total number of distinct arrangements are \\(96\\).\nBy inclusion-exclusion, the number of arrangments with atleast one (\\(1\\)-sock, \\(3\\)-sock) pair = \\(576 - 96 = 480\\). Thus, the number of satisfactory arrangments is \\(720 - 480 = 240\\).\nThe probability of \\(3\\) satisfactory pairs = \\(\\frac{240}{720}=\\frac{1}{3}\\)\n\nExample 12 Player M has \\(1\\) dollar and player N has \\(2\\) dollars. Each game gives the winner $1 from the other. As a better player, M wins \\(2/3\\) of the games. They play until one of them is bankrupt. What Is the probability that M wins?\n\nSolution.\n\n\n\nWinning the game\n\n\nLet \\(p_{1W}\\) be the hitting probability of state \\(W\\) given we are in state \\(1\\). We can quickly setup:\n\\[\n\\begin{align*}\np_{1W} &= \\frac{2}{3}p_{2W}  + \\frac{1}{3} \\times 0\np_{2W} &= \\frac{1}{3}p_{1W} + \\frac{2}{3} \\times 1\n\\end{align*}\n\\]\nSo, we get:\n\\[\n\\begin{align*}\np_{1W} &= \\frac{2}{3}\\left(\\frac{1}{3}p_{1W} + \\frac{2}{3}\\right)\\\\\n&= \\frac{2}{9} p_{1W} + \\frac{4}{9}\\\\\n\\frac{7}{9}p_{1W} &= \\frac{4}{9}\\\\\np_{1W} &= \\frac{4}{7}\n\\end{align*}\n\\]\n\nExample 13 We throw \\(3\\) dice one by one. What is the probability that we obtain 3 points in strictly increasing order?\n\nSolution.\nWe can choose a sub-population of \\(3\\) numbers without ordering from a population of \\(n=6\\) in \\({6 \\choose 3}\\) ways. For each selection, there is only one unique way to order them in strictly increasing order. Hence, the number of dice rolls where the points are in strictly increasing order are:\n\\[\n\\frac{{6 \\choose 3}}{6^3} = \\frac{20}{216}\n\\]\n\nExample 14 Five boys and five girls are seated in a row at the movie theater. To ensure that the children are engaged during the movie, the teacher mandates that no two children of the same gender can sit next to each other. How many arrangements are possible?\n\nSolution.\nWe label the set of boys and girls as\n\\[\n\\{B_1, B_2, B_3, B_4, B_5, G_1, G_2, G_3, G_4, G_5 \\}\n\\]\nThere are \\(5 \\times 4 \\times 3 \\times 2 \\times = 5!\\) ways to pick a girl for each boy. A boy and girl \\((B_i, G_j)\\) within a pair can be further be permuted. Additionally, the person in the first seat can be boy or a girl.\n\\[\np = \\frac{5! 5! 2}{10!}\n\\]\n\nExample 15 A company is hosting a dinner for working mothers who have at least one son. Ms. Jackson, a mother with two children, has been invited to the event. What are the chances that both of her children are boys? In the second part, a new colleague, Ms. Parker, has two children. If you happen to see her walking with one of her children, and the child happens to be a boy, what is the probability that both of her children are boys?\n\nSolution\nThe sample space \\(\\Omega = \\{ GG, GB, BG, BB \\}\\). The probability that both children are boys given that atleast one is a boy is \\(\\frac{1}{3}\\).\nThe probability that both children are boys given that a specific child is a boy is given by\n\\[\n\\begin{align*}\n\\mathbb{P}(\\text{Both are boys} | \\text{Specific child is a boy}) &= P(\\text{Both are boys}|\\text{First is a boy}) \\times P(\\text{First is a boy}) + P(\\text{Both are boys}|\\text{Second is a boy}) \\times P(\\text{Second is a boy})\\\\\n&= \\frac{1}{2} \\times \\frac{1}{2} + \\frac{1}{2} \\times \\frac{1}{2}\\\\\n&= \\frac{1}{2}\n\\end{align*}\n\\]\n\nExample 16 You have been given a thousand coins to study. One of these coins has heads on both sides, while the remaining 999 are fair coins. You pick a coin at random and flip it ten times. To your surprise, the coin turns up heads every time. What is the likelihood that the coin you picked is the one with two heads?\n\nSolution.\nBy Bayes,\n\\[\n\\begin{align*}\nP(\\text{Double head coin}|\\text{10 heads}) &= \\frac{P(\\text{10 heads} \\cap \\text{Double head coin})}{P(\\text{10 heads})}\\\\\n&= \\frac{\\frac{1}{1000}}{P(\\text{10 heads} | \\text{Double head coin}) P(\\text{Double head coin}) + P(\\text{10 heads} | \\text{Fair coin}) P(\\text{Fair coin})} \\\\\n&= \\frac{\\frac{1}{1000}\\cdot 1}{\\frac{1}{1000} \\cdot 1 + \\frac{1}{2^{10}} \\cdot \\frac{999}{1000} }\\\\\n\\approx 0.5061\n\\end{align*}\n\\]\n\nExample 17 You have ten coins. \\(9\\) of them are fair coins and \\(1\\) of them is a coin with two heads. You pick a random coin from the set of coins and flip it five times. All five flips happen to be heads. Given this, what is the probability that the next flip will also be heads?\n\nSolution.\nLet \\(D\\) be the event that a double coin is picked and \\(F\\) be the event that a fair coin was picked. Let \\(E\\) be the event that the next flip is heads. Let \\(S\\) be the event that we get a sequence of \\(5\\)-heads.\nBy Bayes:\n\\[\n\\begin{align*}\nP(E|S) &= \\frac{P(SE)}{P(S)}\\\\\n&= \\frac{P(SE|F) P(F) + P(SE|D) P(D)}{P(S|F)P(F) + P(S|D) P(D)}\\\\\n&= \\frac{\\frac{1}{2^6} \\cdot \\frac{9}{10} + 1\\cdot \\frac{1}{10}}{\\frac{1}{2^5}\\frac{9}{10} + 1 \\cdot \\frac{1}{10}}\\\\\n&= \\frac{73}{82}\n\\approx 0.890243\n\\end{align*}\n\\]\n\nExample 18 You are given n random variables, \\(X_1, X_2 \\ldots, X_N\\). Each of these variables has a uniform distribution that ranges from \\(0\\) to \\(1\\). Your task is to determine the probability that the sum of these variables, denoted as \\(S\\), is less than equal to \\(1\\). Can you solve this problem?\n\nSolution.\nFor \\(N=2\\), \\(\\mathbb{P}[X_1 + X_2 \\leq 1]\\) can be visualized as follows:\n\n\n\nSum of Uniforms\n\n\nThe two uniform random variables can be plotted along two orthogonal axes. Since \\(X_1 \\geq 0\\), \\(X_2 \\geq 0\\) and \\(X_1 + X_2 \\leq 1\\), we are interested in the area of the yellow shaded portion. This should be \\(\\frac{1}{2}\\).\nSimilarly, for \\(N=3\\) random variables, we will be interested in the volume of the tetrahedron, having vertices \\((1,0,0)\\), \\((0,1,0)\\), \\((0,0,1)\\) and \\((0,0,0)\\) which equals \\(\\frac{1}{2\\cdot 3}\\).\nIn general, we posit that the probability that the sum of \\(N\\) uniforms is less than unity is \\(\\frac{1}{N!}\\).\nMore rigorously, the MGF of a uniform random variable is: \\[\n\\begin{align*}\nP(X_1 + X_2 \\leq t) &= \\int_0^t P(X_2 \\leq t - x_1 | X_1 = x_1 ) f_{X_1}(x_1) dx_1 \\\\\n&= \\int_0^t \\int_0^{t-x_1} dx_2 dx_1 \\\\\n&= \\int_0^t (t-x_1) dx_1\\\\\n&= \\left[\\frac{(t-x_1)^2}{2}\\right]_0^t \\\\\n&= \\frac{t^2}{2}\n\\end{align*}\n\\]\nAssume that \\(P(X_1 + \\ldots + X_k \\leq t) = \\frac{t^k}{k!}\\). We are interested to show that \\(P(X_1+ \\ldots + X_{k} + X_{k+1} \\leq t) = \\frac{t^{k+1}}{(k+1)!}\\).\nDefine \\(S_k \\stackrel{def}{=} \\sum_{i=1}^{k} X_k\\). We have:\n\\[\n\\begin{align*}\nP(S_k + X_{k+1} \\leq t) &= \\int_0^t P(S_k \\leq t - x_{k+1} | X_{k+1} = x_{k+1}) f_{X_{k+1}}(x_{k+1}) dx_{k+1}\\\\\n&= \\int_0^t \\frac{(t - x_{k+1})^k}{k!} dx_{k+1}\\\\\n&= \\left[\\frac{(t-x_{k+1})^{k+1}}{(k+1)k!}\\right]_0^t\\\\\n&= \\frac{t^{k+1}}{(k+1)!}\n\\end{align*}\n\\]\n\nExample 19 Person A has a \\(20\\)-sided dice and person B has three \\(6\\)-sided dice. They both roll their dice and whoever gets a bigger number/sum of numbers wins the game. Is it a fair game? Now, what if there is one more player \\(C\\) who has a \\(20\\)-sided dice. Is this new game fair? (all dice are fair; a \\(20\\)-sided dice has number \\(1,2,\\ldots,20\\) on each of its \\(20\\) sides)\n\nSolution\nThe game between is \\(A\\) and \\(B\\) is not fair.\nDefine \\(X_1\\) as the face value on the \\(20\\)-sided die rolled by person A.\nDefine \\(Y_1, Y_2, Y_3\\) as the face values on the three \\(6\\)-sided die rolled by person B.\nDefine \\(S_1 \\stackrel{def}{=} X_1\\), \\(S_2 \\stackrel{def}{=} Y_1 + Y_2 + Y_3\\).\nIt’s a fair game, if the expected cost of playing a game equals the expected winnings. The expected cost for \\(A\\) is expectetaion of \\(B\\) winnings.\n\\[\n\\mathbb{E}[S_1] - \\mathbb{E}[S_2]  = 10.5 - 3 \\times 3.5 = 0\n\\]\n\nExample 20 I keep rolling a die until a \\(6\\) appears. What is the probability the sum of all rolls is even?\n\nSolution.\n\n\n\nEven Sum\n\n\nWe have:\n\\[\n\\begin{align*}\np_{13} &= \\frac{1}{6} \\cdot 1 + \\frac{1}{3} \\cdot p_{13} + \\frac{1}{2} \\cdot p_{23}\\\\\np_{23} &= \\frac{1}{2} \\cdot p_{13} + \\frac{1}{3} \\cdot p_{23} + \\frac{1}{6} \\cdot 0\n\\end{align*}\n\\]\nSo, \\(\\frac{2}{3}p_{23} = \\frac{1}{2}p_{13}\\) which implies \\(p_{23} = \\frac{3}{4}p_{13}\\). Substituting in the first equation, we have:\n\\[\n\\begin{align*}\n\\frac{2}{3}p_{13} &= \\frac{1}{6} + \\frac{1}{2} \\cdot \\frac{3}{4} p_{13} \\\\\n\\frac{7}{24} p_{13} &= \\frac{1}{6}\\\\\np_{13} &= \\frac{4}{7}\n\\end{align*}\n\\]\n\nExample 21 You have two dice, how do you simulate one seventh odds with the two dice? Same way as one third odds with coins.\n\nSolution."
  },
  {
    "objectID": "posts/discrete-probability-and-counting-puzzles/index.html#puzzles-on-discrete-probability",
    "href": "posts/discrete-probability-and-counting-puzzles/index.html#puzzles-on-discrete-probability",
    "title": "Discrete probability and counting puzzles",
    "section": "",
    "text": "Example 1 We flip a fair coin until we obtain our first heads. If the first heads occurs on the \\(k\\)-th flip, we are given \\(k\\) balls. We put them into 3 bins labeled 1, 2, and 3 at random. Find the probability that none of the three bins are empty.\n\nSolution.\nLet \\(A_k\\) be the event that the first head occurs on the \\(k\\)th flip. So, we are interested in the sequence \\(\\underbrace{T \\ldots T}_{(k-1)\\text{-tails}}H\\). We have:\n\\[\n\\mathbb{P}(A_k) = \\left(\\frac{1}{2}\\right)^{k-1} \\cdot \\frac{1}{2} = \\frac{1}{2^k}\n\\]\n\nExample 2 Imagine you have \\(4\\) \\(6\\)-sided dice. What is the probability that you roll a different number on each die?\n\nSolution.\n\\[\np = \\frac{6\\cdot 5 \\cdot 4 \\cdot 3}{6^4}\n\\]\n\nExample 3 What is the probability of flipping exactly \\(5\\) heads when flipping \\(10\\) fair coins?\n\nSolution.\n\\[\nP(k = 5) = {10 \\choose 5} \\frac{1}{2^{10}}\n\\]\n\nExample 4 Two players are at deuce in a tennis match — player \\(1\\) has \\(60\\) percent of winning the point and player \\(2\\) has \\(40\\) percent chance. What are the odds of player 1 winning?\n\nSolution\nWhen a game is at the 40-40 mark, a player still needs two clear points to win the game. We can quickly draw the following state diagram to represent the game (it is a discrete-time markov chain).\n\n\n\nWinning the game\n\n\nLet the state \\(s_1 \\stackrel{def}{=}\\) the two players are 40-40. And the state \\(s_3 \\stackrel{def}{=}\\) player \\(1\\) wins. The states \\(3\\) and \\(5\\) are absorbing states. Let \\(p_{13}\\) be the hitting probability of state \\(3\\) from state \\(1\\). We have:\n\\[\n\\begin{align*}\np_{13} &= 0.6 p_{23} + 0.4 p_{43}\\\\\np_{23} &= 0.6 (1) + 0.4p_{13}\\\\\np_{43} &= 0.6p_{13} + 0.4(0)\n\\end{align*}\n\\]\nIt turns out that \\(p_{13} = \\frac{9}{13}\\).\n\nExample 5 You have a plate of spaghetti in front of you (no sauce!). You pick two ends and tie them together. Then you pick two more ends and tie them together. Continue until there are no free ends left. If there were \\(n\\) spaghettis originally, what is the probability that you now have a single giant loop consisting of all the spaghettis?\n\nLet \\(p_n\\) be the probability of a single giant loop. \\(n\\) spaghettis have \\(2n\\) free ends. In each of the \\(n\\) trials, you pick \\(2\\) ends. At the start, the probability that you don’t tie a sphagetti to itself is\n\\[\n\\frac{2n}{2n} \\cdot \\frac{2n - 2}{2n - 1} = \\frac{2n - 2}{2n - 1}\n\\]\nAfter the first draw, we have reduced the problem to \\((n-1)\\) spaghetti strands and \\(2n-2\\) free ends. So, the probability of no-loops is:\n\\[\np_n =  \\frac{2n - 2}{2n - 1} \\cdot p_{n-1}\n\\]\nExtending this to \\(k=(n-1)\\) trials: \\[\n\\begin{align*}\np_n &= \\frac{2n - 2}{2n - 1} \\cdot \\frac{2n-4}{2n-3} \\cdots \\frac{2}{1}\\\\\n&= 2^{n-1} \\frac{(n-1)!}{(2n-1)(2n-3)\\cdots 1}\\\\\n&= 2^{n-1} \\frac{2^n n! (n-1)!}{(2n)(2n-1)(2n-2)(2n-3) \\cdots 1}\\\\\n&= 2^{2n-1} \\frac{n! (n-1)!}{(2n)!}\\\\\n\\end{align*}\n\\]\n\nExample 6 An electronic safe has a three digit passcode. You are given three constraints regarding the code. Firstly, the code is not an odd number. Secondly, the code does not contain the number six. Lastly, one of the digits appears more than once. How many possible three digit entries satisfy these three requirements?\n\nSolution.\nSince it’s a \\(3\\)-digit electronic passcode to a safe, \\(0\\) is a valid first digit. The last digit must be one of \\(0,2,4,8\\). The first digit must be one of \\(\\{0,1,2,\\ldots,5,7,8,9\\}\\). The middle digit must be must be one of \\(\\{0,1,2,\\ldots,5,7,8,9\\}\\)\nCase I. The first two digits are identical.\nThere are \\(9 \\times 1 \\times 4 = 36\\) such distinguishable codes.\nCase II. The last two digits are identical.\nThere are \\(9 \\times 1 \\times 4 = 36\\) such distinguishable codes.\nCase III. The first and the third digits are identical.\nThere are \\(1 \\times 9 \\times 4 = 36\\) such distinguishable codes.\nAlso, \\(000\\), \\(222\\), \\(444\\) and \\(888\\) have been overcounted \\(3\\) times. They should be accounted for only once. Hence, the number of possible three digit entries satisfying the above requirements are \\(108 - 8 = 100\\).\n\nExample 7 Suppose we roll \\(5\\) standard fair dice and sum the faces of the largest \\(3\\) values showing. Find the probability that the sum is \\(18\\).\n\nSolution.\nTo reach a sum of \\(18\\) on the largest three die faces, we must get atleast \\(3\\) sixes in \\(5\\) dice rolls.\nDefine success as getting a \\(6\\) on a die, \\(p = \\frac{1}{6}\\), \\(q=\\frac{5}{6}\\) and let \\(X\\) be the number of sixes in \\(5\\) die rolls.\n\\[\n\\begin{align*}\nP(X \\ge 3) &= 1 - (P(X=0) + P(X=1) + P(X=2))\\\\\n&= 1 - \\left(\\frac{5}{6}\\right)^5 - {5 \\choose 1} \\left(\\frac{1}{6}\\right)\\left(\\frac{5}{6}\\right)^4 - {5 \\choose 2} \\left(\\frac{1}{6}\\right)^2\\left(\\frac{5}{6}\\right)^3\\\\\n&= \\frac{23}{648}\n\\end{align*}\n\\]\n\nExample 8 Consider a \\(2023 \\times 2023\\) grid. The grid squares from the middle row are shaded in. What is the probability that a randomly selected rectangle contains at least one shaded square?\n\nSolution.\nLet’s solve this puzzle for a smaller \\(5 \\times 5\\) grid. A rectangle is always determined by a choice of a pair of vertical grid lines and a pair of horizonal grid lines.\n\n\n\nRectangles\n\n\nThe number of horizontal and vertical grid lines are \\(6\\). So, the total number of rectangles are \\({6 \\choose 2} \\times {6 \\choose 2}\\).\nIn order to pick rectangle that includes atleast one shaded square, one of the grid lines must chosen from the top \\(3\\) horizontal grid lines and the second grid line must be chosen from the bottom \\(3\\) horizontal grid lines. That yields \\({3 \\choose 1}^2\\) pairs of horizontal grid lines. There are no restrictions on the vertical grid lines so there are \\({6 \\choose 2}\\) pairs of vertical grid lines. Hence, the number of favorable rectangles are \\(3^2 \\times {6 \\choose 2}\\).\nGeneralizing, the desired probability for a \\((2n-1) \\times (2n-1)\\) grid is:\n\\[\n\\begin{align*}\np_{2n-1} &= \\frac{n^2 \\cdot {2n \\choose 2}}{{2n \\choose 2}^2} \\\\\n&= \\frac{n^2 }{{2n \\choose 2}} \\\\\n&= \\frac{2n^2}{(2n)(2n-1)}\\\\\n&= \\frac{n}{2n-1}\n\\end{align*}\n\\]\nSo, \\(p_{2023} = \\frac{1012}{2023} \\approx 0.5\\).\n\nExample 9 How many paths are there where you can only move up or right one unit at each step that go from \\((0, 0)\\) to \\((5, 3)\\) without crossing the line \\(y = x\\)? You are allowed to touch it.\n\nWe are interested in those paths where each vertice on the trajectory has \\(x\\) coordinate greater than or equal to the \\(y\\)- coordinate.\n\nExample 10 How many paths are there where you can only move up or right one unit at each step that go from \\((0, 0)\\) to \\((5, 3)\\) without crossing the line \\(y = x\\)? You are allowed to touch it.\n\n\nExample 11 Imagine 3 pairs of socks (6 total) labeled \\(\\{1,1,2,2,3,3\\}\\). Define a satisfactory pair as any pair of individual socks such that their numbers differ by a maximum of 1 (i.e. 2 3 is a satisfactory pair). In this game, drawing without replacement, what is the probability that a player will draw three satisfactory pairs of socks?\n\nSolution.\nLabel the socks as\n\\[\n\\{a_1, a_2, b_1, b_2, c_1, c_2\\}\n\\]\nArrangements with \\(3\\) satisfactory pairs are only obtained, if there are no pairs where a 1-sock is paired with a 3-sock. Let us find the number of arrangements, where there is atleast \\(1\\) pair containing a 1-sock paired with a 3-sock.\nThe number of distinguishable arrangements where the first pair has a 1-sock paired with a 3-sock are given as follows. There are \\(2\\) possible choices for the 1-sock, \\(2\\) possible choices for the \\(3\\)-sock, \\(2\\) possible arrangements within this pair. For each such choice, there are \\(4!\\) choices for second and third pairs of socks. So, the result is \\(2 \\times 2 \\times 2 \\times 4! = 192\\). By similar arguments, the number of arrangements with the second pair/third pair containing a 1-sock and 3-sock are \\(192\\) each. So, the total number of distinct arrangements are \\(192 \\times 3 = 576\\).\nHowever, we overcounted the arrangements that have two (\\(1\\)-sock,\\(3\\)-sock) pairs. The number of arrangements where the first and second pair are (\\(1\\)-sock,\\(3\\)-sock) pairs is \\(2 \\times 2 \\times 2 \\times 1 \\times 2 = 16\\). The three pairs can be arrangement amongst themselves in \\(3! = 6\\) ways. So, the total number of distinct arrangements are \\(96\\).\nBy inclusion-exclusion, the number of arrangments with atleast one (\\(1\\)-sock, \\(3\\)-sock) pair = \\(576 - 96 = 480\\). Thus, the number of satisfactory arrangments is \\(720 - 480 = 240\\).\nThe probability of \\(3\\) satisfactory pairs = \\(\\frac{240}{720}=\\frac{1}{3}\\)\n\nExample 12 Player M has \\(1\\) dollar and player N has \\(2\\) dollars. Each game gives the winner $1 from the other. As a better player, M wins \\(2/3\\) of the games. They play until one of them is bankrupt. What Is the probability that M wins?\n\nSolution.\n\n\n\nWinning the game\n\n\nLet \\(p_{1W}\\) be the hitting probability of state \\(W\\) given we are in state \\(1\\). We can quickly setup:\n\\[\n\\begin{align*}\np_{1W} &= \\frac{2}{3}p_{2W}  + \\frac{1}{3} \\times 0\np_{2W} &= \\frac{1}{3}p_{1W} + \\frac{2}{3} \\times 1\n\\end{align*}\n\\]\nSo, we get:\n\\[\n\\begin{align*}\np_{1W} &= \\frac{2}{3}\\left(\\frac{1}{3}p_{1W} + \\frac{2}{3}\\right)\\\\\n&= \\frac{2}{9} p_{1W} + \\frac{4}{9}\\\\\n\\frac{7}{9}p_{1W} &= \\frac{4}{9}\\\\\np_{1W} &= \\frac{4}{7}\n\\end{align*}\n\\]\n\nExample 13 We throw \\(3\\) dice one by one. What is the probability that we obtain 3 points in strictly increasing order?\n\nSolution.\nWe can choose a sub-population of \\(3\\) numbers without ordering from a population of \\(n=6\\) in \\({6 \\choose 3}\\) ways. For each selection, there is only one unique way to order them in strictly increasing order. Hence, the number of dice rolls where the points are in strictly increasing order are:\n\\[\n\\frac{{6 \\choose 3}}{6^3} = \\frac{20}{216}\n\\]\n\nExample 14 Five boys and five girls are seated in a row at the movie theater. To ensure that the children are engaged during the movie, the teacher mandates that no two children of the same gender can sit next to each other. How many arrangements are possible?\n\nSolution.\nWe label the set of boys and girls as\n\\[\n\\{B_1, B_2, B_3, B_4, B_5, G_1, G_2, G_3, G_4, G_5 \\}\n\\]\nThere are \\(5 \\times 4 \\times 3 \\times 2 \\times = 5!\\) ways to pick a girl for each boy. A boy and girl \\((B_i, G_j)\\) within a pair can be further be permuted. Additionally, the person in the first seat can be boy or a girl.\n\\[\np = \\frac{5! 5! 2}{10!}\n\\]\n\nExample 15 A company is hosting a dinner for working mothers who have at least one son. Ms. Jackson, a mother with two children, has been invited to the event. What are the chances that both of her children are boys? In the second part, a new colleague, Ms. Parker, has two children. If you happen to see her walking with one of her children, and the child happens to be a boy, what is the probability that both of her children are boys?\n\nSolution\nThe sample space \\(\\Omega = \\{ GG, GB, BG, BB \\}\\). The probability that both children are boys given that atleast one is a boy is \\(\\frac{1}{3}\\).\nThe probability that both children are boys given that a specific child is a boy is given by\n\\[\n\\begin{align*}\n\\mathbb{P}(\\text{Both are boys} | \\text{Specific child is a boy}) &= P(\\text{Both are boys}|\\text{First is a boy}) \\times P(\\text{First is a boy}) + P(\\text{Both are boys}|\\text{Second is a boy}) \\times P(\\text{Second is a boy})\\\\\n&= \\frac{1}{2} \\times \\frac{1}{2} + \\frac{1}{2} \\times \\frac{1}{2}\\\\\n&= \\frac{1}{2}\n\\end{align*}\n\\]\n\nExample 16 You have been given a thousand coins to study. One of these coins has heads on both sides, while the remaining 999 are fair coins. You pick a coin at random and flip it ten times. To your surprise, the coin turns up heads every time. What is the likelihood that the coin you picked is the one with two heads?\n\nSolution.\nBy Bayes,\n\\[\n\\begin{align*}\nP(\\text{Double head coin}|\\text{10 heads}) &= \\frac{P(\\text{10 heads} \\cap \\text{Double head coin})}{P(\\text{10 heads})}\\\\\n&= \\frac{\\frac{1}{1000}}{P(\\text{10 heads} | \\text{Double head coin}) P(\\text{Double head coin}) + P(\\text{10 heads} | \\text{Fair coin}) P(\\text{Fair coin})} \\\\\n&= \\frac{\\frac{1}{1000}\\cdot 1}{\\frac{1}{1000} \\cdot 1 + \\frac{1}{2^{10}} \\cdot \\frac{999}{1000} }\\\\\n\\approx 0.5061\n\\end{align*}\n\\]\n\nExample 17 You have ten coins. \\(9\\) of them are fair coins and \\(1\\) of them is a coin with two heads. You pick a random coin from the set of coins and flip it five times. All five flips happen to be heads. Given this, what is the probability that the next flip will also be heads?\n\nSolution.\nLet \\(D\\) be the event that a double coin is picked and \\(F\\) be the event that a fair coin was picked. Let \\(E\\) be the event that the next flip is heads. Let \\(S\\) be the event that we get a sequence of \\(5\\)-heads.\nBy Bayes:\n\\[\n\\begin{align*}\nP(E|S) &= \\frac{P(SE)}{P(S)}\\\\\n&= \\frac{P(SE|F) P(F) + P(SE|D) P(D)}{P(S|F)P(F) + P(S|D) P(D)}\\\\\n&= \\frac{\\frac{1}{2^6} \\cdot \\frac{9}{10} + 1\\cdot \\frac{1}{10}}{\\frac{1}{2^5}\\frac{9}{10} + 1 \\cdot \\frac{1}{10}}\\\\\n&= \\frac{73}{82}\n\\approx 0.890243\n\\end{align*}\n\\]\n\nExample 18 You are given n random variables, \\(X_1, X_2 \\ldots, X_N\\). Each of these variables has a uniform distribution that ranges from \\(0\\) to \\(1\\). Your task is to determine the probability that the sum of these variables, denoted as \\(S\\), is less than equal to \\(1\\). Can you solve this problem?\n\nSolution.\nFor \\(N=2\\), \\(\\mathbb{P}[X_1 + X_2 \\leq 1]\\) can be visualized as follows:\n\n\n\nSum of Uniforms\n\n\nThe two uniform random variables can be plotted along two orthogonal axes. Since \\(X_1 \\geq 0\\), \\(X_2 \\geq 0\\) and \\(X_1 + X_2 \\leq 1\\), we are interested in the area of the yellow shaded portion. This should be \\(\\frac{1}{2}\\).\nSimilarly, for \\(N=3\\) random variables, we will be interested in the volume of the tetrahedron, having vertices \\((1,0,0)\\), \\((0,1,0)\\), \\((0,0,1)\\) and \\((0,0,0)\\) which equals \\(\\frac{1}{2\\cdot 3}\\).\nIn general, we posit that the probability that the sum of \\(N\\) uniforms is less than unity is \\(\\frac{1}{N!}\\).\nMore rigorously, the MGF of a uniform random variable is: \\[\n\\begin{align*}\nP(X_1 + X_2 \\leq t) &= \\int_0^t P(X_2 \\leq t - x_1 | X_1 = x_1 ) f_{X_1}(x_1) dx_1 \\\\\n&= \\int_0^t \\int_0^{t-x_1} dx_2 dx_1 \\\\\n&= \\int_0^t (t-x_1) dx_1\\\\\n&= \\left[\\frac{(t-x_1)^2}{2}\\right]_0^t \\\\\n&= \\frac{t^2}{2}\n\\end{align*}\n\\]\nAssume that \\(P(X_1 + \\ldots + X_k \\leq t) = \\frac{t^k}{k!}\\). We are interested to show that \\(P(X_1+ \\ldots + X_{k} + X_{k+1} \\leq t) = \\frac{t^{k+1}}{(k+1)!}\\).\nDefine \\(S_k \\stackrel{def}{=} \\sum_{i=1}^{k} X_k\\). We have:\n\\[\n\\begin{align*}\nP(S_k + X_{k+1} \\leq t) &= \\int_0^t P(S_k \\leq t - x_{k+1} | X_{k+1} = x_{k+1}) f_{X_{k+1}}(x_{k+1}) dx_{k+1}\\\\\n&= \\int_0^t \\frac{(t - x_{k+1})^k}{k!} dx_{k+1}\\\\\n&= \\left[\\frac{(t-x_{k+1})^{k+1}}{(k+1)k!}\\right]_0^t\\\\\n&= \\frac{t^{k+1}}{(k+1)!}\n\\end{align*}\n\\]\n\nExample 19 Person A has a \\(20\\)-sided dice and person B has three \\(6\\)-sided dice. They both roll their dice and whoever gets a bigger number/sum of numbers wins the game. Is it a fair game? Now, what if there is one more player \\(C\\) who has a \\(20\\)-sided dice. Is this new game fair? (all dice are fair; a \\(20\\)-sided dice has number \\(1,2,\\ldots,20\\) on each of its \\(20\\) sides)\n\nSolution\nThe game between is \\(A\\) and \\(B\\) is not fair.\nDefine \\(X_1\\) as the face value on the \\(20\\)-sided die rolled by person A.\nDefine \\(Y_1, Y_2, Y_3\\) as the face values on the three \\(6\\)-sided die rolled by person B.\nDefine \\(S_1 \\stackrel{def}{=} X_1\\), \\(S_2 \\stackrel{def}{=} Y_1 + Y_2 + Y_3\\).\nIt’s a fair game, if the expected cost of playing a game equals the expected winnings. The expected cost for \\(A\\) is expectetaion of \\(B\\) winnings.\n\\[\n\\mathbb{E}[S_1] - \\mathbb{E}[S_2]  = 10.5 - 3 \\times 3.5 = 0\n\\]\n\nExample 20 I keep rolling a die until a \\(6\\) appears. What is the probability the sum of all rolls is even?\n\nSolution.\n\n\n\nEven Sum\n\n\nWe have:\n\\[\n\\begin{align*}\np_{13} &= \\frac{1}{6} \\cdot 1 + \\frac{1}{3} \\cdot p_{13} + \\frac{1}{2} \\cdot p_{23}\\\\\np_{23} &= \\frac{1}{2} \\cdot p_{13} + \\frac{1}{3} \\cdot p_{23} + \\frac{1}{6} \\cdot 0\n\\end{align*}\n\\]\nSo, \\(\\frac{2}{3}p_{23} = \\frac{1}{2}p_{13}\\) which implies \\(p_{23} = \\frac{3}{4}p_{13}\\). Substituting in the first equation, we have:\n\\[\n\\begin{align*}\n\\frac{2}{3}p_{13} &= \\frac{1}{6} + \\frac{1}{2} \\cdot \\frac{3}{4} p_{13} \\\\\n\\frac{7}{24} p_{13} &= \\frac{1}{6}\\\\\np_{13} &= \\frac{4}{7}\n\\end{align*}\n\\]\n\nExample 21 You have two dice, how do you simulate one seventh odds with the two dice? Same way as one third odds with coins.\n\nSolution."
  },
  {
    "objectID": "posts/continuous_probability_puzzles/index.html",
    "href": "posts/continuous_probability_puzzles/index.html",
    "title": "Continuous probability puzzles",
    "section": "",
    "text": "Example 1 What is the maximum possible variance of a random variable that takes the values in the set \\([-1,1]\\)?\n\nSolution.\nIntuitively speaking, the variance of a mass distribution is the probability weighted average of the sum of the squared distances from the mean. It is maximized if the masses are placed far away from the center of gravity. So, if we place two point masses with probability weights \\(1/2\\) at \\((-1,0)\\) and \\((1,0)\\), the variance would be maximal. Hence, the maximum variance equals \\(1\\).\n\nExample 2 What is the maximum possible variance of a random variable that takes the values in the set \\([0,1]\\)?\n\nSolution.\nAgain, we can have point masses with probability weights \\(1/2\\) at \\(X=0\\) and \\(X=1\\). The center of mass or expectation of this distribution \\(EX = 1/2\\). So, the maximal variance would be \\((1/2)(1/2)^2 + (1/2)(1/2)^2=1/4\\).\n\nExample 3 Let \\(X\\) be a random variable such that \\(P(X \\ne 0) &gt; 0\\). Suppose that for some real numbers \\(a\\) and \\(b\\), the random variables \\(aX\\) and \\(bX\\) have the same distribution. Is it true that \\(a = b\\)? What if we also assume that \\(a\\) and \\(b\\) are both positive.\n\nSolution.\nIf \\(aX\\) and \\(bX\\) have the same mass distribution, they have the same expectation and variance.\nHence, \\(\\mathbb{E}[aX] = \\mathbb{E}[bX]\\). So, \\(a\\mathbb{E}[X] = b \\mathbb{E}[X]\\). Consequently, \\((a-b)\\mathbb{E}[X] = 0\\). If \\(a \\neq b\\), then \\(\\mathbb{E}[X] = 0\\). For example, consider the \\(U \\sim U[-1,1]\\) random variable. Both \\(U\\) and \\(-U\\) have the same distribution. Also, their second moments must match. So, \\(\\mathbb{E}[aX\\)"
  },
  {
    "objectID": "posts/continuous_probability_puzzles/index.html#puzzles-on-continuous-probability",
    "href": "posts/continuous_probability_puzzles/index.html#puzzles-on-continuous-probability",
    "title": "Continuous probability puzzles",
    "section": "",
    "text": "Example 1 What is the maximum possible variance of a random variable that takes the values in the set \\([-1,1]\\)?\n\nSolution.\nIntuitively speaking, the variance of a mass distribution is the probability weighted average of the sum of the squared distances from the mean. It is maximized if the masses are placed far away from the center of gravity. So, if we place two point masses with probability weights \\(1/2\\) at \\((-1,0)\\) and \\((1,0)\\), the variance would be maximal. Hence, the maximum variance equals \\(1\\).\n\nExample 2 What is the maximum possible variance of a random variable that takes the values in the set \\([0,1]\\)?\n\nSolution.\nAgain, we can have point masses with probability weights \\(1/2\\) at \\(X=0\\) and \\(X=1\\). The center of mass or expectation of this distribution \\(EX = 1/2\\). So, the maximal variance would be \\((1/2)(1/2)^2 + (1/2)(1/2)^2=1/4\\).\n\nExample 3 Let \\(X\\) be a random variable such that \\(P(X \\ne 0) &gt; 0\\). Suppose that for some real numbers \\(a\\) and \\(b\\), the random variables \\(aX\\) and \\(bX\\) have the same distribution. Is it true that \\(a = b\\)? What if we also assume that \\(a\\) and \\(b\\) are both positive.\n\nSolution.\nIf \\(aX\\) and \\(bX\\) have the same mass distribution, they have the same expectation and variance.\nHence, \\(\\mathbb{E}[aX] = \\mathbb{E}[bX]\\). So, \\(a\\mathbb{E}[X] = b \\mathbb{E}[X]\\). Consequently, \\((a-b)\\mathbb{E}[X] = 0\\). If \\(a \\neq b\\), then \\(\\mathbb{E}[X] = 0\\). For example, consider the \\(U \\sim U[-1,1]\\) random variable. Both \\(U\\) and \\(-U\\) have the same distribution. Also, their second moments must match. So, \\(\\mathbb{E}[aX\\)"
  },
  {
    "objectID": "posts/gaussian-processes/index.html",
    "href": "posts/gaussian-processes/index.html",
    "title": "Gaussian Processes",
    "section": "",
    "text": "Consider a probability space \\((\\Omega,\\mathcal{F},\\mathbb{P})\\). We can define several random variables on \\(\\Omega\\). A \\(n\\)-tuple of random variables on this space is called a random vector. For example, if \\(X_{1},X_{2},\\ldots,X_{n}\\) are random variables on \\((\\Omega,\\mathcal{F},\\mathbb{P})\\), then the \\(n\\)-tuple \\((X_{1},X_{2},\\ldots,X_{n})\\) is a random vector on \\((\\Omega,\\mathcal{F},\\mathbb{P})\\). The vector is said to be \\(n\\)-dimensional because it contains \\(n\\)-variables. We will sometimes denote a random vector by \\(X\\).\nA good point of view is to think of a random vector \\(X=(X_{1},\\ldots,X_{n})\\) as a random variable (point) in \\(\\mathbf{R}^{n}\\). In other words, for an outcome \\(\\omega\\in\\Omega\\), \\(X(\\omega)\\) is a point sampled in \\(\\mathbf{R}^{n}\\), where \\(X_{j}(\\omega)\\) represents the \\(j\\)-th coordinate of the point. The distribution of \\(X\\), denoted \\(\\mu_{X}\\) is the probability on \\(\\mathbf{R}^{n}\\)defined by the events related to the values of \\(X\\):\n\\[\\mathbb{P}\\{X\\in A\\}=\\mu_{X}(A)\\quad\\text{for a subset }A\\text{ in }\\mathbf{R}^{n}\\]\nIn other words, \\(\\mathbb{P}(X\\in A)=\\mu_{X}(A)\\) is the probability that the random point \\(X\\) falls in \\(A\\). The distribution of the vector \\(X\\) is also called the joint distribution of \\((X_{1},\\ldots,X_{n})\\).\n\nDefinition 1 (Joint Distribution) The joint distribution function of \\(\\mathbf{X}=(X,Y)\\) is the function \\(F:\\mathbf{R}^{2}\\to[0,1]\\) given by:\n\\[F_{\\mathbf{X}}(x,y)=\\mathbb{P}(X\\leq x,Y\\leq y)\\]\n\n\nDefinition 2 (Joint density) The joint PDF \\(f_{\\mathbf{X}}(x_{1},\\ldots,x_{n})\\) of a random vector \\(\\mathbf{X}\\) is a function \\(f_{\\mathbf{X}}:\\mathbf{R}^{n}\\to\\mathbf{R}\\) such that the probability that \\(X\\) falls in a subset \\(A\\) of \\(\\mathbf{R}^{n}\\) and is expressed as the multiple integral of \\(f(x_{1},x_{2,}\\ldots,x_{n})\\) over \\(A\\).\n\\[\\mathbb{P}(X\\in A)=\\int_{A}f(x_{1},x_{2},\\ldots,x_{n})dx_{1}dx_{2}\\ldots dx_{n}\\]\n\nNote that: we must have that the integral of \\(f\\) over the whole of \\(\\mathbf{R}^{n}\\) is \\(1\\).\nIf \\(F\\) is differentiable at the point \\((x,y)\\), then we usually specify:\n\\[f(x,y)=\\frac{\\partial^{2}}{\\partial x\\partial y}F(x,y)\\]\n\nTheorem 1 (Law of total probability) Let \\((X,Y)\\) be the random variables with joint density function \\(f_{X,Y}(x,y)\\). The marginal density function \\(f_{X}(x)\\) and \\(f_{Y}(y)\\) of the random variables \\(X\\) and \\(Y\\) respectively is given by:\n\\[\\begin{aligned}\nf_{X}(x) & =\\int_{-\\infty}^{+\\infty}f_{(X,Y)}(x,y)dy\\\\ f_{Y}(y) & =\\int_{-\\infty}^{+\\infty}f_{(X,Y)}(x,y)dx\\end{aligned}\\]\n\nProof.\nWe have:\n\\[\\begin{aligned}\nF_{X}(x) & =P(X\\leq x)\\\\ & =\\int_{-\\infty}^{x}\\int_{y=-\\infty}^{y=+\\infty}f(x,y)dydx\\end{aligned}\\]\nDifferentiating both sides with respect to \\(x\\),\n\\[\\begin{aligned}\nf_{X}(x) & =\\int_{y=-\\infty}^{y=+\\infty}f(x,y)dydx\\end{aligned}\\] \nThis closes the proof. \\(\\blacksquare\\)\n\nDefinition 3 (Conditional density function) For continuous random variables \\(X\\) and \\(Y\\) with the joint density function \\(f_{(X,Y)}\\), the conditional density of \\(Y\\) given \\(X=x\\) is:\n\\[\\begin{aligned}\nf_{Y|X}(y|x) & =\\frac{f_{(X,Y)}(x,y)}{f_{X}(x)}\\end{aligned}\\]\nfor all \\(x\\) with \\(f_{X}(x)&gt;0\\). This is considered as a function of \\(y\\) for a fixed \\(x\\). As a convention, in order to make \\(f_{Y|X}(y|x)\\) well-defined for all real \\(x\\), let \\(f_{Y|X}(y|x)=0\\) for all \\(x\\) with \\(f_{X}(x)=0\\).\n\nWe are essentially slicing the the joint density function of \\(f_{(X,Y)}(x,y)\\) by a thin plane \\(X=x\\). How can we speak of conditioning on \\(X=x\\) for \\(X\\) being a continuous random variable, considering that this event has probability zero. Rigorously speaking, we are actually conditioning on the event that \\(X\\) falls within a small interval containing \\(x\\), say \\(X\\in(x-\\epsilon,x+\\epsilon)\\) and then taking the limit as \\(\\epsilon\\) approaches zero from the right.\nWe can recover the joint PDF \\(f_{(X,Y)}\\) if we have the conditional PDF \\(f_{Y|X}\\) and the corresponding marginal \\(f_{X}\\):\n\\[\n\\begin{aligned}\nf_{(X,Y)}(x,y) & =f_{Y|X}(y|x)\\cdot f_{X}(x)\n\\end{aligned}\n\\]\n\nTheorem 2 (Bayes rule and LOTP) Let \\((X,Y)\\) be continuous random variables. We have the following continuous form of the Bayes rule:\n\\[f_{Y|X}(y|x)=\\frac{f_{X|Y}(x|y)\\cdot f_{Y}(y)}{f_{X}(x)}\\]\nAnd we have the following continuous form of the law of total probability:\n\\[\\begin{aligned}\nf_{X}(x) & =\\int_{y=-\\infty}^{y=+\\infty}f_{X|Y}(x|y)\\cdot f_{Y}(y)dy\\end{aligned}\\]\n\nProof.\nBy the definition of conditional PDFs, we have:\n\\[\n\\begin{aligned}\nf_{X|Y}(x|y)\\cdot f_{Y}(y) & =f_{(X,Y)}(x,y)=f_{Y|X}(y|x)\\cdot f_{X}(x)\\end{aligned}\n\\]\nDividing throughout by \\(f_{X}(x)\\), we have:\n\\[\n\\begin{aligned}\nf_{Y|X}(x) & =\\frac{f_{X|Y}(x|y)\\cdot f_{Y}(y)}{f_{X}(x)}=\\frac{f_{(X,Y)}(x,y)}{f_{X}(x)}\\end{aligned}\n\\] \nThis closes the proof. \\(\\blacksquare\\)\n\nExample 1 (Sampling uniformly in the unit disc). Consider the random vector \\(\\mathbf{X}=(X,Y)\\) corresponding to a random point chosen uniformly in the unit disc \\(\\{(x,y):x^{2}+y^{2}\\leq1\\}\\). \\(\\mathbf{X}\\) is said to have uniform on the unit circle distribution. In this case the PDF is \\(0\\) outside the disc and \\(\\frac{1}{\\pi}\\) inside the disc:\n\\[\\begin{aligned}\nf(x,y) & =\\frac{1}{\\pi}\\quad\\text{ if }x^{2}+y^{2}\\leq1\\end{aligned}\\]\nThe random point \\((X,Y)\\) has \\(x\\)-coordinate \\(X\\) and \\(Y\\) coordinate \\(Y\\). Each of these are random variables and their PDFs and CDFs can be computed. This is a valid PDF, because:\n\\[\\begin{aligned}\n\\int\\int_{D}f(x,y)dydx & =\\int_{-1}^{1}\\int_{-\\sqrt{1-x^{2}}}^{\\sqrt{1-x^{2}}}\\frac{1}{\\pi}dydx\\\\ & =\\frac{1}{\\pi}\\int_{-1}^{1}\\left[y\\right]_{-\\sqrt{1-x^{2}}}^{+\\sqrt{1-x^{2}}}dx\\\\ & =\\frac{2}{\\pi}\\int_{-1}^{1}\\sqrt{1-x^{2}}dx\\end{aligned}\\]\nSubstituting \\(x=\\sin\\theta\\), we have: \\(dx=\\cos\\theta d\\theta\\) and \\(\\sqrt{1-x^{2}}=\\cos\\theta\\). The limits of integration are \\(\\theta=-\\pi/2\\) to \\(\\theta=\\pi/2\\). Thus,\n\\[\\begin{aligned}\n\\int\\int_{D}f(x,y)dydx & =\\frac{2}{\\pi}\\int_{-\\pi/2}^{\\pi/2}\\cos^{2}\\theta d\\theta\\\\ & =\\frac{1}{\\pi}\\int_{-\\pi/2}^{\\pi/2}(1+\\cos2\\theta)d\\theta\\\\ & =\\frac{1}{\\pi}\\left[\\theta+\\frac{1}{2}\\sin2\\theta\\right]_{-\\pi/2}^{\\pi/2}\\\\ & =\\frac{1}{\\pi}\\cdot\\pi\\\\ & =1\\end{aligned}\\]\nThe CDF of \\(X\\) is given by:\n\\[\\begin{aligned}\nF_{X}(a) & =\\int_{-1}^{a}\\int_{-\\sqrt{1-x^{2}}}^{\\sqrt{1-x^{2}}}\\frac{1}{\\pi}dydx\\\\ & =\\frac{2}{\\pi}\\int_{-1}^{a}\\sqrt{1-x^{2}}dx\\end{aligned}\\]\nI leave it in this integral form. The PDF of \\(X\\) is obtained by differentiating the CDF, so it is:\n\\[f_{X}(x)=\\frac{2}{\\pi}\\sqrt{1-x^{2}}\\label{eq:marginal-pdf-of-X}\\]\n\nLet’s quickly plot the density of \\(X\\) over the domain of the definition \\(-1\\leq x\\leq1\\).\n::: center Figure. The PDF of the random variable \\(X\\). :::\nNot suprisingly the distribution of the \\(x\\)-coordinate is no longer uniform!\nIf \\((X_{1},X_{2},\\ldots,X_{n})\\) is a random vector, the distribution of a single coordinate, say \\(X_{1}\\) is called the marginal distribution. In the example [Uniform-on-the-unit-circle-distribution], the marginal distribution of \\(X\\) is determined by the PDF [eq:marginal-pdf-of-X].\nRandom variables \\(X_{1},X_{2},\\ldots,X_{n}\\) defined on the same probability space are said to be independent if for any intervals \\(A_{1},A_{2},\\ldots,A_{n}\\) in \\(\\mathbf{R}\\), the probability factors:\n\\[\\mathbb{P}(X_{1}\\in A_{1},X_{2}\\in A_{2},\\ldots,X_{n}\\in A_{n})=\\mathbb{P}(X_{1}\\in A_{1})\\times\\mathbb{P}(X_{2}\\in A_{2})\\times\\ldots\\times\\mathbb{P}(X_{n}\\in A_{n})\\] We say that the random variables are independent and identically distributed (IID) if they are independent and their marginal distributions are the same.\nWhen the random vector \\((X_{1},X_{2},\\ldots,X_{n})\\) has a joint PDF \\(f(x_{1},x_{2},\\ldots,x_{n})\\), the independence of random variables is equivalent to saying that the joint PDF is given by the product of the marginal PDFs:\n\\[f(x_{1},x_{2},\\ldots,x_{n})=f_{1}(x_{1})\\times f_{2}(x_{2})\\times\\ldots\\times f_{n}(x_{n})\\]\n\n\n\nInequalities are extremely useful tools in the theoretical development of probability theory.\n\n\n\nTheorem 3 If \\(g\\) is a convex function, and \\(a&gt;0\\), \\(b&gt;0\\), with \\(p\\in[0,1]\\), it follows that:\n\\[g(pa+(1-p)b)\\leq pg(a)+(1-p)g(b)\\]\n\nProof. This directly follows from the definition of convex functions. \\(\\blacksquare\\)\n\n\n\n\nTheorem 4 If \\(g\\) is a convex function, then it follows that:\n\\[\\mathbb{E}(g(X))\\geq g(\\mathbb{E}X)\\]\n\nProof.\nAnother way to express the idea, that a function is convex is to observe that the tangent line at an arbitrary point \\((t,g(t))\\) always lies below the curve. Let \\(y=a+bx\\) be the tangent to \\(g\\) at the point \\(t\\). Then, it follows that:\n\\[\\begin{aligned}\na+bt & =g(t)\\\\ a+bx & \\leq g(x)\\end{aligned}\\]\nfor all \\(x\\).\nThus, it follows that, for any point \\(t\\), there exists \\(b\\) such that:\n\\[\\begin{aligned}\ng(x)-g(t) & \\geq b(x-t)\\end{aligned}\\]\nfor all \\(x\\). Set \\(t=\\mathbb{E}X\\) and \\(x=X\\). Then,\n\\[\\begin{aligned}\ng(X)-g(\\mathbb{E}X) & \\geq b(X-\\mathbb{E}X)\\end{aligned}\\]\nTaking expectations on both sides and simplifying:\n\\[\\begin{aligned}\n\\mathbb{E}\\left(g(X)\\right)-g(\\mathbb{E}X) & \\geq b(\\mathbb{E}X-\\mathbb{E}X)=0\\\\ \\mathbb{E}g(X) & \\geq g(\\mathbb{E}X)\\end{aligned}\\] \nThis closes the proof. \\(\\blacksquare\\)\n\n\n\n\nTheorem 5 If \\(a\\geq0\\) and \\(b\\geq0\\) are non-negative real numbers and if \\(p&gt;1\\) and \\(q&gt;1\\) are real numbers such that \\(\\frac{1}{p}+\\frac{1}{q}=1\\), then:\n\\[ab\\leq\\frac{a^{p}}{p}+\\frac{b^{q}}{q}\\]\n\nProof.\nConsider \\(g(x)=\\log x\\). Being a concave function, Jensen’s inequality can be reversed. We have:\n\\[\\begin{aligned}\ng\\left(\\frac{1}{p}a^{p}+\\frac{1}{q}b^{q}\\right) & \\geq\\frac{1}{p}g(a^{p})+\\frac{1}{q}g(b^{q})\\\\ \\log\\left(\\frac{1}{p}a^{p}+\\frac{1}{q}b^{q}\\right) & \\geq\\frac{1}{p}\\log(a^{p})+\\frac{1}{q}\\log(b^{q})\\\\ \\log\\left(\\frac{1}{p}a^{p}+\\frac{1}{q}b^{q}\\right) & \\geq\\frac{1}{p}\\cdot p\\log(a)+\\frac{1}{q}\\cdot q\\log(b)\\\\ \\log\\left(\\frac{1}{p}a^{p}+\\frac{1}{q}b^{q}\\right) & \\geq\\log ab\\end{aligned}\\]\nBy the Monotonicity of the \\(\\log x\\) function, it follows that :\n\\[\\begin{aligned}\nab & \\leq\\frac{a^{p}}{p}+\\frac{b^{q}}{q}\\end{aligned}\\] \nThis closes the proof. \\(\\blacksquare\\)\n\n\n\nOne of the simplest and very useful probabilistic inequalities is a tail bound by expectation: the so called Chebyshev’s inequality.\n\nTheorem 6 (Chebyshev’s inequality) If \\(X\\) is a non-negative random variable, then for every \\(t\\geq0\\):\n\\[\\mathbb{P}(X\\geq t)\\leq\\frac{1}{t}\\mathbb{E}X\\]\n\nProof.\nWe have:\n\\[\\begin{aligned}\nt\\cdot\\mathbf{1}_{\\{X\\geq t\\}} & \\leq X\\cdot\\mathbf{1}_{\\{X\\geq t\\}}\\end{aligned}\\]\nBy the monotonicity of expectations, we have:\n\\[\\begin{aligned}\n\\mathbb{E}\\mathbf{1}_{\\{X\\geq t\\}} & \\leq\\frac{1}{t}\\mathbb{E}X\\\\ \\implies\\mathbb{P}\\{X\\geq t\\} & \\leq\\frac{1}{t}\\mathbb{E}X\\end{aligned}\\]\nThis closes the proof. \\(\\blacksquare\\)\nThere are several variants, easily deduced from Chebyshev’s inequality using monotonicity of several functions. For a non-negative random variable \\(X\\) and \\(t&gt;0\\), using the power function \\(x^{p}\\), \\(p&gt;0\\), we get:\n\\[\\mathbb{P}(X\\geq t)=\\mathbb{P}(X^{p}\\geq t^{p})\\leq\\frac{1}{t^{p}}\\mathbb{E}X^{p}\\]\nFor a real valued random variable \\(X\\), every \\(t\\in\\mathbf{R}\\), using the square function \\(x^{2}\\) and variance, we have:\n\\[\\mathbb{P}(|X-\\mathbb{E}X|\\geq t)\\leq\\frac{1}{t^{2}}\\mathbb{E}|X-\\mathbb{E}X|^{2}=\\frac{1}{t^{2}}Var(X)\\]\nFor a real-valued random variable \\(X\\), every \\(t\\in\\mathbf{R}\\) and \\(\\lambda&gt;0\\), using the exponential function \\(e^{\\lambda x}\\)(which is monotonic), we have:\n\\[\\mathbb{P}(X\\geq t)=\\mathbb{P}(\\lambda X\\geq\\lambda t)=\\mathbb{P}(e^{\\lambda X}\\geq e^{\\lambda t})\\leq\\frac{1}{e^{\\lambda t}}\\mathbb{E}e^{\\lambda X}\\]\nOur next inequality, the so-called Holder’s inequality is a very effective inequality to factor out the expectation of a product.\n\n\n\n\nTheorem 7 Let \\(p,q\\geq1\\) be such that \\(\\frac{1}{p}+\\frac{1}{q}=1\\), For random variables \\(X\\) and \\(Y\\), we have:\n\\[\\begin{aligned}\n\\mathbb{E}|XY| & \\leq\\left(\\mathbb{E}|X^{p}|\\right)^{1/p}\\left(\\mathbb{E}|Y^{q}|\\right)^{1/q}\\end{aligned}\\]\n\nProof. From the Young’s inequality, for any \\(a,b\\in\\mathbf{R}\\), \\(p,q\\geq1\\), we have:\n\\[\\begin{aligned}\nab & \\leq\\frac{a^{p}}{p}+\\frac{b^{q}}{q}\\end{aligned}\\]\nSetting \\(a=\\frac{|X|}{\\left(\\mathbb{E}|X^{p}|\\right)^{1/p}}\\) and \\(b=\\frac{|Y|}{\\left(\\mathbb{E}|Y^{q}|\\right)^{1/q}}\\), we get:\n\\[\\begin{aligned}\n\\frac{|XY|}{\\left(\\mathbb{E}|X^{p}|\\right)^{1/p}\\left(\\mathbb{E}|Y^{q}|\\right)^{1/q}} & \\leq\\frac{1}{p}\\cdot\\frac{|X|^{p}}{\\mathbb{E}|X^{p}|}+\\frac{1}{q}\\cdot\\frac{|Y|^{q}}{\\mathbb{E}|Y^{q}|}\\end{aligned}\\]\nTaking expectations on both sides, and using the monotonicity of expectation property, we get:\n\\[\\begin{aligned}\n\\frac{\\mathbb{E}|XY|}{\\left(\\mathbb{E}|X^{p}|\\right)^{1/p}\\left(\\mathbb{E}|Y^{q}|\\right)^{1/q}} & \\leq\\frac{1}{p}\\cdot\\frac{\\mathbb{E}|X|^{p}}{\\mathbb{E}|X^{p}|}+\\frac{1}{q}\\cdot\\frac{\\mathbb{E}|Y|^{q}}{\\mathbb{E}|Y^{q}|}=\\frac{1}{p}+\\frac{1}{q}=1\\end{aligned}\\]\nConsequently,\n\\[\\begin{aligned}\n\\mathbb{E}|XY| & \\leq\\left(\\mathbb{E}|X^{p}|\\right)^{1/p}\\left(\\mathbb{E}|Y^{q}|\\right)^{1/q}\\end{aligned}\\]\nLet \\(p=2\\) and \\(q=2\\). Then, we get the Cauchy-Schwarz inequality:\n\\[\\begin{aligned}\n\\mathbb{E}|XY| & \\leq\\left[\\mathbb{E}(X^{2})\\right]^{1/2}\\left[\\mathbb{E}(Y^{2})\\right]^{1/2}\\end{aligned}\\]\nIn some ways, the \\(p\\)-th moment of a random variable can be thought of as it’s length or \\(p\\)-norm.\nDefine:\n\\[\\left\\Vert X\\right\\Vert _{p}=\\left(\\mathbb{E}|X|^{p}\\right)^{1/p}\\] \nThis closes the proof. \\(\\blacksquare\\)\n\n\n\n\nTheorem 8 For random variables \\(X\\) and \\(Y\\), and for all \\(p\\geq1\\) we have:\n\\[\\left\\Vert X+Y\\right\\Vert _{p}\\leq\\left\\Vert X\\right\\Vert _{p}+\\left\\Vert Y\\right\\Vert _{p}\\]\n\nProof.\nThe basic idea of the proof is to use Holder’s inequality. Let \\(\\frac{1}{q}=1-\\frac{1}{p}\\) or in other words, \\(q=\\frac{p}{p-1}\\). We have:\n\\[\\begin{aligned}\n\\mathbb{E}|X||X+Y|^{p-1} & \\leq\\left(\\mathbb{E}|X|^{p}\\right)^{1/p}\\left(\\mathbb{E}|X+Y|^{(p-1)q}\\right)^{1/q} & (a)\\\\ \\mathbb{E}|Y||X+Y|^{p-1} & \\leq\\left(\\mathbb{E}|Y|^{p}\\right)^{1/p}\\left(\\mathbb{E}|X+Y|^{(p-1)q}\\right)^{1/q} & (b)\\end{aligned}\\]\nAdding the above two equations, we get:\n\\[\\begin{aligned}\n\\mathbb{E}(|X+Y||X+Y|^{p-1})\\leq\\mathbb{E}(|X|+|Y|)(|X+Y|^{p-1}) & \\leq\\left\\{ \\left(\\mathbb{E}|X|^{p}\\right)^{1/p}+\\left(\\mathbb{E}|Y|^{p}\\right)^{1/p}\\right\\} \\left(\\mathbb{E}|X+Y|^{(p-1)q}\\right)^{1/q}\\\\ \\mathbb{E}|X+Y|^{p} & \\leq\\left\\{ \\left\\Vert X\\right\\Vert _{p}+\\left\\Vert Y\\right\\Vert _{p}\\right\\} \\left(\\mathbb{E}|X+Y|^{p}\\right)^{1/q}\\\\ \\left(\\mathbb{E}|X+Y|^{p}\\right)^{1/p} & \\leq\\left\\Vert X\\right\\Vert _{p}+\\left\\Vert Y\\right\\Vert _{p}\\\\ \\left\\Vert X+Y\\right\\Vert _{p} & \\leq\\left\\Vert X\\right\\Vert _{p}+\\left\\Vert Y\\right\\Vert _{p}\\end{aligned}\\] \nThis closes the proof. \\(\\blacksquare\\)\n\n\n\n\nMany of the concepts in this chapter have very elegant interpretations, if we think of real-valued random variables on a probability space as vectors in a vector space. In particular, variance is related to the concept of norm and distance, while covariance is related to inner-products. These concepts can help unify some of the ideas in this chapter from a geometric point of view. Of course, real-valued random variables are simply measurable, real-valued functions on the abstract space \\(\\Omega.\\)\n\nDefinition 4 (Vector Space.) By a vector space, we mean a non-empty set \\(V\\) with two operations: :::\n\nVector addition: \\(+:(\\mathbf{x},\\mathbf{y})\\to\\mathbf{x}+\\mathbf{y}\\)\nScalar multiplication: \\(\\cdot:(\\alpha,\\mathbf{x})\\to\\alpha\\mathbf{x}\\)\n\nsuch that the following conditions are satisfied:\n(A1) Commutativity. \\(\\mathbf{x}+\\mathbf{y}=\\mathbf{y}+\\mathbf{x}\\) for all \\(\\mathbf{x},\\mathbf{y}\\in V\\)\n(A2) Associativity: \\((\\mathbf{x}+\\mathbf{y})+\\mathbf{z}=\\mathbf{x}+(\\mathbf{y}+\\mathbf{z})\\) for all \\(\\mathbf{x},\\mathbf{y},\\mathbf{z}\\in V\\)\n(A3) Zero Element: There exists a zero element, denoted \\(\\mathbf{0}\\) in \\(V\\), for all \\(\\mathbf{x}\\in V\\), such that \\(\\mathbf{x}+\\mathbf{0}=\\mathbf{x}\\).\n(A4) Additive Inverse: For all \\(\\mathbf{x}\\in V\\), there exists an additive inverse(negative element) denoted \\(-\\mathbf{x}\\) in \\(V\\), such that \\(\\mathbf{x}+(-\\mathbf{x})=\\mathbf{0}\\).\n(M1) Scalar multiplication by identity element in \\(F\\): For all \\(\\mathbf{x}\\in V\\), \\(1\\cdot\\mathbf{x}=\\mathbf{x}\\), where \\(1\\) denotes the multiplicative identity in \\(F\\).\n(M2) Scalar multiplication and field multiplication mix well: For all \\(\\alpha,\\beta\\in F\\) and \\(\\mathbf{v}\\in V\\), \\((\\alpha\\beta)\\mathbf{v}=\\alpha(\\beta\\mathbf{v})\\).\n(D1) Distribution of scalar multiplication over vector addition: For all \\(\\alpha\\in F\\), and \\(\\mathbf{u},\\mathbf{v}\\in V\\), \\(\\alpha(\\mathbf{u}+\\mathbf{v})=\\alpha\\mathbf{u}+\\alpha\\mathbf{v}\\).\n(D2) Distribution of field addition over scalar multiplication: For all \\(\\alpha,\\beta\\in F\\), and \\(\\mathbf{v}\\in V\\), \\((\\alpha+\\beta)\\mathbf{v}=\\alpha\\mathbf{v}+\\beta\\mathbf{v}\\).\n\nAs usual, our starting point is a random experiment modeled by a probability space \\((\\Omega,\\mathcal{F},\\mathbb{P})\\), so that \\(\\Omega\\) is the set of outcomes, \\(\\mathscr{\\mathcal{F}}\\) is the \\(\\sigma\\)-algebra of events and \\(\\mathbb{P}\\) is the probability measure on the measurable space \\((\\Omega,\\mathcal{F})\\). Our basic vector space \\(V\\) consists of all real-valued random variables defined on \\((\\Omega,\\mathcal{F},\\mathbb{P})\\). We define vector addition and scalar multiplication in the usual way point-wise.\n\nVector addition: \\((X+Y)(\\omega)=X(\\omega)+Y(\\omega)\\).\nScalar multiplication: \\((\\alpha X)(\\omega)=\\alpha X(\\omega)\\)\n\nClearly, any function \\(g\\) of a random variable \\(X(\\omega)\\) is also a random variable on the same probability space and any linear combination of random variables on \\((\\Omega,\\mathcal{F},\\mathbb{P})\\) also define a new random variable on the same probability space. Thus, \\(V\\) is closed under vector addition and scalar-multiplication. Since vector-addition and scalar multiplication is defined point-wise, it is easy to see that - all the axioms of a vector space (A1)-(A4), (M1-M2), (D1), (D2) are satisfied. The constantly zero random variable \\(0(\\omega)=0\\) and the indicator random variable \\(I_{\\Omega}(\\omega)\\) can be thought of as the zero and identity vectors in this vector space.\nClearly, any function \\(g\\) of a random variable \\(X(\\omega)\\) is also a random variable on the same probability space and any linear combination of random variables on \\((\\Omega,\\mathcal{F},\\mathbb{P})\\) also define a new random variable on the same probability space. Thus, \\(V\\) is closed under vector addition and scalar-multiplication. Since vector-addition and scalar multiplication is defined point-wise, it is easy to see that - all the axioms of a vector space (A1)-(A4), (M1-M2), (D1), (D2) are satisfied. The constantly zero random variable \\(0(\\omega)=0\\) and the indicator random variable \\(I_{\\Omega}(\\omega)\\) can be thought of as the zero and identity vectors in this vector space.\n\n\nIn Euclidean geometry, the angle between two vectors is specified by their dot product, which is itself formalized by the abstract concept of inner products.\n\nDefinition 5 (Inner Product.) An inner product on the real vector space \\(V\\) is a pairing that takes two vectors \\(\\mathbf{v},\\mathbf{w}\\in V\\) and produces a real number \\(\\left\\langle \\mathbf{v},\\mathbf{w}\\right\\rangle \\in\\mathbf{R}\\). The inner product is required to satisfy the following three axioms for all \\(\\mathbf{u},\\mathbf{v},\\mathbf{w}\\in V\\) and scalars \\(c,d\\in\\mathbf{R}\\).\n\nBilinearity: \\[\n\\left\\langle c\\mathbf{u}+d\\mathbf{v},\\mathbf{w}\\right\\rangle =c\\left\\langle \\mathbf{u},\\mathbf{w}\\right\\rangle +d\\left\\langle \\mathbf{v},\\mathbf{w}\\right\\rangle\n\\]\n\n\\[\n\\left\\langle \\mathbf{u},c\\mathbf{v}+d\\mathbf{w}\\right\\rangle =c\\left\\langle \\mathbf{u},\\mathbf{v}\\right\\rangle +d\\left\\langle \\mathbf{u},\\mathbf{w}\\right\\rangle\n\\]\n\nSymmetry:\n\n\\[\n\\left\\langle \\mathbf{v},\\mathbf{w}\\right\\rangle =\\left\\langle \\mathbf{w},\\mathbf{v}\\right\\rangle\n\\]\n\nPositive Definiteness:\n\n\\[\n\\left\\langle \\mathbf{v},\\mathbf{v}\\right\\rangle &gt;0\\quad\\text{ whenever }\\mathbf{v\\neq\\mathbf{0}}\n\\]\n\\[\n\\left\\langle \\mathbf{v},\\mathbf{v}\\right\\rangle =0\\quad\\text{ whenever }\\mathbf{v=0}\n\\]\n\n\nDefinition 6 (Norm). A norm on a real vector space \\(V\\) is a function \\(\\left\\Vert \\cdot\\right\\Vert :V\\to\\mathbf{R}\\) satisfying :\n(i) Positive Definiteness.\n\\[\\left\\Vert \\mathbf{v}\\right\\Vert \\geq0\\]\nand \\[\\left\\Vert \\mathbf{v}\\right\\Vert =0\\quad\\text{if and only if }\\mathbf{v}=\\mathbf{0}\\]\n(ii) Scalar multiplication.\n\\[\\left\\Vert \\alpha\\mathbf{v}\\right\\Vert =|\\alpha|\\left\\Vert \\mathbf{v}\\right\\Vert\\]\n(iii) Triangle Inequality.\n\\[\\left\\Vert \\mathbf{x+y}\\right\\Vert \\leq\\left\\Vert \\mathbf{x}\\right\\Vert +\\left\\Vert \\mathbf{y}\\right\\Vert\\]\n\nAs mentioned earlier, we can define the \\(p\\)-norm of a random variable as:\n\\[\n\\begin{aligned}\n\\left\\Vert X\\right\\Vert _{p} & =\\left(\\mathbb{E}|X|^{p}\\right)^{1/p}\n\\end{aligned}\n\\]\n(i) Positive semi-definiteness: Since \\(|X|\\) is a non-negative random variable, \\(|X|^{p}\\geq0\\) and the expectation of a non-negative random variable is also non-negative. Hence, \\((\\mathbb{E}|X|^{p})^{1/p}\\geq0\\). Moreover, \\(\\left\\Vert X\\right\\Vert _{p}=0\\) implies that \\(\\mathbb{E}|X|^{p}=0\\). From property (iv) of expectations, \\(X=0\\).\n(ii) Scalar-multiplication: We have:\n\\[\n\\begin{aligned}\n\\left\\Vert cX\\right\\Vert _{p} & =\\left(\\mathbb{E}|cX|^{p}\\right)^{1/p}\\\\\n& =\\left(|c|^{p}\\right)^{1/p}\\left(\\mathbb{E}|X|^{p}\\right)^{1/p}\\\\\n& =|c|\\cdot\\left\\Vert X\\right\\Vert _{p}\n\\end{aligned}\n\\]\n(iii) Triangle Inequality. This followed from the Minkowski’s inequality.\nThe space of all random variables defined on \\((\\Omega,\\mathcal{\\mathcal{F}},\\mathbb{P})\\) such that \\(||X||_{p}&lt;\\infty\\) is finite is called the \\(L^{p}\\) space.\n\n\n\n\nDefinition 7 (Orthogonal Matrix.) Let \\(A\\) be an \\(n\\times n\\) square matrix. We say that the matrix \\(A\\) is orthogonal, if its transpose is equal toits inverse.\n\\[\n\\begin{aligned}\nA' & =A^{-1}\n\\end{aligned}\n\\]\n\nThis may seem like an odd property to study, but the following theorem explains why it is so useful. Essentially, an orthogonal matrix rotates (or reflects) vectors without distorting angles or distances.\n\nProposition 1 (Properties of an orthogonal matrix) Faor an \\(n\\times n\\) square matrix \\(A\\), the following are equivalent:\n(1) \\(A\\) is orthogonal. That is, \\(A'A=I\\).\n(2) \\(A\\) preserves norms. That is, for all \\(\\mathbf{x}\\),\n\\[\\begin{aligned}\n\\left\\Vert A\\mathbf{x}\\right\\Vert &=\\left\\Vert \\mathbf{x}\\right\\Vert \\end{aligned}\\]\n(3) \\(A\\) preserves inner products, that is, for every \\(\\mathbf{x}\\), \\(\\mathbf{y}\\)\\(\\in\\mathbf{R}^{n}\\):\n\\[\\begin{aligned}\n(A\\mathbf{x})\\cdot(A\\mathbf{y}) &=\\mathbf{x}\\cdot\\mathbf{y}\\end{aligned}\\]\n\nProof.\nWe have:\n\\[\\begin{aligned}\n\\left\\Vert A\\mathbf{x}\\right\\Vert ^{2} & =\\left(A\\mathbf{x}\\right)'(A\\mathbf{x})\\\\\n& =\\mathbf{x}'(A'A)\\mathbf{x}\\\\\n& =\\mathbf{x}'I\\mathbf{x}\\\\\n& =\\mathbf{x}'\\mathbf{x}\\\\\n& =||\\mathbf{x}||^{2}\\end{aligned}\\]\nConsequently, \\(||A\\mathbf{x}||=||\\mathbf{x}||\\). The matrix \\(A\\) preserves norms. Thus, (1) implies (2).\nMoreover, consider\n\\[\\begin{aligned}\n||A(\\mathbf{x}+\\mathbf{y})||^{2} & =\\left(A\\mathbf{x}+A\\mathbf{y}\\right)\\cdot\\left(A\\mathbf{x}+A\\mathbf{y}\\right)\\\\\n& =(A\\mathbf{x})\\cdot(A\\mathbf{x})+(A\\mathbf{x})\\cdot(A\\mathbf{y})+(A\\mathbf{y})\\cdot(A\\mathbf{x})+(A\\mathbf{y})\\cdot(A\\mathbf{y})\\\\\n& =||A\\mathbf{x}||^{2}+2(A\\mathbf{x})\\cdot(A\\mathbf{y})+||A\\mathbf{y}||^{2} & \\{\\mathbf{x}\\cdot\\mathbf{y}=\\mathbf{y}\\cdot\\mathbf{x}\\}\\\\\n& =||\\mathbf{x}||^{2}+2(A\\mathbf{x})\\cdot(A\\mathbf{y})+||\\mathbf{y}||^{2} & \\{A\\text{ preserves norms}\\}\\end{aligned}\\]\nBut, \\(||A(\\mathbf{x}+\\mathbf{y})||^{2}=||\\mathbf{x}+\\mathbf{y}||^{2}=||\\mathbf{x}||^{2}+2\\mathbf{x}\\cdot\\mathbf{y}+||\\mathbf{y}||^{2}\\).\nEquating the two expressions, we have the desired result. Hence, (2) implies (3).\nLastly, if \\(A\\) preserves inner products, we may write:\n\\[\\begin{aligned}\n\\left\\langle A\\mathbf{x},A\\mathbf{x}\\right\\rangle  & =\\left\\langle \\mathbf{x},\\mathbf{x}\\right\\rangle \\\\\n\\left(A\\mathbf{x}\\right)'(A\\mathbf{x}) & =\\mathbf{x}'\\mathbf{x}\\\\\n\\mathbf{x}'A'A\\mathbf{x} & =0\\end{aligned}\\]\nSince \\(\\mathbf{x}\\neq\\mathbf{0}\\), it must be true that \\(\\mathbf{x}'A'A-\\mathbf{x}'=0\\). Again, since \\(\\mathbf{x}'\\neq\\mathbf{0}\\), it follows that \\(A'A-I=0\\).\n\nTheorem 9 (Linear Independence of orthogonal vectors) If \\(\\mathbf{q}_{1},\\mathbf{q}_{2},\\ldots,\\mathbf{q}_{k}\\in V\\) be mutually orthogonal elements, such that \\(\\mathbf{q}_{i}\\neq\\mathbf{0}\\) for all \\(i\\), then \\(\\mathbf{q}_{1},\\mathbf{q}_{2},\\ldots,\\mathbf{q}_{k}\\) are linearly independent.\n\nProof.\nLet\n\\[\\begin{aligned}\nc_{1}\\mathbf{q}_{1}+c_{2}\\mathbf{q}_{2}+\\ldots+c_{k}\\mathbf{q}_{k} & =\\mathbf{0}\\end{aligned}\\]\nSince \\(\\left\\langle \\mathbf{q}_{i},\\mathbf{q}_{i}\\right\\rangle =1\\) and \\(\\left\\langle \\mathbf{q}_{i},\\mathbf{q}_{j}\\right\\rangle =0\\) where \\(i\\neq j\\), we can take the inner product of the vector \\(c_1 \\mathbf{q}_{1} + c_2 \\mathbf{q}_{2} + \\ldots + c_i \\mathbf{q}_{i}+\\ldots + c_{k}\\mathbf{q}_{k}\\) with \\(\\mathbf{q}_{i}\\) for each \\(i=1,2,3,\\ldots,k\\). It results in \\(c_{i}||\\mathbf{q}_{i}||^{2}=0\\). Since \\(\\mathbf{q}_{i}\\neq\\mathbf{0}\\), \\(||\\mathbf{q}_{i}||^{2}&gt;0\\). So, \\(c_{i}=0\\). We conclude that \\(c_{1}=c_{2}=\\ldots=c_{k} =0\\). Consequently, \\(\\mathbf{q}_{1},\\mathbf{q}_{2},\\ldots,\\mathbf{q}_{k}\\) are linearly independent. \\(\\blacksquare\\)\n\nTheorem 10 (Orthogonal vectors form a basis) Let \\(Q=\\left[\\begin{array}{cccc} \\mathbf{q}_{1} & \\mathbf{q}_{2} & \\ldots & \\mathbf{q}_{n}\\end{array}\\right]\\) be an \\(n\\times n\\) orthogonal matrix. Then, \\(\\{\\mathbf{q}_{1},\\ldots,\\mathbf{q}_{n}\\}\\) form an orthonormal basis for \\(\\mathbf{R}^{n}\\).\n\nProof.\nWe have \\(Q\\mathbf{e}_{i}=\\mathbf{q}_{i}\\). Consequently,\n\\[\\begin{aligned}\n\\left\\langle \\mathbf{q}_{i},\\mathbf{q}_{i}\\right\\rangle  & =\\mathbf{q}_{i}'\\mathbf{q}_{i}\\\\\n& =(Q\\mathbf{e}_{i})'(Q\\mathbf{e}_{i})\\\\\n& =\\mathbf{e}_{i}'Q'Q\\mathbf{e}_{i}\\\\\n& =\\mathbf{e}_{i}'I\\mathbf{e}_{i}\\\\\n& =\\mathbf{e}_{i}'\\mathbf{e}_{i}\\\\\n& =1\\end{aligned}\\]\nAssume that \\(i\\neq j\\). We have:\n\\[\\begin{aligned}\n\\left\\langle \\mathbf{q}_{i},\\mathbf{q}_{j}\\right\\rangle  & =\\mathbf{q}_{i}'\\mathbf{q}_{j}\\\\\n& =\\mathbf{e}_{i}'Q'Q\\mathbf{e}_{j}\\\\\n& =\\mathbf{e}_{i}'\\mathbf{e}_{j}\\\\\n& =0\\end{aligned}\\]\nFrom Theorem 9, \\(\\{\\mathbf{q}_{1},\\ldots,\\mathbf{q}_{n}\\}\\) are linearly independent and hence form an orthonormal basis for \\(\\mathbf{R}^{n}\\).\n\n\n\nAn expression of the form:\n\\[\\mathbf{x}'A\\mathbf{x}\\]\nwhere \\(\\mathbf{x}\\) is a \\(n\\times1\\) column vector and \\(A\\) is an \\(n\\times n\\) matrix is called a quadratic form in \\(\\mathbf{x}\\) and\n\\[\\begin{aligned}\n\\mathbf{x}'A\\mathbf{x} & =\\sum_{i=1}^{n}\\sum_{j=1}^{n}a_{ij}x_{i}x_{j}\\end{aligned}\\]\nIf \\(A\\) and \\(B\\) are \\(n\\times n\\) and \\(\\mathbf{x},\\mathbf{y}\\) are \\(n\\)-vectors, then\n\\[\\begin{aligned}\n\\mathbf{x}'(A+B)\\mathbf{y} & =\\mathbf{x}'A\\mathbf{y}+\\mathbf{x}'B\\mathbf{y}\\end{aligned}\\]\nThe quadratic form of the matrix \\(A\\) is called positive definite if:\n\\[\\begin{aligned}\n\\mathbf{x}'A\\mathbf{x} & &gt;0\\quad\\text{whenever }\\mathbf{x}\\neq\\mathbf{0}\\end{aligned}\\]\nand positive semidefinite if:\n\\[\\begin{aligned}\n\\mathbf{x}'A\\mathbf{x} & \\geq0\\quad\\text{whenever }\\mathbf{x}\\neq\\mathbf{0}\\end{aligned}\\]\nLetting \\(\\mathbf{e}_{i}\\) be the unit vector with it’s \\(i\\)th coordinate vector \\(1\\), we have:\n\\[\n\\begin{aligned}\n\\mathbf{e}_{i}'A\\mathbf{e}_{i} & =\\left[a_{i1}a_{i2}\\ldots a_{ii}\\ldots a_{in}\\right]\\left[\\begin{array}{c}\n0\\\\\n0\\\\\n\\vdots\\\\\n1\\\\\n\\vdots\\\\\n0\n\\end{array}\\right]=a_{ii}\n\\end{aligned}\n\\]\n\n\n\nLet \\(V\\) and \\(W\\) be finite dimensional vector spaces with \\(dim(V)=n\\) and \\(dim(W)=m\\). A linear transformation \\(T:V\\to W\\), is defined by its action on the basis vectors. Suppose:\n\\[\n\\begin{aligned}\nT(\\mathbf{v}_{j}) & =\\sum_{i=1}^{n}a_{ij}\\mathbf{w}_{i}\n\\end{aligned}\n\\]\nfor all \\(1\\leq i\\leq m\\).\nThen, the matrix \\(A=[T]_{\\mathcal{B}_{V}}^{\\mathcal{B}_{W}}\\) of the linear transformation is defined as:\n\\[\\begin{aligned}\nA & =\\left[\\begin{array}{cccc}\na_{11} & a_{12} & \\ldots & a_{1n}\\\\\na_{21} & a_{22} & \\ldots & a_{2n}\\\\\n\\vdots & \\vdots & \\ddots & \\vdots\\\\\na_{m1} & a_{m2} & \\ldots & a_{mn}\n\\end{array}\\right]\\end{aligned}\\]\n\nDefinition 8 A linear transformation \\(T:V\\to V\\) is said to be diagonalizable if there exists an ordered basis \\(\\mathcal{B}=\\{\\mathbf{v}_{1},\\ldots,\\mathbf{v}_{n}\\}\\) for \\(V\\) so that the matrix for \\(T\\) with respect to \\(\\mathcal{B}\\) is diagonal. This means precisely that, for some scalars \\(\\lambda_{1},\\lambda_{2},\\ldots,\\lambda_{n}\\), we have:\n\\[\n\\begin{aligned}\nT(\\mathbf{v}_{1}) & =\\lambda_{1}\\mathbf{v}_{1}\\\\\nT(\\mathbf{v}_{2}) & =\\lambda_{2}\\mathbf{v}_{2}\\\\\n\\vdots\\\\\nT(\\mathbf{v}_{n}) & =\\lambda_{n}\\mathbf{v}_{n}\n\\end{aligned}\n\\]\n\nIn other words, if \\(A=[T]_{\\mathcal{B}}\\), then we have:\n\\[\\begin{aligned}\nA\\mathbf{v}_{i} & =\\lambda_{i}\\mathbf{v}_{i}\\end{aligned}\\]\nThus, if we let \\(P\\) be the \\(n\\times n\\) matrix whose columns are the vectors \\(\\mathbf{v}_{1},\\mathbf{v}_{2},\\ldots,\\mathbf{v}_{n}\\) and \\(\\Lambda\\) be the \\(n\\times n\\) diagonal matrix with diagonal entries \\(\\lambda_{1},\\lambda_{2},\\ldots,\\lambda_{n}\\), then we have:\n\\[\\begin{aligned}\nA\\left[\\begin{array}{cccc}\n\\mathbf{v}_{1} & \\mathbf{v}_{2} & \\ldots & \\mathbf{v}_{n}\\end{array}\\right] & =\\left[\\begin{array}{cccc}\n\\mathbf{v}_{1} & \\mathbf{v}_{2} & \\ldots & \\mathbf{v}_{n}\\end{array}\\right]\\left[\\begin{array}{cccc}\n\\lambda_{1}\\\\\n& \\lambda_{2}\\\\\n&  & \\ddots\\\\\n&  &  & \\lambda_{n}\n\\end{array}\\right]\\\\\nAP & =P\\Lambda\\\\\nA & =P\\Lambda P^{-1}\\end{aligned}\\]\nThere exists a large class of diagonalizable matrices - the symmetric matrices. A square matrix \\(A\\) is symmetric, if \\(A=A'\\).\n\nDefinition 9 (Eigenvectors) Let \\(T:V\\to V\\) be a linear transformation. A non-zero vector \\(\\mathbf{v}\\in V\\) is called the eigenvector of \\(T\\), if there is a scalar \\(\\lambda\\) so that \\(T(\\mathbf{v})=\\lambda\\mathbf{v}\\). The scalar \\(\\lambda\\) is called the eigenvalue of \\(T\\)."
  },
  {
    "objectID": "posts/gaussian-processes/index.html#random-vectors.",
    "href": "posts/gaussian-processes/index.html#random-vectors.",
    "title": "Gaussian Processes",
    "section": "",
    "text": "Consider a probability space \\((\\Omega,\\mathcal{F},\\mathbb{P})\\). We can define several random variables on \\(\\Omega\\). A \\(n\\)-tuple of random variables on this space is called a random vector. For example, if \\(X_{1},X_{2},\\ldots,X_{n}\\) are random variables on \\((\\Omega,\\mathcal{F},\\mathbb{P})\\), then the \\(n\\)-tuple \\((X_{1},X_{2},\\ldots,X_{n})\\) is a random vector on \\((\\Omega,\\mathcal{F},\\mathbb{P})\\). The vector is said to be \\(n\\)-dimensional because it contains \\(n\\)-variables. We will sometimes denote a random vector by \\(X\\).\nA good point of view is to think of a random vector \\(X=(X_{1},\\ldots,X_{n})\\) as a random variable (point) in \\(\\mathbf{R}^{n}\\). In other words, for an outcome \\(\\omega\\in\\Omega\\), \\(X(\\omega)\\) is a point sampled in \\(\\mathbf{R}^{n}\\), where \\(X_{j}(\\omega)\\) represents the \\(j\\)-th coordinate of the point. The distribution of \\(X\\), denoted \\(\\mu_{X}\\) is the probability on \\(\\mathbf{R}^{n}\\)defined by the events related to the values of \\(X\\):\n\\[\\mathbb{P}\\{X\\in A\\}=\\mu_{X}(A)\\quad\\text{for a subset }A\\text{ in }\\mathbf{R}^{n}\\]\nIn other words, \\(\\mathbb{P}(X\\in A)=\\mu_{X}(A)\\) is the probability that the random point \\(X\\) falls in \\(A\\). The distribution of the vector \\(X\\) is also called the joint distribution of \\((X_{1},\\ldots,X_{n})\\).\n\nDefinition 1 (Joint Distribution) The joint distribution function of \\(\\mathbf{X}=(X,Y)\\) is the function \\(F:\\mathbf{R}^{2}\\to[0,1]\\) given by:\n\\[F_{\\mathbf{X}}(x,y)=\\mathbb{P}(X\\leq x,Y\\leq y)\\]\n\n\nDefinition 2 (Joint density) The joint PDF \\(f_{\\mathbf{X}}(x_{1},\\ldots,x_{n})\\) of a random vector \\(\\mathbf{X}\\) is a function \\(f_{\\mathbf{X}}:\\mathbf{R}^{n}\\to\\mathbf{R}\\) such that the probability that \\(X\\) falls in a subset \\(A\\) of \\(\\mathbf{R}^{n}\\) and is expressed as the multiple integral of \\(f(x_{1},x_{2,}\\ldots,x_{n})\\) over \\(A\\).\n\\[\\mathbb{P}(X\\in A)=\\int_{A}f(x_{1},x_{2},\\ldots,x_{n})dx_{1}dx_{2}\\ldots dx_{n}\\]\n\nNote that: we must have that the integral of \\(f\\) over the whole of \\(\\mathbf{R}^{n}\\) is \\(1\\).\nIf \\(F\\) is differentiable at the point \\((x,y)\\), then we usually specify:\n\\[f(x,y)=\\frac{\\partial^{2}}{\\partial x\\partial y}F(x,y)\\]\n\nTheorem 1 (Law of total probability) Let \\((X,Y)\\) be the random variables with joint density function \\(f_{X,Y}(x,y)\\). The marginal density function \\(f_{X}(x)\\) and \\(f_{Y}(y)\\) of the random variables \\(X\\) and \\(Y\\) respectively is given by:\n\\[\\begin{aligned}\nf_{X}(x) & =\\int_{-\\infty}^{+\\infty}f_{(X,Y)}(x,y)dy\\\\ f_{Y}(y) & =\\int_{-\\infty}^{+\\infty}f_{(X,Y)}(x,y)dx\\end{aligned}\\]\n\nProof.\nWe have:\n\\[\\begin{aligned}\nF_{X}(x) & =P(X\\leq x)\\\\ & =\\int_{-\\infty}^{x}\\int_{y=-\\infty}^{y=+\\infty}f(x,y)dydx\\end{aligned}\\]\nDifferentiating both sides with respect to \\(x\\),\n\\[\\begin{aligned}\nf_{X}(x) & =\\int_{y=-\\infty}^{y=+\\infty}f(x,y)dydx\\end{aligned}\\] \nThis closes the proof. \\(\\blacksquare\\)\n\nDefinition 3 (Conditional density function) For continuous random variables \\(X\\) and \\(Y\\) with the joint density function \\(f_{(X,Y)}\\), the conditional density of \\(Y\\) given \\(X=x\\) is:\n\\[\\begin{aligned}\nf_{Y|X}(y|x) & =\\frac{f_{(X,Y)}(x,y)}{f_{X}(x)}\\end{aligned}\\]\nfor all \\(x\\) with \\(f_{X}(x)&gt;0\\). This is considered as a function of \\(y\\) for a fixed \\(x\\). As a convention, in order to make \\(f_{Y|X}(y|x)\\) well-defined for all real \\(x\\), let \\(f_{Y|X}(y|x)=0\\) for all \\(x\\) with \\(f_{X}(x)=0\\).\n\nWe are essentially slicing the the joint density function of \\(f_{(X,Y)}(x,y)\\) by a thin plane \\(X=x\\). How can we speak of conditioning on \\(X=x\\) for \\(X\\) being a continuous random variable, considering that this event has probability zero. Rigorously speaking, we are actually conditioning on the event that \\(X\\) falls within a small interval containing \\(x\\), say \\(X\\in(x-\\epsilon,x+\\epsilon)\\) and then taking the limit as \\(\\epsilon\\) approaches zero from the right.\nWe can recover the joint PDF \\(f_{(X,Y)}\\) if we have the conditional PDF \\(f_{Y|X}\\) and the corresponding marginal \\(f_{X}\\):\n\\[\n\\begin{aligned}\nf_{(X,Y)}(x,y) & =f_{Y|X}(y|x)\\cdot f_{X}(x)\n\\end{aligned}\n\\]\n\nTheorem 2 (Bayes rule and LOTP) Let \\((X,Y)\\) be continuous random variables. We have the following continuous form of the Bayes rule:\n\\[f_{Y|X}(y|x)=\\frac{f_{X|Y}(x|y)\\cdot f_{Y}(y)}{f_{X}(x)}\\]\nAnd we have the following continuous form of the law of total probability:\n\\[\\begin{aligned}\nf_{X}(x) & =\\int_{y=-\\infty}^{y=+\\infty}f_{X|Y}(x|y)\\cdot f_{Y}(y)dy\\end{aligned}\\]\n\nProof.\nBy the definition of conditional PDFs, we have:\n\\[\n\\begin{aligned}\nf_{X|Y}(x|y)\\cdot f_{Y}(y) & =f_{(X,Y)}(x,y)=f_{Y|X}(y|x)\\cdot f_{X}(x)\\end{aligned}\n\\]\nDividing throughout by \\(f_{X}(x)\\), we have:\n\\[\n\\begin{aligned}\nf_{Y|X}(x) & =\\frac{f_{X|Y}(x|y)\\cdot f_{Y}(y)}{f_{X}(x)}=\\frac{f_{(X,Y)}(x,y)}{f_{X}(x)}\\end{aligned}\n\\] \nThis closes the proof. \\(\\blacksquare\\)\n\nExample 1 (Sampling uniformly in the unit disc). Consider the random vector \\(\\mathbf{X}=(X,Y)\\) corresponding to a random point chosen uniformly in the unit disc \\(\\{(x,y):x^{2}+y^{2}\\leq1\\}\\). \\(\\mathbf{X}\\) is said to have uniform on the unit circle distribution. In this case the PDF is \\(0\\) outside the disc and \\(\\frac{1}{\\pi}\\) inside the disc:\n\\[\\begin{aligned}\nf(x,y) & =\\frac{1}{\\pi}\\quad\\text{ if }x^{2}+y^{2}\\leq1\\end{aligned}\\]\nThe random point \\((X,Y)\\) has \\(x\\)-coordinate \\(X\\) and \\(Y\\) coordinate \\(Y\\). Each of these are random variables and their PDFs and CDFs can be computed. This is a valid PDF, because:\n\\[\\begin{aligned}\n\\int\\int_{D}f(x,y)dydx & =\\int_{-1}^{1}\\int_{-\\sqrt{1-x^{2}}}^{\\sqrt{1-x^{2}}}\\frac{1}{\\pi}dydx\\\\ & =\\frac{1}{\\pi}\\int_{-1}^{1}\\left[y\\right]_{-\\sqrt{1-x^{2}}}^{+\\sqrt{1-x^{2}}}dx\\\\ & =\\frac{2}{\\pi}\\int_{-1}^{1}\\sqrt{1-x^{2}}dx\\end{aligned}\\]\nSubstituting \\(x=\\sin\\theta\\), we have: \\(dx=\\cos\\theta d\\theta\\) and \\(\\sqrt{1-x^{2}}=\\cos\\theta\\). The limits of integration are \\(\\theta=-\\pi/2\\) to \\(\\theta=\\pi/2\\). Thus,\n\\[\\begin{aligned}\n\\int\\int_{D}f(x,y)dydx & =\\frac{2}{\\pi}\\int_{-\\pi/2}^{\\pi/2}\\cos^{2}\\theta d\\theta\\\\ & =\\frac{1}{\\pi}\\int_{-\\pi/2}^{\\pi/2}(1+\\cos2\\theta)d\\theta\\\\ & =\\frac{1}{\\pi}\\left[\\theta+\\frac{1}{2}\\sin2\\theta\\right]_{-\\pi/2}^{\\pi/2}\\\\ & =\\frac{1}{\\pi}\\cdot\\pi\\\\ & =1\\end{aligned}\\]\nThe CDF of \\(X\\) is given by:\n\\[\\begin{aligned}\nF_{X}(a) & =\\int_{-1}^{a}\\int_{-\\sqrt{1-x^{2}}}^{\\sqrt{1-x^{2}}}\\frac{1}{\\pi}dydx\\\\ & =\\frac{2}{\\pi}\\int_{-1}^{a}\\sqrt{1-x^{2}}dx\\end{aligned}\\]\nI leave it in this integral form. The PDF of \\(X\\) is obtained by differentiating the CDF, so it is:\n\\[f_{X}(x)=\\frac{2}{\\pi}\\sqrt{1-x^{2}}\\label{eq:marginal-pdf-of-X}\\]\n\nLet’s quickly plot the density of \\(X\\) over the domain of the definition \\(-1\\leq x\\leq1\\).\n::: center Figure. The PDF of the random variable \\(X\\). :::\nNot suprisingly the distribution of the \\(x\\)-coordinate is no longer uniform!\nIf \\((X_{1},X_{2},\\ldots,X_{n})\\) is a random vector, the distribution of a single coordinate, say \\(X_{1}\\) is called the marginal distribution. In the example [Uniform-on-the-unit-circle-distribution], the marginal distribution of \\(X\\) is determined by the PDF [eq:marginal-pdf-of-X].\nRandom variables \\(X_{1},X_{2},\\ldots,X_{n}\\) defined on the same probability space are said to be independent if for any intervals \\(A_{1},A_{2},\\ldots,A_{n}\\) in \\(\\mathbf{R}\\), the probability factors:\n\\[\\mathbb{P}(X_{1}\\in A_{1},X_{2}\\in A_{2},\\ldots,X_{n}\\in A_{n})=\\mathbb{P}(X_{1}\\in A_{1})\\times\\mathbb{P}(X_{2}\\in A_{2})\\times\\ldots\\times\\mathbb{P}(X_{n}\\in A_{n})\\] We say that the random variables are independent and identically distributed (IID) if they are independent and their marginal distributions are the same.\nWhen the random vector \\((X_{1},X_{2},\\ldots,X_{n})\\) has a joint PDF \\(f(x_{1},x_{2},\\ldots,x_{n})\\), the independence of random variables is equivalent to saying that the joint PDF is given by the product of the marginal PDFs:\n\\[f(x_{1},x_{2},\\ldots,x_{n})=f_{1}(x_{1})\\times f_{2}(x_{2})\\times\\ldots\\times f_{n}(x_{n})\\]"
  },
  {
    "objectID": "posts/gaussian-processes/index.html#basic-probabilistic-inequalities.",
    "href": "posts/gaussian-processes/index.html#basic-probabilistic-inequalities.",
    "title": "Gaussian Processes",
    "section": "",
    "text": "Inequalities are extremely useful tools in the theoretical development of probability theory.\n\n\n\nTheorem 3 If \\(g\\) is a convex function, and \\(a&gt;0\\), \\(b&gt;0\\), with \\(p\\in[0,1]\\), it follows that:\n\\[g(pa+(1-p)b)\\leq pg(a)+(1-p)g(b)\\]\n\nProof. This directly follows from the definition of convex functions. \\(\\blacksquare\\)\n\n\n\n\nTheorem 4 If \\(g\\) is a convex function, then it follows that:\n\\[\\mathbb{E}(g(X))\\geq g(\\mathbb{E}X)\\]\n\nProof.\nAnother way to express the idea, that a function is convex is to observe that the tangent line at an arbitrary point \\((t,g(t))\\) always lies below the curve. Let \\(y=a+bx\\) be the tangent to \\(g\\) at the point \\(t\\). Then, it follows that:\n\\[\\begin{aligned}\na+bt & =g(t)\\\\ a+bx & \\leq g(x)\\end{aligned}\\]\nfor all \\(x\\).\nThus, it follows that, for any point \\(t\\), there exists \\(b\\) such that:\n\\[\\begin{aligned}\ng(x)-g(t) & \\geq b(x-t)\\end{aligned}\\]\nfor all \\(x\\). Set \\(t=\\mathbb{E}X\\) and \\(x=X\\). Then,\n\\[\\begin{aligned}\ng(X)-g(\\mathbb{E}X) & \\geq b(X-\\mathbb{E}X)\\end{aligned}\\]\nTaking expectations on both sides and simplifying:\n\\[\\begin{aligned}\n\\mathbb{E}\\left(g(X)\\right)-g(\\mathbb{E}X) & \\geq b(\\mathbb{E}X-\\mathbb{E}X)=0\\\\ \\mathbb{E}g(X) & \\geq g(\\mathbb{E}X)\\end{aligned}\\] \nThis closes the proof. \\(\\blacksquare\\)\n\n\n\n\nTheorem 5 If \\(a\\geq0\\) and \\(b\\geq0\\) are non-negative real numbers and if \\(p&gt;1\\) and \\(q&gt;1\\) are real numbers such that \\(\\frac{1}{p}+\\frac{1}{q}=1\\), then:\n\\[ab\\leq\\frac{a^{p}}{p}+\\frac{b^{q}}{q}\\]\n\nProof.\nConsider \\(g(x)=\\log x\\). Being a concave function, Jensen’s inequality can be reversed. We have:\n\\[\\begin{aligned}\ng\\left(\\frac{1}{p}a^{p}+\\frac{1}{q}b^{q}\\right) & \\geq\\frac{1}{p}g(a^{p})+\\frac{1}{q}g(b^{q})\\\\ \\log\\left(\\frac{1}{p}a^{p}+\\frac{1}{q}b^{q}\\right) & \\geq\\frac{1}{p}\\log(a^{p})+\\frac{1}{q}\\log(b^{q})\\\\ \\log\\left(\\frac{1}{p}a^{p}+\\frac{1}{q}b^{q}\\right) & \\geq\\frac{1}{p}\\cdot p\\log(a)+\\frac{1}{q}\\cdot q\\log(b)\\\\ \\log\\left(\\frac{1}{p}a^{p}+\\frac{1}{q}b^{q}\\right) & \\geq\\log ab\\end{aligned}\\]\nBy the Monotonicity of the \\(\\log x\\) function, it follows that :\n\\[\\begin{aligned}\nab & \\leq\\frac{a^{p}}{p}+\\frac{b^{q}}{q}\\end{aligned}\\] \nThis closes the proof. \\(\\blacksquare\\)\n\n\n\nOne of the simplest and very useful probabilistic inequalities is a tail bound by expectation: the so called Chebyshev’s inequality.\n\nTheorem 6 (Chebyshev’s inequality) If \\(X\\) is a non-negative random variable, then for every \\(t\\geq0\\):\n\\[\\mathbb{P}(X\\geq t)\\leq\\frac{1}{t}\\mathbb{E}X\\]\n\nProof.\nWe have:\n\\[\\begin{aligned}\nt\\cdot\\mathbf{1}_{\\{X\\geq t\\}} & \\leq X\\cdot\\mathbf{1}_{\\{X\\geq t\\}}\\end{aligned}\\]\nBy the monotonicity of expectations, we have:\n\\[\\begin{aligned}\n\\mathbb{E}\\mathbf{1}_{\\{X\\geq t\\}} & \\leq\\frac{1}{t}\\mathbb{E}X\\\\ \\implies\\mathbb{P}\\{X\\geq t\\} & \\leq\\frac{1}{t}\\mathbb{E}X\\end{aligned}\\]\nThis closes the proof. \\(\\blacksquare\\)\nThere are several variants, easily deduced from Chebyshev’s inequality using monotonicity of several functions. For a non-negative random variable \\(X\\) and \\(t&gt;0\\), using the power function \\(x^{p}\\), \\(p&gt;0\\), we get:\n\\[\\mathbb{P}(X\\geq t)=\\mathbb{P}(X^{p}\\geq t^{p})\\leq\\frac{1}{t^{p}}\\mathbb{E}X^{p}\\]\nFor a real valued random variable \\(X\\), every \\(t\\in\\mathbf{R}\\), using the square function \\(x^{2}\\) and variance, we have:\n\\[\\mathbb{P}(|X-\\mathbb{E}X|\\geq t)\\leq\\frac{1}{t^{2}}\\mathbb{E}|X-\\mathbb{E}X|^{2}=\\frac{1}{t^{2}}Var(X)\\]\nFor a real-valued random variable \\(X\\), every \\(t\\in\\mathbf{R}\\) and \\(\\lambda&gt;0\\), using the exponential function \\(e^{\\lambda x}\\)(which is monotonic), we have:\n\\[\\mathbb{P}(X\\geq t)=\\mathbb{P}(\\lambda X\\geq\\lambda t)=\\mathbb{P}(e^{\\lambda X}\\geq e^{\\lambda t})\\leq\\frac{1}{e^{\\lambda t}}\\mathbb{E}e^{\\lambda X}\\]\nOur next inequality, the so-called Holder’s inequality is a very effective inequality to factor out the expectation of a product.\n\n\n\n\nTheorem 7 Let \\(p,q\\geq1\\) be such that \\(\\frac{1}{p}+\\frac{1}{q}=1\\), For random variables \\(X\\) and \\(Y\\), we have:\n\\[\\begin{aligned}\n\\mathbb{E}|XY| & \\leq\\left(\\mathbb{E}|X^{p}|\\right)^{1/p}\\left(\\mathbb{E}|Y^{q}|\\right)^{1/q}\\end{aligned}\\]\n\nProof. From the Young’s inequality, for any \\(a,b\\in\\mathbf{R}\\), \\(p,q\\geq1\\), we have:\n\\[\\begin{aligned}\nab & \\leq\\frac{a^{p}}{p}+\\frac{b^{q}}{q}\\end{aligned}\\]\nSetting \\(a=\\frac{|X|}{\\left(\\mathbb{E}|X^{p}|\\right)^{1/p}}\\) and \\(b=\\frac{|Y|}{\\left(\\mathbb{E}|Y^{q}|\\right)^{1/q}}\\), we get:\n\\[\\begin{aligned}\n\\frac{|XY|}{\\left(\\mathbb{E}|X^{p}|\\right)^{1/p}\\left(\\mathbb{E}|Y^{q}|\\right)^{1/q}} & \\leq\\frac{1}{p}\\cdot\\frac{|X|^{p}}{\\mathbb{E}|X^{p}|}+\\frac{1}{q}\\cdot\\frac{|Y|^{q}}{\\mathbb{E}|Y^{q}|}\\end{aligned}\\]\nTaking expectations on both sides, and using the monotonicity of expectation property, we get:\n\\[\\begin{aligned}\n\\frac{\\mathbb{E}|XY|}{\\left(\\mathbb{E}|X^{p}|\\right)^{1/p}\\left(\\mathbb{E}|Y^{q}|\\right)^{1/q}} & \\leq\\frac{1}{p}\\cdot\\frac{\\mathbb{E}|X|^{p}}{\\mathbb{E}|X^{p}|}+\\frac{1}{q}\\cdot\\frac{\\mathbb{E}|Y|^{q}}{\\mathbb{E}|Y^{q}|}=\\frac{1}{p}+\\frac{1}{q}=1\\end{aligned}\\]\nConsequently,\n\\[\\begin{aligned}\n\\mathbb{E}|XY| & \\leq\\left(\\mathbb{E}|X^{p}|\\right)^{1/p}\\left(\\mathbb{E}|Y^{q}|\\right)^{1/q}\\end{aligned}\\]\nLet \\(p=2\\) and \\(q=2\\). Then, we get the Cauchy-Schwarz inequality:\n\\[\\begin{aligned}\n\\mathbb{E}|XY| & \\leq\\left[\\mathbb{E}(X^{2})\\right]^{1/2}\\left[\\mathbb{E}(Y^{2})\\right]^{1/2}\\end{aligned}\\]\nIn some ways, the \\(p\\)-th moment of a random variable can be thought of as it’s length or \\(p\\)-norm.\nDefine:\n\\[\\left\\Vert X\\right\\Vert _{p}=\\left(\\mathbb{E}|X|^{p}\\right)^{1/p}\\] \nThis closes the proof. \\(\\blacksquare\\)\n\n\n\n\nTheorem 8 For random variables \\(X\\) and \\(Y\\), and for all \\(p\\geq1\\) we have:\n\\[\\left\\Vert X+Y\\right\\Vert _{p}\\leq\\left\\Vert X\\right\\Vert _{p}+\\left\\Vert Y\\right\\Vert _{p}\\]\n\nProof.\nThe basic idea of the proof is to use Holder’s inequality. Let \\(\\frac{1}{q}=1-\\frac{1}{p}\\) or in other words, \\(q=\\frac{p}{p-1}\\). We have:\n\\[\\begin{aligned}\n\\mathbb{E}|X||X+Y|^{p-1} & \\leq\\left(\\mathbb{E}|X|^{p}\\right)^{1/p}\\left(\\mathbb{E}|X+Y|^{(p-1)q}\\right)^{1/q} & (a)\\\\ \\mathbb{E}|Y||X+Y|^{p-1} & \\leq\\left(\\mathbb{E}|Y|^{p}\\right)^{1/p}\\left(\\mathbb{E}|X+Y|^{(p-1)q}\\right)^{1/q} & (b)\\end{aligned}\\]\nAdding the above two equations, we get:\n\\[\\begin{aligned}\n\\mathbb{E}(|X+Y||X+Y|^{p-1})\\leq\\mathbb{E}(|X|+|Y|)(|X+Y|^{p-1}) & \\leq\\left\\{ \\left(\\mathbb{E}|X|^{p}\\right)^{1/p}+\\left(\\mathbb{E}|Y|^{p}\\right)^{1/p}\\right\\} \\left(\\mathbb{E}|X+Y|^{(p-1)q}\\right)^{1/q}\\\\ \\mathbb{E}|X+Y|^{p} & \\leq\\left\\{ \\left\\Vert X\\right\\Vert _{p}+\\left\\Vert Y\\right\\Vert _{p}\\right\\} \\left(\\mathbb{E}|X+Y|^{p}\\right)^{1/q}\\\\ \\left(\\mathbb{E}|X+Y|^{p}\\right)^{1/p} & \\leq\\left\\Vert X\\right\\Vert _{p}+\\left\\Vert Y\\right\\Vert _{p}\\\\ \\left\\Vert X+Y\\right\\Vert _{p} & \\leq\\left\\Vert X\\right\\Vert _{p}+\\left\\Vert Y\\right\\Vert _{p}\\end{aligned}\\] \nThis closes the proof. \\(\\blacksquare\\)"
  },
  {
    "objectID": "posts/gaussian-processes/index.html#a-quick-refresher-of-linear-algebra.",
    "href": "posts/gaussian-processes/index.html#a-quick-refresher-of-linear-algebra.",
    "title": "Gaussian Processes",
    "section": "",
    "text": "Many of the concepts in this chapter have very elegant interpretations, if we think of real-valued random variables on a probability space as vectors in a vector space. In particular, variance is related to the concept of norm and distance, while covariance is related to inner-products. These concepts can help unify some of the ideas in this chapter from a geometric point of view. Of course, real-valued random variables are simply measurable, real-valued functions on the abstract space \\(\\Omega.\\)\n\nDefinition 4 (Vector Space.) By a vector space, we mean a non-empty set \\(V\\) with two operations: :::\n\nVector addition: \\(+:(\\mathbf{x},\\mathbf{y})\\to\\mathbf{x}+\\mathbf{y}\\)\nScalar multiplication: \\(\\cdot:(\\alpha,\\mathbf{x})\\to\\alpha\\mathbf{x}\\)\n\nsuch that the following conditions are satisfied:\n(A1) Commutativity. \\(\\mathbf{x}+\\mathbf{y}=\\mathbf{y}+\\mathbf{x}\\) for all \\(\\mathbf{x},\\mathbf{y}\\in V\\)\n(A2) Associativity: \\((\\mathbf{x}+\\mathbf{y})+\\mathbf{z}=\\mathbf{x}+(\\mathbf{y}+\\mathbf{z})\\) for all \\(\\mathbf{x},\\mathbf{y},\\mathbf{z}\\in V\\)\n(A3) Zero Element: There exists a zero element, denoted \\(\\mathbf{0}\\) in \\(V\\), for all \\(\\mathbf{x}\\in V\\), such that \\(\\mathbf{x}+\\mathbf{0}=\\mathbf{x}\\).\n(A4) Additive Inverse: For all \\(\\mathbf{x}\\in V\\), there exists an additive inverse(negative element) denoted \\(-\\mathbf{x}\\) in \\(V\\), such that \\(\\mathbf{x}+(-\\mathbf{x})=\\mathbf{0}\\).\n(M1) Scalar multiplication by identity element in \\(F\\): For all \\(\\mathbf{x}\\in V\\), \\(1\\cdot\\mathbf{x}=\\mathbf{x}\\), where \\(1\\) denotes the multiplicative identity in \\(F\\).\n(M2) Scalar multiplication and field multiplication mix well: For all \\(\\alpha,\\beta\\in F\\) and \\(\\mathbf{v}\\in V\\), \\((\\alpha\\beta)\\mathbf{v}=\\alpha(\\beta\\mathbf{v})\\).\n(D1) Distribution of scalar multiplication over vector addition: For all \\(\\alpha\\in F\\), and \\(\\mathbf{u},\\mathbf{v}\\in V\\), \\(\\alpha(\\mathbf{u}+\\mathbf{v})=\\alpha\\mathbf{u}+\\alpha\\mathbf{v}\\).\n(D2) Distribution of field addition over scalar multiplication: For all \\(\\alpha,\\beta\\in F\\), and \\(\\mathbf{v}\\in V\\), \\((\\alpha+\\beta)\\mathbf{v}=\\alpha\\mathbf{v}+\\beta\\mathbf{v}\\).\n\nAs usual, our starting point is a random experiment modeled by a probability space \\((\\Omega,\\mathcal{F},\\mathbb{P})\\), so that \\(\\Omega\\) is the set of outcomes, \\(\\mathscr{\\mathcal{F}}\\) is the \\(\\sigma\\)-algebra of events and \\(\\mathbb{P}\\) is the probability measure on the measurable space \\((\\Omega,\\mathcal{F})\\). Our basic vector space \\(V\\) consists of all real-valued random variables defined on \\((\\Omega,\\mathcal{F},\\mathbb{P})\\). We define vector addition and scalar multiplication in the usual way point-wise.\n\nVector addition: \\((X+Y)(\\omega)=X(\\omega)+Y(\\omega)\\).\nScalar multiplication: \\((\\alpha X)(\\omega)=\\alpha X(\\omega)\\)\n\nClearly, any function \\(g\\) of a random variable \\(X(\\omega)\\) is also a random variable on the same probability space and any linear combination of random variables on \\((\\Omega,\\mathcal{F},\\mathbb{P})\\) also define a new random variable on the same probability space. Thus, \\(V\\) is closed under vector addition and scalar-multiplication. Since vector-addition and scalar multiplication is defined point-wise, it is easy to see that - all the axioms of a vector space (A1)-(A4), (M1-M2), (D1), (D2) are satisfied. The constantly zero random variable \\(0(\\omega)=0\\) and the indicator random variable \\(I_{\\Omega}(\\omega)\\) can be thought of as the zero and identity vectors in this vector space.\nClearly, any function \\(g\\) of a random variable \\(X(\\omega)\\) is also a random variable on the same probability space and any linear combination of random variables on \\((\\Omega,\\mathcal{F},\\mathbb{P})\\) also define a new random variable on the same probability space. Thus, \\(V\\) is closed under vector addition and scalar-multiplication. Since vector-addition and scalar multiplication is defined point-wise, it is easy to see that - all the axioms of a vector space (A1)-(A4), (M1-M2), (D1), (D2) are satisfied. The constantly zero random variable \\(0(\\omega)=0\\) and the indicator random variable \\(I_{\\Omega}(\\omega)\\) can be thought of as the zero and identity vectors in this vector space.\n\n\nIn Euclidean geometry, the angle between two vectors is specified by their dot product, which is itself formalized by the abstract concept of inner products.\n\nDefinition 5 (Inner Product.) An inner product on the real vector space \\(V\\) is a pairing that takes two vectors \\(\\mathbf{v},\\mathbf{w}\\in V\\) and produces a real number \\(\\left\\langle \\mathbf{v},\\mathbf{w}\\right\\rangle \\in\\mathbf{R}\\). The inner product is required to satisfy the following three axioms for all \\(\\mathbf{u},\\mathbf{v},\\mathbf{w}\\in V\\) and scalars \\(c,d\\in\\mathbf{R}\\).\n\nBilinearity: \\[\n\\left\\langle c\\mathbf{u}+d\\mathbf{v},\\mathbf{w}\\right\\rangle =c\\left\\langle \\mathbf{u},\\mathbf{w}\\right\\rangle +d\\left\\langle \\mathbf{v},\\mathbf{w}\\right\\rangle\n\\]\n\n\\[\n\\left\\langle \\mathbf{u},c\\mathbf{v}+d\\mathbf{w}\\right\\rangle =c\\left\\langle \\mathbf{u},\\mathbf{v}\\right\\rangle +d\\left\\langle \\mathbf{u},\\mathbf{w}\\right\\rangle\n\\]\n\nSymmetry:\n\n\\[\n\\left\\langle \\mathbf{v},\\mathbf{w}\\right\\rangle =\\left\\langle \\mathbf{w},\\mathbf{v}\\right\\rangle\n\\]\n\nPositive Definiteness:\n\n\\[\n\\left\\langle \\mathbf{v},\\mathbf{v}\\right\\rangle &gt;0\\quad\\text{ whenever }\\mathbf{v\\neq\\mathbf{0}}\n\\]\n\\[\n\\left\\langle \\mathbf{v},\\mathbf{v}\\right\\rangle =0\\quad\\text{ whenever }\\mathbf{v=0}\n\\]\n\n\nDefinition 6 (Norm). A norm on a real vector space \\(V\\) is a function \\(\\left\\Vert \\cdot\\right\\Vert :V\\to\\mathbf{R}\\) satisfying :\n(i) Positive Definiteness.\n\\[\\left\\Vert \\mathbf{v}\\right\\Vert \\geq0\\]\nand \\[\\left\\Vert \\mathbf{v}\\right\\Vert =0\\quad\\text{if and only if }\\mathbf{v}=\\mathbf{0}\\]\n(ii) Scalar multiplication.\n\\[\\left\\Vert \\alpha\\mathbf{v}\\right\\Vert =|\\alpha|\\left\\Vert \\mathbf{v}\\right\\Vert\\]\n(iii) Triangle Inequality.\n\\[\\left\\Vert \\mathbf{x+y}\\right\\Vert \\leq\\left\\Vert \\mathbf{x}\\right\\Vert +\\left\\Vert \\mathbf{y}\\right\\Vert\\]\n\nAs mentioned earlier, we can define the \\(p\\)-norm of a random variable as:\n\\[\n\\begin{aligned}\n\\left\\Vert X\\right\\Vert _{p} & =\\left(\\mathbb{E}|X|^{p}\\right)^{1/p}\n\\end{aligned}\n\\]\n(i) Positive semi-definiteness: Since \\(|X|\\) is a non-negative random variable, \\(|X|^{p}\\geq0\\) and the expectation of a non-negative random variable is also non-negative. Hence, \\((\\mathbb{E}|X|^{p})^{1/p}\\geq0\\). Moreover, \\(\\left\\Vert X\\right\\Vert _{p}=0\\) implies that \\(\\mathbb{E}|X|^{p}=0\\). From property (iv) of expectations, \\(X=0\\).\n(ii) Scalar-multiplication: We have:\n\\[\n\\begin{aligned}\n\\left\\Vert cX\\right\\Vert _{p} & =\\left(\\mathbb{E}|cX|^{p}\\right)^{1/p}\\\\\n& =\\left(|c|^{p}\\right)^{1/p}\\left(\\mathbb{E}|X|^{p}\\right)^{1/p}\\\\\n& =|c|\\cdot\\left\\Vert X\\right\\Vert _{p}\n\\end{aligned}\n\\]\n(iii) Triangle Inequality. This followed from the Minkowski’s inequality.\nThe space of all random variables defined on \\((\\Omega,\\mathcal{\\mathcal{F}},\\mathbb{P})\\) such that \\(||X||_{p}&lt;\\infty\\) is finite is called the \\(L^{p}\\) space.\n\n\n\n\nDefinition 7 (Orthogonal Matrix.) Let \\(A\\) be an \\(n\\times n\\) square matrix. We say that the matrix \\(A\\) is orthogonal, if its transpose is equal toits inverse.\n\\[\n\\begin{aligned}\nA' & =A^{-1}\n\\end{aligned}\n\\]\n\nThis may seem like an odd property to study, but the following theorem explains why it is so useful. Essentially, an orthogonal matrix rotates (or reflects) vectors without distorting angles or distances.\n\nProposition 1 (Properties of an orthogonal matrix) Faor an \\(n\\times n\\) square matrix \\(A\\), the following are equivalent:\n(1) \\(A\\) is orthogonal. That is, \\(A'A=I\\).\n(2) \\(A\\) preserves norms. That is, for all \\(\\mathbf{x}\\),\n\\[\\begin{aligned}\n\\left\\Vert A\\mathbf{x}\\right\\Vert &=\\left\\Vert \\mathbf{x}\\right\\Vert \\end{aligned}\\]\n(3) \\(A\\) preserves inner products, that is, for every \\(\\mathbf{x}\\), \\(\\mathbf{y}\\)\\(\\in\\mathbf{R}^{n}\\):\n\\[\\begin{aligned}\n(A\\mathbf{x})\\cdot(A\\mathbf{y}) &=\\mathbf{x}\\cdot\\mathbf{y}\\end{aligned}\\]\n\nProof.\nWe have:\n\\[\\begin{aligned}\n\\left\\Vert A\\mathbf{x}\\right\\Vert ^{2} & =\\left(A\\mathbf{x}\\right)'(A\\mathbf{x})\\\\\n& =\\mathbf{x}'(A'A)\\mathbf{x}\\\\\n& =\\mathbf{x}'I\\mathbf{x}\\\\\n& =\\mathbf{x}'\\mathbf{x}\\\\\n& =||\\mathbf{x}||^{2}\\end{aligned}\\]\nConsequently, \\(||A\\mathbf{x}||=||\\mathbf{x}||\\). The matrix \\(A\\) preserves norms. Thus, (1) implies (2).\nMoreover, consider\n\\[\\begin{aligned}\n||A(\\mathbf{x}+\\mathbf{y})||^{2} & =\\left(A\\mathbf{x}+A\\mathbf{y}\\right)\\cdot\\left(A\\mathbf{x}+A\\mathbf{y}\\right)\\\\\n& =(A\\mathbf{x})\\cdot(A\\mathbf{x})+(A\\mathbf{x})\\cdot(A\\mathbf{y})+(A\\mathbf{y})\\cdot(A\\mathbf{x})+(A\\mathbf{y})\\cdot(A\\mathbf{y})\\\\\n& =||A\\mathbf{x}||^{2}+2(A\\mathbf{x})\\cdot(A\\mathbf{y})+||A\\mathbf{y}||^{2} & \\{\\mathbf{x}\\cdot\\mathbf{y}=\\mathbf{y}\\cdot\\mathbf{x}\\}\\\\\n& =||\\mathbf{x}||^{2}+2(A\\mathbf{x})\\cdot(A\\mathbf{y})+||\\mathbf{y}||^{2} & \\{A\\text{ preserves norms}\\}\\end{aligned}\\]\nBut, \\(||A(\\mathbf{x}+\\mathbf{y})||^{2}=||\\mathbf{x}+\\mathbf{y}||^{2}=||\\mathbf{x}||^{2}+2\\mathbf{x}\\cdot\\mathbf{y}+||\\mathbf{y}||^{2}\\).\nEquating the two expressions, we have the desired result. Hence, (2) implies (3).\nLastly, if \\(A\\) preserves inner products, we may write:\n\\[\\begin{aligned}\n\\left\\langle A\\mathbf{x},A\\mathbf{x}\\right\\rangle  & =\\left\\langle \\mathbf{x},\\mathbf{x}\\right\\rangle \\\\\n\\left(A\\mathbf{x}\\right)'(A\\mathbf{x}) & =\\mathbf{x}'\\mathbf{x}\\\\\n\\mathbf{x}'A'A\\mathbf{x} & =0\\end{aligned}\\]\nSince \\(\\mathbf{x}\\neq\\mathbf{0}\\), it must be true that \\(\\mathbf{x}'A'A-\\mathbf{x}'=0\\). Again, since \\(\\mathbf{x}'\\neq\\mathbf{0}\\), it follows that \\(A'A-I=0\\).\n\nTheorem 9 (Linear Independence of orthogonal vectors) If \\(\\mathbf{q}_{1},\\mathbf{q}_{2},\\ldots,\\mathbf{q}_{k}\\in V\\) be mutually orthogonal elements, such that \\(\\mathbf{q}_{i}\\neq\\mathbf{0}\\) for all \\(i\\), then \\(\\mathbf{q}_{1},\\mathbf{q}_{2},\\ldots,\\mathbf{q}_{k}\\) are linearly independent.\n\nProof.\nLet\n\\[\\begin{aligned}\nc_{1}\\mathbf{q}_{1}+c_{2}\\mathbf{q}_{2}+\\ldots+c_{k}\\mathbf{q}_{k} & =\\mathbf{0}\\end{aligned}\\]\nSince \\(\\left\\langle \\mathbf{q}_{i},\\mathbf{q}_{i}\\right\\rangle =1\\) and \\(\\left\\langle \\mathbf{q}_{i},\\mathbf{q}_{j}\\right\\rangle =0\\) where \\(i\\neq j\\), we can take the inner product of the vector \\(c_1 \\mathbf{q}_{1} + c_2 \\mathbf{q}_{2} + \\ldots + c_i \\mathbf{q}_{i}+\\ldots + c_{k}\\mathbf{q}_{k}\\) with \\(\\mathbf{q}_{i}\\) for each \\(i=1,2,3,\\ldots,k\\). It results in \\(c_{i}||\\mathbf{q}_{i}||^{2}=0\\). Since \\(\\mathbf{q}_{i}\\neq\\mathbf{0}\\), \\(||\\mathbf{q}_{i}||^{2}&gt;0\\). So, \\(c_{i}=0\\). We conclude that \\(c_{1}=c_{2}=\\ldots=c_{k} =0\\). Consequently, \\(\\mathbf{q}_{1},\\mathbf{q}_{2},\\ldots,\\mathbf{q}_{k}\\) are linearly independent. \\(\\blacksquare\\)\n\nTheorem 10 (Orthogonal vectors form a basis) Let \\(Q=\\left[\\begin{array}{cccc} \\mathbf{q}_{1} & \\mathbf{q}_{2} & \\ldots & \\mathbf{q}_{n}\\end{array}\\right]\\) be an \\(n\\times n\\) orthogonal matrix. Then, \\(\\{\\mathbf{q}_{1},\\ldots,\\mathbf{q}_{n}\\}\\) form an orthonormal basis for \\(\\mathbf{R}^{n}\\).\n\nProof.\nWe have \\(Q\\mathbf{e}_{i}=\\mathbf{q}_{i}\\). Consequently,\n\\[\\begin{aligned}\n\\left\\langle \\mathbf{q}_{i},\\mathbf{q}_{i}\\right\\rangle  & =\\mathbf{q}_{i}'\\mathbf{q}_{i}\\\\\n& =(Q\\mathbf{e}_{i})'(Q\\mathbf{e}_{i})\\\\\n& =\\mathbf{e}_{i}'Q'Q\\mathbf{e}_{i}\\\\\n& =\\mathbf{e}_{i}'I\\mathbf{e}_{i}\\\\\n& =\\mathbf{e}_{i}'\\mathbf{e}_{i}\\\\\n& =1\\end{aligned}\\]\nAssume that \\(i\\neq j\\). We have:\n\\[\\begin{aligned}\n\\left\\langle \\mathbf{q}_{i},\\mathbf{q}_{j}\\right\\rangle  & =\\mathbf{q}_{i}'\\mathbf{q}_{j}\\\\\n& =\\mathbf{e}_{i}'Q'Q\\mathbf{e}_{j}\\\\\n& =\\mathbf{e}_{i}'\\mathbf{e}_{j}\\\\\n& =0\\end{aligned}\\]\nFrom Theorem 9, \\(\\{\\mathbf{q}_{1},\\ldots,\\mathbf{q}_{n}\\}\\) are linearly independent and hence form an orthonormal basis for \\(\\mathbf{R}^{n}\\).\n\n\n\nAn expression of the form:\n\\[\\mathbf{x}'A\\mathbf{x}\\]\nwhere \\(\\mathbf{x}\\) is a \\(n\\times1\\) column vector and \\(A\\) is an \\(n\\times n\\) matrix is called a quadratic form in \\(\\mathbf{x}\\) and\n\\[\\begin{aligned}\n\\mathbf{x}'A\\mathbf{x} & =\\sum_{i=1}^{n}\\sum_{j=1}^{n}a_{ij}x_{i}x_{j}\\end{aligned}\\]\nIf \\(A\\) and \\(B\\) are \\(n\\times n\\) and \\(\\mathbf{x},\\mathbf{y}\\) are \\(n\\)-vectors, then\n\\[\\begin{aligned}\n\\mathbf{x}'(A+B)\\mathbf{y} & =\\mathbf{x}'A\\mathbf{y}+\\mathbf{x}'B\\mathbf{y}\\end{aligned}\\]\nThe quadratic form of the matrix \\(A\\) is called positive definite if:\n\\[\\begin{aligned}\n\\mathbf{x}'A\\mathbf{x} & &gt;0\\quad\\text{whenever }\\mathbf{x}\\neq\\mathbf{0}\\end{aligned}\\]\nand positive semidefinite if:\n\\[\\begin{aligned}\n\\mathbf{x}'A\\mathbf{x} & \\geq0\\quad\\text{whenever }\\mathbf{x}\\neq\\mathbf{0}\\end{aligned}\\]\nLetting \\(\\mathbf{e}_{i}\\) be the unit vector with it’s \\(i\\)th coordinate vector \\(1\\), we have:\n\\[\n\\begin{aligned}\n\\mathbf{e}_{i}'A\\mathbf{e}_{i} & =\\left[a_{i1}a_{i2}\\ldots a_{ii}\\ldots a_{in}\\right]\\left[\\begin{array}{c}\n0\\\\\n0\\\\\n\\vdots\\\\\n1\\\\\n\\vdots\\\\\n0\n\\end{array}\\right]=a_{ii}\n\\end{aligned}\n\\]\n\n\n\nLet \\(V\\) and \\(W\\) be finite dimensional vector spaces with \\(dim(V)=n\\) and \\(dim(W)=m\\). A linear transformation \\(T:V\\to W\\), is defined by its action on the basis vectors. Suppose:\n\\[\n\\begin{aligned}\nT(\\mathbf{v}_{j}) & =\\sum_{i=1}^{n}a_{ij}\\mathbf{w}_{i}\n\\end{aligned}\n\\]\nfor all \\(1\\leq i\\leq m\\).\nThen, the matrix \\(A=[T]_{\\mathcal{B}_{V}}^{\\mathcal{B}_{W}}\\) of the linear transformation is defined as:\n\\[\\begin{aligned}\nA & =\\left[\\begin{array}{cccc}\na_{11} & a_{12} & \\ldots & a_{1n}\\\\\na_{21} & a_{22} & \\ldots & a_{2n}\\\\\n\\vdots & \\vdots & \\ddots & \\vdots\\\\\na_{m1} & a_{m2} & \\ldots & a_{mn}\n\\end{array}\\right]\\end{aligned}\\]\n\nDefinition 8 A linear transformation \\(T:V\\to V\\) is said to be diagonalizable if there exists an ordered basis \\(\\mathcal{B}=\\{\\mathbf{v}_{1},\\ldots,\\mathbf{v}_{n}\\}\\) for \\(V\\) so that the matrix for \\(T\\) with respect to \\(\\mathcal{B}\\) is diagonal. This means precisely that, for some scalars \\(\\lambda_{1},\\lambda_{2},\\ldots,\\lambda_{n}\\), we have:\n\\[\n\\begin{aligned}\nT(\\mathbf{v}_{1}) & =\\lambda_{1}\\mathbf{v}_{1}\\\\\nT(\\mathbf{v}_{2}) & =\\lambda_{2}\\mathbf{v}_{2}\\\\\n\\vdots\\\\\nT(\\mathbf{v}_{n}) & =\\lambda_{n}\\mathbf{v}_{n}\n\\end{aligned}\n\\]\n\nIn other words, if \\(A=[T]_{\\mathcal{B}}\\), then we have:\n\\[\\begin{aligned}\nA\\mathbf{v}_{i} & =\\lambda_{i}\\mathbf{v}_{i}\\end{aligned}\\]\nThus, if we let \\(P\\) be the \\(n\\times n\\) matrix whose columns are the vectors \\(\\mathbf{v}_{1},\\mathbf{v}_{2},\\ldots,\\mathbf{v}_{n}\\) and \\(\\Lambda\\) be the \\(n\\times n\\) diagonal matrix with diagonal entries \\(\\lambda_{1},\\lambda_{2},\\ldots,\\lambda_{n}\\), then we have:\n\\[\\begin{aligned}\nA\\left[\\begin{array}{cccc}\n\\mathbf{v}_{1} & \\mathbf{v}_{2} & \\ldots & \\mathbf{v}_{n}\\end{array}\\right] & =\\left[\\begin{array}{cccc}\n\\mathbf{v}_{1} & \\mathbf{v}_{2} & \\ldots & \\mathbf{v}_{n}\\end{array}\\right]\\left[\\begin{array}{cccc}\n\\lambda_{1}\\\\\n& \\lambda_{2}\\\\\n&  & \\ddots\\\\\n&  &  & \\lambda_{n}\n\\end{array}\\right]\\\\\nAP & =P\\Lambda\\\\\nA & =P\\Lambda P^{-1}\\end{aligned}\\]\nThere exists a large class of diagonalizable matrices - the symmetric matrices. A square matrix \\(A\\) is symmetric, if \\(A=A'\\).\n\nDefinition 9 (Eigenvectors) Let \\(T:V\\to V\\) be a linear transformation. A non-zero vector \\(\\mathbf{v}\\in V\\) is called the eigenvector of \\(T\\), if there is a scalar \\(\\lambda\\) so that \\(T(\\mathbf{v})=\\lambda\\mathbf{v}\\). The scalar \\(\\lambda\\) is called the eigenvalue of \\(T\\)."
  },
  {
    "objectID": "posts/exercises-in-template-programming/index.html",
    "href": "posts/exercises-in-template-programming/index.html",
    "title": "Challenging exercises in Template Metaprogramming",
    "section": "",
    "text": "For type metaprogramming, the central data structures are the typelist and std::index_sequence. A TypeList is just a static list of types. A std::index_sequence is an integer sequence known at compile-time. TypeLists and std::index_sequences differ from run-time data structures, such as std::list, in that they don’t allow mutation. Adding an element to a TypeList, does not change the original TypeList: rather it creates a new typelist without modifying the original. If you are familar with functional programming languages like Haskell and F#, there’s a lot of parallel between working with typelists in C++ and lists in those languages.\n\n\n\nA TypeList is implemented as a class template. A particular instance of a typelist is a template specialization that encodes the contents of the typelist as template arguments.\ntemplate&lt;typename... Ts&gt;\nstruct TypeList{\n    using type = TypeList&lt;Ts...&gt;;\n    static constexpr auto value = TypeList&lt;Ts...&gt;{};\n};\n\nusing SignedIntegralTypes = TypeList&lt;signed char, short, \n                            int, long, long long&gt;;\nmake_index_sequence metafunction is used to create an integer sequence.\nconstexpr std::index_seq seq = std::make_index_sequence&lt;1,2,3,4,5&gt;{};\n\n\n\nManipulating the typelist and index_sequence typically requires breaking the typelist into parts, generally by separting the first element in the list (the head) from the remaining elements in the list (the tail).\n// front implementation\ntemplate&lt;typename List&gt;\nstruct front;\n\ntemplate&lt;typename Head, typename... Tail&gt;\nstruct front&lt;TypeList&lt;Head,Tail...&gt;&gt;{\n    using type = Head;\n    static constexpr auto value = Head{};\n};\n\ntemplate&lt;typename List&gt;\nstruct seq_front;\n\ntemplate&lt;size_t First, size_t... Rest&gt;\nstruct seq_front&lt;std::index_sequence&lt;First,Rest...&gt;&gt;{\n    static constexpr size_t value = First;\n};\n\nint main(){\n    static_assert(std::is_same_v&lt;front&lt;TypeList&lt;int,float&gt;&gt;::type, int&gt;);\n    constexpr auto seq_front_result = seq_front&lt;std::index_sequence&lt;1,5,8,12&gt;&gt;::value;\n    std::cout &lt;&lt; std::format(\"\\nseq_front result = {}\", seq_front_result);\n}\nCompiler Explorer\nThe above implementation splits the typelist elements into the head and tail and then forms a new TypeList specialization from the elements in the tail.\n\n\n\nThe pop_front metafunction removes the first element from the typelist. Its implementation splits the typelist elements into the head and tail and then forms a new typelist from the elements in the tail.\ntemplate&lt;typename List&gt;\nstruct pop_front;\n\ntemplate&lt;typename Head, typename... Tail&gt;\nstruct pop_front&lt;TypeList&lt;Head,Tail...&gt;&gt;{\n    using type = TypeList&lt;Tail...&gt;;\n    static constexpr auto value = TypeList&lt;Tail...&gt;{};\n};\n\ntemplate&lt;typename List&gt;\nstruct seq_pop_front;\n\ntemplate&lt;size_t First, size_t... Rest&gt;\nstruct seq_pop_front&lt;std::index_sequence&lt;First,Rest...&gt;&gt;{\n    using type = std::index_sequence&lt;Rest...&gt;;\n    static constexpr auto value = std::index_sequence&lt;Rest...&gt;{};\n};\nCompiler Explorer\n\n\n\nWe can also insert elements onto the front of the typelist by capturing all of the existing elements into a template parameter pack, then creating a new TypeList specialization containing all of those elements:\ntemplate&lt;typename Element, typename List&gt;\nstruct push_front;\n\ntemplate&lt;typename T, typename... Ts&gt;\nstruct push_front&lt;T, TypeList&lt;Ts...&gt;&gt;{\n    using type = TypeList&lt;T,Ts...&gt;;\n    static constexpr auto value = TypeList&lt;T,Ts...&gt;{};\n};\n\ntemplate&lt;size_t I, typename IndexSequenceT&gt;\nstruct seq_push_front;\n\ntemplate&lt;size_t I, size_t... Is&gt;\nstruct seq_push_front&lt;I, std::index_sequence&lt;Is...&gt;&gt;{\n    using type = std::index_sequence&lt;I,Is...&gt;;\n    static constexpr auto value = std::index_sequence&lt;I,Is...&gt;{};\n};\n\ntemplate&lt;size_t I, typename IndexSequence&gt;\nusing seq_push_front_t = seq_push_front&lt;I,IndexSequence&gt;::type;\n\n\n\n// push_back implementation\ntemplate&lt;typename Element, typename List&gt;\nstruct push_back;\n\ntemplate&lt;typename Element&gt;\nstruct push_back&lt;Element, TypeList&lt;&gt;&gt;{\n    using type = TypeList&lt;Element&gt;;\n};\n\ntemplate&lt;typename Element, typename... Ts&gt;\nstruct push_back&lt;Element, TypeList&lt;Ts...&gt;&gt;{\n    using type = TypeList&lt;Ts...,Element&gt;;\n};\n\n// push_back implementation for index_sequence\ntemplate&lt;size_t I, typename IndexSequence&gt;\nstruct seq_push_back;\n\ntemplate&lt;size_t I, size_t... Is&gt;\nstruct seq_push_back&lt;I, std::index_sequence&lt;Is...&gt;&gt;{\n    using type = std::index_sequence&lt;Is...,I&gt;;\n    static constexpr auto value = std::index_sequence&lt;Is...,I&gt;{};\n};\n\ntemplate&lt;size_t I, typename IndexSequence&gt;\nusing seq_push_back_t = seq_push_back&lt;I,IndexSequence&gt;::type;\n\n\n\nThe fundamental typelist operations front, push_front, back and push_back can be composed to create more interesting typelist manipulations. For example, we can replace the first element in a typelist by applying push_front to the result of pop_front.\nGoing further, we can implement algorithms - searches, transformations, reversals as metafunctions operating on typelists.\n\n\nOne of the most fundamental operations on a typelist is to extract a specific element of the list. Let us code up a metafunction to extract the \\(N\\)th element.\ntemplate&lt;size_t I, typename List&gt;\nstruct nth_element;\n\ntemplate&lt;typename First, typename... Rest&gt;\nstruct nth_element&lt;1,TypeList&lt;First, Rest...&gt;&gt;{\n    using type = First;\n};\n\ntemplate&lt;size_t N, typename First, typename... Rest&gt;\nstruct nth_element&lt;N, TypeList&lt;First, Rest...&gt;&gt; : nth_element&lt;N-1, TypeList&lt;Rest...&gt;&gt;{};\n\ntemplate&lt;size_t N, typename List, size_t... Is&gt;\nstruct seq_nth_element;\n\ntemplate&lt;size_t I, size_t... Is&gt;\nstruct seq_nth_element&lt;1,std::index_sequence&lt;I,Is...&gt;&gt;{\n    static constexpr auto value = I;\n};\n\ntemplate&lt;size_t N, size_t I, size_t... Is&gt;\nstruct seq_nth_element&lt;N, std::index_sequence&lt;I,Is...&gt;&gt; : seq_nth_element&lt;N-1,std::index_sequence&lt;Is...&gt;&gt;{};\nCompiler Explorer\n\n\n\nMany typelist algorithms search for data within the typelist. This too can be easily achieved with a recursive template metaprogram.\n#include &lt;utility&gt;\n#include &lt;memory&gt;\n#include &lt;format&gt;\n#include &lt;iostream&gt;\n\ntemplate&lt;typename List, template&lt;size_t I&gt; typename Predicate, size_t... Is&gt;\nstruct seq_find_if;\n\ntemplate&lt;template&lt;size_t &gt; typename Predicate&gt;\nstruct seq_find_if&lt;std::index_sequence&lt;&gt;,Predicate&gt; {\n    using type = std::false_type;\n};\n\ntemplate&lt;size_t First, template&lt;size_t &gt; typename Predicate, size_t... Is&gt;\nstruct seq_find_if&lt;std::index_sequence&lt;First, Is...&gt;,Predicate&gt; {\n    static constexpr bool is_true = Predicate&lt;First&gt;::value;\n    static constexpr bool more_elements_to_check = (sizeof...(Is) &gt; 0);\n    using type = std::conditional&lt;\n        is_true, \n        std::integral_constant&lt;size_t,First&gt;, \n        typename std::conditional&lt;more_elements_to_check, typename seq_find_if&lt;std::index_sequence&lt;Is...&gt;,Predicate&gt;::type, std::false_type&gt;::type\n    &gt;::type;\n};\n\ntemplate&lt;size_t N&gt;\nstruct my_predicate{\n    using type = std::conditional&lt;(N % 2 == 0),std::true_type, std::false_type&gt;::type;\n    static constexpr bool value = (N % 2 == 0);\n};\n\nint main(){\n    static_assert(std::is_same_v&lt;\n        seq_find_if&lt;std::index_sequence&lt;1,2,3,4&gt;,my_predicate&gt;::type,\n        std::integral_constant&lt;size_t,2&gt;\n    &gt;);\n}\nCompiler Explorer\n\n\n\nWhen typelists have some ordering among their elements, it is convenient to be able to reverse the ordering of the elements in the typelist when applying some algorithms. The reverse algorithm implements this metafunction:\ntemplate&lt;typename List&gt;\nstruct reverse;\n\n// basis case\ntemplate&lt;typename Head&gt;\nstruct reverse&lt;TypeList&lt;Head&gt;&gt;{\n    using type = TypeList&lt;Head&gt;;\n};\n\ntemplate&lt;typename... Ts&gt;\nstruct reverse&lt;TypeList&lt;Ts...&gt;&gt;{\n    using front_el = front&lt;TypeList&lt;Ts...&gt;&gt;::type;\n    using tail = pop_front&lt;TypeList&lt;Ts...&gt;&gt;::type;\n    using type = push_back&lt;front_el, typename reverse&lt;tail&gt;::type&gt;::type;\n};\nCompiler Explorer\ntemplate&lt;typename IndexSequence&gt;\nstruct seq_reverse;\n\ntemplate&lt;size_t Head&gt;\nstruct seq_reverse&lt;std::index_sequence&lt;Head&gt;&gt;{\n    using type = std::index_sequence&lt;Head&gt;;\n    static constexpr auto value = std::index_sequence&lt;Head&gt;{};\n};\n\ntemplate&lt;size_t Head, size_t... Tail&gt;\nstruct seq_reverse&lt;std::index_sequence&lt;Head,Tail...&gt;&gt;{\n    using type = seq_push_back&lt;Head,typename seq_reverse&lt;std::index_sequence&lt;Tail...&gt;&gt;::type&gt;::type;\n};\nCompiler Explorer\n\n\n\ntemplate&lt;template &lt;size_t I&gt; typename Func, typename IndexSequence&gt;\nstruct seq_transform;\n\ntemplate&lt;template &lt;size_t I&gt; typename Func, size_t First&gt;\nstruct seq_transform&lt;Func, std::index_sequence&lt;First&gt;&gt;{\n    using type=std::index_sequence&lt;Func&lt;First&gt;::value&gt;;\n};\n\ntemplate&lt;template &lt;size_t I&gt; typename Func, size_t... Is&gt;\nstruct seq_transform&lt;Func, std::index_sequence&lt;Is...&gt;&gt;{\n    static constexpr size_t front_el = seq_front&lt;std::index_sequence&lt;Is...&gt;&gt;::value;\n    using tail = seq_pop_front&lt;std::index_sequence&lt;Is...&gt;&gt;::type;\n    using type = seq_push_front&lt;Func&lt;front_el&gt;::value, typename seq_transform&lt;Func,tail&gt;::type&gt;::type;\n};\nCompiler Explorer\n\n\n\nAssume that we a sorted integer sequence such as \\(1, 2, 2, 2, 4, 4, 5, \\ldots\\). We are interested to write a function seq_uniq that will remove duplicates from the sequence.\ntemplate&lt;typename List&gt;\nstruct seq_uniq;\n\ntemplate&lt;size_t I&gt;\nstruct seq_uniq&lt;std::index_sequence&lt;I&gt;&gt;{\n    using type = std::index_sequence&lt;I&gt;;\n};\n\ntemplate&lt;size_t I1, size_t I2&gt;\nstruct seq_uniq&lt;std::index_sequence&lt;I1, I2&gt;&gt;{\n    using type = std::conditional&lt;\n        (I1 == I2),\n        std::index_sequence&lt;I1&gt;,\n        std::index_sequence&lt;I1, I2&gt;\n    &gt;::type;\n};\n\ntemplate&lt;size_t First, size_t... Rest&gt;\nstruct seq_uniq&lt;std::index_sequence&lt;First,Rest...&gt;&gt;{\n    static constexpr size_t first = First;\n    static constexpr size_t next = seq_front&lt;std::index_sequence&lt;Rest...&gt;&gt;::value;\n    using tail = std::index_sequence&lt;Rest...&gt;;\n    using tail_next = seq_pop_front&lt;std::index_sequence&lt;Rest...&gt;&gt;::type;\n    using type = std::conditional&lt;\n        (first == next),\n        typename seq_uniq&lt;typename seq_push_front&lt;First, tail_next&gt;::type&gt;::type,\n        typename seq_push_front&lt;First, typename seq_uniq&lt;tail&gt;::type&gt;::type\n    &gt;::type;\n};\nCompiler Explorer\n\n\n\nWe can write a cool metafunction to implement merge sort. I’d encourage you to try this as a challenge. Let’s see what you’ve got!\ntemplate&lt;typename V&gt;\nstruct MergeSort{\n    using type = typename MergeVecs&lt;\n        typename MergeSort&lt;typename SplitVec&lt;V&gt;::left&gt;::type,\n        typename MergeSort&lt;typename SplitVec&lt;V&gt;::right&gt;::type\n    &gt;::type;\n};\n\nint main(){\n    static_assert(\n        std::is_same_v&lt;\n            MergeSort&lt;Vec&lt;2, 4, 1, 5, 7, 9, 4, 5&gt;&gt;::type,\n            Vec&lt;1, 2, 4, 4, 5, 5, 7, 9&gt;\n        &gt;\n    );\n}\nHere’s my implementation of merge-sort:\ntemplate&lt;size_t... Is&gt;\nusing Vec = std::index_sequence&lt;Is...&gt;;\n\ntemplate&lt;typename List, typename Indexer&gt;\nstruct SelectVec;\n\ntemplate&lt;size_t... Is, size_t... Js&gt;\nstruct SelectVec&lt;std::index_sequence&lt;Is...&gt;, std::index_sequence&lt;Js...&gt;&gt;{\n    using type = std::index_sequence&lt;seq_nth_element&lt;Is,typename std::index_sequence&lt;Js...&gt;&gt;::value...&gt;;\n};\n\ntemplate&lt;size_t Start,typename List, typename Indexer&gt;\nstruct VecSliceHelper;\n\ntemplate&lt;size_t Start, size_t... Is, size_t... Js&gt;\nstruct VecSliceHelper&lt;Start, std::index_sequence&lt;Is...&gt;, std::index_sequence&lt;Js...&gt;&gt;{\n    using type = std::index_sequence&lt;seq_nth_element&lt;Start + Js,typename std::index_sequence&lt;Is...&gt;&gt;::value...&gt;;\n};\n\ntemplate&lt;size_t Start, size_t End, typename V&gt;\nstruct VecSlice;\n\ntemplate&lt;size_t Start, size_t End, size_t... Is&gt;\nstruct VecSlice&lt;Start, End, Vec&lt;Is...&gt;&gt;{\n    static constexpr size_t num_elements = End - Start + 1;\n    using s = std::make_index_sequence&lt;num_elements&gt;;\n    using type = VecSliceHelper&lt;Start, Vec&lt;Is...&gt;, s&gt;::type;\n};\n\ntemplate&lt;typename V&gt;\nstruct SplitVec;\n\ntemplate&lt;size_t I1, size_t I2&gt;\nstruct SplitVec&lt;Vec&lt;I1, I2&gt;&gt;{\n    using left = Vec&lt;I1&gt;;\n    using right = Vec&lt;I2&gt;;\n};\n\ntemplate&lt;size_t... Is&gt;\nstruct SplitVec&lt;Vec&lt;Is...&gt;&gt;{\n    static constexpr size_t N = sizeof...(Is);\n    static constexpr size_t mid = N / 2;\n    using left = VecSlice&lt;1,mid,Vec&lt;Is...&gt;&gt;::type;\n    using right = VecSlice&lt;mid+1,N,Vec&lt;Is...&gt;&gt;::type;\n};\n\ntemplate&lt;typename Vec1, typename Vec2, typename Result &gt;\nstruct MergeHelper;\n\n// Base cases\ntemplate&lt;size_t... I&gt;\nstruct MergeHelper&lt;Vec&lt;&gt;, Vec&lt;&gt;, Vec&lt;I...&gt;&gt;{\n    using type = Vec&lt;I...&gt;;\n};\n\n// When no elements remain in right subarray\ntemplate&lt;size_t... I1, size_t... I&gt;\nstruct MergeHelper&lt;Vec&lt;I1...&gt;, Vec&lt;&gt;, Vec&lt;I...&gt;&gt;{\n    static constexpr size_t element = seq_front&lt;Vec&lt;I1...&gt;&gt;::value;\n    using tail = seq_pop_front&lt;Vec&lt;I1...&gt;&gt;::type;\n    using result = seq_push_back&lt;element, Vec&lt;I...&gt;&gt;::type;\n    using type = MergeHelper&lt;tail, Vec&lt;&gt;, result&gt;::type;\n};\n\n// When no elements remain in left subarray\ntemplate&lt;size_t... I2, size_t... I&gt;\nstruct MergeHelper&lt;Vec&lt;&gt;, Vec&lt;I2...&gt;, Vec&lt;I...&gt;&gt;{\n    static constexpr size_t element = seq_front&lt;Vec&lt;I2...&gt;&gt;::value;\n    using tail = seq_pop_front&lt;Vec&lt;I2...&gt;&gt;::type;\n    using result = seq_push_back&lt;element, Vec&lt;I...&gt;&gt;::type;\n    using type = MergeHelper&lt;tail, Vec&lt;&gt;, result&gt;::type;\n};\n\n// compare the head elements of both vectors, \n// pop off the smaller of the two and insert it into the results array\ntemplate&lt;size_t... I1, size_t... I2, size_t... I&gt;\nstruct MergeHelper&lt;Vec&lt;I1...&gt;, Vec&lt;I2...&gt;, Vec&lt;I...&gt;&gt;{\n    using left = Vec&lt;I1...&gt;; using right = Vec&lt;I2...&gt;;\n    using left_tail = seq_pop_front&lt;left&gt;::type;\n    using right_tail = seq_pop_front&lt;right&gt;::type;\n    using result = Vec&lt;I...&gt;;\n\n    static constexpr size_t p = seq_front&lt;Vec&lt;I1...&gt;&gt;::value;\n    static constexpr size_t q = seq_front&lt;Vec&lt;I2...&gt;&gt;::value;\n    using type = std::conditional&lt;\n        p &lt; q,\n        typename MergeHelper&lt;left_tail, right, typename seq_push_back&lt;p, result&gt;::type&gt;::type,\n        typename MergeHelper&lt;left, right_tail, typename seq_push_back&lt;q, result&gt;::type&gt;::type\n    &gt;::type;\n};\n\ntemplate&lt;typename Vec1, typename Vec2&gt;\nstruct Merge;\n\ntemplate&lt;size_t... Is, size_t... Js&gt;\nstruct Merge&lt;Vec&lt;Is...&gt;,Vec&lt;Js...&gt;&gt;\n{\n    using type = MergeHelper&lt;Vec&lt;Is...&gt;,Vec&lt;Js...&gt;,Vec&lt;&gt;&gt;::type;\n};\n\ntemplate&lt;typename V&gt;\nstruct MergeSort;\n\ntemplate&lt;&gt;\nstruct MergeSort&lt;Vec&lt;&gt;&gt;{\n    using type = Vec&lt;&gt;;\n};\n\ntemplate&lt;size_t I&gt;\nstruct MergeSort&lt;Vec&lt;I&gt;&gt;{\n    using type = Vec&lt;I&gt;;\n};\n\ntemplate&lt;size_t... Is&gt;\nstruct MergeSort&lt;Vec&lt;Is...&gt;&gt;{\n    using type = Merge&lt;\n        typename MergeSort&lt;typename SplitVec&lt;Vec&lt;Is...&gt;&gt;::left&gt;::type,\n        typename MergeSort&lt;typename SplitVec&lt;Vec&lt;Is...&gt;&gt;::right&gt;::type\n    &gt;::type;\n};\nCompiler Explorer\n\n\n\nLet’s say you have a bunch of compile-time vectors. We’d want to write a metafunction that takes multiple vectors and zips them with *. For example, given the input:\nVector&lt;1,2,3&gt;, Vector&lt;4,5,6&gt;, Vector&lt;7,8,9&gt;\nproduce:\nVector&lt;28,80,162&gt;\nThat is:\nVector&lt;1*4*7, 2*5*8, 3*6*9&gt;\nYou can try writing your implementation using the below as a starting point:\n#include &lt;type_traits&gt;\n#include &lt;iostream&gt;\n#include &lt;utility&gt;\n\n// DEFINITION: Compile-time integer vector defined as: \ntemplate&lt;int... I&gt;\nstruct Vector;\n\n// The code below will assume a 'zip' metafunction is used, but feel free to use a different approach. \n// If you do, please adjust the static assert accordingly. \n\nint main(){\n    static_assert(std::is_same&lt;\n            zip&lt;Vector&lt;1, 2, 3&gt;, Vector&lt;4, 5, 6&gt;, Vector&lt;7, 8, 9&gt;&gt;::type,\n            Vector&lt;1*4*7,2*5*8,3*6*9&gt;&gt;::value, \"\");\n}\nPut on your thinking cap and happy coding! When you’re done with your attempt, you can take a look below at my solution:\n#include &lt;type_traits&gt;\n#include &lt;iostream&gt;\n#include &lt;utility&gt;\n\n// DEFINITION: Compile-time integer vector defined as: \ntemplate&lt;int... I&gt;\nstruct Vector;\n\n// The code below will assume a 'zip' metafunction is used, but feel free to use a different approach. \n// If you do, please adjust the static assert accordingly. \n\n// A getter for the nth-element of the compile-time sequence \n// of integers\ntemplate&lt;size_t N, typename List&gt;\nstruct get;\n\n// Base case\ntemplate&lt;int Head, int... Tail&gt;\nstruct get&lt;0, Vector&lt;Head,Tail...&gt;&gt;{\n    static constexpr auto value = Head;  \n};\n\n// get&lt;N,Vector&lt;I1,I2,...&gt;&gt; inherits from get&lt;N-1,Vector&lt;I2,...&gt;&gt;\ntemplate&lt;size_t N, int Head, int... Tail&gt;\nstruct get&lt;N, Vector&lt;Head,Tail...&gt;&gt; : get&lt;N-1,Vector&lt;Tail...&gt;&gt;{};\n\n\ntemplate&lt;int... I&gt;\nstruct front{\n    static constexpr auto value = get&lt;0, Vector&lt;I...&gt;&gt;::value;\n};\n\ntemplate&lt;typename List&gt;\nstruct pop_front;\n\ntemplate&lt;int I, int... Is&gt;\nstruct pop_front&lt;Vector&lt;I,Is...&gt;&gt;{\n    using type = Vector&lt;Is...&gt;;\n};\n\n// Let's design a metafunction zip that accepts a variadic pack\n// of Vector's.\n// Template declaration\ntemplate&lt;typename... Vectors&gt;\nstruct zip;\n\n// Partial specialization\ntemplate&lt;int... Is&gt;\nstruct zip&lt;Vector&lt;Is...&gt;&gt;{\n    using type = Vector&lt;Is...&gt;;\n};\n\ntemplate&lt;typename Indexes, typename V, typename... List&gt;\nstruct zip_impl;\n\ntemplate&lt;size_t... Is, int... Elements&gt;\nstruct zip_impl&lt;std::index_sequence&lt;Is...&gt;, Vector&lt;Elements...&gt;&gt;{\n    using type = Vector&lt;Elements...&gt;;\n};\n\ntemplate&lt;size_t... Is, int... Elements, typename... Vectors&gt;\nstruct zip_impl&lt;std::index_sequence&lt;Is...&gt;,Vector&lt;Elements...&gt;, Vectors...&gt;{\n    using first = Vector&lt;Elements...&gt;;\n    using rest = typename zip_impl&lt;std::index_sequence&lt;Is...&gt;, Vectors...&gt;::type;\n    using type = Vector&lt;(get&lt;Is, first&gt;::value * get&lt;Is, rest&gt;::value)...&gt;;\n};\n\ntemplate&lt;int... Is, typename... Vectors&gt;\nstruct zip&lt;Vector&lt;Is...&gt;, Vectors...&gt;{\n    static constexpr size_t N = sizeof...(Is);\n    using seq = std::make_index_sequence&lt;N&gt;;\n    using type = zip_impl&lt;seq,Vector&lt;Is...&gt;,Vectors...&gt;::type;\n};\n\n// TEST\nint main() {\n\n    // Test case #1\n    static_assert(get&lt;0,Vector&lt;1,2,3&gt;&gt;::value == 1);\n    static_assert(std::is_same&lt;\n        zip&lt;Vector&lt;1, 2, 3&gt;, Vector&lt;4, 5, 6&gt;, Vector&lt;7, 8, 9&gt;&gt;::type,\n        Vector&lt;1*4*7,2*5*8,3*6*9&gt;&gt;::value, \"\");\n    \n    // TASK: Add more test cases here\n    \n    // TASK: Ensure it compiles before submission\n    return 0;\n}\nCompiler Explorer\n\n\n\n\nA tuple is an arbitrary collection of heterogenous data. It is a recursive data-structure. A tuple has a static component and a run-time component. The list of types are baked into the tuple definition at compile-time. The actual values/objects held by the tuple can be objects known at run-time.\nWe will design a tuple class template. Implementing your own version tuple type is a good exercise to flex your metaprogramming muscles.\n#include &lt;utility&gt;\n#include &lt;memory&gt;\n#include &lt;format&gt;\n#include &lt;iostream&gt;\n#include &lt;cassert&gt;\n\nnamespace dev \n{\n    // TypeList definition\n    template&lt;typename... Ts&gt;\n    struct TypeList{\n        using type = TypeList&lt;Ts...&gt;;\n        static constexpr auto value = TypeList&lt;Ts...&gt;{};\n    };\n\n    // TypeList Indexing \n    template&lt;size_t I, typename List&gt;\n    struct nth_element;\n\n    template&lt;typename First, typename... Rest&gt;\n    struct nth_element&lt;1,TypeList&lt;First, Rest...&gt;&gt;{\n        using type = First;\n    };\n\n    template&lt;size_t N, typename First, typename... Rest&gt;\n    struct nth_element&lt;N, TypeList&lt;First, Rest...&gt;&gt; : nth_element&lt;N-1, TypeList&lt;Rest...&gt;&gt;{};\n\n    // Implement tuple. This is a forward declaration.\n    template &lt;typename... Types&gt;\n    class tuple;\n\n    // Base case\n    template &lt;&gt;\n    class tuple&lt;&gt; { };\n\n    template&lt;typename Head, typename... Tail&gt;\n    requires std::is_trivially_default_constructible_v&lt;Head&gt;\n    class tuple&lt;Head, Tail...&gt;{\n        using type = TypeList&lt;Head, Tail...&gt;;\n\n        private:\n        Head m_head;\n        tuple&lt;Tail...&gt; m_tail;\n\n        public:\n        tuple()\n        : m_head{}\n        , m_tail{}\n        {}\n\n        tuple(Head head, Tail... tail)\n        : m_head{head}\n        , m_tail{tail...}\n        {}\n\n        Head head() const{\n            return m_head;\n        }\n\n        tuple&lt;Tail...&gt; tail() const{\n            return m_tail;\n        }\n\n        constexpr auto empty(){\n            return std::tuple&lt;&gt;();\n        }\n\n        constexpr auto initialize(Head head, Tail... tail){\n            m_head = head;\n            if constexpr(sizeof...(Tail))\n                m_tail.initialize(tail...);\n        }\n    };\n\n    // Implement get\n    template &lt;unsigned N, typename... Types&gt;\n    auto get(const tuple&lt;Types...&gt;& tuple) {\n        if constexpr(N == 0)\n            return tuple.head();\n        else\n            return get&lt;N-1&gt;(tuple.tail());\n    }\n}\nint main(){\n    dev::tuple&lt;int&gt; tup;\n    assert(get&lt;0&gt;(tup) == 0);\n}\nCompiler Explorer\n\n\n\n\n\ntemplate&lt;typename TupleT, typename Func, size_t... Is&gt;\nconstexpr auto transform_impl(TupleT tup, Func func, std::index_sequence&lt;Is...&gt; indexes){\n    return std::make_tuple(func(std::get&lt;Is&gt;(tup))...);\n}\n\n// transform\ntemplate&lt;typename TupleT, typename Fn&gt;\nconstexpr auto transform(Fn func, TupleT tup)\n{\n    constexpr auto index_seq = std::make_index_sequence&lt;std::tuple_size_v&lt;TupleT&gt;&gt;{};\n    return transform_impl(tup, func, index_seq);\n}\n\n\n\n// select_tuple\ntemplate&lt;typename TupleT, size_t... Is&gt;\nconstexpr auto select_tuple(TupleT tuple, std::index_sequence&lt;Is...&gt; idx_sequence)\n{\n    return std::make_tuple((std::get&lt;Is&gt;(tuple))...);\n}\n\n\n\ntemplate&lt;typename TupleT, size_t... Is&gt;\nconstexpr auto reverse_tuple_impl(TupleT tuple, std::index_sequence&lt;Is...&gt; idx_seq){\n    constexpr auto rev_idx_seq = seq_reverse&lt;std::index_sequence&lt;Is...&gt;&gt;::value;\n    return select_tuple(tuple, rev_idx_seq);\n}\n\ntemplate&lt;typename TupleT&gt;\nconstexpr auto reverse_tuple(TupleT tuple){\n    constexpr std::index_sequence idx_sequence = std::make_index_sequence&lt;std::tuple_size_v&lt;TupleT&gt;&gt;{};\n    return reverse_tuple_impl(tuple, idx_sequence);\n}\n\n\n\ntemplate&lt;typename TupleT1, typename TupleT2, size_t... I1s, size_t... I2s&gt;\nconstexpr auto cat_tuple_impl(TupleT1 tuple1, TupleT2 tuple2, std::index_sequence&lt;I1s...&gt; seq1, std::index_sequence&lt;I2s...&gt; seq2){\n    return std::make_tuple(std::get&lt;I1s&gt;(tuple1)...,std::get&lt;I2s&gt;(tuple2)...);\n}\n\ntemplate&lt;typename TupleT1, typename TupleT2&gt;\nconstexpr auto cat_tuple(TupleT1 t1, TupleT2 t2)\n{\n    constexpr std::index_sequence seq1 = std::make_index_sequence&lt;std::tuple_size_v&lt;TupleT1&gt;&gt;{};\n    constexpr std::index_sequence seq2 = std::make_index_sequence&lt;std::tuple_size_v&lt;TupleT2&gt;&gt;{};\n    return cat_tuple_impl(t1, t2, seq1, seq2);\n}\n\n\n\ntemplate&lt;typename TupleT1, typename TupleT2, size_t... I1s, size_t... I2s&gt;\nconstexpr auto zip_tuple_impl(TupleT1 tuple1, TupleT2 tuple2, std::index_sequence&lt;I1s...&gt; seq1, std::index_sequence&lt;I2s...&gt; seq2){\n    return std::make_tuple(std::make_tuple(std::get&lt;I1s&gt;(tuple1), std::get&lt;I2s&gt;(tuple2))...);\n}\n\ntemplate&lt;typename TupleT1, typename TupleT2&gt;\nconstexpr auto zip_tuple(TupleT1 t1, TupleT2 t2){\n    constexpr std::index_sequence seq1 = std::make_index_sequence&lt;std::tuple_size_v&lt;TupleT1&gt;&gt;{};\n    constexpr std::index_sequence seq2 = std::make_index_sequence&lt;std::tuple_size_v&lt;TupleT2&gt;&gt;{};\n    return zip_tuple_impl(t1, t2, seq1, seq2);\n}"
  },
  {
    "objectID": "posts/exercises-in-template-programming/index.html#typelists-and-stdindex_sequence",
    "href": "posts/exercises-in-template-programming/index.html#typelists-and-stdindex_sequence",
    "title": "Challenging exercises in Template Metaprogramming",
    "section": "",
    "text": "For type metaprogramming, the central data structures are the typelist and std::index_sequence. A TypeList is just a static list of types. A std::index_sequence is an integer sequence known at compile-time. TypeLists and std::index_sequences differ from run-time data structures, such as std::list, in that they don’t allow mutation. Adding an element to a TypeList, does not change the original TypeList: rather it creates a new typelist without modifying the original. If you are familar with functional programming languages like Haskell and F#, there’s a lot of parallel between working with typelists in C++ and lists in those languages."
  },
  {
    "objectID": "posts/exercises-in-template-programming/index.html#implementing-a-typelist",
    "href": "posts/exercises-in-template-programming/index.html#implementing-a-typelist",
    "title": "Challenging exercises in Template Metaprogramming",
    "section": "",
    "text": "A TypeList is implemented as a class template. A particular instance of a typelist is a template specialization that encodes the contents of the typelist as template arguments.\ntemplate&lt;typename... Ts&gt;\nstruct TypeList{\n    using type = TypeList&lt;Ts...&gt;;\n    static constexpr auto value = TypeList&lt;Ts...&gt;{};\n};\n\nusing SignedIntegralTypes = TypeList&lt;signed char, short, \n                            int, long, long long&gt;;\nmake_index_sequence metafunction is used to create an integer sequence.\nconstexpr std::index_seq seq = std::make_index_sequence&lt;1,2,3,4,5&gt;{};"
  },
  {
    "objectID": "posts/exercises-in-template-programming/index.html#manipulating-typelist-and-index_sequence",
    "href": "posts/exercises-in-template-programming/index.html#manipulating-typelist-and-index_sequence",
    "title": "Challenging exercises in Template Metaprogramming",
    "section": "",
    "text": "Manipulating the typelist and index_sequence typically requires breaking the typelist into parts, generally by separting the first element in the list (the head) from the remaining elements in the list (the tail).\n// front implementation\ntemplate&lt;typename List&gt;\nstruct front;\n\ntemplate&lt;typename Head, typename... Tail&gt;\nstruct front&lt;TypeList&lt;Head,Tail...&gt;&gt;{\n    using type = Head;\n    static constexpr auto value = Head{};\n};\n\ntemplate&lt;typename List&gt;\nstruct seq_front;\n\ntemplate&lt;size_t First, size_t... Rest&gt;\nstruct seq_front&lt;std::index_sequence&lt;First,Rest...&gt;&gt;{\n    static constexpr size_t value = First;\n};\n\nint main(){\n    static_assert(std::is_same_v&lt;front&lt;TypeList&lt;int,float&gt;&gt;::type, int&gt;);\n    constexpr auto seq_front_result = seq_front&lt;std::index_sequence&lt;1,5,8,12&gt;&gt;::value;\n    std::cout &lt;&lt; std::format(\"\\nseq_front result = {}\", seq_front_result);\n}\nCompiler Explorer\nThe above implementation splits the typelist elements into the head and tail and then forms a new TypeList specialization from the elements in the tail."
  },
  {
    "objectID": "posts/exercises-in-template-programming/index.html#implementing-pop_front",
    "href": "posts/exercises-in-template-programming/index.html#implementing-pop_front",
    "title": "Challenging exercises in Template Metaprogramming",
    "section": "",
    "text": "The pop_front metafunction removes the first element from the typelist. Its implementation splits the typelist elements into the head and tail and then forms a new typelist from the elements in the tail.\ntemplate&lt;typename List&gt;\nstruct pop_front;\n\ntemplate&lt;typename Head, typename... Tail&gt;\nstruct pop_front&lt;TypeList&lt;Head,Tail...&gt;&gt;{\n    using type = TypeList&lt;Tail...&gt;;\n    static constexpr auto value = TypeList&lt;Tail...&gt;{};\n};\n\ntemplate&lt;typename List&gt;\nstruct seq_pop_front;\n\ntemplate&lt;size_t First, size_t... Rest&gt;\nstruct seq_pop_front&lt;std::index_sequence&lt;First,Rest...&gt;&gt;{\n    using type = std::index_sequence&lt;Rest...&gt;;\n    static constexpr auto value = std::index_sequence&lt;Rest...&gt;{};\n};\nCompiler Explorer"
  },
  {
    "objectID": "posts/exercises-in-template-programming/index.html#implementing-push_front",
    "href": "posts/exercises-in-template-programming/index.html#implementing-push_front",
    "title": "Challenging exercises in Template Metaprogramming",
    "section": "",
    "text": "We can also insert elements onto the front of the typelist by capturing all of the existing elements into a template parameter pack, then creating a new TypeList specialization containing all of those elements:\ntemplate&lt;typename Element, typename List&gt;\nstruct push_front;\n\ntemplate&lt;typename T, typename... Ts&gt;\nstruct push_front&lt;T, TypeList&lt;Ts...&gt;&gt;{\n    using type = TypeList&lt;T,Ts...&gt;;\n    static constexpr auto value = TypeList&lt;T,Ts...&gt;{};\n};\n\ntemplate&lt;size_t I, typename IndexSequenceT&gt;\nstruct seq_push_front;\n\ntemplate&lt;size_t I, size_t... Is&gt;\nstruct seq_push_front&lt;I, std::index_sequence&lt;Is...&gt;&gt;{\n    using type = std::index_sequence&lt;I,Is...&gt;;\n    static constexpr auto value = std::index_sequence&lt;I,Is...&gt;{};\n};\n\ntemplate&lt;size_t I, typename IndexSequence&gt;\nusing seq_push_front_t = seq_push_front&lt;I,IndexSequence&gt;::type;"
  },
  {
    "objectID": "posts/exercises-in-template-programming/index.html#implementing-push_back",
    "href": "posts/exercises-in-template-programming/index.html#implementing-push_back",
    "title": "Challenging exercises in Template Metaprogramming",
    "section": "",
    "text": "// push_back implementation\ntemplate&lt;typename Element, typename List&gt;\nstruct push_back;\n\ntemplate&lt;typename Element&gt;\nstruct push_back&lt;Element, TypeList&lt;&gt;&gt;{\n    using type = TypeList&lt;Element&gt;;\n};\n\ntemplate&lt;typename Element, typename... Ts&gt;\nstruct push_back&lt;Element, TypeList&lt;Ts...&gt;&gt;{\n    using type = TypeList&lt;Ts...,Element&gt;;\n};\n\n// push_back implementation for index_sequence\ntemplate&lt;size_t I, typename IndexSequence&gt;\nstruct seq_push_back;\n\ntemplate&lt;size_t I, size_t... Is&gt;\nstruct seq_push_back&lt;I, std::index_sequence&lt;Is...&gt;&gt;{\n    using type = std::index_sequence&lt;Is...,I&gt;;\n    static constexpr auto value = std::index_sequence&lt;Is...,I&gt;{};\n};\n\ntemplate&lt;size_t I, typename IndexSequence&gt;\nusing seq_push_back_t = seq_push_back&lt;I,IndexSequence&gt;::type;"
  },
  {
    "objectID": "posts/exercises-in-template-programming/index.html#typelist-algorithms",
    "href": "posts/exercises-in-template-programming/index.html#typelist-algorithms",
    "title": "Challenging exercises in Template Metaprogramming",
    "section": "",
    "text": "The fundamental typelist operations front, push_front, back and push_back can be composed to create more interesting typelist manipulations. For example, we can replace the first element in a typelist by applying push_front to the result of pop_front.\nGoing further, we can implement algorithms - searches, transformations, reversals as metafunctions operating on typelists.\n\n\nOne of the most fundamental operations on a typelist is to extract a specific element of the list. Let us code up a metafunction to extract the \\(N\\)th element.\ntemplate&lt;size_t I, typename List&gt;\nstruct nth_element;\n\ntemplate&lt;typename First, typename... Rest&gt;\nstruct nth_element&lt;1,TypeList&lt;First, Rest...&gt;&gt;{\n    using type = First;\n};\n\ntemplate&lt;size_t N, typename First, typename... Rest&gt;\nstruct nth_element&lt;N, TypeList&lt;First, Rest...&gt;&gt; : nth_element&lt;N-1, TypeList&lt;Rest...&gt;&gt;{};\n\ntemplate&lt;size_t N, typename List, size_t... Is&gt;\nstruct seq_nth_element;\n\ntemplate&lt;size_t I, size_t... Is&gt;\nstruct seq_nth_element&lt;1,std::index_sequence&lt;I,Is...&gt;&gt;{\n    static constexpr auto value = I;\n};\n\ntemplate&lt;size_t N, size_t I, size_t... Is&gt;\nstruct seq_nth_element&lt;N, std::index_sequence&lt;I,Is...&gt;&gt; : seq_nth_element&lt;N-1,std::index_sequence&lt;Is...&gt;&gt;{};\nCompiler Explorer\n\n\n\nMany typelist algorithms search for data within the typelist. This too can be easily achieved with a recursive template metaprogram.\n#include &lt;utility&gt;\n#include &lt;memory&gt;\n#include &lt;format&gt;\n#include &lt;iostream&gt;\n\ntemplate&lt;typename List, template&lt;size_t I&gt; typename Predicate, size_t... Is&gt;\nstruct seq_find_if;\n\ntemplate&lt;template&lt;size_t &gt; typename Predicate&gt;\nstruct seq_find_if&lt;std::index_sequence&lt;&gt;,Predicate&gt; {\n    using type = std::false_type;\n};\n\ntemplate&lt;size_t First, template&lt;size_t &gt; typename Predicate, size_t... Is&gt;\nstruct seq_find_if&lt;std::index_sequence&lt;First, Is...&gt;,Predicate&gt; {\n    static constexpr bool is_true = Predicate&lt;First&gt;::value;\n    static constexpr bool more_elements_to_check = (sizeof...(Is) &gt; 0);\n    using type = std::conditional&lt;\n        is_true, \n        std::integral_constant&lt;size_t,First&gt;, \n        typename std::conditional&lt;more_elements_to_check, typename seq_find_if&lt;std::index_sequence&lt;Is...&gt;,Predicate&gt;::type, std::false_type&gt;::type\n    &gt;::type;\n};\n\ntemplate&lt;size_t N&gt;\nstruct my_predicate{\n    using type = std::conditional&lt;(N % 2 == 0),std::true_type, std::false_type&gt;::type;\n    static constexpr bool value = (N % 2 == 0);\n};\n\nint main(){\n    static_assert(std::is_same_v&lt;\n        seq_find_if&lt;std::index_sequence&lt;1,2,3,4&gt;,my_predicate&gt;::type,\n        std::integral_constant&lt;size_t,2&gt;\n    &gt;);\n}\nCompiler Explorer\n\n\n\nWhen typelists have some ordering among their elements, it is convenient to be able to reverse the ordering of the elements in the typelist when applying some algorithms. The reverse algorithm implements this metafunction:\ntemplate&lt;typename List&gt;\nstruct reverse;\n\n// basis case\ntemplate&lt;typename Head&gt;\nstruct reverse&lt;TypeList&lt;Head&gt;&gt;{\n    using type = TypeList&lt;Head&gt;;\n};\n\ntemplate&lt;typename... Ts&gt;\nstruct reverse&lt;TypeList&lt;Ts...&gt;&gt;{\n    using front_el = front&lt;TypeList&lt;Ts...&gt;&gt;::type;\n    using tail = pop_front&lt;TypeList&lt;Ts...&gt;&gt;::type;\n    using type = push_back&lt;front_el, typename reverse&lt;tail&gt;::type&gt;::type;\n};\nCompiler Explorer\ntemplate&lt;typename IndexSequence&gt;\nstruct seq_reverse;\n\ntemplate&lt;size_t Head&gt;\nstruct seq_reverse&lt;std::index_sequence&lt;Head&gt;&gt;{\n    using type = std::index_sequence&lt;Head&gt;;\n    static constexpr auto value = std::index_sequence&lt;Head&gt;{};\n};\n\ntemplate&lt;size_t Head, size_t... Tail&gt;\nstruct seq_reverse&lt;std::index_sequence&lt;Head,Tail...&gt;&gt;{\n    using type = seq_push_back&lt;Head,typename seq_reverse&lt;std::index_sequence&lt;Tail...&gt;&gt;::type&gt;::type;\n};\nCompiler Explorer\n\n\n\ntemplate&lt;template &lt;size_t I&gt; typename Func, typename IndexSequence&gt;\nstruct seq_transform;\n\ntemplate&lt;template &lt;size_t I&gt; typename Func, size_t First&gt;\nstruct seq_transform&lt;Func, std::index_sequence&lt;First&gt;&gt;{\n    using type=std::index_sequence&lt;Func&lt;First&gt;::value&gt;;\n};\n\ntemplate&lt;template &lt;size_t I&gt; typename Func, size_t... Is&gt;\nstruct seq_transform&lt;Func, std::index_sequence&lt;Is...&gt;&gt;{\n    static constexpr size_t front_el = seq_front&lt;std::index_sequence&lt;Is...&gt;&gt;::value;\n    using tail = seq_pop_front&lt;std::index_sequence&lt;Is...&gt;&gt;::type;\n    using type = seq_push_front&lt;Func&lt;front_el&gt;::value, typename seq_transform&lt;Func,tail&gt;::type&gt;::type;\n};\nCompiler Explorer\n\n\n\nAssume that we a sorted integer sequence such as \\(1, 2, 2, 2, 4, 4, 5, \\ldots\\). We are interested to write a function seq_uniq that will remove duplicates from the sequence.\ntemplate&lt;typename List&gt;\nstruct seq_uniq;\n\ntemplate&lt;size_t I&gt;\nstruct seq_uniq&lt;std::index_sequence&lt;I&gt;&gt;{\n    using type = std::index_sequence&lt;I&gt;;\n};\n\ntemplate&lt;size_t I1, size_t I2&gt;\nstruct seq_uniq&lt;std::index_sequence&lt;I1, I2&gt;&gt;{\n    using type = std::conditional&lt;\n        (I1 == I2),\n        std::index_sequence&lt;I1&gt;,\n        std::index_sequence&lt;I1, I2&gt;\n    &gt;::type;\n};\n\ntemplate&lt;size_t First, size_t... Rest&gt;\nstruct seq_uniq&lt;std::index_sequence&lt;First,Rest...&gt;&gt;{\n    static constexpr size_t first = First;\n    static constexpr size_t next = seq_front&lt;std::index_sequence&lt;Rest...&gt;&gt;::value;\n    using tail = std::index_sequence&lt;Rest...&gt;;\n    using tail_next = seq_pop_front&lt;std::index_sequence&lt;Rest...&gt;&gt;::type;\n    using type = std::conditional&lt;\n        (first == next),\n        typename seq_uniq&lt;typename seq_push_front&lt;First, tail_next&gt;::type&gt;::type,\n        typename seq_push_front&lt;First, typename seq_uniq&lt;tail&gt;::type&gt;::type\n    &gt;::type;\n};\nCompiler Explorer\n\n\n\nWe can write a cool metafunction to implement merge sort. I’d encourage you to try this as a challenge. Let’s see what you’ve got!\ntemplate&lt;typename V&gt;\nstruct MergeSort{\n    using type = typename MergeVecs&lt;\n        typename MergeSort&lt;typename SplitVec&lt;V&gt;::left&gt;::type,\n        typename MergeSort&lt;typename SplitVec&lt;V&gt;::right&gt;::type\n    &gt;::type;\n};\n\nint main(){\n    static_assert(\n        std::is_same_v&lt;\n            MergeSort&lt;Vec&lt;2, 4, 1, 5, 7, 9, 4, 5&gt;&gt;::type,\n            Vec&lt;1, 2, 4, 4, 5, 5, 7, 9&gt;\n        &gt;\n    );\n}\nHere’s my implementation of merge-sort:\ntemplate&lt;size_t... Is&gt;\nusing Vec = std::index_sequence&lt;Is...&gt;;\n\ntemplate&lt;typename List, typename Indexer&gt;\nstruct SelectVec;\n\ntemplate&lt;size_t... Is, size_t... Js&gt;\nstruct SelectVec&lt;std::index_sequence&lt;Is...&gt;, std::index_sequence&lt;Js...&gt;&gt;{\n    using type = std::index_sequence&lt;seq_nth_element&lt;Is,typename std::index_sequence&lt;Js...&gt;&gt;::value...&gt;;\n};\n\ntemplate&lt;size_t Start,typename List, typename Indexer&gt;\nstruct VecSliceHelper;\n\ntemplate&lt;size_t Start, size_t... Is, size_t... Js&gt;\nstruct VecSliceHelper&lt;Start, std::index_sequence&lt;Is...&gt;, std::index_sequence&lt;Js...&gt;&gt;{\n    using type = std::index_sequence&lt;seq_nth_element&lt;Start + Js,typename std::index_sequence&lt;Is...&gt;&gt;::value...&gt;;\n};\n\ntemplate&lt;size_t Start, size_t End, typename V&gt;\nstruct VecSlice;\n\ntemplate&lt;size_t Start, size_t End, size_t... Is&gt;\nstruct VecSlice&lt;Start, End, Vec&lt;Is...&gt;&gt;{\n    static constexpr size_t num_elements = End - Start + 1;\n    using s = std::make_index_sequence&lt;num_elements&gt;;\n    using type = VecSliceHelper&lt;Start, Vec&lt;Is...&gt;, s&gt;::type;\n};\n\ntemplate&lt;typename V&gt;\nstruct SplitVec;\n\ntemplate&lt;size_t I1, size_t I2&gt;\nstruct SplitVec&lt;Vec&lt;I1, I2&gt;&gt;{\n    using left = Vec&lt;I1&gt;;\n    using right = Vec&lt;I2&gt;;\n};\n\ntemplate&lt;size_t... Is&gt;\nstruct SplitVec&lt;Vec&lt;Is...&gt;&gt;{\n    static constexpr size_t N = sizeof...(Is);\n    static constexpr size_t mid = N / 2;\n    using left = VecSlice&lt;1,mid,Vec&lt;Is...&gt;&gt;::type;\n    using right = VecSlice&lt;mid+1,N,Vec&lt;Is...&gt;&gt;::type;\n};\n\ntemplate&lt;typename Vec1, typename Vec2, typename Result &gt;\nstruct MergeHelper;\n\n// Base cases\ntemplate&lt;size_t... I&gt;\nstruct MergeHelper&lt;Vec&lt;&gt;, Vec&lt;&gt;, Vec&lt;I...&gt;&gt;{\n    using type = Vec&lt;I...&gt;;\n};\n\n// When no elements remain in right subarray\ntemplate&lt;size_t... I1, size_t... I&gt;\nstruct MergeHelper&lt;Vec&lt;I1...&gt;, Vec&lt;&gt;, Vec&lt;I...&gt;&gt;{\n    static constexpr size_t element = seq_front&lt;Vec&lt;I1...&gt;&gt;::value;\n    using tail = seq_pop_front&lt;Vec&lt;I1...&gt;&gt;::type;\n    using result = seq_push_back&lt;element, Vec&lt;I...&gt;&gt;::type;\n    using type = MergeHelper&lt;tail, Vec&lt;&gt;, result&gt;::type;\n};\n\n// When no elements remain in left subarray\ntemplate&lt;size_t... I2, size_t... I&gt;\nstruct MergeHelper&lt;Vec&lt;&gt;, Vec&lt;I2...&gt;, Vec&lt;I...&gt;&gt;{\n    static constexpr size_t element = seq_front&lt;Vec&lt;I2...&gt;&gt;::value;\n    using tail = seq_pop_front&lt;Vec&lt;I2...&gt;&gt;::type;\n    using result = seq_push_back&lt;element, Vec&lt;I...&gt;&gt;::type;\n    using type = MergeHelper&lt;tail, Vec&lt;&gt;, result&gt;::type;\n};\n\n// compare the head elements of both vectors, \n// pop off the smaller of the two and insert it into the results array\ntemplate&lt;size_t... I1, size_t... I2, size_t... I&gt;\nstruct MergeHelper&lt;Vec&lt;I1...&gt;, Vec&lt;I2...&gt;, Vec&lt;I...&gt;&gt;{\n    using left = Vec&lt;I1...&gt;; using right = Vec&lt;I2...&gt;;\n    using left_tail = seq_pop_front&lt;left&gt;::type;\n    using right_tail = seq_pop_front&lt;right&gt;::type;\n    using result = Vec&lt;I...&gt;;\n\n    static constexpr size_t p = seq_front&lt;Vec&lt;I1...&gt;&gt;::value;\n    static constexpr size_t q = seq_front&lt;Vec&lt;I2...&gt;&gt;::value;\n    using type = std::conditional&lt;\n        p &lt; q,\n        typename MergeHelper&lt;left_tail, right, typename seq_push_back&lt;p, result&gt;::type&gt;::type,\n        typename MergeHelper&lt;left, right_tail, typename seq_push_back&lt;q, result&gt;::type&gt;::type\n    &gt;::type;\n};\n\ntemplate&lt;typename Vec1, typename Vec2&gt;\nstruct Merge;\n\ntemplate&lt;size_t... Is, size_t... Js&gt;\nstruct Merge&lt;Vec&lt;Is...&gt;,Vec&lt;Js...&gt;&gt;\n{\n    using type = MergeHelper&lt;Vec&lt;Is...&gt;,Vec&lt;Js...&gt;,Vec&lt;&gt;&gt;::type;\n};\n\ntemplate&lt;typename V&gt;\nstruct MergeSort;\n\ntemplate&lt;&gt;\nstruct MergeSort&lt;Vec&lt;&gt;&gt;{\n    using type = Vec&lt;&gt;;\n};\n\ntemplate&lt;size_t I&gt;\nstruct MergeSort&lt;Vec&lt;I&gt;&gt;{\n    using type = Vec&lt;I&gt;;\n};\n\ntemplate&lt;size_t... Is&gt;\nstruct MergeSort&lt;Vec&lt;Is...&gt;&gt;{\n    using type = Merge&lt;\n        typename MergeSort&lt;typename SplitVec&lt;Vec&lt;Is...&gt;&gt;::left&gt;::type,\n        typename MergeSort&lt;typename SplitVec&lt;Vec&lt;Is...&gt;&gt;::right&gt;::type\n    &gt;::type;\n};\nCompiler Explorer\n\n\n\nLet’s say you have a bunch of compile-time vectors. We’d want to write a metafunction that takes multiple vectors and zips them with *. For example, given the input:\nVector&lt;1,2,3&gt;, Vector&lt;4,5,6&gt;, Vector&lt;7,8,9&gt;\nproduce:\nVector&lt;28,80,162&gt;\nThat is:\nVector&lt;1*4*7, 2*5*8, 3*6*9&gt;\nYou can try writing your implementation using the below as a starting point:\n#include &lt;type_traits&gt;\n#include &lt;iostream&gt;\n#include &lt;utility&gt;\n\n// DEFINITION: Compile-time integer vector defined as: \ntemplate&lt;int... I&gt;\nstruct Vector;\n\n// The code below will assume a 'zip' metafunction is used, but feel free to use a different approach. \n// If you do, please adjust the static assert accordingly. \n\nint main(){\n    static_assert(std::is_same&lt;\n            zip&lt;Vector&lt;1, 2, 3&gt;, Vector&lt;4, 5, 6&gt;, Vector&lt;7, 8, 9&gt;&gt;::type,\n            Vector&lt;1*4*7,2*5*8,3*6*9&gt;&gt;::value, \"\");\n}\nPut on your thinking cap and happy coding! When you’re done with your attempt, you can take a look below at my solution:\n#include &lt;type_traits&gt;\n#include &lt;iostream&gt;\n#include &lt;utility&gt;\n\n// DEFINITION: Compile-time integer vector defined as: \ntemplate&lt;int... I&gt;\nstruct Vector;\n\n// The code below will assume a 'zip' metafunction is used, but feel free to use a different approach. \n// If you do, please adjust the static assert accordingly. \n\n// A getter for the nth-element of the compile-time sequence \n// of integers\ntemplate&lt;size_t N, typename List&gt;\nstruct get;\n\n// Base case\ntemplate&lt;int Head, int... Tail&gt;\nstruct get&lt;0, Vector&lt;Head,Tail...&gt;&gt;{\n    static constexpr auto value = Head;  \n};\n\n// get&lt;N,Vector&lt;I1,I2,...&gt;&gt; inherits from get&lt;N-1,Vector&lt;I2,...&gt;&gt;\ntemplate&lt;size_t N, int Head, int... Tail&gt;\nstruct get&lt;N, Vector&lt;Head,Tail...&gt;&gt; : get&lt;N-1,Vector&lt;Tail...&gt;&gt;{};\n\n\ntemplate&lt;int... I&gt;\nstruct front{\n    static constexpr auto value = get&lt;0, Vector&lt;I...&gt;&gt;::value;\n};\n\ntemplate&lt;typename List&gt;\nstruct pop_front;\n\ntemplate&lt;int I, int... Is&gt;\nstruct pop_front&lt;Vector&lt;I,Is...&gt;&gt;{\n    using type = Vector&lt;Is...&gt;;\n};\n\n// Let's design a metafunction zip that accepts a variadic pack\n// of Vector's.\n// Template declaration\ntemplate&lt;typename... Vectors&gt;\nstruct zip;\n\n// Partial specialization\ntemplate&lt;int... Is&gt;\nstruct zip&lt;Vector&lt;Is...&gt;&gt;{\n    using type = Vector&lt;Is...&gt;;\n};\n\ntemplate&lt;typename Indexes, typename V, typename... List&gt;\nstruct zip_impl;\n\ntemplate&lt;size_t... Is, int... Elements&gt;\nstruct zip_impl&lt;std::index_sequence&lt;Is...&gt;, Vector&lt;Elements...&gt;&gt;{\n    using type = Vector&lt;Elements...&gt;;\n};\n\ntemplate&lt;size_t... Is, int... Elements, typename... Vectors&gt;\nstruct zip_impl&lt;std::index_sequence&lt;Is...&gt;,Vector&lt;Elements...&gt;, Vectors...&gt;{\n    using first = Vector&lt;Elements...&gt;;\n    using rest = typename zip_impl&lt;std::index_sequence&lt;Is...&gt;, Vectors...&gt;::type;\n    using type = Vector&lt;(get&lt;Is, first&gt;::value * get&lt;Is, rest&gt;::value)...&gt;;\n};\n\ntemplate&lt;int... Is, typename... Vectors&gt;\nstruct zip&lt;Vector&lt;Is...&gt;, Vectors...&gt;{\n    static constexpr size_t N = sizeof...(Is);\n    using seq = std::make_index_sequence&lt;N&gt;;\n    using type = zip_impl&lt;seq,Vector&lt;Is...&gt;,Vectors...&gt;::type;\n};\n\n// TEST\nint main() {\n\n    // Test case #1\n    static_assert(get&lt;0,Vector&lt;1,2,3&gt;&gt;::value == 1);\n    static_assert(std::is_same&lt;\n        zip&lt;Vector&lt;1, 2, 3&gt;, Vector&lt;4, 5, 6&gt;, Vector&lt;7, 8, 9&gt;&gt;::type,\n        Vector&lt;1*4*7,2*5*8,3*6*9&gt;&gt;::value, \"\");\n    \n    // TASK: Add more test cases here\n    \n    // TASK: Ensure it compiles before submission\n    return 0;\n}\nCompiler Explorer"
  },
  {
    "objectID": "posts/exercises-in-template-programming/index.html#basic-stdtuple-design",
    "href": "posts/exercises-in-template-programming/index.html#basic-stdtuple-design",
    "title": "Challenging exercises in Template Metaprogramming",
    "section": "",
    "text": "A tuple is an arbitrary collection of heterogenous data. It is a recursive data-structure. A tuple has a static component and a run-time component. The list of types are baked into the tuple definition at compile-time. The actual values/objects held by the tuple can be objects known at run-time.\nWe will design a tuple class template. Implementing your own version tuple type is a good exercise to flex your metaprogramming muscles.\n#include &lt;utility&gt;\n#include &lt;memory&gt;\n#include &lt;format&gt;\n#include &lt;iostream&gt;\n#include &lt;cassert&gt;\n\nnamespace dev \n{\n    // TypeList definition\n    template&lt;typename... Ts&gt;\n    struct TypeList{\n        using type = TypeList&lt;Ts...&gt;;\n        static constexpr auto value = TypeList&lt;Ts...&gt;{};\n    };\n\n    // TypeList Indexing \n    template&lt;size_t I, typename List&gt;\n    struct nth_element;\n\n    template&lt;typename First, typename... Rest&gt;\n    struct nth_element&lt;1,TypeList&lt;First, Rest...&gt;&gt;{\n        using type = First;\n    };\n\n    template&lt;size_t N, typename First, typename... Rest&gt;\n    struct nth_element&lt;N, TypeList&lt;First, Rest...&gt;&gt; : nth_element&lt;N-1, TypeList&lt;Rest...&gt;&gt;{};\n\n    // Implement tuple. This is a forward declaration.\n    template &lt;typename... Types&gt;\n    class tuple;\n\n    // Base case\n    template &lt;&gt;\n    class tuple&lt;&gt; { };\n\n    template&lt;typename Head, typename... Tail&gt;\n    requires std::is_trivially_default_constructible_v&lt;Head&gt;\n    class tuple&lt;Head, Tail...&gt;{\n        using type = TypeList&lt;Head, Tail...&gt;;\n\n        private:\n        Head m_head;\n        tuple&lt;Tail...&gt; m_tail;\n\n        public:\n        tuple()\n        : m_head{}\n        , m_tail{}\n        {}\n\n        tuple(Head head, Tail... tail)\n        : m_head{head}\n        , m_tail{tail...}\n        {}\n\n        Head head() const{\n            return m_head;\n        }\n\n        tuple&lt;Tail...&gt; tail() const{\n            return m_tail;\n        }\n\n        constexpr auto empty(){\n            return std::tuple&lt;&gt;();\n        }\n\n        constexpr auto initialize(Head head, Tail... tail){\n            m_head = head;\n            if constexpr(sizeof...(Tail))\n                m_tail.initialize(tail...);\n        }\n    };\n\n    // Implement get\n    template &lt;unsigned N, typename... Types&gt;\n    auto get(const tuple&lt;Types...&gt;& tuple) {\n        if constexpr(N == 0)\n            return tuple.head();\n        else\n            return get&lt;N-1&gt;(tuple.tail());\n    }\n}\nint main(){\n    dev::tuple&lt;int&gt; tup;\n    assert(get&lt;0&gt;(tup) == 0);\n}\nCompiler Explorer"
  },
  {
    "objectID": "posts/exercises-in-template-programming/index.html#tuple-algorithms",
    "href": "posts/exercises-in-template-programming/index.html#tuple-algorithms",
    "title": "Challenging exercises in Template Metaprogramming",
    "section": "",
    "text": "template&lt;typename TupleT, typename Func, size_t... Is&gt;\nconstexpr auto transform_impl(TupleT tup, Func func, std::index_sequence&lt;Is...&gt; indexes){\n    return std::make_tuple(func(std::get&lt;Is&gt;(tup))...);\n}\n\n// transform\ntemplate&lt;typename TupleT, typename Fn&gt;\nconstexpr auto transform(Fn func, TupleT tup)\n{\n    constexpr auto index_seq = std::make_index_sequence&lt;std::tuple_size_v&lt;TupleT&gt;&gt;{};\n    return transform_impl(tup, func, index_seq);\n}\n\n\n\n// select_tuple\ntemplate&lt;typename TupleT, size_t... Is&gt;\nconstexpr auto select_tuple(TupleT tuple, std::index_sequence&lt;Is...&gt; idx_sequence)\n{\n    return std::make_tuple((std::get&lt;Is&gt;(tuple))...);\n}\n\n\n\ntemplate&lt;typename TupleT, size_t... Is&gt;\nconstexpr auto reverse_tuple_impl(TupleT tuple, std::index_sequence&lt;Is...&gt; idx_seq){\n    constexpr auto rev_idx_seq = seq_reverse&lt;std::index_sequence&lt;Is...&gt;&gt;::value;\n    return select_tuple(tuple, rev_idx_seq);\n}\n\ntemplate&lt;typename TupleT&gt;\nconstexpr auto reverse_tuple(TupleT tuple){\n    constexpr std::index_sequence idx_sequence = std::make_index_sequence&lt;std::tuple_size_v&lt;TupleT&gt;&gt;{};\n    return reverse_tuple_impl(tuple, idx_sequence);\n}\n\n\n\ntemplate&lt;typename TupleT1, typename TupleT2, size_t... I1s, size_t... I2s&gt;\nconstexpr auto cat_tuple_impl(TupleT1 tuple1, TupleT2 tuple2, std::index_sequence&lt;I1s...&gt; seq1, std::index_sequence&lt;I2s...&gt; seq2){\n    return std::make_tuple(std::get&lt;I1s&gt;(tuple1)...,std::get&lt;I2s&gt;(tuple2)...);\n}\n\ntemplate&lt;typename TupleT1, typename TupleT2&gt;\nconstexpr auto cat_tuple(TupleT1 t1, TupleT2 t2)\n{\n    constexpr std::index_sequence seq1 = std::make_index_sequence&lt;std::tuple_size_v&lt;TupleT1&gt;&gt;{};\n    constexpr std::index_sequence seq2 = std::make_index_sequence&lt;std::tuple_size_v&lt;TupleT2&gt;&gt;{};\n    return cat_tuple_impl(t1, t2, seq1, seq2);\n}\n\n\n\ntemplate&lt;typename TupleT1, typename TupleT2, size_t... I1s, size_t... I2s&gt;\nconstexpr auto zip_tuple_impl(TupleT1 tuple1, TupleT2 tuple2, std::index_sequence&lt;I1s...&gt; seq1, std::index_sequence&lt;I2s...&gt; seq2){\n    return std::make_tuple(std::make_tuple(std::get&lt;I1s&gt;(tuple1), std::get&lt;I2s&gt;(tuple2))...);\n}\n\ntemplate&lt;typename TupleT1, typename TupleT2&gt;\nconstexpr auto zip_tuple(TupleT1 t1, TupleT2 t2){\n    constexpr std::index_sequence seq1 = std::make_index_sequence&lt;std::tuple_size_v&lt;TupleT1&gt;&gt;{};\n    constexpr std::index_sequence seq2 = std::make_index_sequence&lt;std::tuple_size_v&lt;TupleT2&gt;&gt;{};\n    return zip_tuple_impl(t1, t2, seq1, seq2);\n}"
  },
  {
    "objectID": "posts/deducing-this/index.html",
    "href": "posts/deducing-this/index.html",
    "title": "deducing this",
    "section": "",
    "text": "Introduction\nMember functions can be overloaded by cv-qualifiers and reference qualifiers & (ref) and && (ref-ref).\n/* \nMember functions can be overloaded by cv-qualifiers and \nreference qualifiers.\n*/\n#include &lt;iostream&gt;\n// Implicit\nstruct X{\n    void f() &{ std::cout &lt;&lt; \"\\n\" &lt;&lt; \"X::f() &\"; }\n    void f() const&{ std::cout &lt;&lt; \"\\n\" &lt;&lt; \"X::f() const&\"; }\n    void f() && { std::cout &lt;&lt; \"\\n\" &lt;&lt; \"X::f() &&\"; }\n    void f() const&& { std::cout &lt;&lt; \"\\n\" &lt;&lt; \"X::f() const&&\"; }\n};\n\n//Explicit\nstruct Y{\n    void f(this Y&){ std::cout &lt;&lt; \"\\n\" &lt;&lt; \"Y::f() &\"; }\n    void f(this const Y&){ std::cout &lt;&lt; \"\\n\" &lt;&lt; \"Y::f() const&\"; }\n    void f(this Y&&){ std::cout &lt;&lt; \"\\n\" &lt;&lt; \"Y::f() &&\"; }\n    void f(this const Y&&){ std::cout &lt;&lt; \"\\n\" &lt;&lt; \"Y::f() const &&\"; }\n};\n\nint main(){\n    X x; Y y;\n    const X c_x; const Y c_y;\n\n    x.f();\n    c_x.f();\n    X().f();\n    const_cast&lt;const X&&&gt;(X()).f();\n\n    y.f();\n    c_y.f();\n    Y().f();\n    const_cast&lt;const Y&&&gt;(Y()).f();\n    return 0;\n}\nCompiler Explorer\n\n\ndeducing this feature\nIf const and non-const overloads of a method and (ref)& and (ref-ref)&& overloads share the same implementation, then we can de-duplicate these overloads and allow the compiler to automatically deduce the object type, on which the member function was invoked using this feature.\nThe real value of deducing this comes from using the type Self in some way in the body e.g. using std::forward_like&lt;T,U&gt; to propagate an owning-object’s value category to its member data.\nConsider the following example. We are writing a homegrown version of vector&lt;T&gt; container and want to implement the begin() method.\n#include &lt;iostream&gt;\n#include &lt;memory&gt;\n#include &lt;type_traits&gt;\n#include &lt;concepts&gt;\n\ntemplate&lt;typename T&gt;\nstruct vector{\n    T* m_data;\n    std::size_t m_size;\n    std::size_t m_capacity;\n\n    vector()\n    : m_data{new T[8]}\n    , m_size{0}\n    , m_capacity{8}\n    {}\n\n    template&lt;typename U&gt;\n    struct Iterator{\n        using difference_type = std::ptrdiff_t;\n        using value_type = U;\n\n        Iterator() = default;\n\n        explicit Iterator(U* ptr)\n        : m_ptr{ptr}\n        {}\n\n        U* m_ptr;\n    };\n\n    using iterator = Iterator&lt;T&gt;;\n    using const_iterator = Iterator&lt;const T&gt;;\n\n    auto begin(this auto&& self){\n        return Iterator(self.m_data);\n        //              ^----------\n        //               T* const, if self is const\n        //               T*, otherwise\n    }\n\n    auto end(this auto&& self){\n        return Iterator(self.m_data + self.m_size);\n    }\n\n    ~vector(){\n        delete[] m_data;\n    }\n\n};\n\nint main(){\n\n    vector&lt;double&gt; v;\n    const vector&lt;double&gt; cv;\n\n    static_assert(\n        std::is_same_v&lt;\n            decltype(v.begin()),\n            vector&lt;double&gt;::Iterator&lt;double&gt;\n        &gt;\n    );\n\n    static_assert(\n        std::is_same_v&lt;\n            decltype(cv.begin()),\n            vector&lt;double&gt;::Iterator&lt;double&gt;\n        &gt;\n    );\n    return 0;\n}\nCompiler Explorer\nInstead of writing traditional const and non-const variants of begin(), we are using the deducing this feature to de-duplicate overloads.\nWhile at the outset, this code might look fine, be warned that std::is_same_v&lt;decltype(cv.begin()),vector&lt;double&gt;::Iterator&lt;const double&gt;&gt; returns false_type. T* m_data of a const object becomes T* const m_data, that is const ends up on the top-level of that type. const qualifiers on the top-level Iterator class are then discarded when template argument deduction is performed on the implicit function-template powering the constructor call Iterator(self.m_data). The client may write hostile code and modify the contents of the const vector through the iterator object. What we want is a pointer-to-const T instead of a const-pointer-to-T.\nWe can branch on the const-ness of self and return the correct iterator type.\n#include &lt;iostream&gt;\n#include &lt;memory&gt;\n#include &lt;type_traits&gt;\n#include &lt;concepts&gt;\n\ntemplate&lt;typename T&gt;\nstruct vector{\n    T* m_data;\n    std::size_t m_size;\n    std::size_t m_capacity;\n\n    template&lt;typename U&gt;\n    struct Iterator{\n        using difference_type = std::ptrdiff_t;\n        using value_type = U;\n        using reference = U&;\n        using const_reference = const U&;\n        using pointer = U*;\n\n        U* m_ptr;\n\n        Iterator() = default;\n\n        explicit Iterator(U* ptr)\n        : m_ptr{ptr}\n        {}\n        \n        Iterator& operator++(){\n            ++m_ptr;\n            return *this;\n        }\n\n        Iterator operator++(int){\n            auto temp {*this};\n            ++m_ptr;\n            return temp;\n        }\n\n        Iterator operator+(int n){\n            return Iterator(m_ptr + n);\n        }\n\n        U& operator*(){\n            return *m_ptr;\n        }\n\n        auto operator&lt;=&gt;(const Iterator& other) const{\n            return m_ptr&lt;=&gt;other.m_ptr;\n        }\n\n        bool operator==(const Iterator& other) const{\n            return m_ptr==other.m_ptr;\n        }\n    };\n\n    using iterator = Iterator&lt;T&gt;;\n    using const_iterator = Iterator&lt;const T&gt;;\n\n    auto begin(this auto&& self){\n        if constexpr(std::is_const_v&lt;std::remove_reference_t&lt;decltype(self)&gt;&gt;)\n            return const_iterator(self.m_data);\n        else\n            return iterator(self.m_data);\n            \n    }\n\n    auto end(this auto&& self){\n        if constexpr(std::is_const_v&lt;std::remove_reference_t&lt;decltype(self)&gt;&gt;)\n            return const_iterator(self.m_data + self.m_size);\n        else\n            return iterator(self.m_data);\n    }\n\n    vector(std::size_t n, const T& x)\n    : m_data{ static_cast&lt;T*&gt;(::operator new(sizeof(T) * n)) }\n    , m_size{0}\n    , m_capacity{n}\n    {\n        auto p{begin()};\n        try{\n            for(;p != (begin()+n);++p)\n                new(static_cast&lt;void*&gt;(p.m_ptr)) T(x);\n        }\n        catch(...){\n            for(auto q{begin()}; q!=p; ++q)\n                q.m_ptr-&gt;~T();\n            ::operator delete (m_data);\n            throw;\n        }\n\n        m_size = n;\n    }\n\n    ~vector(){\n        std::destroy(begin(), end());\n        ::operator delete (m_data);\n    }\n};\n\ntemplate&lt;typename IterType&gt;\nvoid foo(IterType iter){\n    std::cout &lt;&lt; \"\\n\" &lt;&lt; \"foo(IterType iter)\" &lt;&lt; \", *iter = \" &lt;&lt; *iter;\n}\n\nint main(){\n    vector v(5,2.0);\n    const vector cv(5,2.0);\n    static_assert(\n        std::is_same_v&lt;\n            decltype(v.begin()),\n            vector&lt;double&gt;::Iterator&lt;double&gt;\n        &gt;\n    );\n\n    static_assert(\n        std::is_same_v&lt;\n            decltype(cv.begin()),\n            vector&lt;double&gt;::Iterator&lt;const double&gt;\n        &gt;\n    );\n\n    foo(vector(10,2.0).begin());\n    return 0;\n}\nCompiler Explorer\n\n\nA small digression - auto deduction rules\nIn the below code snippet, can you tell why the static assertion passes?\n#include &lt;iostream&gt;\n#include &lt;concepts&gt;\n#include &lt;type_traits&gt;\n\ntemplate&lt;typename T&gt;\nstruct Wrapper{\n    T* m_data;\n\n    Wrapper(const T& val)\n    : m_data{new T(val)}\n    {}\n\n    auto get(this Wrapper& self){\n        return self.m_data;\n    }\n\n    auto get(this Wrapper const& self){\n        return self.m_data;\n    }\n\n    auto get(this Wrapper&& self){\n        return self.m_data;\n    }\n\n    auto get(this Wrapper const&& self){\n        return self.m_data;\n    }\n};\n\nint main(){\n    Wrapper&lt;int&gt; wrapper{5};\n    const Wrapper&lt;int&gt; const_wrapper{42};\n\n    static_assert(std::is_same_v&lt;\n        decltype(const_wrapper.get()),\n        int*\n    &gt;);\n\n    // const_wrapper.m_data = new int(10);  m_data is immutable\n    *const_wrapper.m_data = 10;\n    return 0;\n}\nCompiler Explorer\nThe static assertion passes, because get() returns auto. It is, as if, we are returning by value. auto always deduces a non-const, non-reference object.\n\n\nPropagating the value category of the owning object\nConsider a highly simplified version of optional&lt;T&gt; which is a wrapper type for representing nullable T objects which may/may not contain a value.\ntemplate&lt;typename T&gt;\nstruct optional{\n    T m_storage;\n    bool m_is_initialized;\n\n    optional(T const& v)\n    : m_storage{}\n    , m_is_initialized(true)\n    {\n        ::operator new (static_cast&lt;void*&gt;&m_storage) T(v));\n    }\n\n    optional()\n    : m_storage{}\n    , m_is_initialized{false}\n    {}\n\n    /* ... */\n};\nFrom a design perspective, we would like that getters such as optional&lt;T&gt;::get() should propagate the value-category of the owning object to it’s member data.\n#include &lt;utility&gt;\n#include &lt;iostream&gt;\n#include &lt;type_traits&gt;\n\ntemplate&lt;typename T&gt;\nstruct optional{\n    T m_storage;\n    bool m_is_initialized;\n\n    optional(T const& v)\n    : m_storage{}\n    , m_is_initialized(true)\n    {\n        ::new (static_cast&lt;void*&gt;(&m_storage)) T(v); // placement new\n    }\n    \n    optional()\n    : m_storage{}\n    , m_is_initialized{false}\n    {}\n\n    template&lt;typename Self&gt;\n    decltype(auto) value(this Self&& self){\n        return std::forward&lt;decltype(self)&gt;(self).m_storage;\n    }\n};\n\nint main(){\n    optional&lt;double&gt; opt_d(42.0);\n    opt_d.value();\n\n    const optional&lt;double&gt; copt_d(5.0);\n    copt_d.value();\n\n    optional&lt;double&gt;(17.0).value();\n    static_cast&lt;optional&lt;double&gt;&&&gt;(optional&lt;double&gt;(28.0)).value();\n    return 0;\n}\nCompiler Explorer\nOne function template does it. This is equivalent to writing:\n#include &lt;utility&gt;\n#include &lt;iostream&gt;\ntemplate&lt;typename T&gt;\nstruct optional{\n    T m_storage;\n    bool m_is_initialized;\n\n    optional(T const& v)\n    : m_storage(v)\n    , m_is_initialized(true)\n    {}\n\n    optional()\n    : m_storage{}\n    , m_is_initialized{false}\n    {}\n\n    /*\n    template&lt;typename Self&gt;\n    decltype(auto) value(this Self&& self){\n        return std::forward&lt;decltype(self)&gt;(self).m_storage;\n    }\n    */\n    decltype(auto) value(this optional& self){\n        std::cout &lt;&lt; \"\\n\" &lt;&lt; \"value(this optional&)\";\n        return self.m_storage;\n    }\n\n    decltype(auto) value(this optional const& self){\n        std::cout &lt;&lt; \"\\n\" &lt;&lt; \"value(this optional const&)\";\n        return (self.m_storage);\n    }\n\n    decltype(auto) value(this optional&& self){\n        std::cout &lt;&lt; \"\\n\" &lt;&lt; \"value(this optional &&)\";\n        return (std::move(self).m_storage);\n    }\n\n    decltype(auto) value(this optional const&& self){\n        std::cout &lt;&lt; \"\\n\" &lt;&lt; \"value(this optional const &&)\";\n        return (std::move(self).m_storage);\n    }\n};\n\nint main(){\n    optional&lt;double&gt; opt_d(42.0);\n    opt_d.value();\n\n    const optional&lt;double&gt; copt_d(5.0);\n    copt_d.value();\n\n    optional&lt;double&gt;(17.0).value();\n    static_cast&lt;optional&lt;double&gt; const&&&gt;(optional&lt;double&gt;(28.0)).value();\n    return 0;\n}\nCompiler Explorer\n\n\nGetter return types\nIf we need to propagate both const-ness and the value category of the owning object o to its T m_data data-member, we could use std::forward_like&lt;T,U&gt; defined in the &lt;utility&gt; header."
  },
  {
    "objectID": "posts/virtualization/index.html",
    "href": "posts/virtualization/index.html",
    "title": "The virtual keyword",
    "section": "",
    "text": "The virtual keyword specifies that a non-static member function is virtual and supports dynamic dispatch. It may only appear in the initial declaration of a non-static member function (i.e., when it is declared in the class definition).\n#include &lt;iostream&gt;\n\nclass Base\n{\n    public:\n    void foo(){\n        std::cout &lt;&lt; \"\\n\" &lt;&lt; \"Base::foo()\";\n    }\n};\n\nclass Derived : public Base{\n    public:\n    void foo(){\n        std::cout &lt;&lt; \"\\n\" &lt;&lt; \"Derived::foo()\";\n    }\n};\n\nint main(){\n    Base base_obj;\n    Derived derived_obj;\n    Base* base_ptr{nullptr};\n\n    base_ptr = &base_obj;\n    base_ptr-&gt;foo();\n\n    base_ptr = &derived_obj;\n    base_ptr-&gt;foo();\n    return 0;\n}\nRun at Compiler Explorer\nOutput:\nBase::foo()\nBase::foo()\nThe version of foo invoked is determined at compile time, based on the pointer type.\nIf we declare the foo() as a virtual method, then the version of foo() invoked is resolved dynamically on-the-fly depending on the type of object being pointed to (pointee).\n#include &lt;iostream&gt;\n\nclass Base\n{\n    public:\n    virtual void foo(){\n        std::cout &lt;&lt; \"\\n\" &lt;&lt; \"Base::foo()\";\n    }\n};\n\nclass Derived : public Base{\n    public:\n    void foo() override{    //override is optional\n        std::cout &lt;&lt; \"\\n\" &lt;&lt; \"Derived::foo()\";\n    }\n};\n\nint main(){\n    Base b;\n    Derived d;\n    \n    // Virtual function call through reference\n    Base& br = b;   // the type of br is Base&\n    Base& dr = d;   // the type of dr is Base&\n    br.foo();       // Calls Base::foo()\n    dr.foo();       // Calls Derived::foo()\n\n    // Virtual function call through pointers\n    Base* bp = &b;  // type of bp is Base*\n    Base* dp = &d;  // type of dp is Base* as well\n    bp-&gt;foo();      // Calls Base::foo()\n    dp-&gt;foo();      // Calls Derived::foo()\n\n    // Non-virtual function calls\n    br.Base::foo();\n    dr.Base::foo();\n    return 0;\n}\nRun at Compiler Explorer\nOutput:\nBase::foo()\nDerived::foo()\nBase::foo()\nDerived::foo()\nBase::foo()\nBase::foo()\nA derived class virtual function is considered an override if and only if it has the same\n\nname\nparameter type list (but not the return type)\ncv-qualifiers\nref-qualifiers\n\n#include &lt;iostream&gt;\n\nclass Base\n{\n    public:\n    virtual void vf(){\n        std::cout &lt;&lt; \"\\n\" &lt;&lt; \"Base::vf()\";\n    }\n};\n\nclass Derived : public Base{\n    public:\n    void vf() const{\n        std::cout &lt;&lt; \"\\n\" &lt;&lt; \"Derived::vf() const\";\n    }\n};\n\nint main(){\n    Base b;\n    Derived d;\n    const Derived const_d;\n\n    Base* bp{nullptr};\n\n    bp = &b;\n    bp-&gt;vf();\n\n    bp = &d;\n    bp-&gt;vf();\n    d.vf();\n    return 0;\n}\nOutput:\nBase::vf()\nBase::vf()\nDerived::vf() const\nIn the above code snippet, the compiler does not treat void Derived::vf() const as an override for the base class virtual member function void Base::vf().\n\n\nA member function defined as virtual in the base class will be virtual in all child classes.\n#include&lt;iostream&gt;\nstruct A{\n    virtual void vf(){\n        std::cout &lt;&lt; \"\\n\" &lt;&lt; \"A::vf()\";\n    }\n\n    void g(){\n        std::cout &lt;&lt; \"\\n\" &lt;&lt; \"A::g()\";\n    }\n};\n \nstruct B : A{\n    void vf() override{\n        std::cout &lt;&lt; \"\\n\" &lt;&lt; \"B::vf()\";\n    }\n\n    void g(){\n        std::cout &lt;&lt; \"\\n\" &lt;&lt; \"B::g()\";\n    }\n};\n\nstruct C : B{\n    void vf() override{\n        std::cout &lt;&lt; \"\\n\" &lt;&lt; \"C::vf()\";\n    }\n\n    void g(){\n        std::cout &lt;&lt; \"\\n\" &lt;&lt; \"C::g()\";\n    }\n};\n\nstruct D : C{\n    void g(){\n        std::cout &lt;&lt; \"\\n\" &lt;&lt; \"D::g()\";\n    }\n};\n\nint main()\n{\n    A a; B b; C c; D d;\n    A* a_as_aptr = &a;\n    A* b_as_aptr = &b;\n    A* c_as_aptr = &c;\n    A* d_as_aptr = &d;\n\n    a_as_aptr-&gt;vf();\n    b_as_aptr-&gt;vf();\n    c_as_aptr-&gt;vf();\n    d_as_aptr-&gt;vf();\n\n    a_as_aptr-&gt;g();\n    b_as_aptr-&gt;g();\n    c_as_aptr-&gt;g();\n    d_as_aptr-&gt;g();\n}\nRun at Compiler Explorer\nOutput:\nA::vf()\nB::vf()\nC::vf()\nC::vf()\nA::g()\nA::g()\nA::g()\nA::g()\nBecause vf() is a virtual function, the dynamic type (type of the pointee object) is used at run-time to resolve calls to b_as_aptr-&gt;vf() or c_as_aptr-&gt;vf(). With non-virtual functions such as g(), the compiler uses the static type to determine what function to call, and it can do so at compile-time.\n\n\n\nEvery time you define a method in the derived class that override virtual member function in the base class, as a good practice, tag it override. This way, you show that your intention for the derived class is to override the behavior of vf in the base class.\n#include&lt;iostream&gt;\nstruct Base{\n    virtual void vf(){\n        std::cout &lt;&lt; \"\\n\" &lt;&lt; \"void Base::vf()\";\n    }\n};\n\nstruct Derived : public Base{\n    void vf() override{\n        std::cout &lt;&lt; \"\\n\" &lt;&lt; \"void Derived::vf()\";\n    }\n};\nIf a function is declared with specifier override but does not override a base class virtual member function, the program is ill-formed and will not compile.\n#include&lt;iostream&gt;\nstruct Base{\n    virtual void vf(){\n        std::cout &lt;&lt; \"\\n\" &lt;&lt; \"void Base::vf()\";\n    }\n};\n\nstruct Derived : public Base{\n    void vf(long) override{\n        std::cout &lt;&lt; \"\\n\" &lt;&lt; \"void Derived::vf()\";\n    }\n};\nRun at Compiler Explorer\nBase::vf() does not need to be accessible or visible to be overriden. Base::vf() can be declared as private, or Base can be inherited using private inheritance.\n#include&lt;iostream&gt;\nclass B\n{\n    virtual void do_f(){ // private member\n        std::cout &lt;&lt; \"\\n\" &lt;&lt; \"B::do_f()\";\n    }\n    public:\n    void f() { do_f(); } // public interface\n};\n \nclass D : public B\n{\n    void do_f() override{ // overrides B::do_f\n        std::cout &lt;&lt; \"\\n\" &lt;&lt; \"D::do_f()\";\n    }\n};\n \nint main()\n{\n    D d;\n    B* bp = &d;\n    bp-&gt;f(); // internally calls D::do_f();\n}\nRun at Compiler Explorer\n\n\n\nWe can also designate a function as final. Any attempt to override a function that has been defined as final will be flagged as an error:\nstruct A{ virtual void foo(){} };\nstruct B : public A\n{ \n    void foo() final {}  \n};\nstruct C : B\n    // void foo() {} // error: B declared foo as final\n}\n\n\n\nLike any other function, a virtual function can have default arguments. If a call uses a default argument, the value that is used is the one defined by the static type through which the function is called. Default arguments for virtual functions are substituted at the compile time.\nThat is, when a call is made through a reference or pointer-to-base, the default argument(s) will be those defined in the base class. The base-class arguments will be used even when the derived version of the function is run.\n#include &lt;iostream&gt;\n\nclass Base {\npublic:\n    virtual void foo(int x = 10) {\n        std::cout &lt;&lt; \"Base::foo(\" &lt;&lt; x &lt;&lt; \")\\n\";\n    }\n    \n    virtual void bar(int x = 20) {\n        std::cout &lt;&lt; \"Base::bar(\" &lt;&lt; x &lt;&lt; \")\\n\";\n    }\n};\n\nclass Derived : public Base {\npublic:\n    void foo(int x = 30) override {\n        std::cout &lt;&lt; \"Derived::foo(\" &lt;&lt; x &lt;&lt; \")\\n\";\n    }\n    \n    void bar(int x) override {\n        std::cout &lt;&lt; \"Derived::bar(\" &lt;&lt; x &lt;&lt; \")\\n\";\n    }\n};\n\nint main() {\n    Derived d;\n    Base* b = &d;\n    \n    d.foo();        // Line 1\n    b-&gt;foo();       // Line 2\n    b-&gt;bar();       // Line 3\n    \n    return 0;\n}\nOutput:\nDerived::foo(30)\nDerived::foo(10)\nDerived::bar(20)"
  },
  {
    "objectID": "posts/virtualization/index.html#dynamic-dispatch",
    "href": "posts/virtualization/index.html#dynamic-dispatch",
    "title": "The virtual keyword",
    "section": "",
    "text": "A member function defined as virtual in the base class will be virtual in all child classes.\n#include&lt;iostream&gt;\nstruct A{\n    virtual void vf(){\n        std::cout &lt;&lt; \"\\n\" &lt;&lt; \"A::vf()\";\n    }\n\n    void g(){\n        std::cout &lt;&lt; \"\\n\" &lt;&lt; \"A::g()\";\n    }\n};\n \nstruct B : A{\n    void vf() override{\n        std::cout &lt;&lt; \"\\n\" &lt;&lt; \"B::vf()\";\n    }\n\n    void g(){\n        std::cout &lt;&lt; \"\\n\" &lt;&lt; \"B::g()\";\n    }\n};\n\nstruct C : B{\n    void vf() override{\n        std::cout &lt;&lt; \"\\n\" &lt;&lt; \"C::vf()\";\n    }\n\n    void g(){\n        std::cout &lt;&lt; \"\\n\" &lt;&lt; \"C::g()\";\n    }\n};\n\nstruct D : C{\n    void g(){\n        std::cout &lt;&lt; \"\\n\" &lt;&lt; \"D::g()\";\n    }\n};\n\nint main()\n{\n    A a; B b; C c; D d;\n    A* a_as_aptr = &a;\n    A* b_as_aptr = &b;\n    A* c_as_aptr = &c;\n    A* d_as_aptr = &d;\n\n    a_as_aptr-&gt;vf();\n    b_as_aptr-&gt;vf();\n    c_as_aptr-&gt;vf();\n    d_as_aptr-&gt;vf();\n\n    a_as_aptr-&gt;g();\n    b_as_aptr-&gt;g();\n    c_as_aptr-&gt;g();\n    d_as_aptr-&gt;g();\n}\nRun at Compiler Explorer\nOutput:\nA::vf()\nB::vf()\nC::vf()\nC::vf()\nA::g()\nA::g()\nA::g()\nA::g()\nBecause vf() is a virtual function, the dynamic type (type of the pointee object) is used at run-time to resolve calls to b_as_aptr-&gt;vf() or c_as_aptr-&gt;vf(). With non-virtual functions such as g(), the compiler uses the static type to determine what function to call, and it can do so at compile-time."
  },
  {
    "objectID": "posts/virtualization/index.html#override-a-useful-feature-to-prevent-bugs",
    "href": "posts/virtualization/index.html#override-a-useful-feature-to-prevent-bugs",
    "title": "The virtual keyword",
    "section": "",
    "text": "Every time you define a method in the derived class that override virtual member function in the base class, as a good practice, tag it override. This way, you show that your intention for the derived class is to override the behavior of vf in the base class.\n#include&lt;iostream&gt;\nstruct Base{\n    virtual void vf(){\n        std::cout &lt;&lt; \"\\n\" &lt;&lt; \"void Base::vf()\";\n    }\n};\n\nstruct Derived : public Base{\n    void vf() override{\n        std::cout &lt;&lt; \"\\n\" &lt;&lt; \"void Derived::vf()\";\n    }\n};\nIf a function is declared with specifier override but does not override a base class virtual member function, the program is ill-formed and will not compile.\n#include&lt;iostream&gt;\nstruct Base{\n    virtual void vf(){\n        std::cout &lt;&lt; \"\\n\" &lt;&lt; \"void Base::vf()\";\n    }\n};\n\nstruct Derived : public Base{\n    void vf(long) override{\n        std::cout &lt;&lt; \"\\n\" &lt;&lt; \"void Derived::vf()\";\n    }\n};\nRun at Compiler Explorer\nBase::vf() does not need to be accessible or visible to be overriden. Base::vf() can be declared as private, or Base can be inherited using private inheritance.\n#include&lt;iostream&gt;\nclass B\n{\n    virtual void do_f(){ // private member\n        std::cout &lt;&lt; \"\\n\" &lt;&lt; \"B::do_f()\";\n    }\n    public:\n    void f() { do_f(); } // public interface\n};\n \nclass D : public B\n{\n    void do_f() override{ // overrides B::do_f\n        std::cout &lt;&lt; \"\\n\" &lt;&lt; \"D::do_f()\";\n    }\n};\n \nint main()\n{\n    D d;\n    B* bp = &d;\n    bp-&gt;f(); // internally calls D::do_f();\n}\nRun at Compiler Explorer"
  },
  {
    "objectID": "posts/virtualization/index.html#the-final-specifier",
    "href": "posts/virtualization/index.html#the-final-specifier",
    "title": "The virtual keyword",
    "section": "",
    "text": "We can also designate a function as final. Any attempt to override a function that has been defined as final will be flagged as an error:\nstruct A{ virtual void foo(){} };\nstruct B : public A\n{ \n    void foo() final {}  \n};\nstruct C : B\n    // void foo() {} // error: B declared foo as final\n}"
  },
  {
    "objectID": "posts/virtualization/index.html#virtual-functions-and-default-arguments",
    "href": "posts/virtualization/index.html#virtual-functions-and-default-arguments",
    "title": "The virtual keyword",
    "section": "",
    "text": "Like any other function, a virtual function can have default arguments. If a call uses a default argument, the value that is used is the one defined by the static type through which the function is called. Default arguments for virtual functions are substituted at the compile time.\nThat is, when a call is made through a reference or pointer-to-base, the default argument(s) will be those defined in the base class. The base-class arguments will be used even when the derived version of the function is run.\n#include &lt;iostream&gt;\n\nclass Base {\npublic:\n    virtual void foo(int x = 10) {\n        std::cout &lt;&lt; \"Base::foo(\" &lt;&lt; x &lt;&lt; \")\\n\";\n    }\n    \n    virtual void bar(int x = 20) {\n        std::cout &lt;&lt; \"Base::bar(\" &lt;&lt; x &lt;&lt; \")\\n\";\n    }\n};\n\nclass Derived : public Base {\npublic:\n    void foo(int x = 30) override {\n        std::cout &lt;&lt; \"Derived::foo(\" &lt;&lt; x &lt;&lt; \")\\n\";\n    }\n    \n    void bar(int x) override {\n        std::cout &lt;&lt; \"Derived::bar(\" &lt;&lt; x &lt;&lt; \")\\n\";\n    }\n};\n\nint main() {\n    Derived d;\n    Base* b = &d;\n    \n    d.foo();        // Line 1\n    b-&gt;foo();       // Line 2\n    b-&gt;bar();       // Line 3\n    \n    return 0;\n}\nOutput:\nDerived::foo(30)\nDerived::foo(10)\nDerived::bar(20)"
  },
  {
    "objectID": "posts/virtualization/index.html#calling-virtual-functions-during-construction-and-destruction",
    "href": "posts/virtualization/index.html#calling-virtual-functions-during-construction-and-destruction",
    "title": "The virtual keyword",
    "section": "Calling virtual functions during construction and destruction",
    "text": "Calling virtual functions during construction and destruction\nWhen a virtual function is called directly or indirectly from a constructor or destructor (including during the construction or destruction of the class non-static data members e.g. in a member-initializer list), and the object to which the call applies is the object under construction or destruction, the function called is the final overrider in the constructor’s or destructor’s class and not the one overriding it in a more-derived class.\n#include &lt;iostream&gt;\n\nclass Base {\npublic:\n    Base() {\n        std::cout &lt;&lt; \"Base constructor\\n\";\n        me();  // Virtual call during construction\n    }\n    \n    virtual ~Base() {\n        std::cout &lt;&lt; \"Base destructor\\n\";\n        me();  // Virtual call during destruction\n    }\n    \n    virtual void me() {\n        std::cout &lt;&lt; \"  I am Base\\n\";\n    }\n};\n\nclass Derived : public Base {\npublic:\n    Derived() {\n        std::cout &lt;&lt; \"Derived constructor\\n\";\n        me();  // Virtual call during construction\n    }\n    \n    ~Derived() {\n        std::cout &lt;&lt; \"Derived destructor\\n\";\n        me();  // Virtual call during destruction\n    }\n    \n    void me() override {\n        std::cout &lt;&lt; \"  I am Derived\\n\";\n    }\n};\n\nint main() {\n    Derived d;\n    std::cout &lt;&lt; \"\\nNormal call:\\n\";\n    d.me();\n}\nOutput:\nBase constructor\n  I am Base\nDerived constructor\n  I am Derived\n\nNormal call:\n  I am Derived\nDerived destructor\n  I am Derived\nBase destructor\n  I am Base"
  },
  {
    "objectID": "posts/virtualization/index.html#vtable-for-class-a",
    "href": "posts/virtualization/index.html#vtable-for-class-a",
    "title": "The virtual keyword",
    "section": "vtable for class A",
    "text": "vtable for class A\nA::_ZTV1A: 6 entries says the name of the vtable, which is a static array, is A::_ZTV1A and there are \\(6\\) function pointer entries in this static array. The offset of each entry is \\(8\\) bytes.\nVtable for A\nA::_ZTV1A: 6 entries\n0     (int (*)(...))0\n8     (int (*)(...))(& _ZTI1A)\n16    (int (*)(...))__cxa_pure_virtual\n24    (int (*)(...))A::baz\n32    0\n40    0\n\nClass A\n   size=8 align=8\n   base size=8 base align=8\nA (0x0x7cb4a0bd8000) 0 nearly-empty\n    vptr=((& A::_ZTV1A) + 16)\n16 (int (*)(...))__cxa_pure_virtual and 24 (int (*)(...))A::baz are pointers to the pure virtual function A::foo()=0 and the virtual function A::baz() respectively."
  },
  {
    "objectID": "posts/virtualization/index.html#vtable-for-class-b",
    "href": "posts/virtualization/index.html#vtable-for-class-b",
    "title": "The virtual keyword",
    "section": "vtable for class B",
    "text": "vtable for class B\nVtable for B\nB::_ZTV1B: 6 entries\n0     (int (*)(...))0\n8     (int (*)(...))(& _ZTI1B)\n16    (int (*)(...))B::foo\n24    (int (*)(...))B::baz\n32    (int (*)(...))B::~B\n40    (int (*)(...))B::~B\n\nClass B\n   size=8 align=8\n   base size=8 base align=8\nB (0x0x7cb4a0bd8120) 0 nearly-empty\n    vptr=((& B::_ZTV1B) + 16)\nAgain, 16 (int (*)(...))B::foo and 24 (int (*)(...))B::baz are pointers to the virtual functions B::foo() and B::baz().\nThe entries for virtual destructors are actually pairs of entries.\nThe first destructor, 32 (int (*)(...))B::~B called the complete object destructor, only performs destruction of variables that live on the stack having automatic storage duration. This memory does not need to be deallocated.\nThe second destructor, 40 (int (*)(...))B::~B called the deleting destructor of T is function, that in addition, to calling the complete object destructor, also calls the appropriate deallocation function for T (operator delete on T).\nSince the class A has atleast one pure virtual method, it cannot be instantiated directly, hence its vtable does not contain entries for destructors."
  },
  {
    "objectID": "posts/virtualization/index.html#vtable-for-class-c",
    "href": "posts/virtualization/index.html#vtable-for-class-c",
    "title": "The virtual keyword",
    "section": "vtable for class C",
    "text": "vtable for class C\nVtable for C\nC::_ZTV1C: 7 entries\n0     (int (*)(...))0\n8     (int (*)(...))(& _ZTI1C)\n16    (int (*)(...))C::foo\n24    (int (*)(...))B::baz\n32    (int (*)(...))C::~C\n40    (int (*)(...))C::~C\n48    (int (*)(...))C::bar\n\nClass C\n   size=8 align=8\n   base size=8 base align=8\nC (0x0x7cb4a0a0e618) 0 nearly-empty\n    vptr=((& C::_ZTV1C) + 16)\nB (0x0x7cb4a0bd8180) 0 nearly-empty\n      primary-for C (0x0x7cb4a0a0e618)\nC is a child class of B. 16 (int (*)(...))C::foo is a pointer to the overriding function of B::foo() - C::foo() and 24 (int (*)(...))B::baz is a pointer to the inherited function B::baz().\n32 (int (*)(...))C::~C and 40 (int (*)(...))C::~C are the pairs of destrutors.\n48 (int (*)(...))C::bar is the pointer to the subclass method C::bar()."
  },
  {
    "objectID": "posts/virtualization/index.html#vtable-for-class-d",
    "href": "posts/virtualization/index.html#vtable-for-class-d",
    "title": "The virtual keyword",
    "section": "vtable for class D",
    "text": "vtable for class D\nD inherits from both A and C (indirectly from B).\nVtable for D\nD::_ZTV1D: 13 entries\n0     (int (*)(...))0\n8     (int (*)(...))(& _ZTI1D)\n16    (int (*)(...))D::foo\n24    (int (*)(...))B::baz\n32    (int (*)(...))D::~D\n40    (int (*)(...))D::~D\n48    (int (*)(...))D::bar\n56    (int (*)(...))-8\n64    (int (*)(...))(& _ZTI1D)\n72    (int (*)(...))D::_ZThn8_N1D3fooEv\n80    (int (*)(...))A::baz\n88    (int (*)(...))D::_ZThn8_N1DD1Ev\n96    (int (*)(...))D::_ZThn8_N1DD0Ev\n\nClass D\n   size=16 align=8\n   base size=16 base align=8\nD (0x0x7cb4a0be7000) 0\n    vptr=((& D::_ZTV1D) + 16)\nC (0x0x7cb4a0a0e8f0) 0 nearly-empty\n      primary-for D (0x0x7cb4a0be7000)\nB (0x0x7cb4a0bd8240) 0 nearly-empty\n        primary-for C (0x0x7cb4a0a0e8f0)\nA (0x0x7cb4a0bd82a0) 8 nearly-empty\n      vptr=((& D::_ZTV1D) + 72)\n16 (int (*)(...))D::foo is a pointer to the overriding function of A:foo() and C::foo() - D::foo().\n24 (int (*)(...))B::baz and 80 (int (*)(...))A::baz are pointers to the copies of baz() inherited through the parents A and B.\n32 (int (*)(...))D::~D and 40 (int (*)(...))D::~D are pairs of destructors.\n48 (int (*)(...))D::bar is a pointer to the overriding function of C::bar() - D::bar().\nWhen a class inherits from multiple base classes ( as in the case of class D inheriting from both A and C), the memory layout of the derived class D includes subobjects for each of the base class. The this pointer must be adjusted to point to the correct subobject when calling a virtual function from one of the base classes.\nThe vcall-offset is an adjustment value that ensures that the this pointer points to the correct base class subobject, when a virtual function is invoked.\nThe vcall-offset is stored in the vtable as an entry (in this case, -8). When a virtual function is called, the vcall-offset is added to the current this pointer to adjust it to the correct base class subobject.\nIf the this pointer points to the D subobject, adding the vcall-offset -8 adjusts it to point to the A subobject inherited directly by D."
  },
  {
    "objectID": "posts/virtualization/index.html#references",
    "href": "posts/virtualization/index.html#references",
    "title": "The virtual keyword",
    "section": "References",
    "text": "References\n\n\nVirtual Tables."
  },
  {
    "objectID": "posts/quanto-options/index.html",
    "href": "posts/quanto-options/index.html",
    "title": "Quanto Options",
    "section": "",
    "text": "A quick refresher\nA quanto option is a derivative where the underlying is denominated in one currency, but the option-payoff is settled in a different one (the quanto-currency) at a pre-defined fixed exchange rate \\(Q\\).\nI take the example of gold quoted as \\(XAU/USD\\) that is quantoed in \\(INR\\).\nDefine :\n\\[\n\\begin{align*}\nS_T &:= \\text{Price of gold in the underlying currency} \\\\\nX_T &:= \\text{Price of the underlying currency in quanto currency terms}\\\\\nK &:= \\text{Strike expressed in underlying currency terms}\\\\\nQ &:= \\text{Pre-specified exchange rate}\n\\end{align*}\n\\]\nSince the payoff is in \\(INR\\), we take \\(INR\\) as the base currency or numeraire in the Black-Scholes model.\nThen, the payoff of the quanto-call option is:\n\\[\nV_T = Q\\left(\\frac{S_T}{X_T} - K\\right)^{+}\n\\]\n\\(S_T/X_T\\) has units \\(\\frac{XAU}{USD}\\), and \\(Q\\) - the pre-specified conversion factor has units \\(\\frac{USD}{INR}\\).\n\n\nThe Setup\nThe domestic risk-neutral measure \\(Q^{INR}\\) is the probability measure linked to the domestic money-market account \\(M_T^{INR}\\).\nThe risk-neutral measure \\(Q^{USD}\\) is the probability measure linked to the underlying money-market account expressed in quanto currency terms, \\((M_T^{USD} \\cdot X_T)\\). \\(M_T^{USD}\\) has units \\(USD^{-1}\\) and \\(X_T\\) has units \\(USD \\cdot INR^{-1}\\).\nConsider the Black-Scholes model:\n\\[\n\\begin{align*}\n{XAU/INR : } \\quad dS_t &= r_{INR} S_t dt + \\sigma_S S_t dW_{S}^{Q^{INR}}(t) \\\\\n{USD/INR : } \\quad dX_t &= (r_{INR} - r_{USD})X_t dt + \\sigma_X X(t) dW_X^{Q^{INR}}(t)\\\\\ndW_{S}^{Q^{INR}}(t) \\cdot dW_X^{Q^{INR}}(t) &= \\rho_{(f,q),(d,q)} dt\n\\end{align*}\n\\]\nwhere \\((W^{Q^{INR}}(t),t\\geq 0)\\) is a \\(Q^{INR}\\)-standard brownian motion.\n\n\nThe evolution of the underlying XAU-USD\nThe actual underlying is :\n\\[\n\\text{XAU/USD } := \\frac{S(t)}{X(t)}\n\\]\nUsing Ito’s formula, we obtain:\n\\[\n\\begin{align*}\nd\\left(\\frac{1}{X_t}\\right) &= -\\frac{1}{X_t^2}dX_t + \\frac{1}{2}\\cdot\\frac{2}{X_t^3} (dX_t)^2 \\\\\n&= -\\frac{1}{X_t}[(r_{INR} - r_{USD}) dt + \\sigma_X dW_X^{Q^{INR}}(t)] + \\frac{1}{X_t}\\sigma_X^2 dt\\\\\n&= \\frac{1}{X_t} [(\\sigma_X^2 + r_{USD} - r_{INR}) dt - \\sigma_X dW_X^{Q^{INR}}(t)]\n\\end{align*}\n\\]\nand hence:\n\\[\n\\begin{align*}\nd\\left(\\frac{S_t}{X_t}\\right) &= S_t \\cdot d\\left(\\frac{1}{X_t}\\right) + \\frac{1}{X_t} dS_t + dS_t \\cdot d\\left(\\frac{1}{X_t}\\right)\\\\\n&= \\frac{S_t}{X_t}[(\\sigma_X^2 + r_{USD} - r_{INR}) dt - \\sigma_X dW_X^{Q^{INR}}(t)] + \\frac{S_t}{X_t}[r_{INR} dt + \\sigma_S dW_{S}^{Q^{INR}}(t)] \\\\\n&-\\frac{S_t}{X_t} [((\\sigma_X^2 + r_{USD} - r_{INR}) dt - \\sigma_X dW_X^{Q^{INR}}(t))(r_{INR} dt + \\sigma_S dW_{S}^{Q^{INR}}(t))] \\\\\n&=\\frac{S_t}{X_t}[(\\sigma_X^2 +r_{USD} + \\rho \\sigma_X \\sigma_S ) dt + \\sigma_S dW_S^{Q^{INR}(t)} - \\sigma_X dW_X^{Q^{INR}}(t)]\n\\end{align*}\n\\]\nWe can find an orthogonal decomposition of the random vector process \\(\\begin{bmatrix} W_S^{Q^{INR}}(t) \\\\ W_X^{Q^{INR}}(t)\\end{bmatrix}\\).\nDefine : \\[\n\\begin{bmatrix}\nW_S^{Q^{INR}}(t) \\\\\nW_X^{Q^{INR}}(t)\n\\end{bmatrix} =\n\\begin{bmatrix}\nZ_S^{Q^{INR}}(t) \\\\\n\\rho Z_S^{Q^{INR}}(t) + \\sqrt{1-\\rho^2} Z_X^{Q^{INR}}(t)\n\\end{bmatrix}\n\\]\nwhere \\(Z_S^{Q^{INR}}(t)\\) and \\(Z_X^{Q^{INR}}(t)\\) are independent standard brownian motions.\nSo, the SDE can be written as:\n\\[\n\\begin{align*}\nd\\left(\\frac{S_t}{X_t}\\right) &= \\frac{S_t}{X_t}[(\\sigma_X^2 +r_{USD} + \\rho \\sigma_X \\sigma_S ) dt + \\sigma_S dZ_S^{Q^{INR}}(t) - \\sigma_X (\\rho \\cdot dZ_S^{Q^{INR}}(t) +  \\sqrt{1-\\rho^2} \\cdot dZ_X^{Q^{INR}}(t))] \\\\\n&=\\frac{S_t}{X_t}[(\\sigma_X^2 +r_{USD} + \\rho \\sigma_X \\sigma_S ) dt + (\\sigma_S - \\rho \\sigma_X ) dZ_S^{Q^{INR}}(t) - (\\sigma_X \\sqrt{1-\\rho^2}) dZ_X^{Q^{INR}}(t)]\n\\end{align*}\n\\]\nDefine:\n\\[\nB^{Q^{INR}}(t) = \\frac{(\\sigma_S - \\rho \\sigma_X ) Z_S^{Q^{INR}}(t) - (\\sigma_X \\sqrt{1-\\rho^2}) Z_X^{Q^{INR}}(t)}{(\\sigma_S - \\rho \\sigma_X )^2 + (\\sigma_X \\sqrt{1-\\rho^2})^2}\n\\]\nIt’s easy to see that \\(B^{Q^{INR}}(t)\\) is Gaussian and has mean and variance given by \\(\\mathcal{N}(0,t)\\).\nConsequently, we can re-write the SDE as:\n\\[\nd\\left(\\frac{S_t}{X_t}\\right) = \\frac{S_t}{X_t}[(\\sigma_X^2 +r_{USD} + \\rho \\sigma_X \\sigma_S ) dt + (\\sigma_S^2 - 2\\rho \\sigma_S \\sigma_X + \\sigma_X^2)dB^{Q^{INR}}(t)]\n\\]\nThus, \\((\\frac{S_t}{X_t})_{t\\geq 0}\\) follows a geometric brownian motion:\n\\[\n\\frac{S_t}{X_t} = \\frac{S_0}{X_0}\\exp\\left[\\left(\\alpha - \\frac{\\beta^2}{2}\\right)T+\\beta B^{Q^{INR}}(T)\\right]\n\\]\nwhere \\(\\alpha = \\sigma_X^2 +r_{USD} + \\rho \\sigma_X \\sigma_S\\), \\(\\beta = \\sigma_S^2 - 2\\rho \\sigma_S \\sigma_X + \\sigma_X^2\\)\nThis can easily be plugged into the Black formula to derive analytic expressions for quanto vanilla calls and puts."
  },
  {
    "objectID": "posts/shared_ptr/index.html",
    "href": "posts/shared_ptr/index.html",
    "title": "The inner workings of the shared_ptr",
    "section": "",
    "text": "shared_ptr&lt;T&gt; is tricky to implement, since it is a wrapper over raw underlying pointer of type T* and a reference counter. This post is partly inspired by the fantastic book C++ Memory Management by Patrice Roy. The toy examples in this book are very instructive and I highly reckon you order a copy.\nIf you follow the instructions in my GitHub repo, you should be able to build the source and run unit tests against my homegrown version of shared_ptr&lt;T&gt;."
  },
  {
    "objectID": "posts/shared_ptr/index.html#writing-the-shared_ptrt-destructor",
    "href": "posts/shared_ptr/index.html#writing-the-shared_ptrt-destructor",
    "title": "The inner workings of the shared_ptr",
    "section": "Writing the ~shared_ptr<T>() destructor",
    "text": "Writing the ~shared_ptr&lt;T&gt;() destructor\nThe destructor is tricky to get right.\nA naive algorithm for destruction could be that, if *m_ref_count_ptr == 1, call delete on both pointees, otherwise decrement the counter. It is possible that two threads enter the destructor concurrently with *m_ref_count_ptr=2, and neither thread sees *m_ref_count_ptr==1 and the pointees are never destroyed.\nAnother algorithm could be to decrement *m_ref_count_ptr. If *m_ref_count_ptr==0, invoke delete’s. There is a possibility that two threads enter the destructor concurrently, with *m_ref_count_ptr=2, then both concurrently decrement *m_ref_count_ptr leading to the possibility of both seeing *m_ref_count_ptr=0, resulting in double deletion."
  },
  {
    "objectID": "posts/type-traits-101/index.html",
    "href": "posts/type-traits-101/index.html",
    "title": "Type Traits 101",
    "section": "",
    "text": "Meta-programs are programs that treat other programs as data. They could be other programs or itself. A meta-function is not a function, but a class or struct. Metafunctions are not part of the language and have no formal language support. They exist purely as an idiomatic use of the existing language features. Now, since their use is not enforced by the language, their used has to be dictated by a convention. Over the years, the C++ community has created common set of standard conventions. Actually this work goes back all the way to Boost type_traits.\nMetafunctions are not functions. Technically, they are a class with zero or more template parameters and zero+ return types and values. The convention is that a metafunction should return just one thing, like a regular function. The convention was developed over time, so there are plenty of existing examples that do not follow this convention. More modern metafunctions do follow this convention."
  },
  {
    "objectID": "posts/type-traits-101/index.html#how-do-we-return-from-a-metafunction",
    "href": "posts/type-traits-101/index.html#how-do-we-return-from-a-metafunction",
    "title": "Type Traits 101",
    "section": "How do we return from a metafunction",
    "text": "How do we return from a metafunction\nIf we have to return a value, basically, we are going to expose a public field named value.\ntemplate&lt;typename T&gt;\nstruct TheAnswer{\n    static constexpr int value = 42;\n};\nAnd if we are going to return a type, we are going to expose a public field named type.\ntemplate&lt;typename T&gt;\nstruct Echo{\n    using type = T;\n};\nNow, here’s kind of the difference between regular functions and metafunctions. A regular function in C++ always works on some form of data and it’s always going to return to you some piece of data as well. Amongst metafunctions, we have value metafunctions that work on values like we are used to and then we have metafunctions that work entirely on types and they yield back some type to you. And so in the both of the examples above, we return something by exposing the public members of a class."
  },
  {
    "objectID": "posts/type-traits-101/index.html#value-metafunctions",
    "href": "posts/type-traits-101/index.html#value-metafunctions",
    "title": "Type Traits 101",
    "section": "Value metafunctions",
    "text": "Value metafunctions\nA value metafunction is kind of like a simple regular function. Let’s look at a simple regular function - the integer identity function.\nint int_identity(int x)\n{\n    return x;\n}\n\nassert(42 == int_identity(42));\nThis function just applies the identity transformation on any integer passed to it, and spits out the same number. A simple metafunction for identity - we can call it the intIdentity metafunction would look like this:\ntemplate&lt;int X&gt;\nstruct intIdentity{\n    static constexpr int value = X;\n};\n\nstatic_assert(42 == IntIdentity&lt;42&gt;::value);\nWe see that it’s not that much different. You return a value by having a static data-member called value and it has the metafunction’s return value. IntIdentity&lt;42&gt;::value is where we are calling the metafunction. Now, this convention needs to be adhered to, because if you give your metafunction some other name such as my_value, for example, if you write:\ntemplate&lt;int X&gt;\nstruct intIdentity{\n    static constexpr int my_value = X;\n};\n\nstatic_assert(42 == IntIdentity&lt;42&gt;::value);\nit’s not going to work well with other things.\n\nGeneric Identity Function\nLet’s look at the generic identity function.\ntemplate&lt;typename T&gt;\nT identity(T x){\n    return x;\n}\n\n//Returned type will be 42\nassert(42 == identity(42));\n\n// Returned type will be unsigned long long\nassert(42ul == identity(42ul))\nThis is just a function that will be an identity for any type. You give me a value of any type and I will give you that value back. Now we can create a generic identity metafunction as well:\ntemplate&lt;typename T, T x&gt;\nstruct ValueIdentity{\n    static constexpr T value = x;\n};\n\n// The type of value will be int\nstatic_assert(42 == identity&lt;int,42&gt;::value);\n\n// The type of value will unsigned long long\nstatic_assert(42ull == identity&lt;unsigned long long,42ull&gt;::value);\nValueIdentity is a generic metafunction, so we have to first feed it the type int and then the value 42. It’s a little cumbersome, but you get used to it after a while.\nIn C++17, things get a little bit easier with generic metafunctions, because we have this cool keyword called auto. I won’t go into all the details of auto. For now, it basically means that the template will accept and deduce the type of any non-type template parameter.\ntemplate&lt;auto X&gt;\nstruct ValueIdentity{\n    static constexpr auto value = X;\n};\n\n// The type of value will be int\nstatic_assert(42 == identity&lt;int,42&gt;::value);\n\n// The type of value will unsigned long long\nstatic_assert(42ull == identity&lt;unsigned long long,42ull&gt;::value);\nLet’s look at another function sum(). We can do this in a regular function, and we can do this in a metafunction as well.\nint sum(int x, int y){\n    return x + y;\n}\n\ntemplate&lt;int X, int Y&gt;\nstruct intSum{\n    static constexpr int value = X + Y;\n};\n\nstatic_assert(42 == IntSum&lt;30,12&gt;::value);\nSo, we can also create a generic version of this:\ntemplate&lt;typename X, typename Y&gt;\nauto sum(T x, Ty){\n    return x + y;\n}\n\ntemplate&lt;auto X, auto Y&gt;\nstruct Sum{\n    static constexpr auto value = X + Y;\n};"
  },
  {
    "objectID": "posts/type-traits-101/index.html#type-metafunctions",
    "href": "posts/type-traits-101/index.html#type-metafunctions",
    "title": "Type Traits 101",
    "section": "Type metafunctions",
    "text": "Type metafunctions\nType metafunctions are the workhorse of doing type transformations. You can manipulate types through type metafunctions. Type *metafunctions are going to return just a type.\nHere’s our TypeIdentity function:\ntemplate&lt;typename T&gt;\nstruct TypeIdentity{\n    using type = T;\n}\nJust like we have ValueIdentity, where given any value, it’s going you the value back; we have TypeIdentity, where you give it any type, and it’s going to give you the type back.\nC++20 actually introduces std::type_identity, which is pretty much what we see above.\n\nCalling Type Metafunctions\nWhen we call a value metafunction, we can easily call the function:\nValueIdentity&lt;42&gt;::value\nValueIdentity is the metafunction, it’s passed the parameter 42 in the angle brackets (just like parentheses for a regular value function) and ::value is how I get it’s value back.\nWhen I call a type metafunction, it’s the same way. The function call consists of the metafunction name std::type_identity, the parameters to the metafunction in angle brackets (&lt;42&gt;) and ::type is how I get it’s value back.\n#include &lt;iostream&gt;\n#include &lt;type_traits&gt;\n\nint main()\n{\n    using T = std::type_identity&lt;int&gt;::type;\n    return 0;\n}\nCompiler Explorer"
  },
  {
    "objectID": "posts/type-traits-101/index.html#understanding-name-binding-and-dependent-types",
    "href": "posts/type-traits-101/index.html#understanding-name-binding-and-dependent-types",
    "title": "Type Traits 101",
    "section": "Understanding name binding and dependent types",
    "text": "Understanding name binding and dependent types\nName binding is the process of establishing, determining explicitly the type of each name (declaration) in a template. There are two kinds of names used within a template: dependent and non-dependent names. Names that depend on a template parameter are called dependent names.\n\nFor dependent names, name binding is performed at the point of template instantiation.\nFor non-dependent names, name binding is performed at the point of template definition.\n\nConsider the following C++ code:\n// Ref: Template metaprogramming with C++\n// Mariusz Bancilla, pages 123 \n#include &lt;iostream&gt;\n\ntemplate&lt;typename T&gt;\nstruct handler{\n    void handle(T value)    //[1] handle is a dependent name\n    {\n        std::cout &lt;&lt; \"handler&lt;T&gt;: \" &lt;&lt; value &lt;&lt; '\\n';\n    }\n};\n\ntemplate&lt;typename T&gt;\nstruct parser{\n    void parse(T arg){      //[2] parse is a dependent name\n        arg.handle(x);\n    }\n\n    double x;                  //[3] x is a non-dependent name\n};\n\nint main(){\n    handler&lt;double&gt; doubleHandler;                //[5] template instantiation\n    parser&lt;handler&lt;double&gt;&gt; doubleParser(3.14);   //[6] template instantiation\n    doubleParser.parse(doubleHandler);\n    return 0;\n}\nWhen the compiler sees dependent names, e.g. at points [1] and [2], it cannot determine the type-signature of these functions. So, parse() and handle() are not bound at this point.\nThe declaration double x at point [3] declares a non-dependent type. So, the type of the variable x is known and bound.\nContinuing with the code, at point [4], there is a template specialization for the handler class template for the type int.\nTemplate instantiation happens at points [5] and [6]. At point [5], handler&lt;double&gt;::handle is bound to handle and at point [6], parser&lt;handler&lt;double&gt;&gt;::parse is bound to parse.\n\nTwo-phase name lookup\nName binding happens differently for dependent names (those that depend on a template parameter) and non-dependent names. When the compiler passes throuh the definition of a template, it needs to figure out whether a name is dependent or non-dependent. Further, name binding depends upon this categorization. Thus, the instantiation of a template happens in 2-phases.\n\nThe first phase occurs at the point of the definition when the template syntax is checked and the names are categorized as dependent or non-dependent.\nThe second phase occurs at the point of template instantiation when the template arguments are substituted for the template parameters. Name binding for dependent names happens at this point.\n\nThis process in two steps is called the two-phase name lookup.\nConsider the following C++ code:\n// Ref: Template metaprogramming with C++\n// Mariusz Bancilla, pages 125\ntemplate&lt;typename T&gt;\nstruct base_parser\n{\n    void init()                     // [1] non-dependent name\n    {\n        std::cout &lt;&lt; \"init\\n\";\n    }\n};\n\ntemplate&lt;typename T&gt;\nstruct parser::public base_parser&lt;T&gt;\n{\n    void parse(){                  // [2] non-dependent name\n        // The compiler at [3] will try to bind init(), as it's a non-dependent name.\n        // However, base_parser has not yet been instantiated. This will result in a \n        // compile-error\n        //init();                  // [3] non-dependent name\n        std::cout &lt;&lt; \"parse\\n\";\n    }\n};\n\nint main(){\n    parser&lt;double&gt; p;\n    p.parse();\n}\nThe call to init() inside the parse() member function has been commented out. Uncommenting it will cause a compile error.\nThe intention here is to call the base-class init() function. However, the compiler will issue an error, because it’s not able to find init(). The reason is that init() is a non-dependent name. Therefore, it must be bound at the time of the definition of the parser template. Although, base_parser&lt;T&gt;::init() exists, this template has still not been instantiated. The compiler cannot assume its what we want to call, because the primary template base_parser can always be specialized and init() can be defined as something else.\nThis problem can be fixed, by making init a dependent name. This can be done by either prefixing it with this-&gt; or with base_parser&lt;T&gt;::.\n\n\nDependent type names\nThere are cases where a dependent name is a type. Consider the following C++ code:\n#include &lt;iostream&gt;\n\ntemplate&lt;typename T&gt;\nstruct base_parser{\n    using value_type = T;\n};\n\ntemplate&lt;typename T&gt;\nstruct parser: base_parser&lt;T&gt;{\n    void parse(){\n        // value_type v{};  // [1] : Error\n        // base_parser&lt;T&gt;::value_type v{};  //[2] :Error\n        std::cout &lt;&lt; \"parse\\n\";\n    }\n};\n\nint main()\n{\n    parser&lt;double&gt; p;\n    p.parse();\n    return 0;\n}\nCompiler Explorer\nIn this code snippet, the metafunction base_parser is an identity metafunction and returns back the type you give it. base_parser&lt;T&gt;::value_type is actually a dependent type, which depends on the template parameter T. At point [1] and [2], the compiler does not know what T will be. If it attempts to bind the name v, it will fail. We need to tell the compiler explicitly base_parser&lt;T&gt;::value_type is a dependent type. You do that using the typename keyword.\n#include &lt;iostream&gt;\n\ntemplate&lt;typename T&gt;\nstruct base_parser{\n    using value_type = T;\n};\n\ntemplate&lt;typename T&gt;\nstruct parser: base_parser&lt;T&gt;{\n    void parse(){\n        // value_type v{};  // [1] : Error\n        // base_parser&lt;T&gt;::value_type v{};  //[2] :Error\n        typename base_parser&lt;T&gt;::value_type v{};  //[3] :Ok\n        std::cout &lt;&lt; \"parse\\n\";\n    }\n};\n\nint main()\n{\n    parser&lt;double&gt; p;\n    p.parse();\n    return 0;\n}\nSo, any time, when calling a type metafunction, if the compiler does not know what ::type is, you must prefix it using the typename keyword, if we want to treat it as a type."
  },
  {
    "objectID": "posts/type-traits-101/index.html#convenience-calling-functions",
    "href": "posts/type-traits-101/index.html#convenience-calling-functions",
    "title": "Type Traits 101",
    "section": "Convenience calling functions",
    "text": "Convenience calling functions\nValue metafunctions often use helper functions (variable templates) ending with _v. For example, we often define the helper function:\ntemplate &lt;auto X&gt;\ninline constexpr auto ValueIdentity_v = ValueIdentity&lt;X&gt;::value;\n\nstatic_assert(42 == ValueIdentity&lt;42&gt;::value);\nstatic_assert(42 == ValueIdentity_v&lt;42&gt;)\nWe are just calling the ValueIdentity&lt;&gt; metafunction, grabbing its value and storing it into this variable ValueIdentity_v. This is a convenient way of calling value metafunctions. It does require you to instantiate an extra variable template.\nIt’s really helpful when we start using it with types. Type metafunctions use alias templates ending with _t. It helps us get rid of the entire typename dance.\ntemplate &lt;typename T&gt;\nusing TypeIdentity_t = typename TypeIdentity&lt;T&gt;::type;\n\nstatic_assert(std::is_same_v&lt;int, TypeIdentity_t&lt;int&gt;);\nInstead of calling the TypeIdentity metafunction with the parameter int and writing ::type to get its value, I can just call the metafunction with _t and with its parameters in angle brackets(&lt;&gt;).\nThese calling conventions are easier to use. But each one must be explicitly hand-written. So, every time you write a metafunction, if you want to provide convenience capabilities, you also have to write the convenience variable template or alias template."
  },
  {
    "objectID": "posts/type-traits-101/index.html#useful-metafunctions-to-think-of",
    "href": "posts/type-traits-101/index.html#useful-metafunctions-to-think-of",
    "title": "Type Traits 101",
    "section": "Useful metafunctions to think of",
    "text": "Useful metafunctions to think of\nHow is std::remove_pointer metafunction implemented? You can intuitively come up with what it must look like:\ntemplate&lt;typename T&gt;\nstruct RemovePointer{\n    using type = T;\n};\n\n// template specialization\ntemplate&lt;typename T&gt;\nstruct RemovePointer&lt;T*&gt;{\n    using type = T;\n};\nIf the std::remove_pointer metafunction receives int* as a parameter, the specialized version of the template kicks in, as int* is matched against T*. Here is the full implementation of std::remove_pointer&lt;T&gt;:\ntemplate &lt;class T&gt; struct remove_pointer                    { using type = T };\ntemplate &lt;class T&gt; struct remove_pointer&lt;T*&gt;                { using type = T };\ntemplate &lt;class T&gt; struct remove_pointer&lt;T* const&gt;          { using type = T };\ntemplate &lt;class T&gt; struct remove_pointer&lt;T* volatile&gt;       { using type = T };\ntemplate &lt;class T&gt; struct remove_pointer&lt;T* const volatile&gt; { using type = T };\nAs you can see, the same technique is applied to more subtle edge cases.\nHow about std::remove_reference?\ntemplate&lt;typename T&gt;\nstruct RemoveReference{\n    using type = T;\n};\n\n// template specialization\ntemplate&lt;typename T&gt;\nstruct RemoveReference&lt;T&&gt;{\n    using type = T;\n};\n\n// template specialization\ntemplate&lt;typename T&gt;\nstruct RemoveReference&lt;T&&&gt;{\n    using type = T;\n};\nBut, removing qualifiers from types is only the tip of the iceberg. How are std::enable_if and std::conditional implemented? Take a guess!\nThe type metafunction std::enable_if returns the type T, if the predicate B is true.\ntemplate &lt;bool B, typename T&gt;\nstruct EnableIf{};\n\ntemplate &lt;typename T&gt;\nstruct EnableIf&lt;true,T&gt;{\n    using type = T;\n};\nThe type metafunction std::conditional returns T, if the predicate B is true, otherwise returns F. It’s a compile-time if-else operating with types.\ntemplate &lt;bool B, typename T, typename F&gt;\nstruct Conditional{\n    using type = T;\n};\n\ntemplate &lt;typename T, typename F&gt;\nstruct Conditional&lt;false, T, F&gt;{\n    using type = F;\n};\nThe type metafunction std::remove_const removes any top-level const qualifier. It’s a transformation trait. Let’s look at the usage of this metafunction to ensure we handle all cases correctly.\nWe could try to implement it from scratch as follows:\n//Primary template : do nothing if there's no const\ntemplate&lt;typename T&gt;\nstruct RemoveConst : std::type_identity&lt;T&gt; {};\n\n//Partial specialization \ntemplate&lt;typename T&gt; struct RemoveConst&lt;T const&gt;{\n    using type = T;\n}\nand likewise for removing volatile.\ntemplate &lt;typename T&gt;\nstruct RemoveVolatile {\n    using Type = T;\n};\n\n// remove volatile\ntemplate &lt;typename T&gt;\nstruct RemoveVolatile&lt;volatile T&gt; {\n    using Type = T;\n};\nRemoveConst and RemoveVolatile can be composed into RemoveCV.\ntemplate &lt;typename T&gt;\nstruct RemoveCVT : RemoveConst&lt;RemoveVolatile&lt;T&gt;&gt; {};\nI hope you enjoyed the warm-up. Now, let’s try and implement std::decay from scratch."
  },
  {
    "objectID": "posts/type-traits-101/index.html#implementing-stddecay",
    "href": "posts/type-traits-101/index.html#implementing-stddecay",
    "title": "Type Traits 101",
    "section": "Implementing std::decay",
    "text": "Implementing std::decay\nSince C++11, std::decay was introduced into &lt;type_traits&gt;. It is used to decay a type, or to convert a type into it’s corresponding by-value type. It will remove any top-level cv-qualifiers (const, volatile) and reference qualifiers for the specified type. For example, int& is turned into int. An array type becomes a pointer to its element types. A function type becomes a pointer to the function.\n\nNon-Array and Non-function case\nWe handle the non-array and non-function cases first.\n// RemoveConst and RemoveVolatile can be composed into RemoveCV\ntemplate &lt;typename T&gt;\nstruct DecayT : RemoveCVT&lt;RemoveReference&lt;T&gt;&gt; {};\n\n\nArray-to-pointer decay\nNow, we take array types into account. Below are partial specialisations to convert an array type into a pointer to its element type:\n// unbounded array\ntemplate &lt;typename T&gt;\nstruct DecayT&lt;T[]&gt; {\n    using Type = T*;\n};\n\n// bounded array\ntemplate &lt;typename T, std::size_t N&gt;\nstruct DecayT&lt;T[N]&gt; {\n    using Type = T*;\n};\n\n\nFunction-to-pointer decay\nWe want to recognise a function regardless of its return type and parameter types, and then get its function pointer. Because there are different number of parameters, we need to employ variadic templates:\ntemplate &lt;typename Ret, typename...Args&gt;\nstruct DecayT&lt;Ret(Args...)&gt; {\n    using Type = Ret(*)(Args...);\n};"
  },
  {
    "objectID": "posts/type-traits-101/index.html#stdintegral_constant-metafunction",
    "href": "posts/type-traits-101/index.html#stdintegral_constant-metafunction",
    "title": "Type Traits 101",
    "section": "std::integral_constant metafunction",
    "text": "std::integral_constant metafunction\nThe std:integral_constant wraps a static constant of the specified type. It is a value meta-function. In fact, it is an identity meta-function, so that, std::integral_constant&lt;char,'a'&gt;::value returns a. It is also a type meta-function. Here’s a possible implementation:\ntemplate&lt;class T, T v&gt;\nstruct integral_constant\n{\n    static constexpr T value = v;\n    \n    using value_type = T;\n    \n    using type = integral_constant; // using injected-class-name\n    \n    constexpr operator value_type() const noexcept { return value; }\n    \n    constexpr value_type operator()() const noexcept { return value; } // since c++14\n};\nNow, std::true_type is simply the compile-time constant defined as std::integral_constant&lt;bool,true&gt;. std::false_type is the compile-time constant defined as std::integral_constant&lt;bool,false&gt;."
  },
  {
    "objectID": "posts/type-traits-101/index.html#stdis_same",
    "href": "posts/type-traits-101/index.html#stdis_same",
    "title": "Type Traits 101",
    "section": "std::is_same",
    "text": "std::is_same\nstd::is_same&lt;T1,T2&gt; is a comparison metafunction for types. We have a primary template:\n// Primary template\ntemplate&lt;typename T1, typename T2&gt;\nstruct is_same : std::false_type {};\nIt takes two types as arguments. If the two types are the same, we have the explicit specialisation:\n// Template metaprogramming \n// Mariusz Bancila \ntemplate&lt;typename T&gt;\nstruct is_same&lt;T,T&gt;{\n    using value = std::true_type;\n}\n\n// Convenience - variable template\ntemplate&lt;typename T1, typename T2&gt;\nconstexpr inline bool is_same_v = is_same&lt;T1,T2&gt;::value;\nNow, we can define is_floating_point as an alias template:\ntemplate&lt;class T&gt;\nusing is_floating_point = std::bool_constant&lt;\n         // Note: standard floating-point types\n         std::is_same&lt;float, typename std::remove_cv&lt;T&gt;::type&gt;::value\n         || std::is_same&lt;double, typename std::remove_cv&lt;T&gt;::type&gt;::value\n         || std::is_same&lt;long double, typename std::remove_cv&lt;T&gt;::type&gt;::value\n\n         // Note: extended floating-point types (C++23, if supported)\n         || std::is_same&lt;std::float16_t, typename std::remove_cv&lt;T&gt;::type&gt;::value\n         || std::is_same&lt;std::float32_t, typename std::remove_cv&lt;T&gt;::type&gt;::value\n         || std::is_same&lt;std::float64_t, typename std::remove_cv&lt;T&gt;::type&gt;::value\n         || std::is_same&lt;std::float128_t, typename std::remove_cv&lt;T&gt;::type&gt;::value\n         || std::is_same&lt;std::bfloat16_t, typename std::remove_cv&lt;T&gt;::type&gt;::value\n&gt;;"
  },
  {
    "objectID": "posts/type-traits-101/index.html#examples-of-using-type-traits",
    "href": "posts/type-traits-101/index.html#examples-of-using-type-traits",
    "title": "Type Traits 101",
    "section": "Examples of using type traits",
    "text": "Examples of using type traits\nConsider the below widget and gadget classes:\n#include &lt;array&gt;\n#include &lt;iterator&gt;\n#include &lt;iostream&gt;\n#include &lt;string&gt;\n\nstruct widget{\n    int id;\n    std::string name;\n\n    std::ostream& write(std::ostream& os) const{\n        os &lt;&lt; id &lt;&lt; std::endl;\n        return os;\n    }\n};\n\nstruct gadget{\n    int id;\n    std::string name;\n\n    friend std::ostream& operator&lt;&lt;(std::ostream& os, gadget const & g);\n};\n\nstd::ostream& operator&lt;&lt;(std::ostream& os, gadget const & g){\n    os &lt;&lt; g.id &lt;&lt; \",\" &lt;&lt; g.name &lt;&lt; \"\\n\";\n    return os;\n}\n\nint main(){\n    return 0;\n}\nCompiler Explorer\nThe widget class contains a member function write. However, for the gadget class, the stream operator &lt;&lt; is overloaded for the same purpose. We can write the following code using these classes:\nwidget w{1, \"one\"};\nw.write(std::cout);\n\ngagdet g{2, \"two\"}\nstd::cout &lt;&lt; g\nHowever, we want to write a function template that enables us to treat them the same way. In other words, instead of using either write or the &lt;&lt; operator, we should be able to write the following:\nserialize(std::cout, w);\nserialize(std::cout, g);\nHow would such a function template look? How can we know whether a type provides a write method or has the &lt;&lt; operator overloaded? In other words, we need to query if a type supports write. We can write our own type trait.\nLet’s write a type metafunction uses_write&lt;T&gt; which returns true, if T is widget and false otherwise.\ntemplate&lt;typename T&gt;\nstruct uses_write {\n    static inline constexpr bool value = false;\n};\n\ntemplate&lt;&gt;\nstruct uses_write&lt;widget&gt;{\n    static inline constexpr bool value = true;\n};\nNext, let’s assume for simplicity that types that don’t provide a write() member function always overload the output stream operator &lt;&lt;.\nI can write a primary template to handle the default case.\ntemplate&lt;bool B&gt;\nstruct serializer{\n\n    template&lt;typename T&gt;\n    static void serialize(std::ostream& os, T const & obj){\n        os &lt;&lt; obj;\n    }\n};\nI can specialize this template to handle the case where T supports write.\nstruct serializer&lt;true&gt;{\n\n    template&lt;typename T&gt;\n    static void serialize(std::ostream& os, T const & obj){\n        obj.write(os);\n    }\n};\nWe can now write a free-standing function serialize function, that calls the type-metafunction use_write&lt;T&gt; to determine which function to dispatch at compile-time.\ntemplate &lt;typename T&gt;\nvoid serialize(std::ostream& os, T const & obj){\n    serializer&lt;uses_write&lt;T&gt;::value&gt;::serialize(os, obj);\n}\nCompiler Explorer"
  },
  {
    "objectID": "posts/thread-safe-stack/index.html",
    "href": "posts/thread-safe-stack/index.html",
    "title": "Thread-Safe Stack Implementation",
    "section": "",
    "text": "We can use C++ synchronization primitives to implement a basic thread-safe stack and queue.\n\n\n\n\n\n#include &lt;gtest/gtest.h&gt;\n#include \"threadsafe_stack.h\"\n#include &lt;thread&gt;\n#include &lt;vector&gt;\n#include &lt;algorithm&gt;\n\nTEST(ThreadSafeStackTest, PushAndTopTest) {\n    dev::threadsafe_stack&lt;int&gt; stack;\n    stack.push(42);\n    EXPECT_EQ(stack.top(), 42);\n}\n\nTEST(ThreadSafeStackTest, PopTest) {\n    dev::threadsafe_stack&lt;int&gt; stack;\n    stack.push(42);\n    auto popped = stack.pop();\n    EXPECT_TRUE(popped.has_value());\n    EXPECT_EQ(popped.value(), 42);\n    EXPECT_TRUE(stack.empty());\n}\n\nTEST(ThreadSafeStackTest, EmptyTest) {\n    dev::threadsafe_stack&lt;int&gt; stack;\n    EXPECT_TRUE(stack.empty());\n    stack.push(42);\n    EXPECT_FALSE(stack.empty());\n}\n\nTEST(ThreadSafeStackTest, ConcurrentPushTest) {\n    dev::threadsafe_stack&lt;int&gt; stack;\n    std::vector&lt;std::thread&gt; threads;\n\n    for (int i = 0; i &lt; 10; ++i) {\n        threads.emplace_back([&stack, i]() {\n            stack.push(i);\n        });\n    }\n\n    for (auto& thread : threads) {\n        thread.join();\n    }\n\n    EXPECT_FALSE(stack.empty());\n    EXPECT_TRUE(stack.size() == 10);\n}\n\nTEST(ThreadSafeStackTest, ConcurrentPopTest) {\n    dev::threadsafe_stack&lt;int&gt; stack;\n    for (int i = 0; i &lt; 10; ++i) {\n        stack.push(i);\n    }\n\n    std::vector&lt;std::thread&gt; threads;\n    std::vector&lt;int&gt; results;\n    std::mutex mtx;\n\n    for (int i = 0; i &lt; 10; ++i) {\n        threads.emplace_back([&stack, &results, &mtx]() {\n            auto popped = stack.pop();\n            if (popped.has_value()) {\n                std::unique_lock&lt;std::mutex&gt; unique_lck(mtx);\n                results.push_back(popped.value());\n            }\n        });\n    }\n\n    for (auto& thread : threads) {\n        thread.join();\n    }\n\n    EXPECT_EQ(results.size(), 10);\n}\n\nTEST(ThreadSafeStackTest, ConcurrentSwapTest){\n    dev::threadsafe_stack&lt;int&gt; evens, odds;\n    for(int i{0};i&lt;5;++i)\n        evens.push(2*i);\n    \n    for(int i{0};i&lt;5;++i)\n        odds.push(2*i + 1);  \n        \n    dev::threadsafe_stack&lt;int&gt; evensCopy {evens};\n    dev::threadsafe_stack&lt;int&gt; oddsCopy {odds};            \n\n    std::vector&lt;std::thread&gt; threads;\n\n    for(int j{0};j&lt;2;++j){\n        threads.emplace_back([&evens, &odds](){\n            evens.swap(odds);\n        });\n    }\n\n    for(int j{0};j&lt;2;++j)\n        threads[j].join();\n    \n    EXPECT_EQ(evens == evensCopy, true);\n    EXPECT_EQ(odds == oddsCopy, true);\n}\n\n\n#include &lt;stack&gt;\n#include &lt;mutex&gt;\n#include &lt;shared_mutex&gt;\n#include &lt;optional&gt;\n\nnamespace dev{\n    template&lt;typename T&gt;\n    class threadsafe_stack{\n        private:\n        std::stack&lt;T&gt; m_stack;\n        std::shared_mutex m_shared_mutex;\n\n        public:\n        using value_type = T;\n        using reference = T&;\n        using const_reference = const T&;\n\n        // default constructor\n        threadsafe_stack() = default;\n\n        // copy constructor\n        threadsafe_stack(const threadsafe_stack& other)\n        {\n            std::shared_lock&lt;std::shared_mutex&gt; shared_lck(const_cast&lt;std::shared_mutex&&gt;(other.m_shared_mutex));\n            m_stack = other.m_stack;\n        }\n\n        // copy assignment\n        threadsafe_stack& operator=(const threadsafe_stack& ) = delete;\n\n        /**\n         * @brief Inserts an element at the top of the stack.\n         */\n        void push(const_reference element){\n            std::unique_lock unique_lck(m_shared_mutex);\n            if constexpr(std::is_nothrow_constructible_v&lt;T&gt;){\n                m_stack.push(std::move(element));\n            }\n            else{\n                m_stack.push(element);\n            }\n        }\n\n        std::optional&lt;T&gt; pop(){\n            std::unique_lock&lt;std::shared_mutex&gt; unique_lck(m_shared_mutex);\n            if(m_stack.empty())\n                return std::nullopt;\n            \n            T element;\n            if constexpr(std::is_nothrow_move_constructible_v&lt;T&gt;){\n                element = std::move(m_stack.top());\n            }\n            else{\n                element = m_stack.top();\n            }\n            m_stack.pop();\n            return element;\n        }\n\n        value_type top(){\n            std::shared_lock&lt;std::shared_mutex&gt; shared_lck(m_shared_mutex);\n            return m_stack.top();\n        }\n\n        bool empty(){\n            std::shared_lock&lt;std::shared_mutex&gt; shared_lck(m_shared_mutex);\n            return m_stack.empty();\n        }\n\n        std::size_t size(){\n            std::shared_lock&lt;std::shared_mutex&gt; shared_lck(m_shared_mutex);\n            return m_stack.size();\n        }\n\n        void swap(threadsafe_stack& other){\n            std::scoped_lock&lt;std::shared_mutex, std::shared_mutex&gt; scoped_lck(m_shared_mutex, other.m_shared_mutex);\n            std::swap(m_stack, other.m_stack);\n        }\n\n        friend void swap(threadsafe_stack& lhs, threadsafe_stack& rhs){\n            lhs.swap(rhs);\n        }\n\n        friend bool operator==(threadsafe_stack& lhs, threadsafe_stack& rhs){\n            std::scoped_lock&lt;std::shared_mutex, std::shared_mutex&gt; scoped_lck(lhs.m_shared_mutex, rhs.m_shared_mutex);\n            if(lhs.m_stack.size() != rhs.m_stack.size())\n                return false;\n            return lhs.m_stack == rhs.m_stack;\n        }\n    };\n}"
  },
  {
    "objectID": "posts/thread-safe-stack/index.html#basic-functionalities-expected-from-a-thread-safe-stack",
    "href": "posts/thread-safe-stack/index.html#basic-functionalities-expected-from-a-thread-safe-stack",
    "title": "Thread-Safe Stack Implementation",
    "section": "",
    "text": "#include &lt;gtest/gtest.h&gt;\n#include \"threadsafe_stack.h\"\n#include &lt;thread&gt;\n#include &lt;vector&gt;\n#include &lt;algorithm&gt;\n\nTEST(ThreadSafeStackTest, PushAndTopTest) {\n    dev::threadsafe_stack&lt;int&gt; stack;\n    stack.push(42);\n    EXPECT_EQ(stack.top(), 42);\n}\n\nTEST(ThreadSafeStackTest, PopTest) {\n    dev::threadsafe_stack&lt;int&gt; stack;\n    stack.push(42);\n    auto popped = stack.pop();\n    EXPECT_TRUE(popped.has_value());\n    EXPECT_EQ(popped.value(), 42);\n    EXPECT_TRUE(stack.empty());\n}\n\nTEST(ThreadSafeStackTest, EmptyTest) {\n    dev::threadsafe_stack&lt;int&gt; stack;\n    EXPECT_TRUE(stack.empty());\n    stack.push(42);\n    EXPECT_FALSE(stack.empty());\n}\n\nTEST(ThreadSafeStackTest, ConcurrentPushTest) {\n    dev::threadsafe_stack&lt;int&gt; stack;\n    std::vector&lt;std::thread&gt; threads;\n\n    for (int i = 0; i &lt; 10; ++i) {\n        threads.emplace_back([&stack, i]() {\n            stack.push(i);\n        });\n    }\n\n    for (auto& thread : threads) {\n        thread.join();\n    }\n\n    EXPECT_FALSE(stack.empty());\n    EXPECT_TRUE(stack.size() == 10);\n}\n\nTEST(ThreadSafeStackTest, ConcurrentPopTest) {\n    dev::threadsafe_stack&lt;int&gt; stack;\n    for (int i = 0; i &lt; 10; ++i) {\n        stack.push(i);\n    }\n\n    std::vector&lt;std::thread&gt; threads;\n    std::vector&lt;int&gt; results;\n    std::mutex mtx;\n\n    for (int i = 0; i &lt; 10; ++i) {\n        threads.emplace_back([&stack, &results, &mtx]() {\n            auto popped = stack.pop();\n            if (popped.has_value()) {\n                std::unique_lock&lt;std::mutex&gt; unique_lck(mtx);\n                results.push_back(popped.value());\n            }\n        });\n    }\n\n    for (auto& thread : threads) {\n        thread.join();\n    }\n\n    EXPECT_EQ(results.size(), 10);\n}\n\nTEST(ThreadSafeStackTest, ConcurrentSwapTest){\n    dev::threadsafe_stack&lt;int&gt; evens, odds;\n    for(int i{0};i&lt;5;++i)\n        evens.push(2*i);\n    \n    for(int i{0};i&lt;5;++i)\n        odds.push(2*i + 1);  \n        \n    dev::threadsafe_stack&lt;int&gt; evensCopy {evens};\n    dev::threadsafe_stack&lt;int&gt; oddsCopy {odds};            \n\n    std::vector&lt;std::thread&gt; threads;\n\n    for(int j{0};j&lt;2;++j){\n        threads.emplace_back([&evens, &odds](){\n            evens.swap(odds);\n        });\n    }\n\n    for(int j{0};j&lt;2;++j)\n        threads[j].join();\n    \n    EXPECT_EQ(evens == evensCopy, true);\n    EXPECT_EQ(odds == oddsCopy, true);\n}\n\n\n#include &lt;stack&gt;\n#include &lt;mutex&gt;\n#include &lt;shared_mutex&gt;\n#include &lt;optional&gt;\n\nnamespace dev{\n    template&lt;typename T&gt;\n    class threadsafe_stack{\n        private:\n        std::stack&lt;T&gt; m_stack;\n        std::shared_mutex m_shared_mutex;\n\n        public:\n        using value_type = T;\n        using reference = T&;\n        using const_reference = const T&;\n\n        // default constructor\n        threadsafe_stack() = default;\n\n        // copy constructor\n        threadsafe_stack(const threadsafe_stack& other)\n        {\n            std::shared_lock&lt;std::shared_mutex&gt; shared_lck(const_cast&lt;std::shared_mutex&&gt;(other.m_shared_mutex));\n            m_stack = other.m_stack;\n        }\n\n        // copy assignment\n        threadsafe_stack& operator=(const threadsafe_stack& ) = delete;\n\n        /**\n         * @brief Inserts an element at the top of the stack.\n         */\n        void push(const_reference element){\n            std::unique_lock unique_lck(m_shared_mutex);\n            if constexpr(std::is_nothrow_constructible_v&lt;T&gt;){\n                m_stack.push(std::move(element));\n            }\n            else{\n                m_stack.push(element);\n            }\n        }\n\n        std::optional&lt;T&gt; pop(){\n            std::unique_lock&lt;std::shared_mutex&gt; unique_lck(m_shared_mutex);\n            if(m_stack.empty())\n                return std::nullopt;\n            \n            T element;\n            if constexpr(std::is_nothrow_move_constructible_v&lt;T&gt;){\n                element = std::move(m_stack.top());\n            }\n            else{\n                element = m_stack.top();\n            }\n            m_stack.pop();\n            return element;\n        }\n\n        value_type top(){\n            std::shared_lock&lt;std::shared_mutex&gt; shared_lck(m_shared_mutex);\n            return m_stack.top();\n        }\n\n        bool empty(){\n            std::shared_lock&lt;std::shared_mutex&gt; shared_lck(m_shared_mutex);\n            return m_stack.empty();\n        }\n\n        std::size_t size(){\n            std::shared_lock&lt;std::shared_mutex&gt; shared_lck(m_shared_mutex);\n            return m_stack.size();\n        }\n\n        void swap(threadsafe_stack& other){\n            std::scoped_lock&lt;std::shared_mutex, std::shared_mutex&gt; scoped_lck(m_shared_mutex, other.m_shared_mutex);\n            std::swap(m_stack, other.m_stack);\n        }\n\n        friend void swap(threadsafe_stack& lhs, threadsafe_stack& rhs){\n            lhs.swap(rhs);\n        }\n\n        friend bool operator==(threadsafe_stack& lhs, threadsafe_stack& rhs){\n            std::scoped_lock&lt;std::shared_mutex, std::shared_mutex&gt; scoped_lck(lhs.m_shared_mutex, rhs.m_shared_mutex);\n            if(lhs.m_stack.size() != rhs.m_stack.size())\n                return false;\n            return lhs.m_stack == rhs.m_stack;\n        }\n    };\n}"
  },
  {
    "objectID": "posts/the_markov_property/index.html",
    "href": "posts/the_markov_property/index.html",
    "title": "The Markov Property",
    "section": "",
    "text": "Let’s start by exhibiting the Markov property of Brownian motion. To see this, consider \\((\\mathcal{F}_t,t\\geq 0)\\), the natural filtration of the Brownian motion \\((B_t,t\\geq 0)\\). Consider \\(g(B_t)\\) for some time \\(t\\) and bounded function \\(g\\). (For example, \\(g\\) could be an indicator function.) Consider also a random variable \\(W\\) that is \\(\\mathcal{F}_s\\) measurable for \\(s &lt; t\\). (For example, \\(W\\) could be \\(B_s\\) or \\(1_{B_s &gt; 0}\\).) Let’s compute \\(\\mathbb{E}[g(B_t)W]\\).\n\n%load_ext itikz\n\n\\[\\begin{align*}\n\\mathbb{E}[g(B_t)W] &= \\mathbb{E}[\\mathbb{E}[Wg(B_t - B_s + B_s)|\\mathcal{F}_s]]\n\\end{align*}\\]\nThe random variable \\((B_t - B_s)\\) follows a \\(\\mathcal{N}(0,t-s)\\) distribution. By LOTUS,\n\\[\n\\begin{align*}\n\\mathbb{E}[g(B_t)W]\n&= \\int_{\\mathbb{R}} \\mathbb{E}[W g(y + B_s)|\\mathcal{F_s}]f_{(B_t - B_s)|B_s}(y) dy\\\\\n&= \\{\\text{ Using the fact that }B_t - B_s \\perp B_s\\}\\\\\n&= \\int_{\\mathbb{R}} \\mathbb{E}[W g(y + B_s)]f_{(B_t - B_s)}(y)dy\\\\\n&= \\int_{\\mathbb{R}} \\mathbb{E}[W g(y + B_s)]\\frac{e^{-\\frac{y^2}{2(t-s)}}}{\\sqrt{2\\pi(t-s)}}dy\n\\end{align*}\n\\]\nBy Fubini’s theorem, the integral and the expectation operator can be interchanged, and since \\(W\\) is \\(\\mathcal{F}_s\\) measurable, it follows from the definition of conditional expectations that:\n\\[\n\\begin{align*}\n\\mathbb{E}[Wg(B_t)] = \\mathbb{E}[W\\mathbb{E}[g(B_t)|\\mathcal{F}_s]] = \\mathbb{E}\\left[W\\int_{\\mathbb{R}}g(y + B_s)]\\frac{e^{-\\frac{y^2}{2(t-s)}}}{\\sqrt{2\\pi(t-s)}}dy\\right]\n\\end{align*}\n\\]\nIt follows that:\n\\[\n\\begin{align*}\n\\mathbb{E}[g(B_t)|\\mathcal{F}_s] = \\int_{\\mathbb{R}}g(y + B_s)]\\frac{e^{-\\frac{y^2}{2(t-s)}}}{\\sqrt{2\\pi(t-s)}}dy\n\\end{align*}\n\\tag{1}\\]\nWe make two important observations. First, the right hand side is a function of \\(s,t\\) and \\(B_s\\) only (and not of the Brownian motion before time s). In particular, we have:\n\\[\n\\mathbb{E}[g(B_t)|\\mathcal{F}_s] = \\mathbb{E}[g(B_t)|B_s]\n\\]\nThis holds for any bounded function \\(g\\). In particular, it holds for all indicator functions. This implies that the conditional distribution of \\(B_t\\) given \\(\\mathcal{F}_s\\) depends solely on \\(B_s\\), and not on other values before time \\(s\\). Second, the right-hand side is time-homogenous in the sense that it depends on the time difference \\(t-s\\).\nWe have just shown that Brownian motion is a time-homogenous Markov process.\n\nDefinition 1 (Markov process.) Consider a stochastic process \\((X_t,t\\geq 0)\\) and its natural filtration \\((\\mathcal{F}_t,t\\geq 0)\\). It is said to be a Markov process if and only if for any (bounded) function \\(g: \\mathbb{R} \\to \\mathbb{R}\\), we have:\n\\[\n\\mathbb{E}[g(X_t) | \\mathcal{F}_s] = \\mathbb{E}[g(X_t) | X_s], \\quad \\forall t \\geq 0, \\forall s \\leq t\n\\tag{2}\\]\n\nThis implies that \\(\\mathbb{E}[g(X_t)|\\mathcal{F}_s]\\) is an explicit function of \\(s\\), \\(t\\) and \\(X_s\\). It is said to be time-homogenous, if it is a function of \\(t-s\\) and \\(X_s\\). Since the above holds for all bounded \\(g\\), the conditional distribution of \\(X_t\\) given \\(\\mathcal{F}_s\\) is the same as the conditional distribution of \\(X_t\\) given \\(X_s\\).\nOne way to compute the conditional distribution of \\(X_t\\) given \\(\\mathcal{F}_s\\) is to compute the conditional MGF given \\(\\mathcal{F}_s\\), that is:\n\\[\n\\mathbb{E}[e^{a X_t}|\\mathcal{F}_s], \\quad a \\geq 0\n\\tag{3}\\]\nThe process would be Markov, if the conditional MGF is an explicit function of \\(s\\), \\(t\\) and \\(X_s\\).\n\nExample 1 (Brownian Motion is Markov) Let \\((B_t,t\\geq 0)\\) be a standard brownian motion. Our claim is that the brownian motion is a markov process.\n\nProof.\nWe have:\n\\[\\begin{align*}\n\\mathbb{E}[e^{a B_t}|\\mathcal{F}_s] &= \\mathbb{E}[e^{a (B_t - B_s + B_s)}|\\mathcal{F}_s]\\\\\n& \\{ \\text{ since }B_s \\text{ is }\\mathcal{F}_s-\\text{ measurable }\\}\\\\\n&= e^{a B_s} \\mathbb{E}[e^{a (B_t - B_s)}|\\mathcal{F}_s]\\\\\n& \\{ \\text{ since }B_t - B_s \\perp \\mathcal{F}_s \\}\\\\\n&= e^{a B_s} \\mathbb{E}[e^{a (B_t - B_s)}]\\\\\n&= e^{a B_s} e^{\\frac{1}{2}a^2(t-s)}\n\\end{align*}\\]\nThis closes the proof. \\(\\blacksquare\\)\nAn equivalent (but more symmetric) way to express the Markov property is to say that the future of the process is independent of the past, when conditioned on the present. Concretely, this means that for any \\(r &lt; s&lt; t\\), we have that \\(X_t\\) is independent of \\(X_r\\), when we condition on \\(X_s\\).\nThe conditional distribution of \\(X_t\\) given \\(X_s\\) is well described using transition probabilities. We will more interested in a case well these probabilities admit a density \\(f_{X_t|X_s=x}(y)\\). More precisely, for such a Markov process, we have:\n\\[\n\\begin{align*}\n\\mathbb{E}[g(X_t)|X_s = x] &= \\int_{\\mathbb{R}} g(y) f_{X_t|X_s=x}(y) dy\\\\\n&=\\int_{\\mathbb{R}} g(y) p(y,t|x,s) dy\n\\end{align*}\n\\]\nHere, we explicitly write the left-hand side as a function of space, that is, the position \\(X_s\\), by fixing \\(X_s = x\\). In words, the transition probability density \\(p(y,t|x,s)\\) represents the probability density that starting from \\(X_s = x\\) at time \\(s\\), the process ends up at \\(X_t = y\\) at time \\(t &gt; s\\). If the process is time-homogenous, this only depends on the time difference \\((t-s)\\) and we write \\(p(y,t|x,s)\\). From Equation 1, we can write: \\[\n\\mathbb{E}[g(B_t)|B_s = x] = \\int_{\\mathbb{R}} g(u + x) \\frac{e^{-\\frac{u^2}{2(t-s)}}}{\\sqrt{2\\pi(t-s)}} du\n\\]\nIn the above expression, the random variable \\(B_t - B_s\\) takes some value \\(u \\in \\mathbb{R}\\) and \\(B_s = x\\) is fixed. Then, \\(B_t\\) takes the value \\(u + x\\). Let \\(y = u + x\\). Then, \\(u = y - x\\). Consequently, we may write:\n\\[\n\\mathbb{E}[g(B_t)|B_s = x] = \\int_{\\mathbb{R}} g(y) \\frac{e^{-\\frac{(y-x)^2}{2(t-s)}}}{\\sqrt{2\\pi(t-s)}} dy\n\\]\nSo, the transition density function for standard Brownian motion is:\n\\[\np(y,t|x,0)= \\frac{e^{-\\frac{(y-x)^2}{2s}}}{\\sqrt{2\\pi s}}, \\quad s&gt;0, x,y\\in\\mathbb{R}\n\\tag{4}\\]\nThis function is sometimes called the heat kernel, as it relates to the heat equation.\nThe Markov property is very convenient to compute quantities, as we shall see throughout the chapter. As a first example, we remark that it is easy to express joint probabilities of a markov process \\((X_t,t\\geq 0)\\) at different times. Consider the functions \\(f = \\mathbf{1}_A\\) and \\(g = \\mathbf{1}_B\\) from \\(\\mathbb{R} \\to \\mathbb{R}\\), where \\(A\\) and \\(B\\) are two intervals in \\(\\mathbb{R}\\). Let’s compute \\(\\mathbb{P}(X_{t_1} \\in A, X_{t_2} \\in B) = \\mathbb{E}[\\mathbf{1}_{A} \\mathbf{1}_{B}] = \\mathbb{E}[f(X_{t_1}) g(X_{t_2})]\\) for \\(t_1 &lt; t_2\\). By the properties of conditional expectation and the Markov property, we have:\n\\[\\begin{align*}\n\\mathbb{P}(X_{t_1} \\in A, X_{t_2} \\in B) &= \\mathbb{E}[f(X_{t_1})g(X_{t_2})]\\\\\n&= \\mathbb{E}[f(X_{t_1})\\mathbb{E}[g(X_{t_2})|\\mathcal{F}_{t_1}]]\\\\\n&= \\mathbb{E}[f(X_{t_1})\\mathbb{E}[g(X_{t_2})|X_{t_1}]]\n\\end{align*}\\]\nAssuming that the process is time-homogenous and admits a transition density \\(p(y,t|x,0)\\) as for Brownian motion, this becomes:\n\\[\\begin{align*}\n\\mathbb{P}(X_{t_1} \\in A, X_{t_2} \\in B) &= \\int_{\\mathbb{R}} f(x_1) \\left(\\int_{\\mathbb{R}} g(x_2) p(x_2,t_2|x_1,t_1) dx_2 \\right) p(x_1,t_1|x_0,0) dx_1\\\\\n&= \\int_{A} \\left(\\int_{B} p(x_2,t_2|x_1,t_1) dx_2 \\right) p(x_1,t_1|x_0,0) dx_1\n\\end{align*}\\]\nThis easily generalizes to any finite-dimensional distribution of \\((X_t, t\\geq 0)\\).\n\nExample 2 (Markov versus Martingale.) Martingales are not markov processes in general and markov processes are not martingales in general. There are processes such as brownian motion that enjoy both. An example of a markov process that is not a martingale is a Brownian motion with a drift \\((X_t, t \\geq 0)\\), where \\(X_t = \\sigma B_t + \\mu t\\). Conversely, take \\(Y_t = \\int_0^t X_s dB_s\\), where \\(X_s = \\int_0^s B_u dB_u\\). The integrand \\(X_s\\) depends on whole Brownian motion path upto time \\(s\\) and not just on \\(B_s\\).\n\n\n\n\n\n\n\nFunctions of Markov Processes\n\n\n\nIt might be tempting to think that if \\((X_t,t\\geq 0)\\) is a Markov process, then the process defined by \\(Y_t = f(X_t)\\) for some reasonable function \\(f\\) is also Markov. Indeed, one could hope to write for an arbitrary bounded function \\(g\\):\n\\[\n\\begin{align*}\n\\mathbb{E}[g(Y_t)|\\mathcal{F}_s] = \\mathbb{E}[g(f(X_t))|\\mathcal{F}_s] = \\mathbb{E}[g(f(X_t))|\\mathcal{X}_s]\n\\end{align*}\n\\tag{5}\\]\nby using the Markov property of \\((X_t,t\\geq 0)\\). The flaw in this reasoning is that the Markov property should hold for the natural fitration \\((\\mathcal{F}_t^Y,t\\geq 0)\\) of the process \\((Y_t,t\\geq 0)\\) and not the one of \\((X_t,t\\geq 0)\\), \\((\\mathcal{F}_t^X,t\\geq 0)\\). It might be that the filtration \\((\\mathcal{F}_t^Y,t\\geq 0)\\) has less information that \\((\\mathcal{F}_t^X,t\\geq 0)\\), especially, if the function \\(f\\) is not one-to-one. For example, if \\(f(x)=x^2\\), then \\(\\mathcal{F}_t^Y\\) has less information than \\(\\mathcal{F}_t^X\\) as we cannot recover the sign of \\(X_t\\) knowing \\(Y_t\\). In other words, the second equality may not hold. In some cases, a function of a Brownian motion might be Markov, even when \\(f\\) is not one-to-one.\n\n\nIt turns out that diffusions such as the Ornstein-Uhlenbeck process and the Brownian bridge are Markov processes.\n\nTheorem 1 (Diffusions are Markov processes.) Let \\((B_t,t\\geq 0)\\) be a standard Brownian motion. Let \\(\\mu : \\mathbb{R} \\to \\mathbb{R}\\) and \\(\\sigma: \\mathbb{R} \\to \\mathbb{R}\\) be differentiable functions with bounded derivatives on \\([0,T]\\). Then, the diffusion with the SDE\n\\[\ndX_t = \\mu(X_t) dt + \\sigma(X_t)dB_t, \\quad X_0 = x_0\n\\]\ndefines a time-homogenous markov process on \\([0,T]\\).\n\nAn analogous statement holds for time-inhomogenous diffusions. The proof is generalization of the Markov property of Brownian motion. We take advantage of the independence of Brownian increments.\nProof.\nBy the existence and uniqueness theorem, this stochastic initial value problem(SIVP) defines a unique continous adapted process \\((X_t,t\\leq T)\\). Let \\((\\mathcal{F}_t^X,t\\geq 0)\\) be the natural filtration of \\((X_t,t\\leq T)\\). For a fixed \\(t &gt; 0\\), consider the process \\(W_s = B_{t+s} - B_t, s \\geq 0\\). Let \\((\\mathcal{F}_t,t \\geq 0)\\) be the natural filtration of \\((B_t,t \\geq 0)\\). It turns out that the process \\((W_s,s \\geq 0)\\) is a standard brownian motion independent of \\(\\mathcal{F}_t\\) (Exercise 1). For \\(s \\geq 0\\), we consider the SDE:\n\\[\ndY_s = \\mu (Y_s) ds + \\sigma(Y_s) dW_s, \\quad Y_0 = X_t\n\\]\nAgain by the existence and uniqueness theorem, there exists a unique solution to the SIVP that is adapted to the natural filtration of \\(W\\). Note that, the shifted process \\((X_{t+s},s\\geq 0)\\) is the solution to this SIVP since:\n\\[\\begin{align*}\nX_{t+s} &= X_{t} + \\int_{t}^{t+s}\\mu(X_u) du + \\int_{t}^{t+s}\\sigma(X_u) dB_u\n\\end{align*}\\]\nPerform a change of variable \\(v = u - t\\). Then, \\(dv = du\\), \\(dB_u = B(u_2) - B(u_1)= B(t + v_2) - B(t + v_1) = W(v_2) - W(v_1) = dW_v\\). So,\n\\[\\begin{align*}\nX_{t+s} &= X_{t} + \\int_{0}^{s}\\mu(X_{t+v}) dv + \\int_{0}^{s}\\sigma(X_{t+v}) dW_v\n\\end{align*}\\]\nLet \\(Y_v= X_{t+v}\\), \\(Y_0 = X_t\\). Then,\n\\[\\begin{align*}\nY_s &= Y_0 + \\int_{0}^{s}\\mu(Y_v) dv + \\int_{0}^{s}\\sigma(Y_v) dW_v\n\\end{align*}\\]\nThus, we conclude that for any interval \\(A\\):\n\\[\n\\mathbb{P}(X_{t+s} \\in A|\\mathcal{F}_t^X) = \\mathbb{P}(Y_s \\in A | \\mathcal{F}_t^X)\n\\]\nBut, since \\((Y_s,s \\geq 0)\\) depends on \\(\\mathcal{F}_t^X\\) only through \\(X_t\\) (because \\((W_s,s \\geq 0)\\) is independent of \\(\\mathcal{F}_t\\)), we conclude that \\(\\mathbb{P}(X_{t+s} \\in A|\\mathcal{F}_t^X) = \\mathbb{P}(X_{t+s} \\in A|X_t)\\), so \\((X_t,t \\geq 0)\\) is a time-homogenous markov process. \\(\\blacksquare\\)"
  },
  {
    "objectID": "posts/the_markov_property/index.html#the-markov-property-for-diffusions",
    "href": "posts/the_markov_property/index.html#the-markov-property-for-diffusions",
    "title": "The Markov Property",
    "section": "",
    "text": "Let’s start by exhibiting the Markov property of Brownian motion. To see this, consider \\((\\mathcal{F}_t,t\\geq 0)\\), the natural filtration of the Brownian motion \\((B_t,t\\geq 0)\\). Consider \\(g(B_t)\\) for some time \\(t\\) and bounded function \\(g\\). (For example, \\(g\\) could be an indicator function.) Consider also a random variable \\(W\\) that is \\(\\mathcal{F}_s\\) measurable for \\(s &lt; t\\). (For example, \\(W\\) could be \\(B_s\\) or \\(1_{B_s &gt; 0}\\).) Let’s compute \\(\\mathbb{E}[g(B_t)W]\\).\n\n%load_ext itikz\n\n\\[\\begin{align*}\n\\mathbb{E}[g(B_t)W] &= \\mathbb{E}[\\mathbb{E}[Wg(B_t - B_s + B_s)|\\mathcal{F}_s]]\n\\end{align*}\\]\nThe random variable \\((B_t - B_s)\\) follows a \\(\\mathcal{N}(0,t-s)\\) distribution. By LOTUS,\n\\[\n\\begin{align*}\n\\mathbb{E}[g(B_t)W]\n&= \\int_{\\mathbb{R}} \\mathbb{E}[W g(y + B_s)|\\mathcal{F_s}]f_{(B_t - B_s)|B_s}(y) dy\\\\\n&= \\{\\text{ Using the fact that }B_t - B_s \\perp B_s\\}\\\\\n&= \\int_{\\mathbb{R}} \\mathbb{E}[W g(y + B_s)]f_{(B_t - B_s)}(y)dy\\\\\n&= \\int_{\\mathbb{R}} \\mathbb{E}[W g(y + B_s)]\\frac{e^{-\\frac{y^2}{2(t-s)}}}{\\sqrt{2\\pi(t-s)}}dy\n\\end{align*}\n\\]\nBy Fubini’s theorem, the integral and the expectation operator can be interchanged, and since \\(W\\) is \\(\\mathcal{F}_s\\) measurable, it follows from the definition of conditional expectations that:\n\\[\n\\begin{align*}\n\\mathbb{E}[Wg(B_t)] = \\mathbb{E}[W\\mathbb{E}[g(B_t)|\\mathcal{F}_s]] = \\mathbb{E}\\left[W\\int_{\\mathbb{R}}g(y + B_s)]\\frac{e^{-\\frac{y^2}{2(t-s)}}}{\\sqrt{2\\pi(t-s)}}dy\\right]\n\\end{align*}\n\\]\nIt follows that:\n\\[\n\\begin{align*}\n\\mathbb{E}[g(B_t)|\\mathcal{F}_s] = \\int_{\\mathbb{R}}g(y + B_s)]\\frac{e^{-\\frac{y^2}{2(t-s)}}}{\\sqrt{2\\pi(t-s)}}dy\n\\end{align*}\n\\tag{1}\\]\nWe make two important observations. First, the right hand side is a function of \\(s,t\\) and \\(B_s\\) only (and not of the Brownian motion before time s). In particular, we have:\n\\[\n\\mathbb{E}[g(B_t)|\\mathcal{F}_s] = \\mathbb{E}[g(B_t)|B_s]\n\\]\nThis holds for any bounded function \\(g\\). In particular, it holds for all indicator functions. This implies that the conditional distribution of \\(B_t\\) given \\(\\mathcal{F}_s\\) depends solely on \\(B_s\\), and not on other values before time \\(s\\). Second, the right-hand side is time-homogenous in the sense that it depends on the time difference \\(t-s\\).\nWe have just shown that Brownian motion is a time-homogenous Markov process.\n\nDefinition 1 (Markov process.) Consider a stochastic process \\((X_t,t\\geq 0)\\) and its natural filtration \\((\\mathcal{F}_t,t\\geq 0)\\). It is said to be a Markov process if and only if for any (bounded) function \\(g: \\mathbb{R} \\to \\mathbb{R}\\), we have:\n\\[\n\\mathbb{E}[g(X_t) | \\mathcal{F}_s] = \\mathbb{E}[g(X_t) | X_s], \\quad \\forall t \\geq 0, \\forall s \\leq t\n\\tag{2}\\]\n\nThis implies that \\(\\mathbb{E}[g(X_t)|\\mathcal{F}_s]\\) is an explicit function of \\(s\\), \\(t\\) and \\(X_s\\). It is said to be time-homogenous, if it is a function of \\(t-s\\) and \\(X_s\\). Since the above holds for all bounded \\(g\\), the conditional distribution of \\(X_t\\) given \\(\\mathcal{F}_s\\) is the same as the conditional distribution of \\(X_t\\) given \\(X_s\\).\nOne way to compute the conditional distribution of \\(X_t\\) given \\(\\mathcal{F}_s\\) is to compute the conditional MGF given \\(\\mathcal{F}_s\\), that is:\n\\[\n\\mathbb{E}[e^{a X_t}|\\mathcal{F}_s], \\quad a \\geq 0\n\\tag{3}\\]\nThe process would be Markov, if the conditional MGF is an explicit function of \\(s\\), \\(t\\) and \\(X_s\\).\n\nExample 1 (Brownian Motion is Markov) Let \\((B_t,t\\geq 0)\\) be a standard brownian motion. Our claim is that the brownian motion is a markov process.\n\nProof.\nWe have:\n\\[\\begin{align*}\n\\mathbb{E}[e^{a B_t}|\\mathcal{F}_s] &= \\mathbb{E}[e^{a (B_t - B_s + B_s)}|\\mathcal{F}_s]\\\\\n& \\{ \\text{ since }B_s \\text{ is }\\mathcal{F}_s-\\text{ measurable }\\}\\\\\n&= e^{a B_s} \\mathbb{E}[e^{a (B_t - B_s)}|\\mathcal{F}_s]\\\\\n& \\{ \\text{ since }B_t - B_s \\perp \\mathcal{F}_s \\}\\\\\n&= e^{a B_s} \\mathbb{E}[e^{a (B_t - B_s)}]\\\\\n&= e^{a B_s} e^{\\frac{1}{2}a^2(t-s)}\n\\end{align*}\\]\nThis closes the proof. \\(\\blacksquare\\)\nAn equivalent (but more symmetric) way to express the Markov property is to say that the future of the process is independent of the past, when conditioned on the present. Concretely, this means that for any \\(r &lt; s&lt; t\\), we have that \\(X_t\\) is independent of \\(X_r\\), when we condition on \\(X_s\\).\nThe conditional distribution of \\(X_t\\) given \\(X_s\\) is well described using transition probabilities. We will more interested in a case well these probabilities admit a density \\(f_{X_t|X_s=x}(y)\\). More precisely, for such a Markov process, we have:\n\\[\n\\begin{align*}\n\\mathbb{E}[g(X_t)|X_s = x] &= \\int_{\\mathbb{R}} g(y) f_{X_t|X_s=x}(y) dy\\\\\n&=\\int_{\\mathbb{R}} g(y) p(y,t|x,s) dy\n\\end{align*}\n\\]\nHere, we explicitly write the left-hand side as a function of space, that is, the position \\(X_s\\), by fixing \\(X_s = x\\). In words, the transition probability density \\(p(y,t|x,s)\\) represents the probability density that starting from \\(X_s = x\\) at time \\(s\\), the process ends up at \\(X_t = y\\) at time \\(t &gt; s\\). If the process is time-homogenous, this only depends on the time difference \\((t-s)\\) and we write \\(p(y,t|x,s)\\). From Equation 1, we can write: \\[\n\\mathbb{E}[g(B_t)|B_s = x] = \\int_{\\mathbb{R}} g(u + x) \\frac{e^{-\\frac{u^2}{2(t-s)}}}{\\sqrt{2\\pi(t-s)}} du\n\\]\nIn the above expression, the random variable \\(B_t - B_s\\) takes some value \\(u \\in \\mathbb{R}\\) and \\(B_s = x\\) is fixed. Then, \\(B_t\\) takes the value \\(u + x\\). Let \\(y = u + x\\). Then, \\(u = y - x\\). Consequently, we may write:\n\\[\n\\mathbb{E}[g(B_t)|B_s = x] = \\int_{\\mathbb{R}} g(y) \\frac{e^{-\\frac{(y-x)^2}{2(t-s)}}}{\\sqrt{2\\pi(t-s)}} dy\n\\]\nSo, the transition density function for standard Brownian motion is:\n\\[\np(y,t|x,0)= \\frac{e^{-\\frac{(y-x)^2}{2s}}}{\\sqrt{2\\pi s}}, \\quad s&gt;0, x,y\\in\\mathbb{R}\n\\tag{4}\\]\nThis function is sometimes called the heat kernel, as it relates to the heat equation.\nThe Markov property is very convenient to compute quantities, as we shall see throughout the chapter. As a first example, we remark that it is easy to express joint probabilities of a markov process \\((X_t,t\\geq 0)\\) at different times. Consider the functions \\(f = \\mathbf{1}_A\\) and \\(g = \\mathbf{1}_B\\) from \\(\\mathbb{R} \\to \\mathbb{R}\\), where \\(A\\) and \\(B\\) are two intervals in \\(\\mathbb{R}\\). Let’s compute \\(\\mathbb{P}(X_{t_1} \\in A, X_{t_2} \\in B) = \\mathbb{E}[\\mathbf{1}_{A} \\mathbf{1}_{B}] = \\mathbb{E}[f(X_{t_1}) g(X_{t_2})]\\) for \\(t_1 &lt; t_2\\). By the properties of conditional expectation and the Markov property, we have:\n\\[\\begin{align*}\n\\mathbb{P}(X_{t_1} \\in A, X_{t_2} \\in B) &= \\mathbb{E}[f(X_{t_1})g(X_{t_2})]\\\\\n&= \\mathbb{E}[f(X_{t_1})\\mathbb{E}[g(X_{t_2})|\\mathcal{F}_{t_1}]]\\\\\n&= \\mathbb{E}[f(X_{t_1})\\mathbb{E}[g(X_{t_2})|X_{t_1}]]\n\\end{align*}\\]\nAssuming that the process is time-homogenous and admits a transition density \\(p(y,t|x,0)\\) as for Brownian motion, this becomes:\n\\[\\begin{align*}\n\\mathbb{P}(X_{t_1} \\in A, X_{t_2} \\in B) &= \\int_{\\mathbb{R}} f(x_1) \\left(\\int_{\\mathbb{R}} g(x_2) p(x_2,t_2|x_1,t_1) dx_2 \\right) p(x_1,t_1|x_0,0) dx_1\\\\\n&= \\int_{A} \\left(\\int_{B} p(x_2,t_2|x_1,t_1) dx_2 \\right) p(x_1,t_1|x_0,0) dx_1\n\\end{align*}\\]\nThis easily generalizes to any finite-dimensional distribution of \\((X_t, t\\geq 0)\\).\n\nExample 2 (Markov versus Martingale.) Martingales are not markov processes in general and markov processes are not martingales in general. There are processes such as brownian motion that enjoy both. An example of a markov process that is not a martingale is a Brownian motion with a drift \\((X_t, t \\geq 0)\\), where \\(X_t = \\sigma B_t + \\mu t\\). Conversely, take \\(Y_t = \\int_0^t X_s dB_s\\), where \\(X_s = \\int_0^s B_u dB_u\\). The integrand \\(X_s\\) depends on whole Brownian motion path upto time \\(s\\) and not just on \\(B_s\\).\n\n\n\n\n\n\n\nFunctions of Markov Processes\n\n\n\nIt might be tempting to think that if \\((X_t,t\\geq 0)\\) is a Markov process, then the process defined by \\(Y_t = f(X_t)\\) for some reasonable function \\(f\\) is also Markov. Indeed, one could hope to write for an arbitrary bounded function \\(g\\):\n\\[\n\\begin{align*}\n\\mathbb{E}[g(Y_t)|\\mathcal{F}_s] = \\mathbb{E}[g(f(X_t))|\\mathcal{F}_s] = \\mathbb{E}[g(f(X_t))|\\mathcal{X}_s]\n\\end{align*}\n\\tag{5}\\]\nby using the Markov property of \\((X_t,t\\geq 0)\\). The flaw in this reasoning is that the Markov property should hold for the natural fitration \\((\\mathcal{F}_t^Y,t\\geq 0)\\) of the process \\((Y_t,t\\geq 0)\\) and not the one of \\((X_t,t\\geq 0)\\), \\((\\mathcal{F}_t^X,t\\geq 0)\\). It might be that the filtration \\((\\mathcal{F}_t^Y,t\\geq 0)\\) has less information that \\((\\mathcal{F}_t^X,t\\geq 0)\\), especially, if the function \\(f\\) is not one-to-one. For example, if \\(f(x)=x^2\\), then \\(\\mathcal{F}_t^Y\\) has less information than \\(\\mathcal{F}_t^X\\) as we cannot recover the sign of \\(X_t\\) knowing \\(Y_t\\). In other words, the second equality may not hold. In some cases, a function of a Brownian motion might be Markov, even when \\(f\\) is not one-to-one.\n\n\nIt turns out that diffusions such as the Ornstein-Uhlenbeck process and the Brownian bridge are Markov processes.\n\nTheorem 1 (Diffusions are Markov processes.) Let \\((B_t,t\\geq 0)\\) be a standard Brownian motion. Let \\(\\mu : \\mathbb{R} \\to \\mathbb{R}\\) and \\(\\sigma: \\mathbb{R} \\to \\mathbb{R}\\) be differentiable functions with bounded derivatives on \\([0,T]\\). Then, the diffusion with the SDE\n\\[\ndX_t = \\mu(X_t) dt + \\sigma(X_t)dB_t, \\quad X_0 = x_0\n\\]\ndefines a time-homogenous markov process on \\([0,T]\\).\n\nAn analogous statement holds for time-inhomogenous diffusions. The proof is generalization of the Markov property of Brownian motion. We take advantage of the independence of Brownian increments.\nProof.\nBy the existence and uniqueness theorem, this stochastic initial value problem(SIVP) defines a unique continous adapted process \\((X_t,t\\leq T)\\). Let \\((\\mathcal{F}_t^X,t\\geq 0)\\) be the natural filtration of \\((X_t,t\\leq T)\\). For a fixed \\(t &gt; 0\\), consider the process \\(W_s = B_{t+s} - B_t, s \\geq 0\\). Let \\((\\mathcal{F}_t,t \\geq 0)\\) be the natural filtration of \\((B_t,t \\geq 0)\\). It turns out that the process \\((W_s,s \\geq 0)\\) is a standard brownian motion independent of \\(\\mathcal{F}_t\\) (Exercise 1). For \\(s \\geq 0\\), we consider the SDE:\n\\[\ndY_s = \\mu (Y_s) ds + \\sigma(Y_s) dW_s, \\quad Y_0 = X_t\n\\]\nAgain by the existence and uniqueness theorem, there exists a unique solution to the SIVP that is adapted to the natural filtration of \\(W\\). Note that, the shifted process \\((X_{t+s},s\\geq 0)\\) is the solution to this SIVP since:\n\\[\\begin{align*}\nX_{t+s} &= X_{t} + \\int_{t}^{t+s}\\mu(X_u) du + \\int_{t}^{t+s}\\sigma(X_u) dB_u\n\\end{align*}\\]\nPerform a change of variable \\(v = u - t\\). Then, \\(dv = du\\), \\(dB_u = B(u_2) - B(u_1)= B(t + v_2) - B(t + v_1) = W(v_2) - W(v_1) = dW_v\\). So,\n\\[\\begin{align*}\nX_{t+s} &= X_{t} + \\int_{0}^{s}\\mu(X_{t+v}) dv + \\int_{0}^{s}\\sigma(X_{t+v}) dW_v\n\\end{align*}\\]\nLet \\(Y_v= X_{t+v}\\), \\(Y_0 = X_t\\). Then,\n\\[\\begin{align*}\nY_s &= Y_0 + \\int_{0}^{s}\\mu(Y_v) dv + \\int_{0}^{s}\\sigma(Y_v) dW_v\n\\end{align*}\\]\nThus, we conclude that for any interval \\(A\\):\n\\[\n\\mathbb{P}(X_{t+s} \\in A|\\mathcal{F}_t^X) = \\mathbb{P}(Y_s \\in A | \\mathcal{F}_t^X)\n\\]\nBut, since \\((Y_s,s \\geq 0)\\) depends on \\(\\mathcal{F}_t^X\\) only through \\(X_t\\) (because \\((W_s,s \\geq 0)\\) is independent of \\(\\mathcal{F}_t\\)), we conclude that \\(\\mathbb{P}(X_{t+s} \\in A|\\mathcal{F}_t^X) = \\mathbb{P}(X_{t+s} \\in A|X_t)\\), so \\((X_t,t \\geq 0)\\) is a time-homogenous markov process. \\(\\blacksquare\\)"
  },
  {
    "objectID": "posts/the_markov_property/index.html#the-strong-markov-property",
    "href": "posts/the_markov_property/index.html#the-strong-markov-property",
    "title": "The Markov Property",
    "section": "The Strong Markov Property",
    "text": "The Strong Markov Property\nThe Doob’s Optional Stopping theorem extended some properties of martingales to stopping times. The Markov property can also be extended to stopping times for certain processes. These processes are called strong Markov processes.\nWe know, that the sigma-algebra \\(\\mathcal{F}_t\\) represents the set of all observable events upto time \\(t\\). What is the sigma-algebra of observable events at a random stopping time \\(\\tau\\)?\n\nDefinition 2 (\\(\\sigma\\)-algebra of \\(\\tau\\)-past) Let \\((\\Omega,\\mathcal{F},\\{\\mathcal{F}_t\\}_{t\\geq 0},\\mathbb{P})\\) be a filtered probability space. The sigma-algebra at the stopping time \\(\\tau\\) is then:\n\\[\n\\mathcal{F}_{\\tau} = \\{A \\in \\mathcal{F}_\\infty : A \\cap \\{\\tau \\leq t\\} \\in \\mathcal{F}_t, \\forall t \\geq 0 \\}\n\\tag{6}\\]\n\nIn words, an event \\(A\\) is in \\(\\mathcal{F}_\\tau\\), if we can determine if \\(A\\) and \\(\\{\\tau \\leq t\\}\\) both occurred or not based on the information \\(\\mathcal{F}_t\\) known at any arbitrary time \\(t\\). You should be able to tell the value of the random variable \\(\\mathbf{1}_A \\cdot \\mathbf{1}_{\\{\\tau \\leq t\\}}\\) given \\(\\mathcal{F}_t\\) for any arbitrary time \\(t \\geq 0\\).\nFor example, if \\(\\tau &lt; \\infty\\), the event \\(\\{B_\\tau &gt; 0\\}\\) is in \\(\\mathcal{F}_\\tau\\). However, the event \\(\\{B_1 &gt; 0\\}\\) is not in \\(\\mathcal{F}_\\tau\\) in general, since \\(A \\cap \\{\\tau \\leq t\\}\\) is not in \\(\\mathcal{F}_t\\) for \\(t &lt; 1\\). Roughly speaking, a random variable that is \\(\\mathcal{F}_\\tau\\)-measurable should be thought of as an explicit function of \\(X_\\tau\\). With this new object, we are ready to define the strong markov property.\n\nDefinition 3 (Strong Markov Property) Let \\((X_t,t\\geq 0)\\) be a stochastic process and let \\((\\mathcal{F}_t,t\\geq 0)\\) be its natural filtration. The process \\((X_t,t\\geq 0)\\) is said to be strong markov if for any stopping time \\(\\tau\\) for the filtration of the process and any bounded function \\(g\\):\n\\[\n\\mathbb{E}[g(X_{t+\\tau})|\\mathcal{F}_\\tau] = \\mathbb{E}[g(X_{t+\\tau})|X_\\tau]\n\\]\n\nThis means that \\(X_{t+\\tau}\\) depends on \\(\\mathcal{F}_\\tau\\) solely through \\(X_\\tau\\) (whenever \\(\\tau &lt; \\infty\\)). It turns out that Brownian motion is a strong markov process. In fact a stronger statement holds which generalizes Exercise 1.\n\nTheorem 2 Let \\(\\tau\\) be a stopping time for the filtration of the Brownian motion \\((B_t,t\\geq 0)\\) such that \\(\\tau &lt; \\infty\\). Then, the process:\n\\[\n(B_{t+\\tau} - B_{\\tau},t\\geq 0)\n\\]\nis a standard brownian motion independent of \\(\\mathcal{F}_\\tau\\).\n\n\nExample 3 (Brownian motion is strong Markov) To see this, let’s compute the conditional MGF as in Equation 3. We have:\n\\[\n\\begin{align*}\n\\mathbb{E}[e^{aB_{t+\\tau}}|\\mathcal{F}_\\tau] &= \\mathbb{E}[e^{a(B_{t+\\tau} - B_\\tau + B_\\tau)}|\\mathcal{F}_\\tau]\\\\\n&= e^{aB_\\tau} \\mathbb{E}[e^{a(B_{t+\\tau} - B_\\tau)}|\\mathcal{F}_\\tau]\\\\\n& \\{ B_\\tau \\text{ is }\\mathcal{F}_\\tau-\\text{measurable }\\}\\\\\n&= e^{aB_\\tau}\\mathbb{E}[e^{a(B_{t+\\tau} - B_\\tau)}]\\\\\n& \\{ (B_{t+\\tau} - B_\\tau) \\perp \\mathcal{F}_\\tau\\}\\\\\n&= e^{aB_\\tau}e^{\\frac{1}{2}a^2 t}\\\\\n\\end{align*}\n\\]\nThus, the conditional MGF is an explicit function of \\(B_\\tau\\) and \\(t\\). This proves the proposition. \\(\\blacksquare\\)\n\nProof of Theorem 2.\nWe first consider for fixed \\(n\\) the discrete valued stopping time:\n\\[\n\\tau_n = \\frac{k + 1}{2^n}, \\quad \\text{ if } \\frac{k}{2^n} \\leq \\tau &lt; \\frac{k+1}{2^n}, k\\in \\mathbb{N}\n\\]\nIn other words, if \\(\\tau\\) occurs in the interval \\([\\frac{k}{2^n},\\frac{k+1}{2^n})\\), we stop at the next dyadic \\(\\frac{k+1}{2^n}\\). By construction \\(\\tau_n\\) depends only on the process in the past. Consider the process \\(W_t = B_{t + \\tau_n} - B_{\\tau_n}, t \\geq 0\\). We show it is a standard brownian motion independent of \\(\\tau_n\\). This is feasible as we can decompose over the discrete values taken by \\(\\tau_n\\). More, precisely, take \\(E \\in \\mathcal{F}_{\\tau_n}\\), and some generic event \\(\\{W_t \\in A\\}\\) for the process \\(W\\). Then, by decomposing over the values of \\(\\tau_n\\), we have:\n\\[\n\\begin{align*}\n\\mathbb{P}(\\{W_t \\in A\\} \\cap E) &= \\sum_{k=0}^\\infty \\mathbb{P}\\left(\\{W_t \\in A\\} \\cap E \\cap \\{\\tau_n = \\frac{k}{2^n}\\}\\right)\\\\\n&= \\sum_{k=0}^\\infty \\mathbb{P}\\left(\\{(B_{t+k/2^n} - B_{k/2^n}) \\in A\\} \\cap E \\cap \\{\\tau_n = \\frac{k}{2^n}\\}\\right)\\\\\n&= \\sum_{k=0}^\\infty \\mathbb{P}\\left(\\{(B_{t+k/2^n} - B_{k/2^n}) \\in A\\}\\right) \\times \\mathbb{P}\\left( E \\cap \\{\\tau_n = \\frac{k}{2^n}\\}\\right)\n\\end{align*}\n\\]\nsince \\((B_{t+k/2^n} - B_{k/2^n})\\) is independent of \\(\\mathcal{F}_{k/2^n}\\) by Exercise 1 and since \\(E \\cap \\{\\tau_n = \\frac{k}{2^n}\\} \\in \\mathcal{F}_{k/2^n}\\) by definition of stopping time. But, given \\(\\{\\tau_n = k/2^n\\}\\), the event \\(\\{(B_{t+k/2^n} - B_{k/2^n}) \\in A\\}\\) is the same as \\(\\{B_t \\in A\\} = \\{W_t \\in A\\}\\), since this process is now a standard brownian motion. Thus, \\(\\mathbb{P}\\{(B_{t+k/2^n} - B_{k/2^n}) \\in A\\} = \\mathbb{P}\\{B_t \\in A\\} = \\mathbb{P}\\{W_t \\in A\\}\\), dropping the dependence on \\(k\\). The sum over \\(k\\) then yields:\n\\[\n\\mathbb{P}\\left(\\{W_t \\in A\\}\\cap E\\right) = \\mathbb{P}(W_t \\in A) \\mathbb{P}(E)\n\\]\nas claimed. The extension to \\(\\tau\\) is done by using continuity of paths. We have:\n\\[\n\\lim_{n \\to \\infty} B_{t + \\tau_n} - B_{\\tau_n} = B_{t+\\tau} - B_{\\tau} \\text{ almost surely}\n\\]\nNote, that this only uses right continuity! Moreover, this implies that \\(B_{t+\\tau} - B_\\tau\\) is independent of \\(\\mathcal{F}_{\\tau_n}\\) for all \\(n\\). Again by (right-)continuity this extends to independence of \\(\\mathcal{F}_\\tau\\). The limiting distribution of the process is obtained by looking at the finite dimensional distributions of the increments of \\(B_{t+\\tau_n} - B_{\\tau_n}\\) for a finite number of \\(t\\)’s and taking the limit as above. \\(\\blacksquare\\)\nMost diffusions also enjoy the strong markov property, as long as the functions \\(\\sigma\\) and \\(\\mu\\) encoding the volatility and drift are nice enough. This is the case for the diffusions we have considered.\n\nTheorem 3 (Most diffusions are strong markov) Consider a diffusion \\((X_t,t\\leq T)\\) as as in Theorem 1. Then, the diffusion has strong markov property.\n\nThe proof follows the line of the one of Theorem 1\nProof.\nConsider the time-homogenous diffusion:\n\\[\ndX_t = \\mu(X_t)dt + \\sigma(X_t)dB_t\n\\]\nBy the existence and uniqueness theorem, this SIVP defines a unique continuous adapted process \\((X_t,t \\geq 0)\\). Let \\(\\mathfrak{F}=(\\mathcal{F}_t^X,t \\geq 0)\\) be the natural filtration of \\((X_t, t\\leq T)\\). Let \\(\\tau\\) be a stopping time for the filtration \\(\\mathfrak{F}\\) and consider the process \\(W_t = B_{t+\\tau} - B_\\tau\\). From Theorem 2, we know that the process \\((W_t,t\\geq 0)\\) is a standard brownian motion independent \\(\\mathcal{F}_\\tau\\). For \\(s \\geq 0\\), we consider the SDE:\n\\[\ndY_s = \\mu(Y_s)ds + \\sigma(Y_s)dW_s, \\quad Y_0 = X_\\tau\n\\tag{7}\\]\nAgain by the existence and uniqueness theorem, there exists a unique solution to the SIVP that is adapted to the natural filtration of \\(W\\). We claim that \\((X_{s+\\tau},s \\geq 0)\\) is the solution to this equation, since:\n\\[\nX_{s+\\tau} = X_\\tau + \\int_\\tau^{s+\\tau} \\mu(X_u)du + \\int_{\\tau}^{s+\\tau} \\sigma(X_u)dB_u\n\\]\nPerform a change of variable \\(v = u - \\tau\\). Then, the limits of integration bare, \\(v = 0\\) and \\(v = s\\). And \\(dv = du\\).\n\\(dB_u \\approx B_{u_2} - B_{u_1} = B(v_1 + \\tau) - B(v_2 + \\tau) = W(v_2) - W(v_1) =dW_v\\).\n\\[\nX_{s+\\tau} = X_\\tau + \\int_0^{s} \\mu(X_{v+\\tau})dv + \\int_{0}^{s} \\sigma(X_{v+\\tau})dW_v\n\\]\nIf we let \\(Y_0 = X_\\tau\\), \\(Y_v = X_{v+\\tau}\\), we recover the dynamics of \\((Y_v,v \\geq 0)\\) in Equation 8. So, \\((X_{s+\\tau},s\\geq 0)\\) is the solution to the SIVP in Equation 8. Thus, we conclude for any interval \\(A\\):\n\\[\n\\mathbb{P}(X_{s+\\tau} \\in A | \\mathcal{F}_\\tau^X) = \\mathbb{P}(Y_v \\in A| \\mathcal{F}_\\tau^X)\n\\]\nBut, since \\((Y_v,v\\geq 0)\\) depends on \\(\\mathcal{F}_\\tau^X\\) only through \\(X_\\tau\\), we conclude that \\(\\mathbb{P}(X_{s + \\tau} \\in A | \\mathcal{F}_\\tau^X) = \\mathbb{P}(X_{s + \\tau} \\in A| X_\\tau)\\). Consequently, \\((X_t,t \\geq 0)\\) is a strong-markov process. \\(\\blacksquare\\)\n\n\n\n\n\n\nExtension of optional sampling\n\n\n\nConsider a continuous martingale \\((M_t, t\\leq T)\\) for a filtration \\((\\mathcal{F}_t, t\\geq 0)\\) and a stopping time \\(\\tau\\) for the same filtration. Suppose we would like to compute for some \\(T\\):\n\\[\n\\mathbb{E}[M_T \\mathbf{1}_{\\{\\tau \\leq T\\}}]\n\\]\nIt would be tempting to condition on \\(\\mathcal{F}_\\tau\\) and write \\(\\mathbb{E}[M_T |\\mathcal{F}_\\tau] = M_\\tau\\) on the event \\(\\{\\tau \\leq T\\}\\). We would then conclude that:\n\\[\n\\mathbb{E}[M_T 1_{\\{\\tau \\leq T\\}}] = \\mathbb{E}[1_{\\{\\tau \\leq T\\}} \\mathbb{E}[M_T|\\mathcal{F}_\\tau] ] = \\mathbb{E}[M_\\tau 1_{\\{\\tau \\leq T\\}}]\n\\]\nIn some sense, we have extended the martingale property to stopping times. This property can be proved under reasonable assumptions on \\((M_t,t\\leq T)\\) (for example, if it is positive). Indeed, it suffices to approximate \\(\\tau\\) by discrete valued stopping time \\(\\tau_n\\) as in the proof of Theorem 2. One can then apply martingale property at a fixed time."
  },
  {
    "objectID": "posts/the_markov_property/index.html#the-heat-equation",
    "href": "posts/the_markov_property/index.html#the-heat-equation",
    "title": "The Markov Property",
    "section": "The Heat Equation",
    "text": "The Heat Equation\nWe look at more detail on how PDEs come up when computing quantities related to Markov processes.\nConsider a homogenous rod of length \\(L\\) lying along the interval \\([0,L]\\) on the \\(x\\)-axis. We focus on a little segment of this rod \\([x,x+\\Delta x]\\). Suppose the temperature measurement of this little segment at time \\(t\\) is \\(u(x,t)\\) degrees. In general, the temperature \\(u\\) of the rod varies with space \\(x\\) and time \\(t\\).\nThe heat energy content in this little segment at time \\(t\\) is : \\[E(x,x+\\Delta x, t) \\approx s \\cdot u(x,t) \\cdot (\\rho \\Delta x)\\]\nwhere \\(s\\) is the specific heat constant, \\(\\rho\\) is the mass density \\(\\text{kg}\\cdot m^{-1}\\).\n’s law of heat conduction quantifies the idea that heat flows from warmer to colder regions and states that the (rightward) heat flux density (the flow of heat energy per unit area per unit time, SI units \\(Js^{-1}m^{-2}\\) at any point is:\n\\[\\phi(x,t) = -K_0 u_x(x,t)\\]\nwhere \\(K_0\\) is the thermal conductivity of the rode. The negative sign shows that the heat flows from higher temperature regions to colder temperature regions.\nAppealing to the law of conservation of energy:\n\\[\\underbrace{\\frac{\\partial}{\\partial t}(u(x,t) \\cdot s \\cdot (\\rho \\Delta x))}_{\\text{Heat flux through segment}} = \\underbrace{(-K_0u_x(x,t))}_{\\text{Flux in}} - \\underbrace{(-K_0u_x(x+\\Delta x, t))}_{\\text{Flux out}}\\]\nDividing throughout by \\(\\Delta x\\), we have:\n\\[\\frac{\\partial u}{\\partial t} = \\frac{K_0}{s\\rho}\\frac{u_x(x+\\Delta x,t) - u_x(x,t)}{\\Delta x}\\]\nLetting \\(\\Delta x \\to 0\\), we get:\n\\[\n\\begin{aligned}\n\\boxed{\\frac{\\partial u}{\\partial t} = c^2\\frac{\\partial^2 u}{\\partial x^2}}\n\\end{aligned}\n\\tag{8}\\]\nwhere \\(c^2 = \\frac{K_0}{s\\rho}\\) is called the ."
  },
  {
    "objectID": "posts/the_markov_property/index.html#deriving-the-diffusion-equation-using-the-einsteins-approach",
    "href": "posts/the_markov_property/index.html#deriving-the-diffusion-equation-using-the-einsteins-approach",
    "title": "The Markov Property",
    "section": "Deriving the diffusion equation using the Einstein’s approach",
    "text": "Deriving the diffusion equation using the Einstein’s approach\nWe now summarize Einstein’s original 1905 argument. Let’s say that we are interested in the motion along the horizontal \\(x\\)-axis. Let’s say we drop brownian particles in a liquid. Let \\(f(t,x)\\) represent the number of particles per unit volume (density) at position \\(x\\) at time \\(t\\). So, the number of particles in a small interval \\(I=[x,x+dx]\\) of width \\(dx\\) will be \\(f(t,x)dx\\).\n\n\nShow the code\n%%itikz --temp-dir --tex-packages=tikz --tikz-libraries=arrows --implicit-standalone \n%uncomment if require: \\path (0,300); %set diagram left start at 0, and has height of 300\n\\begin{tikzpicture}[x=0.75pt,y=0.75pt,yscale=-1.5,xscale=1.5]\n%Straight Lines [id:da6446978261676468] \n\\draw    (140.67,160) -- (400.5,160.17) ;\n%Straight Lines [id:da5099895315117877] \n\\draw    (400.5,160.17) -- (400.5,210.17) ;\n%Straight Lines [id:da29223877192666536] \n\\draw    (140.5,209.5) -- (477.17,210.16) ;\n\\draw [shift={(480.17,210.17)}, rotate = 180.11] [fill={rgb, 255:red, 0; green, 0; blue, 0 }  ][line width=0.08]  [draw opacity=0] (8.93,-4.29) -- (0,0) -- (8.93,4.29) -- cycle    ;\n%Straight Lines [id:da7176453962138043] \n\\draw    (140.5,209.5) -- (140.18,93.17) ;\n\\draw [shift={(140.17,90.17)}, rotate = 89.84] [fill={rgb, 255:red, 0; green, 0; blue, 0 }  ][line width=0.08]  [draw opacity=0] (8.93,-4.29) -- (0,0) -- (8.93,4.29) -- cycle    ;\n%Shape: Circle [id:dp9172058642707208] \n\\draw  [draw opacity=0][fill={rgb, 255:red, 184; green, 233; blue, 134 }  ,fill opacity=1 ] (155,176.08) .. controls (155,170.33) and (159.66,165.67) .. (165.42,165.67) .. controls (171.17,165.67) and (175.83,170.33) .. (175.83,176.08) .. controls (175.83,181.84) and (171.17,186.5) .. (165.42,186.5) .. controls (159.66,186.5) and (155,181.84) .. (155,176.08) -- cycle ;\n%Shape: Circle [id:dp41708018361647703] \n\\draw  [draw opacity=0][fill={rgb, 255:red, 184; green, 233; blue, 134 }  ,fill opacity=1 ] (175,196.08) .. controls (175,190.33) and (179.66,185.67) .. (185.42,185.67) .. controls (191.17,185.67) and (195.83,190.33) .. (195.83,196.08) .. controls (195.83,201.84) and (191.17,206.5) .. (185.42,206.5) .. controls (179.66,206.5) and (175,201.84) .. (175,196.08) -- cycle ;\n%Shape: Circle [id:dp7781895801877037] \n\\draw  [draw opacity=0][fill={rgb, 255:red, 184; green, 233; blue, 134 }  ,fill opacity=1 ] (185.67,174.42) .. controls (185.67,168.66) and (190.33,164) .. (196.08,164) .. controls (201.84,164) and (206.5,168.66) .. (206.5,174.42) .. controls (206.5,180.17) and (201.84,184.83) .. (196.08,184.83) .. controls (190.33,184.83) and (185.67,180.17) .. (185.67,174.42) -- cycle ;\n%Shape: Circle [id:dp24637416264324552] \n\\draw  [draw opacity=0][fill={rgb, 255:red, 184; green, 233; blue, 134 }  ,fill opacity=1 ] (213.33,173.42) .. controls (213.33,167.66) and (218,163) .. (223.75,163) .. controls (229.5,163) and (234.17,167.66) .. (234.17,173.42) .. controls (234.17,179.17) and (229.5,183.83) .. (223.75,183.83) .. controls (218,183.83) and (213.33,179.17) .. (213.33,173.42) -- cycle ;\n%Shape: Circle [id:dp48466517127845876] \n\\draw  [draw opacity=0][fill={rgb, 255:red, 184; green, 233; blue, 134 }  ,fill opacity=1 ] (267.67,194.75) .. controls (267.67,189) and (272.33,184.33) .. (278.08,184.33) .. controls (283.84,184.33) and (288.5,189) .. (288.5,194.75) .. controls (288.5,200.5) and (283.84,205.17) .. (278.08,205.17) .. controls (272.33,205.17) and (267.67,200.5) .. (267.67,194.75) -- cycle ;\n%Shape: Circle [id:dp2216365065410234] \n\\draw  [draw opacity=0][fill={rgb, 255:red, 184; green, 233; blue, 134 }  ,fill opacity=1 ] (253.67,172.42) .. controls (253.67,166.66) and (258.33,162) .. (264.08,162) .. controls (269.84,162) and (274.5,166.66) .. (274.5,172.42) .. controls (274.5,178.17) and (269.84,182.83) .. (264.08,182.83) .. controls (258.33,182.83) and (253.67,178.17) .. (253.67,172.42) -- cycle ;\n%Shape: Circle [id:dp315977950945718] \n\\draw  [draw opacity=0][fill={rgb, 255:red, 184; green, 233; blue, 134 }  ,fill opacity=1 ] (314.33,175.08) .. controls (314.33,169.33) and (319,164.67) .. (324.75,164.67) .. controls (330.5,164.67) and (335.17,169.33) .. (335.17,175.08) .. controls (335.17,180.84) and (330.5,185.5) .. (324.75,185.5) .. controls (319,185.5) and (314.33,180.84) .. (314.33,175.08) -- cycle ;\n%Shape: Circle [id:dp43596515241859735] \n\\draw  [draw opacity=0][fill={rgb, 255:red, 184; green, 233; blue, 134 }  ,fill opacity=1 ] (347.33,174.75) .. controls (347.33,169) and (352,164.33) .. (357.75,164.33) .. controls (363.5,164.33) and (368.17,169) .. (368.17,174.75) .. controls (368.17,180.5) and (363.5,185.17) .. (357.75,185.17) .. controls (352,185.17) and (347.33,180.5) .. (347.33,174.75) -- cycle ;\n%Shape: Circle [id:dp9605369285734118] \n\\draw  [draw opacity=0][fill={rgb, 255:red, 184; green, 233; blue, 134 }  ,fill opacity=1 ] (372,195.42) .. controls (372,189.66) and (376.66,185) .. (382.42,185) .. controls (388.17,185) and (392.83,189.66) .. (392.83,195.42) .. controls (392.83,201.17) and (388.17,205.83) .. (382.42,205.83) .. controls (376.66,205.83) and (372,201.17) .. (372,195.42) -- cycle ;\n%Straight Lines [id:da31603620824605405] \n\\draw    (213.33,239.68) -- (240.5,239.82) ;\n\\draw [shift={(243.5,239.83)}, rotate = 180.29] [fill={rgb, 255:red, 0; green, 0; blue, 0 }  ][line width=0.08]  [draw opacity=0] (8.93,-4.29) -- (0,0) -- (8.93,4.29) -- cycle    ;\n\\draw [shift={(210.33,239.67)}, rotate = 0.29] [fill={rgb, 255:red, 0; green, 0; blue, 0 }  ][line width=0.08]  [draw opacity=0] (8.93,-4.29) -- (0,0) -- (8.93,4.29) -- cycle    ;\n%Shape: Rectangle [id:dp2322723029099315] \n\\draw  [color={rgb, 255:red, 74; green, 144; blue, 226 }  ,draw opacity=1 ] (210,140.5) -- (242.83,140.5) -- (242.83,230.17) -- (210,230.17) -- cycle ;\n%Shape: Circle [id:dp21415420334871738] \n\\draw  [draw opacity=0][fill={rgb, 255:red, 184; green, 233; blue, 134 }  ,fill opacity=1 ] (222,197.75) .. controls (222,192) and (226.66,187.33) .. (232.42,187.33) .. controls (238.17,187.33) and (242.83,192) .. (242.83,197.75) .. controls (242.83,203.5) and (238.17,208.17) .. (232.42,208.17) .. controls (226.66,208.17) and (222,203.5) .. (222,197.75) -- cycle ;\n\n% Text Node\n\\draw (209.33,211.07) node [anchor=north west][inner sep=0.75pt]    {$x$};\n% Text Node\n\\draw (215,243.07) node [anchor=north west][inner sep=0.75pt]    {$dx$};\n% Text Node\n\\draw (186,120.4) node [anchor=north west][inner sep=0.75pt]    {$f( x,t)$};\n\n\\end{tikzpicture}\n\n\n\n\n\nNow, as time progresses, the number of particles in this interval \\(I\\) will change. The brownian particles will zig-zag upon bombardment by the molecules of the liquid. Some particles will move out of the interval \\(I\\), while other particles will move in.\nLet’s consider a timestep of length \\(\\tau\\). Einstein’s probabilistic approach was to model the distance travelled by the particles or displacement of the particles as a random variable \\(\\Delta\\). To determine how many particles end up in the interval \\(I\\), we start with the area to the right of the interval \\(I\\).\nThe density of particles at \\(x+\\Delta\\) is \\(f(t,x+\\Delta)\\); the number of particles in a small interval of length \\(dx\\) is \\(f(t,x+\\Delta)dx\\). If we represent the probability density of the displacement by \\(\\phi(\\Delta)\\), then the number of particles at \\(x+\\Delta\\) that will move to \\(x\\) will be \\(dx \\cdot f(t,x+\\Delta)\\phi(\\Delta)\\). We can apply the same logic to the left hand side. The number of particles at \\(x - \\Delta\\) that will move to \\(x\\) will be \\(dx \\cdot f(t,x-\\Delta)\\phi(-\\Delta)\\). Assume that \\(\\phi(\\Delta) = \\phi(-\\Delta)\\).\nNow, if we integrate these movements across the real line, then we get the number of particles at \\(x\\) at a short time later \\(t + \\tau\\).\n\\[\nf(t+ \\tau,x) dx = dx \\int_{-\\infty}^{\\infty} f(t,x+\\Delta) \\phi(\\Delta) d\\Delta\n\\]\nNow, we can get rid of \\(dx\\).\n\\[\nf(t+ \\tau,x) = \\int_{-\\infty}^{\\infty} f(t,x+\\Delta) \\phi(\\Delta) d\\Delta\n\\tag{9}\\]\nThe Taylor’s series expansion of \\(f(t+\\tau,x)\\) centered at \\(t\\) (holding \\(x\\) constant) is:\n\\[\nf(t + \\tau,x) = f(t,x) + \\frac{\\partial f}{\\partial t}\\tau + O(\\tau^2)\n\\]\nThe Taylor’s series expansion of \\(f(t,x+\\Delta)\\) centered at \\(x\\) (holding \\(t\\) constant) is:\n\\[\nf(t,x+\\Delta) = f(t,x) + \\frac{\\partial f}{\\partial x}\\Delta + \\frac{1}{2}\\frac{\\partial^2 f}{\\partial x^2}\\Delta^2 + O(\\Delta^3)\n\\]\nWe can now substitute these into Equation 9 to get:\n\\[\n\\begin{align*}\nf(t,x) + \\frac{\\partial f}{\\partial t}\\tau &= \\int_{-\\infty}^{\\infty}\\left(f(t,x) + \\frac{\\partial f}{\\partial x}\\Delta + \\frac{1}{2}\\frac{\\partial^2 f}{\\partial x^2}\\Delta^2\\right) \\phi(\\Delta)d\\Delta\\\\\n&= f(t,x) \\int_{-\\infty}^{\\infty} \\phi(\\Delta)d\\Delta \\\\\n&+ \\frac{\\partial f} {\\partial x} \\int_{-\\infty}^{\\infty} \\Delta \\phi(\\Delta)d\\Delta \\\\\n&+ \\frac{1}{2}\\frac{\\partial^2 f}{\\partial x^2}\\int_{-\\infty}^{\\infty}\\Delta^2 \\phi(\\Delta)d\\Delta\n\\end{align*}\n\\]\nNow, since the probability distribution of displacement \\(\\phi(\\cdot)\\) is symmetric around the origin, the second term is zero. And we know, that if we integrate the density over \\(\\mathbb{R}\\), we should get one, so the first term equals one. So, we get:\n\\[\nf(t,x) + \\frac{\\partial f}{\\partial t}\\tau = f(t,x) + \\frac{1}{2}\\frac{\\partial^2 f}{\\partial x^2}\\int_{-\\infty}^{\\infty}\\Delta^2 \\phi(\\Delta)d\\Delta\n\\]\nNow, we can cancel the \\(f\\) on both sides and then shift \\(\\tau\\) to the right hand side:\n\\[\n\\frac{\\partial f}{\\partial t} =  \\left(\\frac{1}{2\\tau} \\int_{-\\infty}^{\\infty}\\Delta^2 \\phi(\\Delta)d\\Delta \\right)\\frac{\\partial^2 f}{\\partial x^2}\n\\]\nDefine \\(D:= \\left(\\frac{1}{2\\tau} \\int_{-\\infty}^{\\infty}\\Delta^2 \\phi(\\Delta)d\\Delta \\right)\\). Then, we have:\n\\[\n\\frac{\\partial f}{\\partial t} =  D\\frac{\\partial^2 f}{\\partial x^2}\n\\]\nThe microscopic interpretation of the diffusion coefficient is, that its just the average of the squared displacements. The larger the \\(D\\), the faster the brownian particles move."
  },
  {
    "objectID": "posts/the_markov_property/index.html#kolmogorovs-backward-equation",
    "href": "posts/the_markov_property/index.html#kolmogorovs-backward-equation",
    "title": "The Markov Property",
    "section": "Kolmogorov’s Backward Equation",
    "text": "Kolmogorov’s Backward Equation\nThink of \\(y\\) and \\(t\\) as being current values and \\(y'\\) and \\(t'\\) being future values. The transition probability density function \\(p(y',t'|y,t)\\) of a diffusion satisfies two equations - one involving derivatives with respect to a future state and time (\\(y'\\) and \\(t'\\)) called forward equation and the other involving derivatives with respect to the current state and current time (\\(y\\) and \\(t\\)) called the backward equation. These two equations are parabolic partial differential equations not dissimilar to the Black-Scholes equation.\n\nTheorem 4 (Backward equation with initial value) Let \\((X_t,t\\geq 0)\\) be a diffusion in \\(\\mathbb{R}\\) with the SDE:\n\\[\ndX_t = \\sigma(X_t)dB_t + \\mu(X_t) dt\n\\]\nLet \\(g\\in C^2(\\mathbb{R})\\) be such that \\(g\\) is \\(0\\) outside an interval. Then, the solution of the PDE with initial value\n\\[\n\\begin{align*}\n\\frac{\\partial f}{\\partial t}(t,x) &= \\frac{\\sigma(x)^2}{2}\\frac{\\partial^2 f}{\\partial x^2} + \\mu(x)\\frac{\\partial f}{\\partial x}\\\\\nf(0,x) &= g(x)\n\\end{align*}\n\\tag{10}\\]\nhas the representation:\n\\[\nf(t,x) = \\mathbb{E}[g(X_t)|X_0 = x]\n\\]\n\nProof.\nStep 1. Let’s fix \\(t\\) and consider the function of space \\(h(x)=f(t,x)=\\mathbb{E}[g(X_t)|X_0=x]\\). We will show that, \\(f\\) satisfies the PDE Equation 10. Applying Ito’s formula to \\(h\\), we have:\n\\[\\begin{align}\ndh(X_s) &= h'(X_s) dX_s + \\frac{1}{2}h''(X_s) (dX_s)^2\\\\\n&= h'(X_s) (\\sigma(X_s)dB_s + \\mu(X_s) ds) + \\frac{\\sigma(X_s)^2}{2}h''(X_s)ds\\\\\n&= \\sigma(X_s)h'(X_s)dB_s + \\left(\\frac{\\sigma(X_s)^2}{2}h''(X_s) + \\mu(X_s)h'(X_s)\\right)ds\n\\end{align}\\]\nIn the integral form this is:\n\\[\\begin{align*}\nh(X_s) - h(X_0) &= \\int_0^s \\sigma(X_u)h'(X_u)dB_u \\\\\n&+ \\int_0^s \\left(\\frac{\\sigma(X_u)^2}{2}h''(X_u) + \\mu(X_u)h'(X_u)\\right)du\n\\end{align*}\\]\nStep 2. Take expectations on both sides, divide by \\(s\\) and let \\(s \\to 0\\). We are interested in taking the derivative with respect to \\(s\\) at \\(s_0=0\\).\n\\[\n\\begin{align*}\n\\mathbb{E}\\left[\\frac{h(X_s) - h(X_0)}{s}\\rvert X_0 = x \\right] &= \\frac{1}{s}\\mathbb{E}\\left[\\int_0^s \\sigma(X_u)h'(X_u)dB_u | X_0 = x\\right] \\\\\n&+ \\frac{1}{s}\\int_{0}^{s}\\mathbb{E}\\left[\\frac{\\sigma(X_u)^2}{2}h''(X_u) + \\mu(X_u)h'(X_u)|X_0 = x\\right]du\n\\end{align*}\n\\]\nThe expectation of the first term on the right hand side is zero, by the properties of the Ito integral.\nThe integrand of the second term (RHS) is a conditional expectation \\(\\mathbb{E}[\\xi(X_u)|X_0 = x]\\), it is an average at time \\(u\\), of the paths of the process starting at initial position \\(X_0 = x\\), so it is a function of \\(u\\) and \\(x\\). Let \\(\\mathbb{E}[\\xi(X_u)|X_0 = x] = \\gamma(u,x)\\). Suppressing the argument \\(x\\), we have the representation:\n\\[\\begin{align}\n\\int_0^s \\gamma(u) du\n\\end{align}\\]\nRecall that, if \\(\\gamma\\) is a continuous function, then it is Riemann integrable. Further, since integration and differentiation are inverse operations, there exists a unique antiderivative \\(\\Gamma\\) given by\n\\[\n\\Gamma(s) = \\int_{0}^{s}\\gamma(u)du\n\\]\nsatisfying \\(\\Gamma'(0) = \\gamma(0)\\).\nBy the definition of the derivative:\n\\[\\Gamma'(0) = \\lim_{s \\to 0} \\frac{\\Gamma(s) - \\Gamma(0)}{s} = \\lim_{s\\to 0} \\frac{\\Gamma(s)}{s} = \\gamma(0) \\quad \\{ \\Gamma(0)=0 \\text{ by definition }\\}\\]\nThus, we have:\n\\[\n\\gamma(0,x) = \\mathbb{E}[\\xi(X_0)|X_0 = x] = \\frac{\\sigma(x)^2}{2} h''(x) + \\mu(x)h'(x)\n\\]\nThis is the desired RHS.\nStep 3. As for the left-hand side, we have:\n\\[\n\\lim_{s \\to 0} \\frac{\\mathbb{E}[h(X_s)|X_0 = x] - h(X_0)}{s} = \\lim_{s \\to 0} \\frac{\\mathbb{E}[h(X_s)|X_0 = x] - f(t,x)}{s}\n\\]\nTo prove that this limit is \\(\\frac{\\partial f}{\\partial t}(t,x)\\), it remains to show that \\(\\mathbb{E}[h(X_s)|X_0 = x]=\\mathbb{E}[g(X_{t+s})|X_0 = x]=f(t+s,x)\\).\nTo see this, note that \\(h(X_s) = \\mathbb{E}[g(X_{t+s})|X_s]\\). We deduce:\n\\[\\begin{align*}\n\\mathbb{E}[h(X_s)|X_0 = x] &= \\mathbb{E}[\\mathbb{E}[g(X_{t+s})|X_s]|X_0 = x]\\\\\n&= \\mathbb{E}[\\mathbb{E}[g(X_{t+s})|\\mathcal{F}_s]|X_0 = x]\\\\\n& \\{ (X_t,t\\geq 0) \\text{ is Markov }\\} \\\\\n&= \\mathbb{E}[g(X_{t+s})|X_0 = x]\\\\\n& \\{ \\text{ Tower property }\\} \\\\\n&= f(t+s,x)\n\\end{align*}\\]\nSo, the LHS is \\(\\frac{\\partial f}{\\partial t}(t,x)\\). This closes the proof. \\(\\blacksquare\\)\nThe backward equation (Equation 10) can be conveniently written in terms of the generator of the diffusion.\n\nDefinition 4 (Generator of a diffusion) The generator of a diffusion with SDE \\(dX_t = \\sigma(X_t) dB_t + \\mu(X_t)dt\\) is the differential operator acting on functions of space defined by :\n\\[\nA = \\frac{\\sigma(x)^2}{2}\\frac{\\partial }{\\partial x^2} + \\mu(x)\\frac{\\partial}{\\partial x}\n\\]\n\nWith this notation, the backward equation for the function \\(f(t,x)\\) takes the form:\n\\[\n\\frac{\\partial f}{\\partial t}(t,x) = Af(t,x)\n\\]\nwhere it is understood that \\(A\\) acts only on the space variable. Theorem 4 gives a nice interpretation of the generator: it quantifies how much the function \\(f(t,x) = \\mathbb{E}[g(X_t)|X_0 = x]\\) changes in a small time interval.\n\nThe heat equation as a special case of the Backward equation\n\nExample 4 Let \\((B_t,t\\geq 0)\\) be a standard brownian motion. Then, the generator is:\n\\[\nA = \\frac{1}{2}\\frac{\\partial^2 f}{\\partial x^2}(t,x)\n\\]\nThen, by Theorem 4, the solution of the heat PDE\n\\[\n\\begin{align*}\n\\frac{\\partial f}{\\partial t}(t,x) = Af(x) = \\frac{1}{2}\\frac{\\partial^2 f}{\\partial x^2}(t,x)\n\\end{align*}\n\\]\nwith initial value \\(f(0,x)=g(x)\\) has the stochastic representation:\n\\[f(t,x) = \\mathbb{E}[g(B_t)|B_0 = x]\\]\nIt can be represented as an average of \\(g(B_t)\\) over all Brownian motion paths starting at the location \\(x\\).\n\n\n\nOther examples\n\nExample 5 (Generator of the Ornstein Uhlenbeck Process) The SDE of the Ornstein-Uhlenbeck process is:\n\\[\ndX_t = dB_t - X_t dt\n\\]\nThis means that its generator is:\n\\[\nA = \\frac{1}{2}\\frac{\\partial^2}{\\partial x^2} - x \\frac{\\partial}{\\partial x}\n\\]\n\n\nExample 6 (Generator of Geometric Brownian Motion) Recall that the geometric Brownian motion\n\\[\nS_t = S_0 \\exp(\\sigma B_t + \\mu t)\n\\]\nsatisfies the SDE:\n\\[\ndS_t = \\sigma S_t dB_t + \\left(\\mu + \\frac{\\sigma^2}{2}\\right) S_t dt\n\\]\nIn particular, the generator of geometric Brownian motion is :\n\\[\nA = \\frac{\\sigma^2 x^2}{2} x \\frac{\\partial^2}{\\partial x^2} + \\left(\\mu + \\frac{\\sigma^2}{2}\\right)\\frac{\\partial}{\\partial x}\n\\]\n\nFor applications, in particular in mathematical finance, it is important to solve the backward equation with terminal value instead of with initial value. The reversal of time causes the appearance of an extra minus sign in the equation.\n\n\nBackward equation with terminal value\n\nTheorem 5 Let \\((X_t,t\\leq T)\\) be a diffusion with the dynamics:\n\\[\ndX_t = \\sigma(X_t) dB_t + \\mu(X_t)dt\n\\]\nLet \\(g\\in C^2(\\mathbb{R})\\) be such that \\(g\\) is \\(0\\) outside an interval. Then, the solution of the PDE with terminal value at time \\(T\\)\n\\[\n\\begin{align*}\n-\\frac{\\partial f}{\\partial t} &= \\frac{\\sigma(x)^2}{2}\\frac{\\partial^2 f}{\\partial x^2} + \\mu(x)\\frac{\\partial f}{\\partial x}\\\\\nf(T,x) &= g(x)\n\\end{align*}\n\\tag{11}\\]\nhas the representation:\n\\[\nf(t,x) = \\mathbb{E}[g(X_T)|X_t = x]\n\\]\n\n\n\n\n\n\n\nBackward equation with terminal value appears in the martingale condition\n\n\n\nOne way to construct a martingale for the filtration \\((\\mathcal{F}_t,t\\geq 0)\\) is to take\n\\[\nM_t = \\mathbb{E}[Y | \\mathcal{F}_t]\n\\]\nwhere \\(Y\\) is some integrable random variable. The martingale property then follows from the tower property of the conditional expectation. In the setup of Theorem 5, the random variable \\(Y\\) is \\(g(X_T)\\). By the Markov property of diffusion, we therefore have:\n\\[\nf(t,X_t) = \\mathbb{E}[g(X_T)|X_t] = \\mathbb{E}[g(X_T)|\\mathcal{F}_t]\n\\]\nIn other words, the solution to the backward equation with terminal value evaluated at \\(X_t = x\\) yields a martingale for the natural filtration of the process. This is a different point of view on the procedure we have used many times now: To get a martingale of the form \\(f(t,X_t)\\), apply the Ito’s formula to \\(f(t,X_t)\\) and set the \\(dt\\) term to zero. The PDE we obtain is the backward equation with terminal value. In fact, the proof of the theorem takes this exact route.\n\n\nProof.\nConsider \\(f(t,X_t)\\) and apply Ito’s formula.\n\\[\n\\begin{align*}\ndf(t,X_t) &= \\frac{\\partial f}{\\partial t} dt + \\frac{\\partial f}{\\partial x}dX_t + \\frac{1}{2}\\frac{\\partial^2 f}{\\partial x^2} dX_t \\cdot dX_t\\\\\n&= \\frac{\\partial f}{\\partial t} dt + \\frac{\\partial f}{\\partial x}(\\sigma(X_t) dB_t + \\mu(X_t)dt) + \\frac{\\sigma(X_t)^2}{2}\\frac{\\partial^2 f}{\\partial x^2} dt\\\\\n&= \\sigma(X_t) dB_t + \\left(\\frac{\\partial f}{\\partial t} + \\frac{\\sigma(X_t)^2}{2}\\frac{\\partial^2 f}{\\partial x^2} + \\mu(X_t)\\frac{\\partial f}{\\partial x}\\right)dt\n\\end{align*}\n\\]\nSince \\(f(t,x)\\) is a solution to the equation, we get that the \\(dt\\) term is \\(0\\) and \\(f(t,X_t)\\) is a martingale for the Brownian filtration (and thus also for the natural filtration of the diffusion, which contains less information). In particular we have:\n\\[\nf(t,X_t) = \\mathbb{E}[f(T,X_T)|\\mathcal{F}_t] = \\mathbb{E}[g(X_T)|\\mathcal{F}_t]\n\\]\nSince \\((X_t,t\\leq T)\\) is a Markov process, we finally get:\n\\[\nf(t,x) = \\mathbb{E}[g(X_T)|X_t = x]\n\\]\n\nExample 7 (Martingales of geometric Brownian motion) Let \\((S_t, \\geq 0)\\) be a geometric brownian motion with SDE:\n\\[\ndS_t = \\sigma S_t dB_t + \\left(\\mu + \\frac{\\sigma^2}{2}\\right)dt\n\\]\nAs we saw in Example 6, its generator is:\n\\[\nA = \\frac{\\sigma^2 x^2}{2}\\frac{\\partial^2}{\\partial x^2} + x\\left(\\mu+\\frac{\\sigma^2}{2}\\right)\\frac{\\partial}{\\partial x}\n\\]\nIn view of Theorem 5, if \\(f(t,x)\\) satisfies the PDE\n\\[\n\\frac{\\partial f}{\\partial t} + \\frac{\\sigma^2 x^2}{2}\\frac{\\partial^2 f}{\\partial x^2} + x\\left(\\mu+\\frac{\\sigma^2}{2}\\right)\\frac{\\partial f}{\\partial x}\n\\]\nthen processes of the form \\(f(t,S_t)\\) will be martingales for the natural filtration."
  },
  {
    "objectID": "posts/the_markov_property/index.html#kolmogorovs-forward-equation",
    "href": "posts/the_markov_property/index.html#kolmogorovs-forward-equation",
    "title": "The Markov Property",
    "section": "Kolmogorov’s forward equation",
    "text": "Kolmogorov’s forward equation\nThe companion equation to the backward equation is the Kolmogorov forward equation or forward equation. It is also known as the Fokker-Planck equation from its physics origin. The equation is very useful as it is satisfied by the transition density function \\(p(y',t'|y,t)\\) of a time-homogenous diffusion. It involves the adjoint of the generator.\n\nDefinition 5 (Adjoint of the generator) The adjoint \\(A^*\\) of the generator of a diffusion \\((X_t,t\\geq 0)\\) with SDE:\n\\[\ndX_t = \\sigma(X_t)dB_t + \\mu(X_t)dt\n\\]\nis the differential operator acting on a function of space \\(f(x)\\) as follows:\n\\[\nA^*f(x) = \\frac{1}{2}\\frac{\\partial^2 }{\\partial x^2} \\sigma(x)^2 f(x) - \\frac{\\partial }{\\partial x}\\mu(x)f(x)\n\\tag{12}\\]\n\nNote the differences with the generator in Definition 4: there is an extra minus sign and the derivatives also act on the volatility and the drift.\n\nExample 8 (The generator of Brownian motion is self-adjoint) In the case of standard brownian motion, it is easy to check that:\n\\[\nA^* = \\frac{1}{2}\\frac{\\partial^2}{\\partial x^2}\n\\]\nand\n\\[\nA^* = \\frac{1}{2}\\nabla^2\n\\]\nin the multivariate case. In other words, the generator and its adjoint are the same. In this case, the operator is self-adjoint.\n\n\nExample 9 We see that the adjoint of the generator acting on \\(f(x)\\) for geometric Brownian motion is:\n\\[\nA^*f(x) = \\frac{1}{2}\\frac{\\partial^2}{\\partial x^2} (\\sigma^2 x^2 f(x)) - \\frac{\\partial}{\\partial x} \\left(\\left(\\mu + \\frac{\\sigma^2}{2}\\right) x f(x)\\right)\n\\]\nUsing the product rule in differentiating we get:\n\\[\nA^*[f(x)] = \\frac{\\sigma^2}{2}\\left(2x f(x) + x^2 f''(x)\\right) - \\left(\\left(\\mu + \\frac{\\sigma^2}{2}\\right)\\left(f(x) + x f'(x)\\right)\\right)\n\\]\n\n\nExample 10 The generator for the Ornstein-Uhlenbeck process was given in Example 5. The adjoint acting on \\(f\\) is therefore:\n\\[\n\\begin{align*}\nA^*f(x) &= \\frac{1}{2}\\frac{\\partial^2}{\\partial x^2}(f(x)) - \\frac{\\partial}{\\partial x}(- x f(x))\\\\\n&= \\frac{f''(x)}{2} + (f(x)+xf'(x))\n\\end{align*}\n\\]\n\nThe forward equation takes the following form for a function \\(f(t,x)\\) of time and space:\n\\[\n\\frac{\\partial f}{\\partial t} = A^* f\n\\tag{13}\\]\nFor brownian motion, since \\(A^* = A\\), the backward and forward equations are the same. As advertised earlier, the forward equation is satisfied by the transition \\(p_t(y',t'|y,t)\\) of a diffusion. Before showing this in general, we verify it in the Brownian case.\n\nExample 11 (The Heat Kernel as the solution of the forward equation) Recall that the transition probability density \\(p(y,t|x,0)\\) for Brownian motion, or heat kernel, is:\n\\[\np(y,t|x,0) = \\frac{e^{-\\frac{(y-x)^2}{2t}}}{\\sqrt{2\\pi t}}\n\\]\nHere, the space variable will be \\(y\\) and \\(x\\) will be fixed. The relevant function is thus \\(f(t,y) = p(y,t|x,0)\\). The adjoint operator acting on the space variable \\(y\\) is \\(A^* = A = \\frac{1}{2}\\frac{\\partial^2}{\\partial y^2}\\). The relevant time and space derivatives are given by:\n\\[\n\\begin{align*}\n\\frac{\\partial f}{\\partial t} & =\\frac{\\partial }{\\partial t}\\left(\\frac{1}{\\sqrt{2\\pi t}}\\exp\\left( -\\frac{( y-x)^{2}}{2t}\\right)\\right)\\\\\n& =\\frac{\\sqrt{2\\pi t} \\cdot \\frac{\\partial }{\\partial t}\\left(\\exp\\left( -\\frac{( y-x)^{2}}{2t}\\right)\\right) -\\exp\\left( -\\frac{( y-x)^{2}}{2t}\\right) \\cdot \\frac{\\partial }{\\partial t}\\left(\\sqrt{2\\pi t}\\right)}{\\left(\\sqrt{2\\pi t}\\right)^{2}}\\\\\n& =\\frac{\\sqrt{2\\pi t} \\cdot \\exp\\left( -\\frac{( y-x)^{2}}{2t}\\right) \\cdot \\frac{\\partial }{\\partial t}\\left( -\\frac{( y-x)^{2}}{2t}\\right) -\\exp\\left( -\\frac{( y-x)^{2}}{2t}\\right)\\frac{\\sqrt{2\\pi }}{2\\sqrt{t}}}{\\left(\\sqrt{2\\pi t}\\right)^{2}}\\\\\n& =\\exp\\left( -\\frac{( y-x)^{2}}{2t}\\right)\\frac{\\sqrt{2\\pi t} \\cdot \\left( -\\frac{( y-x)^{2}}{2}\\right) \\cdot \\left( -\\frac{1}{t^{2}}\\right) -\\frac{\\sqrt{2\\pi }}{2\\sqrt{t}}}{\\left(\\sqrt{2\\pi t}\\right)^{2}}\\\\\n& =\\sqrt{2\\pi }\\exp\\left( -\\frac{( y-x)^{2}}{2t}\\right)\\frac{\\frac{( y-x)^{2}}{2t^{3/2}} -\\frac{1}{2t^{1/2}}}{\\left(\\sqrt{2\\pi }\\right)^{2} \\cdot t}\\\\\n& =\\frac{1}{2t^{1/2}} \\cdot \\frac{1}{\\sqrt{2\\pi }}\\exp\\left( -\\frac{( y-x)^{2}}{2t}\\right)\\frac{\\frac{( y-x)^{2} -t}{t}}{t}\\\\\n& =\\frac{1}{\\sqrt{2\\pi }}\\exp\\left( -\\frac{( y-x)^{2}}{2t}\\right)\\frac{( y-x)^{2} -t}{2t^{5/2}}\\\\\n& =\\frac{( y-x)^{2} -t}{2t^{2}} f\n\\end{align*}\n\\]\nAlso:\n\\[\n\\begin{align*}\n\\frac{\\partial f}{\\partial y} & =\\frac{\\partial }{\\partial y}\\left(\\frac{1}{\\sqrt{2\\pi t}}\\exp\\left( -\\frac{( y-x)^{2}}{2t}\\right)\\right)\\\\\n& =\\frac{1}{\\sqrt{2\\pi t}}\\exp\\left( -\\frac{( y-x)^{2}}{2t}\\right) \\cdot \\frac{\\partial }{\\partial x}\\left( -\\frac{( y-x)^{2}}{2t}\\right)\\\\\n& =-\\frac{1}{\\sqrt{2\\pi }} \\cdot \\frac{1}{2t^{3/2}} \\cdot \\exp\\left( -\\frac{( y-x)^{2}}{2t}\\right) 2( y-x)\\\\\n& =-\\frac{1}{\\sqrt{2\\pi }} \\cdot \\frac{1}{t^{3/2}} \\cdot \\exp\\left( -\\frac{( y-x)^{2}}{2t}\\right)( y-x)\\\\\n& =-\\frac{1}{t}( y-x) f\n\\end{align*}\n\\]\nand\n\\[\n\\begin{align*}\nA^{*} f=\\frac{1}{2}\\frac{\\partial ^{2} f}{\\partial y^{2}} & =\\frac{1}{2}\\left( -\\frac{1}{t}\\right)\\frac{\\partial }{\\partial y}( yf-xf)\\\\\n& =-\\frac{1}{2t}\\left( f+y\\frac{\\partial f}{\\partial y} -x\\frac{\\partial f}{\\partial y}\\right)\\\\\n& =-\\frac{1}{2t}\\left( f+( y-x)\\frac{\\partial f}{\\partial y}\\right)\\\\\n& =-\\frac{1}{2t}\\left( f-\\frac{( y-x)^{2}}{t} f\\right)\\\\\n& =\\frac{( y-x)^{2} -t}{2t^{2}} f\n\\end{align*}\n\\]\nWe conclude that \\(f(t,y)=p(y,t|x,0)\\) is a solution of the forward equation in the standard Brownian motion case. \\(\\blacksquare\\)\n\nWhere does the form of the adjoint operator Equation 12 come from? In some sense, the adjoint operator plays a role similar to that of the transpose of a matrix in linear algebra. The adjoint acts on the function on the left. To see this, consider two functions \\(f,g\\) of space on which the generator \\(A\\) of a diffusion is well-defined. In particular, let’s assume that the functions are zero outside an interval. Consider the quantity\n\\[\n\\int_{\\mathbb{R}}g(x)A(f(x))dx = \\int_{\\mathbb{R}} g(x)\\left(\\frac{\\sigma(x)^2 }{2}f''(x) + \\mu(x)f'(x)\\right)dx\n\\]\nThis quantity can represent for example the average of \\(Af(x)\\) over some PDF \\(g(x)\\). In the above, \\(A\\) acts on the function on the right. To make the operator act on \\(g\\), we integrate by parts. This gives for the second term:\n\\[\n\\int_{\\mathbb{R}} g(x)\\mu(x)f'(x)dx = g(x)\\mu(x)f(x)\\Bigg|_{-\\infty}^{\\infty}-\\int_{\\mathbb{R}}f(x)\\frac{d}{dx}(g(x)\\mu(x))dx\n\\]\nThe boundary term \\(g(x)f(x)\\mu(x)\\Bigg|_{-\\infty}^\\infty\\) is \\(0\\) by the assumptions on \\(f,g\\). This term on \\(\\sigma\\) is obtained by integrating by parts twice:\n\\[\n\\begin{align*}\n\\int_{\\mathbb{R}} g(x) \\frac{\\sigma(x)^2}{2}f''(x)dx &= g(x) \\frac{\\sigma(x)^2}{2}f'(x)\\Bigg|_{-\\infty}^{\\infty} - \\int_{\\mathbb{R}}\\frac{d}{dx}\\left(g(x) \\frac{\\sigma(x)^2}{2}\\right) f'(x)dx\\\\\n-\\int_{\\mathbb{R}} \\frac{d}{dx}\\left(g(x) \\frac{\\sigma(x)^2}{2}\\right)f'(x)dx &= -\\frac{d}{dx}\\left(g(x) \\frac{\\sigma(x)^2}{2}\\right)f(x) \\Bigg|_{-\\infty}^{\\infty} + \\int_{\\mathbb{R}}\\frac{d^2}{dx^2}\\left(g(x) \\frac{\\sigma(x)^2}{2}\\right)f(x)dx\n\\end{align*}\n\\]\nThus,\n\\[\n\\begin{align*}\n\\int_{\\mathbb{R}}g(x) Af(x)dx &= \\int_{\\mathbb{R}}\\left(\\frac{1}{2}\\frac{d^2}{dx^2}(g(x) \\sigma(x)^2) - \\frac{d}{dx}(g(x)\\mu(x))\\right)f(x)dx\\\\\n&= \\int_{\\mathbb{R}}(A^*g(x))f(x)dx\n\\end{align*}\n\\tag{14}\\]\n\nTheorem 6 (Forward equation and transition probability) Let \\((X_t,t\\geq 0)\\) be a diffusion with SDE:\n\\[\ndX_t = \\sigma(X_t)dB_t + \\mu(X_t)dt, \\quad X_0 = x_0\n\\]\nLet \\(p(x,t|x_0,0)\\) be the transition probability density function for a fixed \\(x_0\\). Then, the function \\(f(t,y) = p(y,t|x_0,0)\\) is a solution of the PDE\n\\[\n\\frac{\\partial f}{\\partial t} = A^* f\n\\]\nwhere \\(A^*\\) is the adjoint of \\(A\\).\n\nProof.\nLet \\(h(x)\\) be some arbitrary function of space that is \\(0\\) outside an interval. We compute :\n\\[\n\\frac{1}{\\epsilon}(\\mathbb{E}[h(X_{t+\\epsilon}) - \\mathbb{E}[h(X_t)]])\n\\]\ntwo different ways and take the limit as \\(\\epsilon \\to 0\\).\nOn one hand, we have by the definition of the transition density\n\\[\n\\frac{1}{\\epsilon}\\left(\\mathbb{E}[h(X_{t+\\epsilon})]-\\mathbb{E}[h(X_t)]\\right) = \\int_{\\mathbb{R}}\\frac{1}{\\epsilon}(p(x,t+\\epsilon|x,0) - p(x,t|x_0,0))h(x)dx\n\\]\nBy taking the limit \\(\\epsilon \\to 0\\) inside the integral (assuming this is fine), we get:\n\\[\n\\int_{\\mathbb{R}} \\frac{\\partial}{\\partial t}p(x,t|x_0,0)h(x)dx\n\\tag{15}\\]\nOn the other hand, Ito’s formula implies\n\\[\n\\begin{align*}\ndh(X_s) &= \\frac{\\partial h}{\\partial x} dX_s + \\frac{1}{2} \\frac{\\partial^2 h}{\\partial x^2} (dX_s)^2\\\\\n&= \\frac{\\partial h}{\\partial x} (\\sigma(X_s) dB_s + \\mu(X_s)ds) + \\frac{1}{2} \\frac{\\partial^2 h}{\\partial x^2} (\\sigma(X_s)^2 ds)\\\\\n&= \\sigma(X_s)\\frac{\\partial h}{\\partial x} dB_s + \\left(\\mu(X_s) \\frac{\\partial h}{\\partial x} + \\frac{\\sigma(X_s)^2}{2}\\frac{\\partial^2 h}{\\partial x^2}\\right)ds\\\\\nh(X_{t+\\epsilon}) - h(X_t) &= \\int_{t}^{t+\\epsilon}\\sigma(X_s)\\frac{\\partial h}{\\partial x} dB_s + \\int_{t}^{t+\\epsilon}(Ah(x))ds\\\\\n\\mathbb{E}[h(X_{t+\\epsilon})] - \\mathbb{E}[h(X_t)] &= \\underbrace{\\mathbb{E}\\left[\\int_{t}^{t+\\epsilon}\\sigma(X_s)\\frac{\\partial h}{\\partial x} dB_s\\right]}_{0} + \\int_{t}^{t+\\epsilon}\\mathbb{E}[Ah(X_s)]ds\n\\end{align*}\n\\]\nDividing by \\(\\epsilon\\) and taking the limit as \\(\\epsilon \\to 0\\), we have:\n\\[\n\\begin{align*}\n\\lim_{\\epsilon \\to 0} \\frac{1}{\\epsilon} (\\mathbb{E}[h(X_{t+\\epsilon})] - \\mathbb{E}[h(X_t)]) &= \\mathbb{E}[Ah(X_t)]\\\\\n&= \\int_{\\mathbb{R}} p(x,t|x_0,0) Ah(x) dx\n\\end{align*}\n\\]\nThis can be written using Equation 14 as,\n\\[\n\\int_{\\mathbb{R}}(A^* p(x,t|x_0,0)) h(x) dx\n\\]\nSince \\(h\\) is arbitrary, we conclude that:\n\\[\n\\frac{\\partial}{\\partial t}p(x,t|x_0,0) = A^* p(x,t|x_0,0)\n\\tag{16}\\]\n\nExample 12 (Forward equation and invariant probability.) The Ornstein-Uhlenbeck process converges to a stationary distribution as noted in the example here. For example, for the SDE of the form\n\\[\ndX_t = -X_t dt + dB_t\n\\]\nwith \\(X_0\\) a Gaussian of mean \\(0\\) and variance \\(1/2\\), the PDF of \\(X_t\\), is, for all \\(t\\) is:\n\\[\nf(x) = \\frac{1}{\\sqrt{\\pi}} e^{-x^2}\n\\tag{17}\\]\nThis invariant distribution can be seen from the point of view of the forward equation. Indeed since the PDF is constant in time, the forward equation simply becomes:\n\\[\nA^* f = 0\n\\tag{18}\\]\n\n\nExample 13 The SDE of the Ornstein-Uhlenbeck process can be generated as follows. Consider \\(V(x)\\), a smooth function of space such that \\(\\int_{\\mathbb{R}} e^{-2V(x)}dx&lt;\\infty\\). The Smoluchowski equation is the SDE of the form:\n\\[\ndX_t = dB_t - V'(X_t) dt\n\\tag{19}\\]\nThe SDE can be interpreted as follows: \\(X_t\\) represents the position of a particle on \\(\\mathbb{R}\\). The position varies due to the Brownian fluctuations and also due to a force \\(V'(X_t)\\) that depends on the position. The function \\(V(x)\\) should then be thought of as the potential with which the particle moves, since the force (field) is the (negative) derivative of the potential function in Newtonian physics. The generator of this diffusion is:\n\\[\nA = \\frac{1}{2}\\frac{\\partial^2}{\\partial x^2} - V'(x)\\frac{\\partial}{\\partial x}\n\\]\nThis diffusion admits an invariant distribution :\n\\[\nf(x) = Ce^{-2V(x)}\n\\]\nwhere \\(C\\) is such that \\(\\int_{\\mathbb{R}}f(x)dx = 1\\)."
  },
  {
    "objectID": "posts/the_markov_property/index.html#the-feynman-kac-formula",
    "href": "posts/the_markov_property/index.html#the-feynman-kac-formula",
    "title": "The Markov Property",
    "section": "The Feynman-Kac Formula",
    "text": "The Feynman-Kac Formula\nWe saw in ?@exm-heat-equation-and-brownian-motion that the solution of the heat equation:\n\\[\n\\frac{\\partial f}{\\partial t} = \\frac{1}{2}\\frac{\\partial^2 f}{\\partial x^2}\n\\]\ncan be represented as an average over Brownian paths. This representation was extended to diffusions in theorem Theorem 4 where the second derivative in the equation is replaced by the generator of the corresponding diffusion. How robust is this representation? In other words, is it possible to slightly change the PDE and still get a stochastic representation representation for the solution? The answer to this question is yes, when a term of the form \\(r(x)f(t,x)\\) is added to the equation, where \\(r(x)\\) is a well-behaved function of space (for example, piecewise continuous). The stochastic representation of the PDE in this case bears the name Feynman-Kac formula, making a fruitful collaboration between the physicist Richard Feynman and the mathematician Mark Kac. By the way, you pronounce “Kac” as “cats”. His name is Polish. People who immigrated from Poland before him spelled their names as “Katz”. The case when \\(r(x)\\) is linear will be important in the applications to mathematical finance, where it represents the contribution of the interest rate.\n\nTheorem 7 (Initial Value Problem) Let \\((X_t,t\\geq 0)\\) be a diffusion in \\(\\mathbb{R}\\) with the SDE:\n\\[\ndX_t = \\sigma(X_t) dB_t + \\mu(X_t)dt\n\\]\nLet \\(g\\in C^2(\\mathbb{R})\\) be such that \\(g\\) is \\(0\\) outside an interval. Then, the solution of the PDE with initial value\n\\[\n\\begin{align*}\n\\frac{\\partial f}{\\partial t}(t,x) &= \\frac{\\sigma(x)^2}{2}\\frac{\\partial^2 f}{\\partial x^2}(t,x) + \\mu(x)\\frac{\\partial f}{\\partial x}(t,x) - r(x)f(x)\\\\\nf(0,x) &= g(x)\n\\end{align*}\n\\tag{20}\\]\nhas the stochastic representation:\n\\[\nf(t,x) = \\mathbb{E}\\left[g(X_t)\\exp\\left(-\\int_0^t r(X_s) ds\\right)\\Bigg| X_0 = x\\right]\n\\]\n\nProof.\nThe proof is again based on Ito’s formula. For a fixed \\(t\\), we consider the process:\n\\[\nM_s = f(t-s, X_s) \\exp\\left(-\\int_0^s r(X_u) du\\right), \\quad s \\leq t\n\\]\nWrite \\(Z_s = \\exp\\left(-\\int_0^s r(X_u) du\\right)\\) and \\(V_s = f(t-s,X_s)\\). A direct application of Ito’s formula yields:\nLet \\(R_s = -\\int_0^s r(X_u) du\\). So, \\(dR_t = r(X_t) dt\\). \\((R_t,t\\geq 0)\\) is a random variable, because \\(r(X_s)\\) depends on how \\((X_s, s \\leq t)\\) evolves, it is stochastic, but for very small intervals of time \\(r(X_s)\\) is a constant, and hence the process \\((R_t,t\\geq 0)\\) is said to be locally deterministic.\n\\[\n\\begin{align*}\nZ_s &= e^{-R_s}\\\\\ndZ_s &= -e^{-R_s} dR_s + \\frac{1}{2}e^{R_s} (dR_s)^2\\\\\n&= -Z_s r(X_s) ds\n\\end{align*}\n\\]\nand\n\\[\n\\begin{align*}\ndV_s &= \\frac{\\partial}{\\partial s}f(t-s, X_s)ds + \\frac{\\partial}{\\partial x}f(t-s, X_s)dX_s + \\frac{1}{2}\\frac{\\partial^2}{\\partial x^2}f(t-s,X_s)(dX_s)^2\\\\\n&= -f_s ds + f_x (\\sigma(X_s)dB_s + \\mu(X_s)ds) + \\frac{1}{2}f_{xx} \\sigma(X_s)^2 ds \\\\\n&= \\sigma(X_s) f_x dB_s + \\\\\n&+ \\left\\{-f_s + \\mu(X_s)f_x + \\frac{\\sigma(X_s)^2}{2}f_{xx}\\right\\}ds\n\\end{align*}\n\\]\nRecall that \\(t\\) is fixed here, and we differentiate with respect to \\(s\\) in time. Since \\(f(t,x)\\) is a solution of the PDE, we can write the second equation as:\n\\[\ndV_s = \\sigma(X_s) f_x dB_s + r(X_s) f(t-s,X_s)ds\n\\]\nNow, by Ito’s product rule, we finally have:\n\\[\n\\begin{align*}\ndM_s &= V_s dZ_s + Z_s dV_s + dZ_s dV_s\\\\\n&= -f(t-s,X_s)Z_s r(X_s) ds + Z_s (\\sigma(X_s) f_x dB_s + r(X_s) f(t-s,X_s)ds) + 0\\\\\n&= \\sigma(X_s)Z_s f_x dB_s\n\\end{align*}\n\\]\nThis proves that \\((M_s, s \\leq t)\\) is a martingale. We conclude that:\n\\[\n\\mathbb{E}[M_t] = \\mathbb{E}[M_0]\n\\]\nUsing the definition of \\(M_t\\), this yields:\n\\[\n\\mathbb{E}[M_t] = \\mathbb{E}\\left[f(0,X_t)\\exp\\left(-\\int_0^t r(X_u) du\\right)\\right] = \\mathbb{E}\\left[g(X_t)\\exp\\left(-\\int_0^t r(X_u) du\\right)\\right] = \\mathbb{E}[M_0] = f(t,x)\n\\]\nThis proves the theorem. \\(\\blacksquare\\)\nAs for the backward equation, it is natural to consider the terminal value problem for the same PDE.\n\nTheorem 8 (Terminal Value Problem) Let \\((X_t,t \\leq T)\\) be a diffusion in \\(\\mathbb{R}\\) with the SDE:\n\\[\ndX_t = \\sigma(X_t) dB_t + \\mu(X_t) dt\n\\]\nLet \\(g\\in C^2(\\mathbb{R})\\) be such that \\(g\\) is \\(0\\) outside an interval. Then, the solution of the PDE with initial value\n\\[\n\\begin{align*}\n-\\frac{\\partial f}{\\partial t}(t,x) &= \\frac{\\sigma(x)^2}{2}\\frac{\\partial^2 f}{\\partial x^2}(t,x) + \\mu(x)\\frac{\\partial f}{\\partial x}(t,x) - r(x)f(t,x)\\\\\nf(T,x) &= g(x)\n\\end{align*}\n\\]\nhas the stochastic representation :\n\\[\nf(t,x) = \\mathbb{E}\\left[g(X_T)\\exp\\left(-\\int_t^T r(X_u) du\\right)\\Bigg|X_t = x\\right]\n\\]\n\nProof.\nThe proof is similar by considering instead\n\\[\nM_t = f(t,X_t)\\exp\\left(-\\int_0^t r(X_u) du\\right)\n\\]\n\nTheorem 9 (Generalized version.) Let \\(V\\in C^2(\\mathbb{R})\\) be the payout function. Then, the solution to the PDE\n\\[\n\\begin{align*}\n\\left(\\frac{\\partial}{\\partial t} + \\mu(t,x)\\frac{\\partial}{\\partial x} + \\frac{1}{2}\\sigma^2(t,x)\\frac{\\partial^2}{\\partial x^2}\\right)f = r(t,x)f(t,x) + B(t,x)\n\\end{align*}\n\\]\nwith the boundary condition:\n\\[\nf(T,x) = V(x)\n\\]\nhas the stochastic representation:\n\\[\nf(t,x)=\\mathbb{E}_t\\left[\\exp\\left(-\\int_t^T r(u,X_u) du\\right)V(X_T)\\right] - \\mathbb{E}_t\\left[\\int_{t}^T \\exp\\left(-\\int_t^s r(u,X_u) du\\right)B(s,X_s)ds\\right]\n\\]\nwhere \\((X_t,t\\leq T)\\) is a diffusion in \\(\\mathbb{R}\\) with the dynamics :\n\\[\ndX_t = \\sigma(t,X_t) dB_t + \\mu(t,X_t)dt\n\\]\n\nProof\nFor brevity, I drop the space coordinates in the below derivations.\nDefine \\(Z_s = \\exp\\left(-\\int_t^s r_u du\\right)\\). Consider the process\n\\[\nY(s) = Z_s f(s,X_s) - \\int_t^s Z_s B_s ds\n\\]\nBy Ito’s product rule:\n\\[\n\\begin{align*}\ndY_s &= dZ_s f + Z_s df + dZ_s df - Z_s B_s ds\n\\end{align*}\n\\]\nSince \\(dZ_s df = O(dt dt)\\) it can be dropped. We have:\n\\[\n\\begin{align*}\ndY_s &= -r_s Z_s f ds + Z_s \\left(f_s ds + f_x dX_s + \\frac{1}{2}f_{xx}(dX_s)^2\\right) - Z_s B_s ds\\\\\n&= -r_s Z_s f ds + Z_s \\left[f_s ds + f_x (\\mu ds + \\sigma dW_s) + \\frac{1}{2}\\sigma^2f_{xx}ds\\right] - Z_s B_s ds \\\\\n&= -r_s Z_s f ds + Z_s \\left[\\left(f_s + \\mu f_x  + \\frac{1}{2}\\sigma^2f_{xx}\\right)ds + \\sigma f_x dW_s \\right]  - Z_s B_s ds\n\\end{align*}\n\\]\nWe can substitute the term in the round brackets \\(\\left(f_s + \\mu f_x + \\frac{1}{2}\\sigma^2f_{xx}\\right) = r_s f + B_s\\), since \\(f\\) satisfies the PDE. So, we have:\n\\[\n\\begin{align*}\ndY_s\n&= -r_s Z_s f ds + Z_s \\left[\\left(r_s f + B_s\\right)ds + \\sigma f_x dW_s \\right]  - Z_s B_s ds\\\\\n&= Z_s \\sigma f_x dW_s\n\\end{align*}\n\\]\nSo, the process \\((Y_s,s\\leq T)\\) is a martingale. Integrating the above equation from \\(t\\) to \\(T\\), we have:\n\\[\nY(T) - Y(t) = \\int_t^T Z_s \\sigma f_x dW_s\n\\]\nUpon taking expectations, conditioned on \\(X_t = x\\) and observing that the RHS is an Ito integral, which has zero expectation, it follows that:\n\\[\n\\mathbb{E}_t[Y_T|X_t = x] =  \\mathbb{E}_t[Y_t|X_t = x]\n\\]\nOn the right hand side, \\(Y_t = f(t,X_t) =f(t,x)\\). It follows that:\n\\[\n\\begin{align*}\nf(t,x) &= \\mathbb{E}_t\\left[Z_T f(T,X_T) - \\int_{t}^T Z_s B_s ds \\right]\\\\\n&= \\mathbb{E}_t\\left[Z_T V(X_T)\\right] - \\mathbb{E}_t\\left[\\int_{t}^T Z_s B_s ds \\right]\n\\end{align*}\n\\]\nThis closes the proof. \\(\\blacksquare\\)"
  },
  {
    "objectID": "posts/the_markov_property/index.html#exercises",
    "href": "posts/the_markov_property/index.html#exercises",
    "title": "The Markov Property",
    "section": "Exercises",
    "text": "Exercises\n\nExercise 1 (Shifted Brownian Motion) Let \\((B_t,t\\geq 0)\\) be a standard brownian motion. Fix \\(t &gt; 0\\). Show that the process \\((W_s,s \\geq 0)\\) with \\(W_s = B_{t+s} - B_t\\) is a standard brownian motion independent of \\(\\mathcal{F}_t\\).\n\nSolution.\nAt \\(s = 0\\), \\(W(0) = B(t) - B(t) = 0\\).\nConsider any arbitrary times \\(t_1 &lt; t_2\\). We have:\n\\[\\begin{align*}\nW(t_2) - W(t_1) &= (B(t + t_2) - B(t)) - (B(t + t_1) - B(t))\\\\\n&= B(t + t_2) - B(t + t_1)\n\\end{align*}\\]\nNow, \\(B(t + t_2) - B(t + t_1) \\sim \\mathcal{N}(0,t_2 - t_1)\\). So, \\(W(t_2) - W(t_1)\\) is a Gaussian random variable with mean \\(0\\) and variance \\(t_2 - t_1\\).\nFinally, consider any finite set of times \\(0=t_0 &lt; t_1 &lt; t_2 &lt; \\ldots &lt; t_n = T\\). Then, \\(t &lt; t + t_1 &lt; t + t_2 &lt; \\ldots &lt; t + t_n\\). We have that, \\(B(t + t_1) - B(t)\\), \\(B(t + t_2) - B(t + t_1)\\), \\(B(t + t_3) - B(t + t_2)\\), \\(\\ldots\\), \\(B(t+T) - B(t+t_{n-1})\\) are independent random variables. Consequently, \\(W(t_1) - W(0)\\), \\(W(t_2) - W(t_1)\\), \\(W(t_3) - W(t_2)\\), \\(\\ldots\\), \\(W(t_n) - W(t_{n-1})\\) are independent random variables. So, \\((W_s,s\\geq 0)\\) is a standard brownian motion.\nAlso, we have:\n\\[\\begin{align*}\n\\mathbb{E}[W(s)|\\mathcal{F}_t] &= \\mathbb{E}[B(t + s) - B(t)|\\mathcal{F}_t]\\\\\n& \\{ B(t+s) - B(t) \\perp \\mathcal{F}_t \\}\\\\\n&= \\mathbb{E}[B(t + s) - B(t)]\\\\\n&= \\mathbb{E}[W(s)]\n\\end{align*}\\]\nThus, \\(W(s)\\) is independent of \\(\\mathcal{F}_t\\), it does not depend upon the information available upto time \\(t\\)."
  },
  {
    "objectID": "posts/spectral_theorem/index.html",
    "href": "posts/spectral_theorem/index.html",
    "title": "The Spectral Theorem",
    "section": "",
    "text": "Spectral Theorem\nEvery real, symmetric matrix is orthogonally diagonalizable.\n\nTheorem 1 (Spectral Theorem) Every real symmetric matrix is diagonalizable.\nLet \\(A\\) be a \\(n \\times n\\) real symmetric matrix. Then,\n\nThe eigenvalues of \\(A\\) are real.\nThere exists an orthonormal basis \\(\\{\\mathbf{q}_1,\\ldots,\\mathbf{q}_n\\}\\) for \\(\\mathbb{R}^n\\) consisting of the eigenvectors of \\(A\\). That is, there is an orthogonal matrix \\(Q\\) so that \\(A = QAQ^{-1}\\).\n\n\n\n\n\n\n\n\nSpectral values\n\n\n\nThe term spectrum refers to the eigenvalues of a matrix, or more, generally a linear operator. In Physics, the spectral energy lines of atoms (e.g. Balmer lines of the Hydrogen atom), are characterized as the eigenvalues of the governing quantum mechanical Schrodinger operator.\n\n\nProof.\nClaim. The eigenvalues of \\(A\\) are real.\n\\[\n\\begin{align*}\n\\langle A\\mathbf{x}, \\mathbf{y} \\rangle &= (A \\mathbf{x})' \\mathbf{y}\\\\\n&= \\mathbf{x}'A' \\mathbf{y}\\\\\n&= \\langle \\mathbf{x},A'\\mathbf{y}\\rangle\n\\end{align*}\n\\]\nSince, for a symmetric matrix \\(A\\), \\(A = A'\\), it follows that:\n\\[\n\\langle A\\mathbf{x},\\mathbf{y}\\rangle = \\langle \\mathbf{x}, A\\mathbf{y} \\rangle\n\\]\nOr using the dot-product notation, we could write:\n\\[\n(A\\mathbf{x})\\cdot \\mathbf{y} = \\mathbf{x}\\cdot (A\\mathbf{y})\n\\tag{1}\\]\nSuppose \\(\\mathbf{v}\\neq\\mathbf{0}\\) is a non-zero vector in \\(\\mathbf{R}^n\\) such that there exists a complex scalar \\(\\lambda\\), satisfying:\n\\[\nA \\mathbf{v} = \\lambda \\mathbf{v}\n\\tag{2}\\]\nWe can now take the complex conjugate of the eigenvalue equation. Remember that \\(A\\) is a real matrix, so \\(\\bar{A} = A\\). Thus, we have the conjugated version of the eigenvalue equation:\n\\[\n\\overline{(A\\mathbf{v})}=\\overline{A}\\overline{\\mathbf{v}} = A\\overline{\\mathbf{v}} = \\overline{\\lambda \\mathbf{v}} = \\overline{\\lambda}\\overline{\\mathbf{v}}\n\\tag{3}\\]\nUsing the eigenvalue equation (Equation 2), we can write:\n\\[\n(A \\mathbf{v})\\cdot \\overline{\\mathbf{v}} = (\\lambda \\mathbf{v}) \\cdot \\overline{\\mathbf{v}} = \\lambda (\\mathbf{v} \\cdot \\overline{\\mathbf{v}})\n\\]\nAlternatively, using Equation 1 and Equation 3, we have:\n\\[\n(A \\mathbf{v})\\cdot \\overline{\\mathbf{v}} = \\mathbf{v} \\cdot (A\\overline{\\mathbf{v}}) = \\mathbf{v} \\cdot (\\overline{\\lambda} \\overline{\\mathbf{v}}) = \\overline{\\lambda} (\\mathbf{v} \\cdot \\overline{\\mathbf{v}})\n\\]\nConsequently,\n\\[\n(\\lambda - \\overline{\\lambda})(\\mathbf{v}\\cdot \\overline{\\mathbf{v}}) = 0\n\\]\nSince, \\(\\mathbf{v} \\neq \\mathbf{0}\\), \\(\\lambda = \\overline{\\lambda}\\). Therefore, \\(\\lambda \\in \\mathbb{R}\\).\nClaim. \\(A\\) is orthogonally diagonalizable.\nWe proceed by induction.\nFor \\(n=1\\), \\(A\\) and \\(v\\) are scalars, so \\(Av = \\lambda v\\), where \\(\\lambda = A\\). Thus, we can pick any non-zero scalar \\(v\\) to form a basis in \\(\\mathbf{R}\\). And \\(A=P^{-1}\\Lambda P\\), where \\(P=I\\) and \\(\\Lambda = A\\).\nInductive hypotheis. Every \\(k \\times k\\) matrix is diagonalisable for \\(k=1,2,3,\\ldots,n-1\\).\nClaim. Let \\(A \\in \\mathbf{R}^{n \\times n}\\) be symmetric. Then, we are interested to prove that \\(A\\) is diagonalizable. We break the induction part into 3 steps.\nEvery square matrix \\(A\\) has atleast one eigenvalue. Suppose \\(\\lambda_{1}\\) is an eigenvalue of the matrix \\(A\\) and has a corresponding eigenvector \\(\\mathbf{v}_1\\). By part (I), we know that \\(\\lambda_{1}\\in\\mathbf{R}\\). We can normalize \\(\\mathbf{v}_1\\) as \\(\\mathbf{q}_{1} = \\mathbf{v}_1/||\\mathbf{v}_1||\\), so that it is an eigenvector with eigenvalue \\(\\lambda_{1}\\). (Obviously, this is no problem, since if \\(A\\mathbf{v}_1 = \\lambda_1 \\mathbf{v}_1\\), it implies \\(A (\\mathbf{v}_1/||\\mathbf{v}_1||) = \\lambda_1 (\\mathbf{v}_1/||\\mathbf{v}_1||)\\). It follows that, \\(A \\mathbf{q}_1 = \\lambda_1 \\mathbf{q}_1\\). )\nNow, we can extend this to a basis \\(\\{\\mathbf{q}_{1},\\mathbf{w}_{2},\\ldots,\\mathbf{w}_{n}\\}\\) of \\(\\mathbf{R}^n\\). By the Gram-Schmidt orthogonalization algorithm, given the basis \\(\\{\\mathbf{q}_{1},\\mathbf{w}_{2},\\ldots,\\mathbf{w}_{n}\\}\\), we can find a corresponding orthonormal basis \\(\\{\\mathbf{q}_{1},\\mathbf{q}_{2},\\ldots,\\mathbf{q}_{n}\\}\\) of \\(\\mathbf{R}^n\\).\nNow, we huddle these basis vectors together as column-vectors of a matrix and formulate the matrix \\(P\\).\n\\[\n\\begin{align*}\nP & =\\left[\\begin{array}{cccc}\n\\mathbf{\\mathbf{q}_{1}} & \\mathbf{q}_{2} & \\ldots & \\mathbf{q}_{n}\\end{array}\\right]\n\\end{align*}\n\\]\nBy definition, \\(P\\) is an orthogonal matrix. So, \\(P^{-1} = P^T\\).\nDefine\n\\[\n\\begin{align*}\nB & =P^{-1}AP\n\\end{align*}\n\\]\nStep I. \\(B\\) is symmetric.\nWe have:\n\\[\n\\begin{align*}\nB^{T} & =(P^{-1}AP)^{T}\\\\\n& =(P^{T}AP)^{T} & \\{P^{-1}=P^{T}\\}\\\\\n& =P^{T}A^{T}(P^{T})^{T}\\\\\n& =P^{T}A^{T}P\\\\\n& =P^{T}AP & \\{A\\text{ is symmetric}\\}\\\\\n& =B\n\\end{align*}\n\\]\nWe are now going to try and write \\(B\\) in the block form to try to see the structure that this matrix must have and hope that it looks like, it is going to be diagonal.\nStep II. The structure of \\(B\\).\nThe way we do this, is to consider the matrix \\(B\\) post-multiplied by \\(\\mathbf{e}_{1}\\). Consider \\(B\\mathbf{e}_{1}\\). This should actually give us the first column of \\(B\\). Now, we also know that \\(B=P^{T}AP\\). So, we could actually say, well,\n\\[\n\\begin{align*}\nP^{T}AP\\mathbf{e}_{1} & =P^{T}A\\mathbf{q}_{1}\n\\end{align*}\n\\]\nNow, remember that \\(\\mathbf{q}_{1}\\) is the normalized eigenvector corresponding to the eigenvalue \\(\\lambda_{1}\\). So, \\(A\\mathbf{q}_{1}=\\lambda_{1}\\mathbf{q}_{1}\\). That means, this is equal to:\n\\[\\begin{align*}\nP^{T}A\\mathbf{q}_{1} & =P^{T}\\lambda_{1}\\mathbf{q}_{1}\\\\\n& =\\lambda_{1}P^{t}\\mathbf{q}_{1}\\\\\n& =\\lambda_{1}\\left[\\begin{array}{c}\n\\mathbf{q}_{1}^{T}\\\\\n\\mathbf{q}_{2}^{T}\\\\\n\\vdots\\\\\n\\mathbf{q}_{n}^{T}\n\\end{array}\\right]\\mathbf{q}_{1}\\\\\n& =\\lambda_{1}\\left[\\begin{array}{c}\n\\mathbf{q}_{1}^{T}\\mathbf{q}_{1}\\\\\n\\mathbf{q}_{2}^{T}\\mathbf{q}_{1}\\\\\n\\vdots\\\\\n\\mathbf{q}_{n}^{T}\\mathbf{q}_{1}\n\\end{array}\\right]\\\\\n& =\\lambda_{1}\\left[\\begin{array}{c}\n1\\\\\n0\\\\\n\\vdots\\\\\n0\n\\end{array}\\right]\\\\\n& =\\left[\\begin{array}{c}\n\\lambda_{1}\\\\\n0\\\\\n0\\\\\n0\n\\end{array}\\right]\n\\end{align*}\\]\nThis is the first column of the matrix \\(B\\). Since \\(B=B^{T}\\), the first row should also be\n\\[\n\\begin{bmatrix}\n\\lambda_1 & 0 & 0 & \\ldots & 0\n\\end{bmatrix}\n\\]\nSo, we can write the matrix \\(B\\) in the block form:\n\\[\\begin{align*}\nB & =\\left[\\begin{array}{cc}\n\\lambda_{1} & O\\\\\nO & C\n\\end{array}\\right]\n\\end{align*}\\]\nThe first row and the first column are satisying the need to be diagonal.\nStep III.\nWe know that \\(C\\) is a \\(n-1\\times n-1\\) symmetric matrix. By the induction hypothesis, there exists an orthogonal matrix \\(Q\\) such that \\(D=Q^{-1}CQ = Q^T C Q\\).\nNow, define the matrix \\(R\\) as:\n\\[\\begin{equation}\nR:=P\\left[\\begin{array}{cc}\n1 & 0_{1\\times n-1}\\\\\n0_{n-1\\times1} & Q\n\\end{array}\\right]\n\\end{equation}\\]\nClaim. Our claim is that \\(R\\) is orthogonal and \\(R^{-1}AR\\) is diagonal.\n\nWe have:\n\n\\[\\begin{align*}\nR^{-1} & =\\left[\\begin{array}{cc}\n1 & 0_{1\\times n-1}\\\\\n0_{n-1\\times1} & Q^{-1}\n\\end{array}\\right]P^{-1} & \\{\\text{Reverse order law}\\}\\\\\n& =\\left[\\begin{array}{cc}\n1 & 0_{1\\times n-1}\\\\\n0_{n-1\\times1} & Q^{T}\n\\end{array}\\right]P^{T} & \\{P\\text{ and }Q\\text{ are orthogonal}\\}\n\\end{align*}\\]\nBut,\n\\[\\begin{align*}\nR^{T} & =\\left[\\begin{array}{cc}\n1 & 0_{1\\times n-1}\\\\\n0_{n-1\\times1} & Q^{T}\n\\end{array}\\right]P^{T}\n\\end{align*}\\]\nSo,\n\\[\\begin{align*}\nR^{T} & =R^{-1}\n\\end{align*}\\]\nThus, \\(R\\) is orthogonal.\n\nWell, let’s compute \\(R^{-1}AR\\).\n\n\\[\\begin{align*}\nR^{-1}AR & =R^{T}AR & \\{R\\text{ is orthogonal}\\}\\\\\n& =\\left[\\begin{array}{cc}\n1 & 0_{1\\times n-1}\\\\\n0_{n-1\\times1} & Q^{T}\n\\end{array}\\right]P^{T}AP\\left[\\begin{array}{cc}\n1 & 0_{1\\times n-1}\\\\\n0_{n-1\\times1} & Q\n\\end{array}\\right]\\\\\n& =\\left[\\begin{array}{cc}\n1 & 0_{1\\times n-1}\\\\\n0_{n-1\\times1} & Q^{T}\n\\end{array}\\right]B\\left[\\begin{array}{cc}\n1 & 0_{1\\times n-1}\\\\\n0_{n-1\\times1} & Q\n\\end{array}\\right]\\\\\n& =\\left[\\begin{array}{cc}\n1 & 0_{1\\times n-1}\\\\\n0_{n-1\\times1} & Q^{T}\n\\end{array}\\right]\\left[\\begin{array}{cc}\n\\lambda_{1} & 0_{1\\times n-1}\\\\\n0_{n-1\\times1} & C\n\\end{array}\\right]\\left[\\begin{array}{cc}\n1 & 0_{1\\times n-1}\\\\\n0_{n-1\\times1} & Q\n\\end{array}\\right]\\\\\n& =\\left[\\begin{array}{cc}\n\\lambda_{1} & 0_{1\\times n-1}\\\\\n0_{n-1\\times1} & Q^{T}C\n\\end{array}\\right]\\left[\\begin{array}{cc}\n1 & 0_{1\\times n-1}\\\\\n0_{n-1\\times1} & Q\n\\end{array}\\right]\\\\\n& =\\left[\\begin{array}{cc}\n\\lambda_{1} & 0_{1\\times n-1}\\\\\n0_{n-1\\times1} & Q^{T}CQ\n\\end{array}\\right]\n\\end{align*}\\]\nSince \\(Q^{T}CQ\\) is diagonal, it follows that \\(R^{-1}AR\\) is diagonal. This closes the proof. \\(\\blacksquare\\)"
  },
  {
    "objectID": "posts/rule-of-five/index.html",
    "href": "posts/rule-of-five/index.html",
    "title": "Rule of Five",
    "section": "",
    "text": "Introduction\nThe rule-of-five states that, if a class C has one of user-declared\n\nDestructor ~C\nCopy constructor C(const C&)\nCopy assignment operator C& operator=(const C&)\nMove constructor C(C&&)\nMove assignment operator C& operator=(C&&)\n\nit should declare all five special member functions.\nUser-declared != User-provided. Any explicitly defaulted (=default) or deleted (=delete) functions count as user-declared.\nA function is user-provided if it is user-declared and not explicitly defaulted or deleted.\n\n\nHinnant Table\nThe infamous Hinnant table elaborates the various special members implicitly generated by the compiler in the presence of user-declared special functions.\n\n\n\nHinnant table"
  },
  {
    "objectID": "posts/pricing-under-collateral/index.html",
    "href": "posts/pricing-under-collateral/index.html",
    "title": "Collateralized Discounting",
    "section": "",
    "text": "In the past, standard derivatives pricing theory assumed the existence of a risk-free rate for derivatives discounting. Until the global financial crisis(GFC), this assumption worked well, but has since been replaced by Collateral adjusted valuation(CAV). Collateralized discounting is standard practice on derivatives trading desks.\nA risk-neutral measure can still be defined and much of the pricing technology developed in the traditional setting can be reused.\nThe theoretical foundations of collateralized discounting are the papers Cooking with collateral and Funding beyond Discounting by Piterbarg. I summarize the main arguments here.\n\n\n\nWe replicate the derivative worth \\(V(t)\\), by an amount \\(\\theta_1\\) of the underlying \\(X\\), an amount \\(\\theta_2\\) of funding account \\(B_f(t)\\) and an amount \\(\\theta_3\\) of collateral account \\(B_c(t)\\). The value of the portfolio at time \\(t\\) is:\n\\[\n\\begin{align*}\nV(t) = \\theta_1(t) X(t) + \\theta_2(t) B_f(t) + \\theta_3(t) B_c(t)\n\\end{align*}\n\\tag{1}\\]\nThe self-financing assumption implies that:\n\\[\ndV(t) = \\theta_1 dX_t + \\theta_2 dB_f(t) + \\theta_3 dB_c(t)\n\\tag{2}\\]\nAssume that the dynamics of the three assets is as follows:\n\\[\n\\begin{align*}\ndX(t) &= \\mu^{\\mathbb{P}}(t) X(t) dt + \\sigma(t)X(t)dW^\\mathbb{P}(t)\\\\\ndB_f(t) &= r_f(t)B_f(t) dt\\\\\ndB_c(t) &= r_c(t)B_c(t) dt\n\\end{align*}\n\\tag{3}\\]\nThe derivative’s price dynamics \\(dV(t,X_t)\\) is obtained by the Ito’s lemma as:\n\\[\n\\begin{aligned}\ndV( t,X) & =\\frac{\\partial V}{\\partial t} dt+\\frac{\\partial V}{\\partial X} dX_{t} +\\frac{1}{2}\\frac{\\partial ^{2} V}{\\partial X^{2}}( dX_{t})^{2}\\\\\n& =\\frac{\\partial V}{\\partial t} dt+\\frac{\\partial V}{\\partial X}\\left( \\mu ^{\\mathbb{P}} X_{t} dt+\\sigma _{t} X_{t} dW_{t}^{\\mathbb{P}}\\right) +\\frac{1}{2} \\sigma _{t}^{2} X_{t}^{2} dt\\\\\n& =\\left(\\frac{\\partial V}{\\partial t} +\\mu ^{\\mathbb{P}} X_{t}\\frac{\\partial V}{\\partial X} +\\frac{1}{2} \\sigma _{t}^{2} X_{t}^{2}\\frac{\\partial ^{2} V}{\\partial X^{2}}\\right) dt+\\sigma _{t} X_{t}\\frac{\\partial V}{\\partial X} dW_{t}^{\\mathbb{P}}\n\\end{aligned}\n\\tag{4}\\]\nSubstituting Equation 3 and Equation 4 in Equation 2, we have:\n\\[\n\\begin{aligned}\n\\left(\\frac{\\partial V}{\\partial t} +\\mu ^{\\mathbb{P}} X_{t}\\frac{\\partial V}{\\partial X} +\\frac{1}{2} \\sigma _{t}^{2} X_{t}^{2}\\frac{\\partial ^{2} V}{\\partial X^{2}}\\right) dt+\\sigma _{t} X_{t}\\frac{\\partial V}{\\partial X} dW_{t}^{\\mathbb{P}} & =\\theta _{1}\\left( \\mu ^{\\mathbb{P}} X_{t} dt+\\sigma _{t} X_{t} dW_{t}^{\\mathbb{P}}\\right)\\\\\n& +\\theta _{2}( r_{f}( t) B_{f}( t) dt) +\\theta _{3}( r_{c}( t) B_{c}( t) dt)\n\\end{aligned}\n\\]\nThe perfect collateral condition implies that the collateral held at any time equals the mark-to-market(MtM) value of the derivative. So, \\(B_c(t) = V(t)\\). So, we have:\n\\[\n\\begin{aligned}\n\\left(\\frac{\\partial V}{\\partial t} +\\mu ^{\\mathbb{P}} X_{t}\\frac{\\partial V}{\\partial X} +\\frac{1}{2} \\sigma _{t}^{2} X_{t}^{2}\\frac{\\partial ^{2} V}{\\partial X^{2}}\\right) dt+\\sigma _{t} X_{t}\\frac{\\partial V}{\\partial X} dW_{t}^{\\mathbb{P}} & =\\theta _{1}\\left( \\mu ^{\\mathbb{P}} X_{t} dt+\\sigma _{t} X_{t} dW_{t}^{\\mathbb{P}}\\right)\\\\\n& +\\theta _{2}( r_{f}( t) B_{f}( t) dt) +\\theta _{3}( r_{c}( t) V( t) dt)\n\\end{aligned}\n\\tag{5}\\]\nSetting \\(\\theta_3(t) = 1\\) in Equation 1, we get :\n\\[\n\\begin{align*}\n\\theta_2(t)B_f(t) = \\theta_1(t)X(t)\n\\end{align*}\n\\tag{6}\\]\nSubstituting Equation 6 in Equation 5, we get:\n\\[\n\\begin{align*}\n\\left(\\frac{\\partial V}{\\partial t} +\\mu ^{\\mathbb{P}} X_{t}\\frac{\\partial V}{\\partial X} +\\frac{1}{2} \\sigma _{t}^{2} X_{t}^{2}\\frac{\\partial ^{2} V}{\\partial X^{2}}\\right) dt+\\sigma _{t} X_{t}\\frac{\\partial V}{\\partial X} dW_{t}^{\\mathbb{P}} & =\\theta _{1}\\left( \\mu ^{\\mathbb{P}} X_{t} dt+\\sigma _{t} X_{t} dW_{t}^{\\mathbb{P}}\\right)\\\\\n& -\\theta _{1}( r_{f}( t) X( t) dt) +( r_{c}( t) V( t) dt)\n\\end{align*}\n\\]\nRe-arranging the terms, we get:\n\\[\n\\begin{align*}\n\\left(\\frac{\\partial V}{\\partial t} -\\mu ^{\\mathbb{P}} X_{t}\\left( \\theta _{1} -\\frac{\\partial V}{\\partial X}\\right) +r_{f}( t) \\theta _{1}( t) X( t) +\\frac{1}{2} \\sigma _{t}^{2} X_{t}^{2}\\frac{\\partial ^{2} V}{\\partial X^{2}}\\right) dt & =\\sigma _{t} X_{t}\\left( \\theta _{1}( t) -\\frac{\\partial V}{\\partial X}\\right) dW_{t}^{\\mathbb{P}}\\\\\n& +( r_{c}( t) V( t) dt)\n\\end{align*}\n\\]\nSetting \\(\\theta_(t) = \\frac{\\partial V(t)}{\\partial X}\\), we get:\n\\[\n\\begin{align*}\n\\left(\\frac{\\partial V}{\\partial t} +r_{f}( t) X( t)\\frac{\\partial V}{\\partial X} +\\frac{1}{2} \\sigma _{t}^{2} X_{t}^{2}\\frac{\\partial ^{2} V}{\\partial X^{2}}\\right) dt & =r_{c}( t) V( t) dt\n\\end{align*}\n\\]\nor equivalently:\n\\[\n\\begin{align*}\n\\left(\\frac{\\partial V}{\\partial t} +r_{f}( t) X( t)\\frac{\\partial V}{\\partial X} +\\frac{1}{2} \\sigma _{t}^{2} X_{t}^{2}\\frac{\\partial ^{2} V}{\\partial X^{2}}\\right) & =r_{c}( t) V( t)\n\\end{align*}\n\\tag{7}\\]\nThis is the pricing PDE. Applying Feynman-Kac, the solution to this PDE for the boundary condition:\n\\[\nV(T,x) = g(x)\n\\]\nhas the stochastic representation:\n\\[\nV(t,x) = \\mathbb{E}^{\\mathbb{Q}^f}[e^{-\\int_t^T r_c(t) dt } g(X_T)|\\mathcal{F}_t]\n\\tag{8}\\]\nwhere \\(\\mathbb{Q}^f\\) is the measure associated with the funding account numeraire \\(B_f(t)\\) and the underlying risky asset has the dynamics:\n\\[\ndX_t = r_f(t)X(t)dt+ \\sigma(t)X(t)dW^{\\mathbb{Q}^f}(t)\n\\]"
  },
  {
    "objectID": "posts/pricing-under-collateral/index.html#introduction",
    "href": "posts/pricing-under-collateral/index.html#introduction",
    "title": "Collateralized Discounting",
    "section": "",
    "text": "In the past, standard derivatives pricing theory assumed the existence of a risk-free rate for derivatives discounting. Until the global financial crisis(GFC), this assumption worked well, but has since been replaced by Collateral adjusted valuation(CAV). Collateralized discounting is standard practice on derivatives trading desks.\nA risk-neutral measure can still be defined and much of the pricing technology developed in the traditional setting can be reused.\nThe theoretical foundations of collateralized discounting are the papers Cooking with collateral and Funding beyond Discounting by Piterbarg. I summarize the main arguments here."
  },
  {
    "objectID": "posts/pricing-under-collateral/index.html#pricing-under-collateral",
    "href": "posts/pricing-under-collateral/index.html#pricing-under-collateral",
    "title": "Collateralized Discounting",
    "section": "",
    "text": "We replicate the derivative worth \\(V(t)\\), by an amount \\(\\theta_1\\) of the underlying \\(X\\), an amount \\(\\theta_2\\) of funding account \\(B_f(t)\\) and an amount \\(\\theta_3\\) of collateral account \\(B_c(t)\\). The value of the portfolio at time \\(t\\) is:\n\\[\n\\begin{align*}\nV(t) = \\theta_1(t) X(t) + \\theta_2(t) B_f(t) + \\theta_3(t) B_c(t)\n\\end{align*}\n\\tag{1}\\]\nThe self-financing assumption implies that:\n\\[\ndV(t) = \\theta_1 dX_t + \\theta_2 dB_f(t) + \\theta_3 dB_c(t)\n\\tag{2}\\]\nAssume that the dynamics of the three assets is as follows:\n\\[\n\\begin{align*}\ndX(t) &= \\mu^{\\mathbb{P}}(t) X(t) dt + \\sigma(t)X(t)dW^\\mathbb{P}(t)\\\\\ndB_f(t) &= r_f(t)B_f(t) dt\\\\\ndB_c(t) &= r_c(t)B_c(t) dt\n\\end{align*}\n\\tag{3}\\]\nThe derivative’s price dynamics \\(dV(t,X_t)\\) is obtained by the Ito’s lemma as:\n\\[\n\\begin{aligned}\ndV( t,X) & =\\frac{\\partial V}{\\partial t} dt+\\frac{\\partial V}{\\partial X} dX_{t} +\\frac{1}{2}\\frac{\\partial ^{2} V}{\\partial X^{2}}( dX_{t})^{2}\\\\\n& =\\frac{\\partial V}{\\partial t} dt+\\frac{\\partial V}{\\partial X}\\left( \\mu ^{\\mathbb{P}} X_{t} dt+\\sigma _{t} X_{t} dW_{t}^{\\mathbb{P}}\\right) +\\frac{1}{2} \\sigma _{t}^{2} X_{t}^{2} dt\\\\\n& =\\left(\\frac{\\partial V}{\\partial t} +\\mu ^{\\mathbb{P}} X_{t}\\frac{\\partial V}{\\partial X} +\\frac{1}{2} \\sigma _{t}^{2} X_{t}^{2}\\frac{\\partial ^{2} V}{\\partial X^{2}}\\right) dt+\\sigma _{t} X_{t}\\frac{\\partial V}{\\partial X} dW_{t}^{\\mathbb{P}}\n\\end{aligned}\n\\tag{4}\\]\nSubstituting Equation 3 and Equation 4 in Equation 2, we have:\n\\[\n\\begin{aligned}\n\\left(\\frac{\\partial V}{\\partial t} +\\mu ^{\\mathbb{P}} X_{t}\\frac{\\partial V}{\\partial X} +\\frac{1}{2} \\sigma _{t}^{2} X_{t}^{2}\\frac{\\partial ^{2} V}{\\partial X^{2}}\\right) dt+\\sigma _{t} X_{t}\\frac{\\partial V}{\\partial X} dW_{t}^{\\mathbb{P}} & =\\theta _{1}\\left( \\mu ^{\\mathbb{P}} X_{t} dt+\\sigma _{t} X_{t} dW_{t}^{\\mathbb{P}}\\right)\\\\\n& +\\theta _{2}( r_{f}( t) B_{f}( t) dt) +\\theta _{3}( r_{c}( t) B_{c}( t) dt)\n\\end{aligned}\n\\]\nThe perfect collateral condition implies that the collateral held at any time equals the mark-to-market(MtM) value of the derivative. So, \\(B_c(t) = V(t)\\). So, we have:\n\\[\n\\begin{aligned}\n\\left(\\frac{\\partial V}{\\partial t} +\\mu ^{\\mathbb{P}} X_{t}\\frac{\\partial V}{\\partial X} +\\frac{1}{2} \\sigma _{t}^{2} X_{t}^{2}\\frac{\\partial ^{2} V}{\\partial X^{2}}\\right) dt+\\sigma _{t} X_{t}\\frac{\\partial V}{\\partial X} dW_{t}^{\\mathbb{P}} & =\\theta _{1}\\left( \\mu ^{\\mathbb{P}} X_{t} dt+\\sigma _{t} X_{t} dW_{t}^{\\mathbb{P}}\\right)\\\\\n& +\\theta _{2}( r_{f}( t) B_{f}( t) dt) +\\theta _{3}( r_{c}( t) V( t) dt)\n\\end{aligned}\n\\tag{5}\\]\nSetting \\(\\theta_3(t) = 1\\) in Equation 1, we get :\n\\[\n\\begin{align*}\n\\theta_2(t)B_f(t) = \\theta_1(t)X(t)\n\\end{align*}\n\\tag{6}\\]\nSubstituting Equation 6 in Equation 5, we get:\n\\[\n\\begin{align*}\n\\left(\\frac{\\partial V}{\\partial t} +\\mu ^{\\mathbb{P}} X_{t}\\frac{\\partial V}{\\partial X} +\\frac{1}{2} \\sigma _{t}^{2} X_{t}^{2}\\frac{\\partial ^{2} V}{\\partial X^{2}}\\right) dt+\\sigma _{t} X_{t}\\frac{\\partial V}{\\partial X} dW_{t}^{\\mathbb{P}} & =\\theta _{1}\\left( \\mu ^{\\mathbb{P}} X_{t} dt+\\sigma _{t} X_{t} dW_{t}^{\\mathbb{P}}\\right)\\\\\n& -\\theta _{1}( r_{f}( t) X( t) dt) +( r_{c}( t) V( t) dt)\n\\end{align*}\n\\]\nRe-arranging the terms, we get:\n\\[\n\\begin{align*}\n\\left(\\frac{\\partial V}{\\partial t} -\\mu ^{\\mathbb{P}} X_{t}\\left( \\theta _{1} -\\frac{\\partial V}{\\partial X}\\right) +r_{f}( t) \\theta _{1}( t) X( t) +\\frac{1}{2} \\sigma _{t}^{2} X_{t}^{2}\\frac{\\partial ^{2} V}{\\partial X^{2}}\\right) dt & =\\sigma _{t} X_{t}\\left( \\theta _{1}( t) -\\frac{\\partial V}{\\partial X}\\right) dW_{t}^{\\mathbb{P}}\\\\\n& +( r_{c}( t) V( t) dt)\n\\end{align*}\n\\]\nSetting \\(\\theta_(t) = \\frac{\\partial V(t)}{\\partial X}\\), we get:\n\\[\n\\begin{align*}\n\\left(\\frac{\\partial V}{\\partial t} +r_{f}( t) X( t)\\frac{\\partial V}{\\partial X} +\\frac{1}{2} \\sigma _{t}^{2} X_{t}^{2}\\frac{\\partial ^{2} V}{\\partial X^{2}}\\right) dt & =r_{c}( t) V( t) dt\n\\end{align*}\n\\]\nor equivalently:\n\\[\n\\begin{align*}\n\\left(\\frac{\\partial V}{\\partial t} +r_{f}( t) X( t)\\frac{\\partial V}{\\partial X} +\\frac{1}{2} \\sigma _{t}^{2} X_{t}^{2}\\frac{\\partial ^{2} V}{\\partial X^{2}}\\right) & =r_{c}( t) V( t)\n\\end{align*}\n\\tag{7}\\]\nThis is the pricing PDE. Applying Feynman-Kac, the solution to this PDE for the boundary condition:\n\\[\nV(T,x) = g(x)\n\\]\nhas the stochastic representation:\n\\[\nV(t,x) = \\mathbb{E}^{\\mathbb{Q}^f}[e^{-\\int_t^T r_c(t) dt } g(X_T)|\\mathcal{F}_t]\n\\tag{8}\\]\nwhere \\(\\mathbb{Q}^f\\) is the measure associated with the funding account numeraire \\(B_f(t)\\) and the underlying risky asset has the dynamics:\n\\[\ndX_t = r_f(t)X(t)dt+ \\sigma(t)X(t)dW^{\\mathbb{Q}^f}(t)\n\\]"
  },
  {
    "objectID": "posts/optimization_algorithms/index.html",
    "href": "posts/optimization_algorithms/index.html",
    "title": "Optimization Algorithms",
    "section": "",
    "text": "Definition. Let \\(f:\\mathbf{R}^n \\to \\mathbf{R}\\) be a scalar-valued function. The gradient vector of \\(f\\) is defined as:\n\\[\\begin{align*}\n\\nabla f(\\mathbf{x}) = \\left[\\frac{\\partial f}{\\partial x_1},\\frac{\\partial f}{\\partial x_2},\\ldots,\\frac{\\partial f}{\\partial x_n}\\right]\n\\end{align*}\\]\nThe graph of the function \\(f:\\mathbf{R}^n \\to \\mathbf{R}\\) is the hypersurface in \\(\\mathbf{R}^{n+1}\\) given by the equation \\(x_{n+1}=f(x_1,\\ldots,x_n)\\).\nDefinition. \\(f\\) is said to be differentiable at \\(\\mathbf{a}\\) if all the partial derivatives \\(f_{x_i}(\\mathbf{a})\\) exist and if the function \\(h(\\mathbf{x})\\) defined by:\n\\[\\begin{align*}\nh(\\mathbf{x}) = f(\\mathbf{a}) + \\nabla f(\\mathbf{a})\\cdot (\\mathbf{x}-\\mathbf{a})\n\\end{align*}\\]\nis a good linear approximation to \\(f\\) near \\(a\\), meaning that:\n\\[\\begin{align*}\nL = \\lim_{\\mathbf{x} \\to \\mathbf{a}} \\frac{f(\\mathbf{x}) - h(\\mathbf{x})}{||\\mathbf{x} - \\mathbf{a}||} = 0\n\\end{align*}\\]\nIf \\(f\\) is differentiable at \\(\\mathbf{a},f(\\mathbf{a})\\), then the hypersurface determined by the graph has a tangent hyperplane at \\((\\mathbf{a},f(\\mathbf{a}))\\) given by the equation:\n\\[\\begin{align*}\nh(\\mathbf{x}) = f(\\mathbf{a}) + \\nabla f(\\mathbf{a})\\cdot (\\mathbf{x}-\\mathbf{a})\n\\end{align*}\\]\n\n\nLet \\(f(x,y)\\) be a scalar-valued function of two variables. We understand the partial derivative \\(\\frac{\\partial f}{\\partial x}(a,b)\\) as the slope at the point \\((a,b,f(a,b))\\) of the curve obtained as the intersection of the surface \\(z=f(x,y)\\) and the plane \\(y=b\\). The other partial derivative has a geometric interpretation. However, the surface \\(z=f(x,y)\\) contains infinitely many curves passing through \\((a,b,f(a,b))\\) whose slope we might choose to measure. The directional derivative enables us to do this.\nIntuitively, \\(\\frac{\\partial f}{\\partial x}(a,b)\\) is as the rate of change of \\(f\\) as we move infinitesimally from \\(\\mathbf{a}=(a,b)\\) in the \\(\\mathbf{i}\\) direction.\nMathematically, by the definition of the derivative of \\(f\\):\n\\[\\begin{align*}\n\\frac{\\partial f}{\\partial x}(a,b) &= \\lim_{h \\to 0} \\frac{f(a+h,b) - f(a,b)}{h}\\\\\n&=\\lim_{h \\to 0} \\frac{f((a,b) + (h,0)) - f(a,b)}{h}\\\\\n&=\\lim_{h \\to 0} \\frac{f((a,b) + h(1,0)) - f(a,b)}{h}\\\\\n&=\\lim_{h \\to 0} \\frac{f(\\mathbf{a} + h\\mathbf{i}) - f(\\mathbf{a})}{h}\n\\end{align*}\\]\nSimilarly, we have:\n\\[\\begin{align*}\n\\frac{\\partial f}{\\partial y}(a,b) = \\lim_{h\\to 0} \\frac{f(\\mathbf{a} + h\\mathbf{j})-f(\\mathbf{a})}{h}\n\\end{align*}\\]\nWriting partial derivatives as we have enables us to see that they are special cases of a more general type of derivative. Suppose \\(\\mathbf{v}\\) is a unit vector in \\(\\mathbf{R}^2\\). The quantity:\n\\[\\begin{align*}\n\\lim_{h \\to 0} \\frac{f(\\mathbf{a} + h\\mathbf{v}) - f(\\mathbf{a})}{h}\n\\end{align*}\\]\nis nothing more than the rate of change of \\(f\\) as we move infinitesimally from \\(\\mathbf{a} = (a,b)\\) in the direction specified by \\(\\mathbf{v}=(A,B) = A\\mathbf{i} + B\\mathbf{j}\\).\nDefinition. Let \\(\\mathbf{v}\\in \\mathbf{R}^n\\) be any unit vector, then the directional derivative of \\(f\\) at \\(\\mathbf{a}\\) in the direction of \\(\\mathbf{v}\\), denoted \\(D_{\\mathbf{v}}f(\\mathbf{a})\\) is:\n\\[\\begin{align*}\nD_{\\mathbf{v}}f(\\mathbf{a}) = \\lim_{h \\to 0} \\frac{f(\\mathbf{a} + h\\mathbf{v}) - f(\\mathbf{a})}{h}\n\\end{align*}\\]\nLet’s define a new function \\(F\\) of a single variable \\(t\\), by holding everything else constant:\n\\[\\begin{align*}\nF(t) = f(\\mathbf{a} + t\\mathbf{v})\n\\end{align*}\\]\nThen, by the definition of directional derivatives, we have:\n\\[\\begin{align*}\nD_{\\mathbf{v}}f(\\mathbf{a}) &= \\lim_{t\\to 0} \\frac{f(\\mathbf{a} + t\\mathbf{v}) - f(\\mathbf{a})}{t}\\\\\n&= \\lim_{t\\to 0} \\frac{F(t) - F(0)}{t - 0} \\\\\n&= F'(0)\n\\end{align*}\\]\nThat is:\n\\[\\begin{align*}\nD_{\\mathbf{v}}f(\\mathbf{a}) = \\frac{d}{dt} f(\\mathbf{a} + t\\mathbf{v})\\vert_{t=0}\n\\end{align*}\\]\nLet \\(\\mathbf{x}(t) = \\mathbf{a}+t\\mathbf{v}\\). Then, by the chain rule:\n\\[\\begin{align*}\n\\frac{d}{dt} f(\\mathbf{a} + t\\mathbf{v}) &= Df(\\mathbf{x}) D\\mathbf{x}(t) \\\\\n&= \\nabla f(\\mathbf{x}) \\cdot \\mathbf{v}\n\\end{align*}\\]\nThis equation emphasizes the geometry of the situation. The directional derivative is just the dot product of the gradient vector and the direction vector \\(\\mathbf{v}\\).\nTheorem. Let \\(f:X\\to\\mathbf{R}\\) be differentiable at \\(\\mathbf{a}\\in X\\). Then, the directional derivative \\(D_{\\mathbf{v}}f(\\mathbf{a})\\) exists for all directions \\(\\mathbf{v}\\in\\mathbf{R}^n\\) and moreover we have:\n\\[\\begin{align*}\nD_{\\mathbf{v}}f(\\mathbf{a}) = \\nabla f(\\mathbf{x})\\cdot \\mathbf{v}\n\\end{align*}\\]\n\n\n\nSuppose you are traveling in space near the planet Nilrebo and that one of your spaceship’s instruments measures the external atmospheric pressure on your ship as a function \\(f(x,y,z)\\) of position. Assume quite reasonably that this function is differentiable. Then, the directional derivative exists and if you travel from point \\(\\mathbf{a}=(a,b,c)\\) in the direction of the unit vector \\(\\mathbf{u}=u\\mathbf{i}+v\\mathbf{j}+w\\mathbf{k}\\), the rate of change of pressure is given by:\n\\[\\begin{align*}\nD_{\\mathbf{u}}f(\\mathbf{a}) = \\nabla f(\\mathbf{a}) \\cdot \\mathbf{u} = ||\\nabla f(\\mathbf{a})|| \\cdot ||\\mathbf{u}|| \\cos \\theta\n\\end{align*}\\]\nwhere \\(\\theta\\) is the angle between \\(\\mathbf{u}\\) and the gradient vector \\(\\nabla f(\\mathbf{a})\\). Because, \\(-1 \\leq \\cos \\theta \\leq 1\\), and \\(||\\mathbf{u}||=1\\), we have:\n\\[\\begin{align*}\n- ||\\nabla f(\\mathbf{a})|| \\leq D_{\\mathbf{u}}f(\\mathbf{a}) \\leq ||\\nabla f(\\mathbf{a})||\n\\end{align*}\\]\nMoreover, \\(\\cos \\theta = 1\\) when \\(\\theta = 0\\) and \\(\\cos \\theta = -1\\) when \\(\\theta = \\pi\\).\nTheorem. The directional derivative \\(D_{\\mathbf{u}}f(\\mathbf{a})\\) is maximized, with respect to the direction, when \\(\\mathbf{u}\\) points in the direction of the gradient vector \\(f(\\mathbf{a})\\) and is minimized when \\(\\mathbf{u}\\) points in the opposite direction. Furthermore, the maximum and minimum values of \\(D_{\\mathbf{u}}f(\\mathbf{a})\\) are \\(||\\nabla f(\\mathbf{a})||\\) and \\(-||\\nabla f(\\mathbf{a})||\\).\nTheorem Let \\(f:X \\subseteq \\mathbf{R}^n \\to \\mathbf{R}\\) be a function of class \\(C^1\\). If \\(\\mathbf{x}_0\\) is a point on the level set \\(S=\\{\\mathbf{x} \\in X | f(\\mathbf{x}) = c\\}\\), then the gradient vector \\(\\nabla f(\\mathbf{x}_0) \\in \\mathbf{R}^n\\) is perpendicular to \\(S\\).\nProof. We need to establish the following: if \\(\\mathbf{v}\\) is any vector tangent to \\(S\\) at \\(\\mathbf{x}_0\\), then \\(\\nabla f(\\mathbf{x}_0)\\) is perpendicular to \\(\\mathbf{v}\\) (i.e. \\(\\nabla f(\\mathbf{x}_0) \\cdot \\mathbf{v} = 0\\)). By a tangent vector to \\(S\\) at \\(\\mathbf{x}_0\\), we mean that \\(\\mathbf{v}\\) is the velocity vector of a curve \\(C\\) that lies in \\(S\\) and passes through \\(\\mathbf{x}_0\\).\nLet \\(C\\) be given parametrically by \\(\\mathbf{x}(t)=(x_1(t),\\ldots,x_n(t))\\) where \\(a &lt; t &lt; b\\) and \\(\\mathbf{x}(t_0) = \\mathbf{x}_0\\) for some number \\(t_0\\) in \\((a,b)\\).\n\\[\\begin{align*}\n\\frac{d}{dt}[f(\\mathbf{x}(t))] &= Df(\\mathbf{x}) \\cdot \\mathbf{x}'(t)\\\\\n&= \\nabla f(\\mathbf{x}) \\cdot \\mathbf{v}\n\\end{align*}\\]\nEvaluation at \\(t = t_0\\), yields:\n\\[\\begin{align*}\n\\nabla f (\\mathbf{x}(t_0)) \\cdot \\mathbf{x}'(t_0) = \\nabla f(\\mathbf{x}_0) \\cdot \\mathbf{v}\n\\end{align*}\\]\nOn the other hand, since \\(C\\) is contained in \\(S\\), \\(f(\\mathbf{x})=c\\). So,\n\\[\\begin{align*}\n\\frac{d}{dt}[f(\\mathbf{x}(t))] &= \\frac{d}{dt}[c] = 0\n\\end{align*}\\]\nPutting the above two facts together, we have the desired result."
  },
  {
    "objectID": "posts/optimization_algorithms/index.html#gradient-vector",
    "href": "posts/optimization_algorithms/index.html#gradient-vector",
    "title": "Optimization Algorithms",
    "section": "",
    "text": "Definition. Let \\(f:\\mathbf{R}^n \\to \\mathbf{R}\\) be a scalar-valued function. The gradient vector of \\(f\\) is defined as:\n\\[\\begin{align*}\n\\nabla f(\\mathbf{x}) = \\left[\\frac{\\partial f}{\\partial x_1},\\frac{\\partial f}{\\partial x_2},\\ldots,\\frac{\\partial f}{\\partial x_n}\\right]\n\\end{align*}\\]\nThe graph of the function \\(f:\\mathbf{R}^n \\to \\mathbf{R}\\) is the hypersurface in \\(\\mathbf{R}^{n+1}\\) given by the equation \\(x_{n+1}=f(x_1,\\ldots,x_n)\\).\nDefinition. \\(f\\) is said to be differentiable at \\(\\mathbf{a}\\) if all the partial derivatives \\(f_{x_i}(\\mathbf{a})\\) exist and if the function \\(h(\\mathbf{x})\\) defined by:\n\\[\\begin{align*}\nh(\\mathbf{x}) = f(\\mathbf{a}) + \\nabla f(\\mathbf{a})\\cdot (\\mathbf{x}-\\mathbf{a})\n\\end{align*}\\]\nis a good linear approximation to \\(f\\) near \\(a\\), meaning that:\n\\[\\begin{align*}\nL = \\lim_{\\mathbf{x} \\to \\mathbf{a}} \\frac{f(\\mathbf{x}) - h(\\mathbf{x})}{||\\mathbf{x} - \\mathbf{a}||} = 0\n\\end{align*}\\]\nIf \\(f\\) is differentiable at \\(\\mathbf{a},f(\\mathbf{a})\\), then the hypersurface determined by the graph has a tangent hyperplane at \\((\\mathbf{a},f(\\mathbf{a}))\\) given by the equation:\n\\[\\begin{align*}\nh(\\mathbf{x}) = f(\\mathbf{a}) + \\nabla f(\\mathbf{a})\\cdot (\\mathbf{x}-\\mathbf{a})\n\\end{align*}\\]\n\n\nLet \\(f(x,y)\\) be a scalar-valued function of two variables. We understand the partial derivative \\(\\frac{\\partial f}{\\partial x}(a,b)\\) as the slope at the point \\((a,b,f(a,b))\\) of the curve obtained as the intersection of the surface \\(z=f(x,y)\\) and the plane \\(y=b\\). The other partial derivative has a geometric interpretation. However, the surface \\(z=f(x,y)\\) contains infinitely many curves passing through \\((a,b,f(a,b))\\) whose slope we might choose to measure. The directional derivative enables us to do this.\nIntuitively, \\(\\frac{\\partial f}{\\partial x}(a,b)\\) is as the rate of change of \\(f\\) as we move infinitesimally from \\(\\mathbf{a}=(a,b)\\) in the \\(\\mathbf{i}\\) direction.\nMathematically, by the definition of the derivative of \\(f\\):\n\\[\\begin{align*}\n\\frac{\\partial f}{\\partial x}(a,b) &= \\lim_{h \\to 0} \\frac{f(a+h,b) - f(a,b)}{h}\\\\\n&=\\lim_{h \\to 0} \\frac{f((a,b) + (h,0)) - f(a,b)}{h}\\\\\n&=\\lim_{h \\to 0} \\frac{f((a,b) + h(1,0)) - f(a,b)}{h}\\\\\n&=\\lim_{h \\to 0} \\frac{f(\\mathbf{a} + h\\mathbf{i}) - f(\\mathbf{a})}{h}\n\\end{align*}\\]\nSimilarly, we have:\n\\[\\begin{align*}\n\\frac{\\partial f}{\\partial y}(a,b) = \\lim_{h\\to 0} \\frac{f(\\mathbf{a} + h\\mathbf{j})-f(\\mathbf{a})}{h}\n\\end{align*}\\]\nWriting partial derivatives as we have enables us to see that they are special cases of a more general type of derivative. Suppose \\(\\mathbf{v}\\) is a unit vector in \\(\\mathbf{R}^2\\). The quantity:\n\\[\\begin{align*}\n\\lim_{h \\to 0} \\frac{f(\\mathbf{a} + h\\mathbf{v}) - f(\\mathbf{a})}{h}\n\\end{align*}\\]\nis nothing more than the rate of change of \\(f\\) as we move infinitesimally from \\(\\mathbf{a} = (a,b)\\) in the direction specified by \\(\\mathbf{v}=(A,B) = A\\mathbf{i} + B\\mathbf{j}\\).\nDefinition. Let \\(\\mathbf{v}\\in \\mathbf{R}^n\\) be any unit vector, then the directional derivative of \\(f\\) at \\(\\mathbf{a}\\) in the direction of \\(\\mathbf{v}\\), denoted \\(D_{\\mathbf{v}}f(\\mathbf{a})\\) is:\n\\[\\begin{align*}\nD_{\\mathbf{v}}f(\\mathbf{a}) = \\lim_{h \\to 0} \\frac{f(\\mathbf{a} + h\\mathbf{v}) - f(\\mathbf{a})}{h}\n\\end{align*}\\]\nLet’s define a new function \\(F\\) of a single variable \\(t\\), by holding everything else constant:\n\\[\\begin{align*}\nF(t) = f(\\mathbf{a} + t\\mathbf{v})\n\\end{align*}\\]\nThen, by the definition of directional derivatives, we have:\n\\[\\begin{align*}\nD_{\\mathbf{v}}f(\\mathbf{a}) &= \\lim_{t\\to 0} \\frac{f(\\mathbf{a} + t\\mathbf{v}) - f(\\mathbf{a})}{t}\\\\\n&= \\lim_{t\\to 0} \\frac{F(t) - F(0)}{t - 0} \\\\\n&= F'(0)\n\\end{align*}\\]\nThat is:\n\\[\\begin{align*}\nD_{\\mathbf{v}}f(\\mathbf{a}) = \\frac{d}{dt} f(\\mathbf{a} + t\\mathbf{v})\\vert_{t=0}\n\\end{align*}\\]\nLet \\(\\mathbf{x}(t) = \\mathbf{a}+t\\mathbf{v}\\). Then, by the chain rule:\n\\[\\begin{align*}\n\\frac{d}{dt} f(\\mathbf{a} + t\\mathbf{v}) &= Df(\\mathbf{x}) D\\mathbf{x}(t) \\\\\n&= \\nabla f(\\mathbf{x}) \\cdot \\mathbf{v}\n\\end{align*}\\]\nThis equation emphasizes the geometry of the situation. The directional derivative is just the dot product of the gradient vector and the direction vector \\(\\mathbf{v}\\).\nTheorem. Let \\(f:X\\to\\mathbf{R}\\) be differentiable at \\(\\mathbf{a}\\in X\\). Then, the directional derivative \\(D_{\\mathbf{v}}f(\\mathbf{a})\\) exists for all directions \\(\\mathbf{v}\\in\\mathbf{R}^n\\) and moreover we have:\n\\[\\begin{align*}\nD_{\\mathbf{v}}f(\\mathbf{a}) = \\nabla f(\\mathbf{x})\\cdot \\mathbf{v}\n\\end{align*}\\]\n\n\n\nSuppose you are traveling in space near the planet Nilrebo and that one of your spaceship’s instruments measures the external atmospheric pressure on your ship as a function \\(f(x,y,z)\\) of position. Assume quite reasonably that this function is differentiable. Then, the directional derivative exists and if you travel from point \\(\\mathbf{a}=(a,b,c)\\) in the direction of the unit vector \\(\\mathbf{u}=u\\mathbf{i}+v\\mathbf{j}+w\\mathbf{k}\\), the rate of change of pressure is given by:\n\\[\\begin{align*}\nD_{\\mathbf{u}}f(\\mathbf{a}) = \\nabla f(\\mathbf{a}) \\cdot \\mathbf{u} = ||\\nabla f(\\mathbf{a})|| \\cdot ||\\mathbf{u}|| \\cos \\theta\n\\end{align*}\\]\nwhere \\(\\theta\\) is the angle between \\(\\mathbf{u}\\) and the gradient vector \\(\\nabla f(\\mathbf{a})\\). Because, \\(-1 \\leq \\cos \\theta \\leq 1\\), and \\(||\\mathbf{u}||=1\\), we have:\n\\[\\begin{align*}\n- ||\\nabla f(\\mathbf{a})|| \\leq D_{\\mathbf{u}}f(\\mathbf{a}) \\leq ||\\nabla f(\\mathbf{a})||\n\\end{align*}\\]\nMoreover, \\(\\cos \\theta = 1\\) when \\(\\theta = 0\\) and \\(\\cos \\theta = -1\\) when \\(\\theta = \\pi\\).\nTheorem. The directional derivative \\(D_{\\mathbf{u}}f(\\mathbf{a})\\) is maximized, with respect to the direction, when \\(\\mathbf{u}\\) points in the direction of the gradient vector \\(f(\\mathbf{a})\\) and is minimized when \\(\\mathbf{u}\\) points in the opposite direction. Furthermore, the maximum and minimum values of \\(D_{\\mathbf{u}}f(\\mathbf{a})\\) are \\(||\\nabla f(\\mathbf{a})||\\) and \\(-||\\nabla f(\\mathbf{a})||\\).\nTheorem Let \\(f:X \\subseteq \\mathbf{R}^n \\to \\mathbf{R}\\) be a function of class \\(C^1\\). If \\(\\mathbf{x}_0\\) is a point on the level set \\(S=\\{\\mathbf{x} \\in X | f(\\mathbf{x}) = c\\}\\), then the gradient vector \\(\\nabla f(\\mathbf{x}_0) \\in \\mathbf{R}^n\\) is perpendicular to \\(S\\).\nProof. We need to establish the following: if \\(\\mathbf{v}\\) is any vector tangent to \\(S\\) at \\(\\mathbf{x}_0\\), then \\(\\nabla f(\\mathbf{x}_0)\\) is perpendicular to \\(\\mathbf{v}\\) (i.e. \\(\\nabla f(\\mathbf{x}_0) \\cdot \\mathbf{v} = 0\\)). By a tangent vector to \\(S\\) at \\(\\mathbf{x}_0\\), we mean that \\(\\mathbf{v}\\) is the velocity vector of a curve \\(C\\) that lies in \\(S\\) and passes through \\(\\mathbf{x}_0\\).\nLet \\(C\\) be given parametrically by \\(\\mathbf{x}(t)=(x_1(t),\\ldots,x_n(t))\\) where \\(a &lt; t &lt; b\\) and \\(\\mathbf{x}(t_0) = \\mathbf{x}_0\\) for some number \\(t_0\\) in \\((a,b)\\).\n\\[\\begin{align*}\n\\frac{d}{dt}[f(\\mathbf{x}(t))] &= Df(\\mathbf{x}) \\cdot \\mathbf{x}'(t)\\\\\n&= \\nabla f(\\mathbf{x}) \\cdot \\mathbf{v}\n\\end{align*}\\]\nEvaluation at \\(t = t_0\\), yields:\n\\[\\begin{align*}\n\\nabla f (\\mathbf{x}(t_0)) \\cdot \\mathbf{x}'(t_0) = \\nabla f(\\mathbf{x}_0) \\cdot \\mathbf{v}\n\\end{align*}\\]\nOn the other hand, since \\(C\\) is contained in \\(S\\), \\(f(\\mathbf{x})=c\\). So,\n\\[\\begin{align*}\n\\frac{d}{dt}[f(\\mathbf{x}(t))] &= \\frac{d}{dt}[c] = 0\n\\end{align*}\\]\nPutting the above two facts together, we have the desired result."
  },
  {
    "objectID": "posts/optimization_algorithms/index.html#gradient-descent---naive-implementation",
    "href": "posts/optimization_algorithms/index.html#gradient-descent---naive-implementation",
    "title": "Optimization Algorithms",
    "section": "Gradient Descent - Naive Implementation",
    "text": "Gradient Descent - Naive Implementation\nBeginning at \\(\\mathbf{x}_0\\), optimization algorithms generate a sequence of iterates \\(\\{\\mathbf{x}_k\\}_{k=0}^{\\infty}\\) that terminate when no more progress can be made or it seems a solution point has been approximated with sufficient accuracy. The gradient descent method is an optimization algorithm that moves along \\(\\mathbf{d}_k = -\\nabla f(\\mathbf{x}_k)\\) at every step. Thus,\n\\[\\begin{align*}\n\\mathbf{x}_{k+1} = \\mathbf{x}_k - \\alpha_k \\mathbf{d}_k\n\\end{align*}\\]\nIt can choose the step length \\(\\alpha_k\\) in a variety of ways. One advantage of steepest descent is that it requires the calculation of the gradient \\(\\nabla f(\\mathbf{x}_k)\\), but not of the second derivatives. However, it can be excruciatingly slow on difficult problems.\n\n%load_ext itikz\n\n\nfrom typing import Callable\nimport numpy as np\n\n\ndef gradient_descent(\n    func: Callable[[float], float],\n    alpha: float,\n    xval_0: np.array,\n    epsilon: float = 1e-5,\n    n_iter: int = 10000,\n    debug_step: int = 100,\n):\n    \"\"\"\n    The gradient descent algorithm.\n    \"\"\"\n\n    xval_hist = []\n    funcval_hist = []\n\n    xval_curr = xval_0\n    error = 1.0\n    i = 0\n\n    while np.linalg.norm(error) &gt; epsilon and i &lt; n_iter:\n        # Save down x_curr and func(x_curr)\n        xval_hist.append(xval_curr)\n        funcval_hist.append(func(xval_curr))\n\n        # Calculate the forward difference\n        bump = 0.001\n        num_dims = len(xval_curr)\n        xval_bump = xval_curr + np.eye(num_dims) * bump\n        xval_nobump = np.full((num_dims, num_dims), xval_curr)\n\n        grad = np.array(\n            [\n                (func(xval_h) - func(xval)) / bump\n                for xval_h, xval in zip(xval_bump, xval_nobump)\n            ]\n        )\n\n        # Compute the next iterate\n        xval_next = xval_curr - alpha * grad\n\n        # Compute the error vector\n        error = xval_next - xval_curr\n\n        if i % debug_step == 0:\n            print(\n                f\"x[{i}] = {xval_curr}, f({xval_curr}) = {func(xval_curr)}, f'({xval_curr}) = {grad}, error={error}\"\n            )\n\n        xval_curr = xval_next\n        i += 1\n\n    return xval_hist, funcval_hist\n\nOne infamous test function is the Rosenbrock function defined as:\n\\[\\begin{align*}\nf(x,y) = (a-x)^2 + b(y-x^2)^2\n\\end{align*}\\]\n\ndef rosenbrock(x):\n    return 1*(1-x[0])**2 + 100*(x[1]-x[0]**2)**2\n\ndef f(x):\n    return x[0]**2 + x[1]**2\n\nHere is the plot of the Rosenbrock function with parameters \\(a=1,b=100\\).\n\n\nShow the code\n%%itikz --temp-dir --tex-packages=tikz,pgfplots --tikz-libraries=arrows --implicit-standalone\n\\begin{tikzpicture}[scale=1.5]\n\\begin{axis}[\n     title={Plot of $f(x,y)=(1-x)^2 + 100(y-x^2)^2$},\n]\n    \\addplot3 [surf] {(1-x)^2 + 100*(y-x^2)^2};\n\\end{axis}\n\\end{tikzpicture}\n\n\n\n\n\n\nx_history, f_x_history = gradient_descent(\n    func=rosenbrock,\n    alpha=0.001,\n    xval_0=np.array([-2.0, 2.0]),\n    epsilon=1e-7,\n    debug_step=1000,\n)\n\nprint(f\"x* = {x_history[-1]}, f(x*)={f_x_history[-1]}\")\n\nx[0] = [-2.  2.], f([-2.  2.]) = 409.0, f'([-2.  2.]) = [-1603.9997999  -399.9      ], error=[1.6039998 0.3999   ]\nx[1000] = [-0.34194164  0.12278388], f([-0.34194164  0.12278388]) = 1.804241076974863, f'([-0.34194164  0.12278388]) = [-1.8359394   1.27195859], error=[ 0.00183594 -0.00127196]\nx[2000] = [0.59082668 0.34719456], f([0.59082668 0.34719456]) = 0.16777685109400048, f'([0.59082668 0.34719456]) = [-0.23242066 -0.27632251], error=[0.00023242 0.00027632]\nx[3000] = [0.71914598 0.51617916], f([0.71914598 0.51617916]) = 0.0789773438798074, f'([0.71914598 0.51617916]) = [-0.06806067 -0.09835534], error=[6.80606659e-05 9.83553399e-05]\nx[4000] = [0.7626568  0.58094326], f([0.7626568  0.58094326]) = 0.05638109494458334, f'([0.7626568  0.58094326]) = [-0.02638936 -0.04042575], error=[2.63893643e-05 4.04257465e-05]\nx[5000] = [0.78028032 0.60825002], f([0.78028032 0.60825002]) = 0.04831123625687607, f'([0.78028032 0.60825002]) = [-0.01115051 -0.01747329], error=[1.11505139e-05 1.74732947e-05]\nx[6000] = [0.78785296 0.62017375], f([0.78785296 0.62017375]) = 0.045035368749296534, f'([0.78785296 0.62017375]) = [-0.00487137 -0.00770719], error=[4.87136843e-06 7.70718502e-06]\nx[7000] = [0.79118466 0.62545602], f([0.79118466 0.62545602]) = 0.04363059164103049, f'([0.79118466 0.62545602]) = [-0.00215834 -0.00342913], error=[2.1583377e-06 3.4291304e-06]\nx[8000] = [0.79266536 0.62781071], f([0.79266536 0.62781071]) = 0.04301342477692797, f'([0.79266536 0.62781071]) = [-0.00096218 -0.00153153], error=[9.62177510e-07 1.53153219e-06]\nx[9000] = [0.79332635 0.62886327], f([0.79332635 0.62886327]) = 0.042739342077472306, f'([0.79332635 0.62886327]) = [-0.0004301  -0.00068518], error=[4.30102710e-07 6.85176669e-07]\nx* = [0.7936218  0.62933403], f(x*)=0.04261711392593988"
  },
  {
    "objectID": "posts/optimization_algorithms/index.html#convergence.",
    "href": "posts/optimization_algorithms/index.html#convergence.",
    "title": "Optimization Algorithms",
    "section": "Convergence.",
    "text": "Convergence.\nWhen applying gradient descent in practice, we need to choose a value for the learning rate parameter \\(\\alpha\\). An error surface \\(E\\) is usually a convex function on the weight space \\(\\mathbf{w}\\). Intuitively, we might expect that increasing the value of \\(\\alpha\\) should lead to bigger steps through the weight space and hence faster convergence. However, the successive steps oscillate back and forth across the valley, and if we increase \\(\\alpha\\) too much, these oscillations will become divergent. Because \\(\\alpha\\) must be kept sufficiently small to avoid divergent oscillations across the valley, progress along the valley is very slow. Gradient descent then takes many small steps to reach the minimum and is a very inefficient procedure.\nWe can gain deeper insight into this problem, by considering a quadratic approximation to the error function in the neighbourhood of the minimum. Let the error function be given by:\n\\[\\begin{align*}\nf(w) = \\frac{1}{2}w^T A w - b^T w, \\quad w\\in\\mathbf{R}^n\n\\end{align*}\\]\nwhere \\(A\\) is symmetric and \\(A \\succ 0\\).\nDifferentiating on both sides, the gradient of the error function is:\n\\[\\begin{align*}\n\\nabla f(w) = Aw - b\n\\end{align*}\\]\nand the hessian is:\n\\[\\begin{align*}\n\\nabla^2 f(w) = A\n\\end{align*}\\]\nThe critical points of \\(f\\) are given by:\n\\[\\begin{align*}\n\\nabla f(w^*) &= 0\\\\\nAw^{*} - b &= 0\\\\\nw^{*} &= A^{-1}b\n\\end{align*}\\]\nand\n\\[\\begin{align*}\nf(w^{*}) &= \\frac{1}{2}(A^{-1}b)^T A (A^{-1}b) - b^T (A^{-1} b)\\\\\n&= \\frac{1}{2}b^T A^{-1} A A^{-1} b -b^T A^{-1} b \\\\\n&= \\frac{1}{2}b^T A^{-1} b - b^T A^{-1} b \\\\\n&= -\\frac{1}{2}b^T A^{-1} b\n\\end{align*}\\]\nTherefore, the iterates of \\(w\\) are:\n\\[\\begin{align*}\nw^{(k+1)} = w^{(k)} - \\alpha(Aw^{(k)} - b)\n\\end{align*}\\]\nBy the spectral theorem, every symmetric matrix \\(A\\) is orthogonally diagonalizable. So, \\(A\\) admits a factorization:\n\\[\\begin{align*}\nA = Q \\Lambda Q^T\n\\end{align*}\\]\nwhere \\(\\Lambda = diag(\\lambda_1,\\ldots,\\lambda_n)\\) and as per convention, we will assume that \\(\\lambda_i\\)are sorted from smallest \\(\\lambda_1\\) to biggest \\(\\lambda_n\\).\nRecall that \\(Q=[q_1,\\ldots,q_n]\\), where \\(q_i\\) are the eigenvectors of \\(A\\) and \\(Q\\) is the change of basis matrix from the standard basis to the eigenvector basis. So, if \\(a \\in \\mathbf{R}^n\\) are the coordinates of a vector in the standard basis and \\(b \\in \\mathbf{R}^n\\) are its coordinates in the eigenvector basis, then \\(a = Qb\\) or \\(b=Q^T a\\).\nLet \\(x^{(k)}=Q^T(w^{(k)}-w^{*})\\). Equivalently, \\(w^{(k)} = Qx^{(k)} + w^{*}\\). Thus, we are shifting the origin to \\(w^{*}\\) and changing the axes to be aligned with the eigenvectors. In this new coordinate system,\n\\[\\begin{align*}\nQx^{(k+1)} + w^{*} &= Qx^{(k)} + w^{*} - \\alpha(AQx^{(k)} + Aw^{*} - b)\\\\\nQx^{(k+1)} &= Qx^{(k)} - \\alpha(AQx^{(k)} + Aw^{*} - b)\\\\\nQx^{(k+1)} &= Qx^{(k)} - \\alpha(AQx^{(k)} + A(A^{-1}b) - b)\\\\\n& \\quad \\{\\text{Substituting } w^{*}=A^{-1}b \\}\\\\\nQx^{(k+1)} &= Qx^{(k)} - \\alpha(AQx^{(k)})\\\\\nQx^{(k+1)} &= Qx^{(k)} - \\alpha(Q\\Lambda Q^T Qx^{(k)})\\\\\n& \\quad \\{\\text{Substituting } A = Q\\Lambda Q^T \\}\\\\\nQx^{(k+1)} &= Qx^{(k)} - \\alpha(Q\\Lambda x^{(k)})\\\\\n& \\quad \\{\\text{Using } Q^T Q = I \\}\\\\\nx^{(k+1)} &= x^{(k)} - \\alpha\\Lambda x^{(k)}\n\\end{align*}\\]\nThe \\(i\\)-th coordinate of this recursive system is given by:\n\\[\\begin{align*}\nx_i^{(k+1)} &= x_i^{(k)} - \\alpha\\lambda_i x_i^{(k)}\\\\\n&= (1-\\alpha \\lambda_i)x_i^{(k)}\\\\\n&= (1-\\alpha \\lambda_i)^{k+1}x_i^{(0)}\n\\end{align*}\\]\nMoving back to our original space \\(w\\), we can see that:\n\\[\\begin{align*}\nw^{(k)} - w^{*} = Qx^{(k)} &= \\sum_i q_i x_i^{(k)}\\\\\n&= \\sum_i q_i (1-\\alpha \\lambda_i)^{k+1} x_i^{(0)}\n\\end{align*}\\]\nand there we have it - gradient descent in the closed form.\n\nDecomposing the error\nThe above equation admits a simple interpretation. Each element of \\(x^{(0)}\\) is the component of the error in the initial guess in \\(Q\\)-basis. There are \\(n\\) such errors and each of these errors follow their own, solitary path to the minimum, decreasing exponentially with a compounding rate of \\(1-\\alpha \\lambda_i\\). The closer that number is to \\(1\\), the slower it converges.\nFor most step-sizes, the eigenvectors with the largest eigenvalues converge the fastest. This triggers an explosion of progress in the first few iterations, before things slow down, as the eigenvectors with smaller eigenvalues’ struggles are revealed. It’s easy to visualize this - look at the sequences of \\(\\frac{1}{2^k}\\) and \\(\\frac{1}{3^k}\\).\n\n\nShow the code\n%%itikz --temp-dir --tex-packages=tikz,pgfplots --tikz-libraries=arrows --implicit-standalone\n\\begin{tikzpicture}[scale=1.5]\n\\begin{axis}[\n     title={Comparison of the rates of convergence},\n     xlabel={$n$},\n     ylabel={$f(n)$}\n]\n    \\addplot [domain=0:5,samples=400,blue] {1/(2^x)} node [midway,above] {$2^{-n}$};\n    \\addplot [domain=0:5,samples=400,red] {1/(3^x)} node [midway,below] {$3^{-n}$};\n\\end{axis}\n\\end{tikzpicture}\n\n\n\n\n\n\n\nChoosing a step size\nThe above analysis gives us immediate guidance as to how to set a step-size \\(\\alpha\\). In order to converge, each \\(|1-\\alpha \\lambda_i| &lt; 1\\). All workable step-sizes, therefore, fall in the interval:\n\\[\\begin{align*}\n-1 &\\leq 1 - \\alpha \\lambda_i &\\leq 1 \\\\\n-2 &\\leq - \\alpha \\lambda_i &\\leq 0 \\\\\n0 &\\leq \\alpha \\lambda_i &\\leq 2\n\\end{align*}\\]\nBecause \\((1-\\alpha \\lambda_i)\\) could be either positive or negative, the overall convergence rate is determined by the slowest error component, which must be either \\(\\lambda_1\\) or \\(\\lambda_n\\):\n\\[\\begin{align*}\n\\text{rate}(\\alpha) = \\max \\{|1-\\alpha \\lambda_1|,|1-\\alpha \\lambda_n|\\}\n\\end{align*}\\]\nThe optimal learning rate is that which balances the convergence rate. Setting the convergence rate to be equal for the smallest and largest eigenvalues, we can solve for the optimal step size.\n\\[\\begin{align*}\n|1- \\alpha \\lambda_1| = |1- \\alpha \\lambda_n|\n\\end{align*}\\]\nAssuming \\(\\lambda_1 \\neq \\lambda_n\\):\n\\[\\begin{align*}\n1 - \\alpha \\lambda_1 &= -1 + \\alpha \\lambda_n\\\\\n\\alpha (\\lambda_1 + \\lambda_n) &= 2\\\\\n\\alpha^* &= \\frac{2}{\\lambda_1 + \\lambda_n}\n\\end{align*}\\]\nSo, the optimal convergence rate equals:\n\\[\\begin{align*}\n\\max \\{|1-\\alpha \\lambda_1|,|1-\\alpha \\lambda_n|\\} &= 1 - \\frac{2\\lambda_1}{\\lambda_1 + \\lambda_n} \\\\\n&= \\frac{\\lambda_n - \\lambda_1}{\\lambda_n + \\lambda_1}\\\\\n&= \\frac{\\kappa - 1}{\\kappa + 1}\n\\end{align*}\\]\nThe ratio \\(\\kappa = \\lambda_n / \\lambda_1\\) determines the convergence rate of the problem. Recall that the level curves of the error surface are ellipsoids. Hence, a poorly conditioned Hessian results in stretching one of the axes of the ellipses, and taken to its extreme, the contours are almost parallel. Since gradient vectors are orthogonal to the level curves, the optimizer keeps pin-balling between parallel lines and takes forever to reach the center."
  },
  {
    "objectID": "posts/optimization_algorithms/index.html#stochastic-gradient-descentsgd",
    "href": "posts/optimization_algorithms/index.html#stochastic-gradient-descentsgd",
    "title": "Optimization Algorithms",
    "section": "Stochastic Gradient Descent(SGD)",
    "text": "Stochastic Gradient Descent(SGD)\nIn machine learning applications, we typically want to minimize the loss function \\(\\mathcal{L}(w)\\) that has the form of a sum:\n\\[\\begin{align*}\n\\mathcal{L}(w) = \\frac{1}{n}\\sum_i L_i(w)\n\\end{align*}\\]\nwhere the weights \\(w\\) (and the biases) are to be estimated. Each summand function \\(L_i\\) is typically associated with the \\(i\\)-th sample in the data-set used for training.\nWhen we minimize the above function with respect to the weights and biases, a standard gradient descent method would perform the following operations:\n\\[\\begin{align*}\nw_{k+1} := w_k - \\alpha_k \\nabla \\mathcal{L}(w_{k}) = w_k - \\frac{\\alpha_k}{n}\\sum_{i} \\nabla L_i(w_{k})\n\\end{align*}\\]\nIn the stochastic (or online) gradient descent algorithm, the true gradient of \\(\\mathcal{L}(w)\\) is approximated by the gradient at a single sample:\n\\[\\begin{align*}\nw_{k+1} := w_k - \\alpha_k \\nabla \\mathcal{L}(w_{k}) = w_k - \\alpha_k \\nabla L_i(w_{k})\n\\end{align*}\\]"
  },
  {
    "objectID": "posts/optimization_algorithms/index.html#sgdoptimizer-class",
    "href": "posts/optimization_algorithms/index.html#sgdoptimizer-class",
    "title": "Optimization Algorithms",
    "section": "SGDOptimizer class",
    "text": "SGDOptimizer class\nWe are now in a position to code the SGDOptimizer class.\n\n# Global imports\nimport numpy as np\nimport nnfs\nimport matplotlib.pyplot as plt\nfrom nnfs.datasets import spiral_data\n\nfrom dense_layer import DenseLayer\nfrom relu_activation import ReLUActivation\nfrom softmax_activation import SoftmaxActivation\n\nfrom loss import Loss\nfrom categorical_cross_entropy_loss import CategoricalCrossEntropyLoss\nfrom categorical_cross_entropy_softmax import CategoricalCrossEntropySoftmax\n\n\nclass SGDOptimizer:\n\n    # Initialize the optimizer\n    def __init__(self, learning_rate=1.0):\n        self.learning_rate = learning_rate\n\n    # Update the parameters\n    def update_params(self, layer):\n        layer.weights -= self.learning_rate * layer.dloss_dweights\n        layer.biases -= self.learning_rate * layer.dloss_dbiases\n\nLet’s play around with our optimizer.\n\n# Create dataset\nX, y = spiral_data(samples=100, classes=3)\n\n# Create a DenseLayer with 2 input features and 64 neurons\ndense1 = DenseLayer(2, 64)\n\n# Create ReLU Activation (to be used with DenseLayer 1)\nactivation1 = ReLUActivation()\n\n# Create the second DenseLayer with 64 inputs and 3 output values\ndense2 = DenseLayer(64,3)\n\n# Create SoftmaxClassifer's combined loss and activation\nloss_activation = CategoricalCrossEntropySoftmax()\n\n# The next step is to create the optimizer object\noptimizer = SGDOptimizer()\n\nNow, we perform a forward pass of our sample data.\n\n# Perform a forward pass for our sample data\ndense1.forward(X)\n\n# Performs a forward pass through the activation function\n# takes the output of the first dense layer here\nactivation1.forward(dense1.output)\n\n# Performs a forward pass through the second DenseLayer\ndense2.forward(activation1.output)\n\n# Performs a forward pass through the activation/loss function\n# takes the output of the second DenseLayer and returns the loss\nloss = loss_activation.forward(dense2.output, y)\n\n# Let's print the loss value\nprint(f\"Loss = {loss}\")\n\n# Now we do our backward pass \nloss_activation.backward(loss_activation.output, y)\ndense2.backward(loss_activation.dloss_dz)\nactivation1.backward(dense2.dloss_dinputs)\ndense1.backward(activation1.dloss_dz)\n\n# Then finally we use our optimizer to update the weights and biases\noptimizer.update_params(dense1)\noptimizer.update_params(dense2)\n\nLoss = 1.0986526582562541\n\n\nThis is everything we need to train our model!\nBut why would we only perform this optimization only once, when we can perform it many times by leveraging Python’s looping capabilities? We will repeatedly perform a forward pass, backward pass and optimization until we reach some stopping point. Each full pass through all of the training data is called an epoch.\nIn most deep learning tasks, a neural network will be trained for multiple epochs, though the ideal scenario would be to have a perfect model with ideal weights and biases after only one epoch. To add multiple epochs of our training into our code, we will initialize our model and run a loop around all the code performing the forward pass, backward pass and optimization calculations.\n\n# Create dataset\nX, y = spiral_data(samples=100, classes=3)\n\n# Create a dense layer with 2 input features and 64 output values\ndense1 = DenseLayer(2, 64)\n\n# Create ReLU Activation (to be used with the DenseLayer)\nactivation1 = ReLUActivation()\n\n# Create a second DenseLayer with 64 input features (as we take\n# output of the previous layer here) and 3 output values (output values)\ndense2 = DenseLayer(64, 3)\n\n# Create Softmax classifier's combined loss and activation\nloss_activation = CategoricalCrossEntropySoftmax()\n\n# Create optimizer\noptimizer = SGDOptimizer()\n\n# Train in loop\nfor epoch in range(10001):\n\n    # Perform a forward pass of our training data through this layer\n    dense1.forward(X)\n\n    # Perform a forward pass through the activation function\n    # takes the output of the first dense layer here\n    activation1.forward(dense1.output)\n\n    # Perform a forward pass through second DenseLayer\n    # takes the outputs of the activation function of first layer as inputs\n    dense2.forward(activation1.output)\n\n    # Perform a forward pass through the activation/loss function\n    # takes the output of the second DenseLayer here and returns the loss\n    loss = loss_activation.forward(dense2.output, y)\n\n    if not epoch % 1000:\n        print(f\"Epoch: {epoch}, Loss: {loss: .3f}\")\n\n    # Backward pass\n    loss_activation.backward(loss_activation.output, y)\n    dense2.backward(loss_activation.dloss_dz)\n    activation1.backward(dense2.dloss_dinputs)\n    dense1.backward(activation1.dloss_dz)\n\n    # Update the weights and the biases\n    optimizer.update_params(dense1)\n    optimizer.update_params(dense2)\n\nEpoch: 0, Loss:  1.099\nEpoch: 1000, Loss:  1.029\nEpoch: 2000, Loss:  0.962\nEpoch: 3000, Loss:  0.848\nEpoch: 4000, Loss:  0.699\nEpoch: 5000, Loss:  0.544\nEpoch: 6000, Loss:  0.508\nEpoch: 7000, Loss:  0.478\nEpoch: 8000, Loss:  0.460\nEpoch: 9000, Loss:  0.443\nEpoch: 10000, Loss:  0.419\n\n\nOur neural network mostly stays stuck at around a loss of \\(1.0\\) and later around \\(0.85\\)-\\(0.90\\) Given that this loss didn’t decrease much, we can assume that this learning rate being too high, also caused the model to get stuck in a local minimum, which we’ll learn more about soon. Iterating over more epochs, doesn’t seem helpful at this point, which tells us that we’re likely stuck with our optimization. Does this mean that this is the most we can get from our optimizer on this dataset?\nRecall that we’re adjusting our weights and biases by applying some fraction, in this case \\(1.0\\) to the gradient and subtracting this from the weights and biases. This fraction is called the learning rate (LR) and is the primary adjustable parameter for the optimizer as it decreases loss."
  },
  {
    "objectID": "posts/optimization_algorithms/index.html#learning-rate-decay",
    "href": "posts/optimization_algorithms/index.html#learning-rate-decay",
    "title": "Optimization Algorithms",
    "section": "Learning Rate Decay",
    "text": "Learning Rate Decay\nThe idea of a learning rate decay is to start with a large learning rate, say \\(1.0\\) in our case and then decrease it during training. There are a few methods for doing this. One option is program a decay rate, which steadily decays the learning rate per batch or per epoch.\nLet’s plan to decay per step. This can also be referred to as \\(1/t\\) decaying or exponential decaying. Basically, we’re going to update the learning rate each step by the reciprocal of the step count fraction. This fraction is a new hyper parameter that we’ll add to the optimizer, called the learning rate decay.\n\ninitial_learning_rate = 1.0\nlearning_rate_decay = 0.1\n\nfor step in range(10):\n    learning_rate = initial_learning_rate * 1.0 / (1 + learning_rate_decay * step)\n    print(learning_rate)\n\n1.0\n0.9090909090909091\n0.8333333333333334\n0.7692307692307692\n0.7142857142857143\n0.6666666666666666\n0.625\n0.588235294117647\n0.5555555555555556\n0.5263157894736842\n\n\nThe derivative of the function \\(\\frac{1}{1+x}\\) is \\(-\\frac{1}{(1+x)^2}\\).\n\n\nShow the code\n%%itikz --temp-dir --tex-packages=tikz,pgfplots --tikz-libraries=arrows --implicit-standalone\n\\begin{tikzpicture}[scale=1.5]\n\\begin{axis}[\n     title={Plot of $f(x)=-\\frac{1}{(1+x)^2}$},\n     xlabel={$x$},\n     ylabel={$f(x)$}\n]\n    \\addplot [domain=0:1,samples=400] {-1/(( 1 + x)^2)};\n\\end{axis}\n\\end{tikzpicture}\n\n\n\n\n\nThe learning rate drops fast initially, but the change in the learning rate lowers in each step. We can update our SGDOptimizer class to allow for the learning rate decay.\n\nclass SGDOptimizer:\n\n    # Initial optimizer - set settings\n    # learning rate of 1. is default for this optimizer\n    def __init__(self, learning_rate=1.0, decay=0.0):\n        self.learning_rate = learning_rate\n        self.current_learning_rate = learning_rate\n        self.decay = decay\n        self.iterations = 0\n\n    # Call once before any parameter updates\n    def pre_update_params(self):\n        if self.decay:\n            self.current_learning_rate = self.learning_rate * (\n                1.0 / (1.0 + self.decay * self.iterations)\n            )\n\n    # Update parameters\n    def update_params(self, layer):\n        layer.weights += -self.current_learning_rate * layer.dloss_dweights\n        layer.biases += -self.current_learning_rate * layer.dloss_dbiases\n\n    def post_update_params(self):\n        self.iterations += 1\n\nLet’s use a decay rate of \\(0.01\\) and train our neural network again.\n\ndef train(decay):\n    # Create a dataset\n    X, y = spiral_data(samples=100, classes=3)\n\n    # Create a dense layer with 2 input features and 64 output values\n    dense1 = DenseLayer(2, 64)\n\n    # Create ReLU activation (to be used with the dense layer)\n    activation1 = ReLUActivation()\n\n    # Create second DenseLayer with 64 input features (as we take output of the\n    # previous layer here) and 3 output values\n    dense2 = DenseLayer(64, 3)\n\n    # Create Softmax classifier's combined loss and activation\n    loss_activation = CategoricalCrossEntropySoftmax()\n\n    # Create optimizer\n    optimizer = SGDOptimizer(learning_rate=1.0,decay=decay)\n\n    acc_vals = []\n    loss_vals = []\n    lr_vals = []\n\n    # Train in a loop\n    for epoch in range(10001):\n        # Perform a forward pass of our training data through this layer\n        dense1.forward(X)\n\n        # Perform a forward pass through the activation function\n        # takes the output of the first dense layer here\n        activation1.forward(dense1.output)\n\n        # Perform a forward pass through second DenseLayer\n        # takes the outputs of the activation function of first layer as inputs\n        dense2.forward(activation1.output)\n\n        # Perform a forward pass through the activation/loss function\n        # takes the output of the second DenseLayer here and returns the loss\n        loss = loss_activation.forward(dense2.output, y)\n\n        # Calculate accuracy from output of activation2 and targets\n        # Calculate values along the first axis\n        predictions = np.argmax(loss_activation.output, axis=1)\n        if len(y.shape) == 2:\n            y = np.argmax(y, axis=1)\n\n        accuracy = np.mean(predictions == y)\n\n        if epoch % 1000 == 0:\n            print(\n                f\"epoch: {epoch}, \\\n                acc : {accuracy:.3f}, \\\n                loss: {loss: .3f}, \\\n                lr : {optimizer.current_learning_rate}\"\n            )\n\n        acc_vals.append(accuracy)\n        loss_vals.append(loss)\n        lr_vals.append(optimizer.current_learning_rate)\n\n        # Backward pass\n        loss_activation.backward(loss_activation.output, y)\n        dense2.backward(loss_activation.dloss_dz)\n        activation1.backward(dense2.dloss_dinputs)\n        dense1.backward(activation1.dloss_dz)\n\n        # Update the weights and the biases\n        optimizer.pre_update_params()\n        optimizer.update_params(dense1)\n        optimizer.update_params(dense2)\n        optimizer.post_update_params()\n\n    return acc_vals, loss_vals, lr_vals\n\n\nacc_vals, loss_vals, lr_vals = train(decay=0.01)\n\nepoch: 0,                 acc : 0.333,                 loss:  1.099,                 lr : 1.0\nepoch: 1000,                 acc : 0.477,                 loss:  1.066,                 lr : 0.09099181073703366\nepoch: 2000,                 acc : 0.457,                 loss:  1.065,                 lr : 0.047641734159123386\nepoch: 3000,                 acc : 0.453,                 loss:  1.065,                 lr : 0.03226847370119393\nepoch: 4000,                 acc : 0.450,                 loss:  1.064,                 lr : 0.02439619419370578\nepoch: 5000,                 acc : 0.440,                 loss:  1.064,                 lr : 0.019611688566385566\nepoch: 6000,                 acc : 0.443,                 loss:  1.063,                 lr : 0.016396130513198885\nepoch: 7000,                 acc : 0.447,                 loss:  1.063,                 lr : 0.014086491055078181\nepoch: 8000,                 acc : 0.447,                 loss:  1.063,                 lr : 0.012347203358439314\nepoch: 9000,                 acc : 0.447,                 loss:  1.062,                 lr : 0.010990218705352238\nepoch: 10000,                 acc : 0.447,                 loss:  1.062,                 lr : 0.009901970492127933\n\n\n\n\nShow the code\nplt.grid(True)\nepochs = np.linspace(0,10000,10001)\nplt.ylabel('Accuracy')\nplt.xlabel('Epochs')\nplt.plot(epochs,acc_vals)\nplt.show()\n\n\n\n\n\n\n\nShow the code\nplt.grid(True)\nplt.ylabel('Loss')\nplt.xlabel('Epochs')\nplt.plot(epochs,loss_vals)\nplt.show()\n\n\n\n\n\n\n\nShow the code\nplt.grid(True)\nplt.ylabel(\"Learning rate\")\nplt.xlabel(\"Epochs\")\nplt.plot(epochs, lr_vals)\nplt.show()\n\n\n\n\n\nThe optimization algorithm appears to be stuck and the reason is because the learning rate decayed far too quickly and became too small, trapping the optimizer in some local minimum. We can, instead, try to decay a bit slower by making our decay a smaller number. For example, let’s go with \\(10^{-3}\\).\n\nacc_vals, loss_vals, lr_vals = train(decay=1e-3)\n\nepoch: 0,                 acc : 0.327,                 loss:  1.099,                 lr : 1.0\nepoch: 1000,                 acc : 0.410,                 loss:  1.066,                 lr : 0.5002501250625312\nepoch: 2000,                 acc : 0.413,                 loss:  1.055,                 lr : 0.33344448149383127\nepoch: 3000,                 acc : 0.457,                 loss:  1.014,                 lr : 0.25006251562890724\nepoch: 4000,                 acc : 0.527,                 loss:  0.968,                 lr : 0.2000400080016003\nepoch: 5000,                 acc : 0.547,                 loss:  0.935,                 lr : 0.16669444907484582\nepoch: 6000,                 acc : 0.563,                 loss:  0.918,                 lr : 0.1428775539362766\nepoch: 7000,                 acc : 0.573,                 loss:  0.900,                 lr : 0.12501562695336915\nepoch: 8000,                 acc : 0.577,                 loss:  0.882,                 lr : 0.11112345816201799\nepoch: 9000,                 acc : 0.590,                 loss:  0.860,                 lr : 0.1000100010001\nepoch: 10000,                 acc : 0.603,                 loss:  0.845,                 lr : 0.09091735612328393\n\n\n\n\nShow the code\nplt.grid(True)\nepochs = np.linspace(0,10000,10001)\nplt.ylabel('Accuracy')\nplt.xlabel('Epochs')\nplt.plot(epochs,acc_vals)\nplt.show()\n\n\n\n\n\n\n\nShow the code\nplt.grid(True)\nplt.ylabel('Loss')\nplt.xlabel('Epochs')\nplt.plot(epochs,loss_vals)\nplt.show()\n\n\n\n\n\n\n\nShow the code\nplt.grid(True)\nplt.ylabel(\"Learning rate\")\nplt.xlabel(\"Epochs\")\nplt.plot(epochs, lr_vals)\nplt.show()"
  },
  {
    "objectID": "posts/optimization_algorithms/index.html#stochastic-gradient-descent-with-momentum",
    "href": "posts/optimization_algorithms/index.html#stochastic-gradient-descent-with-momentum",
    "title": "Optimization Algorithms",
    "section": "Stochastic Gradient Descent with Momentum",
    "text": "Stochastic Gradient Descent with Momentum\nMomentum proposes a small tweak to gradient descent. We give gradient descent a short-term memory. Let’s define the updated velocity \\(z^{k+1}\\) to be weighted and controlled by the mass \\(\\beta\\). When \\(\\beta\\) is high, we simply use the velocity from the last time, that is, we are entirely driven by momentum. When \\(\\beta=0\\), the momentum is zero.\n\\[\\begin{align*}\nz^{(k+1)} &= \\beta z^{(k)} + \\nabla f(w^{(k)})\\\\\nw^{k+1} &= w^k - \\alpha z^{k+1}\n\\end{align*}\\]\n\\(z^{(k+1)}\\) is called the velocity. It accumulates the past gradients similar to how a heavy ball rolling down the error function landscape integrates over past forces. To see what’s happening in more detail, we can recursively write out:\n\\[\\begin{align*}\nz^{(k)} &= \\beta z^{k-1} + \\nabla f(w^{(k-1)}) \\\\\n&= \\beta(\\beta z^{k-2} + \\nabla f(w^{(k-2)})) + \\nabla f(w^{(k-1)})\\\\\n&= \\beta^2 z^{k-2} + \\beta \\nabla f(w^{(k-2)}) + \\nabla f(w^{(k-1)})\\\\\n&= \\beta^2 (\\beta z^{k-3} + \\nabla f(w^{(k-3)}) ) + \\beta \\nabla f(w^{(k-2)}) + \\nabla f(w^{(k-1)})\\\\\n&= \\sum_{t=0}^{k} \\beta^t \\nabla f(w^{(k-1-t)})\n\\end{align*}\\]\nThe new gradient replacement no longer points into the direction of steepest descent on a particular instance any longer but rather in the direction of an exponentially weighted average of past gradients.\n\nThe dynamics of Momentum\nSince \\(\\nabla f(w^k) = Aw^k - b\\), the update on the quadratic is:\n\\[\\begin{align*}\nz^{k+1} &= \\beta z^k + (Aw^k - b)\\\\\nw^{k+1} &= w^k - \\alpha z^{k+1}\n\\end{align*}\\]\nWe go through the same motions as before with the change of basis \\((w^k - w^{*})=Qx^k\\) and \\(z^k = Q y^k\\) to yield the update rule:\n\\[\\begin{align*}\nQ y^{k+1} &= \\beta Q y^k + (AQx^k + Aw^* - b)\\\\\nQ y^{k+1} &= \\beta Q y^k + (AQx^k + AA^{-1}b - b)\\\\\nQ y^{k+1} &= \\beta Q y^k + Q\\Lambda Q^T Q x^k\\\\\nQ y^{k+1} &= \\beta Q y^k + Q\\Lambda x^k\\\\\ny^{k+1} &= \\beta y^k + \\Lambda x^k\n\\end{align*}\\]\nor equivalently:\n\\[\\begin{align*}\ny_i^{k+1} &= \\beta y_i^k + \\lambda_i x_i^k\n\\end{align*}\\]\nMoreover,\n\\[\\begin{align*}\nQx^{k+1} + w^* &= Qx^k + w^* - \\alpha Qy^{k+1}\\\\\nx^{k+1} &= x^k - \\alpha y^{k+1}\n\\end{align*}\\]\nor equivalently:\n\\[\\begin{align*}\nx_i^{k+1} &= x_i^k - \\alpha y_i^{k+1}\n\\end{align*}\\]\nThis lets us rewrite our iterates as:\n\\[\\begin{align*}\n\\begin{bmatrix}\ny_i^{k+1}\\\\\nx_i^{k+1}\n\\end{bmatrix} &=\n\\begin{bmatrix}\n\\beta y_i^k + \\lambda_i x_i^k\\\\\n(1-\\alpha\\lambda_i)x_i^k - \\alpha \\beta y_i^k\n\\end{bmatrix}\\\\\n&=\\begin{bmatrix}\n\\beta & \\lambda_i\\\\\n- \\alpha \\beta & (1-\\alpha\\lambda_i)\n\\end{bmatrix}\n\\begin{bmatrix}\ny_i^k\\\\\nx_i^k\n\\end{bmatrix}\n\\end{align*}\\]\nConsequently,\n\\[\\begin{align*}\n\\begin{bmatrix}\ny_i^k\\\\\nx_i^k\n\\end{bmatrix} = R^k \\begin{bmatrix}\ny_i^0\\\\\nx_i^0\n\\end{bmatrix},\\quad\nR = \\begin{bmatrix}\n\\beta & \\lambda_i\\\\\n- \\alpha \\beta & (1-\\alpha\\lambda_i)\n\\end{bmatrix}\n\\end{align*}\\]\nIn the case of \\(2 \\times 2\\) matrix, there is an elegant little known formula in terms of the eigenvalues of the matrix \\(R\\), \\(\\sigma_1\\) and \\(\\sigma_2\\):\n\\[\\begin{align*}\nR^k = \\begin{cases}\n\\sigma_1^k R_1 - \\sigma_2^k R_2 & \\sigma_1 \\neq \\sigma_2,\\\\\n\\sigma_1^k(kR\\sigma_1-(k-1)I) & \\sigma_1 = \\sigma_2\n\\end{cases}\n\\quad\nR_j = \\frac{R-\\sigma_j I}{\\sigma_1 - \\sigma_2}\n\\end{align*}\\]\nThe formula is rather complicated, but the takeway here is that it plays the exact same role the individual convergence rates \\((1-\\alpha \\lambda_i)\\) do in gradient descent. The convergence rate is therefore the slowest of the two rates, \\(\\max \\{|\\sigma_1|,|\\sigma_2|\\}\\).\nFor what values of \\(\\alpha\\) and \\(\\beta\\) does momentum converge? Since we need both \\(\\sigma_1\\) and \\(\\sigma_2\\) to converge, our convergence criterion is now \\(\\max \\{|\\sigma_1|,|\\sigma_2|\\} &lt; 1\\).\nIt can be shown that when we choose an optimal value of the parameters \\(\\alpha\\) and \\(\\beta\\), the convergence rate is proportional to:\n\\[\\begin{align*}\n\\frac{\\sqrt{\\kappa} - 1}{\\sqrt{\\kappa} + 1}\n\\end{align*}\\]\nWith barely a modicum of extra effort, we have square-rooted the condition number."
  },
  {
    "objectID": "posts/optimization_algorithms/index.html#adding-momentum-to-the-sgdoptimizer-class",
    "href": "posts/optimization_algorithms/index.html#adding-momentum-to-the-sgdoptimizer-class",
    "title": "Optimization Algorithms",
    "section": "Adding momentum to the SGDOptimizer class",
    "text": "Adding momentum to the SGDOptimizer class\nWe are now in a position to add momentum to the SGDOptimizer class.\n\nclass SGDOptimizer:\n\n    # Initial optimizer - set settings\n    # learning rate of 1. is default for this optimizer\n    def __init__(self, learning_rate=1.0, decay=0.0, momentum=0.0):\n        self.learning_rate = learning_rate\n        self.current_learning_rate = learning_rate\n        self.decay = decay\n        self.iterations = 0\n        self.beta = momentum\n\n    # Call once before any parameter updates\n    def pre_update_params(self):\n        if self.decay:\n            self.current_learning_rate = self.learning_rate * (\n                1.0 / (1.0 + self.decay * self.iterations)\n            )\n\n    # Update parameters\n    def update_params(self, layer):\n\n        # If we use momentum\n        if self.beta:\n\n            # If the layer does not contain momentum arrays, create them\n            # filled with zeros\n            if not hasattr(layer, \"weight_momentums\"):\n                layer.weight_momentums = np.zeros_like(layer.dloss_dweights)\n                # If there is no momentumm array for weights\n                # the array doesnt exist for biases yet either\n                layer.bias_momentums = np.zeros_like(layer.dloss_dbiases)\n\n            # Build weight updates with momentum - take previous\n            # updates multiplied by retain factor and update with\n            # with current gradients\n            # v[t+1] = \\beta * v[t] + \\alpha * dL/dw\n            weight_updates = (\n                self.beta * layer.weight_momentums\n                + self.current_learning_rate * layer.dloss_dweights\n            )\n            layer.weight_momentums = weight_updates\n\n            # Build bias updates\n            bias_updates = (\n                self.beta * layer.bias_momentums\n                + self.current_learning_rate * layer.dloss_dbiases\n            )\n            layer.bias_momentums = bias_updates\n        else:\n            # Vanilla SGD updates (as before momentum update)\n            weight_updates = self.current_learning_rate * layer.dloss_dweights\n            bias_updates = self.current_learning_rate * layer.dloss_dbiases\n\n        layer.weights -= weight_updates\n        layer.biases -= bias_updates\n\n    def post_update_params(self):\n        self.iterations += 1\n\nLet’s see an example illustrating how adding momentum changes the learning process. Keeping the same learning_rate=1.0 and decay=1e-3 from the previous training attempt and using a momentum of 0.50:\n\ndef train(decay, momentum):\n    # Create a dataset\n    X, y = spiral_data(samples=100, classes=3)\n\n    # Create a dense layer with 2 input features and 64 output values\n    dense1 = DenseLayer(2, 64)\n\n    # Create ReLU activation (to be used with the dense layer)\n    activation1 = ReLUActivation()\n\n    # Create second DenseLayer with 64 input features (as we take output of the\n    # previous layer here) and 3 output values\n    dense2 = DenseLayer(64, 3)\n\n    # Create Softmax classifier's combined loss and activation\n    loss_activation = CategoricalCrossEntropySoftmax()\n\n    # Create optimizer\n    optimizer = SGDOptimizer(learning_rate=1.0,decay=decay,momentum=momentum)\n\n    acc_vals = []\n    loss_vals = []\n    lr_vals = []\n\n    # Train in a loop\n    for epoch in range(10001):\n        # Perform a forward pass of our training data through this layer\n        dense1.forward(X)\n\n        # Perform a forward pass through the activation function\n        # takes the output of the first dense layer here\n        activation1.forward(dense1.output)\n\n        # Perform a forward pass through second DenseLayer\n        # takes the outputs of the activation function of first layer as inputs\n        dense2.forward(activation1.output)\n\n        # Perform a forward pass through the activation/loss function\n        # takes the output of the second DenseLayer here and returns the loss\n        loss = loss_activation.forward(dense2.output, y)\n\n        # Calculate accuracy from output of activation2 and targets\n        # Calculate values along the first axis\n        predictions = np.argmax(loss_activation.output, axis=1)\n        if len(y.shape) == 2:\n            y = np.argmax(y, axis=1)\n\n        accuracy = np.mean(predictions == y)\n\n        if epoch % 1000 == 0:\n            print(\n                f\"epoch: {epoch}, \\\n                acc : {accuracy:.3f}, \\\n                loss: {loss: .3f}, \\\n                lr : {optimizer.current_learning_rate}\"\n            )\n\n        acc_vals.append(accuracy)\n        loss_vals.append(loss)\n        lr_vals.append(optimizer.current_learning_rate)\n\n        # Backward pass\n        loss_activation.backward(loss_activation.output, y)\n        dense2.backward(loss_activation.dloss_dz)\n        activation1.backward(dense2.dloss_dinputs)\n        dense1.backward(activation1.dloss_dz)\n\n        # Update the weights and the biases\n        optimizer.pre_update_params()\n        optimizer.update_params(dense1)\n        optimizer.update_params(dense2)\n        optimizer.post_update_params()\n\n    return acc_vals, loss_vals, lr_vals\n\n\nacc_vals, loss_vals, lr_vals = train(decay=1e-3, momentum=0.5)\n\nepoch: 0,                 acc : 0.337,                 loss:  1.099,                 lr : 1.0\nepoch: 1000,                 acc : 0.510,                 loss:  0.978,                 lr : 0.5002501250625312\nepoch: 2000,                 acc : 0.557,                 loss:  0.879,                 lr : 0.33344448149383127\nepoch: 3000,                 acc : 0.580,                 loss:  0.771,                 lr : 0.25006251562890724\nepoch: 4000,                 acc : 0.630,                 loss:  0.735,                 lr : 0.2000400080016003\nepoch: 5000,                 acc : 0.657,                 loss:  0.670,                 lr : 0.16669444907484582\nepoch: 6000,                 acc : 0.753,                 loss:  0.573,                 lr : 0.1428775539362766\nepoch: 7000,                 acc : 0.783,                 loss:  0.522,                 lr : 0.12501562695336915\nepoch: 8000,                 acc : 0.790,                 loss:  0.481,                 lr : 0.11112345816201799\nepoch: 9000,                 acc : 0.807,                 loss:  0.441,                 lr : 0.1000100010001\nepoch: 10000,                 acc : 0.843,                 loss:  0.401,                 lr : 0.09091735612328393\n\n\nThe model achieved the lowest loss and the highest accuracy that we’ve seen so far. Can we do better? Sure, we can! Let’s try to set the momentum to \\(0.9\\):\n\nacc_vals, loss_vals, lr_vals = train(decay=1e-3, momentum=0.9)\n\nepoch: 0,                 acc : 0.340,                 loss:  1.099,                 lr : 1.0\nepoch: 1000,                 acc : 0.763,                 loss:  0.463,                 lr : 0.5002501250625312\nepoch: 2000,                 acc : 0.790,                 loss:  0.407,                 lr : 0.33344448149383127\nepoch: 3000,                 acc : 0.803,                 loss:  0.396,                 lr : 0.25006251562890724\nepoch: 4000,                 acc : 0.813,                 loss:  0.391,                 lr : 0.2000400080016003\nepoch: 5000,                 acc : 0.813,                 loss:  0.386,                 lr : 0.16669444907484582\nepoch: 6000,                 acc : 0.813,                 loss:  0.384,                 lr : 0.1428775539362766\nepoch: 7000,                 acc : 0.813,                 loss:  0.375,                 lr : 0.12501562695336915\nepoch: 8000,                 acc : 0.833,                 loss:  0.332,                 lr : 0.11112345816201799\nepoch: 9000,                 acc : 0.880,                 loss:  0.285,                 lr : 0.1000100010001\nepoch: 10000,                 acc : 0.880,                 loss:  0.277,                 lr : 0.09091735612328393"
  },
  {
    "objectID": "posts/optimization_algorithms/index.html#adagrad",
    "href": "posts/optimization_algorithms/index.html#adagrad",
    "title": "Optimization Algorithms",
    "section": "AdaGrad",
    "text": "AdaGrad\nIn real-world datasets, some input features are sparse and some features are dense. If we use the same learning rate \\(\\alpha\\) for all the weights, parameters associated with sparse features receive meaningful updates only when these features occur. Given a decreasing learning rate, we might end up with a situation where parameters for dense features converge rather quickly to their optimal values, whereas for sparse features, we are still short of observing them sufficiently frequently before their optimal values can be determined. In other words, the learning rate decreases too slowly for dense features and too quickly for sparse features.\nThe update rule for adaptive step-size gradient descent is:\n\\[\\begin{align*}\n\\mathbf{g}_t &= \\frac{\\partial \\mathcal L}{\\partial \\mathbf{w}}\\\\\n\\mathbf{s}_t &= \\mathbf{s}_{t-1} + \\mathbf{g}_{t}^2 \\\\\n\\mathbf{w}_t &= \\mathbf{w}_{t-1} + \\frac{\\alpha}{\\sqrt{\\mathbf{s}_t+\\epsilon}}\\cdot \\mathbf{g}_t\n\\end{align*}\\]\nHere the operations are applied coordinate-wise. So, the jacobian \\(\\mathbf{g}_t^2\\) has entries \\(g_t^2\\). As before, \\(\\alpha\\) is the learning rate and \\(\\epsilon\\) is an additive constant that ensures that we do not divide by \\(0\\). Thus, the learning rate for features whose weights receive frequent updates is decreased faster, whilst for those features, whose weights receive infrequent updates, it is decreased slower.\nThus, Adagrad decreases the learning-rate dynamically on a per-coordinate basis.\n\nclass AdagradOptimizer:\n\n    # Initial optimizer - set settings\n    # learning rate of 1. is default for this optimizer\n    def __init__(self, learning_rate=1.0, decay=0.0, epsilon=1e-7):\n        self.learning_rate = learning_rate\n        self.current_learning_rate = learning_rate\n        self.decay = decay\n        self.iterations = 0\n        self.epsilon = epsilon\n\n    # Call once before any parameter updates\n    def pre_update_params(self):\n        if self.decay:\n            self.current_learning_rate = self.learning_rate * (\n                1.0 / (1.0 + self.decay * self.iterations)\n            )\n\n    # Update parameters\n    def update_params(self, layer):\n        if not hasattr(layer, \"weight_cache\"):\n            layer.weight_cache = np.zeros_like(layer.weights)\n            layer.bias_cache = np.zeros_like(layer.biases)\n\n        # Update cache with squared current gradients\n        layer.weight_cache += layer.dloss_dweights**2\n        layer.bias_cache += layer.dloss_dbiases**2\n\n        # Vanilla SGD parameter update + normalization\n        # with square rooted cache\n        layer.weights += (\n            self.current_learning_rate\n            * layer.dloss_dweights\n            / (np.sqrt(layer.weight_cache) + self.epsilon)\n        )\n        layer.biases += (\n            self.current_learning_rate\n            * layer.dloss_dbiases\n            / (np.sqrt(layer.bias_cache) + self.epsilon)\n        )\n\n    def post_update_params(self):\n        self.iterations += 1"
  },
  {
    "objectID": "posts/optimization_algorithms/index.html#rmsprop",
    "href": "posts/optimization_algorithms/index.html#rmsprop",
    "title": "Optimization Algorithms",
    "section": "RMSProp",
    "text": "RMSProp\nOne of the key issues of Adagrad is that the learning rate decreases at a predefined schedule essentially at a rate proportional \\(\\frac{1}{\\sqrt{t}}\\). While this is generally appropriate for convex problems, it might not be ideal for nonconvex ones, such as those encountered in deep learning. Yet, the coordinate-wise adaptivity of Adagrad is highly desirable as a preconditioner.\nTieleman and Hinton(2012) have proposed the RMSProp algorithm as a simple fix to decouple the rate scheduling from coordinate adaptive learning rates. The issue is that the squares of the gradient \\(\\mathbf{g}_t\\) keeps accumulating into the state vector \\(\\mathbf{s}_t = \\mathbf{s}_{t-1} + \\mathbf{g}_t^2\\). As a result, \\(\\mathbf{s}_t\\) keeps on growing without bounds, essentially linearly as the algorithm converges.\n\nThe Algorithm\nThe update rule for the RMSProp algorithm is as follows:\n\\[\\begin{align*}\n\\mathbf{s}_t &= \\gamma \\mathbf{s}_{t-1} + (1- \\gamma)\\mathbf{g}_t^2\\\\\n\\mathbf{x}_t &= \\mathbf{x}_{t-1} - \\frac{\\alpha}{\\sqrt{\\mathbf{s}_t + \\epsilon}}\\odot \\mathbf{g}_t\n\\end{align*}\\]"
  },
  {
    "objectID": "posts/numerical-integration/index.html",
    "href": "posts/numerical-integration/index.html",
    "title": "Numerical Integration",
    "section": "",
    "text": "We are interested in an approximate calculation of the definite integral\n\\[\n\\begin{align*}\nI[f] = \\int_{a}^{b}f(x)dx\n\\end{align*}\n\\tag{1}\\]\nwhere \\(f(x)\\) is a given function and \\([a,b]\\) is a finite interval. This problem is often called numerical quadrature, since it relates to the ancient problem of the quadrature of a circle i.e. constructing a square with equal area to that of a circle. The computation of the above quantity is equivalent to solving the IVP:\n\\[\n\\begin{align*}\ny'(x) = f(x), \\quad y(a)=0, \\quad x \\in[a,b]\n\\end{align*}\n\\tag{2}\\]\nfor \\(y(b)=I[f]\\).\nAs is well known, even many relatively simple integrals cannot be expressed in finite terms of elementary functions, and thus must be evaluated by numerical methods. Even when a closed form analytical solution exists, it may be preferable to use a numerical quadrature formula.\nSince \\(I[f]\\) is a linear functional, numerical integration is a special case of the problem of approximating a linear functional. We shall consider formulas of the form:\n\\[\n\\begin{align*}\nI[f] \\approx \\sum_{i=1}^n w_if(x_i)\n\\end{align*}\n\\tag{3}\\]\nwhere \\(x_1 &lt; x_2 &lt; \\ldots &lt; x_n\\) are distinct nodes and \\(w_1\\), \\(w_2\\), \\(\\ldots\\), \\(w_n\\) the corresponding weights. Often (but not always) all nodes lie in \\([a,b]\\).\n\nDefinition 1 (Order of accuracy of a Quadrature Rule) A quadrature rule (Equation 3) has order of accuracy (or degree of exactness) equal to \\(d\\), iff it is exact for all polynomials of degree \\(\\leq d\\), that is, for all \\(p\\in\\mathcal{P}_{d+1}\\).\n\n\n\n\nInterpolatory quadrature formulas, where the nodes are constrained to be equally spaced, are called Newton-Cotes formulas. These are especially suited for integrating a tabulated function, a task that was more common before the computer age. The midpoint, the trapezoidal and the Simpson’s rules, to be described here, are all special cases of (unweighted) Newton-Cotes formulas.\nThe trapezoidal rule is based on the linear interpolation of \\(f(x)\\) at \\(x_1 = a\\) and \\(x_2 = b\\), that is, \\(f(x)\\) is approximated by :\n\\[\n\\begin{align*}\np(x) = f(a) + (x-a)[a,b]f = f(a) + (x - a)\\frac{f(b) - f(a)}{b - a}\n\\end{align*}\n\\]\nThe integral of \\(p(x)\\) equals the area of a trapezoid with base \\((b-a)\\) times the average height \\(\\frac{1}{2}(f(a) + f(b))\\). Hence,\n\\[\n\\int_{a}^{b} f(x)dx \\approx \\frac{(b-a)}{2}(f(a) + f(b))\n\\]\nTo increase the accuracy, we subdivide the interval \\([a,b]\\) and assume that \\(f_i = f(x_i)\\) is known on a grid of equidistant points:\n\\[\n\\begin{align*}\nx_0 = a, \\quad x_i = x_0 + ih, \\quad x_n = b\n\\end{align*}\n\\tag{4}\\]\nwhere \\(h = (b - a)/n\\) is the step length. The trapezoidal approximation for the \\(i\\)th subinterval is:\n\\[\n\\begin{align*}\n\\int_{x_i}^{x_{i+1}} f(x)dx = T(h) + R_i, \\quad T(h) = \\frac{h}{2}(f_i + f_{i+1})\n\\end{align*}\n\\tag{5}\\]\nLet \\(p_2(x)\\in\\mathcal{P}_2\\) be the unique interpolating polynomial (Newton polynomial) passing through the points \\((x_i,f_i)\\) and \\((x_{i+1},f_{i+1})\\), that is, \\(p_2(x_i)=f(x_i)\\) and \\(p_2(x_{i+1}) = f(x_{i+1})\\). The exact remainder in Newton’s interpolation formula is given by:\n\\[\n\\begin{align*}\nf(x) - p_2(x) &= [x_i,x_{i+1},x]f\\cdot \\Phi_2(x)\\\\\n&=[x_i,x_{i+1},x]f \\cdot (x - x_{i+1})\\Phi_1(x)\\\\\n&=[x_i,x_{i+1},x]f \\cdot (x - x_{i+1})(x - x_{i})\\Phi_0\\\\\n&=[x_i,x_{i+1},x]f \\cdot (x - x_{i+1})(x - x_{i})\n\\end{align*}\n\\]\nSo, we have:\n\\[\n\\begin{align*}\nR_i &= \\int_{x_i}^{x_{i+1}} (f(x) - p_2(x))dx = \\int_{x_i}^{x_{i+1}}(x - x_i)(x - x_{i+1})[x_i,x_{i+1},x]f dx\n\\end{align*}\n\\tag{6}\\]\nBy the theorem on the remainder term for interpolation, we can write:\n\\[\n[x_1,\\ldots,x_n,x_{n+1}]f = \\frac{f^{(n)}(\\xi)}{n!}\n\\]\nConsequently,\n\\[\n[x_i,x_{i+1},x]f = \\frac{f''(\\xi)}{2}\n\\]\nSo, we have:\n\\[\n\\begin{align*}\nR_i &= \\frac{f''(\\xi)}{2}\\int_{x_i}^{x_{i+1}} (x - x_i)(x - x_{i+1})dx\n\\end{align*}\n\\tag{7}\\]\nSetting \\(x = x_i + ht\\), \\(dx = hdt\\) such that the limits of integration are from \\(t=0\\) to \\(t=1\\), $we get:\n\\[\n\\begin{align*}\nR_i &=  \\frac{f''(\\xi)}{2} \\int_{0}^{1}(ht)(x_i + ht - x_{i+1})h dt\\\\\n&= \\frac{f''(\\xi)}{2} \\int_{0}^{1}(ht)(ht - h)h dt\\\\\n&= \\frac{f''(\\xi)}{2} \\int_{0}^{1}(ht)(ht - h)h dt\\\\\n&= \\frac{f''(\\xi) h^3}{2} \\int_{0}^{1}(t^2 - t) dt\\\\\n&= \\frac{f''(\\xi) h^3}{2} \\left[\\frac{t^3}{3} - \\frac{t^2}{2}\\right]_{0}^{1} \\\\\n&= \\frac{f''(\\xi) h^3}{2} \\left[\\frac{1}{3} - \\frac{1}{2}\\right] \\\\\n&= -\\frac{1}{12}h^3 f''(\\xi)\n\\end{align*}\n\\tag{8}\\]\nSumming the contributions for each subinterval \\([x_i,x_{i+1}]\\), \\(i=0...n\\), gives:\n\\[\n\\begin{align*}\n\\int_{a}^{b}f(x)dx = T(h) + R_T, \\quad T(h) = \\frac{h}{2}(f_0 + f_n) + h\\sum_{i=1}^{n-1}f_i\n\\end{align*}\n\\tag{9}\\]\nwhich is the composite trapezoidal rule. The global truncation error is:"
  },
  {
    "objectID": "posts/numerical-integration/index.html#interpolatory-quadrature-rules",
    "href": "posts/numerical-integration/index.html#interpolatory-quadrature-rules",
    "title": "Numerical Integration",
    "section": "",
    "text": "We are interested in an approximate calculation of the definite integral\n\\[\n\\begin{align*}\nI[f] = \\int_{a}^{b}f(x)dx\n\\end{align*}\n\\tag{1}\\]\nwhere \\(f(x)\\) is a given function and \\([a,b]\\) is a finite interval. This problem is often called numerical quadrature, since it relates to the ancient problem of the quadrature of a circle i.e. constructing a square with equal area to that of a circle. The computation of the above quantity is equivalent to solving the IVP:\n\\[\n\\begin{align*}\ny'(x) = f(x), \\quad y(a)=0, \\quad x \\in[a,b]\n\\end{align*}\n\\tag{2}\\]\nfor \\(y(b)=I[f]\\).\nAs is well known, even many relatively simple integrals cannot be expressed in finite terms of elementary functions, and thus must be evaluated by numerical methods. Even when a closed form analytical solution exists, it may be preferable to use a numerical quadrature formula.\nSince \\(I[f]\\) is a linear functional, numerical integration is a special case of the problem of approximating a linear functional. We shall consider formulas of the form:\n\\[\n\\begin{align*}\nI[f] \\approx \\sum_{i=1}^n w_if(x_i)\n\\end{align*}\n\\tag{3}\\]\nwhere \\(x_1 &lt; x_2 &lt; \\ldots &lt; x_n\\) are distinct nodes and \\(w_1\\), \\(w_2\\), \\(\\ldots\\), \\(w_n\\) the corresponding weights. Often (but not always) all nodes lie in \\([a,b]\\).\n\nDefinition 1 (Order of accuracy of a Quadrature Rule) A quadrature rule (Equation 3) has order of accuracy (or degree of exactness) equal to \\(d\\), iff it is exact for all polynomials of degree \\(\\leq d\\), that is, for all \\(p\\in\\mathcal{P}_{d+1}\\).\n\n\n\n\nInterpolatory quadrature formulas, where the nodes are constrained to be equally spaced, are called Newton-Cotes formulas. These are especially suited for integrating a tabulated function, a task that was more common before the computer age. The midpoint, the trapezoidal and the Simpson’s rules, to be described here, are all special cases of (unweighted) Newton-Cotes formulas.\nThe trapezoidal rule is based on the linear interpolation of \\(f(x)\\) at \\(x_1 = a\\) and \\(x_2 = b\\), that is, \\(f(x)\\) is approximated by :\n\\[\n\\begin{align*}\np(x) = f(a) + (x-a)[a,b]f = f(a) + (x - a)\\frac{f(b) - f(a)}{b - a}\n\\end{align*}\n\\]\nThe integral of \\(p(x)\\) equals the area of a trapezoid with base \\((b-a)\\) times the average height \\(\\frac{1}{2}(f(a) + f(b))\\). Hence,\n\\[\n\\int_{a}^{b} f(x)dx \\approx \\frac{(b-a)}{2}(f(a) + f(b))\n\\]\nTo increase the accuracy, we subdivide the interval \\([a,b]\\) and assume that \\(f_i = f(x_i)\\) is known on a grid of equidistant points:\n\\[\n\\begin{align*}\nx_0 = a, \\quad x_i = x_0 + ih, \\quad x_n = b\n\\end{align*}\n\\tag{4}\\]\nwhere \\(h = (b - a)/n\\) is the step length. The trapezoidal approximation for the \\(i\\)th subinterval is:\n\\[\n\\begin{align*}\n\\int_{x_i}^{x_{i+1}} f(x)dx = T(h) + R_i, \\quad T(h) = \\frac{h}{2}(f_i + f_{i+1})\n\\end{align*}\n\\tag{5}\\]\nLet \\(p_2(x)\\in\\mathcal{P}_2\\) be the unique interpolating polynomial (Newton polynomial) passing through the points \\((x_i,f_i)\\) and \\((x_{i+1},f_{i+1})\\), that is, \\(p_2(x_i)=f(x_i)\\) and \\(p_2(x_{i+1}) = f(x_{i+1})\\). The exact remainder in Newton’s interpolation formula is given by:\n\\[\n\\begin{align*}\nf(x) - p_2(x) &= [x_i,x_{i+1},x]f\\cdot \\Phi_2(x)\\\\\n&=[x_i,x_{i+1},x]f \\cdot (x - x_{i+1})\\Phi_1(x)\\\\\n&=[x_i,x_{i+1},x]f \\cdot (x - x_{i+1})(x - x_{i})\\Phi_0\\\\\n&=[x_i,x_{i+1},x]f \\cdot (x - x_{i+1})(x - x_{i})\n\\end{align*}\n\\]\nSo, we have:\n\\[\n\\begin{align*}\nR_i &= \\int_{x_i}^{x_{i+1}} (f(x) - p_2(x))dx = \\int_{x_i}^{x_{i+1}}(x - x_i)(x - x_{i+1})[x_i,x_{i+1},x]f dx\n\\end{align*}\n\\tag{6}\\]\nBy the theorem on the remainder term for interpolation, we can write:\n\\[\n[x_1,\\ldots,x_n,x_{n+1}]f = \\frac{f^{(n)}(\\xi)}{n!}\n\\]\nConsequently,\n\\[\n[x_i,x_{i+1},x]f = \\frac{f''(\\xi)}{2}\n\\]\nSo, we have:\n\\[\n\\begin{align*}\nR_i &= \\frac{f''(\\xi)}{2}\\int_{x_i}^{x_{i+1}} (x - x_i)(x - x_{i+1})dx\n\\end{align*}\n\\tag{7}\\]\nSetting \\(x = x_i + ht\\), \\(dx = hdt\\) such that the limits of integration are from \\(t=0\\) to \\(t=1\\), $we get:\n\\[\n\\begin{align*}\nR_i &=  \\frac{f''(\\xi)}{2} \\int_{0}^{1}(ht)(x_i + ht - x_{i+1})h dt\\\\\n&= \\frac{f''(\\xi)}{2} \\int_{0}^{1}(ht)(ht - h)h dt\\\\\n&= \\frac{f''(\\xi)}{2} \\int_{0}^{1}(ht)(ht - h)h dt\\\\\n&= \\frac{f''(\\xi) h^3}{2} \\int_{0}^{1}(t^2 - t) dt\\\\\n&= \\frac{f''(\\xi) h^3}{2} \\left[\\frac{t^3}{3} - \\frac{t^2}{2}\\right]_{0}^{1} \\\\\n&= \\frac{f''(\\xi) h^3}{2} \\left[\\frac{1}{3} - \\frac{1}{2}\\right] \\\\\n&= -\\frac{1}{12}h^3 f''(\\xi)\n\\end{align*}\n\\tag{8}\\]\nSumming the contributions for each subinterval \\([x_i,x_{i+1}]\\), \\(i=0...n\\), gives:\n\\[\n\\begin{align*}\n\\int_{a}^{b}f(x)dx = T(h) + R_T, \\quad T(h) = \\frac{h}{2}(f_0 + f_n) + h\\sum_{i=1}^{n-1}f_i\n\\end{align*}\n\\tag{9}\\]\nwhich is the composite trapezoidal rule. The global truncation error is:"
  },
  {
    "objectID": "posts/multivariate_ito_calculus/index.html",
    "href": "posts/multivariate_ito_calculus/index.html",
    "title": "Multivariate Ito Calculus",
    "section": "",
    "text": "We can generalize the theory to functions of several brownian motions. This unleashes the full power of Ito calculus.\n\n\n\nDefinition 1 (Brownian motion in \\(\\mathbf{R}^{d}\\).) Take \\(d\\in\\mathbf{N}\\). Let \\(B^{(1)},\\ldots,B^{(d)}\\) be independent standard Brownian motions in \\((\\Omega,\\mathcal{F},\\mathbb{P})\\). The process \\((B_{t}:t\\geq0)\\) taking values in \\(\\mathbf{R}^{d}\\) defined by :\n\\[\\begin{aligned}\nB_{t} & =(B_{t}^{(1)},\\ldots,B_{t}^{(d)}),\\quad t\\geq0\n\\end{aligned}\\]\nis called a \\(d-\\)dimensional Brownian motion or a Brownian motion in \\(\\mathbf{R}^{d}\\).\n\nThe Brownian filtration \\((\\mathcal{F}_{t}:t\\geq0)\\) is now composed of the information of all Brownian motions. In other words, it is given by the sigma-fields:\n\\[\\begin{aligned}\n\\mathcal{F}_{t} & =\\sigma(B_{s}^{(i)},1\\leq i\\leq d,s\\leq t)\n\\end{aligned}\\]\nFor every outcome \\(\\omega\\), the path of trajectory of a \\(d-\\)dimensional Brownian motion is a curve in space parametrized by the time \\(t\\):\n\\[\\begin{aligned}\nt\\mapsto B_{t}(\\omega) & =(B_{t}^{(1)}(\\omega),B_{t}^{(2)}(\\omega),\\ldots,B_{t}^{(d)}(\\omega))\n\\end{aligned}\\]\nOf course, this curve is continuous, since each coordinate is. The below numerical project gives an example of one path of a two-dimensional brownian motion. This is a very rugged and intertwined curve! We might wonder, what it does as \\(t\\to\\infty\\). Does it wander around \\((0,0)\\) ad infinitum or does it eventually escape to infinity? We will answer this question in a later section. For doing so, we shall need a version of Ito’s formula for multi-dimensional Brownian motion. We finish this section by noticing that it is also easy to construct Brownian motions in higher dimensions for which the coordinates are correlated.\n\n\nConsider a two-dimensional Brownian motion \\((B_{t}^{(1)},B_{2}^{(2)})\\) starting at \\((0,0)\\).\nLet’s plot one path of this Brownian motion on the plane \\(\\mathbf{R}^{2}\\) on the plane in \\(\\mathbf{R}^{2}\\) on the time interval \\([0,5]\\) using a discretization of \\(0.001\\).\nWe define BrownianMotion2D class.\n\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nsns.set_style(\"whitegrid\")\n\nclass BrownianMotion2D:\n    \"\"\"\n    Generate sample paths for a 2d-brownian motion\n    \"\"\"\n    def __init__(\n        self,\n        endpoint : float = 1.0,\n        discretization : float = 0.01\n    ):\n        self.endpoint = endpoint\n        self.discretization = discretization\n\n    def generate_paths(self, num_paths : int):\n        steps = int(self.endpoint/self.discretization)\n        delta_z = np.sqrt(self.discretization) * np.random.randn(num_paths,2,steps)\n        \n        # paths has shape [num_paths,2,num_steps]\n        paths = np.cumsum(delta_z,axis=2)\n\n        # Brownian motion has position (0,0) at time t=0\n        # Append initial position \n        init_position = np.zeros((num_paths,2,1))\n        paths = np.append(init_position,paths,axis=2)\n\n        return paths\n\nWe can then configure and use BrownianMotion2D objects as we please.\n\n\nShow the code\nbm = BrownianMotion2D(endpoint=5.0,discretization=0.001)\npaths = bm.generate_paths(num_paths=1)\npath = paths[0]\n\n\nplt.xlabel(r'$x$')\nplt.ylabel(r'$y$')\nplt.title(r'2D-Brownian motion')\nplt.grid(True)\nplt.plot(path[0],path[1],linewidth=1,color='blue')\nplt.show()\n\n\n\n\n\n\n\n\n\nExample 1 (Brownian motion with correlated coordinates) Let \\((B_{t}:t\\geq0)\\) be a two dimensional brownian motion. Let \\(-1&lt;\\rho&lt;1\\). We construct the two dimensional process as follows: \\(W_{t}=(W_{t}^{(1)},W_{t}^{(2)})\\) where:\n\\[\\begin{aligned}\nW_{t}^{(1)} & =B_{t}^{(1)}\\\\\nW_{t}^{(2)} & =\\rho B_{t}^{(1)}+\\sqrt{1-\\rho^{2}}B_{t}^{(2)}\n\\end{aligned}\\]\n\\(W_{t}^{(1)}=B_{t}^{(1)}\\) is Gaussian with mean \\(0\\) and variance \\(t\\). Since, \\(B_{t}^{(1)}\\) and \\(B_{t}^{(2)}\\)are independent gaussian random variables and the sum of IID Gaussians is Gaussian, \\(W_{t}^{(2)}\\) is Gaussian with mean \\(0\\) and variance \\(t\\). The covariance between \\(W_{t}^{(1)}\\) and \\(W_{t}^{(2)}\\) is:\n\\[\\begin{aligned}\n\\mathbf{E}[W_{t}^{(1)}W_{t}^{(2)}] & =\\mathbf{E}[B_{t}^{(1)}(\\rho B_{t}^{(1)}+\\sqrt{1-\\rho^{2}}B_{t}^{(2)})]\\\\\n& =\\mathbf{E}[\\rho(B_{t}^{(1)})^{2}+\\sqrt{1-\\rho^{2}}B_{t}^{(1)}B_{t}^{(2)}]\\\\\n& =\\rho t\n\\end{aligned}\\]\nHence, the coordinates at time \\(t\\) are not independent.\n\nConsider now the process \\((W_{t}:t\\geq0)\\) for \\(\\rho=1/2\\) as in example 2. Let’s plot one path of this process on the plane \\(\\mathbf{R}^{2}\\) on the time-interval \\([0,5]\\) using a discretization of \\(0.001\\).\n\nclass BrownianMotion2DWithCorrelatedCoords(BrownianMotion2D):\n    \"\"\"\n    Generate sample paths for a 2d-brownian motion\n    have correlated coordiantes\n    \"\"\"\n\n    def __init__(\n        self, \n        endpoint: float = 1.0, \n        discretization: float = 0.01, \n        rho: float = 0.0\n    ):\n        self.endpoint = endpoint\n        self.discretization = discretization\n        self.rho = rho\n\n    def generate_paths(self, num_paths: int):\n\n        # Call the base class generate_paths() method to generate a pair of\n        # independent brownian motion paths. It returns a tensor of\n        # shape (num_paths, 2, num_steps)\n        paths = super().generate_paths(num_paths=num_paths)\n\n        # Extract the brownian motions B1(t) and B2(t)\n        # B1(t) and B2(t) have dimensions [num_paths,num_steps]\n        x_coord = paths[:, 0, :]\n        y_coord = paths[:, 1, :]\n\n        # Apply the transformation\n        # W1(t) = B1(t)\n        # W2(t) = rho * B1(t) + sqrt(1 - rho**2) B2(t)\n        x_coord = x_coord\n        y_coord = self.rho * x_coord + np.sqrt(1 - self.rho**2) * y_coord\n\n        # Assemble back the x- and y- coordinates\n        x_coord = np.expand_dims(x_coord, axis=1)\n        y_coord = np.expand_dims(y_coord, axis=1)\n\n        # Return a tensor of shape [num_paths,d=2,num_steps]\n        return np.concatenate([x_coord, y_coord], axis=1)\n\nLet’s configure the BrownianMotion2DWithCorrelatedCoords engine with the settings endpoint=5.0, discretization=0.001 and rho=0.5 and generate a sample path.\n\n\nShow the code\nbm = BrownianMotion2DWithCorrelatedCoords(\n    endpoint=5.0,\n    discretization=0.001,\n    rho=0.50\n)\npaths = bm.generate_paths(num_paths=1)\npath = paths[0]\n\nplt.xlabel(r'$x$')\nplt.ylabel(r'$y$')\nplt.title(r'Correlated Brownian motion $W(t)=(W^{(1)}(t),W^{(2)}(t))$')\nplt.grid(True)\nplt.plot(path[0],path[1],linewidth=1,color='blue')\nplt.show()\n\n\n\n\n\n\n\nShow the code\nplt.xlabel(r'$t$')\nplt.ylabel(r'$W_t$')\nplt.title(r'Correlated Brownian motion paths')\nplt.grid(True)\nt = np.linspace(0.0,stop=5.0,num=5001)\nplt.plot(t,path[0],linewidth=0.75)\nplt.plot(t,path[1],linewidth=0.75)\nplt.show()\n\n\n\n\n\n\n\n\n\n\nTheorem 1 (Ito’s Formula.) Let \\((B_{t}:t\\geq0)\\) be a \\(d-\\)dimensional brownian motion. Consider \\(f\\in\\mathcal{C}^{2}(\\mathbf{R}^{d})\\). Then, we have with probability one that for all \\(t\\geq0\\):\n\\[\\begin{aligned}\nf(B_{t})-f(B_{0}) & =\\sum_{i=1}^{d}\\int_{0}^{t}\\partial_{x_{i}}f(B_{s})dB_{s}^{(i)}+\\frac{1}{2}\\int_{0}^{t}\\sum_{i=1}^{d}\\partial_{x_{i}}^{2}f(B_{s})ds\\label{eq:multidimensional-ito-formula}\n\\end{aligned}\\]\n\n\nI stress that, as in the one-dimensional case, Ito’s formula is an equality of processes (and not an equality in distribution). Thus, the processes on both sides must agree for each path.\n\nInterestingly, the mixed partials \\(\\partial_{x_{i}x_{j}}f(B_{s})\\), \\(i\\neq j\\) do not appear in the formula! We see from Ito’s formula that the process \\(f(B_{t})\\) can be represented as a sum of \\(d+1\\) processes: \\(d\\) Ito integrals and one Riemann integral (which is a process of finite variation). In vector notation, the formula takes the form:\n\\[\\begin{aligned}\nf(B_{t})-f(B_{0}) & =\\int_{0}^{t}\\nabla f(B_{s})^{T}dB_{s}+\\frac{1}{2}\\int_{0}^{t}\\nabla^{2}f(B_{s})ds\n\\end{aligned}\\]\nwhere it is understood that the first term is the sum of the \\(d\\) Ito integrals in the equation. The symbol \\(\\nabla^{2}\\) is the Laplacian of \\(f\\):\n\\(\\sum_{i=1}^{d}\\frac{\\partial^{2}}{\\partial x_{i}^{2}}f(B_{s}^{(1)},\\ldots,B_{s}^{(d)})ds\\)\nIn differential form, Ito’s formula becomes very neat:\n\\[\\begin{aligned}\ndf(B_{t}) & =\\sum_{i=1}^{d}\\partial_{x_{i}}f(B_{s})dB_{t}^{(i)}+\\frac{1}{2}\\sum_{i=1}^{d}\\partial_{x_{i}}^{2}f(B_{s})dt=\\nabla f(B_{t})^{T}dB_{s}+\\frac{1}{2}\\nabla^{2}f(B_{t})dt\n\\end{aligned}\\]\n\nExample 2 Consider the functions (1) \\(f(x_{1},x_{2})=x_{1}^{2}+x_{2}^{2}\\) (2) \\(f(x_{1},x_{2})=e^{x_{1}}\\cos x_{2}\\) and the processes \\((X_{t}:t\\geq0)\\) and \\((Y_{t}:t\\geq0)\\). If we apply Ito’s formula to the first process, we have:\n\\[\\begin{aligned}\nX_{t} & =\\int_{0}^{t}2B_{s}^{(1)}dB_{s}^{(1)}+\\int_{0}^{t}2B_{s}^{(2)}dB_{s}^{(2)}+\\frac{1}{2}\\int_{0}^{t}(4dt)\\\\\n& =\\int_{0}^{t}2B_{s}^{(1)}dB_{s}^{(1)}+\\int_{0}^{t}2B_{s}^{(2)}dB_{s}^{(2)}+2t\n\\end{aligned}\\]\nThe second process gives:\n\\[\\begin{aligned}\nY_{t} & =\\cos B_{s}^{(2)}\\int_{0}^{t}e^{B_{s}^{(1)}}dB_{s}^{(1)}-e^{B_{s}^{(1)}}\\int\\sin B_{s}^{(2)}dB_{s}^{(2)}+\\frac{1}{2}\\int_{0}^{t}\\left(e^{B_{s}^{(1)}}\\cos B_{s}^{(2)}-e^{B_{s}^{(1)}}\\cos B_{s}^{(2)}\\right)dt\\\\\n& =1+\\cos B_{s}^{(2)}\\int_{0}^{t}e^{B_{s}^{(1)}}dB_{s}^{(1)}-e^{B_{s}^{(1)}}\\int\\sin B_{s}^{(2)}dB_{s}^{(2)}\n\\end{aligned}\\]\n\n\nExample 3 (Cross-Variation of \\(B_{t}^{(1)}\\) and \\(B_{t}^{(2)}\\)). Let \\((t_{j}:j\\leq n)\\) be a sequence of partitions of \\([0,t]\\) such that \\(\\max_{j}|t_{j+1}-t_{j}|\\to0\\) as \\(n\\to\\infty\\). Prove that:\n\\[\\begin{aligned}\n\\lim_{n\\to\\infty}\\sum_{j=0}^{n-1}(B_{t_{j+1}}^{(1)}-B_{t_{j}}^{(1)})(B_{t_{j+1}}^{(2)}-B_{t_{j}}^{(2)}) & =0\\quad\\text{in } L^{2}\n\\end{aligned}\\]\nThis justifies the rule \\(dB_{t}^{(1)}\\cdot dB_{t}^{(2)}=0\\).\nHint: Just compute the second moment of the sum.\n\n\nWe have:\n\\[\\begin{aligned}\n& \\mathbf{E}\\left[\\left(\\sum_{j=0}^{n-1}(B_{t_{j+1}}^{(1)}-B_{t_{j}}^{(1)})(B_{t_{j+1}}^{(2)}-B_{t_{j}}^{(2)})\\right)^{2}\\right]\\\\\n= & \\sum_{j=0}^{n-1}\\mathbf{E}[(B_{t_{j+1}}^{(1)}-B_{t_{j}}^{(1)})^{2}(B_{t_{j+1}}^{(2)}-B_{t_{j}}^{(2)})^{2}]\\\\\n+ & 2\\sum_{j&lt;k}\\mathbf{E}\\left[(B_{t_{j+1}}^{(1)}-B_{t_{j}}^{(1)})(B_{t_{k+1}}^{(1)}-B_{t_{k}}^{(1)})(B_{t_{j+1}}^{(2)}-B_{t_{j}}^{(2)})(B_{t_{k+1}}^{(2)}-B_{t_{k}}^{(2)})\\right]\n\\end{aligned}\\]\nBoth these expectations are zero, since the brownian motions are independent and non-overlapping increments are independent.\nConsequently, \\(\\sum_{j=0}^{n-1}(B_{t_{j+1}}^{(1)}-B_{t_{j}}^{(1)})(B_{t_{j+1}}^{(2)}-B_{t_{j}}^{(2)})\\to0\\) in the \\(L^{2}\\) sense.\n\n\nProof. The proof of the formula follows the usual recipe: Taylor’s theorem together with the quadratic variation and the cross-variation. In this case, we do get a cross-variation between the different Brownian motions. More precisely, consider a partition \\((t_{j}:j\\leq n)\\) of \\([0,t]\\). Then we can write:\n\\[\\begin{aligned}\nf(B_{t})-f(B_{0}) & =\\sum_{j=0}^{n-1}(f(B_{t_{j+1}})-f(B_{t_{j}}))\n\\end{aligned}\\]\nWe can apply the Taylor’s series expansion for each \\(j\\) to get:\n\\[\\begin{aligned}\nf(B_{t})-f(B_{0}) & =\\sum_{j=0}^{n-1}\\nabla f(B_{t_{j}})(B_{t_{j+1}}-B_{t_{j}})\\\\\n& +\\frac{1}{2}\\sum_{j=0}^{n-1}(B_{t_{j+1}}-B_{t_{j}})^{T}Hf(B_{t_{j}})(B_{t_{j+1}}-B_{t_{j}})+\\mathcal{E}\n\\end{aligned}\\]\nwhere \\(Hf\\) is the Hessian matrix of \\(f\\). We wrote the expansion using the vector notation to be economical. Let’s keep in mind that each term is a sum over the derivatives. The first term will converge to \\(d\\) Ito integrals as in the one-dimensional case. Now, the summand in the second term is:\n\\[(B_{t_{j+1}}^{(1)}-B_{t_{j}}^{(1)},\\ldots,B_{t_{j+1}}^{(d)}-B_{t_{j}}^{(d)})\\left[\\begin{array}{ccc}\n\\partial_{x_{1}}^{2}f(B_{t_{j}}) & \\ldots & \\partial_{x_{1}x_{d}}^{2}f(B_{t_{j}})\\\\\n\\vdots & \\ddots\\\\\n\\partial_{x_{d}x_{1}}^{2}f(B_{t_{j}}) &  & \\partial_{x_{d}}^{2}f(B_{t_{j}})\n\\end{array}\\right]\\left[\\begin{array}{c}\nB_{t_{j+1}}^{(1)}-B_{t_{j}}^{(1)}\\\\\n\\vdots\\\\\nB_{t_{j+1}}^{(d)}-B_{t_{j}}^{(d)}\n\\end{array}\\right]\\]\nSo, \\((B_{t_{j+1}}^{(i)}-B_{t_{j}}^{(i)})\\) is pre-multiplied with the term \\(\\partial_{x_{i}x_{k}}^{2}f(B_{t_{j}})\\) and it is post-multiplied \\((B_{t_{j+1}}^{(k)}-B_{t_{j}}^{(k)})\\). Consequently, the second term in the Taylor’s series expansion can be re-written as:\n\\[\\sum_{j=0}^{n-1}\\left(\\sum_{i=1}^{d}\\partial_{x_{i}}^{2}f(B_{t_{j}})(B_{t_{j+1}}^{(i)}-B_{t_{j}}^{(i)})^{2}+\\sum_{1\\leq i&lt;k\\leq d}\\partial_{x_{i}x_{k}}^{2}f(B_{t_{j}})(B_{t_{j+1}}^{(i)}-B_{t_{j}}^{(i)})(B_{t_{j+1}}^{(k)}-B_{t_{j}}^{(k)})\\right)\\]\nThe second term on the right converges to \\(0\\) in the \\(L^{2}\\) sense when \\(i\\neq k\\), from exercise. This explains why the mixed derivatives disappear in the multi-dimensional Ito’s formula. As for the case \\(i=k\\), it reduces to the quadratic variation as in the one-dimensional case. This is where the Riemann integral arises, after suitable conditioning on \\(\\mathcal{F}_{t_{j}}\\), the sigma-field generated by \\(B_{s}\\), \\(s\\leq t_{j}\\).\n\nAs in the one-dimensional case,it is not necessary to learn Ito’s formula by heart. It suffices to write the differential of the function \\(f\\) to second order. We can then apply the rules of multivariate Ito calculus:\n\n\n\n\\(\\cdot\\)\n\\(dt\\)\n\\(dB_{t}^{(1)}\\)\n\\(dB_{t}^{(2)}\\)\n\\(\\ldots\\)\n\n\n\n\n\\(dt\\)\n\\(0\\)\n\\(0\\)\n\\(0\\)\n\\(0\\)\n\n\n\\(dB_{t}^{(1)}\\)\n\\(0\\)\n\\(dt\\)\n\\(0\\)\n\\(0\\)\n\n\n\\(dB_{t}^{(2)}\\)\n\\(0\\)\n\\(0\\)\n\\(dt\\)\n\\(0\\)\n\n\n\\(\\ldots\\)\n\\(0\\)\n\\(0\\)\n\\(0\\)\n\\(dt\\)\n\n\n\nNote that the rule \\(dB_{t}^{(i)}dB_{t}^{(j)}=0\\) for \\(i\\neq j\\) is being motivated by the cross-variation result.\nHow can we construct martingales using the Ito’s formula? Recall that an Ito integral \\((\\int_{0}^{t}X_{s}dB_{s},t\\leq T)\\) is a martingale whenever the integrand is in \\(\\mathcal{L}_{c}^{2}(T)\\), the space of adapted processes with continuous paths and for which:\n\\[\\begin{aligned}\n\\int_{0}^{T}\\mathbf{E}[X_{s}^{2}]ds & &lt;\\infty\n\\end{aligned}\\]\nThe only difference here is that the integrand is a function of many Brownian motions. However, the integrands involved in the Ito integrals of the multidimensional Ito’s formula are clearly adapted to the filtration \\((\\mathcal{F}_{t}:t\\geq0)\\) of \\((B_{t}:t\\geq0)\\) as they are functions of the Brownian motion at the time. The arguments of Ito integral in and apply verbatim, if we take the definition of \\(\\mathcal{L}_{c}^{2}(t)\\) with the filtration \\((\\mathcal{F}_{t}:t\\geq0)\\) of \\((B_{t}:t\\geq0)\\). With this in mind, we have the following corollary.\n\n\n\nCorollary 1 (Brownian Martingales.) Let \\((B_{t}:t\\geq0)\\) be a Brownian motion in \\(\\mathbf{R}^{d}\\). Consider \\(f\\in\\mathcal{C}^{2}(\\mathbf{R}^{d})\\) such that processes \\((\\partial_{x {i}}f(B_{t}),t\\leq T)\\in\\mathcal{L}_{c}^{2}(T)\\) for every \\(i\\leq d\\). Then, the process :\n\\[f(B_{t})-\\frac{1}{2}\\int_{0}^{t}\\nabla^{2}f(B_{s})ds,\\quad t\\leq T\\]\nwhere \\(\\nabla^{2}=\\sum_{i=1}^{d}\\partial_{x_{i}}^{2}\\) is the Laplacian, is a martingale for the Brownian filtration.\n\nFor example, consider the processes \\(X_{t}=(B_{t}^{(1)})^{2}+(B_{t}^{(2)})^{2}\\) and \\(Y_{t}=\\exp(B_{t}^{(1)})\\cos(B_{t}^{(2)})\\). Then, we have :\n\\[\\frac{1}{2}\\int_{0}^{t}\\nabla^{2}X_{s}ds=\\frac{1}{2}\\int_{0}^{t}4ds=2t\\]\nand\n\\[\\begin{aligned}\n\\frac{1}{2}\\int_{0}^{t}\\nabla^{2}Y_{s}ds & =\\frac{1}{2}\\int_{0}^{t}0\\cdot ds=0\n\\end{aligned}\\]\nThus, the processes \\(X_{t}-2t\\) and \\(Y_{t}\\) are martingales for the Brownian filtration. In one dimension, there are no interesting martingales constructed with functions of space only. Indeed, \\((f(B_{t}):t\\geq0)\\) is a martingale if and only if \\(f''(x)=0\\) for all \\(x\\). But, such functions are of the form \\(f(x)=ax+b\\), \\(a,b\\in\\mathbf{R}\\). In other words, in one dimension, Brownian martingales of the form \\(f(B_{t})\\) are simply \\(aB_{t}+b\\). Not very surprising! The situation is very different in higher dimensions. Indeed, corollary implies that \\(f(B_{t})\\) is a martingale whenever \\(f\\) is a harmonic function:\n\nDefinition 2 (Harmonic function.) A function \\(f:\\mathbf{R}^{d}\\to\\mathbf{R}\\) is harmonic in \\(\\mathbf{R}^{d}\\) if and only if \\(\\nabla^{2}f(x)\\equiv0\\) for all \\(x\\in\\mathbf{R}^{d}\\). More generally, a function \\(f:\\mathbf{R}^{d}\\to\\mathbf{R}\\) is harmonic in the region \\(\\mathcal{O}\\subset\\mathbf{R}^{d}\\) if and only if \\(\\nabla^{2}f(x)\\equiv0\\) for all \\(x\\in\\mathcal{O}\\).\n\nNote that the function \\(f(x)=e^{x_{1}}\\cos x_{2}\\) is harmonic in \\(\\mathbf{R}^{d}\\). This is why the process \\(Y_{t}=\\exp(B_{t}^{(1)})\\cos(B_{t}^{(2)})\\) is a martingale. The distinction to a subset of \\(\\mathbf{R}^{d}\\) in the above definition is important since it may happen that the function is harmonic only in a subset of the space; see for example equation. It is possible to define a Brownian martingale in such cases by considering the process until it exits the region. This will turn out to be important as we move ahead.\nThe multidimensional Ito’s formula generalizes to functions of time and space as in proposition:\n\nDefinition 3 A function \\(f:[0,\\infty)\\times\\mathbf{R}^{d}\\to\\mathbf{R}\\) is in \\(\\mathcal{C}^{1,2}([0,T]\\times\\mathbf{R}^{d})\\) if the partial derivative in time :\n\\[\\frac{\\partial}{\\partial t}f(t,\\mathbf{x})\\]\nexists and is continuous and the second order partial derivatives in space:\n\\[\\frac{\\partial^{2}}{\\partial x_{i}^{2}}f(t,x_{1},x_{2},\\ldots,x_{i},\\ldots,x_{d}),\\quad1\\leq i\\leq d\\]\nexist and are continuous.\n\n\n\n\n\n\nTheorem 2 (Multidimensional Ito’s formula for functions of space and time) Let \\((B_{t}:t\\leq T)\\) be a \\(d\\)-dimensional Brownian motion. Consider a function \\(f\\in\\mathcal{C}^{1,2}([0,T]\\times\\mathbf{R}^{d})\\). Then, we have with probability one for all \\(t\\leq T\\):\n\\[\\begin{aligned}\nf(t,B_{t})-f(0,B_{0}) & =\\sum_{i=1}^{d}\\int_{0}^{t}\\partial_{x_{i}}f(s,B_{s})dB_{s}^{(i)}+\\int_{0}^{t}\\left(\\partial_{t}f(s,B_{s})+\\sum_{i=1}^{d}\\partial_{x_{i}}^{2}f(s,B_{s})\\right)ds\n\\end{aligned}\\]\n\nThe martingale condition is then similar to the ones in corollary ([cor:brownian-martingales-in-Rd]): if the processes \\((\\partial_{x_{i}}f(s,B_{s}),t\\leq T)\\in\\mathcal{L}_{c}^{2}(T)\\) for every \\(1\\leq i\\leq d\\), then the process\n\\[f(t,B_{t})-\\int_{0}^{t}\\left\\{ \\partial_{t}f(s,B_{s})++\\sum_{i=1}^{d}\\partial_{x_{i}}^{2}f(s,B_{s})\\right\\} ds,\\quad t\\leq T \\tag{1}\\]\nis a martingale for the Brownian filtration. In particular, if \\(f\\) satisfies the partial differential equation:\n\\[\n\\begin{aligned}\n\\frac{\\partial f}{\\partial t}+\\frac{1}{2}\\nabla^{2}f & =0\n\\end{aligned}\n\\tag{2}\\]\nthen the process \\((f(t,B_{t}):t\\leq T)\\) itself is a martingale.\n\n\n\nConsider a simple random walk on the integer lattice \\(\\mathbb{Z}^d\\). At each time step, a random walker makes a random move of length one in one of the lattice directions.\nWe say that, if the random walk returns to the origin with probability one infinitely many times, it is recurrent, if it does not we will call it transient.\nIt’s worth to spend a moment visiting Polya’s Random Walk Theorem, a fascinating, but not so intuitive result.\nAssuming all random walks start at the origin, we define \\(u\\) to be the probability that a random walker returns to the origin. The probability that the random walker returns to the origin exactly \\(m\\) times is:\n\\[\\begin{align*}\n{m \\choose m-1} u^{m-1} (1 - u)^{m - (m - 1)} = u^{m-1}(1-u)\n\\end{align*}\\]\nThe expected number of times the particle returns to the origin for an infinite random walk is:\n\\[\\begin{align*}\nE &= \\sum_{m = 1}^{\\infty} m (u^{m-1}(1-u))\\\\\n&= (1-u)\\sum_{m=1}^{\\infty}mu^{m-1}\\\\\n&= (1-u)\\sum_{m=1}^{\\infty}\\frac{d}{du}u^{m}\\\\\n\\end{align*}\\]\nWe note that limit exchanging is acceptable since the power series \\(\\sum_{n=1}^{\\infty}x^n\\) converges uniformly for \\(u &lt; 1\\) and we can apply the differentiable limit theorem.\nSo we obtain:\n\\[\\begin{align*}\nE &= (1-u)\\frac{d}{du}\\sum_{m = 1}^{\\infty} u^m \\\\\n&= (1-u)\\cdot \\frac{1}{(1-u)^2}\\\\\n&= \\frac{1}{1-u}\n\\end{align*}\\]\nSo, we see that if \\(E\\) is finite, \\(u &lt; 1\\), then the walk is transient and if \\(E = +\\infty\\), \\(u=1\\), then the walk is recurrent.\nWe then define \\(u_n\\) to be the probability that a given walk is at the origin on the \\(n\\)th step, defining the value \\(u_0=1\\) for the trivial loop. We also introduce an indicator random variable \\(x_n\\), which takes the value \\(1\\), if the particle is at the origin on the \\(n\\)th step and zero otherwise.\nThen\n\\[\\begin{align*}\nT = \\sum_{n=1}^{\\infty}x_n\n\\end{align*}\\]\nis the total number of times, the particle is at the origin, so \\(E\\) is equal to the expectation of \\(T\\), \\(\\mathbb{E}(T)\\), which is equal to:\n\\[\\begin{align*}\n\\mathbb{E}[T] &= \\sum_{n=1}^{\\infty}\\mathbb{E}[x_n]\\\\\n&= \\sum_{n=1}^{\\infty} u_n\n\\end{align*}\\]\nBut, we showed previously that if \\(E\\) is finite, then the walk is transient and if \\(E = \\infty\\), then the walk is recurrent, so we have established that if:\n\\[\\begin{align*}\n\\sum_{n=1}^{\\infty}u_n\n\\end{align*}\\]\nconverges then the walk is transient and if the sum diverges, then the walk is recurrent.\n\n\nNow that we have built up the necessary tools, we will consider the cases. We start by considering a simple random walk on \\(\\mathbb{Z}^1\\). Since, as mentioned previously, a walk must have an even number of steps to be a loop, we only look at \\(u_{2n},n \\in \\mathbb{Z}^+\\). A path of length \\(2n\\) returning to the origin must have \\(n\\) up-moves and \\(n\\) down-moves. The number of such paths are \\({2n \\choose n}\\). Each such path has a probability of occurrence \\(\\frac{1}{2^{2n}}\\). Thus,\n\\[\\begin{align*}\nu_{2n} = \\frac{1}{2^{2n}}{2n \\choose n}\n\\end{align*}\\]\nUsing Stirling’s approximation \\(n! \\sim \\sqrt{2\\pi n} e^{-n} n^{n}\\), we obtain:\n\\[\\begin{align*}\nu_{2n} &= \\frac{1}{2^{2n}} \\frac{(2n)!}{n! n!}\\\\\n&\\approx \\frac{1}{2^{2n}} \\cdot \\frac{\\sqrt{2\\pi(2n)} e^{-2n}(2n)^{2n}}{\\left(\\sqrt{2\\pi n} e^{-n} n^n\\right)^2}\\\\\n&=\\frac{1}{\\sqrt{\\pi n}}\n\\end{align*}\\]\nSo, we see that:\n\\[\\begin{align*}\n\\sum_{n=0}^{\\infty} u_{2n} \\approx \\sum_{n=0}^{\\infty} \\frac{1}{\\sqrt{n\\pi}}\n\\end{align*}\\]\nAnd the series on the right certainly diverges so, we see that a simple random walk in \\(\\mathbb{Z}^1\\) is recurrent since \\(E\\) diverges.\n\n\n\nA particle has an equal probability \\(1/4\\) of moving left, right, up or down randomly in the \\(d=2\\) dimensional lattice. Each path of \\(2n\\) steps has a probability \\(\\frac{1}{4^{2n}}\\) of occurring. We then consider the number of paths with equal steps left and right (say \\(L\\) steps in each horizontal direction) and equal steps up and down (then \\(n-L\\)) is:\n\\[\\begin{align*}\n{2n \\choose L}{2n - L \\choose L}{2n - 2L \\choose n - L}{n-L \\choose n - L} = \\frac{(2n)!}{L! L! (n-L)! (n-L)!}\n\\end{align*}\\]\nSo we get:\n\\[\\begin{align*}\nu_{2n} &= \\frac{1}{4^{2n}} \\sum_{L=0}^n \\frac{(2n)!}{L! L! (n-L)! (n-L)!} \\\\\n&= \\frac{1}{4^{2n}} \\sum_{L=0}^n \\frac{(2n)!}{n! n!} \\cdot \\left(\\frac{n!}{L! (n-L)!}\\right)^2 \\\\\n&=\\frac{1}{4^{2n}} {2n \\choose n}\\sum_{L=0}^n {n \\choose L}^2\n\\end{align*}\\]\nSuppose, we are to form a team of \\(n\\) players from a population of \\(2n\\) participants. There \\({2n \\choose n}\\) distinguishable teams of size \\(n\\). Alternatively, we could divide the population into two halves of \\(n\\) participants each, choose \\(L\\) participants from the first sub-population, and the remaining \\(n-L\\) participants from the second sub-population. So, the number of distinguishable teams is:\n\\[\\begin{align*}\n\\sum_{L=0}^{n}{n \\choose L}{n \\choose n - L} = \\sum_{L=0}^{n} {n \\choose L}^2\n\\end{align*}\\]\nSo, we have the combinatorial identity:\n\\[\\begin{align*}\n\\sum_{L=0}^{n} {n \\choose L}^2 = {2n \\choose n}\n\\end{align*}\\]\nThus,\n\\[\\begin{align*}\nu_{2n} &=\\frac{1}{4^{2n}} {2n \\choose n}\\sum_{L=0}^n {n \\choose L}^2\\\\\n&= \\left(\\frac{1}{2^{2n}} {2n \\choose n}\\right)^2\n\\end{align*}\\]\nSo, we have that, it is just the square of the result from \\(\\mathbb{Z}^1\\), so we see in this case that:\n\\[\\begin{align*}\nu_{2n} &\\approx \\sum_{n=0}^{\\infty} \\frac{1}{\\pi n}\n\\end{align*}\\]\nAnd the series on the right certainly diverges, so we see that a simple random walk in \\(\\mathbb{Z}^2\\) is recurrent as \\(E\\) diverges.\n\n\n\nAs before, in order to have a walk return to the origin we must have equal steps in the positive and negative directions for each direction and each path of \\(2n\\) has a probability of occurring of \\(\\frac{1}{6^{2n}}\\). Then, extending the idea from the previous subsection, the number of paths (of total length \\(2n\\)) with \\(L\\) steps left and right, \\(U\\) steps up and down and \\(n - L - U\\) steps forward and backward is:\n\\[\\begin{align*}\n\\frac{(2n)!}{L! L! U! U! (n - L - U)! (n - L - U)!}\n\\end{align*}\\]\nSo, we get:\n\\[\n\\begin{align*}\nu_{2n} &= \\frac{1}{6^{2n}} \\sum_{L,U,L+U \\leq n} \\frac{(2n)!}{L! L! U! U! (n - L - U)! (n - L - U)!} \\\\\n&= \\frac{1}{2^{2n}} {2n \\choose n} \\sum_{L,U,L+U \\leq n} \\left(\\frac{1}{3^n}\\frac{n!}{L! U! (n - U - L)!}\\right)^2\n\\end{align*}\n\\tag{3}\\]\nConsider a \\(3\\)-sided fair coin, with \\(\\mathbb{P}\\{\\text{Heads}\\} = \\mathbb{P}\\{\\text{Tails}\\} = \\mathbb{P}\\{\\text{Edge}\\} = \\frac{1}{3}\\). Suppose that the coin is tossed \\(n=3^2 = 9\\) times. The probability of landing \\(L\\) heads, \\(U\\) tails and \\(n - L - U\\) edges is \\(\\frac{n!}{L!U!(n-L-U)!} \\frac{1}{3^n}\\). This is precisely the term seen in the above expression. The number of heads, tails and edges in \\(n\\) coin tosses follows a multinomial distribution. It can be easily demonstrated, that in, \\(n/3 = 3\\) heads, \\(n/3\\) tails and \\(n/3\\) edges are most likely to occur in \\(n\\) coin tosses. So, we can find an upper bound on the summand in Equation 3 as:\n\\[\\begin{align*}\n\\frac{n!}{3^n L! U! (n- L - U)!} \\leq \\frac{n!}{3^n \\lfloor\\frac{n}{3}\\rfloor! \\lfloor\\frac{n}{3}\\rfloor! \\lfloor\\frac{n}{3}\\rfloor!}\n\\end{align*}\\]\nAlso, from the multinomial expansion theorem:\n\\[\\begin{align*}\n(1 + a + b)^n = \\sum_{L,U,L+U\\leq n} \\frac{n!}{L! U! (n-L-U)!} a^L b^U\n\\end{align*}\\]\nSetting \\(a = b = 1\\), we get:\n\\[\\begin{align*}\n\\sum_{L,U,L+U\\leq n} \\frac{n!}{3^n L! U! (n-L-U)!} a^L b^U = 1\n\\end{align*}\\]\nWe then see that:\n\\[\\begin{align*}\nu_{2n} \\leq \\frac{1}{2^{2n}} {2n \\choose n} \\frac{n!}{3^n \\lfloor\\frac{n}{3}\\rfloor! \\lfloor\\frac{n}{3}\\rfloor! \\lfloor\\frac{n}{3}\\rfloor!}\n\\end{align*}\\]\nWe can simplify this as:\n\\[\\begin{align*}\nu_{2n} &= \\frac{1}{2^{2n}}{2n \\choose n} \\frac{n!}{3^n \\left(\\lfloor\\frac{n}{3}\\rfloor!\\right)^3} \\\\\n&\\approx \\frac{1}{\\sqrt{\\pi n}} \\times \\frac{\\sqrt{2\\pi n} e^{-n} n^n}{3^n \\left\\{\\sqrt{2\\pi \\frac{n}{3}}e^{-n/3} \\left(\\frac{n}{3}\\right)^{n/3}\\right\\}^3}\\\\\n&= \\frac{1}{\\sqrt{\\pi n}} \\frac{\\sqrt{2\\pi n} e^{-n} n^n}{3^n \\frac{(2\\pi n)^{3/2}}{3^{3/2}} e^{-n} \\frac{n^n}{3^n}}\\\\\n&= \\frac{1}{\\sqrt{\\pi n}} \\frac{\\sqrt{2\\pi n} \\cancel{e^{-n}} \\cancel{n^n}}{\\cancel{3^n} \\frac{(2\\pi n)^{3/2}}{3^{3/2}} \\cancel{e^{-n}} \\frac{ \\cancel{n^n}}{\\cancel{3^n}}}\\\\\n&\\approx \\frac{M}{(\\pi n)^{3/2}}\n\\end{align*}\\]\nwhere \\(M\\) is a positive constant. We then see:\n\\[\\begin{align*}\n\\sum_n u_{2n} &= M \\sum_n \\frac{1}{n^{\\frac{3}{2}}}\n\\end{align*}\\]\nThe sum on the right hand side converges, so we have that a simple random walk in three dimensions is transient. The proof of Polya’s Random Walk Theorem is complete.\n\n\n\n\nIn one dimension, we established that every path of a Brownian motion reaches any level \\(a \\in \\mathbf{R}\\). More precisely, for \\(a &gt; 0\\), if we define the stopping time :\n\\[\\begin{align*}\n\\tau = \\min \\{ t \\geq 0 : B_t \\geq a\\}\n\\end{align*}\\]\nwe have \\(\\mathbb{P}\\{\\tau_a &lt; \\infty \\} = 1\\). This implies in particular that every path will come back to \\(0\\) and will do infinitely many times. This is because \\(B(t+\\tau) - B(t)\\) is a standard brownian motion. This property of Brownian motion is called recurrence. This is to be compared with Brownian motion with a drift. In our analysis, we found that, if the drift is negative, then there are paths that will not reach a given level \\(a &gt; 0\\) with positive probability. Such paths go to infinity without ever going back to \\(0\\). This property of the process is called transience.\nWe can derive similar properties for the multidimensional Brownian motion. We will rely heavily on Corollary 1 and on some knowledge of harmonic functions. Harmonic functions play a very important role in mathematics, physics and in nature in general. As we mentioned earlier, if \\(d = 1\\), the only harmonic functions are the linear functions, since the equation \\(f''(x) = 0\\) has the solutions \\(f(x)=ax+b\\). However, in higher dimensions, the collection of harmonic functions is very rich. This gives access to a plethora of Brownian martingales. For example, the following functions are harmonic in the whole space minus the origin, \\(\\mathbf{R}^d \\setminus \\{0\\}\\).\n\\[\nh(x) = \\begin{cases}\n\\log ||x||, & d = 2 \\\\\n||x||^{2 - d}, & d \\geq 3\n\\end{cases}\n\\tag{4}\\]\nwhere \\(x\\in\\mathbf{R}^d\\).\n\nProof. Consider\n\\[\\begin{align*}\nf(x_1,x_2) = \\log \\sqrt {x_1^2 + x_2^2}\n\\end{align*}\\]\nWe have:\n\\[\\begin{align*}\n\\frac{\\partial f}{\\partial x_1} &= \\frac{1}{\\sqrt{x_1^2 + x_2^2}} \\cdot \\frac{\\partial }{\\partial x_1} (\\sqrt{x_1^2 + x_2^2})\\\\\n&=\\frac{1}{\\sqrt{x_1^2 + x_2^2}} \\cdot \\frac{x_1}{\\sqrt{x_1^2 + x_2^2}}\\\\\n&= \\frac{x_1}{x_1^2 + x_2^2}\n\\end{align*}\\]\nFurther,\n\\[\\begin{align*}\n\\frac{\\partial^2 f}{\\partial x_1^2} &= \\frac{(x_1^2 + x_2^2)(1) - x_1(2x_1)}{(x_1^2 + x_2^2)^2} \\\\\n&= \\frac{x_1^2 - x_2^2}{(x_1^2 + x_2^2)}\n\\end{align*}\\]\nBy symmetry,\n\\[\\begin{align*}\n\\frac{\\partial^2 f}{\\partial x_2^2}\n&= \\frac{x_2^2 - x_1^2}{(x_1^2 + x_2^2)}\n\\end{align*}\\]\nSo,\n\\[\\begin{align*}\n\\frac{\\partial^2 f}{\\partial x_1^2} &= - \\frac{\\partial^2 f}{\\partial x_2^2}\\\\\n\\frac{\\partial^2 f}{\\partial x_1^2} + \\frac{\\partial^2 f}{\\partial x_2^2}&=0\n\\end{align*}\\]\nWe conclude that \\(f\\) is harmonic.\nNext, consider\n\\[\\begin{align*}\ng(x_1,x_2,\\ldots,x_d) = \\frac{1}{\\left(\\sqrt{x_1^2 + x_2^2 + \\ldots + x_d^2}\\right)^{d-2}}\n\\end{align*}\\]\nNow,\n\\[\\begin{align*}\n\\frac{\\partial g}{\\partial x_i} &= \\frac{(2-d)}{\\left(\\sqrt{x_1^2 + x_2^2 + \\ldots + x_d^2}\\right)^{d-1}} \\cdot \\frac{\\partial }{\\partial x_i}\\left(\\sqrt{x_1^2 + x_2^2 + \\ldots + x_d^2}\\right)\\\\\n&= \\frac{(2-d)}{\\left(\\sqrt{x_1^2 + x_2^2 + \\ldots + x_d^2}\\right)^{d-1}}\\cdot \\frac{2x_i}{2\\left(\\sqrt{x_1^2 + x_2^2 + \\ldots + x_d^2}\\right)}\\\\\n&= \\frac{(2-d)x_i}{\\left(\\sqrt{x_1^2 + x_2^2 + \\ldots + x_d^2}\\right)^d}\n\\end{align*}\\]\nFurther, we have:\n\\[\\begin{align*}\n\\frac{\\partial^2 g}{\\partial x_i^2} &= (2-d)\\frac{\\left(\\sqrt{x_1^2 + x_2^2 + \\ldots + x_d^2}\\right)^d (1) - (x_i)\\cdot d \\cdot\\left(\\sqrt{x_1^2 + x_2^2 + \\ldots + x_d^2}\\right)^{d-1}\\cdot \\frac{x_i}{\\left(\\sqrt{x_1^2 + x_2^2 + \\ldots + x_d^2}\\right)}}{\\left(\\sqrt{x_1^2 + x_2^2 + \\ldots + x_d^2}\\right)^{2d}}\\\\\n&=(2-d)\\left(\\sqrt{x_1^2 + x_2^2 + \\ldots + x_d^2}\\right)^{d-2} \\frac{\\left(\\sqrt{x_1^2 + x_2^2 + \\ldots + x_d^2}\\right)^2  - d x_i^2}{\\left(\\sqrt{x_1^2 + x_2^2 + \\ldots + x_d^2}\\right)^{2d}}\\\\\n&=(2-d) \\frac{\\left(\\sum_{i=1}^d x_i^2\\right) - dx_i^2 }{||x||^{d+2}}\n\\end{align*}\\]\nWe conclude that:\n\\[\\begin{align*}\n\\sum_{i=1}^{d} \\frac{\\partial^2 g}{\\partial x_i^2} = 0\n\\end{align*}\\]\nand hence \\(g\\) is harmonic.\n\nInterestingly enough, the answer to the recurrence versus transience puzzle depends on the dimension. We will show that Brownian motion is recurrent in dimension \\(d=2\\) in the sense that every Brownian motion path starting from \\(x\\) will eventually enter a disc around the origin, no matter how small the disc is. The Brownian path will then enter this disc infinitely many times, as \\(t \\to \\infty\\). Note that, we did not say that the path actually hits \\(0\\), but that it enters a disc around the \\(0\\). This nuance is important, as we will in fact show that a Brownian path actually never hits a given point. In dimension \\(d=3\\) or higher, it is proved that there are some paths starting from a given \\(x\\) that will never enter a given ball around the origin with positive probability. This is the transience property.\nThe strategy of the proof is similar to the approach for Brownian motion with a drift. We will find a good function \\(h : \\mathbf{R}^d \\to \\mathbf{R}\\) for which \\(h(B_t)\\) is a martingale. In light of Corollary 1, this function needs to be harmonic in a suitable region. The desired probability is then obtained by considering the right boundary values.\n\nTheorem 3 (Recurrence and transience of a brownian motion in \\(\\mathbf{R}^d\\)) Let \\((B_t,t\\geq 0)\\) be a Brownian motion in \\(\\mathbf{R}^d\\) starting at \\(B_0 = x\\). Consider for \\(r &lt; ||x||\\), the stopping time\n\\[\\begin{align*}\n\\tau_r = \\min \\{t \\geq 0 : ||B_t|| &lt; r\\}\n\\end{align*}\\]\nthe first hitting time of the paths in a ball of radius \\(r\\) around the origin. We have:\n\\[\\begin{align*}\n\\mathbb{P}(\\tau_r &lt; \\infty) =\n\\begin{cases}\n1 & \\text{ if }d \\leq 2 \\\\\n\\left(\\frac{r}{||x||}\\right)^{d-2} & \\text{ if }d \\geq 3\n\\end{cases}\n\\end{align*}\\]\nIn particular, for \\(d \\leq 2\\), the paths are recurrent; that is, they come back infinitely many times in a neighbourhood of the origin. For \\(d \\geq 3\\), each path will eventually never come back to a neighbourhood of the origin.\n\nNote that we made sure that the starting point of the Brownian motion \\(x\\) is outside the ball of radius \\(r\\).\n\nProof. Consider another hitting time of a ball with a radius larger than \\(||x||\\):\n\\[\\begin{align*}\n\\tau_R' = \\min \\{t \\geq 0 : ||B_t|| \\geq R\\}, \\quad r &lt; ||x|| &lt; R\n\\end{align*}\\]\nNote that \\(\\tau_R'\\) must increase with \\(R\\) and that it must go to \\(+\\infty\\) as \\(R \\to \\infty\\). Moreover, the sequence of events \\(\\{\\tau_r &lt; \\tau_R'\\}_{R &gt; ||x||}\\) is increasing. In particular, by continuity of probability measure, we have:\n\\[\\begin{align*}\n\\lim_{R \\to \\infty} \\mathbb{P}(\\tau_r &lt; \\tau_R') &= \\mathbb{P}(\\lim_{R \\to \\infty} \\tau_r &lt; \\tau_R')\\\\\n&= \\mathbb{P}(\\tau_r &lt; \\infty)\n\\end{align*}\\]\nIf we set \\(\\tau = \\tau_r \\land \\tau_R'\\), then the event \\(\\{\\tau_r &lt; \\tau_R'\\}\\) is the same as the event \\(\\{||B_\\tau||=r\\}\\). So, \\(\\lim_{R \\to \\infty} \\mathbb{P}(\\tau_r &lt; \\tau_R') = \\lim_{R \\to \\infty} \\mathbb{P}(||B_\\tau||=r)\\).\nNow, consider the event \\(\\{\\tau &lt; \\infty\\}\\). Let \\(E_n\\) be the event that the \\(n\\)th increment \\(||B_n - B_{n-1}||\\) exceeds \\(R\\). If \\(E_n\\) occurs, then we must have the Brownian motion exits the spherical shell of thickness \\(R-r\\). Moreover, we have \\(\\mathbb{P}(E_1) = \\ldots = \\mathbb{P}(E_n)\\), for all \\(n\\). Call this probability \\(p\\). Clearly, \\(0 &lt; p &lt; 1\\). Since the events \\(E_n\\) are independent, we have:\n\\[\\begin{align*}\n\\mathbb{P}(E_1^C \\cap \\ldots \\cap E_n^C) = (1 - p)^n\n\\end{align*}\\]\nAs \\(n \\to \\infty\\), we have \\(\\lim_{n \\to \\infty} \\mathbb{P}(\\bigcap_{k=1}^{n}E_k^C) = 0\\). Now, let \\(F_k\\) be the event that there are no excursions upto \\(k\\). That is, \\(F_k = \\bigcap_{i=1}^{k}E_i^C\\). Now, the event \\(F_{k+1}\\) implies \\(F_k\\), or equivalently, \\(F_{k+1} \\subseteq F_k\\). So, \\(\\{F_k\\}_{k=1}^{\\infty}\\) is a decreasing sequence of events. Moreover, \\(\\bigcap_{k=1}^n F_k = \\bigcap_{k=1}^n E_k^C\\). So, by continuity of probability measure,\n\\[\\begin{align*}\n\\lim_{n \\to \\infty} \\mathbb{P}(\\bigcap_{k=1}^{n}E_k^C)\n&= \\lim_{n \\to \\infty} \\mathbb{P}(\\bigcap_{k=1}^{n}F_k) \\\\\n&= \\mathbb{P}(\\lim_{n \\to \\infty} \\bigcap_{k=1}^{n}F_k) \\\\\n&= \\mathbb{P}(\\bigcap_{k=1}^{\\infty}F_k) \\\\\n&= \\mathbb{P}(\\bigcap_{k=1}^{\\infty}E_k^C)\n\\end{align*}\\]\nSo, \\(\\mathbb{P}(\\bigcup_{k=1}^{\\infty}E_k) = 1\\). There exists an \\(n_0 \\in \\mathbf{N}\\), such that the event \\(E_{n_0}\\), an excursion at \\(n_0\\) occurs with probability \\(1\\). So, the event \\(\\{\\tau &lt; \\infty\\}\\) occurs almost surely.\nTo compute \\(\\mathbb{P}(||B_\\tau||=r)\\), the idea is to find a good function \\(h\\) with the following properties:\n\nMartingale: \\((h(B_t),t\\leq \\tau)\\) is a bounded martingale, so that the optional stopping theorem implies:\n\n\\[\\begin{align*}\n\\mathbb{E}[h(B_\\tau)] = h(B_0) = h(x)\n\\end{align*}\\]\n\nBoundary values: Since \\(B_\\tau\\) is a point at \\(||x||=r\\) or at \\(||x||=R\\), we pick boundary conditions for \\(h\\), so that \\(\\mathbb{E}[h(B_{\\tau})]=\\mathbb{P}(||B_\\tau||=r)\\).\n\nThe second point is easy; it suffices to take the boundary conditions \\(h(x)=0\\) at \\(||x||=R\\) and \\(h(x)=1\\) at \\(||x||=r\\). For the first point, by Ito’s formula, we pick \\(h\\) to be harmonic in the annulus \\(\\{x \\in \\mathbf{R}^d : r &lt; ||x||&lt;R \\}\\). Thus, we can use the function in Equation 4. Of course, the functions \\(ah(x) + b\\) remain harmonic. To satisfy the boundary conditions, we pick \\(a\\) and \\(b\\) suitably:\n\n\nLet \\(h(x) = ax + b\\). Then, at \\(x=r\\), we have:\n\\[\n\\begin{align*}\nar + b = 1\n\\end{align*}\n\\tag{5}\\]\nand at \\(x = R\\), we have:\n\\[\n\\begin{align*}\naR + b = 0\n\\end{align*}\n\\tag{6}\\]\nSo, \\(b = -aR\\). Substituting in Equation 5, we get:\n\\[\\begin{align*}\na &= \\frac{1}{r - R}\nb &= -\\frac{R}{r - R}\n\\end{align*}\\]\nConsequently,\n\\[\n\\begin{align*}\nh(x) &= \\frac{R - x}{R - r}\n\\end{align*}\n\\tag{7}\\]\n\n\n\nLet \\(h(x) = \\log ||x||\\). Then, at \\(||x||=r\\), we have:\n\\[\n\\begin{align*}\na \\log ||x|| + b &= 1\na \\log r + b &= 1\n\\end{align*}\n\\tag{8}\\]\nAt \\(||x||=R\\), we have:\n\\[\n\\begin{align*}\na \\log ||x|| + b &= 0\na \\log R + b &= 0\n\\end{align*}\n\\tag{9}\\]\nThus, from Equation 9, \\(b = -a \\log R\\). Substituting the value for \\(b\\) in Equation 8, we have:\n\\[\n\\begin{align*}\na \\log r - a \\log R &= 1\\\\\na &= \\frac{1}{\\log r - \\log R}\n\\end{align*}\n\\]\nConsequently,\n\\[\n\\begin{align*}\nh(x) &= \\frac{\\log ||x||}{\\log r - \\log R} -  \\frac{1}{\\log r - \\log R} \\log R\\\\\n&= \\frac{\\log R - \\log ||x||}{\\log R - \\log r}\n\\end{align*}\n\\tag{10}\\]\n\n\n\nLet \\(h(x)=||x||^{2-d}\\). At \\(||x||=r\\), \\(a h(x) + b = 1\\). So, we have:\n\\[\n\\begin{align*}\na r^{2-d} + b = 1\n\\end{align*}\n\\tag{11}\\]\nAt \\(||x||=R\\), \\(ah(x) + b = 0\\). So, we have:\n\\[\n\\begin{align*}\na ||R||^{2-d} + b &= 0\n\\end{align*}\n\\tag{12}\\]\nFrom Equation 12, we get \\(b = -a R^{2-d}\\). Substituting this value in Equation 11, we get:\n\\[\\begin{align*}\na r^{2-d} - aR^{2-d}  &= 1\\\\\na &= \\frac{1}{r^{2-d} - R^{2-d}}\n\\end{align*}\\]\nAnd\n\\[\n\\begin{align*}\nb = - \\frac{R^{2-d}}{r^{2-d} - R^{2-d}}\n\\end{align*}\n\\]\nThus,\n\\[\n\\begin{align*}\nh(x) &= \\frac{||x||^{2-d}}{r^{2-d} - R^{2-d}} - \\frac{R^{2-d}}{r^{2-d} - R^{2-d}}\\\\\n&= \\frac{R^{2-d} - ||x||}{R^{2-d} - r^{2-d}}\n\\end{align*}\n\\tag{13}\\]\nCollecting all the results together, we get:\n\\[\nh(x) = \\begin{cases}\n\\frac{R - x}{R - r}, & d=1 \\\\\n\\frac{\\log R - \\log ||x||}{\\log R - \\log r}, & d=2 \\\\\n\\frac{R^{2-d} - ||x||^{2-d}}{R^{2-d} - r^{2-d}}, & d \\geq 3\n\\end{cases}\n\\tag{14}\\]\nPassing to the limit as \\(R \\to \\infty\\), for \\(d=1\\), we have:\n\\[\\begin{align*}\n\\lim_{R \\to \\infty} h(x) &= \\lim_{R \\to \\infty} \\frac{R - x}{R - r} \\\\\n&= \\lim_{R \\to \\infty} \\frac{1 - \\frac{x}{R}}{1 - \\frac{r}{R}}\\\\\n&= 1\n\\end{align*}\\]\nFor \\(d = 2\\), we get:\n\\[\\begin{align*}\n\\lim_{R \\to \\infty} h(x) &= \\lim_{R \\to \\infty} \\frac{1 - \\frac{\\log x}{\\log R}}{1 - \\frac{\\log r}{\\log R}} \\\\\n&= 1\n\\end{align*}\\]\nFor \\(d = 3\\), we get:\n\\[\\begin{align*}\n\\lim_{R \\to \\infty}  h(x) &= \\lim_{R \\to \\infty} \\frac{R^{2-d} - ||x||^{2-d}}{R^{2-d} - r^{2-d}}\\\\\n&= \\left(\\frac{||x||}{r}\\right)^{2-d}\n\\end{align*}\\]\nThis concludes the proof. \\(\\blacksquare\\)\n\n\n\nExample 4 We get more from the above proof. Indeed, in dimension \\(d \\geq 2\\), it implies that the probability that a Brownian motion starting at \\(B_0 = x\\) eventually hits any other point \\(y\\) is \\(0\\). Indeed, if we take \\(y = 0\\) and \\(x \\neq 0\\), we have:\n\\[\n\\begin{align*}\n\\mathbb{P}(\\exists t &gt; 0: B_t = 0) &= \\lim_{R \\to \\infty} \\lim_{r \\to \\infty} \\mathbb{P}(\\tau_r &lt; \\tau_R')\\\\\n&= \\lim_{R \\to \\infty} \\lim_{r \\to \\infty} \\frac{R^{2-d} - ||x||^{2-d}}{R^{2-d} - r^{2-d}}\\\\\n&=\\lim_{R \\to \\infty}  \\lim_{r \\to \\infty} \\frac{(R/r)^{2-d} - (||x||/r)^{2-d}}{(R/r)^{2-d} - 1}\\\\\n&= \\lim_{R \\to \\infty} 0\\\\\n&= 0\n\\end{align*}\n\\]\nHere, we shrink the inner radius to \\(0\\) first and then we let the outer radius go to infinity after. It remains to take the limits of the expression obtained in equation Equation 14. The first limit \\(r \\to 0\\) gives \\(0\\) right away.\n\n\n\n\nIn the last section, we translated the problem of recurrence and transience of Brownian motion in terms of a boundary value problem: we needed to find a particular function \\(h\\) that solves a PDE (that is, \\(\\nabla^2 h=0\\)) in a certain region of space(the annulus) and that satisfies given boundary conditions (the function is \\(1\\) on the inner circle and \\(0\\) on the outer circle). This is a particular case of the Dirichlet problem in PDE.\nConsider a region \\(\\mathcal{O} \\subset \\mathbb{R}^d\\). \\(\\mathcal{O}\\) is an open ball. That is, for all \\(x \\in \\mathcal{O}\\), there exists \\(\\epsilon&gt;0\\), such that \\(V_\\epsilon(x) = \\{y : ||y - x|| &lt; \\epsilon\\}\\) is contained in \\(\\mathcal{O}\\). \\(\\mathcal{O}\\) doesn’t contain boundary points \\(\\partial \\mathcal{O}\\). In the proof of Theorem 3, the region was the annulus \\(\\{x: r &lt; ||x|| &lt; R\\}\\) and the boundary was given by the spheres \\(\\{x :||x|| = r\\}\\) and \\(\\{x: ||x||=R\\}\\). The Dirichlet problem in \\(\\mathcal{O}\\) can be stated as follows:\nLet \\(f:\\partial\\mathcal{O} \\to \\mathbb{R}\\) be a function on the boundary of \\(\\mathcal{O}\\). Can we extend the function \\(f\\) to \\(O\\) in such a way that the extension is harmonic on \\(\\mathcal{O}\\) and coincides with \\(f\\) on the boundary?\nIn the instance of the proof of the Theorem 3, we knew the solution of the problem, thanks to Equation 4. The only job left to do was to adjust some parameters to fit the boundary conditions. It turns out that the formalism of stochastic calculus allows us to express the solution of the Dirichlet problem as an average over Brownian paths for general regions of space and boundary conditions. To do so, we look at a twist on the Ito’s formula called the Dynkin’s formula.\nLet \\(x\\) be a point in \\(\\mathcal{O}\\). Consider a Brownian motion \\((B_t,t\\geq 0)\\) starting at \\(x\\), \\(B_0 = x\\). To emphasize the dependence on \\(x\\), we write \\(\\mathbb{P}_x\\) and \\(\\mathbb{E}_x\\) for the probability and the expectation for the Brownian motion. Dykin’s formula is obtained by merging Corollary 1 for the Brownian martingales together with the optional stopping theorem. More precisely, consider \\(f \\in C^2(\\mathbb{R}^d)\\) that satisfies the assumption of the Corollary 1. We then have that the process:\n\\[\\begin{align*}\nM_t &= f(B_t) - \\frac{1}{2}\\int_{0}^t \\nabla^2 f(B_s) ds, \\quad t \\geq 0\n\\end{align*}\\]\nis a Brownian martingale.\nConsider also the stopping time \\(\\tau = \\min \\{t \\geq 0 : B_t \\in \\mathcal{O}^C\\}\\). This is the first exit time of \\(\\mathcal{O}\\) of the Brownian motion path. Then, if the assumptions of the optional stopping theorem are fulfilled, we get Dynkin’s formula:\n\\[\n\\begin{align*}\n\\mathbb{E}[M_\\tau] = \\mathbb{E}[f(B_\\tau)] - \\frac{1}{2} \\mathbb{E}\\left[\\int_0^\\tau \\nabla^2 f(B_s)ds\\right] = f(B_0) = M_0\n\\end{align*}\n\\tag{15}\\]\nAs an application of Dynkin’s formula, let’s express the solution of the Dirichlet problem as an average over Brownian motion. If \\(f\\) is harmonic in \\(\\mathcal{O}\\), then \\(\\nabla^2 f = 0\\) in \\(\\mathcal{O}\\), so the process \\((f(B_t),t\\leq \\tau)\\) is itself a martingale. Note that since \\(\\mathcal{O}\\) is bounded, this is a bounded martingale! Moreover, the integrands \\(\\partial_i f(B_s)\\), \\(1 \\leq i \\leq d\\), are bounded. We conclude that the solution to the Dirichlet problem can be represented as follows:\n\\[\n\\begin{align*}\nf(x) = \\mathbb{E}_x[f(B_\\tau)], \\quad x \\in \\mathcal{O}\n\\end{align*}\n\\tag{16}\\]\nIn other words, the value of the harmonic function of \\(f\\) at \\(x\\) is given by the average over the Brownian paths of the value of the function at the exit point of the path on the boundary of \\(\\mathcal{O}\\). Equation Equation 16 does not prove the existence of the solution to the Dirichlet problem, as we assume that such a function exists. Existence of the solution to the Dirichlet problem can be shown this way, assuming the region \\(\\mathcal{O}\\) and the function on the boundary are nice enough. However, note that the averaging on the right-hand side of the formula makes sense even in the case where \\(f\\) is simply defined on the boundary \\(\\partial \\mathcal{O}\\). We then define a posteriori the harmonic extension of \\(f\\) inside \\(\\mathcal{O}\\) by defining its value at \\(x\\) as \\(\\mathbb{E}_x[f(B_\\tau)]\\).\n\n\n\n\n\n\n\nExercise 1 Gaussian Integration by parts.\n\nLet \\(Z\\) be a standard Gaussian random variable. Show using integration by parts that for a differentiable function \\(g\\):\n\n\\[\n\\begin{align*}\n\\mathbb{E}[Z g(Z)] = \\mathbb{E}[g'(Z)]\n\\end{align*}\n\\tag{17}\\]\nwhere we assume that both expectations are well-defined.\n\nUse this to recover the expression for the moments for \\(\\mathbb{E}[Z^{2j}],j \\in \\mathbb{N}\\).\n\n\nSolution.\nWe have:\n\\[\n\\begin{align*}\n\\mathbb{E}[g'(Z)] &= \\int_{-\\infty}^{\\infty}\\phi(z) \\cdot g'(z) dz \\\\\n&= \\left[\\frac{e^{-z^2/2}}{\\sqrt{2\\pi}}\\cdot g(z)\\right]_{-\\infty}^{\\infty} - \\int_{-\\infty}^{\\infty} g(z) \\frac{-ze^{-z^2/2}}{\\sqrt{2\\pi}}dz \\\\\n&= 0 + \\int_{-\\infty}^{\\infty} z g(z) \\phi(z)dz\\\\\n&= \\mathbb{E}[Zg(Z)]\n\\end{align*}\n\\]\nMoreover, we can write:\n\\[\n\\begin{align*}\n\\mathbb{E}[Z^{2n}] &= \\mathbb{E}[Z \\cdot Z^{2n-1}] \\\\\n&= \\mathbb{E}[Z \\cdot g(Z)], \\quad \\{ \\text{ where }g(x)=x^{2n - 1}\\} \\\\\n&= \\mathbb{E}[g'(Z)] \\\\\n&= (2n - 1) \\mathbb{E}[Z^{(2n - 2)}] \\\\\n& \\vdots \\\\\n&= (2n - 1)\\cdots 5 \\cdot 3 \\cdot \\mathbb{E}[Z^2] \\\\\n&= (2n - 1)\\cdots 5 \\cdot 3 \\cdot 1\n\\end{align*}\n\\]\n\nExercise 2 The Heat Equation.\nUse the Gaussian integration by parts identity to check that the solution \\(f(t,x)\\) to the heat equation is:"
  },
  {
    "objectID": "posts/multivariate_ito_calculus/index.html#multidimensional-brownian-motion.",
    "href": "posts/multivariate_ito_calculus/index.html#multidimensional-brownian-motion.",
    "title": "Multivariate Ito Calculus",
    "section": "",
    "text": "Definition 1 (Brownian motion in \\(\\mathbf{R}^{d}\\).) Take \\(d\\in\\mathbf{N}\\). Let \\(B^{(1)},\\ldots,B^{(d)}\\) be independent standard Brownian motions in \\((\\Omega,\\mathcal{F},\\mathbb{P})\\). The process \\((B_{t}:t\\geq0)\\) taking values in \\(\\mathbf{R}^{d}\\) defined by :\n\\[\\begin{aligned}\nB_{t} & =(B_{t}^{(1)},\\ldots,B_{t}^{(d)}),\\quad t\\geq0\n\\end{aligned}\\]\nis called a \\(d-\\)dimensional Brownian motion or a Brownian motion in \\(\\mathbf{R}^{d}\\).\n\nThe Brownian filtration \\((\\mathcal{F}_{t}:t\\geq0)\\) is now composed of the information of all Brownian motions. In other words, it is given by the sigma-fields:\n\\[\\begin{aligned}\n\\mathcal{F}_{t} & =\\sigma(B_{s}^{(i)},1\\leq i\\leq d,s\\leq t)\n\\end{aligned}\\]\nFor every outcome \\(\\omega\\), the path of trajectory of a \\(d-\\)dimensional Brownian motion is a curve in space parametrized by the time \\(t\\):\n\\[\\begin{aligned}\nt\\mapsto B_{t}(\\omega) & =(B_{t}^{(1)}(\\omega),B_{t}^{(2)}(\\omega),\\ldots,B_{t}^{(d)}(\\omega))\n\\end{aligned}\\]\nOf course, this curve is continuous, since each coordinate is. The below numerical project gives an example of one path of a two-dimensional brownian motion. This is a very rugged and intertwined curve! We might wonder, what it does as \\(t\\to\\infty\\). Does it wander around \\((0,0)\\) ad infinitum or does it eventually escape to infinity? We will answer this question in a later section. For doing so, we shall need a version of Ito’s formula for multi-dimensional Brownian motion. We finish this section by noticing that it is also easy to construct Brownian motions in higher dimensions for which the coordinates are correlated.\n\n\nConsider a two-dimensional Brownian motion \\((B_{t}^{(1)},B_{2}^{(2)})\\) starting at \\((0,0)\\).\nLet’s plot one path of this Brownian motion on the plane \\(\\mathbf{R}^{2}\\) on the plane in \\(\\mathbf{R}^{2}\\) on the time interval \\([0,5]\\) using a discretization of \\(0.001\\).\nWe define BrownianMotion2D class.\n\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nsns.set_style(\"whitegrid\")\n\nclass BrownianMotion2D:\n    \"\"\"\n    Generate sample paths for a 2d-brownian motion\n    \"\"\"\n    def __init__(\n        self,\n        endpoint : float = 1.0,\n        discretization : float = 0.01\n    ):\n        self.endpoint = endpoint\n        self.discretization = discretization\n\n    def generate_paths(self, num_paths : int):\n        steps = int(self.endpoint/self.discretization)\n        delta_z = np.sqrt(self.discretization) * np.random.randn(num_paths,2,steps)\n        \n        # paths has shape [num_paths,2,num_steps]\n        paths = np.cumsum(delta_z,axis=2)\n\n        # Brownian motion has position (0,0) at time t=0\n        # Append initial position \n        init_position = np.zeros((num_paths,2,1))\n        paths = np.append(init_position,paths,axis=2)\n\n        return paths\n\nWe can then configure and use BrownianMotion2D objects as we please.\n\n\nShow the code\nbm = BrownianMotion2D(endpoint=5.0,discretization=0.001)\npaths = bm.generate_paths(num_paths=1)\npath = paths[0]\n\n\nplt.xlabel(r'$x$')\nplt.ylabel(r'$y$')\nplt.title(r'2D-Brownian motion')\nplt.grid(True)\nplt.plot(path[0],path[1],linewidth=1,color='blue')\nplt.show()\n\n\n\n\n\n\n\n\n\nExample 1 (Brownian motion with correlated coordinates) Let \\((B_{t}:t\\geq0)\\) be a two dimensional brownian motion. Let \\(-1&lt;\\rho&lt;1\\). We construct the two dimensional process as follows: \\(W_{t}=(W_{t}^{(1)},W_{t}^{(2)})\\) where:\n\\[\\begin{aligned}\nW_{t}^{(1)} & =B_{t}^{(1)}\\\\\nW_{t}^{(2)} & =\\rho B_{t}^{(1)}+\\sqrt{1-\\rho^{2}}B_{t}^{(2)}\n\\end{aligned}\\]\n\\(W_{t}^{(1)}=B_{t}^{(1)}\\) is Gaussian with mean \\(0\\) and variance \\(t\\). Since, \\(B_{t}^{(1)}\\) and \\(B_{t}^{(2)}\\)are independent gaussian random variables and the sum of IID Gaussians is Gaussian, \\(W_{t}^{(2)}\\) is Gaussian with mean \\(0\\) and variance \\(t\\). The covariance between \\(W_{t}^{(1)}\\) and \\(W_{t}^{(2)}\\) is:\n\\[\\begin{aligned}\n\\mathbf{E}[W_{t}^{(1)}W_{t}^{(2)}] & =\\mathbf{E}[B_{t}^{(1)}(\\rho B_{t}^{(1)}+\\sqrt{1-\\rho^{2}}B_{t}^{(2)})]\\\\\n& =\\mathbf{E}[\\rho(B_{t}^{(1)})^{2}+\\sqrt{1-\\rho^{2}}B_{t}^{(1)}B_{t}^{(2)}]\\\\\n& =\\rho t\n\\end{aligned}\\]\nHence, the coordinates at time \\(t\\) are not independent.\n\nConsider now the process \\((W_{t}:t\\geq0)\\) for \\(\\rho=1/2\\) as in example 2. Let’s plot one path of this process on the plane \\(\\mathbf{R}^{2}\\) on the time-interval \\([0,5]\\) using a discretization of \\(0.001\\).\n\nclass BrownianMotion2DWithCorrelatedCoords(BrownianMotion2D):\n    \"\"\"\n    Generate sample paths for a 2d-brownian motion\n    have correlated coordiantes\n    \"\"\"\n\n    def __init__(\n        self, \n        endpoint: float = 1.0, \n        discretization: float = 0.01, \n        rho: float = 0.0\n    ):\n        self.endpoint = endpoint\n        self.discretization = discretization\n        self.rho = rho\n\n    def generate_paths(self, num_paths: int):\n\n        # Call the base class generate_paths() method to generate a pair of\n        # independent brownian motion paths. It returns a tensor of\n        # shape (num_paths, 2, num_steps)\n        paths = super().generate_paths(num_paths=num_paths)\n\n        # Extract the brownian motions B1(t) and B2(t)\n        # B1(t) and B2(t) have dimensions [num_paths,num_steps]\n        x_coord = paths[:, 0, :]\n        y_coord = paths[:, 1, :]\n\n        # Apply the transformation\n        # W1(t) = B1(t)\n        # W2(t) = rho * B1(t) + sqrt(1 - rho**2) B2(t)\n        x_coord = x_coord\n        y_coord = self.rho * x_coord + np.sqrt(1 - self.rho**2) * y_coord\n\n        # Assemble back the x- and y- coordinates\n        x_coord = np.expand_dims(x_coord, axis=1)\n        y_coord = np.expand_dims(y_coord, axis=1)\n\n        # Return a tensor of shape [num_paths,d=2,num_steps]\n        return np.concatenate([x_coord, y_coord], axis=1)\n\nLet’s configure the BrownianMotion2DWithCorrelatedCoords engine with the settings endpoint=5.0, discretization=0.001 and rho=0.5 and generate a sample path.\n\n\nShow the code\nbm = BrownianMotion2DWithCorrelatedCoords(\n    endpoint=5.0,\n    discretization=0.001,\n    rho=0.50\n)\npaths = bm.generate_paths(num_paths=1)\npath = paths[0]\n\nplt.xlabel(r'$x$')\nplt.ylabel(r'$y$')\nplt.title(r'Correlated Brownian motion $W(t)=(W^{(1)}(t),W^{(2)}(t))$')\nplt.grid(True)\nplt.plot(path[0],path[1],linewidth=1,color='blue')\nplt.show()\n\n\n\n\n\n\n\nShow the code\nplt.xlabel(r'$t$')\nplt.ylabel(r'$W_t$')\nplt.title(r'Correlated Brownian motion paths')\nplt.grid(True)\nt = np.linspace(0.0,stop=5.0,num=5001)\nplt.plot(t,path[0],linewidth=0.75)\nplt.plot(t,path[1],linewidth=0.75)\nplt.show()"
  },
  {
    "objectID": "posts/multivariate_ito_calculus/index.html#itos-formula.",
    "href": "posts/multivariate_ito_calculus/index.html#itos-formula.",
    "title": "Multivariate Ito Calculus",
    "section": "",
    "text": "Theorem 1 (Ito’s Formula.) Let \\((B_{t}:t\\geq0)\\) be a \\(d-\\)dimensional brownian motion. Consider \\(f\\in\\mathcal{C}^{2}(\\mathbf{R}^{d})\\). Then, we have with probability one that for all \\(t\\geq0\\):\n\\[\\begin{aligned}\nf(B_{t})-f(B_{0}) & =\\sum_{i=1}^{d}\\int_{0}^{t}\\partial_{x_{i}}f(B_{s})dB_{s}^{(i)}+\\frac{1}{2}\\int_{0}^{t}\\sum_{i=1}^{d}\\partial_{x_{i}}^{2}f(B_{s})ds\\label{eq:multidimensional-ito-formula}\n\\end{aligned}\\]\n\n\nI stress that, as in the one-dimensional case, Ito’s formula is an equality of processes (and not an equality in distribution). Thus, the processes on both sides must agree for each path.\n\nInterestingly, the mixed partials \\(\\partial_{x_{i}x_{j}}f(B_{s})\\), \\(i\\neq j\\) do not appear in the formula! We see from Ito’s formula that the process \\(f(B_{t})\\) can be represented as a sum of \\(d+1\\) processes: \\(d\\) Ito integrals and one Riemann integral (which is a process of finite variation). In vector notation, the formula takes the form:\n\\[\\begin{aligned}\nf(B_{t})-f(B_{0}) & =\\int_{0}^{t}\\nabla f(B_{s})^{T}dB_{s}+\\frac{1}{2}\\int_{0}^{t}\\nabla^{2}f(B_{s})ds\n\\end{aligned}\\]\nwhere it is understood that the first term is the sum of the \\(d\\) Ito integrals in the equation. The symbol \\(\\nabla^{2}\\) is the Laplacian of \\(f\\):\n\\(\\sum_{i=1}^{d}\\frac{\\partial^{2}}{\\partial x_{i}^{2}}f(B_{s}^{(1)},\\ldots,B_{s}^{(d)})ds\\)\nIn differential form, Ito’s formula becomes very neat:\n\\[\\begin{aligned}\ndf(B_{t}) & =\\sum_{i=1}^{d}\\partial_{x_{i}}f(B_{s})dB_{t}^{(i)}+\\frac{1}{2}\\sum_{i=1}^{d}\\partial_{x_{i}}^{2}f(B_{s})dt=\\nabla f(B_{t})^{T}dB_{s}+\\frac{1}{2}\\nabla^{2}f(B_{t})dt\n\\end{aligned}\\]\n\nExample 2 Consider the functions (1) \\(f(x_{1},x_{2})=x_{1}^{2}+x_{2}^{2}\\) (2) \\(f(x_{1},x_{2})=e^{x_{1}}\\cos x_{2}\\) and the processes \\((X_{t}:t\\geq0)\\) and \\((Y_{t}:t\\geq0)\\). If we apply Ito’s formula to the first process, we have:\n\\[\\begin{aligned}\nX_{t} & =\\int_{0}^{t}2B_{s}^{(1)}dB_{s}^{(1)}+\\int_{0}^{t}2B_{s}^{(2)}dB_{s}^{(2)}+\\frac{1}{2}\\int_{0}^{t}(4dt)\\\\\n& =\\int_{0}^{t}2B_{s}^{(1)}dB_{s}^{(1)}+\\int_{0}^{t}2B_{s}^{(2)}dB_{s}^{(2)}+2t\n\\end{aligned}\\]\nThe second process gives:\n\\[\\begin{aligned}\nY_{t} & =\\cos B_{s}^{(2)}\\int_{0}^{t}e^{B_{s}^{(1)}}dB_{s}^{(1)}-e^{B_{s}^{(1)}}\\int\\sin B_{s}^{(2)}dB_{s}^{(2)}+\\frac{1}{2}\\int_{0}^{t}\\left(e^{B_{s}^{(1)}}\\cos B_{s}^{(2)}-e^{B_{s}^{(1)}}\\cos B_{s}^{(2)}\\right)dt\\\\\n& =1+\\cos B_{s}^{(2)}\\int_{0}^{t}e^{B_{s}^{(1)}}dB_{s}^{(1)}-e^{B_{s}^{(1)}}\\int\\sin B_{s}^{(2)}dB_{s}^{(2)}\n\\end{aligned}\\]\n\n\nExample 3 (Cross-Variation of \\(B_{t}^{(1)}\\) and \\(B_{t}^{(2)}\\)). Let \\((t_{j}:j\\leq n)\\) be a sequence of partitions of \\([0,t]\\) such that \\(\\max_{j}|t_{j+1}-t_{j}|\\to0\\) as \\(n\\to\\infty\\). Prove that:\n\\[\\begin{aligned}\n\\lim_{n\\to\\infty}\\sum_{j=0}^{n-1}(B_{t_{j+1}}^{(1)}-B_{t_{j}}^{(1)})(B_{t_{j+1}}^{(2)}-B_{t_{j}}^{(2)}) & =0\\quad\\text{in } L^{2}\n\\end{aligned}\\]\nThis justifies the rule \\(dB_{t}^{(1)}\\cdot dB_{t}^{(2)}=0\\).\nHint: Just compute the second moment of the sum.\n\n\nWe have:\n\\[\\begin{aligned}\n& \\mathbf{E}\\left[\\left(\\sum_{j=0}^{n-1}(B_{t_{j+1}}^{(1)}-B_{t_{j}}^{(1)})(B_{t_{j+1}}^{(2)}-B_{t_{j}}^{(2)})\\right)^{2}\\right]\\\\\n= & \\sum_{j=0}^{n-1}\\mathbf{E}[(B_{t_{j+1}}^{(1)}-B_{t_{j}}^{(1)})^{2}(B_{t_{j+1}}^{(2)}-B_{t_{j}}^{(2)})^{2}]\\\\\n+ & 2\\sum_{j&lt;k}\\mathbf{E}\\left[(B_{t_{j+1}}^{(1)}-B_{t_{j}}^{(1)})(B_{t_{k+1}}^{(1)}-B_{t_{k}}^{(1)})(B_{t_{j+1}}^{(2)}-B_{t_{j}}^{(2)})(B_{t_{k+1}}^{(2)}-B_{t_{k}}^{(2)})\\right]\n\\end{aligned}\\]\nBoth these expectations are zero, since the brownian motions are independent and non-overlapping increments are independent.\nConsequently, \\(\\sum_{j=0}^{n-1}(B_{t_{j+1}}^{(1)}-B_{t_{j}}^{(1)})(B_{t_{j+1}}^{(2)}-B_{t_{j}}^{(2)})\\to0\\) in the \\(L^{2}\\) sense.\n\n\nProof. The proof of the formula follows the usual recipe: Taylor’s theorem together with the quadratic variation and the cross-variation. In this case, we do get a cross-variation between the different Brownian motions. More precisely, consider a partition \\((t_{j}:j\\leq n)\\) of \\([0,t]\\). Then we can write:\n\\[\\begin{aligned}\nf(B_{t})-f(B_{0}) & =\\sum_{j=0}^{n-1}(f(B_{t_{j+1}})-f(B_{t_{j}}))\n\\end{aligned}\\]\nWe can apply the Taylor’s series expansion for each \\(j\\) to get:\n\\[\\begin{aligned}\nf(B_{t})-f(B_{0}) & =\\sum_{j=0}^{n-1}\\nabla f(B_{t_{j}})(B_{t_{j+1}}-B_{t_{j}})\\\\\n& +\\frac{1}{2}\\sum_{j=0}^{n-1}(B_{t_{j+1}}-B_{t_{j}})^{T}Hf(B_{t_{j}})(B_{t_{j+1}}-B_{t_{j}})+\\mathcal{E}\n\\end{aligned}\\]\nwhere \\(Hf\\) is the Hessian matrix of \\(f\\). We wrote the expansion using the vector notation to be economical. Let’s keep in mind that each term is a sum over the derivatives. The first term will converge to \\(d\\) Ito integrals as in the one-dimensional case. Now, the summand in the second term is:\n\\[(B_{t_{j+1}}^{(1)}-B_{t_{j}}^{(1)},\\ldots,B_{t_{j+1}}^{(d)}-B_{t_{j}}^{(d)})\\left[\\begin{array}{ccc}\n\\partial_{x_{1}}^{2}f(B_{t_{j}}) & \\ldots & \\partial_{x_{1}x_{d}}^{2}f(B_{t_{j}})\\\\\n\\vdots & \\ddots\\\\\n\\partial_{x_{d}x_{1}}^{2}f(B_{t_{j}}) &  & \\partial_{x_{d}}^{2}f(B_{t_{j}})\n\\end{array}\\right]\\left[\\begin{array}{c}\nB_{t_{j+1}}^{(1)}-B_{t_{j}}^{(1)}\\\\\n\\vdots\\\\\nB_{t_{j+1}}^{(d)}-B_{t_{j}}^{(d)}\n\\end{array}\\right]\\]\nSo, \\((B_{t_{j+1}}^{(i)}-B_{t_{j}}^{(i)})\\) is pre-multiplied with the term \\(\\partial_{x_{i}x_{k}}^{2}f(B_{t_{j}})\\) and it is post-multiplied \\((B_{t_{j+1}}^{(k)}-B_{t_{j}}^{(k)})\\). Consequently, the second term in the Taylor’s series expansion can be re-written as:\n\\[\\sum_{j=0}^{n-1}\\left(\\sum_{i=1}^{d}\\partial_{x_{i}}^{2}f(B_{t_{j}})(B_{t_{j+1}}^{(i)}-B_{t_{j}}^{(i)})^{2}+\\sum_{1\\leq i&lt;k\\leq d}\\partial_{x_{i}x_{k}}^{2}f(B_{t_{j}})(B_{t_{j+1}}^{(i)}-B_{t_{j}}^{(i)})(B_{t_{j+1}}^{(k)}-B_{t_{j}}^{(k)})\\right)\\]\nThe second term on the right converges to \\(0\\) in the \\(L^{2}\\) sense when \\(i\\neq k\\), from exercise. This explains why the mixed derivatives disappear in the multi-dimensional Ito’s formula. As for the case \\(i=k\\), it reduces to the quadratic variation as in the one-dimensional case. This is where the Riemann integral arises, after suitable conditioning on \\(\\mathcal{F}_{t_{j}}\\), the sigma-field generated by \\(B_{s}\\), \\(s\\leq t_{j}\\).\n\nAs in the one-dimensional case,it is not necessary to learn Ito’s formula by heart. It suffices to write the differential of the function \\(f\\) to second order. We can then apply the rules of multivariate Ito calculus:\n\n\n\n\\(\\cdot\\)\n\\(dt\\)\n\\(dB_{t}^{(1)}\\)\n\\(dB_{t}^{(2)}\\)\n\\(\\ldots\\)\n\n\n\n\n\\(dt\\)\n\\(0\\)\n\\(0\\)\n\\(0\\)\n\\(0\\)\n\n\n\\(dB_{t}^{(1)}\\)\n\\(0\\)\n\\(dt\\)\n\\(0\\)\n\\(0\\)\n\n\n\\(dB_{t}^{(2)}\\)\n\\(0\\)\n\\(0\\)\n\\(dt\\)\n\\(0\\)\n\n\n\\(\\ldots\\)\n\\(0\\)\n\\(0\\)\n\\(0\\)\n\\(dt\\)\n\n\n\nNote that the rule \\(dB_{t}^{(i)}dB_{t}^{(j)}=0\\) for \\(i\\neq j\\) is being motivated by the cross-variation result.\nHow can we construct martingales using the Ito’s formula? Recall that an Ito integral \\((\\int_{0}^{t}X_{s}dB_{s},t\\leq T)\\) is a martingale whenever the integrand is in \\(\\mathcal{L}_{c}^{2}(T)\\), the space of adapted processes with continuous paths and for which:\n\\[\\begin{aligned}\n\\int_{0}^{T}\\mathbf{E}[X_{s}^{2}]ds & &lt;\\infty\n\\end{aligned}\\]\nThe only difference here is that the integrand is a function of many Brownian motions. However, the integrands involved in the Ito integrals of the multidimensional Ito’s formula are clearly adapted to the filtration \\((\\mathcal{F}_{t}:t\\geq0)\\) of \\((B_{t}:t\\geq0)\\) as they are functions of the Brownian motion at the time. The arguments of Ito integral in and apply verbatim, if we take the definition of \\(\\mathcal{L}_{c}^{2}(t)\\) with the filtration \\((\\mathcal{F}_{t}:t\\geq0)\\) of \\((B_{t}:t\\geq0)\\). With this in mind, we have the following corollary.\n\n\n\nCorollary 1 (Brownian Martingales.) Let \\((B_{t}:t\\geq0)\\) be a Brownian motion in \\(\\mathbf{R}^{d}\\). Consider \\(f\\in\\mathcal{C}^{2}(\\mathbf{R}^{d})\\) such that processes \\((\\partial_{x {i}}f(B_{t}),t\\leq T)\\in\\mathcal{L}_{c}^{2}(T)\\) for every \\(i\\leq d\\). Then, the process :\n\\[f(B_{t})-\\frac{1}{2}\\int_{0}^{t}\\nabla^{2}f(B_{s})ds,\\quad t\\leq T\\]\nwhere \\(\\nabla^{2}=\\sum_{i=1}^{d}\\partial_{x_{i}}^{2}\\) is the Laplacian, is a martingale for the Brownian filtration.\n\nFor example, consider the processes \\(X_{t}=(B_{t}^{(1)})^{2}+(B_{t}^{(2)})^{2}\\) and \\(Y_{t}=\\exp(B_{t}^{(1)})\\cos(B_{t}^{(2)})\\). Then, we have :\n\\[\\frac{1}{2}\\int_{0}^{t}\\nabla^{2}X_{s}ds=\\frac{1}{2}\\int_{0}^{t}4ds=2t\\]\nand\n\\[\\begin{aligned}\n\\frac{1}{2}\\int_{0}^{t}\\nabla^{2}Y_{s}ds & =\\frac{1}{2}\\int_{0}^{t}0\\cdot ds=0\n\\end{aligned}\\]\nThus, the processes \\(X_{t}-2t\\) and \\(Y_{t}\\) are martingales for the Brownian filtration. In one dimension, there are no interesting martingales constructed with functions of space only. Indeed, \\((f(B_{t}):t\\geq0)\\) is a martingale if and only if \\(f''(x)=0\\) for all \\(x\\). But, such functions are of the form \\(f(x)=ax+b\\), \\(a,b\\in\\mathbf{R}\\). In other words, in one dimension, Brownian martingales of the form \\(f(B_{t})\\) are simply \\(aB_{t}+b\\). Not very surprising! The situation is very different in higher dimensions. Indeed, corollary implies that \\(f(B_{t})\\) is a martingale whenever \\(f\\) is a harmonic function:\n\nDefinition 2 (Harmonic function.) A function \\(f:\\mathbf{R}^{d}\\to\\mathbf{R}\\) is harmonic in \\(\\mathbf{R}^{d}\\) if and only if \\(\\nabla^{2}f(x)\\equiv0\\) for all \\(x\\in\\mathbf{R}^{d}\\). More generally, a function \\(f:\\mathbf{R}^{d}\\to\\mathbf{R}\\) is harmonic in the region \\(\\mathcal{O}\\subset\\mathbf{R}^{d}\\) if and only if \\(\\nabla^{2}f(x)\\equiv0\\) for all \\(x\\in\\mathcal{O}\\).\n\nNote that the function \\(f(x)=e^{x_{1}}\\cos x_{2}\\) is harmonic in \\(\\mathbf{R}^{d}\\). This is why the process \\(Y_{t}=\\exp(B_{t}^{(1)})\\cos(B_{t}^{(2)})\\) is a martingale. The distinction to a subset of \\(\\mathbf{R}^{d}\\) in the above definition is important since it may happen that the function is harmonic only in a subset of the space; see for example equation. It is possible to define a Brownian martingale in such cases by considering the process until it exits the region. This will turn out to be important as we move ahead.\nThe multidimensional Ito’s formula generalizes to functions of time and space as in proposition:\n\nDefinition 3 A function \\(f:[0,\\infty)\\times\\mathbf{R}^{d}\\to\\mathbf{R}\\) is in \\(\\mathcal{C}^{1,2}([0,T]\\times\\mathbf{R}^{d})\\) if the partial derivative in time :\n\\[\\frac{\\partial}{\\partial t}f(t,\\mathbf{x})\\]\nexists and is continuous and the second order partial derivatives in space:\n\\[\\frac{\\partial^{2}}{\\partial x_{i}^{2}}f(t,x_{1},x_{2},\\ldots,x_{i},\\ldots,x_{d}),\\quad1\\leq i\\leq d\\]\nexist and are continuous."
  },
  {
    "objectID": "posts/multivariate_ito_calculus/index.html#multidimensional-ito-formula---functions-of-space-and-time",
    "href": "posts/multivariate_ito_calculus/index.html#multidimensional-ito-formula---functions-of-space-and-time",
    "title": "Multivariate Ito Calculus",
    "section": "",
    "text": "Theorem 2 (Multidimensional Ito’s formula for functions of space and time) Let \\((B_{t}:t\\leq T)\\) be a \\(d\\)-dimensional Brownian motion. Consider a function \\(f\\in\\mathcal{C}^{1,2}([0,T]\\times\\mathbf{R}^{d})\\). Then, we have with probability one for all \\(t\\leq T\\):\n\\[\\begin{aligned}\nf(t,B_{t})-f(0,B_{0}) & =\\sum_{i=1}^{d}\\int_{0}^{t}\\partial_{x_{i}}f(s,B_{s})dB_{s}^{(i)}+\\int_{0}^{t}\\left(\\partial_{t}f(s,B_{s})+\\sum_{i=1}^{d}\\partial_{x_{i}}^{2}f(s,B_{s})\\right)ds\n\\end{aligned}\\]\n\nThe martingale condition is then similar to the ones in corollary ([cor:brownian-martingales-in-Rd]): if the processes \\((\\partial_{x_{i}}f(s,B_{s}),t\\leq T)\\in\\mathcal{L}_{c}^{2}(T)\\) for every \\(1\\leq i\\leq d\\), then the process\n\\[f(t,B_{t})-\\int_{0}^{t}\\left\\{ \\partial_{t}f(s,B_{s})++\\sum_{i=1}^{d}\\partial_{x_{i}}^{2}f(s,B_{s})\\right\\} ds,\\quad t\\leq T \\tag{1}\\]\nis a martingale for the Brownian filtration. In particular, if \\(f\\) satisfies the partial differential equation:\n\\[\n\\begin{aligned}\n\\frac{\\partial f}{\\partial t}+\\frac{1}{2}\\nabla^{2}f & =0\n\\end{aligned}\n\\tag{2}\\]\nthen the process \\((f(t,B_{t}):t\\leq T)\\) itself is a martingale."
  },
  {
    "objectID": "posts/multivariate_ito_calculus/index.html#polyas-random-walk-theorem",
    "href": "posts/multivariate_ito_calculus/index.html#polyas-random-walk-theorem",
    "title": "Multivariate Ito Calculus",
    "section": "",
    "text": "Consider a simple random walk on the integer lattice \\(\\mathbb{Z}^d\\). At each time step, a random walker makes a random move of length one in one of the lattice directions.\nWe say that, if the random walk returns to the origin with probability one infinitely many times, it is recurrent, if it does not we will call it transient.\nIt’s worth to spend a moment visiting Polya’s Random Walk Theorem, a fascinating, but not so intuitive result.\nAssuming all random walks start at the origin, we define \\(u\\) to be the probability that a random walker returns to the origin. The probability that the random walker returns to the origin exactly \\(m\\) times is:\n\\[\\begin{align*}\n{m \\choose m-1} u^{m-1} (1 - u)^{m - (m - 1)} = u^{m-1}(1-u)\n\\end{align*}\\]\nThe expected number of times the particle returns to the origin for an infinite random walk is:\n\\[\\begin{align*}\nE &= \\sum_{m = 1}^{\\infty} m (u^{m-1}(1-u))\\\\\n&= (1-u)\\sum_{m=1}^{\\infty}mu^{m-1}\\\\\n&= (1-u)\\sum_{m=1}^{\\infty}\\frac{d}{du}u^{m}\\\\\n\\end{align*}\\]\nWe note that limit exchanging is acceptable since the power series \\(\\sum_{n=1}^{\\infty}x^n\\) converges uniformly for \\(u &lt; 1\\) and we can apply the differentiable limit theorem.\nSo we obtain:\n\\[\\begin{align*}\nE &= (1-u)\\frac{d}{du}\\sum_{m = 1}^{\\infty} u^m \\\\\n&= (1-u)\\cdot \\frac{1}{(1-u)^2}\\\\\n&= \\frac{1}{1-u}\n\\end{align*}\\]\nSo, we see that if \\(E\\) is finite, \\(u &lt; 1\\), then the walk is transient and if \\(E = +\\infty\\), \\(u=1\\), then the walk is recurrent.\nWe then define \\(u_n\\) to be the probability that a given walk is at the origin on the \\(n\\)th step, defining the value \\(u_0=1\\) for the trivial loop. We also introduce an indicator random variable \\(x_n\\), which takes the value \\(1\\), if the particle is at the origin on the \\(n\\)th step and zero otherwise.\nThen\n\\[\\begin{align*}\nT = \\sum_{n=1}^{\\infty}x_n\n\\end{align*}\\]\nis the total number of times, the particle is at the origin, so \\(E\\) is equal to the expectation of \\(T\\), \\(\\mathbb{E}(T)\\), which is equal to:\n\\[\\begin{align*}\n\\mathbb{E}[T] &= \\sum_{n=1}^{\\infty}\\mathbb{E}[x_n]\\\\\n&= \\sum_{n=1}^{\\infty} u_n\n\\end{align*}\\]\nBut, we showed previously that if \\(E\\) is finite, then the walk is transient and if \\(E = \\infty\\), then the walk is recurrent, so we have established that if:\n\\[\\begin{align*}\n\\sum_{n=1}^{\\infty}u_n\n\\end{align*}\\]\nconverges then the walk is transient and if the sum diverges, then the walk is recurrent.\n\n\nNow that we have built up the necessary tools, we will consider the cases. We start by considering a simple random walk on \\(\\mathbb{Z}^1\\). Since, as mentioned previously, a walk must have an even number of steps to be a loop, we only look at \\(u_{2n},n \\in \\mathbb{Z}^+\\). A path of length \\(2n\\) returning to the origin must have \\(n\\) up-moves and \\(n\\) down-moves. The number of such paths are \\({2n \\choose n}\\). Each such path has a probability of occurrence \\(\\frac{1}{2^{2n}}\\). Thus,\n\\[\\begin{align*}\nu_{2n} = \\frac{1}{2^{2n}}{2n \\choose n}\n\\end{align*}\\]\nUsing Stirling’s approximation \\(n! \\sim \\sqrt{2\\pi n} e^{-n} n^{n}\\), we obtain:\n\\[\\begin{align*}\nu_{2n} &= \\frac{1}{2^{2n}} \\frac{(2n)!}{n! n!}\\\\\n&\\approx \\frac{1}{2^{2n}} \\cdot \\frac{\\sqrt{2\\pi(2n)} e^{-2n}(2n)^{2n}}{\\left(\\sqrt{2\\pi n} e^{-n} n^n\\right)^2}\\\\\n&=\\frac{1}{\\sqrt{\\pi n}}\n\\end{align*}\\]\nSo, we see that:\n\\[\\begin{align*}\n\\sum_{n=0}^{\\infty} u_{2n} \\approx \\sum_{n=0}^{\\infty} \\frac{1}{\\sqrt{n\\pi}}\n\\end{align*}\\]\nAnd the series on the right certainly diverges so, we see that a simple random walk in \\(\\mathbb{Z}^1\\) is recurrent since \\(E\\) diverges.\n\n\n\nA particle has an equal probability \\(1/4\\) of moving left, right, up or down randomly in the \\(d=2\\) dimensional lattice. Each path of \\(2n\\) steps has a probability \\(\\frac{1}{4^{2n}}\\) of occurring. We then consider the number of paths with equal steps left and right (say \\(L\\) steps in each horizontal direction) and equal steps up and down (then \\(n-L\\)) is:\n\\[\\begin{align*}\n{2n \\choose L}{2n - L \\choose L}{2n - 2L \\choose n - L}{n-L \\choose n - L} = \\frac{(2n)!}{L! L! (n-L)! (n-L)!}\n\\end{align*}\\]\nSo we get:\n\\[\\begin{align*}\nu_{2n} &= \\frac{1}{4^{2n}} \\sum_{L=0}^n \\frac{(2n)!}{L! L! (n-L)! (n-L)!} \\\\\n&= \\frac{1}{4^{2n}} \\sum_{L=0}^n \\frac{(2n)!}{n! n!} \\cdot \\left(\\frac{n!}{L! (n-L)!}\\right)^2 \\\\\n&=\\frac{1}{4^{2n}} {2n \\choose n}\\sum_{L=0}^n {n \\choose L}^2\n\\end{align*}\\]\nSuppose, we are to form a team of \\(n\\) players from a population of \\(2n\\) participants. There \\({2n \\choose n}\\) distinguishable teams of size \\(n\\). Alternatively, we could divide the population into two halves of \\(n\\) participants each, choose \\(L\\) participants from the first sub-population, and the remaining \\(n-L\\) participants from the second sub-population. So, the number of distinguishable teams is:\n\\[\\begin{align*}\n\\sum_{L=0}^{n}{n \\choose L}{n \\choose n - L} = \\sum_{L=0}^{n} {n \\choose L}^2\n\\end{align*}\\]\nSo, we have the combinatorial identity:\n\\[\\begin{align*}\n\\sum_{L=0}^{n} {n \\choose L}^2 = {2n \\choose n}\n\\end{align*}\\]\nThus,\n\\[\\begin{align*}\nu_{2n} &=\\frac{1}{4^{2n}} {2n \\choose n}\\sum_{L=0}^n {n \\choose L}^2\\\\\n&= \\left(\\frac{1}{2^{2n}} {2n \\choose n}\\right)^2\n\\end{align*}\\]\nSo, we have that, it is just the square of the result from \\(\\mathbb{Z}^1\\), so we see in this case that:\n\\[\\begin{align*}\nu_{2n} &\\approx \\sum_{n=0}^{\\infty} \\frac{1}{\\pi n}\n\\end{align*}\\]\nAnd the series on the right certainly diverges, so we see that a simple random walk in \\(\\mathbb{Z}^2\\) is recurrent as \\(E\\) diverges.\n\n\n\nAs before, in order to have a walk return to the origin we must have equal steps in the positive and negative directions for each direction and each path of \\(2n\\) has a probability of occurring of \\(\\frac{1}{6^{2n}}\\). Then, extending the idea from the previous subsection, the number of paths (of total length \\(2n\\)) with \\(L\\) steps left and right, \\(U\\) steps up and down and \\(n - L - U\\) steps forward and backward is:\n\\[\\begin{align*}\n\\frac{(2n)!}{L! L! U! U! (n - L - U)! (n - L - U)!}\n\\end{align*}\\]\nSo, we get:\n\\[\n\\begin{align*}\nu_{2n} &= \\frac{1}{6^{2n}} \\sum_{L,U,L+U \\leq n} \\frac{(2n)!}{L! L! U! U! (n - L - U)! (n - L - U)!} \\\\\n&= \\frac{1}{2^{2n}} {2n \\choose n} \\sum_{L,U,L+U \\leq n} \\left(\\frac{1}{3^n}\\frac{n!}{L! U! (n - U - L)!}\\right)^2\n\\end{align*}\n\\tag{3}\\]\nConsider a \\(3\\)-sided fair coin, with \\(\\mathbb{P}\\{\\text{Heads}\\} = \\mathbb{P}\\{\\text{Tails}\\} = \\mathbb{P}\\{\\text{Edge}\\} = \\frac{1}{3}\\). Suppose that the coin is tossed \\(n=3^2 = 9\\) times. The probability of landing \\(L\\) heads, \\(U\\) tails and \\(n - L - U\\) edges is \\(\\frac{n!}{L!U!(n-L-U)!} \\frac{1}{3^n}\\). This is precisely the term seen in the above expression. The number of heads, tails and edges in \\(n\\) coin tosses follows a multinomial distribution. It can be easily demonstrated, that in, \\(n/3 = 3\\) heads, \\(n/3\\) tails and \\(n/3\\) edges are most likely to occur in \\(n\\) coin tosses. So, we can find an upper bound on the summand in Equation 3 as:\n\\[\\begin{align*}\n\\frac{n!}{3^n L! U! (n- L - U)!} \\leq \\frac{n!}{3^n \\lfloor\\frac{n}{3}\\rfloor! \\lfloor\\frac{n}{3}\\rfloor! \\lfloor\\frac{n}{3}\\rfloor!}\n\\end{align*}\\]\nAlso, from the multinomial expansion theorem:\n\\[\\begin{align*}\n(1 + a + b)^n = \\sum_{L,U,L+U\\leq n} \\frac{n!}{L! U! (n-L-U)!} a^L b^U\n\\end{align*}\\]\nSetting \\(a = b = 1\\), we get:\n\\[\\begin{align*}\n\\sum_{L,U,L+U\\leq n} \\frac{n!}{3^n L! U! (n-L-U)!} a^L b^U = 1\n\\end{align*}\\]\nWe then see that:\n\\[\\begin{align*}\nu_{2n} \\leq \\frac{1}{2^{2n}} {2n \\choose n} \\frac{n!}{3^n \\lfloor\\frac{n}{3}\\rfloor! \\lfloor\\frac{n}{3}\\rfloor! \\lfloor\\frac{n}{3}\\rfloor!}\n\\end{align*}\\]\nWe can simplify this as:\n\\[\\begin{align*}\nu_{2n} &= \\frac{1}{2^{2n}}{2n \\choose n} \\frac{n!}{3^n \\left(\\lfloor\\frac{n}{3}\\rfloor!\\right)^3} \\\\\n&\\approx \\frac{1}{\\sqrt{\\pi n}} \\times \\frac{\\sqrt{2\\pi n} e^{-n} n^n}{3^n \\left\\{\\sqrt{2\\pi \\frac{n}{3}}e^{-n/3} \\left(\\frac{n}{3}\\right)^{n/3}\\right\\}^3}\\\\\n&= \\frac{1}{\\sqrt{\\pi n}} \\frac{\\sqrt{2\\pi n} e^{-n} n^n}{3^n \\frac{(2\\pi n)^{3/2}}{3^{3/2}} e^{-n} \\frac{n^n}{3^n}}\\\\\n&= \\frac{1}{\\sqrt{\\pi n}} \\frac{\\sqrt{2\\pi n} \\cancel{e^{-n}} \\cancel{n^n}}{\\cancel{3^n} \\frac{(2\\pi n)^{3/2}}{3^{3/2}} \\cancel{e^{-n}} \\frac{ \\cancel{n^n}}{\\cancel{3^n}}}\\\\\n&\\approx \\frac{M}{(\\pi n)^{3/2}}\n\\end{align*}\\]\nwhere \\(M\\) is a positive constant. We then see:\n\\[\\begin{align*}\n\\sum_n u_{2n} &= M \\sum_n \\frac{1}{n^{\\frac{3}{2}}}\n\\end{align*}\\]\nThe sum on the right hand side converges, so we have that a simple random walk in three dimensions is transient. The proof of Polya’s Random Walk Theorem is complete."
  },
  {
    "objectID": "posts/multivariate_ito_calculus/index.html#recurrence-and-transience-of-brownian-motion",
    "href": "posts/multivariate_ito_calculus/index.html#recurrence-and-transience-of-brownian-motion",
    "title": "Multivariate Ito Calculus",
    "section": "",
    "text": "In one dimension, we established that every path of a Brownian motion reaches any level \\(a \\in \\mathbf{R}\\). More precisely, for \\(a &gt; 0\\), if we define the stopping time :\n\\[\\begin{align*}\n\\tau = \\min \\{ t \\geq 0 : B_t \\geq a\\}\n\\end{align*}\\]\nwe have \\(\\mathbb{P}\\{\\tau_a &lt; \\infty \\} = 1\\). This implies in particular that every path will come back to \\(0\\) and will do infinitely many times. This is because \\(B(t+\\tau) - B(t)\\) is a standard brownian motion. This property of Brownian motion is called recurrence. This is to be compared with Brownian motion with a drift. In our analysis, we found that, if the drift is negative, then there are paths that will not reach a given level \\(a &gt; 0\\) with positive probability. Such paths go to infinity without ever going back to \\(0\\). This property of the process is called transience.\nWe can derive similar properties for the multidimensional Brownian motion. We will rely heavily on Corollary 1 and on some knowledge of harmonic functions. Harmonic functions play a very important role in mathematics, physics and in nature in general. As we mentioned earlier, if \\(d = 1\\), the only harmonic functions are the linear functions, since the equation \\(f''(x) = 0\\) has the solutions \\(f(x)=ax+b\\). However, in higher dimensions, the collection of harmonic functions is very rich. This gives access to a plethora of Brownian martingales. For example, the following functions are harmonic in the whole space minus the origin, \\(\\mathbf{R}^d \\setminus \\{0\\}\\).\n\\[\nh(x) = \\begin{cases}\n\\log ||x||, & d = 2 \\\\\n||x||^{2 - d}, & d \\geq 3\n\\end{cases}\n\\tag{4}\\]\nwhere \\(x\\in\\mathbf{R}^d\\).\n\nProof. Consider\n\\[\\begin{align*}\nf(x_1,x_2) = \\log \\sqrt {x_1^2 + x_2^2}\n\\end{align*}\\]\nWe have:\n\\[\\begin{align*}\n\\frac{\\partial f}{\\partial x_1} &= \\frac{1}{\\sqrt{x_1^2 + x_2^2}} \\cdot \\frac{\\partial }{\\partial x_1} (\\sqrt{x_1^2 + x_2^2})\\\\\n&=\\frac{1}{\\sqrt{x_1^2 + x_2^2}} \\cdot \\frac{x_1}{\\sqrt{x_1^2 + x_2^2}}\\\\\n&= \\frac{x_1}{x_1^2 + x_2^2}\n\\end{align*}\\]\nFurther,\n\\[\\begin{align*}\n\\frac{\\partial^2 f}{\\partial x_1^2} &= \\frac{(x_1^2 + x_2^2)(1) - x_1(2x_1)}{(x_1^2 + x_2^2)^2} \\\\\n&= \\frac{x_1^2 - x_2^2}{(x_1^2 + x_2^2)}\n\\end{align*}\\]\nBy symmetry,\n\\[\\begin{align*}\n\\frac{\\partial^2 f}{\\partial x_2^2}\n&= \\frac{x_2^2 - x_1^2}{(x_1^2 + x_2^2)}\n\\end{align*}\\]\nSo,\n\\[\\begin{align*}\n\\frac{\\partial^2 f}{\\partial x_1^2} &= - \\frac{\\partial^2 f}{\\partial x_2^2}\\\\\n\\frac{\\partial^2 f}{\\partial x_1^2} + \\frac{\\partial^2 f}{\\partial x_2^2}&=0\n\\end{align*}\\]\nWe conclude that \\(f\\) is harmonic.\nNext, consider\n\\[\\begin{align*}\ng(x_1,x_2,\\ldots,x_d) = \\frac{1}{\\left(\\sqrt{x_1^2 + x_2^2 + \\ldots + x_d^2}\\right)^{d-2}}\n\\end{align*}\\]\nNow,\n\\[\\begin{align*}\n\\frac{\\partial g}{\\partial x_i} &= \\frac{(2-d)}{\\left(\\sqrt{x_1^2 + x_2^2 + \\ldots + x_d^2}\\right)^{d-1}} \\cdot \\frac{\\partial }{\\partial x_i}\\left(\\sqrt{x_1^2 + x_2^2 + \\ldots + x_d^2}\\right)\\\\\n&= \\frac{(2-d)}{\\left(\\sqrt{x_1^2 + x_2^2 + \\ldots + x_d^2}\\right)^{d-1}}\\cdot \\frac{2x_i}{2\\left(\\sqrt{x_1^2 + x_2^2 + \\ldots + x_d^2}\\right)}\\\\\n&= \\frac{(2-d)x_i}{\\left(\\sqrt{x_1^2 + x_2^2 + \\ldots + x_d^2}\\right)^d}\n\\end{align*}\\]\nFurther, we have:\n\\[\\begin{align*}\n\\frac{\\partial^2 g}{\\partial x_i^2} &= (2-d)\\frac{\\left(\\sqrt{x_1^2 + x_2^2 + \\ldots + x_d^2}\\right)^d (1) - (x_i)\\cdot d \\cdot\\left(\\sqrt{x_1^2 + x_2^2 + \\ldots + x_d^2}\\right)^{d-1}\\cdot \\frac{x_i}{\\left(\\sqrt{x_1^2 + x_2^2 + \\ldots + x_d^2}\\right)}}{\\left(\\sqrt{x_1^2 + x_2^2 + \\ldots + x_d^2}\\right)^{2d}}\\\\\n&=(2-d)\\left(\\sqrt{x_1^2 + x_2^2 + \\ldots + x_d^2}\\right)^{d-2} \\frac{\\left(\\sqrt{x_1^2 + x_2^2 + \\ldots + x_d^2}\\right)^2  - d x_i^2}{\\left(\\sqrt{x_1^2 + x_2^2 + \\ldots + x_d^2}\\right)^{2d}}\\\\\n&=(2-d) \\frac{\\left(\\sum_{i=1}^d x_i^2\\right) - dx_i^2 }{||x||^{d+2}}\n\\end{align*}\\]\nWe conclude that:\n\\[\\begin{align*}\n\\sum_{i=1}^{d} \\frac{\\partial^2 g}{\\partial x_i^2} = 0\n\\end{align*}\\]\nand hence \\(g\\) is harmonic.\n\nInterestingly enough, the answer to the recurrence versus transience puzzle depends on the dimension. We will show that Brownian motion is recurrent in dimension \\(d=2\\) in the sense that every Brownian motion path starting from \\(x\\) will eventually enter a disc around the origin, no matter how small the disc is. The Brownian path will then enter this disc infinitely many times, as \\(t \\to \\infty\\). Note that, we did not say that the path actually hits \\(0\\), but that it enters a disc around the \\(0\\). This nuance is important, as we will in fact show that a Brownian path actually never hits a given point. In dimension \\(d=3\\) or higher, it is proved that there are some paths starting from a given \\(x\\) that will never enter a given ball around the origin with positive probability. This is the transience property.\nThe strategy of the proof is similar to the approach for Brownian motion with a drift. We will find a good function \\(h : \\mathbf{R}^d \\to \\mathbf{R}\\) for which \\(h(B_t)\\) is a martingale. In light of Corollary 1, this function needs to be harmonic in a suitable region. The desired probability is then obtained by considering the right boundary values.\n\nTheorem 3 (Recurrence and transience of a brownian motion in \\(\\mathbf{R}^d\\)) Let \\((B_t,t\\geq 0)\\) be a Brownian motion in \\(\\mathbf{R}^d\\) starting at \\(B_0 = x\\). Consider for \\(r &lt; ||x||\\), the stopping time\n\\[\\begin{align*}\n\\tau_r = \\min \\{t \\geq 0 : ||B_t|| &lt; r\\}\n\\end{align*}\\]\nthe first hitting time of the paths in a ball of radius \\(r\\) around the origin. We have:\n\\[\\begin{align*}\n\\mathbb{P}(\\tau_r &lt; \\infty) =\n\\begin{cases}\n1 & \\text{ if }d \\leq 2 \\\\\n\\left(\\frac{r}{||x||}\\right)^{d-2} & \\text{ if }d \\geq 3\n\\end{cases}\n\\end{align*}\\]\nIn particular, for \\(d \\leq 2\\), the paths are recurrent; that is, they come back infinitely many times in a neighbourhood of the origin. For \\(d \\geq 3\\), each path will eventually never come back to a neighbourhood of the origin.\n\nNote that we made sure that the starting point of the Brownian motion \\(x\\) is outside the ball of radius \\(r\\).\n\nProof. Consider another hitting time of a ball with a radius larger than \\(||x||\\):\n\\[\\begin{align*}\n\\tau_R' = \\min \\{t \\geq 0 : ||B_t|| \\geq R\\}, \\quad r &lt; ||x|| &lt; R\n\\end{align*}\\]\nNote that \\(\\tau_R'\\) must increase with \\(R\\) and that it must go to \\(+\\infty\\) as \\(R \\to \\infty\\). Moreover, the sequence of events \\(\\{\\tau_r &lt; \\tau_R'\\}_{R &gt; ||x||}\\) is increasing. In particular, by continuity of probability measure, we have:\n\\[\\begin{align*}\n\\lim_{R \\to \\infty} \\mathbb{P}(\\tau_r &lt; \\tau_R') &= \\mathbb{P}(\\lim_{R \\to \\infty} \\tau_r &lt; \\tau_R')\\\\\n&= \\mathbb{P}(\\tau_r &lt; \\infty)\n\\end{align*}\\]\nIf we set \\(\\tau = \\tau_r \\land \\tau_R'\\), then the event \\(\\{\\tau_r &lt; \\tau_R'\\}\\) is the same as the event \\(\\{||B_\\tau||=r\\}\\). So, \\(\\lim_{R \\to \\infty} \\mathbb{P}(\\tau_r &lt; \\tau_R') = \\lim_{R \\to \\infty} \\mathbb{P}(||B_\\tau||=r)\\).\nNow, consider the event \\(\\{\\tau &lt; \\infty\\}\\). Let \\(E_n\\) be the event that the \\(n\\)th increment \\(||B_n - B_{n-1}||\\) exceeds \\(R\\). If \\(E_n\\) occurs, then we must have the Brownian motion exits the spherical shell of thickness \\(R-r\\). Moreover, we have \\(\\mathbb{P}(E_1) = \\ldots = \\mathbb{P}(E_n)\\), for all \\(n\\). Call this probability \\(p\\). Clearly, \\(0 &lt; p &lt; 1\\). Since the events \\(E_n\\) are independent, we have:\n\\[\\begin{align*}\n\\mathbb{P}(E_1^C \\cap \\ldots \\cap E_n^C) = (1 - p)^n\n\\end{align*}\\]\nAs \\(n \\to \\infty\\), we have \\(\\lim_{n \\to \\infty} \\mathbb{P}(\\bigcap_{k=1}^{n}E_k^C) = 0\\). Now, let \\(F_k\\) be the event that there are no excursions upto \\(k\\). That is, \\(F_k = \\bigcap_{i=1}^{k}E_i^C\\). Now, the event \\(F_{k+1}\\) implies \\(F_k\\), or equivalently, \\(F_{k+1} \\subseteq F_k\\). So, \\(\\{F_k\\}_{k=1}^{\\infty}\\) is a decreasing sequence of events. Moreover, \\(\\bigcap_{k=1}^n F_k = \\bigcap_{k=1}^n E_k^C\\). So, by continuity of probability measure,\n\\[\\begin{align*}\n\\lim_{n \\to \\infty} \\mathbb{P}(\\bigcap_{k=1}^{n}E_k^C)\n&= \\lim_{n \\to \\infty} \\mathbb{P}(\\bigcap_{k=1}^{n}F_k) \\\\\n&= \\mathbb{P}(\\lim_{n \\to \\infty} \\bigcap_{k=1}^{n}F_k) \\\\\n&= \\mathbb{P}(\\bigcap_{k=1}^{\\infty}F_k) \\\\\n&= \\mathbb{P}(\\bigcap_{k=1}^{\\infty}E_k^C)\n\\end{align*}\\]\nSo, \\(\\mathbb{P}(\\bigcup_{k=1}^{\\infty}E_k) = 1\\). There exists an \\(n_0 \\in \\mathbf{N}\\), such that the event \\(E_{n_0}\\), an excursion at \\(n_0\\) occurs with probability \\(1\\). So, the event \\(\\{\\tau &lt; \\infty\\}\\) occurs almost surely.\nTo compute \\(\\mathbb{P}(||B_\\tau||=r)\\), the idea is to find a good function \\(h\\) with the following properties:\n\nMartingale: \\((h(B_t),t\\leq \\tau)\\) is a bounded martingale, so that the optional stopping theorem implies:\n\n\\[\\begin{align*}\n\\mathbb{E}[h(B_\\tau)] = h(B_0) = h(x)\n\\end{align*}\\]\n\nBoundary values: Since \\(B_\\tau\\) is a point at \\(||x||=r\\) or at \\(||x||=R\\), we pick boundary conditions for \\(h\\), so that \\(\\mathbb{E}[h(B_{\\tau})]=\\mathbb{P}(||B_\\tau||=r)\\).\n\nThe second point is easy; it suffices to take the boundary conditions \\(h(x)=0\\) at \\(||x||=R\\) and \\(h(x)=1\\) at \\(||x||=r\\). For the first point, by Ito’s formula, we pick \\(h\\) to be harmonic in the annulus \\(\\{x \\in \\mathbf{R}^d : r &lt; ||x||&lt;R \\}\\). Thus, we can use the function in Equation 4. Of course, the functions \\(ah(x) + b\\) remain harmonic. To satisfy the boundary conditions, we pick \\(a\\) and \\(b\\) suitably:\n\n\nLet \\(h(x) = ax + b\\). Then, at \\(x=r\\), we have:\n\\[\n\\begin{align*}\nar + b = 1\n\\end{align*}\n\\tag{5}\\]\nand at \\(x = R\\), we have:\n\\[\n\\begin{align*}\naR + b = 0\n\\end{align*}\n\\tag{6}\\]\nSo, \\(b = -aR\\). Substituting in Equation 5, we get:\n\\[\\begin{align*}\na &= \\frac{1}{r - R}\nb &= -\\frac{R}{r - R}\n\\end{align*}\\]\nConsequently,\n\\[\n\\begin{align*}\nh(x) &= \\frac{R - x}{R - r}\n\\end{align*}\n\\tag{7}\\]\n\n\n\nLet \\(h(x) = \\log ||x||\\). Then, at \\(||x||=r\\), we have:\n\\[\n\\begin{align*}\na \\log ||x|| + b &= 1\na \\log r + b &= 1\n\\end{align*}\n\\tag{8}\\]\nAt \\(||x||=R\\), we have:\n\\[\n\\begin{align*}\na \\log ||x|| + b &= 0\na \\log R + b &= 0\n\\end{align*}\n\\tag{9}\\]\nThus, from Equation 9, \\(b = -a \\log R\\). Substituting the value for \\(b\\) in Equation 8, we have:\n\\[\n\\begin{align*}\na \\log r - a \\log R &= 1\\\\\na &= \\frac{1}{\\log r - \\log R}\n\\end{align*}\n\\]\nConsequently,\n\\[\n\\begin{align*}\nh(x) &= \\frac{\\log ||x||}{\\log r - \\log R} -  \\frac{1}{\\log r - \\log R} \\log R\\\\\n&= \\frac{\\log R - \\log ||x||}{\\log R - \\log r}\n\\end{align*}\n\\tag{10}\\]\n\n\n\nLet \\(h(x)=||x||^{2-d}\\). At \\(||x||=r\\), \\(a h(x) + b = 1\\). So, we have:\n\\[\n\\begin{align*}\na r^{2-d} + b = 1\n\\end{align*}\n\\tag{11}\\]\nAt \\(||x||=R\\), \\(ah(x) + b = 0\\). So, we have:\n\\[\n\\begin{align*}\na ||R||^{2-d} + b &= 0\n\\end{align*}\n\\tag{12}\\]\nFrom Equation 12, we get \\(b = -a R^{2-d}\\). Substituting this value in Equation 11, we get:\n\\[\\begin{align*}\na r^{2-d} - aR^{2-d}  &= 1\\\\\na &= \\frac{1}{r^{2-d} - R^{2-d}}\n\\end{align*}\\]\nAnd\n\\[\n\\begin{align*}\nb = - \\frac{R^{2-d}}{r^{2-d} - R^{2-d}}\n\\end{align*}\n\\]\nThus,\n\\[\n\\begin{align*}\nh(x) &= \\frac{||x||^{2-d}}{r^{2-d} - R^{2-d}} - \\frac{R^{2-d}}{r^{2-d} - R^{2-d}}\\\\\n&= \\frac{R^{2-d} - ||x||}{R^{2-d} - r^{2-d}}\n\\end{align*}\n\\tag{13}\\]\nCollecting all the results together, we get:\n\\[\nh(x) = \\begin{cases}\n\\frac{R - x}{R - r}, & d=1 \\\\\n\\frac{\\log R - \\log ||x||}{\\log R - \\log r}, & d=2 \\\\\n\\frac{R^{2-d} - ||x||^{2-d}}{R^{2-d} - r^{2-d}}, & d \\geq 3\n\\end{cases}\n\\tag{14}\\]\nPassing to the limit as \\(R \\to \\infty\\), for \\(d=1\\), we have:\n\\[\\begin{align*}\n\\lim_{R \\to \\infty} h(x) &= \\lim_{R \\to \\infty} \\frac{R - x}{R - r} \\\\\n&= \\lim_{R \\to \\infty} \\frac{1 - \\frac{x}{R}}{1 - \\frac{r}{R}}\\\\\n&= 1\n\\end{align*}\\]\nFor \\(d = 2\\), we get:\n\\[\\begin{align*}\n\\lim_{R \\to \\infty} h(x) &= \\lim_{R \\to \\infty} \\frac{1 - \\frac{\\log x}{\\log R}}{1 - \\frac{\\log r}{\\log R}} \\\\\n&= 1\n\\end{align*}\\]\nFor \\(d = 3\\), we get:\n\\[\\begin{align*}\n\\lim_{R \\to \\infty}  h(x) &= \\lim_{R \\to \\infty} \\frac{R^{2-d} - ||x||^{2-d}}{R^{2-d} - r^{2-d}}\\\\\n&= \\left(\\frac{||x||}{r}\\right)^{2-d}\n\\end{align*}\\]\nThis concludes the proof. \\(\\blacksquare\\)\n\n\n\nExample 4 We get more from the above proof. Indeed, in dimension \\(d \\geq 2\\), it implies that the probability that a Brownian motion starting at \\(B_0 = x\\) eventually hits any other point \\(y\\) is \\(0\\). Indeed, if we take \\(y = 0\\) and \\(x \\neq 0\\), we have:\n\\[\n\\begin{align*}\n\\mathbb{P}(\\exists t &gt; 0: B_t = 0) &= \\lim_{R \\to \\infty} \\lim_{r \\to \\infty} \\mathbb{P}(\\tau_r &lt; \\tau_R')\\\\\n&= \\lim_{R \\to \\infty} \\lim_{r \\to \\infty} \\frac{R^{2-d} - ||x||^{2-d}}{R^{2-d} - r^{2-d}}\\\\\n&=\\lim_{R \\to \\infty}  \\lim_{r \\to \\infty} \\frac{(R/r)^{2-d} - (||x||/r)^{2-d}}{(R/r)^{2-d} - 1}\\\\\n&= \\lim_{R \\to \\infty} 0\\\\\n&= 0\n\\end{align*}\n\\]\nHere, we shrink the inner radius to \\(0\\) first and then we let the outer radius go to infinity after. It remains to take the limits of the expression obtained in equation Equation 14. The first limit \\(r \\to 0\\) gives \\(0\\) right away."
  },
  {
    "objectID": "posts/multivariate_ito_calculus/index.html#dynkins-formula-and-the-dirichlet-problem",
    "href": "posts/multivariate_ito_calculus/index.html#dynkins-formula-and-the-dirichlet-problem",
    "title": "Multivariate Ito Calculus",
    "section": "",
    "text": "In the last section, we translated the problem of recurrence and transience of Brownian motion in terms of a boundary value problem: we needed to find a particular function \\(h\\) that solves a PDE (that is, \\(\\nabla^2 h=0\\)) in a certain region of space(the annulus) and that satisfies given boundary conditions (the function is \\(1\\) on the inner circle and \\(0\\) on the outer circle). This is a particular case of the Dirichlet problem in PDE.\nConsider a region \\(\\mathcal{O} \\subset \\mathbb{R}^d\\). \\(\\mathcal{O}\\) is an open ball. That is, for all \\(x \\in \\mathcal{O}\\), there exists \\(\\epsilon&gt;0\\), such that \\(V_\\epsilon(x) = \\{y : ||y - x|| &lt; \\epsilon\\}\\) is contained in \\(\\mathcal{O}\\). \\(\\mathcal{O}\\) doesn’t contain boundary points \\(\\partial \\mathcal{O}\\). In the proof of Theorem 3, the region was the annulus \\(\\{x: r &lt; ||x|| &lt; R\\}\\) and the boundary was given by the spheres \\(\\{x :||x|| = r\\}\\) and \\(\\{x: ||x||=R\\}\\). The Dirichlet problem in \\(\\mathcal{O}\\) can be stated as follows:\nLet \\(f:\\partial\\mathcal{O} \\to \\mathbb{R}\\) be a function on the boundary of \\(\\mathcal{O}\\). Can we extend the function \\(f\\) to \\(O\\) in such a way that the extension is harmonic on \\(\\mathcal{O}\\) and coincides with \\(f\\) on the boundary?\nIn the instance of the proof of the Theorem 3, we knew the solution of the problem, thanks to Equation 4. The only job left to do was to adjust some parameters to fit the boundary conditions. It turns out that the formalism of stochastic calculus allows us to express the solution of the Dirichlet problem as an average over Brownian paths for general regions of space and boundary conditions. To do so, we look at a twist on the Ito’s formula called the Dynkin’s formula.\nLet \\(x\\) be a point in \\(\\mathcal{O}\\). Consider a Brownian motion \\((B_t,t\\geq 0)\\) starting at \\(x\\), \\(B_0 = x\\). To emphasize the dependence on \\(x\\), we write \\(\\mathbb{P}_x\\) and \\(\\mathbb{E}_x\\) for the probability and the expectation for the Brownian motion. Dykin’s formula is obtained by merging Corollary 1 for the Brownian martingales together with the optional stopping theorem. More precisely, consider \\(f \\in C^2(\\mathbb{R}^d)\\) that satisfies the assumption of the Corollary 1. We then have that the process:\n\\[\\begin{align*}\nM_t &= f(B_t) - \\frac{1}{2}\\int_{0}^t \\nabla^2 f(B_s) ds, \\quad t \\geq 0\n\\end{align*}\\]\nis a Brownian martingale.\nConsider also the stopping time \\(\\tau = \\min \\{t \\geq 0 : B_t \\in \\mathcal{O}^C\\}\\). This is the first exit time of \\(\\mathcal{O}\\) of the Brownian motion path. Then, if the assumptions of the optional stopping theorem are fulfilled, we get Dynkin’s formula:\n\\[\n\\begin{align*}\n\\mathbb{E}[M_\\tau] = \\mathbb{E}[f(B_\\tau)] - \\frac{1}{2} \\mathbb{E}\\left[\\int_0^\\tau \\nabla^2 f(B_s)ds\\right] = f(B_0) = M_0\n\\end{align*}\n\\tag{15}\\]\nAs an application of Dynkin’s formula, let’s express the solution of the Dirichlet problem as an average over Brownian motion. If \\(f\\) is harmonic in \\(\\mathcal{O}\\), then \\(\\nabla^2 f = 0\\) in \\(\\mathcal{O}\\), so the process \\((f(B_t),t\\leq \\tau)\\) is itself a martingale. Note that since \\(\\mathcal{O}\\) is bounded, this is a bounded martingale! Moreover, the integrands \\(\\partial_i f(B_s)\\), \\(1 \\leq i \\leq d\\), are bounded. We conclude that the solution to the Dirichlet problem can be represented as follows:\n\\[\n\\begin{align*}\nf(x) = \\mathbb{E}_x[f(B_\\tau)], \\quad x \\in \\mathcal{O}\n\\end{align*}\n\\tag{16}\\]\nIn other words, the value of the harmonic function of \\(f\\) at \\(x\\) is given by the average over the Brownian paths of the value of the function at the exit point of the path on the boundary of \\(\\mathcal{O}\\). Equation Equation 16 does not prove the existence of the solution to the Dirichlet problem, as we assume that such a function exists. Existence of the solution to the Dirichlet problem can be shown this way, assuming the region \\(\\mathcal{O}\\) and the function on the boundary are nice enough. However, note that the averaging on the right-hand side of the formula makes sense even in the case where \\(f\\) is simply defined on the boundary \\(\\partial \\mathcal{O}\\). We then define a posteriori the harmonic extension of \\(f\\) inside \\(\\mathcal{O}\\) by defining its value at \\(x\\) as \\(\\mathbb{E}_x[f(B_\\tau)]\\)."
  },
  {
    "objectID": "posts/multivariate_ito_calculus/index.html#exercises",
    "href": "posts/multivariate_ito_calculus/index.html#exercises",
    "title": "Multivariate Ito Calculus",
    "section": "",
    "text": "Exercise 1 Gaussian Integration by parts.\n\nLet \\(Z\\) be a standard Gaussian random variable. Show using integration by parts that for a differentiable function \\(g\\):\n\n\\[\n\\begin{align*}\n\\mathbb{E}[Z g(Z)] = \\mathbb{E}[g'(Z)]\n\\end{align*}\n\\tag{17}\\]\nwhere we assume that both expectations are well-defined.\n\nUse this to recover the expression for the moments for \\(\\mathbb{E}[Z^{2j}],j \\in \\mathbb{N}\\).\n\n\nSolution.\nWe have:\n\\[\n\\begin{align*}\n\\mathbb{E}[g'(Z)] &= \\int_{-\\infty}^{\\infty}\\phi(z) \\cdot g'(z) dz \\\\\n&= \\left[\\frac{e^{-z^2/2}}{\\sqrt{2\\pi}}\\cdot g(z)\\right]_{-\\infty}^{\\infty} - \\int_{-\\infty}^{\\infty} g(z) \\frac{-ze^{-z^2/2}}{\\sqrt{2\\pi}}dz \\\\\n&= 0 + \\int_{-\\infty}^{\\infty} z g(z) \\phi(z)dz\\\\\n&= \\mathbb{E}[Zg(Z)]\n\\end{align*}\n\\]\nMoreover, we can write:\n\\[\n\\begin{align*}\n\\mathbb{E}[Z^{2n}] &= \\mathbb{E}[Z \\cdot Z^{2n-1}] \\\\\n&= \\mathbb{E}[Z \\cdot g(Z)], \\quad \\{ \\text{ where }g(x)=x^{2n - 1}\\} \\\\\n&= \\mathbb{E}[g'(Z)] \\\\\n&= (2n - 1) \\mathbb{E}[Z^{(2n - 2)}] \\\\\n& \\vdots \\\\\n&= (2n - 1)\\cdots 5 \\cdot 3 \\cdot \\mathbb{E}[Z^2] \\\\\n&= (2n - 1)\\cdots 5 \\cdot 3 \\cdot 1\n\\end{align*}\n\\]\n\nExercise 2 The Heat Equation.\nUse the Gaussian integration by parts identity to check that the solution \\(f(t,x)\\) to the heat equation is:"
  },
  {
    "objectID": "posts/martingales/index.html",
    "href": "posts/martingales/index.html",
    "title": "Martingales",
    "section": "",
    "text": "In elementary probability, the conditional expectation of a variable \\(Y\\) given another random variable \\(X\\) refers to the expectation of \\(Y\\) given the conditional distribution \\(f_{Y|X}(y|x)\\) of \\(Y\\) given \\(X\\). To illustrate this, let’s go through a simple example. Consider \\(\\mathcal{B}_{1}\\), \\(\\mathcal{B}_{2}\\) to be two independent Bernoulli-distributed random variables with \\(p=1/2\\). Then, construct:\n\\[\\begin{aligned}\nX=\\mathcal{B}_{1}, & \\quad Y=\\mathcal{B}_{1}+\\mathcal{B}_{2}\n\\end{aligned}\\]\nIt is easy to compute \\(\\mathbb{E}[Y|X=0]\\) and \\(\\mathbb{E}[Y|X=1]\\). By definition, it is given by:\n\\[\\begin{aligned}\n\\mathbb{E}[Y|X=0] & =\\sum_{j=0}^{2}j\\mathbb{P}(Y=j|X=0)\\\\\n& =\\sum_{j=0}^{2}j\\cdot\\frac{\\mathbb{P}(Y=j,X=0)}{P(X=0)}\\\\\n& =0+1\\cdot\\frac{(1/4)}{(1/2)}+2\\cdot\\frac{0}{(1/2)}\\\\\n& =\\frac{1}{2}\n\\end{aligned}\\]\nand\n\\[\\begin{aligned}\n\\mathbb{E}[Y|X=1] & =\\sum_{j=0}^{2}j\\mathbb{P}(Y=j|X=1)\\\\\n& =\\sum_{j=0}^{2}j\\cdot\\frac{\\mathbb{P}(Y=j,X=1)}{P(X=1)}\\\\\n& =0+1\\cdot\\frac{(1/4)}{(1/2)}+2\\cdot\\frac{(1/4)}{(1/2)}\\\\\n& =\\frac{3}{2}\n\\end{aligned}\\]\nWith this point of view, the conditional expectation is computed given the information that the event \\(\\{X=0\\}\\) occurred or the event \\(\\{X=1\\}\\) occurred. It is possible to regroup both conditional expectations in a single object, if we think of the conditional expectation as a random variable and denote it by \\(\\mathbb{E}[Y|X]\\). Namely, we take:\n\\[\\begin{aligned}\n\\mathbb{E}[Y|X](\\omega) & =\\begin{cases}\n\\frac{1}{2} & \\text{if }X(\\omega)=0\\\\\n\\frac{3}{2} & \\text{if }X(\\omega)=1\n\\end{cases}\\label{eq:elementary-conditional-expectation-example}\n\\end{aligned}\\]\nThis random variable is called the conditional expectation of \\(Y\\) given \\(X\\). We make two important observations:\n(i) If the value of \\(X\\) is known, then the value of \\(\\mathbb{E}[Y|X]\\) is determined.\n(ii) If we have another random variable \\(g(X)\\) constructed from \\(X\\), then we have:\n\\[\\begin{aligned}\n\\mathbb{E}[g(X)Y] & =\\mathbb{E}[g(X)\\mathbb{E}[Y|X]]\n\\end{aligned}\\]\nIn other words, as far as \\(X\\) is concerned, the conditional expectation \\(\\mathbb{E}[Y|X]\\) is a proxy for \\(Y\\) in the expectation. We sometimes say that \\(\\mathbb{E}[Y|X]\\) is the best estimate of \\(Y\\) given the information of \\(X\\).\nThe last observation is easy to verify since:\n\\[\\begin{aligned}\n\\mathbb{E}[g(X)Y] & =\\sum_{i=0}^{1}\\sum_{j=0}^{2}g(i)\\cdot j\\cdot\\mathbb{P}(X=i,Y=j)\\\\\n& =\\sum_{i=0}^{1}\\mathbb{P}(X=i)g(i)\\left\\{ \\sum_{j=0}^{2}j\\cdot\\frac{\\mathbb{P}(X=i,Y=j)}{\\mathbb{P}(X=i)}\\right\\} \\\\\n& =\\mathbb{E}[g(X)\\mathbb{E}[Y|X]]\n\\end{aligned}\\]\n\n(Elementary Definitions of Conditional Expectation).\n(1) \\((X,Y)\\) discrete. The treatment is similar to the above. If a random variable \\(X\\) takes values \\((x_{i},i\\geq1)\\) and \\(Y\\) takes values \\((y_{j},j\\geq1)\\), we have by definition that the conditional expectation as a random variable is:\n\\[\\begin{aligned}\n\\mathbb{E}[Y|X](\\omega) & =\\sum_{j\\geq1}y_{j}\\mathbb{P}(Y=y_{j}|X=x_{i})\\quad\\text{for }\\omega\\text{ such that }X(\\omega)=x_{i}\n\\end{aligned}\\] (2) \\((X,Y)\\) continuous with joint PDF \\(f_{X,Y}(x,y)\\): In this case, the conditional expectation is the random variable given by\n\\[\\begin{aligned}\n\\mathbb{E}[Y|X] & =h(X)\n\\end{aligned}\\]\nwhere\n\\[\\begin{aligned}\nh(x) & =\\int_{\\mathbf{R}}yf_{Y|X}(y|x)dy=\\int_{\\mathbf{R}}y\\frac{f_{X,Y}(x,y)}{f_{X}(x)}dy=\\frac{\\int_{\\mathbf{R}}yf_{X,Y}(x,y)dy}{\\int_{\\mathbf{R}}f_{X,Y}(x,y)dy}\n\\end{aligned}\\]\n\nIn the two examples above, the expectation of the random variable \\(\\mathbb{E}[Y|X]\\) is equal to \\(\\mathbb{E}[Y]\\). Indeed in the discrete case, we have:\n\\[\\begin{aligned}\n\\mathbb{E}[\\mathbb{E}[Y|X]] & =\\sum_{i=0}^{1}P(X=x_{i})\\cdot\\sum_{j=0}^{2}y_{j}\\mathbb{P}(Y=y_{j}|X=x_{i})\\\\\n& =\\sum_{i=0}^{1}\\sum_{j=0}^{2}y_{j}\\mathbb{P}(Y=y_{j},X=x_{i})\\\\\n& =\\sum_{j=0}^{2}y_{j}\\mathbb{P}(Y=y_{j})\\\\\n& =\\mathbb{E}[Y]\n\\end{aligned}\\]\n\n(Conditional Probability vs Conditional expectation). The conditional probability of the event \\(A\\) given \\(B\\) can be recast in terms of conditional expectation using indicator functions. If \\(0&lt;\\mathbb{P}(B)&lt;1\\), it is not hard to check that: \\(\\mathbb{P}(A|B)=\\mathbb{E}[\\mathbf{1}_{A}|\\mathbf{1}_{B}=1]\\) and \\(\\mathbb{P}(A|B^{C})=\\mathbb{E}[\\mathbf{1}_{A}|1_{B}=0]\\). Indeed the random variables \\(\\mathbf{1}_{A}\\) and \\(\\mathbf{1}_{B}\\) are discrete. If we proceed as in the discrete case above, we have:\n\\[\\begin{aligned}\n\\mathbb{E}[\\mathbf{1}_{A}|\\mathbf{1}_{B}=1] & =1\\cdot\\mathbb{P}(\\mathbf{1}_{A}=1|\\mathbf{1}_{B}=1)\\\\\n& =\\frac{\\mathbb{P}(\\mathbf{1}_{A}=1,\\mathbf{1}_{B}=1)}{\\mathbb{P}(\\mathbf{1}_{B}=1)}\\\\\n& =\\frac{\\mathbb{P}(A\\cap B)}{\\mathbb{P}(B)}\\\\\n& =\\mathbb{P}(A|B)\n\\end{aligned}\\]\nA similar calculation gives \\(\\mathbb{P}(A|B^{C})\\). In particular, the formula for total probability for \\(A\\) is a rewriting of the expectation of the random variable \\(\\mathbb{E}[\\mathbf{1}_{A}|\\mathbf{1}_{B}]\\):\n\\[\\begin{aligned}\n\\mathbb{E}[\\mathbb{E}[\\mathbf{1}_{A}|\\mathbf{1}_{B}]] & =\\mathbb{E}[\\mathbf{1}_{A}|\\mathbf{1}_{B}=1]\\mathbb{P}(\\mathbf{1}_{B}=1)+\\mathbb{E}[\\mathbf{1}_{A}|\\mathbf{1}_{B}=0]\\mathbb{P}(\\mathbf{1}_{B}=0)\\\\\n& =\\mathbb{P}(A|B)\\cdot\\mathbb{P}(B)+\\mathbb{P}(A|B^{C})\\cdot\\mathbb{P}(B^{C})\\\\\n& =\\mathbb{P}(A)\n\\end{aligned}\\]\n\n\n\n\n\n\nWe start by giving the definition of conditional expectation given a single variable. This relates to the two observations (A) and (B) made previously. We assume that the random variable is integrable for the expectations to be well-defined.\n\nLet \\(X\\) and \\(Y\\) be integrable random variables on \\((\\Omega,\\mathcal{F},\\mathbb{P})\\). The conditional expectation of \\(Y\\) given \\(X\\) is the random variable denoted by \\(\\mathbb{E}[Y|X]\\) with the following two properties:\n(A) There exists a function \\(h:\\mathbf{R}\\to\\mathbf{R}\\) such that \\(\\mathbb{E}[Y|X]=h(X)\\).\n(B) For any bounded random variable of the form \\(g(X)\\) for some function \\(g\\),\n\\[\\mathbb{E}[g(X)Y]=\\mathbb{E}[g(X)\\mathbb{E}[Y|X]]\\label{eq:definition-conditional-expectation}\\]\nWe can intepret the second property as follows. The conditional expectation \\(\\mathbb{E}[Y|X]\\) serves as a proxy for \\(Y\\) as far as \\(X\\) is concerned. Note that in equation ([eq:definition-conditional-expectation]), the expectation on the left can be seen as an average over the joint values of \\((X,Y)\\), whereas the one on the right is an average over the values of \\(X\\) only! Another way to see this property is to write is as:\n\\[\\mathbb{E}[g(X)(Y-\\mathbb{E}[Y|X])]=0\\]\nIn other words, the random variable \\(Y-\\mathbb{E}[Y|X]\\) is orthogonal to any random variable constructed from \\(X\\).\nFinally, it is important to notice that if we take \\(g(X)=1\\), then the second property implies :\n\\[\\begin{aligned}\n\\mathbb{E}[Y] & =\\mathbb{E}[\\mathbb{E}[Y|X]]\n\\end{aligned}\\]\nIn other words, the expectation of the conditional expectation of \\(Y\\) is simply the expectation of \\(Y\\).\nThe existence of the conditional expectation \\(\\mathbb{E}[Y|X]\\) is not obvious. We know, it exists in particular cases given in example ([ex:elementary-definitions-of-conditional-expectation]). We will show more generally, that it exists, it is unique whenever \\(Y\\) is in \\(L^{2}(\\Omega,\\mathcal{F},\\mathbb{P})\\) (In fact, it can be shown to exist whenever \\(Y\\) is integrable). Before doing so, let’s warm up by looking at the case of Gaussian vectors.\n\n\n(Conditional expectation of Gaussian vectors - I). Let \\((X,Y)\\) be a Gaussian vector of mean \\(0\\). Then:\n\\[\\mathbb{E}[Y|X]=\\frac{\\mathbb{E}[XY]}{\\mathbb{E}[X^{2}]}X\\label{eq:conditional-expectation-of-gaussian-vector}\\]\nThis candidate satisfies the two defining properties of conditional expectation : (A) It is clearly a function of \\(X\\); in fact it is a simple multiple of \\(X\\). (B) We have that the random variable \\(\\left(Y-\\frac{\\mathbb{E}[XY]}{\\mathbb{E}[X^{2}]}X\\right)\\) is orthogonal and thus independent to \\(X\\). This is a consequence of the proposition ([prop:diagonal-cov-matrix-implies-independence-of-gaussians]), since:\n\\[\\begin{aligned}\n\\mathbb{E}\\left[X\\left(Y-\\frac{\\mathbb{E}[XY]}{\\mathbb{E}[X^{2}]}X\\right)\\right] & =\\mathbb{E}XY-\\frac{\\mathbb{E}[XY]}{\\mathbb{E}[X^{2}]}\\mathbb{E}X^{2}\\\\\n& =\\mathbb{E}XY-\\frac{\\mathbb{E}[XY]}{\\cancel{\\mathbb{E}[X^{2}]}}\\cancel{\\mathbb{E}X^{2}}\\\\\n& =0\n\\end{aligned}\\]\nTherefore, we have for any bounded function \\(g(X)\\) of \\(X\\):\n\\[\\begin{aligned}\n\\mathbb{E}[g(X)(Y-\\mathbb{E}(Y|X))] & =\\mathbb{E}[g(X)]\\mathbb{E}[Y-\\mathbb{E}[Y|X]]=0\n\\end{aligned}\\]\n\n\n(Brownian conditioning-I) Let \\((B_{t},t\\geq0)\\) be a standard Brownian motion. Consider the Gaussian vector \\((B_{1/2},B_{1})\\). Its covariance matrix is:\n\\[\\begin{aligned}\nC & =\\left[\\begin{array}{cc}\n1/2 & 1/2\\\\\n1/2 & 1\n\\end{array}\\right]\n\\end{aligned}\\]\nLet’s compute \\(\\mathbb{E}[B_{1}|B_{1/2}]\\) and \\(\\mathbb{E}[B_{1/2}|B_{1}]\\). This is easy using the equation ([eq:conditional-expectation-of-gaussian-vector]). We have:\n\\[\\begin{aligned}\n\\mathbb{E}[B_{1}|B_{1/2}] & =\\frac{\\mathbb{E}[B_{1}B_{1/2}]}{\\mathbb{E}[B_{1/2}^{2}]}B_{1/2}\\\\\n& =\\frac{(1/2)}{(1/2)}B_{1/2}\\\\\n& =B_{1/2}\n\\end{aligned}\\]\nIn other words, the best approximation of \\(B_{1}\\) given the information of \\(B_{1/2}\\) is \\(B_{1/2}\\). There is no problem in computing \\(\\mathbb{E}[B_{1/2}|B_{1}]\\), even though we are conditioning on a future position. Indeed the same formula gives\n\\[\\begin{aligned}\n\\mathbb{E}[B_{1/2}|B_{1}] & =\\frac{\\mathbb{E}[B_{1}B_{1/2}]}{\\mathbb{E}[B_{1}^{2}]}B_{1}=\\frac{1}{2}B_{1}\n\\end{aligned}\\]\nThis means that the best approximation of \\(B_{1/2}\\) given the position at time \\(1\\), is \\(\\frac{1}{2}B_{1}\\) which makes a whole lot of sense!\n\nIn example ([eq:conditional-expectation-of-gaussian-vector]) for the Gaussian vector \\((X,Y)\\), the conditional expectation was equal to the orthogonal projection of \\(Y\\) onto \\(X\\) in \\(L^{2}\\). In particular, the conditional expectation was a multiple of \\(X\\). Is this always the case? Unfortunately, it is not. For example, in the equation ([eq:elementary-conditional-expectation-example]), the conditional expectation is clearly not a multiple of the random variable \\(X\\). However, it is a function of \\(X\\), as is always the case by definition ([def:conditional-expectation]).\nThe idea to construct the conditional expectation \\(\\mathbb{E}[Y|X]\\) in general is to project \\(Y\\) on the space of all random variables that can be constructed from \\(X\\). To make this precise, consider the following subspace of \\(L^{2}(\\Omega,\\mathcal{F},\\mathbb{P})\\) :\n\nLet \\((\\Omega,\\mathcal{F},\\mathbb{P})\\) be a probability space and \\(X\\) a random variable defined on it. The space \\(L^{2}(\\Omega,\\sigma(X),\\mathbb{P})\\) is the linear subspace of \\(L^{2}(\\Omega,\\mathcal{F},\\mathbb{P})\\) consisting of the square-integrable random variables of the form \\(g(X)\\) for some function \\(g:\\mathbf{R}\\to\\mathbf{R}\\).\n\nThis is a linear subspace of \\(L^{2}(\\Omega,\\mathcal{F},\\mathbb{P})\\): It contains the random variable \\(0\\), and any linear combination of random variables of this kind is also a function of \\(X\\) and must have a finite second moment. We note the following:\n\n\\(L^{2}(\\Omega,\\sigma(X),\\mathbb{P})\\) is a subspace of \\(L^{2}(\\Omega,\\mathcal{F},\\mathbb{P})\\), very much how a plane or line (going through the origin) is a subspace of \\(\\mathbf{R}^{3}\\).\nIn particular, as in the case of a line or a plane, we can project an element of \\(Y\\) of \\(L^{2}(\\Omega,\\mathcal{F},\\mathbb{P})\\) onto \\(L^{2}(\\Omega,\\sigma(X),\\mathbb{P})\\). The resulting projection is an element of \\(L^{2}(\\Omega,\\sigma(X),\\mathbb{P})\\), a square-integrable random-variable that is a function of \\(X\\). For a subspace \\(\\mathcal{S}\\) of \\(\\mathbf{R}^{3}\\) (e.g. a line or a plane), the projection of the vector \\(\\mathbf{v}\\in\\mathbf{R}^{3}\\) onto the subspace \\(\\mathcal{S}\\), denoted \\(\\text{Proj}_{\\mathcal{S}}(\\mathbf{v})\\) is the closest point to \\(\\mathbf{v}\\) lying in the subspace \\(\\mathcal{S}\\). Moreover, \\(\\mathbf{v}-\\text{Proj}_{\\mathcal{S}}(\\mathbf{v})\\) is orthogonal to the subspace. This picture of orthogonal projection also holds in \\(L^{2}\\). Let \\(Y\\) be a random variable in \\(L^{2}(\\Omega,\\mathcal{F},\\mathbb{P})\\) and let \\(L^{2}(\\Omega,\\sigma(X),\\mathbb{P})\\) be the subspace of those random variables that are functions of \\(X\\). We write \\(Y^{\\star}\\) for the random variable in \\(L^{2}(\\Omega,\\sigma(X),\\mathbb{P})\\) that is closest to \\(Y\\). In other words, we have (using the definition of the \\(L^{2}\\)-distance square):\n\\[\\inf_{Z\\in L^{2}(\\Omega,\\sigma(X),\\mathbb{P})}\\mathbb{E}[(Y-Z)^{2}]=\\mathbb{E}[(Y-Y^{\\star})^{2}]\\label{eq:Y-star-is-the-closest-to-Y-in-L2-sense}\\]\n\nIt turns out that \\(Y^{\\star}\\) is the right candidate for the conditional expectation.\n\nFigure. An illustration of the conditional expectation \\(\\mathbb{E}[Y|X]\\) as an orthogonal projection of \\(Y\\) onto the subspace \\(L^2(\\Omega,\\sigma(X),\\mathbb{P})\\).\n\n\n(Existence and uniqueness of the conditional expectation) Let \\(X\\) be a random variable on \\((\\Omega,\\mathcal{F},\\mathbb{P})\\). Let \\(Y\\) be a random variable in \\(L^{2}(\\Omega,\\mathcal{F},\\mathbb{P})\\). Then the conditional expectation \\(\\mathbb{E}[Y|X]\\) is the random variable \\(Y^{\\star}\\) given in the equation ([eq:Y-star-is-the-closest-to-Y-in-L2-sense]). Namely, it is the random variable in \\(L^{2}(\\Omega,\\sigma(X),\\mathbb{P})\\) that is closest to \\(Y\\) in the \\(L^{2}\\)-distance.\nIn particular we have the following:\n1) It is the orthogonal projection of \\(Y\\) onto \\(L^{2}(\\Omega,\\sigma(X),\\mathbb{P})\\), that is \\(Y-Y^{\\star}\\) is orthogonal to any random variables in the subspace \\(L^{2}(\\Omega,\\sigma(X),\\mathbb{P})\\).\n2) It is unique.\n\n\nThis result reinforces the meaning of the conditional expectation \\(\\mathbb{E}[Y|X]\\) as the best estimation of \\(Y\\) given the information of \\(X\\): it is the closest random variable to \\(Y\\) among all the functions of \\(X\\) in the sense of \\(L^{2}\\).\n\n\nProof. Proof. We write for short \\(L^{2}(X)\\) for the subspace \\(L^{2}(\\Omega,\\sigma(X),\\mathbb{P})\\). Let \\(Y^{\\star}\\) be as in equation ([eq:Y-star-is-the-closest-to-Y-in-L2-sense]). We show successively that (1) \\(Y-Y^{\\star}\\) is orthogonal to any element of \\(L^{2}(X)\\), so it is the orthogonal projection (2) \\(Y^{\\star}\\) has the properties of conditional expectation in definition ([eq:definition-conditional-expectation]) (3) \\(Y^{\\star}\\) is unique.\n(1) Let \\(W=g(X)\\) be a random variable in \\(L^{2}(X)\\). We show that \\(W\\) is orthogonal to \\(Y-Y^{\\star}\\); that is \\(\\mathbb{E}[(Y-Y^{\\star})W]=0\\). This should be intuitively clear from figure above. On the one hand, we have by developing the square:\n\\[\\begin{aligned}\n\\mathbb{E}[(W-(Y-Y^{\\star}))^{2}] & =\\mathbb{E}[W^{2}-2W(Y-Y^{\\star})+(Y-Y^{\\star})^{2}]\\nonumber \\\\\n& =\\mathbb{E}[W^{2}]-2\\mathbb{E}[W(Y-Y^{\\star})]+\\mathbb{E}(Y-Y^{\\star})^{2}]\\label{eq:developing-the-square}\n\\end{aligned}\\]\nOn the other hand, \\(Y^{\\star}+W\\) is an arbitrary vector in \\(L^{2}(X)\\)(it is a linear combination of the elements in \\(L^{2}(X)\\)), we must have from equation ([eq:Y-star-is-the-closest-to-Y-in-L2-sense]):\n\\[\\begin{aligned}\n\\mathbb{E}[(W-(Y-Y^{\\star}))^{2}] & =\\mathbb{E}[(Y-(Y^{\\star}+W))^{2}]\\nonumber \\\\\n& \\geq\\inf_{Z\\in L^{2}(X)}\\mathbb{E}[(Y-Z)^{2}]\\nonumber \\\\\n& =\\mathbb{E}[(Y-Y^{\\star})^{2}]\\label{eq:lower-bound}\n\\end{aligned}\\]\nPutting the last two equations ([eq:developing-the-square]), ([eq:lower-bound]) together, we get that for any \\(W\\in L^{2}(X)\\):\n\\[\\begin{aligned}\n\\mathbb{E}[W^{2}]-2\\mathbb{E}[W(Y-Y^{\\star})] & \\geq0\n\\end{aligned}\\]\nIn particular, this also holds for \\(aW\\), in which case we get:\n\\[\\begin{aligned}\na^{2}\\mathbb{E}[W^{2}]-2a\\mathbb{E}[W(Y-Y^{\\star})] & \\geq0\\\\\n\\implies a\\left\\{ a\\mathbb{E}[W^{2}]-2\\mathbb{E}[W(Y-Y^{\\star})]\\right\\}  & \\geq0\n\\end{aligned}\\]\nIf \\(a&gt;0\\), then:\n\\[a\\mathbb{E}[W^{2}]-2\\mathbb{E}[W(Y-Y^{\\star})]\\geq0\\label{eq:case-when-a-gt-zero}\\]\nwhereas if \\(a&lt;0\\), then the sign changes upon dividing throughout by \\(a\\), and we have:\n\\[a\\mathbb{E}[W^{2}]-2\\mathbb{E}[W(Y-Y^{\\star})]\\leq0\\label{eq:case-when-a-lt-zero}\\]\nRearranging ([eq:case-when-a-gt-zero]) yields:\n\\[\\mathbb{E}[W(Y-Y^{\\star})]\\leq a\\mathbb{E}[W^{2}]/2\\label{eq:case-when-a-gt-zero-rearranged}\\]\nRearranging ([eq:case-when-a-lt-zero]) yields:\n\\[\\mathbb{E}[W(Y-Y^{\\star})]\\geq a\\mathbb{E}[W^{2}]/2\\label{eq:case-when-a-lt-zero-rearranged}\\]\nSince ([eq:case-when-a-gt-zero-rearranged]) holds for all \\(a&gt;0\\), the stronger inequality, \\(\\mathbb{E}[W(Y-Y^{\\star})]\\leq0\\) must hold. Since, ([eq:case-when-a-lt-zero-rearranged]) holds for all \\(a&lt;0\\), the stronger inequality \\(\\mathbb{E}[W(Y-Y^{\\star})]\\geq0\\) must hold. Consequently,\n\\[\\mathbb{E}[W(Y-Y^{\\star})]=0\\]\n(2) It is clear that \\(Y^{\\star}\\) is a function of \\(X\\) by construction, since it is in \\(L^{2}(X)\\). Moreover, for any \\(W\\in L^{2}(X)\\), we have from (1) that:\n\\[\\begin{aligned}\n\\mathbb{E}[W(Y-Y^{\\star})] & =0\n\\end{aligned}\\]\nwhich is the second defining property of conditional expectations.\n(3) Lastly, suppose there is another element \\(Y'\\) that is in \\(L^{2}(X)\\) that minimizes the distance to \\(Y\\). Then we would get:\n\\[\\begin{aligned}\n\\mathbb{E}[(Y-Y')^{2}] & =\\mathbb{E}[(Y-Y^{\\star}+Y^{\\star}-Y')^{2}]\\\\\n& =\\mathbb{E}[(Y-Y^{\\star})^{2}]+2\\mathbb{E}[(Y-Y^{\\star})(Y^{\\star}-Y')]+\\mathbb{E}[(Y^{\\star}-Y')^{2}]\\\\\n& =\\mathbb{E}[(Y-Y^{\\star})^{2}]+0+\\mathbb{E}[(Y^{\\star}-Y')^{2}]\\\\\n& \\quad\\left\\{ (Y^{\\star}-Y')\\in L^{2}(X)\\perp(Y-Y^{\\star})\\right\\}\n\\end{aligned}\\]\nwhere we used the fact, that \\(Y^{\\star}-Y'\\) is a vector in \\(L^{2}(X)\\) and the orthogonality of \\(Y-Y^{\\star}\\) with \\(L^{2}(X)\\) as in (1). But, this implies that:\n\\[\\begin{aligned}\n\\cancel{\\mathbb{E}[(Y-Y')^{2}]} & =\\cancel{\\mathbb{E}[(Y-Y^{\\star})^{2}]}+\\mathbb{E}[(Y^{\\star}-Y')^{2}]\\\\\n\\mathbb{E}[(Y^{\\star}-Y')^{2}] & =0\n\\end{aligned}\\]\nSo, \\(Y^{\\star}=Y'\\) almost surely. ◻\n\n\nConditional Expectation of continuous random variables. Let \\((X,Y)\\) be two random variables with joint density \\(f_{X,Y}(x,y)\\) on \\(\\mathbf{R}^{2}\\). Suppose for simplicity, that \\(\\int_{\\mathbf{R}}f(x,y)dx&gt;0\\) for every \\(y\\) belonging to \\(\\mathbf{R}\\). Show that the conditional expectation \\(\\mathbf{E}[Y|X]\\) equals \\(h(X)\\) where \\(h\\) is the function:\n\\[\\begin{aligned}\nh(x) & =\\frac{\\int_{\\mathbf{R}}yf_{X,Y}(x,y)dy}{\\int_{\\mathbf{R}}f_{X,Y}(x,y)dy}\\label{eq:conditional-expectation-of-continuous-random-variables}\n\\end{aligned}\\]\nIn particular, verify that \\(\\mathbf{E}[\\mathbf{E}[Y|X]]=\\mathbf{E}[Y]\\).\nHint: To prove this, verify that the above formula satisfies both the properties of conditional expectations; then invoke uniqueness to finish it off.\n\n\n(i) The density function \\(f_{X,Y}(x,y)\\) is a map \\(f:\\mathbf{R}^{2}\\to\\mathbf{R}\\). The integral \\(\\int_{y=-\\infty}^{y=+\\infty}yf_{X,Y}(x_{0},y)dy\\) is the area under the curve \\(yf(x,y)\\) at the point \\(x=x_{0}\\). Let’s call it \\(A(x_{0})\\). If instead, we have an arbitrary \\(x\\), \\(\\int_{y=-\\infty}^{y=+\\infty}yf_{X,Y}(x,y)dy\\) represents the area \\(A(x)\\) of an arbitrary slice of the surface \\(yf_{X,Y}\\) at the point \\(x\\). Hence, it is a function of \\(x\\). The denominator \\(\\int_{\\mathbf{R}}f_{X,Y}(x,y)dy=f_{X}(x)\\), the density of \\(X\\), which is a function of \\(x\\). Hence, the ratio is a function of \\(x\\).\n(ii) Let \\(g(X)\\) is a bounded random variable. We have:\n\\[\\begin{aligned}\n\\mathbf{E}[g(X)(Y-h(X))] & =\\mathbf{E}[Yg(X)]-\\mathbf{E}[g(X)h(X)]\\\\\n& =\\int\\int_{\\mathbf{R}^{2}}yg(x)f_{X,Y}(x,y)dydx-\\int_{\\mathbf{R}}g(x)h(x)f(x)dx\\\\\n& =\\int\\int_{\\mathbf{R}^{2}}yg(x)f_{X,Y}(x,y)dydx\\\\\n& -\\int_{\\mathbf{R}}\\begin{array}{c}\ng(x)\\cdot\\frac{\\int_{\\mathbf{R}}yf_{X,Y}(x,y)dy}{\\int_{\\mathbf{R}}f_{X,Y}(x,y)dy}\\end{array}\\cdot\\int_{\\mathbf{R}}f_{X,Y}(x,y)dy\\ dx\\\\\n& =\\int\\int_{\\mathbf{R}^{2}}yg(x)f_{X,Y}(x,y)dydx\\\\\n& -\\int_{\\mathbf{R}}\\begin{array}{c}\ng(x)\\cdot\\frac{\\int_{\\mathbf{R}}yf_{X,Y}(x,y)dy}{\\cancel{\\int_{\\mathbf{R}}f_{X,Y}(x,y)dy}}\\end{array}\\cdot\\cancel{\\int_{\\mathbf{R}}f_{X,Y}(x,y)dy}\\ dx\\\\\n& =\\int\\int_{\\mathbf{R}^{2}}yg(x)f_{X,Y}(x,y)dydx-\\int_{\\mathbf{R}^{2}}yg(x)f_{X,Y}(x,y)\\cdot dx\\cdot dy\\\\\n& =0\n\\end{aligned}\\]\n\nThus, \\(h(X)\\) is a valid candidate for the conditional expectation \\(\\mathbf{E}[Y|X]\\). Moreover, by the existence and uniqueness theorem ([th:existence-and-uniqueness-of-the-conditional-expectation]), \\(\\mathbf{E}[Y|X]\\) is unique and equals \\(h(X)\\).\n\n\n\nWe would like to generalize the conditional expectation to the case when we condition on the information of more than one random variable. Taking the \\(L^{2}\\) point of view, we should expect that the conditional expectation is the orthogonal projection of the given random variable on the subspace generated by square integrable functions of all the variables on which we condition.\nIt is now useful to study sigma-fields, an object that was defined in chapter 1.\n\n(Sigma-Field) A sigma-field or sigma-algebra \\(\\mathcal{F}\\) of a sample space \\(\\Omega\\) is a collection of all measurable events with the following properties:\n(1) \\(\\Omega\\) is in \\(\\mathcal{F}\\).\n(2) Closure under complement. If \\(A\\in\\mathcal{F}\\), then \\(A^{C}\\in\\mathcal{F}\\).\n(3) Closure under countable unions. If \\(A_{1},A_{2},\\ldots,\\in\\mathcal{F}\\), then \\(\\bigcup_{n=1}^{\\infty}A_{n}\\in\\mathcal{F}\\).\n\nSuch objects play a fundamental role in the rigorous study of probability and real analysis in general. We will focus on the intuition behind them. First let’s mention some examples of sigma-fields of a given sample space \\(\\Omega\\) to get acquainted with the concept.\n\n(Examples of sigma-fields).\n(1) The trivial sigma-field. Note that the collection of events \\(\\{\\emptyset,\\Omega\\}\\) is a sigma-field of \\(\\Omega\\). We generally denote it by \\(\\mathcal{F}_{0}\\).\n(2) The \\(\\sigma\\)-field generated by an event \\(A\\). Let \\(A\\) be an event that is not \\(\\emptyset\\) and not the entire \\(\\Omega\\). Then the smallest sigma-field containing \\(A\\) ought to be:\n\\[\\begin{aligned}\n\\mathcal{F}_{1} & =\\{\\emptyset,A,A^{C},\\Omega\\}\n\\end{aligned}\\]\nThis sigma-field is denoted by \\(\\sigma(A)\\).\n(3) The sigma-field generated by a random variable \\(X\\).\nWe now define the \\(\\mathcal{F}_{X}\\) as follows:\n\\[\\begin{aligned}\n\\mathcal{F}_{X} & =X^{-1}(\\mathcal{B}):=\\{\\omega:X(\\omega)\\in B\\},\\forall B\\in\\mathcal{B}(\\mathbf{R})\n\\end{aligned}\\]\nwhere \\(\\mathcal{B}\\) is the Borel \\(\\sigma\\)-algebra on \\(\\mathbf{R}\\). \\(\\mathcal{F}_{X}\\) is sometimes denoted as \\(\\sigma(X)\\). \\(\\mathcal{F}_{X}\\)is the set of all events pertaining to \\(X\\). It is a sigma-algebra because:\n(i) \\(\\Omega\\in\\sigma(X)\\) because \\(\\Omega=\\{\\omega:X(\\omega)\\in\\mathbf{R}\\}\\) and \\(\\mathbf{R}\\in\\mathcal{B}(\\mathbf{R})\\).\n(ii) Let any event \\(C\\in\\sigma(X)\\). We need to show that \\(\\Omega\\setminus C\\in\\sigma(X)\\).\nSince \\(C\\in\\sigma(X)\\), there exists \\(A\\in\\mathcal{B}(\\mathbf{R})\\), such that:\n\\[\\begin{aligned}\nC & =\\{\\omega\\in\\Omega:X(\\omega)\\in A\\}\n\\end{aligned}\\]\nNow, we calculate:\n\\[\\begin{aligned}\n\\Omega\\setminus C & =\\{\\omega\\in\\Omega:X(\\omega)\\in\\mathbf{R}\\setminus A\\}\n\\end{aligned}\\]\nSince \\(\\mathcal{B}(\\mathbf{R})\\) is a sigma-algebra, it is closed under complementation. Hence, if \\(A\\in\\mathcal{B}(\\mathbf{R})\\), it implies that \\(\\mathbf{R}\\setminus A\\in\\mathcal{B}(\\mathbf{R})\\). So, \\(\\Omega\\setminus C\\in\\sigma(X)\\).\n(iii) Consider a sequence of events \\(C_{1},C_{2},\\ldots,C_{n},\\ldots\\in\\sigma(X)\\). We need to prove that \\(\\bigcup_{n=1}^{\\infty}C_{n}\\in\\sigma(X)\\).\nSince \\(C_{n}\\in\\sigma(X)\\), there exists \\(A_{n}\\in\\mathcal{B}(\\mathbf{R})\\) such that:\n\\[\\begin{aligned}\nC_{n} & =\\{\\omega\\in\\Omega:X(\\omega)\\in A_{n}\\}\n\\end{aligned}\\]\nNow, we calculuate:\n\\[\\begin{aligned}\n\\bigcup_{n=1}C_{n} & =\\{\\omega\\in\\Omega:X(\\omega)\\in\\bigcup_{n=1}^{\\infty}A_{n}\\}\n\\end{aligned}\\]\nBut, \\(\\bigcup_{n=1}^{\\infty}A_{n}\\in\\mathcal{B}(\\mathbf{R})\\). So, \\(\\bigcup_{n=1}^{\\infty}C_{n}\\in\\sigma(X)\\).\nConsequently, \\(\\sigma(X)\\) is indeed a \\(\\sigma\\)-algebra.\nIntuitively, we think of \\(\\sigma(X)\\) as containing all information about \\(X\\).\n(4) The sigma-field generated by a stochastic process \\((X_{s},s\\leq t)\\). Let \\((X_{s},s\\geq0)\\) be a stochastic process. Consider the process restricted to \\([0,t]\\), \\((X_{s},s\\leq t)\\). We consider the smallest sigma-field containing all events pertaining to the random variables \\(X_{s},s\\leq t\\). We denote it by \\(\\sigma(X_{s},s\\leq t)\\) or \\(\\mathcal{F}_{t}\\).\n\nThe sigma-fields on \\(\\Omega\\) have a natural (partial) ordering: two sigma-fields \\(\\mathcal{G}\\) and \\(\\mathcal{F}\\) of \\(\\Omega\\) are such that \\(\\mathcal{G}\\subseteq\\mathcal{F}\\) if all the events in \\(\\mathcal{G}\\) are in \\(\\mathcal{F}\\). For example, the trivial \\(\\sigma\\)-field \\(\\mathcal{F}_{0}=\\{\\emptyset,\\Omega\\}\\) is contained in all the \\(\\sigma\\)-fields of \\(\\Omega\\). Clearly, the \\(\\sigma\\)-field \\(\\mathcal{F}_{t}=\\sigma(X_{s},s\\leq t)\\) is contained in \\(\\mathcal{F}_{t'}\\) if \\(t\\leq t'\\).\nIf all the events pertaining to a random variable \\(X\\) are in the \\(\\sigma\\)-field \\(\\mathcal{G}\\) (and thus we can compute \\(\\mu(X^{-1}((a,b]))\\)), we will say that \\(X\\) is \\(\\mathcal{G}\\)-measurable. This means that all information about \\(X\\) is contained in \\(\\mathcal{G}\\).\n\nLet \\(X\\) be a random variable defined on \\((\\Omega,\\mathcal{F},\\mathbb{P})\\). Consider another \\(\\mathcal{G}\\subseteq\\mathcal{F}\\). Then \\(X\\) is said to be \\(\\mathcal{G}\\)-measurable, if and only if:\n\\[\\begin{aligned}\n\\{\\omega:X(\\omega)\\in(a,b]\\} & \\in\\mathcal{G}\\text{ for all intervals }(a,b]\\in\\mathbf{R}\n\\end{aligned}\\]\n\n\n(\\(\\mathcal{F}_{0}\\)-measurable random variables). Consider the trivial sigma-field \\(\\mathcal{F}_{0}=\\{\\emptyset,\\Omega\\}\\). A random variable that is \\(\\mathcal{F}_{0}\\)-measurable must be a constant. Indeed, we have that for any interval \\((a,b]\\), \\(\\{\\omega:X(\\omega)\\in(a,b]\\}=\\emptyset\\) or \\(\\{\\omega:X(\\omega)\\in(a,b]\\}=\\Omega\\). This can only hold if \\(X\\) takes a single value.\n\n\n[]{#ex:sigma(X)-measurable-random-variables-example label=“ex:sigma(X)-measurable-random-variables-example”}(\\(\\sigma(X)\\)-measurable random variables). Let \\(X\\) be a given random variable on \\((\\Omega,\\mathcal{F},\\mathbb{P})\\). Roughly speaking, a \\(\\sigma(X)\\)-measurable random variable is determined by the information of \\(X\\) only. Here is the simplest example of a \\(\\sigma(X)\\)-measurable random variable. Take the indicator function \\(Y=\\mathbf{1}_{\\{X\\in B\\}}\\) for some event \\(\\{X\\in B\\}\\) pertaining to \\(X\\). Then the pre-images \\(\\{\\omega:Y(\\omega)\\in(a,b]\\}\\) are either \\(\\emptyset\\), \\(\\{X\\in B\\}\\), \\(\\{X\\in B^{C}\\}\\) or \\(\\Omega\\) depending on whether \\(0,1\\) are in \\((a,b]\\) or not. All of these events are in \\(\\sigma(X)\\). More generally, one can construct a \\(\\sigma(X)\\)-measurable random variable by taking linear combinations of indicator functions of events of the form \\(\\{X\\in B\\}\\).\nIt turns out that any (Borel measurable) function of \\(X\\) can be approximated by taking limits of such simple functions.\nConcretely, this translates to the following statement:\n\\[\\text{If }Y\\text{ is \\ensuremath{\\sigma}(X)-measurable, then Y=g(X) for some function g}\\]\nIn the same way, if \\(Z\\) is \\(\\sigma(X,Y)\\)-measurable, then \\(Z=h(X,Y)\\) for some \\(h\\). These facts can be proved rigorously using measure theory.\n\nWe are ready to give the general definition of conditional expectation.\n\n(Coin-Tossing Space). Suppose a coin is tossed infinitely many times. Let \\(\\Omega\\) be the set of all infinite sequences of \\(H\\)s and \\(T\\)s. A generic element of \\(\\Omega\\) is denoted by \\(\\omega_{1}\\omega_{2}\\ldots\\), where \\(\\omega_{n}\\) indicates the result of the \\(n\\)th coin toss. \\(\\Omega\\) is an uncountable sample space. The trivial sigma-field \\(\\mathcal{F}_{0}=\\{\\emptyset,\\Omega\\}\\). Assume that we don’t know anything about the outcome of the experiement. Even without any information, we know that the true \\(\\omega\\) belongs to \\(\\Omega\\) and does not belong to \\(\\emptyset\\). It is the information learned at time \\(0\\).\nNext, assume that we know the outcome of the first coin toss. Define \\(A_{H}=\\{\\omega:\\omega_{1}=H\\}\\)=set of all sequences beginning with \\(H\\) and \\(A_{T}=\\{\\omega:\\omega_{1}=T\\}\\)=set of all sequences beginning with \\(T\\). The four sets resolved by the first coin-toss form the the \\(\\sigma\\)-field \\(\\mathcal{F}_{1}=\\{\\emptyset,A_{H},A_{T},\\Omega\\}\\). We shall think of this \\(\\sigma\\)-field as containing the information learned by knowing the outcome of the first coin toss. More precisely, if instead of being told about the first coin toss, we are told for each set in \\(\\mathcal{F}_{1}\\), whether or not the true \\(\\omega\\) belongs to that set, then we know the outcome of the first coin toss and nothing more.\nIf we are told the first two coin tosses, we obtain a finer resolution. In particular, the four sets:\n\\[\\begin{aligned}\nA_{HH} & =\\{\\omega:\\omega_{1}=H,\\omega_{2}=H\\}\\\\\nA_{HT} & =\\{\\omega:\\omega_{1}=H,\\omega_{2}=T\\}\\\\\nA_{TH} & =\\{\\omega:\\omega_{1}=T,\\omega_{2}=H\\}\\\\\nA_{TT} & =\\{\\omega:\\omega_{1}=T,\\omega_{2}=T\\}\n\\end{aligned}\\]\nare resolved. Of course, the sets in \\(\\mathcal{F}_{1}\\) are resolved. Whenever a set is resolved, so is its complement, which means that \\(A_{HH}^{C}\\), \\(A_{HT}^{C}\\), \\(A_{TH}^{C}\\) and \\(A_{TT}^{C}\\) are resolved, so is their union which means that \\(A_{HH}\\cup A_{TH}\\), \\(A_{HH}\\cup A_{TT}\\), \\(A_{HT}\\cup A_{TH}\\) and \\(A_{HT}\\cup A_{TT}\\) are resolved. The other two pair-wise unions \\(A_{HH}\\cup A_{HT}=A_{H}\\) and \\(A_{TH}\\cup A_{TT}=A_{T}\\) are already resolved. Finally, the triple unions are also resolved, because \\(A_{HH}\\cup A_{HT}\\cup A_{TH}=A_{TT}^{C}\\) and so forth. Hence, the information pertaining to the second coin-toss is contained in:\n\\[\\begin{aligned}\n\\mathcal{F}_{2} & =\\{\\emptyset,\\Omega,\\\\\n& A_{H},A_{T},\\\\\n& A_{HH},A_{HT},A_{TH},A_{TT},\\\\\n& A_{HH}^{C},A_{HT}^{C},A_{TH}^{C},A_{TT}^{C},\\\\\n& A_{HH}\\cup A_{TH},A_{HH}\\cup A_{TT},A_{HT}\\cup A_{TH},A_{HT}\\cup A_{TT}\\}\n\\end{aligned}\\]\nHence, if the outcome of the first two coin tosses is known, all of the events in \\(\\mathcal{F}_{2}\\) are resolved - we exactly know, if each event has ocurred or not. \\(\\mathcal{F}_{2}\\) is the information learned by observing the first two coin tosses.\n\n\n(Exercises on sigma-fields).\n(a) Let \\(A\\), \\(B\\) be two proper subsets of \\(\\Omega\\) such that \\(A\\cap B\\neq\\emptyset\\) and \\(A\\cup B\\neq\\Omega\\). Write down \\(\\sigma(\\{A,B\\})\\), the smallest sigma-field containing \\(A\\) and \\(B\\) explicitly. What if \\(A\\cap B=\\emptyset\\)?\n(b) The Borel sigma-field is the smallest sigma-field containing intervals of the form \\((a,b]\\) in \\(\\mathbf{R}\\). Show that all singletons \\(\\{b\\}\\) are in \\(\\mathcal{B}(\\mathbf{R})\\) by writing \\(\\{b\\}\\) as a countable intersection of intervals \\((a,b]\\). Conclude that all open intervals \\((a,b)\\) and all closed intervals \\([a,b]\\) are in \\(\\mathcal{B}(\\mathbf{R})\\). Is the subset \\(\\mathbf{Q}\\) of rational numbers a Borel set?\n\n\nProof. Proof. (a) The sigma-field generated by the two events \\(A\\), \\(B\\) is given by:\n\\[\\begin{aligned}\n\\sigma(\\{A,B\\}) & =\\{\\emptyset,\\Omega,\\\\\n& A,B,A^{C},B^{C},\\\\\n& A\\cup B,A\\cap B,\\\\\n& A\\cup B^{C},A^{C}\\cup B,A^{C}\\cup B^{C},\\\\\n& A\\cap B^{C},A^{C}\\cap B,A^{C}\\cap B^{C},\\\\\n& (A\\cup B)\\cap(A\\cap B)^{C},\\\\\n& (A\\cup B)^{C}\\cup(A\\cap B)\\}\n\\end{aligned}\\]\n(b) Firstly, recall that:\n\\[\\begin{aligned}\n\\mathcal{B}(\\mathbf{R}) & =\\bigcap_{\\alpha\\in\\Lambda}\\mathcal{F}_{\\alpha}=\\bigcap\\sigma(\\{I:I\\text{ is an interval }(a,b]\\subseteq\\mathbf{R}\\})\n\\end{aligned}\\]\nWe can write:\n\\[\\begin{aligned}\n\\{b\\} & =\\bigcap_{n=1}^{\\infty}\\left(b-\\frac{1}{n},b\\right]\n\\end{aligned}\\]\nAs \\(\\mathcal{B}(\\mathbf{R})\\) is a sigma-field, it is closed under countable intersections. Hence, the singleton set \\(\\{b\\}\\)is a Borel set.\nSimilarly, we can write, any open interval as the countable union:\n\\[\\begin{aligned}\n(a,b) & =\\bigcup_{n=1}^{\\infty}\\left(a,b-\\frac{1}{n}\\right]\n\\end{aligned}\\]\nWe can convince ourselves, that equality indeed holds. Let \\(x\\in(a,b)\\) and choose \\(N\\), such that \\(\\frac{1}{N}&lt;|b-x|\\). Then, for all \\(n\\geq N\\), \\(x\\in(a,b-1/n]\\). Thus, it belongs to the RHS. In the reverse direction, let \\(x\\) belong to \\(\\bigcup_{n=1}^{\\infty}\\left(a,b-\\frac{1}{n}\\right]\\). So, \\(x\\) belongs to atleast one of these sets. Therefore, \\(x\\in(a,b)\\) is trivially true. So, the two sets are equal.\nHence, open intervals are Borel sets.\nSimilarly, we may write:\n\\[\\begin{aligned}\n[a,b] & =\\bigcap_{n=1}^{\\infty}\\left(a-\\frac{1}{n},b+\\frac{1}{n}\\right)\n\\end{aligned}\\]\nConsequently, closed intervals are Borel sets. Since \\(\\mathbf{Q}\\) is countable, it is a Borel set. Moreover, the empty set \\(\\emptyset\\) and \\(\\mathbf{R}\\) are Borel sets. So, \\(\\mathbf{R}\\backslash\\mathbf{Q}\\) is also a Borel set. ◻\n\n\nLet \\((X,Y)\\) be a Gaussian vector with mean \\(0\\) and covariance matrix\n\\[\\begin{aligned}\nC & =\\left[\\begin{array}{cc}\n1 & \\rho\\\\\n\\rho & 1\n\\end{array}\\right]\n\\end{aligned}\\]\nfor \\(\\rho\\in(-1,1)\\). We verify that the example ([ex:conditional-expectation-of-gaussian-vectors]) and exercise ([ex:=00005BArguin-4.1=00005D-Conditional-Expectation-of-continuous-random-variables]) yield the same conditional expectation.\n(a) Use equation ([eq:conditional-expectation-of-gaussian-vector]) to show that \\(\\mathbf{E}[Y|X]=\\rho X\\).\n(b) Write down the joint PDF \\(f(x,y)\\) of \\((X,Y)\\).\n(c) Show that \\(\\int_{\\mathbf{R}}yf(x,y)dy=\\rho x\\) and that \\(\\int_{\\mathbf{R}}f(x,y)dy=1\\).\n(d) Deduce that \\(\\mathbf{E}[Y|X]=\\rho X\\) using the equation ([eq:conditional-expectation-of-continuous-random-variables]).\n\n\nProof. Proof. (a) Since \\((X,Y)\\) have mean \\(0\\) and variance \\(1\\), it follows that:\n\\[\\begin{aligned}\n\\mathbf{E}[(X-EX)(Y-EY)] & =\\mathbf{E}(XY)\\\\\n\\sqrt{(\\mathbf{E}[X^{2}]-(\\mathbf{E}X)^{2})}\\cdot\\sqrt{(\\mathbf{E}[Y^{2}]-(\\mathbf{E}Y)^{2})} & =\\sqrt{(1-0)(1-0)}\\\\\n& =1\n\\end{aligned}\\]\nand therefore,\n\\[\\begin{aligned}\n\\rho & =\\frac{\\mathbf{E}(XY)}{1}=\\frac{\\mathbf{E}[XY]}{\\mathbf{E}[X^{2}]}\n\\end{aligned}\\]\nSince \\((X,Y)\\) is a Gaussian vector, using ([eq:conditional-expectation-of-gaussian-vector]), we have:\n\\[\\begin{aligned}\n\\mathbf{E}[Y|X] & =\\frac{\\mathbf{E}[XY]}{\\mathbf{E}[X^{2}]}X=\\rho X\n\\end{aligned}\\]\n(b) Consider the augmented matrix \\([C|I]\\). We have:\n\\[\\begin{aligned}\n[C|I] & =\\left[\\left.\\begin{array}{cc}\n1 & \\rho\\\\\n\\rho & 1\n\\end{array}\\right|\\begin{array}{cc}\n1 & 0\\\\\n0 & 1\n\\end{array}\\right]\n\\end{aligned}\\]\nPerforming \\(R_{2}=R_{2}-\\rho R_{1}\\), the above system is row-equivalent to:\n\\[\\left[\\left.\\begin{array}{cc}\n1 & \\rho\\\\\n0 & 1-\\rho^{2}\n\\end{array}\\right|\\begin{array}{cc}\n1 & 0\\\\\n-\\rho & 1\n\\end{array}\\right]\\]\nPerforming \\(R_{2}=\\frac{1}{1-\\rho^{2}}R_{2}\\), the above system is row-equivalent to:\n\\[\\left[\\begin{array}{cc}\n1 & \\rho\\\\\n0 & 1\n\\end{array}\\left|\\begin{array}{cc}\n1 & 0\\\\\n\\frac{-\\rho}{1-\\rho^{2}} & \\frac{1}{1-\\rho^{2}}\n\\end{array}\\right.\\right]\\]\nPerforming \\(R_{1}=R_{1}-\\rho R_{2}\\), we have:\n\\[\\left[\\begin{array}{cc}\n1 & 0\\\\\n0 & 1\n\\end{array}\\left|\\begin{array}{cc}\n\\frac{1}{1-\\rho^{2}} & -\\frac{\\rho}{1-\\rho^{2}}\\\\\n\\frac{-\\rho}{1-\\rho^{2}} & \\frac{1}{1-\\rho^{2}}\n\\end{array}\\right.\\right]\\]\nThus, \\[\\begin{aligned}\nC^{-1} & =\\frac{1}{1-\\rho^{2}}\\left[\\begin{array}{cc}\n1 & -\\rho\\\\\n-\\rho & 1\n\\end{array}\\right]\n\\end{aligned}\\]\nMoreover, \\(\\det C=1-\\rho^{2}.\\)\nTherefore, the joint density of \\((X,Y)\\) is given by:\n\\[\\begin{aligned}\nf(x,y) & =\\frac{1}{2\\pi\\sqrt{1-\\rho^{2}}}\\exp\\left[-\\frac{1}{2(1-\\rho^{2})}\\left[\\begin{array}{cc}\nx & y\\end{array}\\right]\\left[\\begin{array}{cc}\n1 & -\\rho\\\\\n-\\rho & 1\n\\end{array}\\right]\\left[\\begin{array}{c}\nx\\\\\ny\n\\end{array}\\right]\\right]\\\\\n& =\\frac{1}{2\\pi\\sqrt{1-\\rho^{2}}}\\exp\\left[-\\frac{1}{2(1-\\rho^{2})}\\left[\\begin{array}{cc}\nx-\\rho y & -\\rho x+y\\end{array}\\right]\\left[\\begin{array}{c}\nx\\\\\ny\n\\end{array}\\right]\\right]\\\\\n& \\frac{1}{2\\pi\\sqrt{1-\\rho^{2}}}\\exp\\left[-\\frac{1}{2(1-\\rho^{2})}(x^{2}-2\\rho xy+y^{2})\\right]\n\\end{aligned}\\]\n(c) Claim I. \\(\\int_{\\mathbf{R}}yf(x,y)dy=\\rho x\\).\nCompleting the square, we have:\n\\[\\begin{aligned}\n(x^{2}-2\\rho xy+y^{2}) & =(y-\\rho x)^{2}+x^{2}(1-\\rho^{2})\n\\end{aligned}\\]\nThus, we can write:\n\\[\\begin{aligned}\n\\int_{\\mathbf{R}}yf(x,y)dy & =\\frac{1}{2\\pi\\sqrt{1-\\rho^{2}}}e^{-\\frac{1}{2}x^{2}}\\int_{\\mathbf{R}}ye^{-\\frac{1}{2}\\frac{(y-\\rho x)^{2}}{(1-\\rho^{2})}}dy\n\\end{aligned}\\]\nLet’s substitute\n\\[\\begin{aligned}\nz & =\\frac{(y-\\rho x)}{\\sqrt{1-\\rho^{2}}}\\\\\ndz & =\\frac{dy}{\\sqrt{1-\\rho^{2}}}\n\\end{aligned}\\]\nTherefore,\n\\[\\begin{aligned}\n\\int_{\\mathbf{R}}ye^{-\\frac{1}{2}\\frac{(y-\\rho x)^{2}}{(1-\\rho^{2})}}dy & =\\sqrt{1-\\rho^{2}}\\int_{\\mathbf{R}}(\\rho x+\\sqrt{1-\\rho^{2}}z)e^{-\\frac{z^{2}}{2}}dz\\\\\n& =\\rho x\\cdot\\sqrt{1-\\rho^{2}}\\int_{\\mathbf{R}}e^{-\\frac{z^{2}}{2}}dz+(1-\\rho^{2})\\int_{\\mathbf{R}}ze^{-\\frac{z^{2}}{2}}dz\\\\\n& =\\rho x\\cdot\\sqrt{1-\\rho^{2}}\\cdot\\sqrt{2\\pi}+(1-\\rho^{2})\\cdot0\\\\\n& =\\rho x\\cdot\\sqrt{1-\\rho^{2}}\\cdot\\sqrt{2\\pi}\n\\end{aligned}\\]\nConsequently,\n\\[\\begin{aligned}\n\\int_{\\mathbf{R}}yf(x,y)dy & =\\frac{1}{2\\pi\\cancel{\\sqrt{1-\\rho^{2}}}}e^{-\\frac{1}{2}x^{2}}\\rho x\\cdot\\cancel{\\sqrt{1-\\rho^{2}}}\\cdot\\sqrt{2\\pi}\\\\\n& =\\rho x\\cdot\\frac{1}{\\sqrt{2\\pi}}e^{-\\frac{1}{2}x^{2}}\\\\\n& =\\rho x\\cdot f_{X}(x)\\\\\n\\frac{\\int_{\\mathbf{R}}yf(x,y)dy}{f_{X}(x)} & =\\frac{\\int_{\\mathbf{R}}yf(x,y)dy}{\\int_{\\mathbf{R}}f(x,y)}=\\rho x\n\\end{aligned}\\]\n(d) For a Gaussian vector \\((X,Y),\\) the conditional expectation \\(\\mathbf{E}[Y|X]=h(X)\\). Hence, \\(\\mathbf{E}[Y|X]=\\rho X\\). ◻\n\n\n(Conditional Expectation) Let \\(Y\\) be an integrable random variable on \\((\\Omega,\\mathcal{F},\\mathbb{P})\\) and let \\(\\mathcal{G}\\subseteq\\mathcal{F}\\) be a sigma-field of \\(\\Omega\\). The conditional expectation of \\(Y\\) given \\(\\mathcal{G}\\) is the random variable denoted by \\(\\mathbb{E}[Y|\\mathcal{G}]\\) such that the following hold:\n(a) \\(\\mathbb{E}[Y|\\mathcal{G}]\\) is \\(\\mathcal{G}\\)-measurable.\nIn other words, all events pertaining to the random variable \\(\\mathbb{E}[Y|\\mathcal{G}]\\) are in \\(\\mathcal{G}\\).\n(b) For any (bounded) random variable \\(W\\), that is \\(\\mathcal{G}\\)-measurable,\n\\[\\begin{aligned}\n\\mathbb{E}[WY] & =\\mathbb{E}[W\\mathbb{E}[Y|\\mathcal{G}]]\n\\end{aligned}\\]\nIn other words, \\(\\mathbf{E}[Y|\\mathcal{G}]\\) is a proxy for \\(Y\\) as far as the events in \\(\\mathcal{G}\\) are concerned.\nNote that, by taking \\(W=1\\) in the property (B), we recover:\n\\[\\begin{aligned}\n\\mathbf{E}[\\mathbf{E}[Y|\\mathcal{G}]] & =\\mathbf{E}[Y]\n\\end{aligned}\\]\n\n\nBeware of the notation! If \\(\\mathcal{G}=\\sigma(X)\\), then the conditional expectation \\(\\mathbf{E}[Y|\\sigma(X)]\\) is usually denoted by \\(\\mathbf{E}[Y|X]\\) for short. However, one should always keep in mind that conditioning on \\(X\\) is in fact projecting on the linear subspace generated by all variables constructed from \\(X\\) and not on the linear space generated by generated by \\(X\\) alone. In the same way, the conditional expectation \\(\\mathbf{E}[Z|\\sigma(X,Y)]\\) is often written \\(\\mathbf{E}[Z|X,Y]\\) for short.\nAs expected, if \\(Y\\) is in \\(L^{2}(\\Omega,\\mathcal{F},\\mathbb{P})\\), then \\(\\mathbf{E}[Y|\\mathcal{G}]\\) is given by the orthogonal projection of \\(Y\\) onto the subspace \\(L^{2}(\\Omega,\\mathcal{G},\\mathbb{P})\\), the subspace of square integrable random variables that are \\(\\mathcal{G}\\)-measurable. We write \\(Y^{\\star}\\) for the random variable in \\(L^{2}(\\Omega,\\mathcal{G},\\mathbb{P})\\) that is closest to \\(Y\\) that is:\n\\[\\begin{aligned}\n\\min_{Z\\in L^{2}(\\Omega,\\mathcal{G},\\mathbb{P})}\\mathbf{E}[(Y-Z)^{2}] & =\\mathbf{E}[(Y-Y^{\\star})^{2}]\\label{eq:conditional-expectation}\n\\end{aligned}\\]\n\n\n(Existence and Uniqueness of Conditional Expectations) Let \\(\\mathcal{G}\\subset\\mathcal{F}\\) be a sigma-field of \\(\\Omega\\). Let \\(Y\\) be a random variable in \\(L^{2}(\\Omega,\\mathcal{F},\\mathbb{P})\\). Then, the conditional expectation \\(\\mathbf{E}[Y|\\mathcal{G}]\\) is the random variable \\(Y^{\\star}\\) given in the equation ([eq:conditional-expectation]). Namely, it is the random variable in \\(L^{2}(\\Omega,\\mathcal{G},\\mathbb{P})\\) that is closest to \\(Y\\) in the \\(L^{2}\\)-distance. In particular we have the following:\n\n\nIt is the orthogonal projection of \\(Y\\) onto \\(L^{2}(\\Omega,\\mathcal{G},\\mathbb{P})\\), that is, \\(Y-Y^{\\star}\\) is orthogonal to the random variables in \\(L^{2}(\\Omega,\\mathcal{G},\\mathbb{P})\\).\nIt is unique.\n\nAgain, the result should be interpreted as follows: The conditional expectation \\(\\mathbf{E}[Y|\\mathcal{G}]\\) is the best approximation of \\(Y\\) given the information included in \\(\\mathcal{G}\\).\n\nThe conditional expectation in fact exists and is unique for any integrable random variable \\(Y\\)(i.e. \\(Y\\in L^{1}(\\Omega,\\mathcal{F},\\mathbb{P})\\) as the definition suggests. However, there is no orthogonal projection in \\(L^{1}\\), so the intuitive geometric picture is lost.\n\n\nFigure. An illustration of the conditional expectation \\(\\mathbb{E}[Y|\\mathcal{G}]\\) as an orthogonal projection of \\(Y\\) onto the subspace \\(L^2(\\Omega,\\mathcal{G},\\mathbb{P})\\).\n\n\n(Conditional Expectation for Gaussian Vectors. II.) Consider the Gaussian vector \\((X_{1},\\ldots,X_{n})\\). Without loss of generality, suppose it has mean \\(0\\) and is non-degenerate. What is the best approximation of \\(X_{n}\\) given the information \\(X_{1},\\ldots,X_{n-1}\\)? In other words, what is:\n\\[\\mathbf{E}[X_{n}|\\sigma(X_{1},\\ldots,X_{n-1})\\]\nWith example ([ex:sigma(X)-measurable-random-variables-example]) in mind, let’s write \\(\\mathbf{E}[X_{n}|X_{1}\\ldots X_{n-1}]\\) for short. From example ([ex:=00005BArguin-4.1=00005D-Conditional-Expectation-of-continuous-random-variables]), we know that if \\((X,Y)\\) is a Gaussian vector with mean \\(0\\), then \\(\\mathbf{E}[Y|X]\\) is a multiple of \\(X\\). Thus, we expect, that \\(\\mathbf{E}[X_{n}|X_{1}X_{2}\\ldots X_{n-1}]\\) is a linear combination of \\(X_{1},X_{2},\\ldots,X_{n-1}\\). That is, there exists \\(a_{1},\\ldots,a_{n-1}\\) such that:\n\\[\\begin{aligned}\n\\mathbf{E}[X_{n}|X_{1}X_{2}\\ldots X_{n-1}] & =a_{1}X_{1}+a_{2}X_{2}+\\ldots+a_{n-1}X_{n-1}\n\\end{aligned}\\] In particular, since the conditional expectation is a linear combination of the \\(X\\)’s, it is itself a Gaussian random variable. The best way to find the coefficient \\(a\\)’s is to go back to IID decomposition of Gaussian vectors.\nLet \\((Z_{1},Z_{2},\\ldots,Z_{n-1})\\) be IID standard Gaussians constructed from the linear combination of \\((X_{1},X_{2},\\ldots,X_{n-1})\\). Then, we have:\n\\[\\begin{aligned}\n\\mathbf{E}[X_{n}|X_{1}X_{2}\\ldots X_{n-1}] & =b_{1}Z_{1}+\\ldots+b_{n-1}Z_{n-1}\n\\end{aligned}\\]\nNow, recall, that we construct the random variables \\(Z_{1}\\), \\(Z_{2}\\), \\(\\ldots\\), \\(Z_{n}\\) using Gram-Schmidt orthogonalization:\n\\[\\begin{aligned}\n\\tilde{Z_{1}} & =X_{1}, & Z_{1} & =\\frac{\\tilde{Z_{1}}}{\\mathbf{E}(\\tilde{Z}_{1}^{2})}\\\\\n\\tilde{Z_{2}} & =X_{2}-\\mathbf{E}(X_{2}Z_{1})Z_{1} & Z_{2} & =\\frac{\\tilde{Z}_{2}}{\\mathbf{E}(\\tilde{Z}_{2}^{2})}\\\\\n\\tilde{Z_{3}} & =X_{3}-\\sum_{i=1}^{2}\\mathbf{E}(X_{3}Z_{i})Z_{i} & Z_{3} & =\\frac{\\tilde{Z}_{3}}{\\mathbf{E}(\\tilde{Z}_{3}^{2})}\\\\\n& \\vdots\n\\end{aligned}\\]\n\nThe simple case for \\(n=2\\) random variables.\nWe have already seen before:\n\\[\\begin{aligned}\n\\mathbf{E}[X_{1}(X_{2}-\\mathbf{E}(X_{2}Z_{1})Z_{1})] & =\\mathbf{E}[\\tilde{Z}_{1}(X_{2}-\\mathbf{E}(X_{2}Z_{1})Z_{1})]\\\\\n& =\\frac{\\mathbf{E}[\\tilde{Z}_{1}^{2}]}{\\mathbf{E}[\\tilde{Z}_{1}^{2}]}\\times\\mathbf{E}\\left[\\tilde{Z}_{1}(X_{2}-\\mathbf{E}(X_{2}Z_{1})Z_{1})\\right]\\\\\n& =\\mathbf{E}[\\tilde{Z}_{1}^{2}]\\times\\mathbf{E}\\left[\\frac{\\tilde{Z}_{1}}{\\mathbf{E}[\\tilde{Z}_{1}^{2}]}(X_{2}-\\mathbf{E}(X_{2}Z_{1})Z_{1})\\right]\\\\\n& =\\mathbf{E}[\\tilde{Z}_{1}^{2}]\\times\\mathbf{E}[Z_{1}(X_{2}-\\mathbf{E}(X_{2}Z_{1})Z_{1})]\\\\\n& =\\mathbf{E}[\\tilde{Z}_{1}^{2}]\\times\\left(\\mathbf{E}[Z_{1}X_{2}]-\\mathbf{E}(X_{2}Z_{1})\\mathbf{E}[Z_{1}^{2}]\\right)\\\\\n& =0\n\\end{aligned}\\]\nSo,\\(X_{2}-\\mathbf{E}(X_{2}Z_{1})Z_{1}\\) is orthogonal to \\(X_{1}\\).\nMoreover, \\(\\mathbf{E}(X_{2}Z_{1})Z_{1}\\) is a function of \\(X_{1}\\). Thus, both the properties of conditional expectation are satisfied. Since conditional expectations are unique, we must have, \\(\\mathbf{E}[X_{2}|X_{1}]=\\mathbf{E}(X_{2}Z_{1})Z_{1}\\).\nThe case for \\(n=3\\) random variables.\nWe have seen that:\n\\[\\begin{aligned}\n\\mathbf{E}[X_{1}(X_{3}-\\mathbf{E}(X_{3}Z_{1})Z_{1}-\\mathbf{E}(X_{3}Z_{2})Z_{2})] & =\\frac{\\mathbf{E}[\\tilde{Z}_{1}^{2}]}{\\mathbf{E}[\\tilde{Z}_{1}^{2}]}\\times\\mathbf{E}[\\tilde{Z}_{1}(X_{3}-\\mathbf{E}(X_{3}Z_{1})Z_{1}-\\mathbf{E}(X_{3}Z_{2})Z_{2})]\\\\\n& =\\mathbf{E}[\\tilde{Z}_{1}^{2}]\\times\\mathbf{E}\\left\\{ \\frac{\\tilde{Z}_{1}}{\\mathbf{E}[\\tilde{Z}_{1}^{2}]}(X_{3}-\\mathbf{E}(X_{3}Z_{1})Z_{1}-\\mathbf{E}(X_{3}Z_{2})Z_{2})\\right\\} \\\\\n& =\\mathbf{E}[\\tilde{Z}_{1}^{2}]\\times\\mathbf{E}\\left\\{ Z_{1}(X_{3}-\\mathbf{E}(X_{3}Z_{1})Z_{1}-\\mathbf{E}(X_{3}Z_{2})Z_{2})\\right\\} \\\\\n& =\\mathbf{E}[\\tilde{Z}_{1}^{2}]\\times\\mathbf{E}[X_{3}Z_{1}]-\\mathbf{E}[X_{3}Z_{1}]\\mathbf{E}[Z_{1}^{2}]-\\mathbf{E}[X_{3}Z_{2}]\\mathbf{E}[Z_{1}Z_{2}]\\\\\n& =0\n\\end{aligned}\\]\nIt is an easy exercise to show that it is orthogonal to \\(X_{2}\\).\nHence, \\(X_{3}-\\mathbf{E}(X_{3}Z_{1})Z_{1}-\\mathbf{E}(X_{3}Z_{2})Z_{2}\\) is orthogonal to \\(X_{1}\\) and \\(X_{2}\\). Moreover, \\(\\mathbf{E}(X_{3}Z_{1})Z_{1}+\\mathbf{E}(X_{3}Z_{2})Z_{2}\\) is a function of \\(X_{1}\\), \\(X_{2}\\). Thus, we must have:\n\\[\\begin{aligned}\n\\mathbf{E}[X_{3}|X_{1}X_{2}] & =\\mathbf{E}(X_{3}Z_{1})Z_{1}+\\mathbf{E}(X_{3}Z_{2})Z_{2}\n\\end{aligned}\\]\nIn general, \\(X_{n}-\\sum_{i=1}^{n-1}\\mathbf{E}(X_{n}Z_{i})Z_{i}\\) is orthogonal to \\(X_{1}\\), \\(X_{2}\\), \\(\\ldots\\), \\(X_{n-1}\\). Hence,\n\\[\\begin{aligned}\n\\mathbf{E}[X_{n}|X_{1}X_{2}\\ldots X_{n-1}] & =\\sum_{i=1}^{n-1}\\mathbf{E}(X_{n}Z_{i})Z_{i}\n\\end{aligned}\\]\n\n\n\nWe now list the properties of conditional expectation that follow from the two defining properties (A), (B) in the definition. They are extremely useful, when doing explicit computations on martingales. A good way to remember them is to understand how they relate to the interpretation of conditional expectation as an orthogonal projection onto a subspace or, equivalently, as the best approximation of the variable given the information available.\n\nLet \\(Y\\) be an integrable random variable on \\((\\Omega,\\mathcal{F},\\mathbb{P})\\). Let \\(\\mathcal{G}\\subseteq\\mathcal{F}\\) be another sigma-field of \\(\\Omega\\). Then, the conditional expectation \\(\\mathbf{E}[Y|\\mathcal{G}]\\) has the following properties:\n(1) If \\(Y\\) is \\(\\mathcal{G}\\)-measurable, then :\n\\[\\begin{aligned}\n\\mathbf{E}[Y|\\mathcal{G}] & =Y\n\\end{aligned}\\]\n(2) Taking out what is known. More generally, if \\(Y\\) is \\(\\mathcal{G-}\\)measurable and \\(X\\) is another integrable random variable (with \\(XY\\) also integrable), then :\n\\[\\begin{aligned}\n\\mathbf{E}[XY|\\mathcal{G}] & =Y\\mathbf{E}[X|\\mathcal{G}]\n\\end{aligned}\\]\nThis makes sense, since \\(Y\\) is determined by \\(\\mathcal{G}\\), so we can take out what is known; it can be treated as a constant for the conditional expectation.\n(3) Independence. If \\(Y\\) is independent of \\(\\mathcal{G}\\), that is, for any events \\(\\{Y\\in(a,b]\\}\\) and \\(A\\in\\mathcal{G}\\):\n\\[\\begin{aligned}\n\\mathbb{P}(\\{Y\\in I\\}\\cap A) & =\\mathbb{P}(\\{Y\\in I\\})\\cdot\\mathbb{P}(A)\n\\end{aligned}\\]\nthen\n\\[\\begin{aligned}\n\\mathbf{E}[Y|\\mathcal{G}] & =\\mathbf{E}[Y]\n\\end{aligned}\\]\nIn other words, if you have no information on \\(Y\\), your best guess for its value is simply plain expectation.\n(4) Linearity of conditional expectations. Let \\(X\\) be another integrable random variable on \\((\\Omega,\\mathcal{F},\\mathbb{P})\\). Then,\n\\[\\begin{aligned}\n\\mathbf{E}[aX+bY|\\mathcal{G}] & =a\\mathbf{E}[X|\\mathcal{G}]+b\\mathbf{E}[Y|\\mathcal{G}],\\quad\\text{for any }a,b\\in\\mathbf{R}\n\\end{aligned}\\]\nThe linearity justifies the cumbersom choice of notation \\(\\mathbf{E}[Y|\\mathcal{G}]\\) for the random variable.\n(5) Tower Property : If \\(\\mathcal{H}\\subseteq\\mathcal{G}\\) is another sigma-field of \\(\\Omega\\), then:\n\\[\\begin{aligned}\n\\mathbf{E}[Y|\\mathcal{H}] & =\\mathbf{E}[\\mathbf{E}[Y|\\mathcal{G}]|\\mathcal{H}]\n\\end{aligned}\\]\nThink in terms of two successive projections: first on a plane, then on a line in the plane.\n(6) Pythagoras Theorem. We have:\n\\[\\begin{aligned}\n\\mathbf{E}[Y^{2}] & =\\mathbf{E}\\left[\\left(\\mathbf{E}[Y|\\mathcal{G}]\\right)^{2}\\right]+\\mathbf{E}\\left[\\left(Y-\\mathbf{E}[Y|\\mathcal{G}]\\right)^{2}\\right]\n\\end{aligned}\\]\nIn particular:\n\\[\\begin{aligned}\n\\mathbf{E}\\left[\\left(\\mathbf{E}\\left[Y|\\mathcal{G}\\right]\\right)^{2}\\right] & \\leq\\mathbf{E}[Y^{2}]\n\\end{aligned}\\]\nIn words, the \\(L^{2}\\) norm of \\(\\mathbf{E}[X|\\mathcal{G}]\\) is smaller than the one of \\(X\\), which is clear if you think in terms of orthogonal projection.\n(7) Expectation of the conditional expectation.\n\\[\\begin{aligned}\n\\mathbf{E}\\left[\\mathbf{E}[Y|\\mathcal{G}]\\right] & =\\mathbf{E}[Y]\n\\end{aligned}\\]\n\nProof.\nThe uniqueness property of conditional expectations in theorem ([th:existence-and-uniqueness-of-conditional-expectations-II]) might appear to be an academic curiosity. On the contrary, it is very practical, since it ensures, that if we find a candidate for the conditional expectation that has the two properties in Definition ([def:conditional-expectation]), then it must be the conditional expectation. To see this, let’s prove property (1).\n\nIf \\(Y\\) is \\(\\mathcal{G}\\)-measurable, then \\(\\mathbf{E}[Y|\\mathcal{G}]=Y\\).\nIt suffices to show that \\(Y\\) has the two defining properties of conditional expectation.\n(1) We are given that, \\(Y\\) is \\(\\mathcal{G}\\)-measurable. So, property (A) is satisfied.\n(2) For any bounded random variable \\(W\\) that is \\(\\mathcal{G}\\)-measurable, we have:\n\\[\\begin{aligned}\n\\mathbf{E}[W(Y-Y)] & =\\mathbf{E}[0]=0\n\\end{aligned}\\]\nSo, property (B) is also a triviality.\n\n\n(Taking out what is known.) If \\(Y\\) is \\(\\mathcal{G}\\)-measurable and \\(X\\) is another integrable random variable, then:\n\\[\\begin{aligned}\n\\mathbf{E}[XY|\\mathcal{G}] & =Y\\mathbf{E}[X|\\mathcal{G}]\n\\end{aligned}\\]\nIn a similar vein, it suffices to show that, \\(Y\\mathbf{E}[X|\\mathcal{G}]\\) has the two defining properties of conditional expectation.\n(1) We are given that \\(Y\\) is \\(\\mathcal{G}\\)-measurable; from property (1), \\(\\mathbf{E}[X|\\mathcal{G}]\\) is \\(\\mathcal{G}\\)-measurable. It follows that, \\(Y\\mathbf{E}[X|\\mathcal{G}]\\) is \\(\\mathcal{G}\\)-measurable.\n(2) From theorem ([th:existence-and-uniqueness-of-conditional-expectations-II]), \\(X-\\mathbf{E}[X|\\mathcal{G}]\\) is orthogonal to the random variables \\(L^{2}(\\Omega,\\mathcal{G},\\mathbb{P})\\). So, if \\(W\\) is any bounded \\(\\mathcal{G}\\)-measurable random variable, it follows that:\n\\[\\begin{aligned}\n\\mathbf{E}[WY(X-\\mathbf{E}[X|\\mathcal{G}])] & =0\\\\\n\\implies\\mathbf{E}[W\\cdot XY] & =\\mathbf{E}[WY\\mathbf{E}[X|\\mathcal{G}]]\n\\end{aligned}\\]\nThis closes the proof.\n\n\n(Independence.) If \\(Y\\) is independent of \\(\\mathcal{G}\\), that is, for all events \\(\\{Y\\in(a,b]\\}\\) and \\(A\\in\\mathcal{G}\\),\n\\[\\begin{aligned}\n\\mathbf{\\mathbb{P}}\\{Y\\in(a,b]\\cap A\\} & =\\mathbb{P}\\{Y\\in(a,b]\\}\\cdot\\mathbb{P}(A)\n\\end{aligned}\\]\nthen\n\\[\\begin{aligned}\n\\mathbf{E}[Y|\\mathcal{G}] & =\\mathbf{E}[Y]\n\\end{aligned}\\]\nLet us show that \\(\\mathbf{E}[Y]\\) has the two defining properties of conditional expectations.\n(1) \\(\\mathbf{E}[Y]\\) is a constant and so it is \\(\\mathcal{F}_{0}\\) measurable. Hence, it is \\(\\mathcal{G}\\) measurable.\n(2) If \\(W\\) is another \\(\\mathcal{G}\\)-measurable random variable,\n\\[\\begin{aligned}\n\\mathbf{E}[WY] & =\\mathbf{E}[W]\\cdot\\mathbf{E}[Y]\n\\end{aligned}\\]\nsince \\(Y\\) is independent of \\(\\mathcal{G}\\) and therefore it is independent of \\(Y\\). Hence,\n\\[\\begin{aligned}\n\\mathbf{E}[W(Y-\\mathbf{E}[Y])] & =0\n\\end{aligned}\\]\nConsequently, \\(\\mathbf{E}[Y|\\mathcal{G}]=\\mathbf{E}[Y]\\).\n\n\n(Linearity of conditional expectations) Let \\(X\\) be another integrable random variable on \\((\\Omega,\\mathcal{F},\\mathbb{P})\\). Then,\n\\[\\begin{aligned}\n\\mathbf{E}[aX+bY|\\mathcal{G}] & =a\\mathbf{E}[X|\\mathcal{G}]+b\\mathbf{E}[Y|\\mathcal{G}],\\quad\\text{for any }a,b\\in\\mathbf{R}\n\\end{aligned}\\]\n\nSince \\(\\mathbf{E}[X|\\mathcal{G}]\\) and \\(\\mathbf{E}[Y|\\mathcal{G}]\\) are \\(\\mathcal{G}-\\)measurable, any linear combination of these two random variables is also \\(\\mathcal{G}\\)-measurable.\nAlso, if \\(W\\) is any bounded \\(\\mathcal{G}-\\)measurable random variable, we have:\n\\[\\begin{aligned}\n\\mathbf{E}[W(aX+bY-(a\\mathbf{E}[X|\\mathcal{G}]+b\\mathbf{E}[Y|\\mathcal{G}]))] & =a\\mathbf{E}[W(X-\\mathbf{E}[X|\\mathcal{G}])]\\\\\n& +b\\mathbf{E}[W(Y-\\mathbf{E}[Y|\\mathcal{G}])]\n\\end{aligned}\\]\nBy definition, \\(X-\\mathbf{E}(X|\\mathcal{G})\\) is orthogonal t o the subspace \\(L^{2}(\\Omega,\\mathcal{G},\\mathbb{P})\\) and hence to all \\(\\mathcal{G}\\)-measurable random-variables. Hence, the two expectations on the right hand side of the above expression are \\(0\\). Since, conditional expectations are unique, we have the desired result.\n\nIf \\(\\mathcal{H}\\subseteq\\mathcal{G}\\) is another sigma-field of \\(\\Omega\\), then\n\\[\\begin{aligned}\n\\mathbf{E}[Y|\\mathcal{H}] & =\\mathbf{E}[\\mathbf{E}[Y|\\mathcal{G}]|\\mathcal{H}]\n\\end{aligned}\\]\nDefine \\(U:=\\mathbf{E}[Y|\\mathcal{G}]\\). By definition, \\(\\mathbf{E}[U|\\mathcal{H}]\\) is \\(\\mathcal{H}\\)-measurable.\nLet \\(W\\) be any bounded \\(\\mathcal{H}\\)-measurable random variable. We have:\n\\[\\begin{aligned}\n\\mathbf{E}[W\\{\\mathbf{E}(Y|\\mathcal{G})-\\mathbf{E}(\\mathbf{E}(Y|\\mathcal{G})|\\mathcal{H})\\}] & =\\mathbf{E}[W(U-\\mathbf{E}(U|\\mathcal{H})]\n\\end{aligned}\\]\nBut, by definition \\(U-\\mathbf{E}(U|\\mathcal{H})\\) is always orthogonal to the subspace \\(L^{2}(\\Omega,\\mathcal{H},\\mathbb{P})\\) and hence, \\(\\mathbf{E}[W(U-\\mathbf{\\mathbf{E}}(U|\\mathcal{H})]=0\\). Since, conditional expectations are unique, we have the desired result.\n\n\nPythagoras’s theorem. We have:\n\\[\\begin{aligned}\n\\mathbf{E}[Y^{2}] & =\\mathbf{E}[(\\mathbf{E}[Y|\\mathcal{G}])^{2}]+\\mathbf{E}[(Y-\\mathbf{E}(Y|\\mathcal{G}))^{2}]\n\\end{aligned}\\]\nIn particular,\n\\[\\begin{aligned}\n\\mathbf{E}[(\\mathbf{E}[Y|\\mathcal{G}])^{2}] & \\leq\\mathbf{E}[Y^{2}]\n\\end{aligned}\\]\nConsider the orthogonal decomposition:\n\\[\\begin{aligned}\nY & =\\mathbf{E}[Y|\\mathcal{G}]+(Y-\\mathbf{E}[Y|\\mathcal{G}])\n\\end{aligned}\\]\nSquaring on both sides and taking expectations, we have:\n\\[\\begin{aligned}\n\\mathbf{E}[Y^{2}] & =\\mathbf{E}[(\\mathbf{E}(Y|\\mathcal{G}))^{2}]+\\mathbf{E}[(Y-\\mathbf{E}[Y|\\mathcal{G}])^{2}]+2\\mathbf{E}\\left[\\mathbf{E}[Y|\\mathcal{G}](Y-\\mathbf{E}[Y|\\mathcal{G}])\\right]\n\\end{aligned}\\]\nBy definition of conditional expectation, \\((Y-\\mathbf{E}[Y|\\mathcal{G}])\\) is orthogonal to the subspace \\(L^{2}(\\Omega,\\mathcal{G},\\mathbb{P})\\). By the properties of conditional expectation, \\(\\mathbf{E}[Y|\\mathcal{G}]\\) is \\(\\mathcal{G}-\\)measurable, so it belongs to \\(L^{2}(\\Omega,\\mathcal{G},\\mathbb{P})\\). Hence, the dot-product on the right-hand side is \\(0\\). Consequently, we have the desired result.\nMoreover, since \\((Y-\\mathbf{E}[Y|\\mathcal{G}])^{2}\\) is a non-negative random variable, \\(\\mathbf{E}[(Y-\\mathbf{E}[Y|\\mathcal{G}])^{2}]\\geq0\\). It follows that: \\(\\mathbf{E}[Y^{2}]\\geq\\mathbf{E}[(\\mathbf{E}(Y|\\mathcal{G}))^{2}]\\).\n\n\nOur claim is:\n\\[\\begin{aligned}\n\\mathbf{E}\\left[\\mathbf{E}[Y|\\mathcal{G}]\\right] & =\\mathbf{E}[Y]\n\\end{aligned}\\]\nWe know that, if \\(W\\) is any bounded \\(\\mathcal{G}\\)-measurable random variable:\n\\[\\begin{aligned}\n\\mathbf{E}\\left[WY\\right] & =\\mathbf{E}[W\\mathbf{E}[Y|\\mathcal{G}]]\n\\end{aligned}\\]\nTaking \\(W=1\\), we have:\n\\[\\begin{aligned}\n\\mathbf{E}\\left[Y\\right] & =\\mathbf{E}[\\mathbf{E}[Y|\\mathcal{G}]]\n\\end{aligned}\\]\n\n\n(Brownian Conditioning II). We continue the example ([ex:brownian-conditioning-I]). Let’s now compute the conditional expectations \\(\\mathbf{E}[e^{aB_{1}}|B_{1/2}]\\) and \\(\\mathbf{E}[e^{aB_{1/2}}|B_{1}]\\) for some parameter \\(a\\). We shall need the properties of conditional expectation in proposition ([prop:properties-of-conditional-expectation]). For the first one we use the fact that \\(B_{1/2}\\) is independent of \\(B_{1}-B_{1/2}\\) to get:\n\\[\\begin{aligned}\n\\mathbf{E}[e^{aB_{1}}|B_{1/2}] & =\\mathbf{E}[e^{a((B_{1}-B_{1/2})+B_{1/2})}|B_{1/2}]\\\\\n& =\\mathbf{E}[e^{a(B_{1}-B_{2})}\\cdot e^{aB_{1/2}}|B_{1/2}]\\\\\n& \\quad\\left\\{ \\text{Taking out what is known}\\right\\} \\\\\n& =e^{aB_{1/2}}\\mathbf{E}[e^{a(B_{1}-B_{1/2})}|B_{1/2}]\\\\\n& =e^{aB_{1/2}}\\cdot\\mathbf{E}[e^{a(B_{1}-B_{1/2})}]\\\\\n& \\quad\\{\\text{Independence}\\}\n\\end{aligned}\\]\nWe know that, \\(a(B_{1}-B_{1/2})\\) is a gaussian random variable with mean \\(0\\) and variance \\(a^{2}/2\\). We also know that, \\(\\mathbf{E}[e^{tZ}]=e^{t^{2}/2}\\). So, \\(\\mathbf{E}[e^{a(B_{1}-B_{1/2})}]=e^{a^{2}/4}\\). Consequently, \\(\\mathbf{E}[e^{aB_{1}}|B_{1/2}]=e^{aB_{1/2}+a^{2}/4}\\).\nThe result itself has the form of the MGF of a Gaussian with mean \\(B_{1/2}\\) and variance \\(1/2\\). (The MGF of \\(X=\\mu+\\sigma Z\\), \\(Z=N(0,1)\\) is \\(M_{X}(a)=\\exp\\left[\\mu+\\frac{1}{2}\\sigma^{2}a^{2}\\right]\\).) In fact, this shows that the conditional distribution of \\(B_{1}\\) given \\(B_{1/2}\\) is Gaussian of mean \\(B_{1/2}\\) and variance \\(1/2\\).\nFor the other expectation, note that \\(B_{1/2}-\\frac{1}{2}B_{1}\\) is independent of \\(B_{1}\\). We have: \\[\\begin{aligned}\n\\mathbf{E}\\left[\\left(B_{1/2}-\\frac{1}{2}B_{1}\\right)B_{1}\\right] & =\\mathbf{E}(B_{1/2}B_{1})-\\frac{1}{2}\\mathbf{E}[B_{1}^{2}]\\\\\n& =\\frac{1}{2}-\\frac{1}{2}\\cdot1\\\\\n& =0\n\\end{aligned}\\]\nTherefore, we have:\n\\[\\begin{aligned}\n\\mathbf{E}[e^{aB_{1/2}}|B_{1}] & =\\mathbf{E}[e^{a(B_{1/2}-\\frac{1}{2}B_{1})+\\frac{a}{2}B_{1}}|B_{1}]\\\\\n& =\\mathbf{E}[e^{a(B_{1/2}-\\frac{1}{2}B_{1})}\\cdot e^{\\frac{a}{2}B_{1}}|B_{1}]\\\\\n& =e^{\\frac{a}{2}B_{1}}\\mathbf{E}[e^{a(B_{1/2}-\\frac{1}{2}B_{1})}|B_{1}]\\\\\n& \\quad\\{\\text{Taking out what is known }\\}\\\\\n& =e^{\\frac{a}{2}B_{1}}\\mathbf{E}[e^{a(B_{1/2}-\\frac{1}{2}B_{1})}]\\\\\n& \\quad\\{\\text{Independence}\\}\n\\end{aligned}\\]\nNow, \\(a(B_{1/2}-\\frac{1}{2}B_{1})\\) is a random variable with mean \\(0\\) and variance \\(a^{2}(\\frac{1}{2}-\\frac{1}{4})=\\frac{a^{2}}{4}\\). Consequently, \\(\\mathbf{E}[e^{(a/2)Z}]=e^{\\frac{a^{2}}{8}}\\). Thus, \\(\\mathbf{E}[e^{aB_{1/2}}|B_{1}]=e^{\\frac{a}{2}B_{1}+\\frac{a^{2}}{8}}\\).\n\n\n(Brownian bridge is conditioned Brownian motion). We know that the Brownian bridge \\(M_{t}=B_{t}-tB_{1}\\), \\(t\\in[0,1]\\) is independent of \\(B_{1}\\). We use this to show that the conditional distribution of the Brownian motion given the value at the end-point \\(B_{1}\\) is the one of a Brownian bridge shifted by the straight line going from \\(0\\) to \\(B_{1}\\). To see this, we compute the conditional MGF of \\((B_{t_{1}},B_{t_{2}},\\ldots,B_{t_{n}})\\) given \\(B_{1}\\) for some arbitrary choices of \\(t_{1},t_{2},\\ldots,t_{n}\\) in \\([0,1]\\). We get the following by adding and subtracting \\(t_{j}B_{1}\\):\n\\[\\begin{aligned}\n\\mathbf{E}[e^{a_{1}B_{t_{1}}+\\ldots+a_{n}B_{t_{n}}}|B_{1}] & =\\mathbf{E}[e^{a_{1}(B_{t_{1}}-t_{1}B_{1})+\\ldots+a_{n}(B_{t_{n}}-t_{n}B_{1})}\\cdot e^{(a_{1}t_{1}B_{1}+\\ldots+a_{n}t_{n}B_{1})}|B_{1}]\\\\\n& =e^{(a_{1}t_{1}B_{1}+\\ldots+a_{n}t_{n}B_{1})}\\mathbf{E}[e^{a_{1}M_{t_{1}}+\\ldots+a_{n}M_{t_{n}}}|B_{1}]\\\\\n& \\quad\\{\\text{Taking out what is known}\\}\\\\\n& =e^{(a_{1}t_{1}B_{1}+\\ldots+a_{n}t_{n}B_{1})}\\mathbf{E}[e^{a_{1}M_{t_{1}}+\\ldots+a_{n}M_{t_{n}}}]\\\\\n& \\quad\\{\\text{Independence}\\}\n\\end{aligned}\\]\nThe right side is exactly the MGF of the process \\(M_{t}+tB_{1},t\\in[0,1]\\) (for a fixed value \\(B_{1})\\), where \\((M_{t},t\\in[0,1])\\) is a Brownian bridge. This proves the claim.\n\n\n(Conditional Jensen’s Inequality) If \\(c\\) is a convex function on \\(\\mathbf{R}\\) and \\(X\\) is a random variable on \\((\\Omega,\\mathcal{F},\\mathbb{P})\\), then:\n\\[\\begin{aligned}\n\\mathbf{E}[c(X)] & \\geq c(\\mathbf{E}[X])\n\\end{aligned}\\]\nMore generally, if \\(\\mathcal{G}\\subseteq\\mathcal{F}\\) is a sigma-field, then:\n\\[\\mathbf{E}[c(X)|\\mathcal{G}]\\geq c(\\mathbf{E}[X|\\mathcal{G}])\\]\n\n\nProof. Proof. We know that, if \\(c(x)\\) is a convex function, the tangent to the curve \\(c\\) at any point lies below the curve. The tangent to the cuve at this point, is a straight-line of the form:\n\\[\\begin{aligned}\nc(t)=y & =mt+c\n\\end{aligned}\\]\nwhere \\(m(t)=c'(t)\\). This holds for all \\(t\\in\\mathbf{R}\\). At an arbitrary point \\(x\\) we have:\n\\[\\begin{aligned}\nc(x)\\geq & y=mx+c\n\\end{aligned}\\]\nTherefore, we have:\n\\[\\begin{aligned}\nc(x)-c(t) & \\geq m(t)(x-t)\n\\end{aligned}\\]\nfor any \\(x\\) and any point of tangency \\(t\\).\n\\[\\begin{aligned}\nc(X)-c(Y) & \\geq m(Y)(X-Y)\n\\end{aligned}\\]\nSubstituting \\(Y=\\mathbf{E}[X|\\mathcal{G}]\\), we get:\n\\[\\begin{aligned}\nc(X)-c(\\mathbf{E}[X|\\mathcal{G}]) & \\geq m(\\mathbf{E}[X|\\mathcal{G}])(X-\\mathbf{E}[X|\\mathcal{G}])\n\\end{aligned}\\]\nTaking expectations on both sides, we get:\n\\[\\begin{aligned}\n\\mathbf{E}[(c(X)-c(\\mathbf{E}[X|\\mathcal{G}]))|\\mathcal{G}] & \\geq\\mathbf{E}[m(\\mathbf{E}[X|\\mathcal{G}])(X-\\mathbf{E}[X|\\mathcal{G}])|\\mathcal{G}]\n\\end{aligned}\\]\nThe left-hand side simplifies as:\n\\[\\begin{aligned}\n\\mathbf{E}[(c(X)-c(\\mathbf{E}[X|\\mathcal{G}]))|\\mathcal{G}] & =\\mathbf{E}[c(X)|\\mathcal{G}]-\\mathbf{E}[c(\\mathbf{E}[X|\\mathcal{G}]))|\\mathcal{G}]\\\\\n& \\quad\\{\\text{Linearity}\\}\\\\\n& =\\mathbf{E}[c(X)|\\mathcal{G}]-c(\\mathbf{E}[X|\\mathcal{G}])\\\\\n& \\quad\\{\\text{c(\\ensuremath{\\mathbf{E}}[X|\\ensuremath{\\mathcal{G}}])) is \\ensuremath{\\mathcal{G}}-measurable}\\}\n\\end{aligned}\\]\nOn the right hand side, we have:\n\\[\\begin{aligned}\n\\mathbf{E}[m(\\mathbf{E}[X|\\mathcal{G}])(X-\\mathbf{E}[X|\\mathcal{G}])|\\mathcal{G}] & =\\mathbf{E}[m(\\mathbf{E}[X|\\mathcal{G}])\\cdot X|\\mathcal{G}]-\\mathbf{E}[m(\\mathbf{E}[X|\\mathcal{G}])\\cdot\\mathbf{E}[X|\\mathcal{G}]|\\mathcal{G}]\\\\\n& =\\mathbf{E}[X|\\mathcal{G}]m(\\mathbf{E}[X|\\mathcal{G}])-m(\\mathbf{E}[X|\\mathcal{G}])\\cdot\\mathbf{E}[X|\\mathcal{G}]\\\\\n& =0\n\\end{aligned}\\]\nConsequently, it follows that \\(\\mathbf{E}[c(X)|\\mathcal{G}]\\geq c(\\mathbf{E}[X|\\mathcal{G}])\\). ◻\n\n\n(Embeddings of \\(L^{p}\\) spaces) Square-integrable random variables are in fact integrable. In other words, there is always the inclusion \\(L^{2}(\\Omega,\\mathcal{F},\\mathbb{P})\\subseteq L^{1}(\\Omega,\\mathcal{F},\\mathbb{P})\\). In particular, square integrable random variables always have a well-defined variance. This embedding is a simple consequence of Jensen’s inequality since:\n\\[\\begin{aligned}\n|\\mathbf{E}[X]|^{2} & \\leq\\mathbf{E}[|X|^{2}]\n\\end{aligned}\\]\nas \\(f(x)=|x|^{2}\\) is convex. By taking the square root on both sides, we get:\n\\[\\begin{aligned}\n\\left\\Vert X\\right\\Vert _{1} & \\leq\\left\\Vert X\\right\\Vert _{2}\n\\end{aligned}\\]\nMore generally, for any \\(1&lt;p&lt;\\infty\\), we can define \\(L^{p}(\\Omega,\\mathcal{F},\\mathbb{P})\\) to be the linear space of random variables such that \\(\\mathbf{E}[|X|^{p}]&lt;\\infty\\). Then for \\(p&lt;q\\), since \\(x^{q/p}\\) is convex, we get by Jensen’s inequality :\n\\[\\begin{aligned}\n\\mathbf{E}[|X|^{q}] & =\\mathbf{E}[(|X|^{p})^{\\frac{q}{p}}]\\geq\\left(\\mathbf{E}[|X|^{p}]\\right)^{\\frac{q}{p}}\n\\end{aligned}\\]\nTaking the \\(q\\)-th root on both sides:\n\\[\\begin{aligned}\n\\mathbf{E}[|X|^{p}]^{1/p} & \\leq\\mathbf{E}[|X|^{q}]^{1/q}\n\\end{aligned}\\]\nSo, if \\(X\\in L^{q}\\), then it must also be in \\(L^{p}\\). Concretely, this means that any random variable with a finite \\(q\\)-moment will also have a finite \\(p\\)-moment, for \\(q&gt;p\\).\n\n\n\n\n\nWe now have all the tools to define martingales.\n\n(Filtration). A filtration \\((\\mathcal{F}_{t}:t\\geq0)\\) of \\(\\Omega\\) is an increasing sequence of \\(\\sigma\\)-fields of \\(\\Omega\\). That is,\n\\[\\begin{aligned}\n\\mathcal{F}_{s} & \\subseteq\\mathcal{F}_{t},\\quad\\forall s\\leq t\n\\end{aligned}\\]\nWe will usually take \\(\\mathcal{F}_{0}=\\{\\emptyset,\\Omega\\}\\). The canonical example of a filtration is the natural filtration of a given process \\((M_{s}:s\\geq0)\\). This is the filtration given by \\(\\mathcal{F}_{t}=\\sigma(M_{s},s\\leq t)\\). The inclusions of the \\(\\sigma\\)-fields are then clear. For a given Brownian motion \\((B_{t},t\\geq0)\\), the filtration \\(\\mathcal{F}_{t}=\\sigma(B_{s},s\\leq t)\\) is sometimes called the Brownian filtration. We think of the filtration as the flow of information of the process.\n\n\nA stochastic process \\((X_{t}:t\\geq0)\\) is said to be adapted to \\((\\mathcal{F}_{t}:t\\geq0)\\), if for each \\(t\\), the random variable \\(X_{t}\\) is \\(\\mathcal{F}_{t}-\\)measurable.\n\n\n(Martingale). A process \\((M_{t}:t\\geq0)\\) is a martingale for the filtration \\((\\mathcal{F}_{t}:t\\geq0)\\) if the following hold:\n(1) The process is adapted, that is \\(M_{t}\\) is \\(\\mathcal{F}_{t}-\\)measurable for all \\(t\\geq0\\).\n(2) \\(\\mathbf{E}[|M_{t}|]&lt;\\infty\\) for all \\(t\\geq0\\). (This ensures that the conditional expectation is well defined.)\n(3) Martingale property:\n\\[\\begin{aligned}\n\\mathbf{E}[M_{t}|\\mathcal{F}_{s}] & =M_{s}\\quad\\forall s\\leq t\n\\end{aligned}\\]\nRoughly, speaking this means that the best approximation of a process at a future time \\(t\\) is its value at the present.\n\nIn particular, the martingale property implies that:\n\\[\\begin{aligned}\n\\mathbf{E}[M_{t}|\\mathcal{F}_{0}] & =M_{0}\\nonumber \\\\\n\\mathbf{E}[\\mathbf{E}[M_{t}|\\mathcal{F}_{0}]] & =\\mathbf{E}[M_{0}]\\nonumber \\\\\n\\mathbf{E}[M_{t}] & =\\mathbf{E}[M_{0}]\\label{eq:expected-value-of-martingale-at-any-time-is-constant}\\\\\n& \\quad\\{\\text{Tower Property}\\}\\nonumber\n\\end{aligned}\\]\nUsually, we take \\(\\mathcal{F}_{0}\\) to be the trivial sigma-field \\(\\{\\emptyset,\\Omega\\}\\). A random variable that is \\(\\mathcal{F}_{0}\\)-measurable must be a constant, so \\(M_{0}\\) is a constant. In this case, \\(\\mathbf{E}[M_{t}]=M_{0}\\) for all \\(t\\). If properties (1) and (2) are satisfied, but the best approximation is larger, \\(\\mathbf{E}[M_{t}|\\mathcal{F}_{s}]\\geq M_{s}\\), the process is called a submartingale. If it is smaller on average, \\(\\mathbf{E}[M_{t}|\\mathcal{F}_{s}]\\leq\\mathbf{E}[M_{s}]\\), we say it is a supermartingale.\nWe will be mostly interested in martingales that are continuous and square-integrable. Continuous martingales are martingales whose paths \\(t\\mapsto M_{t}(\\omega)\\) are continuous almost surely. Square-integrable martingales are such that \\(\\mathbf{E}[|M_{t}|^{2}]&lt;\\infty\\) for all \\(t\\)’s. This condition is stronger than \\(\\mathbf{E}[|M_{t}|]&lt;\\infty\\) due to Jensen’s inequality.\n\n(Martingales in Discrete-time). Martingales can be defined the same way if the index set of the process is discrete. For example, the filtration \\((\\mathcal{F}_{n}:n\\in\\mathbf{N})\\) is a countable set and the martingale property is then replaced by \\(\\mathbf{E}[M_{n+1}|\\mathcal{F}_{n}]=M_{n}\\) as expected. The tower-property then yields the martingale property \\(\\mathbf{E}[M_{n+k}|\\mathcal{F}_{n}]=M_{n}\\) for \\(k\\geq1\\).\n\n\n(Continuous Filtrations). Filtrations with continuous time can be tricky to handle rigorously. For example, one has to make sense of what it means for \\(\\mathcal{F}_{s}\\) as \\(s\\) approaches \\(t\\) from the left. Is it equal to \\(\\mathcal{F}_{t}\\)? Or is there actually less information in \\(\\lim_{s\\to t^{-}}\\mathcal{F}_{s}\\) than in \\(\\mathcal{F}_{t}\\)? This is a bit of headache when dealing with processes with jumps, like the Poisson process. However, if the paths are continuous, the technical problems are not as heavy.\nLet’s look at some of the important examples of martingales constructed from Brownian Motion.\n\n\n(Examples of Brownian Martingales)\n(i) Standard Brownian Motion. Let \\((B_{t}:t\\geq0)\\) be a standard Brownian motion and let \\((\\mathcal{F}_{t}:t\\geq0)\\) be a Brownian filtration. Then \\((B_{t}:t\\geq0)\\) is a square integrable martingale for the filtration \\((\\mathcal{F}_{t}:t\\geq0)\\). Property (1) is obvious, because all the sets in \\(\\mathcal{F}_{t}\\) are resolved, upon observing the outcome of \\(B_{t}\\). Similarly, \\(\\mathbf{E}[|B_{t}|]=0\\). As for the martingale property, note that, by the properties of conditional expectation in proposition ([prop:properties-of-conditional-expectation]), we have:\n\\[\\begin{aligned}\n\\mathbf{E}[B_{t}|\\mathcal{F}_{s}] & =\\mathbf{E}[B_{t}|B_{s}]\\\\\n& =\\mathbf{E}[B_{t}-B_{s}+B_{s}|B_{s}]\\\\\n& =\\mathbf{E}[B_{t}-B_{s}|B_{s}]+\\mathbf{E}[B_{s}|B_{s}]\\\\\n& \\quad\\{\\text{Linearity}\\}\\\\\n& =\\mathbf{E}[B_{t}-B_{s}]+B_{s}\\\\\n& \\quad\\{\\text{Independence}\\}\\\\\n& =B_{s}\n\\end{aligned}\\]\n(ii) Geometric Brownian Motion. Let \\((B_{t},t\\ge0)\\) be a standard brownian motion, and \\(\\mathcal{F}_{t}=\\sigma(B_{s},s\\leq t)\\). A geometric brownian motion is a process \\((S_{t},t\\geq0)\\) defined by:\n\\[\\begin{aligned}\nS_{t} & =S_{0}\\exp\\left(\\sigma B_{t}+\\mu t\\right)\n\\end{aligned}\\]\nfor some parameter \\(\\sigma&gt;0\\) and \\(\\mu\\in\\mathbf{R}\\). This is simply the exponential of the Brownian motion with drift. This is not a martingale for most choices of \\(\\mu\\)! In fact, one must take\n\\[\\begin{aligned}\n\\mu & =-\\frac{1}{2}\\sigma^{2}\n\\end{aligned}\\] for the process to be a martingale for the Brownian filtration. Let’s verify this. Property (1) is obvious since \\(S_{t}\\) is a function of \\(B_{t}\\) for each \\(t\\). So, it is \\(\\mathcal{F}_{t}\\) measurable. Moreover, property (2) is clear: \\(\\mathbf{E}[\\exp(\\sigma B_{t}+\\mu t)]=\\mathbf{E}[\\exp(\\sigma\\sqrt{t}Z+\\mu t)]=\\exp(\\mu t+\\frac{1}{2}\\sigma^{2}t)\\). So, its a finite quantity. As for the martingale property, note that by the properties of conditional expectation, and the MGF of Gaussians, we have for \\(s\\leq t\\):\n\\[\\begin{aligned}\n\\mathbf{E}[S_{t}|\\mathcal{F}_{s}] & =\\mathbf{E}\\left[S_{0}\\exp\\left(\\sigma B_{t}-\\frac{1}{2}\\sigma^{2}t\\right)|\\mathcal{F}_{s}\\right]\\\\\n& =S_{0}\\exp(-\\frac{1}{2}\\sigma^{2}t)\\mathbf{E}[\\exp(\\sigma(B_{t}-B_{s}+B_{s}))|\\mathcal{F}_{s}]\\\\\n& =S_{0}\\exp(-\\frac{1}{2}\\sigma^{2}t)\\exp(\\sigma B_{s})\\mathbf{E}[\\exp(\\sigma(B_{t}-B_{s}))|\\mathcal{F}_{s}]\\\\\n& \\quad\\{\\text{Taking out what is known}\\}\\\\\n& =S_{0}\\exp\\left(\\sigma B_{s}-\\frac{1}{2}\\sigma^{2}t\\right)\\mathbf{E}\\left[\\exp\\left(\\sigma(B_{t}-B_{s})\\right)\\right]\\\\\n& \\quad\\{\\text{Independence}\\}\\\\\n& =S_{0}\\exp\\left(\\sigma B_{s}-\\frac{1}{2}\\sigma^{2}t+\\frac{1}{2}\\sigma^{2}(t-s)\\right)\\\\\n& =S_{0}\\exp(\\sigma B_{s}-\\frac{1}{2}\\sigma^{2}s)\\\\\n& =S_{s}\n\\end{aligned}\\]\nWe will sometimes abuse terminology and refer to the martingale case of geometric brownian motion simply as geometric Brownian Motion when the context is clear.\n(iii) The square of the Brownian motion, compensated. It is easy to check \\((B_{t}^{2},t\\geq0)\\) is a submartingale by direct computation using increments or by Jensen’s inequality: \\(\\mathbf{E}[B_{t}^{2}|\\mathcal{F}_{s}]&gt;(\\mathbf{E}[B_{t}|\\mathcal{F}_{s}])^{2}=B_{s}^{2}\\), \\(s&lt;t\\). It is nevertheless possible to compensate to get a martingale:\n\\[\\begin{aligned}\nM_{t} & =B_{t}^{2}-t\n\\end{aligned}\\]\nIt is an easy exercise to verify that \\((M_{t}:t\\geq0)\\) is a martingale for the Brownian filtration \\((\\mathcal{F}_{t}:t\\geq0)\\).\n\\[\\begin{aligned}\n\\mathbf{E}[M_{t}|\\mathcal{F}_{s}] & =\\mathbf{E}[B_{t}^{2}-t|\\mathcal{F}_{s}]\\\\\n& =\\mathbf{E}[B_{t}^{2}|\\mathcal{F}_{s}]-t\\\\\n& =\\mathbf{E}[(B_{t}-B_{s}+B_{s})^{2}|\\mathcal{F}_{s}]-t\\\\\n& =\\mathbf{E}[(B_{t}-B_{s})^{2}|\\mathcal{F}_{s}]+2\\mathbf{E}[(B_{t}-B_{s})B_{s}|\\mathcal{F}_{s}]+\\mathbf{E}[B_{s}^{2}|\\mathcal{F}_{s}]-t\\\\\n& =\\mathbf{E}[(B_{t}-B_{s})^{2}]+2B_{s}\\mathbf{E}[(B_{t}-B_{s})|\\mathcal{F}_{s}]+B_{s}^{2}-t\\\\\n& =\\mathbf{E}[(B_{t}-B_{s})^{2}]+2B_{s}\\mathbf{E}[(B_{t}-B_{s})]+B_{s}^{2}-t\\\\\n& \\left\\{ \\begin{array}{c}\n\\text{\\ensuremath{(B_{t}-B_{s})} is independent of \\ensuremath{\\mathcal{F}_{s}}}\\\\\n\\text{Also, \\ensuremath{B_{s}} is known at time \\ensuremath{s}}\n\\end{array}\\right\\} \\\\\n& =(t-s)+2B_{s}\\cdot0+B_{s}^{2}-t\\\\\n& =B_{s}^{2}-s\\\\\n& =M_{s}\n\\end{aligned}\\]\n\n\n(Other important martingales).\n(1) Symmetric random walks. This is an example of a martingale in discrete time. Take \\((X_{i}:i\\in\\mathbf{N})\\) to be IID random variables with \\(\\mathbf{E}[X_{i}]=0\\) and \\(\\mathbf{E}[|X_{i}|]&lt;\\infty\\). Take \\(\\mathcal{F}_{n}=\\sigma(X_{i},i\\leq n)\\) and\n\\[\\begin{aligned}\nS_{n} & =X_{1}+X_{2}+\\ldots+X_{n},\\quad S_{0}=0\n\\end{aligned}\\]\nFirstly, the information learned by observing the outcomes of \\(X_{1}\\),\\(\\ldots\\),\\(X_{n}\\) is enough to completely determine \\(S_{n}\\). Hence, \\(S_{n}\\) is \\(\\mathcal{F}_{n}-\\)measurable.\nNext, \\[\\begin{aligned}\n|S_{n}| & =\\left|\\sum_{i=1}^{n}X_{i}\\right|\\\\\n& \\leq\\sum_{i=1}^{n}|X_{i}|\n\\end{aligned}\\]\nConsequently, by the montonocity of expectations, we have:\n\\[\\begin{aligned}\n\\mathbf{E}[|S_{n}|] & \\leq\\sum_{i=1}^{n}\\mathbf{E}[|X_{i}|]&lt;\\infty\n\\end{aligned}\\]\nThe martingale property is also satisfied. We have:\n\\[\\begin{aligned}\n\\mathbf{E}[S_{n+1}|\\mathcal{F}_{n}] & =\\mathbf{E}[S_{n}+X_{n+1}|\\mathcal{F}_{n}]\\\\\n& =\\mathbf{E}[S_{n}|\\mathcal{F}_{n}]+\\mathbf{E}[X_{n+1}|\\mathcal{F}_{n}]\\\\\n& =S_{n}+\\mathbf{E}[X_{n+1}]\\\\\n& \\left\\{ \\begin{array}{c}\n\\text{\\ensuremath{S_{n}} is \\ensuremath{\\mathcal{F}_{n}}-measurable}\\\\\n\\text{\\ensuremath{X_{n+1}} is independent of \\ensuremath{\\mathcal{F}_{n}}}\n\\end{array}\\right\\} \\\\\n& =S_{n}+0\\\\\n& =S_{n}\n\\end{aligned}\\]\n(2) Compensated Poisson process. Let \\((N_{t}:t\\geq0)\\) be a Poisson process with rate \\(\\lambda\\) and \\(\\mathcal{F}_{t}=\\sigma(N_{s},s\\leq t)\\). Then, \\(N_{t}\\) is a submartingale for its natural filtration. Again, properties (1) and (2) are easily checked. \\(N_{t}\\) is \\(\\mathcal{F}_{t}\\) measurable. Moreover, \\(\\mathbf{E}[|N_{t}|]=\\mathbf{E}[N_{t}]=\\frac{1}{\\lambda t}&lt;\\infty\\). The submartingale property follows by the independence of increments : for \\(s\\leq t\\),\n\\[\\begin{aligned}\n\\mathbf{E}[N_{t}|\\mathcal{F}_{s}] & =\\mathbf{E}[N_{t}-N_{s}+N_{s}|\\mathcal{F}_{s}]\\\\\n& =\\mathbf{E}[N_{t}-N_{s}|\\mathcal{F}_{s}]+\\mathbf{E}[N_{s}|\\mathcal{F}_{s}]\\\\\n& =\\mathbf{E}[N_{t}-N_{s}]+N_{s}\\\\\n& =\\lambda(t-s)+N_{s}\\\\\n& \\left\\{ \\because\\mathbf{E}[N_{t}]=\\lambda t\\right\\}\n\\end{aligned}\\]\nMore importantly, we get a martingale by slightly modifying the process. Indeed, if we subtract \\(\\lambda t\\), we have that the process :\n\\[\\begin{aligned}\nM_{t} & =N_{t}-\\lambda t\n\\end{aligned}\\]\nis a martingale. We have:\n\\[\\begin{aligned}\n\\mathbf{E}[M_{t}|\\mathcal{F}_{s}] & =\\mathbf{E}[N_{t}-\\lambda t|\\mathcal{F}_{s}]\\\\\n& =\\lambda t-\\lambda s+N_{s}-\\lambda t\\\\\n& =N_{s}-\\lambda s\\\\\n& =M_{s}\n\\end{aligned}\\]\nThis is called the compensated Poisson process. Let us simulate \\(10\\) paths of the compensated poisson process on \\([0,10]\\).\n\nimport numpy as np\nimport matplotlib.pyplot as plt\n\n# Generates a sample path of a compensated poisson process \n# with rate : `lambda_` per unit time\n# on the interval [0,T], and subintervals of size `stepSize`.\n\ndef generateCompensatedPoissonPath(lambda_,T,stepSize):\n    N = int(T/stepSize)   \n\n    poissonParam = lambda_ * stepSize        \n\n    x = np.random.poisson(lam=poissonParam,size=N)  \n    x = np.concatenate([[0.0], x])\n    N_t = np.cumsum(x)  \n    t = np.linspace(start=0.0,stop=10.0,num=1001)\n\n    M_t = np.subtract(N_t,lambda_ * t)  \n    return M_t\n\n\nt = np.linspace(0,10,1001)\nplt.grid(True)\n\nplt.xlabel(r'Time $t$')\nplt.ylabel(r'Compensated poisson process $M(t)$')\nplt.grid(True)\nplt.title(r'$10$ paths of the compensated Poisson process on $[0,10]$')\n\nfor i in range(10):\n    # Generate a poisson path with rate 1 /sec = 0.01 /millisec\n    n_t = generateCompensatedPoissonPath(lambda_=1.0, T=10, stepSize=0.01)\n    plt.plot(t, n_t)\n\n\nplt.show()\nplt.close()\nWe saw in the two examples, that, even though a process is not itself a martingale, we can sometimes compensate to obtain a martingale! Ito Calculus will greatly extend this perspective. We will have systematic rules that show when a function of Brownian motion is a martingale and if not, how to modify it to get one.\nFor now, we observe that a convex function of a martingale is always a submartingale by Jensen’s inequality.\n\nIf \\(c\\) is a convex function on \\(\\mathbf{R}\\) and \\((M_{t}:t\\geq0)\\) is a martingale for \\((\\mathcal{F}_{t}:t\\geq0)\\), then the process \\((c(M_{t}):t\\geq0)\\) is a submartingale for the same filtration, granted that \\(\\mathbf{E}[|c(M_{t})|]&lt;\\infty\\).\n\n\nProof. Proof. The fact that \\(c(M_{t})\\) is adapted to the filtration is clear since it is an explicit function of \\(M_{t}\\). The integrability is by assumption. The submartingale property is checked as follows:\n\\[\\begin{aligned}\n\\mathbf{E}[c(M_{t})|\\mathcal{F}_{s}] & \\geq c(\\mathbf{E}[M_{t}|\\mathcal{F}_{s}])=c(M_{s})\n\\end{aligned}\\] ◻\n\n\n(The Doob-Meyer Decomposition Theorem). Let \\((X_{n}:n\\in\\mathbf{N})\\) be a submartingale with respect to a filtration \\((\\mathcal{F}_{n}:n\\in\\mathbf{N})\\). Define a sequence of random variables \\((A_{n}:n\\in\\mathbf{N})\\) by \\(A_{0}=0\\) and\n\\[\\begin{aligned}\nA_{n} & =\\sum_{i=1}^{n}(\\mathbf{E}[X_{i}|\\mathcal{F}_{i-1}]-X_{i-1}),\\quad n\\geq1\n\\end{aligned}\\]\nNote that \\(A_{n}\\) is \\(\\mathcal{F}_{n-1}\\)-measurable. Moreover, since \\((X_{n}:n\\in\\mathbf{N})\\) is a submartingale, we have \\(\\mathbf{E}[X_{i}|\\mathcal{F}_{i-1}]-X_{i-1}\\geq0\\) almost surely. Hence, \\((A_{n}:n\\in\\mathbf{N})\\) is an increasing sequence almost surely. Let \\(M_{n}=X_{n}-A_{n}\\).\nWe have:\n\\[\\begin{aligned}\n\\mathbf{E}[M_{n}|\\mathcal{F}_{n-1}] & =\\mathbf{E}[X_{n}-A_{n}|\\mathcal{F}_{n-1}]\\\\\n& =\\mathbf{E}[X_{n}|\\mathcal{F}_{n-1}]-\\mathbf{E}[A_{n}|\\mathcal{F}_{n-1}]\\\\\n& =\\mathbf{E}[X_{n}|\\mathcal{F}_{n-1}]-\\mathbf{E}\\left[\\left.\\mathbf{E}[X_{n}|\\mathcal{F}_{n-1}]-X_{n-1}+A_{n-1}\\right|\\mathcal{F}_{n-1}\\right]\\\\\n& =\\mathbf{E}[X_{n}|\\mathcal{F}_{n-1}]-\\mathbf{E}[X_{n}|\\mathcal{F}_{n-1}]+\\mathbf{E}[X_{n-1}|\\mathcal{F}_{n-1}]-\\mathbf{E}[A_{n-1}|\\mathcal{F}_{n-1}]\\\\\n& =\\cancel{\\mathbf{E}[X_{n}|\\mathcal{F}_{n-1}]}-\\cancel{\\mathbf{E}[X_{n}|\\mathcal{F}_{n-1}]}+X_{n-1}-A_{n-1}\\\\\n& =M_{n-1}\n\\end{aligned}\\]\nThus, \\((M_{n}:n\\in\\mathbf{N})\\) is a martingale. Thus, we have obtained the Doob decomposition:\n\\[\\begin{aligned}\nX_{n} & =M_{n}+A_{n}\\label{eq:doob-decomposition}\n\\end{aligned}\\]\nThis decomposition of a submartingale as a sum of a martingale and an adapted increasing sequence is unique, if we require that \\(A_{0}=0\\) and that \\(A_{n}\\) is \\(\\mathcal{F}_{n-1}\\)-measurable.\nFor the continuous-time case, the situation is much more complicated. The analogue of equation ([eq:doob-decomposition]) is called the Doob-Meyer decomposition. We briefly describe this decomposition and avoid the technical details. All stochastic processes \\(X(t)\\) are assumed to be right-continuous with left-hand limits \\(X(t-)\\).\nLet \\(X(t)\\), \\(a\\leq t\\leq b\\) be a submartingale with respect to a right-continuous filtration \\((\\mathcal{F}_{t}:a\\leq t\\leq b)\\). If \\(X(t)\\) satisfies certain conditions, then it can be uniquely decomposed as:\n\\[\\begin{aligned}\nX(t) & =M(t)+C(t),\\quad a\\leq t\\leq b\n\\end{aligned}\\]\nwhere \\(M(t)\\), \\(a\\leq t\\leq b\\) is a martingale with respect to \\((\\mathcal{F}_{t};a\\leq t\\leq b)\\), \\(C(t)\\) is right-continuous and increasing almost surely with \\(\\mathbf{E}[C(t)]&lt;\\infty\\).\n\n\n(Square of a Poisson Process). Let \\((N_{t}:t\\geq0)\\) be a Poisson process with rate \\(\\lambda\\). We consider the compensated process \\(M_{t}=N_{t}-\\lambda t\\). By ([corollary:the-convex-function-of-martingale-is-a-submartingale]), the process \\((M_{t}^{2}:t\\geq0)\\) is a submartingale for the filtration \\((\\mathcal{F}_{t}:t\\geq0)\\) of the Poisson process. How should we compensated \\(M_{t}^{2}\\) to get a martingale? A direct computation using the properties of conditional expectation yields:\n\\[\\begin{aligned}\n\\mathbf{E}[M_{t}^{2}|\\mathcal{F}_{s}] & =\\mathbf{E}[(M_{t}-M_{s}+M_{s})^{2}|\\mathcal{F}_{s}]\\\\\n& =\\mathbf{E}[(M_{t}-M_{s})^{2}+2(M_{t}-M_{s})M_{s}+M_{s}^{2}|\\mathcal{F}_{s}]\\\\\n& =\\mathbf{E}[(M_{t}-M_{s})^{2}|\\mathcal{F}_{s}]+2\\mathbf{E}[(M_{t}-M_{s})M_{s}|\\mathcal{F}_{s}]+\\mathbf{E}[M_{s}^{2}|\\mathcal{F}_{s}]\\\\\n& =\\mathbf{E}[(M_{t}-M_{s})^{2}]+2M_{s}\\underbrace{\\mathbf{E}[M_{t}-M_{s}]}_{\\text{equals \\ensuremath{0}}}+M_{s}^{2}\\\\\n& =\\mathbf{E}[(M_{t}-M_{s})^{2}]+M_{s}^{2}\n\\end{aligned}\\]\nNow, if \\(X\\sim\\text{Poisson\\ensuremath{(\\lambda t)}}\\), then \\(\\mathbf{E}[X]=\\lambda t\\) and \\(\\mathbf{E}\\ensuremath{[X^{2}]}=\\lambda t(\\lambda t+1)\\).\n\\[\\begin{aligned}\n\\mathbf{E}[(M_{t}-M_{s})^{2}] & =\\mathbf{E}\\left[\\left\\{ (N_{t}-N_{s})-\\lambda(t-s)\\right\\} ^{2}\\right]\\\\\n& =\\mathbf{E}\\left[(N_{t}-N_{s})^{2}\\right]-2\\lambda(t-s)\\mathbf{E}\\left[(N_{t}-N_{s})\\right]+\\lambda^{2}(t-s)^{2}\\\\\n& =\\lambda^{2}(t-s)^{2}+\\lambda(t-s)-2\\lambda(t-s)\\cdot\\lambda(t-s)+\\lambda^{2}(t-s)^{2}\\\\\n& =\\lambda(t-s)\n\\end{aligned}\\]\nThus,\n\\[\\begin{aligned}\n\\mathbf{E}[M_{t}^{2}-\\lambda t|\\mathcal{F}_{s}] & =M_{s}^{2}-\\lambda s\n\\end{aligned}\\]\nWe conclude that the process \\((M_{t}^{2}-\\lambda t:t\\geq0)\\) is a martingale. The Doob-Meyer decomposition of the submartingale \\(M_{t}^{2}\\) is then:\n\\[\\begin{aligned}\nM_{t}^{2} & =(M_{t}^{2}-\\lambda t)+\\lambda t\n\\end{aligned}\\]\n\n\nConsider a Brownian motion \\(B(t)\\). The quadratic variation of the process \\((B(t):t\\geq0)\\) over the interval \\([0,t]\\) is given by \\([B]_{t}=t\\). On the other hand, we saw, that the square of Brownian motion compensated, \\((B_{t}^{2}-t:t\\geq0)\\) is a martingale. Hence, the Doob-Meyer decomposition of \\(B(t)^{2}\\) is given by:\n\\[\\begin{aligned}\nB(t)^{2} & =(B(t)^{2}-t)+t\n\\end{aligned}\\]\n\n\n\n\nMartingales are not only conceptually interesting, they are also formidable tools to compute probabilities and expectations of processes. For example, in this section, we will solve the gambler’s ruin problem for Brownian motion. For convenience, we introduce the notion of stopping time before doing so.\n\n\n\nDefinition 1 (Stopping Time.) A random variable \\(\\tau:\\Omega\\to\\mathbf{N}\\cup\\{+\\infty\\}\\) is said to be a stopping time for the filtration \\((\\mathcal{F}_{t}:t\\geq0)\\) if and only if:\n\\[\\begin{aligned}\n\\{\\omega:\\tau(\\omega)\\leq t\\} & \\in\\mathcal{F}_{t},\\quad\\forall t\\geq0\n\\end{aligned}\\] Note that since \\(\\mathcal{F}_{t}\\) is a sigma-field, if \\(\\tau\\) is a stopping time, then we must also have that \\(\\{\\omega:\\tau(\\omega)&gt;t\\}\\in\\mathcal{F}_{t}\\).\nIn other words, \\(\\tau\\) is a stopping time, if we can decide if the events \\(\\{\\tau\\leq t\\}\\) occurred or not based on the information available at time \\(t\\).\nThe term stopping time comes from gambling: a gambler can decide to stop playing at a random time (depending for example on previous gains or losses), but when he or she decides to stop, his/her decision is based solely upon the knowledge of what happened before, and does not depend on future outcomes. In other words, the stopping policy/strategy can only depend on past outcomes. Otherwise, it would mean that he/she has a crystall ball.\n\n\n(Examples of stopping times).\n(i) First passage time. This is the first time when a process reaches a certain value. To be precise, let \\(X=(X_{t}:t\\geq0)\\) be a process and \\((\\mathcal{F}_{t}:t\\geq0)\\) be its natural filtration. For \\(a&gt;0\\), we define the first passage time at \\(a\\) to be:\n\\[\\begin{aligned}\n\\tau(\\omega) & =\\inf\\{s\\geq0:X_{s}(\\omega)\\geq a\\}\n\\end{aligned}\\]\nIf the path \\(\\omega\\) never reaches \\(a\\), we set \\(\\tau(\\omega)=\\infty\\). Now, for \\(t\\) fixed and for a given path \\(X(\\omega)\\), it is possible to know if \\(\\{\\tau(\\omega)\\leq t\\}\\) (the path has reached \\(a\\) before time \\(t\\)) or \\(\\{\\tau(\\omega)&gt;t\\}\\) (the path has not reached \\(a\\) before time \\(t\\)) with the information available at time \\(t\\), since we are looking at the first time the process reaches \\(a\\). Hence, we conclude that \\(\\tau\\) is a stopping time.\n(ii) Hitting time. More generally, we can consider the first time (if ever) that the path of a process \\((X_{t}:t\\geq0)\\) enters or hits a subset \\(B\\) of \\(\\mathbf{R}\\):\n\\[\\begin{aligned}\n\\tau(\\omega) & =\\min\\{s\\geq0:X_{s}(\\omega)\\in B\\}\n\\end{aligned}\\]\nThe first passage time is the particular case in which \\(B=[a,\\infty)\\).\n(iii) Minimum of two stopping times. If \\(\\tau\\) and \\(\\tau'\\) are two stopping times for the same filtration \\((\\mathcal{F}_{t}:t\\geq0)\\), then so is the minimum \\(\\tau\\land\\tau'\\) between the two, where\n\\[\\begin{aligned}\n(\\tau\\land\\tau')(\\omega) & =\\min\\{\\tau(\\omega),\\tau'(\\omega)\\}\n\\end{aligned}\\]\nThis is because for any \\(t\\geq0\\):\n\\[\\begin{aligned}\n\\{\\omega: & (\\tau\\land\\tau')(\\omega)\\leq t\\}=\\{\\omega:\\tau(\\omega)\\leq t\\}\\cup\\{\\omega:\\tau'(\\omega)\\leq t\\}\n\\end{aligned}\\]\nSince the right hand side is the union of two events in \\(\\mathcal{F}_{t}\\), it must also be in \\(\\mathcal{F}_{t}\\) by the properties of a sigma-field. We conclude that \\(\\tau\\land\\tau'\\) is a stopping time. Is it also the case that the maximum \\(\\tau\\lor\\tau'\\) is a stopping time?\nFor any fixed \\(t\\geq0\\), we have:\n\\[\\begin{aligned}\n\\{\\omega:(\\tau\\lor\\tau')(\\omega)\\leq t\\} & =\\{\\omega:\\tau(\\omega)\\leq t\\}\\cap\\{\\omega:\\tau'(\\omega)\\leq t\\}\n\\end{aligned}\\]\nSince the right hand side is the intersection of two events in \\(\\mathcal{F}_{t}\\), it must also be in \\(\\mathcal{F}_{t}\\) by the properties of a sigma-field. We conclude that \\(\\tau\\lor\\tau'\\) is a stopping time.\n\n\n(Last passage time is not a stopping time). What if we look at the last time the process reaches \\(a\\), that is:\n\\[\\begin{aligned}\n\\rho(\\omega) & =\\sup\\{t\\geq0:X_{t}(\\omega)\\geq a\\}\n\\end{aligned}\\]\nThis is a well-defined random variable, but it is not a stopping time. Based on the information available at time \\(t\\), we are not able to decide whether or not \\(\\{\\rho(\\omega)\\leq t\\}\\) occurred or not, as the path can always reach \\(a\\) one more time after \\(t\\).\n\nIt turns out that a martingale that is stopped when the stopping time is attained remains a martingale.\n\nProposition 1 (Stopped Martingale.) If \\((M_{t}:t\\geq0)\\) is a continuous martingale for the filtration \\((\\mathcal{F}_{t}:t\\geq0)\\) and \\(\\tau\\) is a stopping time for the same filtration, then the stopped process defined by\n\\[\\begin{aligned}\nM_{t\\land\\tau} & =\\begin{cases}\nM_{t} & t\\leq\\tau\\\\\nM_{\\tau} & t&gt;\\tau\n\\end{cases}\n\\end{aligned}\\]\nis also a continuous martingale for the same filtration.\n\nProof.\nLet \\((M_n,n=0,1,2,\\ldots)\\) be a martingale for the filtration \\((\\mathcal{F}_n,n\\geq 0)\\). Let \\(\\tau\\) be a stopping time for the same filtration and consider the martingale transform with the process:\n\\[\nX_n(\\omega) = \\begin{cases}\n1 & \\quad \\text{ if } n &lt; \\tau(\\omega) \\\\\n0   & \\quad \\text{ if } n \\geq \\tau(\\omega)\n\\end{cases}\n\\]\nThen, the stopped martingale \\((M_{t \\land \\tau},t\\geq 0)\\) can be written as an a martingale transform of the process \\((X_n)_{n=0}^{\\infty}\\).\n\\[\nM = \\sum_{j=0}^{n-1} X_j (M_{j+1} - M_j)\n\\]\nfor all \\(n=0,1,2,\\ldots\\). Invoking the property martingale transforms are continuous martingales, we have that \\(M_t = \\int X_t dM_t\\) must be a continous martingale. Consequently, the stopped process \\((M_{t \\land \\tau}, t\\geq 0)\\) must be a martingale. \\(\\blacksquare\\)\n\nTheorem 1 (Doob’s Optional Stopping Theorem.) If \\((M_{t}:t\\geq0)\\) is a continuous martingale for the filtration \\((\\mathcal{F}_{t}:t\\geq0)\\) and \\(\\tau\\) is a stopping time such that \\(\\tau&lt;\\infty\\) and the stopped process \\((M_{t\\land\\tau}:t\\geq0)\\) is bounded, then:\n\\[\\begin{aligned}\n\\mathbf{E}[M_{\\tau}] & =M_{0}\n\\end{aligned}\\]\n\nProof. Since \\((M_{\\tau\\land t}:t\\geq0)\\) is a martingale, we always have:\n\\[\\begin{aligned}\n\\mathbf{E}[M_{\\tau\\land t}] & =M_{0}\n\\end{aligned}\\]\nNow, since \\(\\tau(\\omega)&lt;\\infty\\), we must\nhave that \\(\\lim_{t\\to\\infty}M_{\\tau\\land t}=M_{\\tau}\\) almost surely. In particular, we have:\n\\[\\begin{aligned}\n\\mathbf{E}[M_{\\tau}] & =\\mathbf{E}\\left[\\lim_{t\\to\\infty}M_{\\tau\\land t}\\right]=\\lim_{t\\to\\infty}\\mathbf{E}[M_{\\tau\\land t}]=\\lim_{t\\to\\infty}M_{0}\n\\end{aligned}\\]\nwhere we passed to the limit, using the dominated convergence theorem. Recall, that the dominated convergence theorem allows us to commute abstract integration \\(\\int\\) and \\(\\lim_{n \\to \\infty}\\).\n\\(\\lim_{n \\to \\infty} \\int f_n = \\lim_{n \\to \\infty} \\int f_n\\) as long as the \\(f_n\\)’s are dominated. \\(\\blacksquare\\)\n\n\n\nThe gambler’s ruin problem is known in different forms. Roughly speaking, it refers to the problem of computing the probability of a gambler making a series of bets reaching a certain amount before going broke. In terms of Brownian motion (and stochastic processes in general), it translates to the following questions: Let \\((B_{t}:t\\geq0)\\) be a standard brownian motion starting at \\(B_{0}=0\\) and \\(a,b&gt;0\\).\n(1) What is the probability that a Brownian path reaches \\(a\\) before \\(-b\\)?\n(2) What is the expected waiting time for the path to reach \\(a\\) or \\(-b\\)?\nFor the first question, it is a simple computation using stopping time and martingale properties. Define the hitting time:\n\\[\\begin{aligned}\n\\tau(\\omega) & =\\inf\\{t\\geq0:B_{t}(\\omega)\\geq a\\text{ or }B_{t}(\\omega)\\leq-b\\}\n\\end{aligned}\\]\nNote that \\(\\tau\\) is the minimum between the first passage time at \\(a\\) and the one at \\(-b\\).\nWe first show that \\(\\tau&lt;\\infty\\) almost surely. In other words, all Brownian paths reach \\(a\\) or \\(-b\\) eventually. To see this, consider the event \\(E_{n}\\) that the \\(n\\)-th increment exceeds \\(a+b\\)\n\\[\\begin{aligned}\nE_{n} & :=\\left\\{ |B_{n}-B_{n-1}|&gt;a+b\\right\\}\n\\end{aligned}\\]\nNote that, if \\(E_{n}\\) occurs, then we must have that the Brownian motion path exits the interval \\([-b,a].\\) Moreover, we have \\(\\mathbb{P}(E_{n})=\\mathbb{P}(E_{1})\\) for all \\(n\\). Call this probability \\(p\\).\nSince the events \\(E_{n}\\) are independent, we have:\n\\[\\begin{aligned}\n\\mathbb{P}(E_{1}^{C}\\cap E_{2}^{C}\\cap\\ldots\\cap E_{n}^{C}) & =(1-p)^{n}\n\\end{aligned}\\]\nAs \\(n\\to\\infty\\) we have:\n\\[\\begin{aligned}\n\\lim_{n\\to\\infty}\\mathbb{P}(E_{1}^{C}\\cap E_{2}^{C}\\cap\\ldots\\cap E_{n}^{C}) & =0\n\\end{aligned}\\]\nThe sequence of events \\((F_{n})\\) where \\(F_{n}=E_{1}^{C}\\cap E_{2}^{C}\\cap\\ldots\\cap E_{n}^{C}\\) is a decreasing sequence of events. By the continuity of probability measure lemma, we conclude that:\n\\[\\begin{aligned}\n\\lim_{n\\to\\infty}\\mathbb{P}\\left(F_{n}\\right) & =\\mathbb{P}\\left(\\bigcap_{n=1}^{\\infty}F_{n}\\right)=0\n\\end{aligned}\\]\nTherefore, it must be the case \\(\\mathbb{P}(\\cup_{n=1}^{\\infty}E_{n})=1\\). So, \\(E_{n}\\) must occur for some \\(n\\), so all brownian motion paths reach \\(a\\) or \\(-b\\) almost surely.\nSince \\(\\tau&lt;\\infty\\) with probability one, the random variable \\(B_{\\tau}\\) is well-defined : \\(B_{\\tau}(\\omega)=B_{t}(\\omega)\\) if \\(\\tau(\\omega)=t\\). It can only take two values: \\(a\\) or \\(-b\\). Question (1) above translates into computing \\(\\mathbb{P}(B_{\\tau}=a)\\). On one hand, we have:\n\\[\\begin{aligned}\n\\mathbf{E}[B_{\\tau}] & =a\\mathbb{P}(B_{\\tau}=a)+(-b)(1-\\mathbb{P}(B_{\\tau}=a))\n\\end{aligned}\\]\nOn the other hand, by Doob’s optional stopping theorem (Theorem 1), we have \\(\\mathbf{E}[B_{\\tau}]=\\mathbf{E}[B_{0}]=0\\). (Note that the stopped process \\((B_{t\\land\\tau}:t\\geq0)\\) is bounded above by \\(a\\) and by \\(-b\\) below). Putting these two observations together, we get:\n\\[\\begin{aligned}\n\\mathbb{P}(B_{\\tau}=a) & =\\frac{b}{a+b}\n\\end{aligned}\\]\nA very simple and elegant answer!\nWe will revisit this problem again and again. In particular, we will answer the question above for Brownian motion with a drift at length further ahead.\n\n\nExample 1 (Expected Waiting Time.) Let \\(\\tau\\) be as in the last example. We now answer question (2) of the gambler’s ruin problem:\n\\[\\begin{aligned}\n\\mathbf{E}[\\tau] & =ab\n\\end{aligned}\\]\nNote that the expected waiting time is consistent with the rough heuristic that Brownian motion travels a distance \\(\\sqrt{t}\\) by time \\(t\\). We now use the martingale \\(M_{t}=B_{t}^{2}-t\\). On the one hand, if we apply optional stopping Theorem 1, we get:\n\\[\\begin{aligned}\n\\mathbf{E}[M_{\\tau}] & =M_{0}=0\n\\end{aligned}\\]\nMoreover, we know the distribution of \\(B_{\\tau}\\), thanks to the probability calculated in the last example. We can therefore compute \\(\\mathbf{E}[M_{\\tau}]\\) directly:\n\\[\\begin{aligned}\n0 & =\\mathbf{E}[M_{\\tau}]\\\\\n& =\\mathbf{E}[B_{\\tau}^{2}-\\tau]\\\\\n& =\\mathbf{E}[B_{\\tau}^{2}]-\\mathbf{E}[\\tau]\\\\\n& =a^{2}\\cdot\\frac{b}{a+b}+b^{2}\\cdot\\frac{a}{a+b}-\\mathbf{E}[\\tau]\\\\\n\\mathbf{E}[\\tau] & =\\frac{a^{2}b+b^{2}a}{a+b}\\\\\n& =\\frac{ab\\cancel{(a+b)}}{\\cancel{(a+b)}}=ab\n\\end{aligned}\\]\nWhy can we apply optional stopping here? The random variable \\(\\tau\\) is finite with probability \\(1\\) as before. However, the stopped martingale is not necessarily bounded as before: \\(B_{\\tau\\land t}\\) is bounded but \\(\\tau\\) is not. However, the conclusion of optional stopping still holds. Indeed, we have:\n\\[\\begin{aligned}\n\\mathbf{E}[M_{t\\land\\tau}] & =\\mathbf{E}[B_{t\\land\\tau}^{2}]-\\mathbf{E}[t\\land\\tau]\n\\end{aligned}\\]\nBy the bounded convergence theorem, we get \\(\\lim_{t\\to\\infty}\\mathbf{E}[B_{t\\land\\tau}^{2}]=\\mathbf{E}[\\lim_{t\\to\\infty}B_{t\\land\\tau}^{2}]=\\mathbf{E}[B_{\\tau}^{2}]\\). Since \\(\\tau\\land t\\) is a non-decreasing sequence and as \\(t\\to\\infty\\), \\(t\\land\\tau\\to\\tau\\) almost surely, as \\(\\tau&lt;\\infty\\), by the monotone convergence theorem, \\(\\lim_{t\\to\\infty}\\mathbf{E}[t\\land\\tau]=\\mathbf{E}[\\tau]\\).\n\n\nExample 2 (First passage time of Brownian Motion.) We can use the previous two examples to get some very interesting information on the first passage time:\n\\[\\begin{aligned}\n\\tau_{a} & =\\inf\\{t\\geq0:B_{t}\\geq a\\}\n\\end{aligned}\\]\nLet \\(\\tau=\\tau_{a}\\land\\tau_{-b}\\) be as in the previous examples with \\(\\tau_{-b}=\\inf\\{t\\geq0:B_{t}\\leq-b\\}\\). Note that \\((\\tau_{-b},b\\in\\mathbf{R}_{+})\\) is a sequence of random variables that is increasing in \\(b\\). A brownian motion path must cross through \\(-1\\) before it hits \\(-2\\) for the first time and in general \\(\\tau_{-n}(\\omega)\\leq\\tau_{-(n+1)}(\\omega)\\). Moreover, we have \\(\\tau_{-b}\\to\\infty\\) almost surely as \\(b\\to\\infty\\). That’s because, \\(\\mathbb{P}\\{\\tau&lt;\\infty\\}=1\\). Moreover, the event \\(\\{B_{\\tau}=a\\}\\) is the same as \\(\\{\\tau_{a}&lt;\\tau_{-b}\\}\\). Now, the events \\(\\{\\tau_{a}&lt;\\tau_{-b}\\}\\) are increasing in \\(b\\), since if a path reaches \\(a\\) before \\(-b\\), it will do so as well for a more negative value of \\(-b\\). On one hand, this means by the continuity of probability measure lemma ([th:continuity-property-of-lebesgue-measure]) that:\n\\[\\begin{aligned}\n\\lim_{b\\to\\infty}\\mathbb{P}\\left\\{ \\tau_{a}&lt;\\tau_{-b}\\right\\}  & =\\mathbb{P}\\{\\lim_{b\\to\\infty}\\tau_{a}&lt;\\tau_{-b}\\}\\\\\n& =\\mathbb{P}\\{\\tau_{a}&lt;\\infty\\}\n\\end{aligned}\\]\nOn the other hand, we have by example ([example:probability-of-hitting-times])\n\\[\\begin{aligned}\n\\lim_{b\\to\\infty}\\mathbb{P}\\left\\{ \\tau_{a}&lt;\\tau_{-b}\\right\\}  & =\\lim_{b\\to\\infty}\\mathbb{P}\\{B_{\\tau}=a\\}\\\\\n& =\\lim_{b\\to\\infty}\\frac{b}{b+a}\\\\\n& =1\n\\end{aligned}\\]\nWe just showed that:\n\\[\\begin{aligned}\n\\mathbb{P}\\left\\{ \\tau_{a}&lt;\\infty\\right\\}  & =1\\label{eq:first-passage-time-to-a-is-finite-almost-surely}\n\\end{aligned}\\]\nIn other words, every Brownian path will reach \\(a\\), no matter how large \\(a\\) is!\nHow long will it take to reach \\(a\\) on average? Well, we know from example ([ex:expected-waiting-times]) that \\(\\mathbf{E}[\\tau_{a}\\land\\tau_{-b}]=ab\\). On one hand this means,\n\\[\\begin{aligned}\n\\lim_{b\\to\\infty}\\mathbf{E}[\\tau_{a}\\land\\tau_{-b}] & =\\lim_{b\\to\\infty}ab=\\infty\n\\end{aligned}\\]\nOn the other hand, since the random variables \\(\\tau_{-b}\\) are increasing,\n\\[\\begin{aligned}\n\\lim_{b\\to\\infty}\\mathbf{E}[\\tau_{a}\\land\\tau_{-b}] & =\\mathbf{E}\\left[\\lim_{b\\to\\infty}\\tau_{a}\\land\\tau_{-b}\\right]=\\mathbf{E}[\\tau_{a}]\n\\end{aligned}\\]\nby the monotone convergence theorem ([th:monotone-convergence-theorem]). We just proved that:\n\\[\\begin{aligned}\n\\mathbf{E}[\\tau_{a}] & =\\infty\n\\end{aligned}\\]\nIn other words, any Brownian motion path will reach \\(a\\), but the expected waiting time for this to occur is infinite, no matter, how small \\(a\\) is! What is happening here? No matter, how small \\(a\\) is, there is always paths that reach very large negative values before hitting \\(a\\). These paths might be unlikely. However, the first passage time for these paths is so large that they affect the value of the expectation substantially. In other words, \\(\\tau_{a}\\) is a heavy-tailed random variable. We look at the distribution of \\(\\tau_{a}\\) in more detail in the next section.\n\n\n(When option stopping fails). Consider \\(\\tau_{a}\\), the first passage time at \\(a&gt;0\\). The random variable \\(B_{\\tau_{a}}\\) is well-defined since \\(\\tau_{a}&lt;\\infty\\). In fact, we have \\(B_{\\tau_{a}}=a\\) with probability one. Therefore, the following must hold:\n\\[\\begin{aligned}\n\\mathbf{E}[B_{\\tau_{a}}] & =a\\neq B_{0}\n\\end{aligned}\\]\nOptional stopping theorem corollary ([th:doob's-optional-sampling-theorem]) does not apply here, since the stopped process \\((B_{t\\land\\tau_{a}}:t\\geq0)\\) is not bounded. \\(B_{t\\land\\tau_{a}}\\) can become infinitely negative before hitting \\(a\\).\n\n\n\n\n\n(Bachelier’s formula). Let \\((B_{t}:t\\leq T)\\) be a standard brownian motion on \\([0,T].\\) Then, the CDF of the random variable \\(\\sup_{0\\leq t\\leq T}B_{t}\\) is:\n\\[\\begin{aligned}\n\\mathbb{P}\\left(\\sup_{0\\leq t\\leq T}B_{t}\\leq a\\right) & =\\mathbb{P}\\left(|B_{T}|\\leq a\\right)\n\\end{aligned}\\]\nIn particular, its PDF is:\n\\[\\begin{aligned}\nf_{\\max}(a) & =\\frac{2}{\\sqrt{2\\pi T}}e^{-\\frac{a^{2}}{2T}}\n\\end{aligned}\\]\n\n\nWe can verify these results empirically. Note that the paths of the random variables \\(\\max_{0\\leq s\\leq t}B_{s}\\) and \\(|B_{t}|\\) are very different as \\(t\\) varies for a given \\(\\omega\\). One is increasing and the other is not. The equality holds in distribution for a fixed \\(t\\). As a bonus corollary, we get the distribution of the first passage time at \\(a\\).\n\n\nLet \\(a\\geq0\\) and \\(\\tau_{a}=\\inf\\{t\\geq0:B_{t}\\geq a\\}\\). Then:\n\\[\\begin{aligned}\n\\mathbb{P}\\left(\\tau_{a}\\leq T\\right) & =\\mathbb{P}\\left(\\max_{0\\leq t\\leq T}B_{t}\\geq a\\right)=\\int_{a}^{\\infty}\\frac{2}{\\sqrt{2\\pi T}}e^{-\\frac{x^{2}}{2T}}dx\n\\end{aligned}\\]\nIn particular, the random variable \\(\\tau_{a}\\) has the PDF:\n\\[\\begin{aligned}\nf_{\\tau_{a}}(t) & =\\frac{a}{\\sqrt{2\\pi}}\\frac{e^{-\\frac{a^{2}}{2t}}}{t^{3/2}},\\quad t&gt;0\n\\end{aligned}\\]\nThis implies that it is heavy-tailed with \\(\\mathbf{E}[\\tau_{a}]=\\infty\\).\n\n\nProof. Proof. The maximum on \\([0,T]\\) is larger than or equal to \\(a\\) if and only if \\(\\tau_{a}\\leq T\\). Therefore, the events \\(\\{\\max_{0\\leq t\\leq T}B_{t}\\geq a\\}\\) and \\(\\{\\tau_{a}\\leq T\\}\\) are the same. So, the CDF \\(\\mathbb{P}(\\tau_{a}\\leq t)\\) of \\(\\tau_{a}\\), by proposition ([prop:bacheliers-formula]) \\(\\int_{a}^{\\infty}f_{\\max}(x)dx=\\int_{a}^{\\infty}\\frac{2}{\\sqrt{2\\pi T}}e^{-\\frac{x^{2}}{2T}}dx\\).\n\\[\\begin{aligned}\nf_{\\tau_{a}}(t) & =-2\\phi(a/\\sqrt{t})\\cdot a\\cdot\\left(-\\frac{1}{2t^{3/2}}\\right)\\\\\n& =\\frac{a}{t^{3/2}}\\phi\\left(\\frac{a}{\\sqrt{t}}\\right)\\\\\n& =\\frac{a}{t^{3/2}}\\cdot\\frac{1}{\\sqrt{2\\pi}}e^{-\\frac{a^{2}}{2t}}\n\\end{aligned}\\]\nTo estimate the expectation, it suffices to realize that for \\(t\\geq1\\), \\(e^{-\\frac{a^{2}}{2t}}\\) is larger than \\(e^{-\\frac{a^{2}}{2}}\\). Therefore, we have:\n\\[\\begin{aligned}\n\\mathbf{E}[\\tau_{a}] & =\\int_{0}^{\\infty}t\\frac{a}{\\sqrt{2\\pi}}\\frac{e^{-a^{2}/2t}}{t^{3/2}}dt\\geq\\frac{ae^{-a^{2}/2}}{\\sqrt{2\\pi}}\\int_{1}^{\\infty}t^{-1/2}dt\n\\end{aligned}\\]\nThis is an improper integral and it diverges like \\(\\sqrt{t}\\) and is infinite as claimed. ◻\n\nTo prove proposition ([prop:bacheliers-formula]), we will need an important property of Brownian motion called the reflection principle. To motivate it, recall the reflection symmetry of Brownian motion at time \\(s\\) in proposition ([prop:brownian-motion-symmetry-of-reflection-at-time-s]). It turns out that this reflection property also holds if \\(s\\) is replaced by a stopping time.\n\n(Reflection principle). Let \\((B_{t}:t\\geq0)\\) be a standard Brownian motion and let \\(\\tau\\) be a stopping time for its filtration. Then, the process \\((\\tilde{B}_{t}:t\\geq0)\\) defined by the reflection at time \\(\\tau\\):\n\\[\\begin{aligned}\n\\tilde{B}_{t} & =\\begin{cases}\nB_{t} & \\text{if \\ensuremath{t\\leq\\tau}}\\\\\nB_{\\tau}-(B_{t}-B_{\\tau}) & \\text{if \\ensuremath{t&gt;\\tau}}\n\\end{cases}\n\\end{aligned}\\]\nis also a standard brownian motion.\n\n\nWe defer the proof of the reflection property of Brownian motion to a further section. It is intuitive and instructive to quickly picture this in the discrete-time setting. I adopt the approach as in Shreve-I.\nWe repeatedly toss a fair coin (\\(p\\), the probability of \\(H\\) on each toss, and \\(q=1-p\\), the probability of \\(T\\) on each toss, are both equal to \\(\\frac{1}{2}\\)). We denote the successive outcomes of the tosses by \\(\\omega_{1}\\omega_{2}\\omega_{3}\\ldots\\). Let\n\\[\\begin{aligned}\nX_{j} & =\\begin{cases}\n-1 & \\text{if \\ensuremath{\\omega_{j}=H}}\\\\\n+1 & \\text{if \\ensuremath{\\omega_{j}=T}}\n\\end{cases}\n\\end{aligned}\\]\nand define \\(M_{0}=0\\), \\(M_{n}=\\sum_{j=1}^{n}X_{n}\\). The process \\((M_{n}:n\\in\\mathbf{N})\\) is a symmetric random walk.\nSuppose we toss a coin an odd number \\((2j-1)\\) of times. Some of the paths will reach level \\(1\\) in the first \\(2j-1\\) steps and other will not reach. In the case of \\(3\\) tosses, there are \\(2^{3}=8\\) possible paths and \\(5\\) of these reach level \\(1\\) at some time \\(\\tau_{1}\\leq2j-1\\). From that moment on, we can create a reflected path, which steps up each time the original path steps down and steps down each time the original path steps up. If the original path ends above \\(1\\) at the final time \\(2j-1\\), the reflected path ends below \\(1\\) and vice versa. If the original path ends at \\(1\\), the reflected path does also. In fact, the reflection at the first hitting time has the same distribution as the original random walk.\nThe key here is, out of the \\(5\\) paths that reach level \\(1\\) at some time, there are as many reflected paths that exceed \\(1\\) at time \\((2j-1)\\) as there are original paths that exceed \\(1\\) at time \\((2j-1)\\). So, to count the total number of paths that reach level \\(1\\) by time \\((2j-1)\\), we can count the paths that are at \\(1\\) at time \\((2j-1)\\) and then add on twice the number of paths that exceed \\(1\\) at time \\((2j-1)\\).\n\nWith this new tool, we can now prove proposition ([prop:bacheliers-formula]).\n\nProof. Proof. Consider \\(\\mathbb{P}(\\max_{t\\leq T}B_{t}\\geq a)\\). By splitting this probability over the event of the endpoint, we have:\n\\[\\begin{aligned}\n\\mathbb{P}\\left(\\max_{t\\leq T}B_{t}\\geq a\\right) & =\\mathbb{P}\\left(\\max_{t\\leq T}B_{t}\\geq a,B_{T}&gt;a\\right)+\\mathbb{P}\\left(\\max_{t\\leq T}B_{t}\\geq a,B_{T}\\leq a\\right)\n\\end{aligned}\\]\nNote also, that \\(\\mathbb{P}(B_{T}=a)=0\\). Hence, the first probability equals \\(\\mathbb{P}(B_{T}\\geq a)\\). As for the second, consider the time \\(\\tau_{a}\\). On the event considered, we have \\(\\tau_{a}\\leq T\\) and using lemma ([lemma:BM-reflection-principle]) at that time, we get\n\\[\\begin{aligned}\n\\mathbb{P}\\left(\\max_{t\\leq T}B_{t}\\geq a,B_{T}\\leq a\\right) & =\\mathbb{P}\\left(\\max_{t\\leq T}B_{t}\\geq a,\\tilde{B}_{T}\\geq a\\right)\n\\end{aligned}\\]\nObserve that the event \\(\\{\\max_{t\\leq T}B_{t}\\geq a\\}\\) is the same as \\(\\{\\max_{t\\leq T}\\tilde{B}_{T}\\geq a\\}\\). (A rough picture might help here.) Thereforem the above probability is\n\\[\\begin{aligned}\n\\mathbb{P}\\left(\\max_{t\\leq T}B_{t}\\geq a,B_{T}\\leq a\\right) & =\\mathbb{P}\\left(\\max_{t\\leq T}\\tilde{B}_{t}\\geq a,\\tilde{B}_{T}\\geq a\\right)=\\mathbb{P}\\left(\\max_{t\\leq T}B_{t}\\geq a,B_{T}\\geq a\\right)\n\\end{aligned}\\]\nwhere the last equality follows from the reflection principle (\\(\\tilde{B}_{t}\\) is also a standard brownian motion, and \\(B_{T}\\) and \\(\\tilde{B}_{T}\\) have the same distribution.) But, as above, the last probability is equal to \\(\\mathbb{P}(B_{T}\\geq a)\\). We conclude that:\n\\[\\begin{aligned}\n\\mathbb{P}\\left(\\max_{t\\leq T}B_{t}\\geq a\\right) & =2\\mathbb{P}(B_{T}\\geq a)=\\frac{2}{\\sqrt{2\\pi T}}\\int_{a}^{\\infty}e^{-\\frac{x^{2}}{2T}}dx=\\mathbb{P}(|B_{T}|\\geq a)\n\\end{aligned}\\]\nThis implies in particular that \\(\\mathbb{P}\\left(\\max_{t\\leq T}B_{t}=a\\right)=0\\). Thus, we also have \\(\\mathbb{P}(\\max_{t\\leq T}B_{t}\\leq a)=\\mathbb{P}(|B_{T}|\\leq a)\\) as claimed. ◻\n\n\n\n\n\n(Simulating Martingales) Sample \\(10\\) paths of the following process with a step-size of \\(0.01\\):\n(a) \\(B_{t}^{2}-t\\), \\(t\\in[0,1]\\)\n(b) Geometric Brownian motion : \\(S_{t}=\\exp(B_{t}-t/2)\\), \\(t\\in[0,1]\\).\nLet’s write a simple \\(\\texttt{BrownianMotion}\\) class, that we shall use to generate sample paths.\n\n\nimport numpy as np\nimport matplotlib.pyplot as plt\n\nimport attrs\nfrom attrs import define, field\n\n@define\nclass BrownianMotion:\n    _step_size = field(validator=attrs.validators.and_(attrs.validators.instance_of(float),\n                                                       attrs.validators.ge(0.0)))\n    # Time T\n    _T = field(validator=attrs.validators.and_(attrs.validators.instance_of(float),\n                                               attrs.validators.ge(0.0)))\n    # number of paths\n    _N = field(validator=attrs.validators.and_(attrs.validators.instance_of(int),\n                                               attrs.validators.gt(0)))\n\n    _num_steps = field(init=False)\n\n    def __attrs_post_init__(self):\n        self._num_steps = int(self._T/self._step_size)\n\n    def covariance_matrix(self):\n        C = np.zeros((self._num_steps,self._num_steps))\n\n        for i in range(self._num_steps):\n            for j in range(self._num_steps):\n                s = (i+1) * self._step_size\n                t = (j+1) * self._step_size\n                C[i,j] = min(s,t)\n        return C\n\n    # Each column vector represents a sample path\n    def generate_paths(self):\n        C = self.covariance_matrix()\n        A = np.linalg.cholesky(C)\n        Z = np.random.standard_normal((self._num_steps, self._N))\n        X = np.matmul(A,Z)\n        X = np.concatenate((np.zeros((1,self._N)),X),axis=0)\n        return X.transpose()\n\nNow, the process \\(B_{t}^{2}-t\\) can be sampled as follows:\n\ndef generateSquareOfBMCompensated(numOfPaths,stepSize,T):\n    N = int(T/stepSize)\n\n    X = []\n    brownianMotion = BrownianMotion(stepSize,T)\n    for n in range(numOfPaths):\n\n        B_t = brownianMotion.samplePath()\n\n        B_t_sq = np.square(B_t)\n\n        t = np.linspace(start=0.0,stop=1.0,num=N+1)\n        M_t = np.subtract(B_t_sq,t)\n        X.append(M_t)\n\n    return X\nThe gBM process can be sampled similarly, with \\(\\texttt{\\ensuremath{M_{t}} = np.exp(np.subtract(\\ensuremath{B_{t}},t/2))}\\).\n\n(Maximum of Brownian Motion.) Consider the maximum of Brownian motion on \\([0,1]\\): \\(\\max_{s\\leq1}B_{s}\\).\n(a) Draw the histogram of the random variable \\(\\max_{s\\leq1}B_{s}\\)using \\(10,0000\\) sampled Brownian paths with a step size of \\(0.01\\).\n(b) Compare this to the PDF of the random variable \\(|B_{1}|\\).\n\nSolution.\nI use the \\(\\texttt{itertools}\\) python library to compute the running maximum of a brownian motion path.\n\nbrownianMotion = BrownianMotion(stepSize=0.01,T=1)\ndata = []\n\nfor i in range(10000):\n    B_t = brownianMotion.samplePath()\n    max_B_t = list(itertools.accumulate(B_t,max))\n    data.append(max_B_t[100])\nAnalytically, we know that \\(B_{1}\\) is a gaussian random variable with mean \\(0\\) and variance \\(1\\).\n\\[\\begin{aligned}\n\\mathbb{P}(|B_{1}|\\leq z) & =\\mathbb{P}(|Z|\\leq z)\\\\\n& =\\mathbb{P}(-z\\leq Z\\leq z)\\\\\n& =\\mathbb{P}(Z\\leq z)-\\mathbb{P}(Z\\leq-z)\\\\\n& =\\mathbb{P}(Z\\leq z)-(1-\\mathbb{P}(Z\\leq z))\\\\\nF_{|B_{1}|}(z) & =2\\Phi(z)-1\n\\end{aligned}\\]\nDifferentiating on both sides, we get:\n\\[\\begin{aligned}\nf_{|B_{1}|}(z) & =2\\phi(z)=\\frac{2}{\\sqrt{2\\pi}}e^{-\\frac{z^{2}}{2}},\\quad z\\in[0,\\infty)\n\\end{aligned}\\]\n\n(First passage time.) Let \\((B_{t}:t\\geq0)\\) be a standard brownian motion. Consider the random variable:\n\\[\\begin{aligned}\n\\tau & =\\min\\{t\\geq0:B_{t}\\geq1\\}\n\\end{aligned}\\]\nThis is the first time that \\(B_{t}\\) reaches \\(1\\).\n(a) Draw a histogram for the distribution of \\(\\tau\\land10\\) on the time-interval \\([0,10]\\) using \\(10,000\\) brownian motion paths on \\([0,10]\\) with discretization \\(0.01\\).\nThe notation \\(\\tau\\land10\\) means that if the path does not reach \\(1\\) on \\([0,10]\\), then give the value \\(10\\) to the stopping time.\n(b) Estimate \\(\\mathbf{E}[\\tau\\land10]\\).\n(c) What proportion of paths never reach \\(1\\) in the time interval \\([0,10]\\)?\n\nSolution.\nTo compute the expectation, we classify the hitting times of all paths into \\(50\\) bins. I simply did\n\\(\\texttt{frequency, bins = np.histogram(firstPassageTimes,bins=50,range=(0,10))}\\)\nand then computed\n\\(\\texttt{expectation=np.dot(frequency,bins[1:])/10000}\\).\nThis expectation estimate on my machine is \\(\\mathbf{E}[\\tau\\land10]=4.34\\) secs. There were approximately \\(2600\\) paths out of \\(10,000\\) that did not reach \\(1\\).\n\n\n\n\nExample 3 (Doob’s maximal inequalities.) We prove the following: Let \\((M_{k}:k\\geq1)\\) be positive submartingale for the filtration \\((\\mathcal{F}_{k}:k\\in\\mathbf{N})\\). Then, for any \\(1\\leq p&lt;\\infty\\) and \\(a&gt;0\\)\n\\[\\begin{aligned}\n\\mathbb{P}\\left(\\max_{k\\leq n}M_{k}&gt;a\\right) & \\leq\\frac{1}{a^{p}}\\mathbf{E}[M_{n}^{p}]\n\\end{aligned}\\]\n(a) Use Jensen’s inequality to show that if \\((M_{k}:k\\geq1)\\) is a positive submartingale, then so is \\((M_{k}^{p}:k\\geq1)\\) for \\(1\\leq p&lt;\\infty\\). Conclude that it suffices to prove the statement for \\(p=1\\).\n\nSolution.\nThe function \\(f(x)=x^{p}\\) is convex. By conditional Jensen’s inequality,\n\\[\\begin{aligned}\n\\left(\\mathbf{E}[M_{k+1}|\\mathcal{F}_{k}]\\right)^{p} & \\leq\\mathbf{E}[M_{k}^{p}|\\mathcal{F}_{k}]\n\\end{aligned}\\]\nThus,\n\\[\\begin{aligned}\n\\mathbf{E}[M_{k+1}^{p}|\\mathcal{F}_{k}] & \\geq\\left(\\mathbf{E}[M_{k+1}|\\mathcal{F}_{k}]\\right)^{p}\\geq M_{k}^{p}\n\\end{aligned}\\]\nwhere the last inequality follows from the fact that \\((M_{k}:k\\geq1)\\) is a positive submartingale, so \\(\\mathbf{E}[M_{k+1}|\\mathcal{F}_{k}]\\geq M_{k}\\). Consequently, \\((M_{k}^{p}:k\\geq1)\\) is also a positive submartingale.\n(b) Consider the events\n\\[\\begin{aligned}\nB_{k} & =\\bigcap_{j&lt;k}\\{\\omega:M_{j}(\\omega)\\leq a\\}\\cap\\{\\omega:M_{k}(\\omega)&gt;a\\}\n\\end{aligned}\\]\nArgue that the \\(B_{k}\\)’s are disjoint and that \\(\\bigcup_{k\\leq n}B_{k}=\\{\\max_{k\\leq n}M_{k}&gt;a\\}=B\\).\nSolution.\nClearly, \\(B_{k}\\) is the event that the first time to cross \\(a\\) is \\(k\\). If \\(B_{k}\\) occurs, \\(B_{k+1},B_{k+2},\\ldots\\) fail to occur. Hence, all \\(B_{k}'s\\) are pairwise disjoint. The event \\(\\bigcup_{k\\leq n}B_{k}\\) is the event that the random walk crosses \\(a\\) at any time \\(k\\leq n\\). Thus, the running maximum of the Brownian motion at time \\(n\\) exceeds \\(a\\).\n(c) Show that\n\\[\\begin{aligned}\n\\mathbf{E}[M_{n}]\\geq\\mathbf{E}[M_{n}\\mathbf{1}_{B}] & \\geq a\\sum_{k\\leq n}\\mathbb{P}(B_{k})=a\\mathbb{P}(B)\n\\end{aligned}\\]\nby decomposing \\(B\\) in \\(B_{k}\\)’s and by using the properties of expectations, as well as the submartingale property.\nSolution.\nClearly, \\(M_{n}\\geq M_{n}\\mathbf{1}_{B}\\geq a\\mathbf{1}_{B}\\). And \\(M_{n}\\) is a positive random variable. By monotonicity of expectations, \\(\\mathbf{E}[M_{n}]\\geq\\mathbf{E}[M_{n}\\mathbf{1}_{B}]\\geq a\\mathbf{E}[\\mathbf{1}_{B}]=a\\mathbb{P}(B)=a\\sum_{k\\leq n}\\mathbb{P}(B_{k})\\), where the last equality holds because the \\(B_{k}\\)’s are disjoint.\n(d) Argue that the inequality holds for continuous paths by discretizing time and using convergence theorems : If \\((M_{t}:t\\geq0)\\) is a positive submartingale with continuous paths for the filtration \\((\\mathcal{F}_{t}:t\\geq0)\\), then for any \\(1\\leq p&lt;\\infty\\) and \\(a&gt;0\\):\n\\[\\begin{aligned}\n\\mathbb{P}\\left(\\max_{s\\leq t}M_{s}&gt;a\\right) & \\leq\\frac{1}{a^{p}}\\mathbf{E}[M_{t}^{p}]\n\\end{aligned}\\]\nSolution.\nLet \\((M_{t}:t\\geq0)\\) be a positive submartingale with continuous paths for the filtration \\((\\mathcal{F}_{t}:t\\geq0)\\). Consider a sequence of partitions of the interval \\([0,t]\\) into \\(2^{r}\\) subintervals :\n\\[\\begin{aligned}\nD_{r} & =\\left\\{ \\frac{kt}{2^{r}}:k=0,1,2,\\ldots,2^{n}\\right\\}\n\\end{aligned}\\]\nAnd consider a sequence of discrete positive sub-martingales:\n\\[\\begin{aligned}\nM_{kt/2^{r}}^{(r)} & =M_{kt/2^{r}},\\quad k\\in\\mathbf{N},0\\leq k\\leq2^{r}\n\\end{aligned}\\]\nNext, we define for \\(r=1,2,3,\\ldots\\)\n\\[\\begin{aligned}\nA_{r} & =\\left\\{ \\sup_{s\\in D_{r}}|M_{s}^{(r)}|&gt;a\\right\\}\n\\end{aligned}\\]\nBy using the maximal inequality in discrete time, gives us:\n\\[\\begin{aligned}\n\\mathbb{P}(A_{r})=\\mathbb{P}\\left\\{ \\sup_{s\\in D_{r}}|M_{s}^{(r)}|&gt;a\\right\\}  & \\leq\\frac{1}{a^{p}}\\mathbf{E}\\left[\\left(M_{s}^{(r)}\\right)^{p}\\right]=\\frac{1}{a^{p}}\\mathbf{E}\\left[M_{t}^{p}\\right]\n\\end{aligned}\\]\n\\[\\begin{aligned}\n\\mathbb{P}\\left(\\max_{s\\leq t}M_{s}&gt;a\\right) & =\\mathbb{P}\\left(\\bigcup_{r=1}^{\\infty}A_{r}\\right)\\\\\n& =\\lim_{r\\to\\infty}\\mathbb{P}\\left(A_{r}\\right)\\\\\n& \\left\\{ \\text{Continuity of probability measure}\\right\\} \\\\\n& \\leq\\lim_{r\\to\\infty}\\frac{1}{a^{p}}\\mathbf{E}\\left[M_{t}^{p}\\right]\n\\end{aligned}\\]\n\nExample 4 Let \\((S_n,n=0,1,2,\\ldots)\\) be a simple random walk starting at \\(S_0 = 100\\) with \\(S_n = S_0 + X_1 + X_2 + \\ldots + X_n\\), where \\(P(X_i = 1) = p\\) and \\(P(X_i = -1) = q = 1 - p\\).\n\nProve that \\(M_n = \\left(\\frac{q}{p}\\right)^{S_n}\\) is a martingale.\nLet \\(\\tau = \\min\\{n \\geq 0 : S_n = 200 \\text{ or } S_n = 0\\}\\). Prove that \\(\\mathbb{E}[\\tau] &lt; \\infty\\).\nFind \\(P(S_\\tau = 200)\\).\n\n\nProof.\n\nClearly, \\((S_n, n=0,1,2,\\ldots)\\) is a martingale. For we have:\n\n\\[\n\\begin{align*}\n\\mathbb{E}\\left[\\left.\\frac{M_{n+1}}{M_n}\\right|\\mathcal{F}_n\\right] &= \\mathbb{E}\\left[\\left.\\left(\\frac{q}{p}\\right)\\right|\\mathcal{F}_n\\right]\\\\\n&= p\\frac{q}{p} + q \\frac{p}{q}\\\\\n&=1\n\\end{align*}\n\\]\nMultiplying both sides by \\(M_n\\), we have the desired result:\n\\[\n\\mathbb{E}[M_{n+1} | \\mathcal{F}_n] = M_n\n\\]"
  },
  {
    "objectID": "posts/martingales/index.html#elementary-conditional-expectation.",
    "href": "posts/martingales/index.html#elementary-conditional-expectation.",
    "title": "Martingales",
    "section": "",
    "text": "In elementary probability, the conditional expectation of a variable \\(Y\\) given another random variable \\(X\\) refers to the expectation of \\(Y\\) given the conditional distribution \\(f_{Y|X}(y|x)\\) of \\(Y\\) given \\(X\\). To illustrate this, let’s go through a simple example. Consider \\(\\mathcal{B}_{1}\\), \\(\\mathcal{B}_{2}\\) to be two independent Bernoulli-distributed random variables with \\(p=1/2\\). Then, construct:\n\\[\\begin{aligned}\nX=\\mathcal{B}_{1}, & \\quad Y=\\mathcal{B}_{1}+\\mathcal{B}_{2}\n\\end{aligned}\\]\nIt is easy to compute \\(\\mathbb{E}[Y|X=0]\\) and \\(\\mathbb{E}[Y|X=1]\\). By definition, it is given by:\n\\[\\begin{aligned}\n\\mathbb{E}[Y|X=0] & =\\sum_{j=0}^{2}j\\mathbb{P}(Y=j|X=0)\\\\\n& =\\sum_{j=0}^{2}j\\cdot\\frac{\\mathbb{P}(Y=j,X=0)}{P(X=0)}\\\\\n& =0+1\\cdot\\frac{(1/4)}{(1/2)}+2\\cdot\\frac{0}{(1/2)}\\\\\n& =\\frac{1}{2}\n\\end{aligned}\\]\nand\n\\[\\begin{aligned}\n\\mathbb{E}[Y|X=1] & =\\sum_{j=0}^{2}j\\mathbb{P}(Y=j|X=1)\\\\\n& =\\sum_{j=0}^{2}j\\cdot\\frac{\\mathbb{P}(Y=j,X=1)}{P(X=1)}\\\\\n& =0+1\\cdot\\frac{(1/4)}{(1/2)}+2\\cdot\\frac{(1/4)}{(1/2)}\\\\\n& =\\frac{3}{2}\n\\end{aligned}\\]\nWith this point of view, the conditional expectation is computed given the information that the event \\(\\{X=0\\}\\) occurred or the event \\(\\{X=1\\}\\) occurred. It is possible to regroup both conditional expectations in a single object, if we think of the conditional expectation as a random variable and denote it by \\(\\mathbb{E}[Y|X]\\). Namely, we take:\n\\[\\begin{aligned}\n\\mathbb{E}[Y|X](\\omega) & =\\begin{cases}\n\\frac{1}{2} & \\text{if }X(\\omega)=0\\\\\n\\frac{3}{2} & \\text{if }X(\\omega)=1\n\\end{cases}\\label{eq:elementary-conditional-expectation-example}\n\\end{aligned}\\]\nThis random variable is called the conditional expectation of \\(Y\\) given \\(X\\). We make two important observations:\n(i) If the value of \\(X\\) is known, then the value of \\(\\mathbb{E}[Y|X]\\) is determined.\n(ii) If we have another random variable \\(g(X)\\) constructed from \\(X\\), then we have:\n\\[\\begin{aligned}\n\\mathbb{E}[g(X)Y] & =\\mathbb{E}[g(X)\\mathbb{E}[Y|X]]\n\\end{aligned}\\]\nIn other words, as far as \\(X\\) is concerned, the conditional expectation \\(\\mathbb{E}[Y|X]\\) is a proxy for \\(Y\\) in the expectation. We sometimes say that \\(\\mathbb{E}[Y|X]\\) is the best estimate of \\(Y\\) given the information of \\(X\\).\nThe last observation is easy to verify since:\n\\[\\begin{aligned}\n\\mathbb{E}[g(X)Y] & =\\sum_{i=0}^{1}\\sum_{j=0}^{2}g(i)\\cdot j\\cdot\\mathbb{P}(X=i,Y=j)\\\\\n& =\\sum_{i=0}^{1}\\mathbb{P}(X=i)g(i)\\left\\{ \\sum_{j=0}^{2}j\\cdot\\frac{\\mathbb{P}(X=i,Y=j)}{\\mathbb{P}(X=i)}\\right\\} \\\\\n& =\\mathbb{E}[g(X)\\mathbb{E}[Y|X]]\n\\end{aligned}\\]\n\n(Elementary Definitions of Conditional Expectation).\n(1) \\((X,Y)\\) discrete. The treatment is similar to the above. If a random variable \\(X\\) takes values \\((x_{i},i\\geq1)\\) and \\(Y\\) takes values \\((y_{j},j\\geq1)\\), we have by definition that the conditional expectation as a random variable is:\n\\[\\begin{aligned}\n\\mathbb{E}[Y|X](\\omega) & =\\sum_{j\\geq1}y_{j}\\mathbb{P}(Y=y_{j}|X=x_{i})\\quad\\text{for }\\omega\\text{ such that }X(\\omega)=x_{i}\n\\end{aligned}\\] (2) \\((X,Y)\\) continuous with joint PDF \\(f_{X,Y}(x,y)\\): In this case, the conditional expectation is the random variable given by\n\\[\\begin{aligned}\n\\mathbb{E}[Y|X] & =h(X)\n\\end{aligned}\\]\nwhere\n\\[\\begin{aligned}\nh(x) & =\\int_{\\mathbf{R}}yf_{Y|X}(y|x)dy=\\int_{\\mathbf{R}}y\\frac{f_{X,Y}(x,y)}{f_{X}(x)}dy=\\frac{\\int_{\\mathbf{R}}yf_{X,Y}(x,y)dy}{\\int_{\\mathbf{R}}f_{X,Y}(x,y)dy}\n\\end{aligned}\\]\n\nIn the two examples above, the expectation of the random variable \\(\\mathbb{E}[Y|X]\\) is equal to \\(\\mathbb{E}[Y]\\). Indeed in the discrete case, we have:\n\\[\\begin{aligned}\n\\mathbb{E}[\\mathbb{E}[Y|X]] & =\\sum_{i=0}^{1}P(X=x_{i})\\cdot\\sum_{j=0}^{2}y_{j}\\mathbb{P}(Y=y_{j}|X=x_{i})\\\\\n& =\\sum_{i=0}^{1}\\sum_{j=0}^{2}y_{j}\\mathbb{P}(Y=y_{j},X=x_{i})\\\\\n& =\\sum_{j=0}^{2}y_{j}\\mathbb{P}(Y=y_{j})\\\\\n& =\\mathbb{E}[Y]\n\\end{aligned}\\]\n\n(Conditional Probability vs Conditional expectation). The conditional probability of the event \\(A\\) given \\(B\\) can be recast in terms of conditional expectation using indicator functions. If \\(0&lt;\\mathbb{P}(B)&lt;1\\), it is not hard to check that: \\(\\mathbb{P}(A|B)=\\mathbb{E}[\\mathbf{1}_{A}|\\mathbf{1}_{B}=1]\\) and \\(\\mathbb{P}(A|B^{C})=\\mathbb{E}[\\mathbf{1}_{A}|1_{B}=0]\\). Indeed the random variables \\(\\mathbf{1}_{A}\\) and \\(\\mathbf{1}_{B}\\) are discrete. If we proceed as in the discrete case above, we have:\n\\[\\begin{aligned}\n\\mathbb{E}[\\mathbf{1}_{A}|\\mathbf{1}_{B}=1] & =1\\cdot\\mathbb{P}(\\mathbf{1}_{A}=1|\\mathbf{1}_{B}=1)\\\\\n& =\\frac{\\mathbb{P}(\\mathbf{1}_{A}=1,\\mathbf{1}_{B}=1)}{\\mathbb{P}(\\mathbf{1}_{B}=1)}\\\\\n& =\\frac{\\mathbb{P}(A\\cap B)}{\\mathbb{P}(B)}\\\\\n& =\\mathbb{P}(A|B)\n\\end{aligned}\\]\nA similar calculation gives \\(\\mathbb{P}(A|B^{C})\\). In particular, the formula for total probability for \\(A\\) is a rewriting of the expectation of the random variable \\(\\mathbb{E}[\\mathbf{1}_{A}|\\mathbf{1}_{B}]\\):\n\\[\\begin{aligned}\n\\mathbb{E}[\\mathbb{E}[\\mathbf{1}_{A}|\\mathbf{1}_{B}]] & =\\mathbb{E}[\\mathbf{1}_{A}|\\mathbf{1}_{B}=1]\\mathbb{P}(\\mathbf{1}_{B}=1)+\\mathbb{E}[\\mathbf{1}_{A}|\\mathbf{1}_{B}=0]\\mathbb{P}(\\mathbf{1}_{B}=0)\\\\\n& =\\mathbb{P}(A|B)\\cdot\\mathbb{P}(B)+\\mathbb{P}(A|B^{C})\\cdot\\mathbb{P}(B^{C})\\\\\n& =\\mathbb{P}(A)\n\\end{aligned}\\]"
  },
  {
    "objectID": "posts/martingales/index.html#conditional-expectation-as-a-projection.",
    "href": "posts/martingales/index.html#conditional-expectation-as-a-projection.",
    "title": "Martingales",
    "section": "",
    "text": "We start by giving the definition of conditional expectation given a single variable. This relates to the two observations (A) and (B) made previously. We assume that the random variable is integrable for the expectations to be well-defined.\n\nLet \\(X\\) and \\(Y\\) be integrable random variables on \\((\\Omega,\\mathcal{F},\\mathbb{P})\\). The conditional expectation of \\(Y\\) given \\(X\\) is the random variable denoted by \\(\\mathbb{E}[Y|X]\\) with the following two properties:\n(A) There exists a function \\(h:\\mathbf{R}\\to\\mathbf{R}\\) such that \\(\\mathbb{E}[Y|X]=h(X)\\).\n(B) For any bounded random variable of the form \\(g(X)\\) for some function \\(g\\),\n\\[\\mathbb{E}[g(X)Y]=\\mathbb{E}[g(X)\\mathbb{E}[Y|X]]\\label{eq:definition-conditional-expectation}\\]\nWe can intepret the second property as follows. The conditional expectation \\(\\mathbb{E}[Y|X]\\) serves as a proxy for \\(Y\\) as far as \\(X\\) is concerned. Note that in equation ([eq:definition-conditional-expectation]), the expectation on the left can be seen as an average over the joint values of \\((X,Y)\\), whereas the one on the right is an average over the values of \\(X\\) only! Another way to see this property is to write is as:\n\\[\\mathbb{E}[g(X)(Y-\\mathbb{E}[Y|X])]=0\\]\nIn other words, the random variable \\(Y-\\mathbb{E}[Y|X]\\) is orthogonal to any random variable constructed from \\(X\\).\nFinally, it is important to notice that if we take \\(g(X)=1\\), then the second property implies :\n\\[\\begin{aligned}\n\\mathbb{E}[Y] & =\\mathbb{E}[\\mathbb{E}[Y|X]]\n\\end{aligned}\\]\nIn other words, the expectation of the conditional expectation of \\(Y\\) is simply the expectation of \\(Y\\).\nThe existence of the conditional expectation \\(\\mathbb{E}[Y|X]\\) is not obvious. We know, it exists in particular cases given in example ([ex:elementary-definitions-of-conditional-expectation]). We will show more generally, that it exists, it is unique whenever \\(Y\\) is in \\(L^{2}(\\Omega,\\mathcal{F},\\mathbb{P})\\) (In fact, it can be shown to exist whenever \\(Y\\) is integrable). Before doing so, let’s warm up by looking at the case of Gaussian vectors.\n\n\n(Conditional expectation of Gaussian vectors - I). Let \\((X,Y)\\) be a Gaussian vector of mean \\(0\\). Then:\n\\[\\mathbb{E}[Y|X]=\\frac{\\mathbb{E}[XY]}{\\mathbb{E}[X^{2}]}X\\label{eq:conditional-expectation-of-gaussian-vector}\\]\nThis candidate satisfies the two defining properties of conditional expectation : (A) It is clearly a function of \\(X\\); in fact it is a simple multiple of \\(X\\). (B) We have that the random variable \\(\\left(Y-\\frac{\\mathbb{E}[XY]}{\\mathbb{E}[X^{2}]}X\\right)\\) is orthogonal and thus independent to \\(X\\). This is a consequence of the proposition ([prop:diagonal-cov-matrix-implies-independence-of-gaussians]), since:\n\\[\\begin{aligned}\n\\mathbb{E}\\left[X\\left(Y-\\frac{\\mathbb{E}[XY]}{\\mathbb{E}[X^{2}]}X\\right)\\right] & =\\mathbb{E}XY-\\frac{\\mathbb{E}[XY]}{\\mathbb{E}[X^{2}]}\\mathbb{E}X^{2}\\\\\n& =\\mathbb{E}XY-\\frac{\\mathbb{E}[XY]}{\\cancel{\\mathbb{E}[X^{2}]}}\\cancel{\\mathbb{E}X^{2}}\\\\\n& =0\n\\end{aligned}\\]\nTherefore, we have for any bounded function \\(g(X)\\) of \\(X\\):\n\\[\\begin{aligned}\n\\mathbb{E}[g(X)(Y-\\mathbb{E}(Y|X))] & =\\mathbb{E}[g(X)]\\mathbb{E}[Y-\\mathbb{E}[Y|X]]=0\n\\end{aligned}\\]\n\n\n(Brownian conditioning-I) Let \\((B_{t},t\\geq0)\\) be a standard Brownian motion. Consider the Gaussian vector \\((B_{1/2},B_{1})\\). Its covariance matrix is:\n\\[\\begin{aligned}\nC & =\\left[\\begin{array}{cc}\n1/2 & 1/2\\\\\n1/2 & 1\n\\end{array}\\right]\n\\end{aligned}\\]\nLet’s compute \\(\\mathbb{E}[B_{1}|B_{1/2}]\\) and \\(\\mathbb{E}[B_{1/2}|B_{1}]\\). This is easy using the equation ([eq:conditional-expectation-of-gaussian-vector]). We have:\n\\[\\begin{aligned}\n\\mathbb{E}[B_{1}|B_{1/2}] & =\\frac{\\mathbb{E}[B_{1}B_{1/2}]}{\\mathbb{E}[B_{1/2}^{2}]}B_{1/2}\\\\\n& =\\frac{(1/2)}{(1/2)}B_{1/2}\\\\\n& =B_{1/2}\n\\end{aligned}\\]\nIn other words, the best approximation of \\(B_{1}\\) given the information of \\(B_{1/2}\\) is \\(B_{1/2}\\). There is no problem in computing \\(\\mathbb{E}[B_{1/2}|B_{1}]\\), even though we are conditioning on a future position. Indeed the same formula gives\n\\[\\begin{aligned}\n\\mathbb{E}[B_{1/2}|B_{1}] & =\\frac{\\mathbb{E}[B_{1}B_{1/2}]}{\\mathbb{E}[B_{1}^{2}]}B_{1}=\\frac{1}{2}B_{1}\n\\end{aligned}\\]\nThis means that the best approximation of \\(B_{1/2}\\) given the position at time \\(1\\), is \\(\\frac{1}{2}B_{1}\\) which makes a whole lot of sense!\n\nIn example ([eq:conditional-expectation-of-gaussian-vector]) for the Gaussian vector \\((X,Y)\\), the conditional expectation was equal to the orthogonal projection of \\(Y\\) onto \\(X\\) in \\(L^{2}\\). In particular, the conditional expectation was a multiple of \\(X\\). Is this always the case? Unfortunately, it is not. For example, in the equation ([eq:elementary-conditional-expectation-example]), the conditional expectation is clearly not a multiple of the random variable \\(X\\). However, it is a function of \\(X\\), as is always the case by definition ([def:conditional-expectation]).\nThe idea to construct the conditional expectation \\(\\mathbb{E}[Y|X]\\) in general is to project \\(Y\\) on the space of all random variables that can be constructed from \\(X\\). To make this precise, consider the following subspace of \\(L^{2}(\\Omega,\\mathcal{F},\\mathbb{P})\\) :\n\nLet \\((\\Omega,\\mathcal{F},\\mathbb{P})\\) be a probability space and \\(X\\) a random variable defined on it. The space \\(L^{2}(\\Omega,\\sigma(X),\\mathbb{P})\\) is the linear subspace of \\(L^{2}(\\Omega,\\mathcal{F},\\mathbb{P})\\) consisting of the square-integrable random variables of the form \\(g(X)\\) for some function \\(g:\\mathbf{R}\\to\\mathbf{R}\\).\n\nThis is a linear subspace of \\(L^{2}(\\Omega,\\mathcal{F},\\mathbb{P})\\): It contains the random variable \\(0\\), and any linear combination of random variables of this kind is also a function of \\(X\\) and must have a finite second moment. We note the following:\n\n\\(L^{2}(\\Omega,\\sigma(X),\\mathbb{P})\\) is a subspace of \\(L^{2}(\\Omega,\\mathcal{F},\\mathbb{P})\\), very much how a plane or line (going through the origin) is a subspace of \\(\\mathbf{R}^{3}\\).\nIn particular, as in the case of a line or a plane, we can project an element of \\(Y\\) of \\(L^{2}(\\Omega,\\mathcal{F},\\mathbb{P})\\) onto \\(L^{2}(\\Omega,\\sigma(X),\\mathbb{P})\\). The resulting projection is an element of \\(L^{2}(\\Omega,\\sigma(X),\\mathbb{P})\\), a square-integrable random-variable that is a function of \\(X\\). For a subspace \\(\\mathcal{S}\\) of \\(\\mathbf{R}^{3}\\) (e.g. a line or a plane), the projection of the vector \\(\\mathbf{v}\\in\\mathbf{R}^{3}\\) onto the subspace \\(\\mathcal{S}\\), denoted \\(\\text{Proj}_{\\mathcal{S}}(\\mathbf{v})\\) is the closest point to \\(\\mathbf{v}\\) lying in the subspace \\(\\mathcal{S}\\). Moreover, \\(\\mathbf{v}-\\text{Proj}_{\\mathcal{S}}(\\mathbf{v})\\) is orthogonal to the subspace. This picture of orthogonal projection also holds in \\(L^{2}\\). Let \\(Y\\) be a random variable in \\(L^{2}(\\Omega,\\mathcal{F},\\mathbb{P})\\) and let \\(L^{2}(\\Omega,\\sigma(X),\\mathbb{P})\\) be the subspace of those random variables that are functions of \\(X\\). We write \\(Y^{\\star}\\) for the random variable in \\(L^{2}(\\Omega,\\sigma(X),\\mathbb{P})\\) that is closest to \\(Y\\). In other words, we have (using the definition of the \\(L^{2}\\)-distance square):\n\\[\\inf_{Z\\in L^{2}(\\Omega,\\sigma(X),\\mathbb{P})}\\mathbb{E}[(Y-Z)^{2}]=\\mathbb{E}[(Y-Y^{\\star})^{2}]\\label{eq:Y-star-is-the-closest-to-Y-in-L2-sense}\\]\n\nIt turns out that \\(Y^{\\star}\\) is the right candidate for the conditional expectation.\n\nFigure. An illustration of the conditional expectation \\(\\mathbb{E}[Y|X]\\) as an orthogonal projection of \\(Y\\) onto the subspace \\(L^2(\\Omega,\\sigma(X),\\mathbb{P})\\).\n\n\n(Existence and uniqueness of the conditional expectation) Let \\(X\\) be a random variable on \\((\\Omega,\\mathcal{F},\\mathbb{P})\\). Let \\(Y\\) be a random variable in \\(L^{2}(\\Omega,\\mathcal{F},\\mathbb{P})\\). Then the conditional expectation \\(\\mathbb{E}[Y|X]\\) is the random variable \\(Y^{\\star}\\) given in the equation ([eq:Y-star-is-the-closest-to-Y-in-L2-sense]). Namely, it is the random variable in \\(L^{2}(\\Omega,\\sigma(X),\\mathbb{P})\\) that is closest to \\(Y\\) in the \\(L^{2}\\)-distance.\nIn particular we have the following:\n1) It is the orthogonal projection of \\(Y\\) onto \\(L^{2}(\\Omega,\\sigma(X),\\mathbb{P})\\), that is \\(Y-Y^{\\star}\\) is orthogonal to any random variables in the subspace \\(L^{2}(\\Omega,\\sigma(X),\\mathbb{P})\\).\n2) It is unique.\n\n\nThis result reinforces the meaning of the conditional expectation \\(\\mathbb{E}[Y|X]\\) as the best estimation of \\(Y\\) given the information of \\(X\\): it is the closest random variable to \\(Y\\) among all the functions of \\(X\\) in the sense of \\(L^{2}\\).\n\n\nProof. Proof. We write for short \\(L^{2}(X)\\) for the subspace \\(L^{2}(\\Omega,\\sigma(X),\\mathbb{P})\\). Let \\(Y^{\\star}\\) be as in equation ([eq:Y-star-is-the-closest-to-Y-in-L2-sense]). We show successively that (1) \\(Y-Y^{\\star}\\) is orthogonal to any element of \\(L^{2}(X)\\), so it is the orthogonal projection (2) \\(Y^{\\star}\\) has the properties of conditional expectation in definition ([eq:definition-conditional-expectation]) (3) \\(Y^{\\star}\\) is unique.\n(1) Let \\(W=g(X)\\) be a random variable in \\(L^{2}(X)\\). We show that \\(W\\) is orthogonal to \\(Y-Y^{\\star}\\); that is \\(\\mathbb{E}[(Y-Y^{\\star})W]=0\\). This should be intuitively clear from figure above. On the one hand, we have by developing the square:\n\\[\\begin{aligned}\n\\mathbb{E}[(W-(Y-Y^{\\star}))^{2}] & =\\mathbb{E}[W^{2}-2W(Y-Y^{\\star})+(Y-Y^{\\star})^{2}]\\nonumber \\\\\n& =\\mathbb{E}[W^{2}]-2\\mathbb{E}[W(Y-Y^{\\star})]+\\mathbb{E}(Y-Y^{\\star})^{2}]\\label{eq:developing-the-square}\n\\end{aligned}\\]\nOn the other hand, \\(Y^{\\star}+W\\) is an arbitrary vector in \\(L^{2}(X)\\)(it is a linear combination of the elements in \\(L^{2}(X)\\)), we must have from equation ([eq:Y-star-is-the-closest-to-Y-in-L2-sense]):\n\\[\\begin{aligned}\n\\mathbb{E}[(W-(Y-Y^{\\star}))^{2}] & =\\mathbb{E}[(Y-(Y^{\\star}+W))^{2}]\\nonumber \\\\\n& \\geq\\inf_{Z\\in L^{2}(X)}\\mathbb{E}[(Y-Z)^{2}]\\nonumber \\\\\n& =\\mathbb{E}[(Y-Y^{\\star})^{2}]\\label{eq:lower-bound}\n\\end{aligned}\\]\nPutting the last two equations ([eq:developing-the-square]), ([eq:lower-bound]) together, we get that for any \\(W\\in L^{2}(X)\\):\n\\[\\begin{aligned}\n\\mathbb{E}[W^{2}]-2\\mathbb{E}[W(Y-Y^{\\star})] & \\geq0\n\\end{aligned}\\]\nIn particular, this also holds for \\(aW\\), in which case we get:\n\\[\\begin{aligned}\na^{2}\\mathbb{E}[W^{2}]-2a\\mathbb{E}[W(Y-Y^{\\star})] & \\geq0\\\\\n\\implies a\\left\\{ a\\mathbb{E}[W^{2}]-2\\mathbb{E}[W(Y-Y^{\\star})]\\right\\}  & \\geq0\n\\end{aligned}\\]\nIf \\(a&gt;0\\), then:\n\\[a\\mathbb{E}[W^{2}]-2\\mathbb{E}[W(Y-Y^{\\star})]\\geq0\\label{eq:case-when-a-gt-zero}\\]\nwhereas if \\(a&lt;0\\), then the sign changes upon dividing throughout by \\(a\\), and we have:\n\\[a\\mathbb{E}[W^{2}]-2\\mathbb{E}[W(Y-Y^{\\star})]\\leq0\\label{eq:case-when-a-lt-zero}\\]\nRearranging ([eq:case-when-a-gt-zero]) yields:\n\\[\\mathbb{E}[W(Y-Y^{\\star})]\\leq a\\mathbb{E}[W^{2}]/2\\label{eq:case-when-a-gt-zero-rearranged}\\]\nRearranging ([eq:case-when-a-lt-zero]) yields:\n\\[\\mathbb{E}[W(Y-Y^{\\star})]\\geq a\\mathbb{E}[W^{2}]/2\\label{eq:case-when-a-lt-zero-rearranged}\\]\nSince ([eq:case-when-a-gt-zero-rearranged]) holds for all \\(a&gt;0\\), the stronger inequality, \\(\\mathbb{E}[W(Y-Y^{\\star})]\\leq0\\) must hold. Since, ([eq:case-when-a-lt-zero-rearranged]) holds for all \\(a&lt;0\\), the stronger inequality \\(\\mathbb{E}[W(Y-Y^{\\star})]\\geq0\\) must hold. Consequently,\n\\[\\mathbb{E}[W(Y-Y^{\\star})]=0\\]\n(2) It is clear that \\(Y^{\\star}\\) is a function of \\(X\\) by construction, since it is in \\(L^{2}(X)\\). Moreover, for any \\(W\\in L^{2}(X)\\), we have from (1) that:\n\\[\\begin{aligned}\n\\mathbb{E}[W(Y-Y^{\\star})] & =0\n\\end{aligned}\\]\nwhich is the second defining property of conditional expectations.\n(3) Lastly, suppose there is another element \\(Y'\\) that is in \\(L^{2}(X)\\) that minimizes the distance to \\(Y\\). Then we would get:\n\\[\\begin{aligned}\n\\mathbb{E}[(Y-Y')^{2}] & =\\mathbb{E}[(Y-Y^{\\star}+Y^{\\star}-Y')^{2}]\\\\\n& =\\mathbb{E}[(Y-Y^{\\star})^{2}]+2\\mathbb{E}[(Y-Y^{\\star})(Y^{\\star}-Y')]+\\mathbb{E}[(Y^{\\star}-Y')^{2}]\\\\\n& =\\mathbb{E}[(Y-Y^{\\star})^{2}]+0+\\mathbb{E}[(Y^{\\star}-Y')^{2}]\\\\\n& \\quad\\left\\{ (Y^{\\star}-Y')\\in L^{2}(X)\\perp(Y-Y^{\\star})\\right\\}\n\\end{aligned}\\]\nwhere we used the fact, that \\(Y^{\\star}-Y'\\) is a vector in \\(L^{2}(X)\\) and the orthogonality of \\(Y-Y^{\\star}\\) with \\(L^{2}(X)\\) as in (1). But, this implies that:\n\\[\\begin{aligned}\n\\cancel{\\mathbb{E}[(Y-Y')^{2}]} & =\\cancel{\\mathbb{E}[(Y-Y^{\\star})^{2}]}+\\mathbb{E}[(Y^{\\star}-Y')^{2}]\\\\\n\\mathbb{E}[(Y^{\\star}-Y')^{2}] & =0\n\\end{aligned}\\]\nSo, \\(Y^{\\star}=Y'\\) almost surely. ◻\n\n\nConditional Expectation of continuous random variables. Let \\((X,Y)\\) be two random variables with joint density \\(f_{X,Y}(x,y)\\) on \\(\\mathbf{R}^{2}\\). Suppose for simplicity, that \\(\\int_{\\mathbf{R}}f(x,y)dx&gt;0\\) for every \\(y\\) belonging to \\(\\mathbf{R}\\). Show that the conditional expectation \\(\\mathbf{E}[Y|X]\\) equals \\(h(X)\\) where \\(h\\) is the function:\n\\[\\begin{aligned}\nh(x) & =\\frac{\\int_{\\mathbf{R}}yf_{X,Y}(x,y)dy}{\\int_{\\mathbf{R}}f_{X,Y}(x,y)dy}\\label{eq:conditional-expectation-of-continuous-random-variables}\n\\end{aligned}\\]\nIn particular, verify that \\(\\mathbf{E}[\\mathbf{E}[Y|X]]=\\mathbf{E}[Y]\\).\nHint: To prove this, verify that the above formula satisfies both the properties of conditional expectations; then invoke uniqueness to finish it off.\n\n\n(i) The density function \\(f_{X,Y}(x,y)\\) is a map \\(f:\\mathbf{R}^{2}\\to\\mathbf{R}\\). The integral \\(\\int_{y=-\\infty}^{y=+\\infty}yf_{X,Y}(x_{0},y)dy\\) is the area under the curve \\(yf(x,y)\\) at the point \\(x=x_{0}\\). Let’s call it \\(A(x_{0})\\). If instead, we have an arbitrary \\(x\\), \\(\\int_{y=-\\infty}^{y=+\\infty}yf_{X,Y}(x,y)dy\\) represents the area \\(A(x)\\) of an arbitrary slice of the surface \\(yf_{X,Y}\\) at the point \\(x\\). Hence, it is a function of \\(x\\). The denominator \\(\\int_{\\mathbf{R}}f_{X,Y}(x,y)dy=f_{X}(x)\\), the density of \\(X\\), which is a function of \\(x\\). Hence, the ratio is a function of \\(x\\).\n(ii) Let \\(g(X)\\) is a bounded random variable. We have:\n\\[\\begin{aligned}\n\\mathbf{E}[g(X)(Y-h(X))] & =\\mathbf{E}[Yg(X)]-\\mathbf{E}[g(X)h(X)]\\\\\n& =\\int\\int_{\\mathbf{R}^{2}}yg(x)f_{X,Y}(x,y)dydx-\\int_{\\mathbf{R}}g(x)h(x)f(x)dx\\\\\n& =\\int\\int_{\\mathbf{R}^{2}}yg(x)f_{X,Y}(x,y)dydx\\\\\n& -\\int_{\\mathbf{R}}\\begin{array}{c}\ng(x)\\cdot\\frac{\\int_{\\mathbf{R}}yf_{X,Y}(x,y)dy}{\\int_{\\mathbf{R}}f_{X,Y}(x,y)dy}\\end{array}\\cdot\\int_{\\mathbf{R}}f_{X,Y}(x,y)dy\\ dx\\\\\n& =\\int\\int_{\\mathbf{R}^{2}}yg(x)f_{X,Y}(x,y)dydx\\\\\n& -\\int_{\\mathbf{R}}\\begin{array}{c}\ng(x)\\cdot\\frac{\\int_{\\mathbf{R}}yf_{X,Y}(x,y)dy}{\\cancel{\\int_{\\mathbf{R}}f_{X,Y}(x,y)dy}}\\end{array}\\cdot\\cancel{\\int_{\\mathbf{R}}f_{X,Y}(x,y)dy}\\ dx\\\\\n& =\\int\\int_{\\mathbf{R}^{2}}yg(x)f_{X,Y}(x,y)dydx-\\int_{\\mathbf{R}^{2}}yg(x)f_{X,Y}(x,y)\\cdot dx\\cdot dy\\\\\n& =0\n\\end{aligned}\\]\n\nThus, \\(h(X)\\) is a valid candidate for the conditional expectation \\(\\mathbf{E}[Y|X]\\). Moreover, by the existence and uniqueness theorem ([th:existence-and-uniqueness-of-the-conditional-expectation]), \\(\\mathbf{E}[Y|X]\\) is unique and equals \\(h(X)\\).\n\n\n\nWe would like to generalize the conditional expectation to the case when we condition on the information of more than one random variable. Taking the \\(L^{2}\\) point of view, we should expect that the conditional expectation is the orthogonal projection of the given random variable on the subspace generated by square integrable functions of all the variables on which we condition.\nIt is now useful to study sigma-fields, an object that was defined in chapter 1.\n\n(Sigma-Field) A sigma-field or sigma-algebra \\(\\mathcal{F}\\) of a sample space \\(\\Omega\\) is a collection of all measurable events with the following properties:\n(1) \\(\\Omega\\) is in \\(\\mathcal{F}\\).\n(2) Closure under complement. If \\(A\\in\\mathcal{F}\\), then \\(A^{C}\\in\\mathcal{F}\\).\n(3) Closure under countable unions. If \\(A_{1},A_{2},\\ldots,\\in\\mathcal{F}\\), then \\(\\bigcup_{n=1}^{\\infty}A_{n}\\in\\mathcal{F}\\).\n\nSuch objects play a fundamental role in the rigorous study of probability and real analysis in general. We will focus on the intuition behind them. First let’s mention some examples of sigma-fields of a given sample space \\(\\Omega\\) to get acquainted with the concept.\n\n(Examples of sigma-fields).\n(1) The trivial sigma-field. Note that the collection of events \\(\\{\\emptyset,\\Omega\\}\\) is a sigma-field of \\(\\Omega\\). We generally denote it by \\(\\mathcal{F}_{0}\\).\n(2) The \\(\\sigma\\)-field generated by an event \\(A\\). Let \\(A\\) be an event that is not \\(\\emptyset\\) and not the entire \\(\\Omega\\). Then the smallest sigma-field containing \\(A\\) ought to be:\n\\[\\begin{aligned}\n\\mathcal{F}_{1} & =\\{\\emptyset,A,A^{C},\\Omega\\}\n\\end{aligned}\\]\nThis sigma-field is denoted by \\(\\sigma(A)\\).\n(3) The sigma-field generated by a random variable \\(X\\).\nWe now define the \\(\\mathcal{F}_{X}\\) as follows:\n\\[\\begin{aligned}\n\\mathcal{F}_{X} & =X^{-1}(\\mathcal{B}):=\\{\\omega:X(\\omega)\\in B\\},\\forall B\\in\\mathcal{B}(\\mathbf{R})\n\\end{aligned}\\]\nwhere \\(\\mathcal{B}\\) is the Borel \\(\\sigma\\)-algebra on \\(\\mathbf{R}\\). \\(\\mathcal{F}_{X}\\) is sometimes denoted as \\(\\sigma(X)\\). \\(\\mathcal{F}_{X}\\)is the set of all events pertaining to \\(X\\). It is a sigma-algebra because:\n(i) \\(\\Omega\\in\\sigma(X)\\) because \\(\\Omega=\\{\\omega:X(\\omega)\\in\\mathbf{R}\\}\\) and \\(\\mathbf{R}\\in\\mathcal{B}(\\mathbf{R})\\).\n(ii) Let any event \\(C\\in\\sigma(X)\\). We need to show that \\(\\Omega\\setminus C\\in\\sigma(X)\\).\nSince \\(C\\in\\sigma(X)\\), there exists \\(A\\in\\mathcal{B}(\\mathbf{R})\\), such that:\n\\[\\begin{aligned}\nC & =\\{\\omega\\in\\Omega:X(\\omega)\\in A\\}\n\\end{aligned}\\]\nNow, we calculate:\n\\[\\begin{aligned}\n\\Omega\\setminus C & =\\{\\omega\\in\\Omega:X(\\omega)\\in\\mathbf{R}\\setminus A\\}\n\\end{aligned}\\]\nSince \\(\\mathcal{B}(\\mathbf{R})\\) is a sigma-algebra, it is closed under complementation. Hence, if \\(A\\in\\mathcal{B}(\\mathbf{R})\\), it implies that \\(\\mathbf{R}\\setminus A\\in\\mathcal{B}(\\mathbf{R})\\). So, \\(\\Omega\\setminus C\\in\\sigma(X)\\).\n(iii) Consider a sequence of events \\(C_{1},C_{2},\\ldots,C_{n},\\ldots\\in\\sigma(X)\\). We need to prove that \\(\\bigcup_{n=1}^{\\infty}C_{n}\\in\\sigma(X)\\).\nSince \\(C_{n}\\in\\sigma(X)\\), there exists \\(A_{n}\\in\\mathcal{B}(\\mathbf{R})\\) such that:\n\\[\\begin{aligned}\nC_{n} & =\\{\\omega\\in\\Omega:X(\\omega)\\in A_{n}\\}\n\\end{aligned}\\]\nNow, we calculuate:\n\\[\\begin{aligned}\n\\bigcup_{n=1}C_{n} & =\\{\\omega\\in\\Omega:X(\\omega)\\in\\bigcup_{n=1}^{\\infty}A_{n}\\}\n\\end{aligned}\\]\nBut, \\(\\bigcup_{n=1}^{\\infty}A_{n}\\in\\mathcal{B}(\\mathbf{R})\\). So, \\(\\bigcup_{n=1}^{\\infty}C_{n}\\in\\sigma(X)\\).\nConsequently, \\(\\sigma(X)\\) is indeed a \\(\\sigma\\)-algebra.\nIntuitively, we think of \\(\\sigma(X)\\) as containing all information about \\(X\\).\n(4) The sigma-field generated by a stochastic process \\((X_{s},s\\leq t)\\). Let \\((X_{s},s\\geq0)\\) be a stochastic process. Consider the process restricted to \\([0,t]\\), \\((X_{s},s\\leq t)\\). We consider the smallest sigma-field containing all events pertaining to the random variables \\(X_{s},s\\leq t\\). We denote it by \\(\\sigma(X_{s},s\\leq t)\\) or \\(\\mathcal{F}_{t}\\).\n\nThe sigma-fields on \\(\\Omega\\) have a natural (partial) ordering: two sigma-fields \\(\\mathcal{G}\\) and \\(\\mathcal{F}\\) of \\(\\Omega\\) are such that \\(\\mathcal{G}\\subseteq\\mathcal{F}\\) if all the events in \\(\\mathcal{G}\\) are in \\(\\mathcal{F}\\). For example, the trivial \\(\\sigma\\)-field \\(\\mathcal{F}_{0}=\\{\\emptyset,\\Omega\\}\\) is contained in all the \\(\\sigma\\)-fields of \\(\\Omega\\). Clearly, the \\(\\sigma\\)-field \\(\\mathcal{F}_{t}=\\sigma(X_{s},s\\leq t)\\) is contained in \\(\\mathcal{F}_{t'}\\) if \\(t\\leq t'\\).\nIf all the events pertaining to a random variable \\(X\\) are in the \\(\\sigma\\)-field \\(\\mathcal{G}\\) (and thus we can compute \\(\\mu(X^{-1}((a,b]))\\)), we will say that \\(X\\) is \\(\\mathcal{G}\\)-measurable. This means that all information about \\(X\\) is contained in \\(\\mathcal{G}\\).\n\nLet \\(X\\) be a random variable defined on \\((\\Omega,\\mathcal{F},\\mathbb{P})\\). Consider another \\(\\mathcal{G}\\subseteq\\mathcal{F}\\). Then \\(X\\) is said to be \\(\\mathcal{G}\\)-measurable, if and only if:\n\\[\\begin{aligned}\n\\{\\omega:X(\\omega)\\in(a,b]\\} & \\in\\mathcal{G}\\text{ for all intervals }(a,b]\\in\\mathbf{R}\n\\end{aligned}\\]\n\n\n(\\(\\mathcal{F}_{0}\\)-measurable random variables). Consider the trivial sigma-field \\(\\mathcal{F}_{0}=\\{\\emptyset,\\Omega\\}\\). A random variable that is \\(\\mathcal{F}_{0}\\)-measurable must be a constant. Indeed, we have that for any interval \\((a,b]\\), \\(\\{\\omega:X(\\omega)\\in(a,b]\\}=\\emptyset\\) or \\(\\{\\omega:X(\\omega)\\in(a,b]\\}=\\Omega\\). This can only hold if \\(X\\) takes a single value.\n\n\n[]{#ex:sigma(X)-measurable-random-variables-example label=“ex:sigma(X)-measurable-random-variables-example”}(\\(\\sigma(X)\\)-measurable random variables). Let \\(X\\) be a given random variable on \\((\\Omega,\\mathcal{F},\\mathbb{P})\\). Roughly speaking, a \\(\\sigma(X)\\)-measurable random variable is determined by the information of \\(X\\) only. Here is the simplest example of a \\(\\sigma(X)\\)-measurable random variable. Take the indicator function \\(Y=\\mathbf{1}_{\\{X\\in B\\}}\\) for some event \\(\\{X\\in B\\}\\) pertaining to \\(X\\). Then the pre-images \\(\\{\\omega:Y(\\omega)\\in(a,b]\\}\\) are either \\(\\emptyset\\), \\(\\{X\\in B\\}\\), \\(\\{X\\in B^{C}\\}\\) or \\(\\Omega\\) depending on whether \\(0,1\\) are in \\((a,b]\\) or not. All of these events are in \\(\\sigma(X)\\). More generally, one can construct a \\(\\sigma(X)\\)-measurable random variable by taking linear combinations of indicator functions of events of the form \\(\\{X\\in B\\}\\).\nIt turns out that any (Borel measurable) function of \\(X\\) can be approximated by taking limits of such simple functions.\nConcretely, this translates to the following statement:\n\\[\\text{If }Y\\text{ is \\ensuremath{\\sigma}(X)-measurable, then Y=g(X) for some function g}\\]\nIn the same way, if \\(Z\\) is \\(\\sigma(X,Y)\\)-measurable, then \\(Z=h(X,Y)\\) for some \\(h\\). These facts can be proved rigorously using measure theory.\n\nWe are ready to give the general definition of conditional expectation.\n\n(Coin-Tossing Space). Suppose a coin is tossed infinitely many times. Let \\(\\Omega\\) be the set of all infinite sequences of \\(H\\)s and \\(T\\)s. A generic element of \\(\\Omega\\) is denoted by \\(\\omega_{1}\\omega_{2}\\ldots\\), where \\(\\omega_{n}\\) indicates the result of the \\(n\\)th coin toss. \\(\\Omega\\) is an uncountable sample space. The trivial sigma-field \\(\\mathcal{F}_{0}=\\{\\emptyset,\\Omega\\}\\). Assume that we don’t know anything about the outcome of the experiement. Even without any information, we know that the true \\(\\omega\\) belongs to \\(\\Omega\\) and does not belong to \\(\\emptyset\\). It is the information learned at time \\(0\\).\nNext, assume that we know the outcome of the first coin toss. Define \\(A_{H}=\\{\\omega:\\omega_{1}=H\\}\\)=set of all sequences beginning with \\(H\\) and \\(A_{T}=\\{\\omega:\\omega_{1}=T\\}\\)=set of all sequences beginning with \\(T\\). The four sets resolved by the first coin-toss form the the \\(\\sigma\\)-field \\(\\mathcal{F}_{1}=\\{\\emptyset,A_{H},A_{T},\\Omega\\}\\). We shall think of this \\(\\sigma\\)-field as containing the information learned by knowing the outcome of the first coin toss. More precisely, if instead of being told about the first coin toss, we are told for each set in \\(\\mathcal{F}_{1}\\), whether or not the true \\(\\omega\\) belongs to that set, then we know the outcome of the first coin toss and nothing more.\nIf we are told the first two coin tosses, we obtain a finer resolution. In particular, the four sets:\n\\[\\begin{aligned}\nA_{HH} & =\\{\\omega:\\omega_{1}=H,\\omega_{2}=H\\}\\\\\nA_{HT} & =\\{\\omega:\\omega_{1}=H,\\omega_{2}=T\\}\\\\\nA_{TH} & =\\{\\omega:\\omega_{1}=T,\\omega_{2}=H\\}\\\\\nA_{TT} & =\\{\\omega:\\omega_{1}=T,\\omega_{2}=T\\}\n\\end{aligned}\\]\nare resolved. Of course, the sets in \\(\\mathcal{F}_{1}\\) are resolved. Whenever a set is resolved, so is its complement, which means that \\(A_{HH}^{C}\\), \\(A_{HT}^{C}\\), \\(A_{TH}^{C}\\) and \\(A_{TT}^{C}\\) are resolved, so is their union which means that \\(A_{HH}\\cup A_{TH}\\), \\(A_{HH}\\cup A_{TT}\\), \\(A_{HT}\\cup A_{TH}\\) and \\(A_{HT}\\cup A_{TT}\\) are resolved. The other two pair-wise unions \\(A_{HH}\\cup A_{HT}=A_{H}\\) and \\(A_{TH}\\cup A_{TT}=A_{T}\\) are already resolved. Finally, the triple unions are also resolved, because \\(A_{HH}\\cup A_{HT}\\cup A_{TH}=A_{TT}^{C}\\) and so forth. Hence, the information pertaining to the second coin-toss is contained in:\n\\[\\begin{aligned}\n\\mathcal{F}_{2} & =\\{\\emptyset,\\Omega,\\\\\n& A_{H},A_{T},\\\\\n& A_{HH},A_{HT},A_{TH},A_{TT},\\\\\n& A_{HH}^{C},A_{HT}^{C},A_{TH}^{C},A_{TT}^{C},\\\\\n& A_{HH}\\cup A_{TH},A_{HH}\\cup A_{TT},A_{HT}\\cup A_{TH},A_{HT}\\cup A_{TT}\\}\n\\end{aligned}\\]\nHence, if the outcome of the first two coin tosses is known, all of the events in \\(\\mathcal{F}_{2}\\) are resolved - we exactly know, if each event has ocurred or not. \\(\\mathcal{F}_{2}\\) is the information learned by observing the first two coin tosses.\n\n\n(Exercises on sigma-fields).\n(a) Let \\(A\\), \\(B\\) be two proper subsets of \\(\\Omega\\) such that \\(A\\cap B\\neq\\emptyset\\) and \\(A\\cup B\\neq\\Omega\\). Write down \\(\\sigma(\\{A,B\\})\\), the smallest sigma-field containing \\(A\\) and \\(B\\) explicitly. What if \\(A\\cap B=\\emptyset\\)?\n(b) The Borel sigma-field is the smallest sigma-field containing intervals of the form \\((a,b]\\) in \\(\\mathbf{R}\\). Show that all singletons \\(\\{b\\}\\) are in \\(\\mathcal{B}(\\mathbf{R})\\) by writing \\(\\{b\\}\\) as a countable intersection of intervals \\((a,b]\\). Conclude that all open intervals \\((a,b)\\) and all closed intervals \\([a,b]\\) are in \\(\\mathcal{B}(\\mathbf{R})\\). Is the subset \\(\\mathbf{Q}\\) of rational numbers a Borel set?\n\n\nProof. Proof. (a) The sigma-field generated by the two events \\(A\\), \\(B\\) is given by:\n\\[\\begin{aligned}\n\\sigma(\\{A,B\\}) & =\\{\\emptyset,\\Omega,\\\\\n& A,B,A^{C},B^{C},\\\\\n& A\\cup B,A\\cap B,\\\\\n& A\\cup B^{C},A^{C}\\cup B,A^{C}\\cup B^{C},\\\\\n& A\\cap B^{C},A^{C}\\cap B,A^{C}\\cap B^{C},\\\\\n& (A\\cup B)\\cap(A\\cap B)^{C},\\\\\n& (A\\cup B)^{C}\\cup(A\\cap B)\\}\n\\end{aligned}\\]\n(b) Firstly, recall that:\n\\[\\begin{aligned}\n\\mathcal{B}(\\mathbf{R}) & =\\bigcap_{\\alpha\\in\\Lambda}\\mathcal{F}_{\\alpha}=\\bigcap\\sigma(\\{I:I\\text{ is an interval }(a,b]\\subseteq\\mathbf{R}\\})\n\\end{aligned}\\]\nWe can write:\n\\[\\begin{aligned}\n\\{b\\} & =\\bigcap_{n=1}^{\\infty}\\left(b-\\frac{1}{n},b\\right]\n\\end{aligned}\\]\nAs \\(\\mathcal{B}(\\mathbf{R})\\) is a sigma-field, it is closed under countable intersections. Hence, the singleton set \\(\\{b\\}\\)is a Borel set.\nSimilarly, we can write, any open interval as the countable union:\n\\[\\begin{aligned}\n(a,b) & =\\bigcup_{n=1}^{\\infty}\\left(a,b-\\frac{1}{n}\\right]\n\\end{aligned}\\]\nWe can convince ourselves, that equality indeed holds. Let \\(x\\in(a,b)\\) and choose \\(N\\), such that \\(\\frac{1}{N}&lt;|b-x|\\). Then, for all \\(n\\geq N\\), \\(x\\in(a,b-1/n]\\). Thus, it belongs to the RHS. In the reverse direction, let \\(x\\) belong to \\(\\bigcup_{n=1}^{\\infty}\\left(a,b-\\frac{1}{n}\\right]\\). So, \\(x\\) belongs to atleast one of these sets. Therefore, \\(x\\in(a,b)\\) is trivially true. So, the two sets are equal.\nHence, open intervals are Borel sets.\nSimilarly, we may write:\n\\[\\begin{aligned}\n[a,b] & =\\bigcap_{n=1}^{\\infty}\\left(a-\\frac{1}{n},b+\\frac{1}{n}\\right)\n\\end{aligned}\\]\nConsequently, closed intervals are Borel sets. Since \\(\\mathbf{Q}\\) is countable, it is a Borel set. Moreover, the empty set \\(\\emptyset\\) and \\(\\mathbf{R}\\) are Borel sets. So, \\(\\mathbf{R}\\backslash\\mathbf{Q}\\) is also a Borel set. ◻\n\n\nLet \\((X,Y)\\) be a Gaussian vector with mean \\(0\\) and covariance matrix\n\\[\\begin{aligned}\nC & =\\left[\\begin{array}{cc}\n1 & \\rho\\\\\n\\rho & 1\n\\end{array}\\right]\n\\end{aligned}\\]\nfor \\(\\rho\\in(-1,1)\\). We verify that the example ([ex:conditional-expectation-of-gaussian-vectors]) and exercise ([ex:=00005BArguin-4.1=00005D-Conditional-Expectation-of-continuous-random-variables]) yield the same conditional expectation.\n(a) Use equation ([eq:conditional-expectation-of-gaussian-vector]) to show that \\(\\mathbf{E}[Y|X]=\\rho X\\).\n(b) Write down the joint PDF \\(f(x,y)\\) of \\((X,Y)\\).\n(c) Show that \\(\\int_{\\mathbf{R}}yf(x,y)dy=\\rho x\\) and that \\(\\int_{\\mathbf{R}}f(x,y)dy=1\\).\n(d) Deduce that \\(\\mathbf{E}[Y|X]=\\rho X\\) using the equation ([eq:conditional-expectation-of-continuous-random-variables]).\n\n\nProof. Proof. (a) Since \\((X,Y)\\) have mean \\(0\\) and variance \\(1\\), it follows that:\n\\[\\begin{aligned}\n\\mathbf{E}[(X-EX)(Y-EY)] & =\\mathbf{E}(XY)\\\\\n\\sqrt{(\\mathbf{E}[X^{2}]-(\\mathbf{E}X)^{2})}\\cdot\\sqrt{(\\mathbf{E}[Y^{2}]-(\\mathbf{E}Y)^{2})} & =\\sqrt{(1-0)(1-0)}\\\\\n& =1\n\\end{aligned}\\]\nand therefore,\n\\[\\begin{aligned}\n\\rho & =\\frac{\\mathbf{E}(XY)}{1}=\\frac{\\mathbf{E}[XY]}{\\mathbf{E}[X^{2}]}\n\\end{aligned}\\]\nSince \\((X,Y)\\) is a Gaussian vector, using ([eq:conditional-expectation-of-gaussian-vector]), we have:\n\\[\\begin{aligned}\n\\mathbf{E}[Y|X] & =\\frac{\\mathbf{E}[XY]}{\\mathbf{E}[X^{2}]}X=\\rho X\n\\end{aligned}\\]\n(b) Consider the augmented matrix \\([C|I]\\). We have:\n\\[\\begin{aligned}\n[C|I] & =\\left[\\left.\\begin{array}{cc}\n1 & \\rho\\\\\n\\rho & 1\n\\end{array}\\right|\\begin{array}{cc}\n1 & 0\\\\\n0 & 1\n\\end{array}\\right]\n\\end{aligned}\\]\nPerforming \\(R_{2}=R_{2}-\\rho R_{1}\\), the above system is row-equivalent to:\n\\[\\left[\\left.\\begin{array}{cc}\n1 & \\rho\\\\\n0 & 1-\\rho^{2}\n\\end{array}\\right|\\begin{array}{cc}\n1 & 0\\\\\n-\\rho & 1\n\\end{array}\\right]\\]\nPerforming \\(R_{2}=\\frac{1}{1-\\rho^{2}}R_{2}\\), the above system is row-equivalent to:\n\\[\\left[\\begin{array}{cc}\n1 & \\rho\\\\\n0 & 1\n\\end{array}\\left|\\begin{array}{cc}\n1 & 0\\\\\n\\frac{-\\rho}{1-\\rho^{2}} & \\frac{1}{1-\\rho^{2}}\n\\end{array}\\right.\\right]\\]\nPerforming \\(R_{1}=R_{1}-\\rho R_{2}\\), we have:\n\\[\\left[\\begin{array}{cc}\n1 & 0\\\\\n0 & 1\n\\end{array}\\left|\\begin{array}{cc}\n\\frac{1}{1-\\rho^{2}} & -\\frac{\\rho}{1-\\rho^{2}}\\\\\n\\frac{-\\rho}{1-\\rho^{2}} & \\frac{1}{1-\\rho^{2}}\n\\end{array}\\right.\\right]\\]\nThus, \\[\\begin{aligned}\nC^{-1} & =\\frac{1}{1-\\rho^{2}}\\left[\\begin{array}{cc}\n1 & -\\rho\\\\\n-\\rho & 1\n\\end{array}\\right]\n\\end{aligned}\\]\nMoreover, \\(\\det C=1-\\rho^{2}.\\)\nTherefore, the joint density of \\((X,Y)\\) is given by:\n\\[\\begin{aligned}\nf(x,y) & =\\frac{1}{2\\pi\\sqrt{1-\\rho^{2}}}\\exp\\left[-\\frac{1}{2(1-\\rho^{2})}\\left[\\begin{array}{cc}\nx & y\\end{array}\\right]\\left[\\begin{array}{cc}\n1 & -\\rho\\\\\n-\\rho & 1\n\\end{array}\\right]\\left[\\begin{array}{c}\nx\\\\\ny\n\\end{array}\\right]\\right]\\\\\n& =\\frac{1}{2\\pi\\sqrt{1-\\rho^{2}}}\\exp\\left[-\\frac{1}{2(1-\\rho^{2})}\\left[\\begin{array}{cc}\nx-\\rho y & -\\rho x+y\\end{array}\\right]\\left[\\begin{array}{c}\nx\\\\\ny\n\\end{array}\\right]\\right]\\\\\n& \\frac{1}{2\\pi\\sqrt{1-\\rho^{2}}}\\exp\\left[-\\frac{1}{2(1-\\rho^{2})}(x^{2}-2\\rho xy+y^{2})\\right]\n\\end{aligned}\\]\n(c) Claim I. \\(\\int_{\\mathbf{R}}yf(x,y)dy=\\rho x\\).\nCompleting the square, we have:\n\\[\\begin{aligned}\n(x^{2}-2\\rho xy+y^{2}) & =(y-\\rho x)^{2}+x^{2}(1-\\rho^{2})\n\\end{aligned}\\]\nThus, we can write:\n\\[\\begin{aligned}\n\\int_{\\mathbf{R}}yf(x,y)dy & =\\frac{1}{2\\pi\\sqrt{1-\\rho^{2}}}e^{-\\frac{1}{2}x^{2}}\\int_{\\mathbf{R}}ye^{-\\frac{1}{2}\\frac{(y-\\rho x)^{2}}{(1-\\rho^{2})}}dy\n\\end{aligned}\\]\nLet’s substitute\n\\[\\begin{aligned}\nz & =\\frac{(y-\\rho x)}{\\sqrt{1-\\rho^{2}}}\\\\\ndz & =\\frac{dy}{\\sqrt{1-\\rho^{2}}}\n\\end{aligned}\\]\nTherefore,\n\\[\\begin{aligned}\n\\int_{\\mathbf{R}}ye^{-\\frac{1}{2}\\frac{(y-\\rho x)^{2}}{(1-\\rho^{2})}}dy & =\\sqrt{1-\\rho^{2}}\\int_{\\mathbf{R}}(\\rho x+\\sqrt{1-\\rho^{2}}z)e^{-\\frac{z^{2}}{2}}dz\\\\\n& =\\rho x\\cdot\\sqrt{1-\\rho^{2}}\\int_{\\mathbf{R}}e^{-\\frac{z^{2}}{2}}dz+(1-\\rho^{2})\\int_{\\mathbf{R}}ze^{-\\frac{z^{2}}{2}}dz\\\\\n& =\\rho x\\cdot\\sqrt{1-\\rho^{2}}\\cdot\\sqrt{2\\pi}+(1-\\rho^{2})\\cdot0\\\\\n& =\\rho x\\cdot\\sqrt{1-\\rho^{2}}\\cdot\\sqrt{2\\pi}\n\\end{aligned}\\]\nConsequently,\n\\[\\begin{aligned}\n\\int_{\\mathbf{R}}yf(x,y)dy & =\\frac{1}{2\\pi\\cancel{\\sqrt{1-\\rho^{2}}}}e^{-\\frac{1}{2}x^{2}}\\rho x\\cdot\\cancel{\\sqrt{1-\\rho^{2}}}\\cdot\\sqrt{2\\pi}\\\\\n& =\\rho x\\cdot\\frac{1}{\\sqrt{2\\pi}}e^{-\\frac{1}{2}x^{2}}\\\\\n& =\\rho x\\cdot f_{X}(x)\\\\\n\\frac{\\int_{\\mathbf{R}}yf(x,y)dy}{f_{X}(x)} & =\\frac{\\int_{\\mathbf{R}}yf(x,y)dy}{\\int_{\\mathbf{R}}f(x,y)}=\\rho x\n\\end{aligned}\\]\n(d) For a Gaussian vector \\((X,Y),\\) the conditional expectation \\(\\mathbf{E}[Y|X]=h(X)\\). Hence, \\(\\mathbf{E}[Y|X]=\\rho X\\). ◻\n\n\n(Conditional Expectation) Let \\(Y\\) be an integrable random variable on \\((\\Omega,\\mathcal{F},\\mathbb{P})\\) and let \\(\\mathcal{G}\\subseteq\\mathcal{F}\\) be a sigma-field of \\(\\Omega\\). The conditional expectation of \\(Y\\) given \\(\\mathcal{G}\\) is the random variable denoted by \\(\\mathbb{E}[Y|\\mathcal{G}]\\) such that the following hold:\n(a) \\(\\mathbb{E}[Y|\\mathcal{G}]\\) is \\(\\mathcal{G}\\)-measurable.\nIn other words, all events pertaining to the random variable \\(\\mathbb{E}[Y|\\mathcal{G}]\\) are in \\(\\mathcal{G}\\).\n(b) For any (bounded) random variable \\(W\\), that is \\(\\mathcal{G}\\)-measurable,\n\\[\\begin{aligned}\n\\mathbb{E}[WY] & =\\mathbb{E}[W\\mathbb{E}[Y|\\mathcal{G}]]\n\\end{aligned}\\]\nIn other words, \\(\\mathbf{E}[Y|\\mathcal{G}]\\) is a proxy for \\(Y\\) as far as the events in \\(\\mathcal{G}\\) are concerned.\nNote that, by taking \\(W=1\\) in the property (B), we recover:\n\\[\\begin{aligned}\n\\mathbf{E}[\\mathbf{E}[Y|\\mathcal{G}]] & =\\mathbf{E}[Y]\n\\end{aligned}\\]\n\n\nBeware of the notation! If \\(\\mathcal{G}=\\sigma(X)\\), then the conditional expectation \\(\\mathbf{E}[Y|\\sigma(X)]\\) is usually denoted by \\(\\mathbf{E}[Y|X]\\) for short. However, one should always keep in mind that conditioning on \\(X\\) is in fact projecting on the linear subspace generated by all variables constructed from \\(X\\) and not on the linear space generated by generated by \\(X\\) alone. In the same way, the conditional expectation \\(\\mathbf{E}[Z|\\sigma(X,Y)]\\) is often written \\(\\mathbf{E}[Z|X,Y]\\) for short.\nAs expected, if \\(Y\\) is in \\(L^{2}(\\Omega,\\mathcal{F},\\mathbb{P})\\), then \\(\\mathbf{E}[Y|\\mathcal{G}]\\) is given by the orthogonal projection of \\(Y\\) onto the subspace \\(L^{2}(\\Omega,\\mathcal{G},\\mathbb{P})\\), the subspace of square integrable random variables that are \\(\\mathcal{G}\\)-measurable. We write \\(Y^{\\star}\\) for the random variable in \\(L^{2}(\\Omega,\\mathcal{G},\\mathbb{P})\\) that is closest to \\(Y\\) that is:\n\\[\\begin{aligned}\n\\min_{Z\\in L^{2}(\\Omega,\\mathcal{G},\\mathbb{P})}\\mathbf{E}[(Y-Z)^{2}] & =\\mathbf{E}[(Y-Y^{\\star})^{2}]\\label{eq:conditional-expectation}\n\\end{aligned}\\]\n\n\n(Existence and Uniqueness of Conditional Expectations) Let \\(\\mathcal{G}\\subset\\mathcal{F}\\) be a sigma-field of \\(\\Omega\\). Let \\(Y\\) be a random variable in \\(L^{2}(\\Omega,\\mathcal{F},\\mathbb{P})\\). Then, the conditional expectation \\(\\mathbf{E}[Y|\\mathcal{G}]\\) is the random variable \\(Y^{\\star}\\) given in the equation ([eq:conditional-expectation]). Namely, it is the random variable in \\(L^{2}(\\Omega,\\mathcal{G},\\mathbb{P})\\) that is closest to \\(Y\\) in the \\(L^{2}\\)-distance. In particular we have the following:\n\n\nIt is the orthogonal projection of \\(Y\\) onto \\(L^{2}(\\Omega,\\mathcal{G},\\mathbb{P})\\), that is, \\(Y-Y^{\\star}\\) is orthogonal to the random variables in \\(L^{2}(\\Omega,\\mathcal{G},\\mathbb{P})\\).\nIt is unique.\n\nAgain, the result should be interpreted as follows: The conditional expectation \\(\\mathbf{E}[Y|\\mathcal{G}]\\) is the best approximation of \\(Y\\) given the information included in \\(\\mathcal{G}\\).\n\nThe conditional expectation in fact exists and is unique for any integrable random variable \\(Y\\)(i.e. \\(Y\\in L^{1}(\\Omega,\\mathcal{F},\\mathbb{P})\\) as the definition suggests. However, there is no orthogonal projection in \\(L^{1}\\), so the intuitive geometric picture is lost.\n\n\nFigure. An illustration of the conditional expectation \\(\\mathbb{E}[Y|\\mathcal{G}]\\) as an orthogonal projection of \\(Y\\) onto the subspace \\(L^2(\\Omega,\\mathcal{G},\\mathbb{P})\\).\n\n\n(Conditional Expectation for Gaussian Vectors. II.) Consider the Gaussian vector \\((X_{1},\\ldots,X_{n})\\). Without loss of generality, suppose it has mean \\(0\\) and is non-degenerate. What is the best approximation of \\(X_{n}\\) given the information \\(X_{1},\\ldots,X_{n-1}\\)? In other words, what is:\n\\[\\mathbf{E}[X_{n}|\\sigma(X_{1},\\ldots,X_{n-1})\\]\nWith example ([ex:sigma(X)-measurable-random-variables-example]) in mind, let’s write \\(\\mathbf{E}[X_{n}|X_{1}\\ldots X_{n-1}]\\) for short. From example ([ex:=00005BArguin-4.1=00005D-Conditional-Expectation-of-continuous-random-variables]), we know that if \\((X,Y)\\) is a Gaussian vector with mean \\(0\\), then \\(\\mathbf{E}[Y|X]\\) is a multiple of \\(X\\). Thus, we expect, that \\(\\mathbf{E}[X_{n}|X_{1}X_{2}\\ldots X_{n-1}]\\) is a linear combination of \\(X_{1},X_{2},\\ldots,X_{n-1}\\). That is, there exists \\(a_{1},\\ldots,a_{n-1}\\) such that:\n\\[\\begin{aligned}\n\\mathbf{E}[X_{n}|X_{1}X_{2}\\ldots X_{n-1}] & =a_{1}X_{1}+a_{2}X_{2}+\\ldots+a_{n-1}X_{n-1}\n\\end{aligned}\\] In particular, since the conditional expectation is a linear combination of the \\(X\\)’s, it is itself a Gaussian random variable. The best way to find the coefficient \\(a\\)’s is to go back to IID decomposition of Gaussian vectors.\nLet \\((Z_{1},Z_{2},\\ldots,Z_{n-1})\\) be IID standard Gaussians constructed from the linear combination of \\((X_{1},X_{2},\\ldots,X_{n-1})\\). Then, we have:\n\\[\\begin{aligned}\n\\mathbf{E}[X_{n}|X_{1}X_{2}\\ldots X_{n-1}] & =b_{1}Z_{1}+\\ldots+b_{n-1}Z_{n-1}\n\\end{aligned}\\]\nNow, recall, that we construct the random variables \\(Z_{1}\\), \\(Z_{2}\\), \\(\\ldots\\), \\(Z_{n}\\) using Gram-Schmidt orthogonalization:\n\\[\\begin{aligned}\n\\tilde{Z_{1}} & =X_{1}, & Z_{1} & =\\frac{\\tilde{Z_{1}}}{\\mathbf{E}(\\tilde{Z}_{1}^{2})}\\\\\n\\tilde{Z_{2}} & =X_{2}-\\mathbf{E}(X_{2}Z_{1})Z_{1} & Z_{2} & =\\frac{\\tilde{Z}_{2}}{\\mathbf{E}(\\tilde{Z}_{2}^{2})}\\\\\n\\tilde{Z_{3}} & =X_{3}-\\sum_{i=1}^{2}\\mathbf{E}(X_{3}Z_{i})Z_{i} & Z_{3} & =\\frac{\\tilde{Z}_{3}}{\\mathbf{E}(\\tilde{Z}_{3}^{2})}\\\\\n& \\vdots\n\\end{aligned}\\]\n\nThe simple case for \\(n=2\\) random variables.\nWe have already seen before:\n\\[\\begin{aligned}\n\\mathbf{E}[X_{1}(X_{2}-\\mathbf{E}(X_{2}Z_{1})Z_{1})] & =\\mathbf{E}[\\tilde{Z}_{1}(X_{2}-\\mathbf{E}(X_{2}Z_{1})Z_{1})]\\\\\n& =\\frac{\\mathbf{E}[\\tilde{Z}_{1}^{2}]}{\\mathbf{E}[\\tilde{Z}_{1}^{2}]}\\times\\mathbf{E}\\left[\\tilde{Z}_{1}(X_{2}-\\mathbf{E}(X_{2}Z_{1})Z_{1})\\right]\\\\\n& =\\mathbf{E}[\\tilde{Z}_{1}^{2}]\\times\\mathbf{E}\\left[\\frac{\\tilde{Z}_{1}}{\\mathbf{E}[\\tilde{Z}_{1}^{2}]}(X_{2}-\\mathbf{E}(X_{2}Z_{1})Z_{1})\\right]\\\\\n& =\\mathbf{E}[\\tilde{Z}_{1}^{2}]\\times\\mathbf{E}[Z_{1}(X_{2}-\\mathbf{E}(X_{2}Z_{1})Z_{1})]\\\\\n& =\\mathbf{E}[\\tilde{Z}_{1}^{2}]\\times\\left(\\mathbf{E}[Z_{1}X_{2}]-\\mathbf{E}(X_{2}Z_{1})\\mathbf{E}[Z_{1}^{2}]\\right)\\\\\n& =0\n\\end{aligned}\\]\nSo,\\(X_{2}-\\mathbf{E}(X_{2}Z_{1})Z_{1}\\) is orthogonal to \\(X_{1}\\).\nMoreover, \\(\\mathbf{E}(X_{2}Z_{1})Z_{1}\\) is a function of \\(X_{1}\\). Thus, both the properties of conditional expectation are satisfied. Since conditional expectations are unique, we must have, \\(\\mathbf{E}[X_{2}|X_{1}]=\\mathbf{E}(X_{2}Z_{1})Z_{1}\\).\nThe case for \\(n=3\\) random variables.\nWe have seen that:\n\\[\\begin{aligned}\n\\mathbf{E}[X_{1}(X_{3}-\\mathbf{E}(X_{3}Z_{1})Z_{1}-\\mathbf{E}(X_{3}Z_{2})Z_{2})] & =\\frac{\\mathbf{E}[\\tilde{Z}_{1}^{2}]}{\\mathbf{E}[\\tilde{Z}_{1}^{2}]}\\times\\mathbf{E}[\\tilde{Z}_{1}(X_{3}-\\mathbf{E}(X_{3}Z_{1})Z_{1}-\\mathbf{E}(X_{3}Z_{2})Z_{2})]\\\\\n& =\\mathbf{E}[\\tilde{Z}_{1}^{2}]\\times\\mathbf{E}\\left\\{ \\frac{\\tilde{Z}_{1}}{\\mathbf{E}[\\tilde{Z}_{1}^{2}]}(X_{3}-\\mathbf{E}(X_{3}Z_{1})Z_{1}-\\mathbf{E}(X_{3}Z_{2})Z_{2})\\right\\} \\\\\n& =\\mathbf{E}[\\tilde{Z}_{1}^{2}]\\times\\mathbf{E}\\left\\{ Z_{1}(X_{3}-\\mathbf{E}(X_{3}Z_{1})Z_{1}-\\mathbf{E}(X_{3}Z_{2})Z_{2})\\right\\} \\\\\n& =\\mathbf{E}[\\tilde{Z}_{1}^{2}]\\times\\mathbf{E}[X_{3}Z_{1}]-\\mathbf{E}[X_{3}Z_{1}]\\mathbf{E}[Z_{1}^{2}]-\\mathbf{E}[X_{3}Z_{2}]\\mathbf{E}[Z_{1}Z_{2}]\\\\\n& =0\n\\end{aligned}\\]\nIt is an easy exercise to show that it is orthogonal to \\(X_{2}\\).\nHence, \\(X_{3}-\\mathbf{E}(X_{3}Z_{1})Z_{1}-\\mathbf{E}(X_{3}Z_{2})Z_{2}\\) is orthogonal to \\(X_{1}\\) and \\(X_{2}\\). Moreover, \\(\\mathbf{E}(X_{3}Z_{1})Z_{1}+\\mathbf{E}(X_{3}Z_{2})Z_{2}\\) is a function of \\(X_{1}\\), \\(X_{2}\\). Thus, we must have:\n\\[\\begin{aligned}\n\\mathbf{E}[X_{3}|X_{1}X_{2}] & =\\mathbf{E}(X_{3}Z_{1})Z_{1}+\\mathbf{E}(X_{3}Z_{2})Z_{2}\n\\end{aligned}\\]\nIn general, \\(X_{n}-\\sum_{i=1}^{n-1}\\mathbf{E}(X_{n}Z_{i})Z_{i}\\) is orthogonal to \\(X_{1}\\), \\(X_{2}\\), \\(\\ldots\\), \\(X_{n-1}\\). Hence,\n\\[\\begin{aligned}\n\\mathbf{E}[X_{n}|X_{1}X_{2}\\ldots X_{n-1}] & =\\sum_{i=1}^{n-1}\\mathbf{E}(X_{n}Z_{i})Z_{i}\n\\end{aligned}\\]\n\n\n\nWe now list the properties of conditional expectation that follow from the two defining properties (A), (B) in the definition. They are extremely useful, when doing explicit computations on martingales. A good way to remember them is to understand how they relate to the interpretation of conditional expectation as an orthogonal projection onto a subspace or, equivalently, as the best approximation of the variable given the information available.\n\nLet \\(Y\\) be an integrable random variable on \\((\\Omega,\\mathcal{F},\\mathbb{P})\\). Let \\(\\mathcal{G}\\subseteq\\mathcal{F}\\) be another sigma-field of \\(\\Omega\\). Then, the conditional expectation \\(\\mathbf{E}[Y|\\mathcal{G}]\\) has the following properties:\n(1) If \\(Y\\) is \\(\\mathcal{G}\\)-measurable, then :\n\\[\\begin{aligned}\n\\mathbf{E}[Y|\\mathcal{G}] & =Y\n\\end{aligned}\\]\n(2) Taking out what is known. More generally, if \\(Y\\) is \\(\\mathcal{G-}\\)measurable and \\(X\\) is another integrable random variable (with \\(XY\\) also integrable), then :\n\\[\\begin{aligned}\n\\mathbf{E}[XY|\\mathcal{G}] & =Y\\mathbf{E}[X|\\mathcal{G}]\n\\end{aligned}\\]\nThis makes sense, since \\(Y\\) is determined by \\(\\mathcal{G}\\), so we can take out what is known; it can be treated as a constant for the conditional expectation.\n(3) Independence. If \\(Y\\) is independent of \\(\\mathcal{G}\\), that is, for any events \\(\\{Y\\in(a,b]\\}\\) and \\(A\\in\\mathcal{G}\\):\n\\[\\begin{aligned}\n\\mathbb{P}(\\{Y\\in I\\}\\cap A) & =\\mathbb{P}(\\{Y\\in I\\})\\cdot\\mathbb{P}(A)\n\\end{aligned}\\]\nthen\n\\[\\begin{aligned}\n\\mathbf{E}[Y|\\mathcal{G}] & =\\mathbf{E}[Y]\n\\end{aligned}\\]\nIn other words, if you have no information on \\(Y\\), your best guess for its value is simply plain expectation.\n(4) Linearity of conditional expectations. Let \\(X\\) be another integrable random variable on \\((\\Omega,\\mathcal{F},\\mathbb{P})\\). Then,\n\\[\\begin{aligned}\n\\mathbf{E}[aX+bY|\\mathcal{G}] & =a\\mathbf{E}[X|\\mathcal{G}]+b\\mathbf{E}[Y|\\mathcal{G}],\\quad\\text{for any }a,b\\in\\mathbf{R}\n\\end{aligned}\\]\nThe linearity justifies the cumbersom choice of notation \\(\\mathbf{E}[Y|\\mathcal{G}]\\) for the random variable.\n(5) Tower Property : If \\(\\mathcal{H}\\subseteq\\mathcal{G}\\) is another sigma-field of \\(\\Omega\\), then:\n\\[\\begin{aligned}\n\\mathbf{E}[Y|\\mathcal{H}] & =\\mathbf{E}[\\mathbf{E}[Y|\\mathcal{G}]|\\mathcal{H}]\n\\end{aligned}\\]\nThink in terms of two successive projections: first on a plane, then on a line in the plane.\n(6) Pythagoras Theorem. We have:\n\\[\\begin{aligned}\n\\mathbf{E}[Y^{2}] & =\\mathbf{E}\\left[\\left(\\mathbf{E}[Y|\\mathcal{G}]\\right)^{2}\\right]+\\mathbf{E}\\left[\\left(Y-\\mathbf{E}[Y|\\mathcal{G}]\\right)^{2}\\right]\n\\end{aligned}\\]\nIn particular:\n\\[\\begin{aligned}\n\\mathbf{E}\\left[\\left(\\mathbf{E}\\left[Y|\\mathcal{G}\\right]\\right)^{2}\\right] & \\leq\\mathbf{E}[Y^{2}]\n\\end{aligned}\\]\nIn words, the \\(L^{2}\\) norm of \\(\\mathbf{E}[X|\\mathcal{G}]\\) is smaller than the one of \\(X\\), which is clear if you think in terms of orthogonal projection.\n(7) Expectation of the conditional expectation.\n\\[\\begin{aligned}\n\\mathbf{E}\\left[\\mathbf{E}[Y|\\mathcal{G}]\\right] & =\\mathbf{E}[Y]\n\\end{aligned}\\]\n\nProof.\nThe uniqueness property of conditional expectations in theorem ([th:existence-and-uniqueness-of-conditional-expectations-II]) might appear to be an academic curiosity. On the contrary, it is very practical, since it ensures, that if we find a candidate for the conditional expectation that has the two properties in Definition ([def:conditional-expectation]), then it must be the conditional expectation. To see this, let’s prove property (1).\n\nIf \\(Y\\) is \\(\\mathcal{G}\\)-measurable, then \\(\\mathbf{E}[Y|\\mathcal{G}]=Y\\).\nIt suffices to show that \\(Y\\) has the two defining properties of conditional expectation.\n(1) We are given that, \\(Y\\) is \\(\\mathcal{G}\\)-measurable. So, property (A) is satisfied.\n(2) For any bounded random variable \\(W\\) that is \\(\\mathcal{G}\\)-measurable, we have:\n\\[\\begin{aligned}\n\\mathbf{E}[W(Y-Y)] & =\\mathbf{E}[0]=0\n\\end{aligned}\\]\nSo, property (B) is also a triviality.\n\n\n(Taking out what is known.) If \\(Y\\) is \\(\\mathcal{G}\\)-measurable and \\(X\\) is another integrable random variable, then:\n\\[\\begin{aligned}\n\\mathbf{E}[XY|\\mathcal{G}] & =Y\\mathbf{E}[X|\\mathcal{G}]\n\\end{aligned}\\]\nIn a similar vein, it suffices to show that, \\(Y\\mathbf{E}[X|\\mathcal{G}]\\) has the two defining properties of conditional expectation.\n(1) We are given that \\(Y\\) is \\(\\mathcal{G}\\)-measurable; from property (1), \\(\\mathbf{E}[X|\\mathcal{G}]\\) is \\(\\mathcal{G}\\)-measurable. It follows that, \\(Y\\mathbf{E}[X|\\mathcal{G}]\\) is \\(\\mathcal{G}\\)-measurable.\n(2) From theorem ([th:existence-and-uniqueness-of-conditional-expectations-II]), \\(X-\\mathbf{E}[X|\\mathcal{G}]\\) is orthogonal to the random variables \\(L^{2}(\\Omega,\\mathcal{G},\\mathbb{P})\\). So, if \\(W\\) is any bounded \\(\\mathcal{G}\\)-measurable random variable, it follows that:\n\\[\\begin{aligned}\n\\mathbf{E}[WY(X-\\mathbf{E}[X|\\mathcal{G}])] & =0\\\\\n\\implies\\mathbf{E}[W\\cdot XY] & =\\mathbf{E}[WY\\mathbf{E}[X|\\mathcal{G}]]\n\\end{aligned}\\]\nThis closes the proof.\n\n\n(Independence.) If \\(Y\\) is independent of \\(\\mathcal{G}\\), that is, for all events \\(\\{Y\\in(a,b]\\}\\) and \\(A\\in\\mathcal{G}\\),\n\\[\\begin{aligned}\n\\mathbf{\\mathbb{P}}\\{Y\\in(a,b]\\cap A\\} & =\\mathbb{P}\\{Y\\in(a,b]\\}\\cdot\\mathbb{P}(A)\n\\end{aligned}\\]\nthen\n\\[\\begin{aligned}\n\\mathbf{E}[Y|\\mathcal{G}] & =\\mathbf{E}[Y]\n\\end{aligned}\\]\nLet us show that \\(\\mathbf{E}[Y]\\) has the two defining properties of conditional expectations.\n(1) \\(\\mathbf{E}[Y]\\) is a constant and so it is \\(\\mathcal{F}_{0}\\) measurable. Hence, it is \\(\\mathcal{G}\\) measurable.\n(2) If \\(W\\) is another \\(\\mathcal{G}\\)-measurable random variable,\n\\[\\begin{aligned}\n\\mathbf{E}[WY] & =\\mathbf{E}[W]\\cdot\\mathbf{E}[Y]\n\\end{aligned}\\]\nsince \\(Y\\) is independent of \\(\\mathcal{G}\\) and therefore it is independent of \\(Y\\). Hence,\n\\[\\begin{aligned}\n\\mathbf{E}[W(Y-\\mathbf{E}[Y])] & =0\n\\end{aligned}\\]\nConsequently, \\(\\mathbf{E}[Y|\\mathcal{G}]=\\mathbf{E}[Y]\\).\n\n\n(Linearity of conditional expectations) Let \\(X\\) be another integrable random variable on \\((\\Omega,\\mathcal{F},\\mathbb{P})\\). Then,\n\\[\\begin{aligned}\n\\mathbf{E}[aX+bY|\\mathcal{G}] & =a\\mathbf{E}[X|\\mathcal{G}]+b\\mathbf{E}[Y|\\mathcal{G}],\\quad\\text{for any }a,b\\in\\mathbf{R}\n\\end{aligned}\\]\n\nSince \\(\\mathbf{E}[X|\\mathcal{G}]\\) and \\(\\mathbf{E}[Y|\\mathcal{G}]\\) are \\(\\mathcal{G}-\\)measurable, any linear combination of these two random variables is also \\(\\mathcal{G}\\)-measurable.\nAlso, if \\(W\\) is any bounded \\(\\mathcal{G}-\\)measurable random variable, we have:\n\\[\\begin{aligned}\n\\mathbf{E}[W(aX+bY-(a\\mathbf{E}[X|\\mathcal{G}]+b\\mathbf{E}[Y|\\mathcal{G}]))] & =a\\mathbf{E}[W(X-\\mathbf{E}[X|\\mathcal{G}])]\\\\\n& +b\\mathbf{E}[W(Y-\\mathbf{E}[Y|\\mathcal{G}])]\n\\end{aligned}\\]\nBy definition, \\(X-\\mathbf{E}(X|\\mathcal{G})\\) is orthogonal t o the subspace \\(L^{2}(\\Omega,\\mathcal{G},\\mathbb{P})\\) and hence to all \\(\\mathcal{G}\\)-measurable random-variables. Hence, the two expectations on the right hand side of the above expression are \\(0\\). Since, conditional expectations are unique, we have the desired result.\n\nIf \\(\\mathcal{H}\\subseteq\\mathcal{G}\\) is another sigma-field of \\(\\Omega\\), then\n\\[\\begin{aligned}\n\\mathbf{E}[Y|\\mathcal{H}] & =\\mathbf{E}[\\mathbf{E}[Y|\\mathcal{G}]|\\mathcal{H}]\n\\end{aligned}\\]\nDefine \\(U:=\\mathbf{E}[Y|\\mathcal{G}]\\). By definition, \\(\\mathbf{E}[U|\\mathcal{H}]\\) is \\(\\mathcal{H}\\)-measurable.\nLet \\(W\\) be any bounded \\(\\mathcal{H}\\)-measurable random variable. We have:\n\\[\\begin{aligned}\n\\mathbf{E}[W\\{\\mathbf{E}(Y|\\mathcal{G})-\\mathbf{E}(\\mathbf{E}(Y|\\mathcal{G})|\\mathcal{H})\\}] & =\\mathbf{E}[W(U-\\mathbf{E}(U|\\mathcal{H})]\n\\end{aligned}\\]\nBut, by definition \\(U-\\mathbf{E}(U|\\mathcal{H})\\) is always orthogonal to the subspace \\(L^{2}(\\Omega,\\mathcal{H},\\mathbb{P})\\) and hence, \\(\\mathbf{E}[W(U-\\mathbf{\\mathbf{E}}(U|\\mathcal{H})]=0\\). Since, conditional expectations are unique, we have the desired result.\n\n\nPythagoras’s theorem. We have:\n\\[\\begin{aligned}\n\\mathbf{E}[Y^{2}] & =\\mathbf{E}[(\\mathbf{E}[Y|\\mathcal{G}])^{2}]+\\mathbf{E}[(Y-\\mathbf{E}(Y|\\mathcal{G}))^{2}]\n\\end{aligned}\\]\nIn particular,\n\\[\\begin{aligned}\n\\mathbf{E}[(\\mathbf{E}[Y|\\mathcal{G}])^{2}] & \\leq\\mathbf{E}[Y^{2}]\n\\end{aligned}\\]\nConsider the orthogonal decomposition:\n\\[\\begin{aligned}\nY & =\\mathbf{E}[Y|\\mathcal{G}]+(Y-\\mathbf{E}[Y|\\mathcal{G}])\n\\end{aligned}\\]\nSquaring on both sides and taking expectations, we have:\n\\[\\begin{aligned}\n\\mathbf{E}[Y^{2}] & =\\mathbf{E}[(\\mathbf{E}(Y|\\mathcal{G}))^{2}]+\\mathbf{E}[(Y-\\mathbf{E}[Y|\\mathcal{G}])^{2}]+2\\mathbf{E}\\left[\\mathbf{E}[Y|\\mathcal{G}](Y-\\mathbf{E}[Y|\\mathcal{G}])\\right]\n\\end{aligned}\\]\nBy definition of conditional expectation, \\((Y-\\mathbf{E}[Y|\\mathcal{G}])\\) is orthogonal to the subspace \\(L^{2}(\\Omega,\\mathcal{G},\\mathbb{P})\\). By the properties of conditional expectation, \\(\\mathbf{E}[Y|\\mathcal{G}]\\) is \\(\\mathcal{G}-\\)measurable, so it belongs to \\(L^{2}(\\Omega,\\mathcal{G},\\mathbb{P})\\). Hence, the dot-product on the right-hand side is \\(0\\). Consequently, we have the desired result.\nMoreover, since \\((Y-\\mathbf{E}[Y|\\mathcal{G}])^{2}\\) is a non-negative random variable, \\(\\mathbf{E}[(Y-\\mathbf{E}[Y|\\mathcal{G}])^{2}]\\geq0\\). It follows that: \\(\\mathbf{E}[Y^{2}]\\geq\\mathbf{E}[(\\mathbf{E}(Y|\\mathcal{G}))^{2}]\\).\n\n\nOur claim is:\n\\[\\begin{aligned}\n\\mathbf{E}\\left[\\mathbf{E}[Y|\\mathcal{G}]\\right] & =\\mathbf{E}[Y]\n\\end{aligned}\\]\nWe know that, if \\(W\\) is any bounded \\(\\mathcal{G}\\)-measurable random variable:\n\\[\\begin{aligned}\n\\mathbf{E}\\left[WY\\right] & =\\mathbf{E}[W\\mathbf{E}[Y|\\mathcal{G}]]\n\\end{aligned}\\]\nTaking \\(W=1\\), we have:\n\\[\\begin{aligned}\n\\mathbf{E}\\left[Y\\right] & =\\mathbf{E}[\\mathbf{E}[Y|\\mathcal{G}]]\n\\end{aligned}\\]\n\n\n(Brownian Conditioning II). We continue the example ([ex:brownian-conditioning-I]). Let’s now compute the conditional expectations \\(\\mathbf{E}[e^{aB_{1}}|B_{1/2}]\\) and \\(\\mathbf{E}[e^{aB_{1/2}}|B_{1}]\\) for some parameter \\(a\\). We shall need the properties of conditional expectation in proposition ([prop:properties-of-conditional-expectation]). For the first one we use the fact that \\(B_{1/2}\\) is independent of \\(B_{1}-B_{1/2}\\) to get:\n\\[\\begin{aligned}\n\\mathbf{E}[e^{aB_{1}}|B_{1/2}] & =\\mathbf{E}[e^{a((B_{1}-B_{1/2})+B_{1/2})}|B_{1/2}]\\\\\n& =\\mathbf{E}[e^{a(B_{1}-B_{2})}\\cdot e^{aB_{1/2}}|B_{1/2}]\\\\\n& \\quad\\left\\{ \\text{Taking out what is known}\\right\\} \\\\\n& =e^{aB_{1/2}}\\mathbf{E}[e^{a(B_{1}-B_{1/2})}|B_{1/2}]\\\\\n& =e^{aB_{1/2}}\\cdot\\mathbf{E}[e^{a(B_{1}-B_{1/2})}]\\\\\n& \\quad\\{\\text{Independence}\\}\n\\end{aligned}\\]\nWe know that, \\(a(B_{1}-B_{1/2})\\) is a gaussian random variable with mean \\(0\\) and variance \\(a^{2}/2\\). We also know that, \\(\\mathbf{E}[e^{tZ}]=e^{t^{2}/2}\\). So, \\(\\mathbf{E}[e^{a(B_{1}-B_{1/2})}]=e^{a^{2}/4}\\). Consequently, \\(\\mathbf{E}[e^{aB_{1}}|B_{1/2}]=e^{aB_{1/2}+a^{2}/4}\\).\nThe result itself has the form of the MGF of a Gaussian with mean \\(B_{1/2}\\) and variance \\(1/2\\). (The MGF of \\(X=\\mu+\\sigma Z\\), \\(Z=N(0,1)\\) is \\(M_{X}(a)=\\exp\\left[\\mu+\\frac{1}{2}\\sigma^{2}a^{2}\\right]\\).) In fact, this shows that the conditional distribution of \\(B_{1}\\) given \\(B_{1/2}\\) is Gaussian of mean \\(B_{1/2}\\) and variance \\(1/2\\).\nFor the other expectation, note that \\(B_{1/2}-\\frac{1}{2}B_{1}\\) is independent of \\(B_{1}\\). We have: \\[\\begin{aligned}\n\\mathbf{E}\\left[\\left(B_{1/2}-\\frac{1}{2}B_{1}\\right)B_{1}\\right] & =\\mathbf{E}(B_{1/2}B_{1})-\\frac{1}{2}\\mathbf{E}[B_{1}^{2}]\\\\\n& =\\frac{1}{2}-\\frac{1}{2}\\cdot1\\\\\n& =0\n\\end{aligned}\\]\nTherefore, we have:\n\\[\\begin{aligned}\n\\mathbf{E}[e^{aB_{1/2}}|B_{1}] & =\\mathbf{E}[e^{a(B_{1/2}-\\frac{1}{2}B_{1})+\\frac{a}{2}B_{1}}|B_{1}]\\\\\n& =\\mathbf{E}[e^{a(B_{1/2}-\\frac{1}{2}B_{1})}\\cdot e^{\\frac{a}{2}B_{1}}|B_{1}]\\\\\n& =e^{\\frac{a}{2}B_{1}}\\mathbf{E}[e^{a(B_{1/2}-\\frac{1}{2}B_{1})}|B_{1}]\\\\\n& \\quad\\{\\text{Taking out what is known }\\}\\\\\n& =e^{\\frac{a}{2}B_{1}}\\mathbf{E}[e^{a(B_{1/2}-\\frac{1}{2}B_{1})}]\\\\\n& \\quad\\{\\text{Independence}\\}\n\\end{aligned}\\]\nNow, \\(a(B_{1/2}-\\frac{1}{2}B_{1})\\) is a random variable with mean \\(0\\) and variance \\(a^{2}(\\frac{1}{2}-\\frac{1}{4})=\\frac{a^{2}}{4}\\). Consequently, \\(\\mathbf{E}[e^{(a/2)Z}]=e^{\\frac{a^{2}}{8}}\\). Thus, \\(\\mathbf{E}[e^{aB_{1/2}}|B_{1}]=e^{\\frac{a}{2}B_{1}+\\frac{a^{2}}{8}}\\).\n\n\n(Brownian bridge is conditioned Brownian motion). We know that the Brownian bridge \\(M_{t}=B_{t}-tB_{1}\\), \\(t\\in[0,1]\\) is independent of \\(B_{1}\\). We use this to show that the conditional distribution of the Brownian motion given the value at the end-point \\(B_{1}\\) is the one of a Brownian bridge shifted by the straight line going from \\(0\\) to \\(B_{1}\\). To see this, we compute the conditional MGF of \\((B_{t_{1}},B_{t_{2}},\\ldots,B_{t_{n}})\\) given \\(B_{1}\\) for some arbitrary choices of \\(t_{1},t_{2},\\ldots,t_{n}\\) in \\([0,1]\\). We get the following by adding and subtracting \\(t_{j}B_{1}\\):\n\\[\\begin{aligned}\n\\mathbf{E}[e^{a_{1}B_{t_{1}}+\\ldots+a_{n}B_{t_{n}}}|B_{1}] & =\\mathbf{E}[e^{a_{1}(B_{t_{1}}-t_{1}B_{1})+\\ldots+a_{n}(B_{t_{n}}-t_{n}B_{1})}\\cdot e^{(a_{1}t_{1}B_{1}+\\ldots+a_{n}t_{n}B_{1})}|B_{1}]\\\\\n& =e^{(a_{1}t_{1}B_{1}+\\ldots+a_{n}t_{n}B_{1})}\\mathbf{E}[e^{a_{1}M_{t_{1}}+\\ldots+a_{n}M_{t_{n}}}|B_{1}]\\\\\n& \\quad\\{\\text{Taking out what is known}\\}\\\\\n& =e^{(a_{1}t_{1}B_{1}+\\ldots+a_{n}t_{n}B_{1})}\\mathbf{E}[e^{a_{1}M_{t_{1}}+\\ldots+a_{n}M_{t_{n}}}]\\\\\n& \\quad\\{\\text{Independence}\\}\n\\end{aligned}\\]\nThe right side is exactly the MGF of the process \\(M_{t}+tB_{1},t\\in[0,1]\\) (for a fixed value \\(B_{1})\\), where \\((M_{t},t\\in[0,1])\\) is a Brownian bridge. This proves the claim.\n\n\n(Conditional Jensen’s Inequality) If \\(c\\) is a convex function on \\(\\mathbf{R}\\) and \\(X\\) is a random variable on \\((\\Omega,\\mathcal{F},\\mathbb{P})\\), then:\n\\[\\begin{aligned}\n\\mathbf{E}[c(X)] & \\geq c(\\mathbf{E}[X])\n\\end{aligned}\\]\nMore generally, if \\(\\mathcal{G}\\subseteq\\mathcal{F}\\) is a sigma-field, then:\n\\[\\mathbf{E}[c(X)|\\mathcal{G}]\\geq c(\\mathbf{E}[X|\\mathcal{G}])\\]\n\n\nProof. Proof. We know that, if \\(c(x)\\) is a convex function, the tangent to the curve \\(c\\) at any point lies below the curve. The tangent to the cuve at this point, is a straight-line of the form:\n\\[\\begin{aligned}\nc(t)=y & =mt+c\n\\end{aligned}\\]\nwhere \\(m(t)=c'(t)\\). This holds for all \\(t\\in\\mathbf{R}\\). At an arbitrary point \\(x\\) we have:\n\\[\\begin{aligned}\nc(x)\\geq & y=mx+c\n\\end{aligned}\\]\nTherefore, we have:\n\\[\\begin{aligned}\nc(x)-c(t) & \\geq m(t)(x-t)\n\\end{aligned}\\]\nfor any \\(x\\) and any point of tangency \\(t\\).\n\\[\\begin{aligned}\nc(X)-c(Y) & \\geq m(Y)(X-Y)\n\\end{aligned}\\]\nSubstituting \\(Y=\\mathbf{E}[X|\\mathcal{G}]\\), we get:\n\\[\\begin{aligned}\nc(X)-c(\\mathbf{E}[X|\\mathcal{G}]) & \\geq m(\\mathbf{E}[X|\\mathcal{G}])(X-\\mathbf{E}[X|\\mathcal{G}])\n\\end{aligned}\\]\nTaking expectations on both sides, we get:\n\\[\\begin{aligned}\n\\mathbf{E}[(c(X)-c(\\mathbf{E}[X|\\mathcal{G}]))|\\mathcal{G}] & \\geq\\mathbf{E}[m(\\mathbf{E}[X|\\mathcal{G}])(X-\\mathbf{E}[X|\\mathcal{G}])|\\mathcal{G}]\n\\end{aligned}\\]\nThe left-hand side simplifies as:\n\\[\\begin{aligned}\n\\mathbf{E}[(c(X)-c(\\mathbf{E}[X|\\mathcal{G}]))|\\mathcal{G}] & =\\mathbf{E}[c(X)|\\mathcal{G}]-\\mathbf{E}[c(\\mathbf{E}[X|\\mathcal{G}]))|\\mathcal{G}]\\\\\n& \\quad\\{\\text{Linearity}\\}\\\\\n& =\\mathbf{E}[c(X)|\\mathcal{G}]-c(\\mathbf{E}[X|\\mathcal{G}])\\\\\n& \\quad\\{\\text{c(\\ensuremath{\\mathbf{E}}[X|\\ensuremath{\\mathcal{G}}])) is \\ensuremath{\\mathcal{G}}-measurable}\\}\n\\end{aligned}\\]\nOn the right hand side, we have:\n\\[\\begin{aligned}\n\\mathbf{E}[m(\\mathbf{E}[X|\\mathcal{G}])(X-\\mathbf{E}[X|\\mathcal{G}])|\\mathcal{G}] & =\\mathbf{E}[m(\\mathbf{E}[X|\\mathcal{G}])\\cdot X|\\mathcal{G}]-\\mathbf{E}[m(\\mathbf{E}[X|\\mathcal{G}])\\cdot\\mathbf{E}[X|\\mathcal{G}]|\\mathcal{G}]\\\\\n& =\\mathbf{E}[X|\\mathcal{G}]m(\\mathbf{E}[X|\\mathcal{G}])-m(\\mathbf{E}[X|\\mathcal{G}])\\cdot\\mathbf{E}[X|\\mathcal{G}]\\\\\n& =0\n\\end{aligned}\\]\nConsequently, it follows that \\(\\mathbf{E}[c(X)|\\mathcal{G}]\\geq c(\\mathbf{E}[X|\\mathcal{G}])\\). ◻\n\n\n(Embeddings of \\(L^{p}\\) spaces) Square-integrable random variables are in fact integrable. In other words, there is always the inclusion \\(L^{2}(\\Omega,\\mathcal{F},\\mathbb{P})\\subseteq L^{1}(\\Omega,\\mathcal{F},\\mathbb{P})\\). In particular, square integrable random variables always have a well-defined variance. This embedding is a simple consequence of Jensen’s inequality since:\n\\[\\begin{aligned}\n|\\mathbf{E}[X]|^{2} & \\leq\\mathbf{E}[|X|^{2}]\n\\end{aligned}\\]\nas \\(f(x)=|x|^{2}\\) is convex. By taking the square root on both sides, we get:\n\\[\\begin{aligned}\n\\left\\Vert X\\right\\Vert _{1} & \\leq\\left\\Vert X\\right\\Vert _{2}\n\\end{aligned}\\]\nMore generally, for any \\(1&lt;p&lt;\\infty\\), we can define \\(L^{p}(\\Omega,\\mathcal{F},\\mathbb{P})\\) to be the linear space of random variables such that \\(\\mathbf{E}[|X|^{p}]&lt;\\infty\\). Then for \\(p&lt;q\\), since \\(x^{q/p}\\) is convex, we get by Jensen’s inequality :\n\\[\\begin{aligned}\n\\mathbf{E}[|X|^{q}] & =\\mathbf{E}[(|X|^{p})^{\\frac{q}{p}}]\\geq\\left(\\mathbf{E}[|X|^{p}]\\right)^{\\frac{q}{p}}\n\\end{aligned}\\]\nTaking the \\(q\\)-th root on both sides:\n\\[\\begin{aligned}\n\\mathbf{E}[|X|^{p}]^{1/p} & \\leq\\mathbf{E}[|X|^{q}]^{1/q}\n\\end{aligned}\\]\nSo, if \\(X\\in L^{q}\\), then it must also be in \\(L^{p}\\). Concretely, this means that any random variable with a finite \\(q\\)-moment will also have a finite \\(p\\)-moment, for \\(q&gt;p\\)."
  },
  {
    "objectID": "posts/martingales/index.html#martingales.-1",
    "href": "posts/martingales/index.html#martingales.-1",
    "title": "Martingales",
    "section": "",
    "text": "We now have all the tools to define martingales.\n\n(Filtration). A filtration \\((\\mathcal{F}_{t}:t\\geq0)\\) of \\(\\Omega\\) is an increasing sequence of \\(\\sigma\\)-fields of \\(\\Omega\\). That is,\n\\[\\begin{aligned}\n\\mathcal{F}_{s} & \\subseteq\\mathcal{F}_{t},\\quad\\forall s\\leq t\n\\end{aligned}\\]\nWe will usually take \\(\\mathcal{F}_{0}=\\{\\emptyset,\\Omega\\}\\). The canonical example of a filtration is the natural filtration of a given process \\((M_{s}:s\\geq0)\\). This is the filtration given by \\(\\mathcal{F}_{t}=\\sigma(M_{s},s\\leq t)\\). The inclusions of the \\(\\sigma\\)-fields are then clear. For a given Brownian motion \\((B_{t},t\\geq0)\\), the filtration \\(\\mathcal{F}_{t}=\\sigma(B_{s},s\\leq t)\\) is sometimes called the Brownian filtration. We think of the filtration as the flow of information of the process.\n\n\nA stochastic process \\((X_{t}:t\\geq0)\\) is said to be adapted to \\((\\mathcal{F}_{t}:t\\geq0)\\), if for each \\(t\\), the random variable \\(X_{t}\\) is \\(\\mathcal{F}_{t}-\\)measurable.\n\n\n(Martingale). A process \\((M_{t}:t\\geq0)\\) is a martingale for the filtration \\((\\mathcal{F}_{t}:t\\geq0)\\) if the following hold:\n(1) The process is adapted, that is \\(M_{t}\\) is \\(\\mathcal{F}_{t}-\\)measurable for all \\(t\\geq0\\).\n(2) \\(\\mathbf{E}[|M_{t}|]&lt;\\infty\\) for all \\(t\\geq0\\). (This ensures that the conditional expectation is well defined.)\n(3) Martingale property:\n\\[\\begin{aligned}\n\\mathbf{E}[M_{t}|\\mathcal{F}_{s}] & =M_{s}\\quad\\forall s\\leq t\n\\end{aligned}\\]\nRoughly, speaking this means that the best approximation of a process at a future time \\(t\\) is its value at the present.\n\nIn particular, the martingale property implies that:\n\\[\\begin{aligned}\n\\mathbf{E}[M_{t}|\\mathcal{F}_{0}] & =M_{0}\\nonumber \\\\\n\\mathbf{E}[\\mathbf{E}[M_{t}|\\mathcal{F}_{0}]] & =\\mathbf{E}[M_{0}]\\nonumber \\\\\n\\mathbf{E}[M_{t}] & =\\mathbf{E}[M_{0}]\\label{eq:expected-value-of-martingale-at-any-time-is-constant}\\\\\n& \\quad\\{\\text{Tower Property}\\}\\nonumber\n\\end{aligned}\\]\nUsually, we take \\(\\mathcal{F}_{0}\\) to be the trivial sigma-field \\(\\{\\emptyset,\\Omega\\}\\). A random variable that is \\(\\mathcal{F}_{0}\\)-measurable must be a constant, so \\(M_{0}\\) is a constant. In this case, \\(\\mathbf{E}[M_{t}]=M_{0}\\) for all \\(t\\). If properties (1) and (2) are satisfied, but the best approximation is larger, \\(\\mathbf{E}[M_{t}|\\mathcal{F}_{s}]\\geq M_{s}\\), the process is called a submartingale. If it is smaller on average, \\(\\mathbf{E}[M_{t}|\\mathcal{F}_{s}]\\leq\\mathbf{E}[M_{s}]\\), we say it is a supermartingale.\nWe will be mostly interested in martingales that are continuous and square-integrable. Continuous martingales are martingales whose paths \\(t\\mapsto M_{t}(\\omega)\\) are continuous almost surely. Square-integrable martingales are such that \\(\\mathbf{E}[|M_{t}|^{2}]&lt;\\infty\\) for all \\(t\\)’s. This condition is stronger than \\(\\mathbf{E}[|M_{t}|]&lt;\\infty\\) due to Jensen’s inequality.\n\n(Martingales in Discrete-time). Martingales can be defined the same way if the index set of the process is discrete. For example, the filtration \\((\\mathcal{F}_{n}:n\\in\\mathbf{N})\\) is a countable set and the martingale property is then replaced by \\(\\mathbf{E}[M_{n+1}|\\mathcal{F}_{n}]=M_{n}\\) as expected. The tower-property then yields the martingale property \\(\\mathbf{E}[M_{n+k}|\\mathcal{F}_{n}]=M_{n}\\) for \\(k\\geq1\\).\n\n\n(Continuous Filtrations). Filtrations with continuous time can be tricky to handle rigorously. For example, one has to make sense of what it means for \\(\\mathcal{F}_{s}\\) as \\(s\\) approaches \\(t\\) from the left. Is it equal to \\(\\mathcal{F}_{t}\\)? Or is there actually less information in \\(\\lim_{s\\to t^{-}}\\mathcal{F}_{s}\\) than in \\(\\mathcal{F}_{t}\\)? This is a bit of headache when dealing with processes with jumps, like the Poisson process. However, if the paths are continuous, the technical problems are not as heavy.\nLet’s look at some of the important examples of martingales constructed from Brownian Motion.\n\n\n(Examples of Brownian Martingales)\n(i) Standard Brownian Motion. Let \\((B_{t}:t\\geq0)\\) be a standard Brownian motion and let \\((\\mathcal{F}_{t}:t\\geq0)\\) be a Brownian filtration. Then \\((B_{t}:t\\geq0)\\) is a square integrable martingale for the filtration \\((\\mathcal{F}_{t}:t\\geq0)\\). Property (1) is obvious, because all the sets in \\(\\mathcal{F}_{t}\\) are resolved, upon observing the outcome of \\(B_{t}\\). Similarly, \\(\\mathbf{E}[|B_{t}|]=0\\). As for the martingale property, note that, by the properties of conditional expectation in proposition ([prop:properties-of-conditional-expectation]), we have:\n\\[\\begin{aligned}\n\\mathbf{E}[B_{t}|\\mathcal{F}_{s}] & =\\mathbf{E}[B_{t}|B_{s}]\\\\\n& =\\mathbf{E}[B_{t}-B_{s}+B_{s}|B_{s}]\\\\\n& =\\mathbf{E}[B_{t}-B_{s}|B_{s}]+\\mathbf{E}[B_{s}|B_{s}]\\\\\n& \\quad\\{\\text{Linearity}\\}\\\\\n& =\\mathbf{E}[B_{t}-B_{s}]+B_{s}\\\\\n& \\quad\\{\\text{Independence}\\}\\\\\n& =B_{s}\n\\end{aligned}\\]\n(ii) Geometric Brownian Motion. Let \\((B_{t},t\\ge0)\\) be a standard brownian motion, and \\(\\mathcal{F}_{t}=\\sigma(B_{s},s\\leq t)\\). A geometric brownian motion is a process \\((S_{t},t\\geq0)\\) defined by:\n\\[\\begin{aligned}\nS_{t} & =S_{0}\\exp\\left(\\sigma B_{t}+\\mu t\\right)\n\\end{aligned}\\]\nfor some parameter \\(\\sigma&gt;0\\) and \\(\\mu\\in\\mathbf{R}\\). This is simply the exponential of the Brownian motion with drift. This is not a martingale for most choices of \\(\\mu\\)! In fact, one must take\n\\[\\begin{aligned}\n\\mu & =-\\frac{1}{2}\\sigma^{2}\n\\end{aligned}\\] for the process to be a martingale for the Brownian filtration. Let’s verify this. Property (1) is obvious since \\(S_{t}\\) is a function of \\(B_{t}\\) for each \\(t\\). So, it is \\(\\mathcal{F}_{t}\\) measurable. Moreover, property (2) is clear: \\(\\mathbf{E}[\\exp(\\sigma B_{t}+\\mu t)]=\\mathbf{E}[\\exp(\\sigma\\sqrt{t}Z+\\mu t)]=\\exp(\\mu t+\\frac{1}{2}\\sigma^{2}t)\\). So, its a finite quantity. As for the martingale property, note that by the properties of conditional expectation, and the MGF of Gaussians, we have for \\(s\\leq t\\):\n\\[\\begin{aligned}\n\\mathbf{E}[S_{t}|\\mathcal{F}_{s}] & =\\mathbf{E}\\left[S_{0}\\exp\\left(\\sigma B_{t}-\\frac{1}{2}\\sigma^{2}t\\right)|\\mathcal{F}_{s}\\right]\\\\\n& =S_{0}\\exp(-\\frac{1}{2}\\sigma^{2}t)\\mathbf{E}[\\exp(\\sigma(B_{t}-B_{s}+B_{s}))|\\mathcal{F}_{s}]\\\\\n& =S_{0}\\exp(-\\frac{1}{2}\\sigma^{2}t)\\exp(\\sigma B_{s})\\mathbf{E}[\\exp(\\sigma(B_{t}-B_{s}))|\\mathcal{F}_{s}]\\\\\n& \\quad\\{\\text{Taking out what is known}\\}\\\\\n& =S_{0}\\exp\\left(\\sigma B_{s}-\\frac{1}{2}\\sigma^{2}t\\right)\\mathbf{E}\\left[\\exp\\left(\\sigma(B_{t}-B_{s})\\right)\\right]\\\\\n& \\quad\\{\\text{Independence}\\}\\\\\n& =S_{0}\\exp\\left(\\sigma B_{s}-\\frac{1}{2}\\sigma^{2}t+\\frac{1}{2}\\sigma^{2}(t-s)\\right)\\\\\n& =S_{0}\\exp(\\sigma B_{s}-\\frac{1}{2}\\sigma^{2}s)\\\\\n& =S_{s}\n\\end{aligned}\\]\nWe will sometimes abuse terminology and refer to the martingale case of geometric brownian motion simply as geometric Brownian Motion when the context is clear.\n(iii) The square of the Brownian motion, compensated. It is easy to check \\((B_{t}^{2},t\\geq0)\\) is a submartingale by direct computation using increments or by Jensen’s inequality: \\(\\mathbf{E}[B_{t}^{2}|\\mathcal{F}_{s}]&gt;(\\mathbf{E}[B_{t}|\\mathcal{F}_{s}])^{2}=B_{s}^{2}\\), \\(s&lt;t\\). It is nevertheless possible to compensate to get a martingale:\n\\[\\begin{aligned}\nM_{t} & =B_{t}^{2}-t\n\\end{aligned}\\]\nIt is an easy exercise to verify that \\((M_{t}:t\\geq0)\\) is a martingale for the Brownian filtration \\((\\mathcal{F}_{t}:t\\geq0)\\).\n\\[\\begin{aligned}\n\\mathbf{E}[M_{t}|\\mathcal{F}_{s}] & =\\mathbf{E}[B_{t}^{2}-t|\\mathcal{F}_{s}]\\\\\n& =\\mathbf{E}[B_{t}^{2}|\\mathcal{F}_{s}]-t\\\\\n& =\\mathbf{E}[(B_{t}-B_{s}+B_{s})^{2}|\\mathcal{F}_{s}]-t\\\\\n& =\\mathbf{E}[(B_{t}-B_{s})^{2}|\\mathcal{F}_{s}]+2\\mathbf{E}[(B_{t}-B_{s})B_{s}|\\mathcal{F}_{s}]+\\mathbf{E}[B_{s}^{2}|\\mathcal{F}_{s}]-t\\\\\n& =\\mathbf{E}[(B_{t}-B_{s})^{2}]+2B_{s}\\mathbf{E}[(B_{t}-B_{s})|\\mathcal{F}_{s}]+B_{s}^{2}-t\\\\\n& =\\mathbf{E}[(B_{t}-B_{s})^{2}]+2B_{s}\\mathbf{E}[(B_{t}-B_{s})]+B_{s}^{2}-t\\\\\n& \\left\\{ \\begin{array}{c}\n\\text{\\ensuremath{(B_{t}-B_{s})} is independent of \\ensuremath{\\mathcal{F}_{s}}}\\\\\n\\text{Also, \\ensuremath{B_{s}} is known at time \\ensuremath{s}}\n\\end{array}\\right\\} \\\\\n& =(t-s)+2B_{s}\\cdot0+B_{s}^{2}-t\\\\\n& =B_{s}^{2}-s\\\\\n& =M_{s}\n\\end{aligned}\\]\n\n\n(Other important martingales).\n(1) Symmetric random walks. This is an example of a martingale in discrete time. Take \\((X_{i}:i\\in\\mathbf{N})\\) to be IID random variables with \\(\\mathbf{E}[X_{i}]=0\\) and \\(\\mathbf{E}[|X_{i}|]&lt;\\infty\\). Take \\(\\mathcal{F}_{n}=\\sigma(X_{i},i\\leq n)\\) and\n\\[\\begin{aligned}\nS_{n} & =X_{1}+X_{2}+\\ldots+X_{n},\\quad S_{0}=0\n\\end{aligned}\\]\nFirstly, the information learned by observing the outcomes of \\(X_{1}\\),\\(\\ldots\\),\\(X_{n}\\) is enough to completely determine \\(S_{n}\\). Hence, \\(S_{n}\\) is \\(\\mathcal{F}_{n}-\\)measurable.\nNext, \\[\\begin{aligned}\n|S_{n}| & =\\left|\\sum_{i=1}^{n}X_{i}\\right|\\\\\n& \\leq\\sum_{i=1}^{n}|X_{i}|\n\\end{aligned}\\]\nConsequently, by the montonocity of expectations, we have:\n\\[\\begin{aligned}\n\\mathbf{E}[|S_{n}|] & \\leq\\sum_{i=1}^{n}\\mathbf{E}[|X_{i}|]&lt;\\infty\n\\end{aligned}\\]\nThe martingale property is also satisfied. We have:\n\\[\\begin{aligned}\n\\mathbf{E}[S_{n+1}|\\mathcal{F}_{n}] & =\\mathbf{E}[S_{n}+X_{n+1}|\\mathcal{F}_{n}]\\\\\n& =\\mathbf{E}[S_{n}|\\mathcal{F}_{n}]+\\mathbf{E}[X_{n+1}|\\mathcal{F}_{n}]\\\\\n& =S_{n}+\\mathbf{E}[X_{n+1}]\\\\\n& \\left\\{ \\begin{array}{c}\n\\text{\\ensuremath{S_{n}} is \\ensuremath{\\mathcal{F}_{n}}-measurable}\\\\\n\\text{\\ensuremath{X_{n+1}} is independent of \\ensuremath{\\mathcal{F}_{n}}}\n\\end{array}\\right\\} \\\\\n& =S_{n}+0\\\\\n& =S_{n}\n\\end{aligned}\\]\n(2) Compensated Poisson process. Let \\((N_{t}:t\\geq0)\\) be a Poisson process with rate \\(\\lambda\\) and \\(\\mathcal{F}_{t}=\\sigma(N_{s},s\\leq t)\\). Then, \\(N_{t}\\) is a submartingale for its natural filtration. Again, properties (1) and (2) are easily checked. \\(N_{t}\\) is \\(\\mathcal{F}_{t}\\) measurable. Moreover, \\(\\mathbf{E}[|N_{t}|]=\\mathbf{E}[N_{t}]=\\frac{1}{\\lambda t}&lt;\\infty\\). The submartingale property follows by the independence of increments : for \\(s\\leq t\\),\n\\[\\begin{aligned}\n\\mathbf{E}[N_{t}|\\mathcal{F}_{s}] & =\\mathbf{E}[N_{t}-N_{s}+N_{s}|\\mathcal{F}_{s}]\\\\\n& =\\mathbf{E}[N_{t}-N_{s}|\\mathcal{F}_{s}]+\\mathbf{E}[N_{s}|\\mathcal{F}_{s}]\\\\\n& =\\mathbf{E}[N_{t}-N_{s}]+N_{s}\\\\\n& =\\lambda(t-s)+N_{s}\\\\\n& \\left\\{ \\because\\mathbf{E}[N_{t}]=\\lambda t\\right\\}\n\\end{aligned}\\]\nMore importantly, we get a martingale by slightly modifying the process. Indeed, if we subtract \\(\\lambda t\\), we have that the process :\n\\[\\begin{aligned}\nM_{t} & =N_{t}-\\lambda t\n\\end{aligned}\\]\nis a martingale. We have:\n\\[\\begin{aligned}\n\\mathbf{E}[M_{t}|\\mathcal{F}_{s}] & =\\mathbf{E}[N_{t}-\\lambda t|\\mathcal{F}_{s}]\\\\\n& =\\lambda t-\\lambda s+N_{s}-\\lambda t\\\\\n& =N_{s}-\\lambda s\\\\\n& =M_{s}\n\\end{aligned}\\]\nThis is called the compensated Poisson process. Let us simulate \\(10\\) paths of the compensated poisson process on \\([0,10]\\).\n\nimport numpy as np\nimport matplotlib.pyplot as plt\n\n# Generates a sample path of a compensated poisson process \n# with rate : `lambda_` per unit time\n# on the interval [0,T], and subintervals of size `stepSize`.\n\ndef generateCompensatedPoissonPath(lambda_,T,stepSize):\n    N = int(T/stepSize)   \n\n    poissonParam = lambda_ * stepSize        \n\n    x = np.random.poisson(lam=poissonParam,size=N)  \n    x = np.concatenate([[0.0], x])\n    N_t = np.cumsum(x)  \n    t = np.linspace(start=0.0,stop=10.0,num=1001)\n\n    M_t = np.subtract(N_t,lambda_ * t)  \n    return M_t\n\n\nt = np.linspace(0,10,1001)\nplt.grid(True)\n\nplt.xlabel(r'Time $t$')\nplt.ylabel(r'Compensated poisson process $M(t)$')\nplt.grid(True)\nplt.title(r'$10$ paths of the compensated Poisson process on $[0,10]$')\n\nfor i in range(10):\n    # Generate a poisson path with rate 1 /sec = 0.01 /millisec\n    n_t = generateCompensatedPoissonPath(lambda_=1.0, T=10, stepSize=0.01)\n    plt.plot(t, n_t)\n\n\nplt.show()\nplt.close()\nWe saw in the two examples, that, even though a process is not itself a martingale, we can sometimes compensate to obtain a martingale! Ito Calculus will greatly extend this perspective. We will have systematic rules that show when a function of Brownian motion is a martingale and if not, how to modify it to get one.\nFor now, we observe that a convex function of a martingale is always a submartingale by Jensen’s inequality.\n\nIf \\(c\\) is a convex function on \\(\\mathbf{R}\\) and \\((M_{t}:t\\geq0)\\) is a martingale for \\((\\mathcal{F}_{t}:t\\geq0)\\), then the process \\((c(M_{t}):t\\geq0)\\) is a submartingale for the same filtration, granted that \\(\\mathbf{E}[|c(M_{t})|]&lt;\\infty\\).\n\n\nProof. Proof. The fact that \\(c(M_{t})\\) is adapted to the filtration is clear since it is an explicit function of \\(M_{t}\\). The integrability is by assumption. The submartingale property is checked as follows:\n\\[\\begin{aligned}\n\\mathbf{E}[c(M_{t})|\\mathcal{F}_{s}] & \\geq c(\\mathbf{E}[M_{t}|\\mathcal{F}_{s}])=c(M_{s})\n\\end{aligned}\\] ◻\n\n\n(The Doob-Meyer Decomposition Theorem). Let \\((X_{n}:n\\in\\mathbf{N})\\) be a submartingale with respect to a filtration \\((\\mathcal{F}_{n}:n\\in\\mathbf{N})\\). Define a sequence of random variables \\((A_{n}:n\\in\\mathbf{N})\\) by \\(A_{0}=0\\) and\n\\[\\begin{aligned}\nA_{n} & =\\sum_{i=1}^{n}(\\mathbf{E}[X_{i}|\\mathcal{F}_{i-1}]-X_{i-1}),\\quad n\\geq1\n\\end{aligned}\\]\nNote that \\(A_{n}\\) is \\(\\mathcal{F}_{n-1}\\)-measurable. Moreover, since \\((X_{n}:n\\in\\mathbf{N})\\) is a submartingale, we have \\(\\mathbf{E}[X_{i}|\\mathcal{F}_{i-1}]-X_{i-1}\\geq0\\) almost surely. Hence, \\((A_{n}:n\\in\\mathbf{N})\\) is an increasing sequence almost surely. Let \\(M_{n}=X_{n}-A_{n}\\).\nWe have:\n\\[\\begin{aligned}\n\\mathbf{E}[M_{n}|\\mathcal{F}_{n-1}] & =\\mathbf{E}[X_{n}-A_{n}|\\mathcal{F}_{n-1}]\\\\\n& =\\mathbf{E}[X_{n}|\\mathcal{F}_{n-1}]-\\mathbf{E}[A_{n}|\\mathcal{F}_{n-1}]\\\\\n& =\\mathbf{E}[X_{n}|\\mathcal{F}_{n-1}]-\\mathbf{E}\\left[\\left.\\mathbf{E}[X_{n}|\\mathcal{F}_{n-1}]-X_{n-1}+A_{n-1}\\right|\\mathcal{F}_{n-1}\\right]\\\\\n& =\\mathbf{E}[X_{n}|\\mathcal{F}_{n-1}]-\\mathbf{E}[X_{n}|\\mathcal{F}_{n-1}]+\\mathbf{E}[X_{n-1}|\\mathcal{F}_{n-1}]-\\mathbf{E}[A_{n-1}|\\mathcal{F}_{n-1}]\\\\\n& =\\cancel{\\mathbf{E}[X_{n}|\\mathcal{F}_{n-1}]}-\\cancel{\\mathbf{E}[X_{n}|\\mathcal{F}_{n-1}]}+X_{n-1}-A_{n-1}\\\\\n& =M_{n-1}\n\\end{aligned}\\]\nThus, \\((M_{n}:n\\in\\mathbf{N})\\) is a martingale. Thus, we have obtained the Doob decomposition:\n\\[\\begin{aligned}\nX_{n} & =M_{n}+A_{n}\\label{eq:doob-decomposition}\n\\end{aligned}\\]\nThis decomposition of a submartingale as a sum of a martingale and an adapted increasing sequence is unique, if we require that \\(A_{0}=0\\) and that \\(A_{n}\\) is \\(\\mathcal{F}_{n-1}\\)-measurable.\nFor the continuous-time case, the situation is much more complicated. The analogue of equation ([eq:doob-decomposition]) is called the Doob-Meyer decomposition. We briefly describe this decomposition and avoid the technical details. All stochastic processes \\(X(t)\\) are assumed to be right-continuous with left-hand limits \\(X(t-)\\).\nLet \\(X(t)\\), \\(a\\leq t\\leq b\\) be a submartingale with respect to a right-continuous filtration \\((\\mathcal{F}_{t}:a\\leq t\\leq b)\\). If \\(X(t)\\) satisfies certain conditions, then it can be uniquely decomposed as:\n\\[\\begin{aligned}\nX(t) & =M(t)+C(t),\\quad a\\leq t\\leq b\n\\end{aligned}\\]\nwhere \\(M(t)\\), \\(a\\leq t\\leq b\\) is a martingale with respect to \\((\\mathcal{F}_{t};a\\leq t\\leq b)\\), \\(C(t)\\) is right-continuous and increasing almost surely with \\(\\mathbf{E}[C(t)]&lt;\\infty\\).\n\n\n(Square of a Poisson Process). Let \\((N_{t}:t\\geq0)\\) be a Poisson process with rate \\(\\lambda\\). We consider the compensated process \\(M_{t}=N_{t}-\\lambda t\\). By ([corollary:the-convex-function-of-martingale-is-a-submartingale]), the process \\((M_{t}^{2}:t\\geq0)\\) is a submartingale for the filtration \\((\\mathcal{F}_{t}:t\\geq0)\\) of the Poisson process. How should we compensated \\(M_{t}^{2}\\) to get a martingale? A direct computation using the properties of conditional expectation yields:\n\\[\\begin{aligned}\n\\mathbf{E}[M_{t}^{2}|\\mathcal{F}_{s}] & =\\mathbf{E}[(M_{t}-M_{s}+M_{s})^{2}|\\mathcal{F}_{s}]\\\\\n& =\\mathbf{E}[(M_{t}-M_{s})^{2}+2(M_{t}-M_{s})M_{s}+M_{s}^{2}|\\mathcal{F}_{s}]\\\\\n& =\\mathbf{E}[(M_{t}-M_{s})^{2}|\\mathcal{F}_{s}]+2\\mathbf{E}[(M_{t}-M_{s})M_{s}|\\mathcal{F}_{s}]+\\mathbf{E}[M_{s}^{2}|\\mathcal{F}_{s}]\\\\\n& =\\mathbf{E}[(M_{t}-M_{s})^{2}]+2M_{s}\\underbrace{\\mathbf{E}[M_{t}-M_{s}]}_{\\text{equals \\ensuremath{0}}}+M_{s}^{2}\\\\\n& =\\mathbf{E}[(M_{t}-M_{s})^{2}]+M_{s}^{2}\n\\end{aligned}\\]\nNow, if \\(X\\sim\\text{Poisson\\ensuremath{(\\lambda t)}}\\), then \\(\\mathbf{E}[X]=\\lambda t\\) and \\(\\mathbf{E}\\ensuremath{[X^{2}]}=\\lambda t(\\lambda t+1)\\).\n\\[\\begin{aligned}\n\\mathbf{E}[(M_{t}-M_{s})^{2}] & =\\mathbf{E}\\left[\\left\\{ (N_{t}-N_{s})-\\lambda(t-s)\\right\\} ^{2}\\right]\\\\\n& =\\mathbf{E}\\left[(N_{t}-N_{s})^{2}\\right]-2\\lambda(t-s)\\mathbf{E}\\left[(N_{t}-N_{s})\\right]+\\lambda^{2}(t-s)^{2}\\\\\n& =\\lambda^{2}(t-s)^{2}+\\lambda(t-s)-2\\lambda(t-s)\\cdot\\lambda(t-s)+\\lambda^{2}(t-s)^{2}\\\\\n& =\\lambda(t-s)\n\\end{aligned}\\]\nThus,\n\\[\\begin{aligned}\n\\mathbf{E}[M_{t}^{2}-\\lambda t|\\mathcal{F}_{s}] & =M_{s}^{2}-\\lambda s\n\\end{aligned}\\]\nWe conclude that the process \\((M_{t}^{2}-\\lambda t:t\\geq0)\\) is a martingale. The Doob-Meyer decomposition of the submartingale \\(M_{t}^{2}\\) is then:\n\\[\\begin{aligned}\nM_{t}^{2} & =(M_{t}^{2}-\\lambda t)+\\lambda t\n\\end{aligned}\\]\n\n\nConsider a Brownian motion \\(B(t)\\). The quadratic variation of the process \\((B(t):t\\geq0)\\) over the interval \\([0,t]\\) is given by \\([B]_{t}=t\\). On the other hand, we saw, that the square of Brownian motion compensated, \\((B_{t}^{2}-t:t\\geq0)\\) is a martingale. Hence, the Doob-Meyer decomposition of \\(B(t)^{2}\\) is given by:\n\\[\\begin{aligned}\nB(t)^{2} & =(B(t)^{2}-t)+t\n\\end{aligned}\\]"
  },
  {
    "objectID": "posts/martingales/index.html#computations-with-martingales.",
    "href": "posts/martingales/index.html#computations-with-martingales.",
    "title": "Martingales",
    "section": "",
    "text": "Martingales are not only conceptually interesting, they are also formidable tools to compute probabilities and expectations of processes. For example, in this section, we will solve the gambler’s ruin problem for Brownian motion. For convenience, we introduce the notion of stopping time before doing so.\n\n\n\nDefinition 1 (Stopping Time.) A random variable \\(\\tau:\\Omega\\to\\mathbf{N}\\cup\\{+\\infty\\}\\) is said to be a stopping time for the filtration \\((\\mathcal{F}_{t}:t\\geq0)\\) if and only if:\n\\[\\begin{aligned}\n\\{\\omega:\\tau(\\omega)\\leq t\\} & \\in\\mathcal{F}_{t},\\quad\\forall t\\geq0\n\\end{aligned}\\] Note that since \\(\\mathcal{F}_{t}\\) is a sigma-field, if \\(\\tau\\) is a stopping time, then we must also have that \\(\\{\\omega:\\tau(\\omega)&gt;t\\}\\in\\mathcal{F}_{t}\\).\nIn other words, \\(\\tau\\) is a stopping time, if we can decide if the events \\(\\{\\tau\\leq t\\}\\) occurred or not based on the information available at time \\(t\\).\nThe term stopping time comes from gambling: a gambler can decide to stop playing at a random time (depending for example on previous gains or losses), but when he or she decides to stop, his/her decision is based solely upon the knowledge of what happened before, and does not depend on future outcomes. In other words, the stopping policy/strategy can only depend on past outcomes. Otherwise, it would mean that he/she has a crystall ball.\n\n\n(Examples of stopping times).\n(i) First passage time. This is the first time when a process reaches a certain value. To be precise, let \\(X=(X_{t}:t\\geq0)\\) be a process and \\((\\mathcal{F}_{t}:t\\geq0)\\) be its natural filtration. For \\(a&gt;0\\), we define the first passage time at \\(a\\) to be:\n\\[\\begin{aligned}\n\\tau(\\omega) & =\\inf\\{s\\geq0:X_{s}(\\omega)\\geq a\\}\n\\end{aligned}\\]\nIf the path \\(\\omega\\) never reaches \\(a\\), we set \\(\\tau(\\omega)=\\infty\\). Now, for \\(t\\) fixed and for a given path \\(X(\\omega)\\), it is possible to know if \\(\\{\\tau(\\omega)\\leq t\\}\\) (the path has reached \\(a\\) before time \\(t\\)) or \\(\\{\\tau(\\omega)&gt;t\\}\\) (the path has not reached \\(a\\) before time \\(t\\)) with the information available at time \\(t\\), since we are looking at the first time the process reaches \\(a\\). Hence, we conclude that \\(\\tau\\) is a stopping time.\n(ii) Hitting time. More generally, we can consider the first time (if ever) that the path of a process \\((X_{t}:t\\geq0)\\) enters or hits a subset \\(B\\) of \\(\\mathbf{R}\\):\n\\[\\begin{aligned}\n\\tau(\\omega) & =\\min\\{s\\geq0:X_{s}(\\omega)\\in B\\}\n\\end{aligned}\\]\nThe first passage time is the particular case in which \\(B=[a,\\infty)\\).\n(iii) Minimum of two stopping times. If \\(\\tau\\) and \\(\\tau'\\) are two stopping times for the same filtration \\((\\mathcal{F}_{t}:t\\geq0)\\), then so is the minimum \\(\\tau\\land\\tau'\\) between the two, where\n\\[\\begin{aligned}\n(\\tau\\land\\tau')(\\omega) & =\\min\\{\\tau(\\omega),\\tau'(\\omega)\\}\n\\end{aligned}\\]\nThis is because for any \\(t\\geq0\\):\n\\[\\begin{aligned}\n\\{\\omega: & (\\tau\\land\\tau')(\\omega)\\leq t\\}=\\{\\omega:\\tau(\\omega)\\leq t\\}\\cup\\{\\omega:\\tau'(\\omega)\\leq t\\}\n\\end{aligned}\\]\nSince the right hand side is the union of two events in \\(\\mathcal{F}_{t}\\), it must also be in \\(\\mathcal{F}_{t}\\) by the properties of a sigma-field. We conclude that \\(\\tau\\land\\tau'\\) is a stopping time. Is it also the case that the maximum \\(\\tau\\lor\\tau'\\) is a stopping time?\nFor any fixed \\(t\\geq0\\), we have:\n\\[\\begin{aligned}\n\\{\\omega:(\\tau\\lor\\tau')(\\omega)\\leq t\\} & =\\{\\omega:\\tau(\\omega)\\leq t\\}\\cap\\{\\omega:\\tau'(\\omega)\\leq t\\}\n\\end{aligned}\\]\nSince the right hand side is the intersection of two events in \\(\\mathcal{F}_{t}\\), it must also be in \\(\\mathcal{F}_{t}\\) by the properties of a sigma-field. We conclude that \\(\\tau\\lor\\tau'\\) is a stopping time.\n\n\n(Last passage time is not a stopping time). What if we look at the last time the process reaches \\(a\\), that is:\n\\[\\begin{aligned}\n\\rho(\\omega) & =\\sup\\{t\\geq0:X_{t}(\\omega)\\geq a\\}\n\\end{aligned}\\]\nThis is a well-defined random variable, but it is not a stopping time. Based on the information available at time \\(t\\), we are not able to decide whether or not \\(\\{\\rho(\\omega)\\leq t\\}\\) occurred or not, as the path can always reach \\(a\\) one more time after \\(t\\).\n\nIt turns out that a martingale that is stopped when the stopping time is attained remains a martingale.\n\nProposition 1 (Stopped Martingale.) If \\((M_{t}:t\\geq0)\\) is a continuous martingale for the filtration \\((\\mathcal{F}_{t}:t\\geq0)\\) and \\(\\tau\\) is a stopping time for the same filtration, then the stopped process defined by\n\\[\\begin{aligned}\nM_{t\\land\\tau} & =\\begin{cases}\nM_{t} & t\\leq\\tau\\\\\nM_{\\tau} & t&gt;\\tau\n\\end{cases}\n\\end{aligned}\\]\nis also a continuous martingale for the same filtration.\n\nProof.\nLet \\((M_n,n=0,1,2,\\ldots)\\) be a martingale for the filtration \\((\\mathcal{F}_n,n\\geq 0)\\). Let \\(\\tau\\) be a stopping time for the same filtration and consider the martingale transform with the process:\n\\[\nX_n(\\omega) = \\begin{cases}\n1 & \\quad \\text{ if } n &lt; \\tau(\\omega) \\\\\n0   & \\quad \\text{ if } n \\geq \\tau(\\omega)\n\\end{cases}\n\\]\nThen, the stopped martingale \\((M_{t \\land \\tau},t\\geq 0)\\) can be written as an a martingale transform of the process \\((X_n)_{n=0}^{\\infty}\\).\n\\[\nM = \\sum_{j=0}^{n-1} X_j (M_{j+1} - M_j)\n\\]\nfor all \\(n=0,1,2,\\ldots\\). Invoking the property martingale transforms are continuous martingales, we have that \\(M_t = \\int X_t dM_t\\) must be a continous martingale. Consequently, the stopped process \\((M_{t \\land \\tau}, t\\geq 0)\\) must be a martingale. \\(\\blacksquare\\)\n\nTheorem 1 (Doob’s Optional Stopping Theorem.) If \\((M_{t}:t\\geq0)\\) is a continuous martingale for the filtration \\((\\mathcal{F}_{t}:t\\geq0)\\) and \\(\\tau\\) is a stopping time such that \\(\\tau&lt;\\infty\\) and the stopped process \\((M_{t\\land\\tau}:t\\geq0)\\) is bounded, then:\n\\[\\begin{aligned}\n\\mathbf{E}[M_{\\tau}] & =M_{0}\n\\end{aligned}\\]\n\nProof. Since \\((M_{\\tau\\land t}:t\\geq0)\\) is a martingale, we always have:\n\\[\\begin{aligned}\n\\mathbf{E}[M_{\\tau\\land t}] & =M_{0}\n\\end{aligned}\\]\nNow, since \\(\\tau(\\omega)&lt;\\infty\\), we must\nhave that \\(\\lim_{t\\to\\infty}M_{\\tau\\land t}=M_{\\tau}\\) almost surely. In particular, we have:\n\\[\\begin{aligned}\n\\mathbf{E}[M_{\\tau}] & =\\mathbf{E}\\left[\\lim_{t\\to\\infty}M_{\\tau\\land t}\\right]=\\lim_{t\\to\\infty}\\mathbf{E}[M_{\\tau\\land t}]=\\lim_{t\\to\\infty}M_{0}\n\\end{aligned}\\]\nwhere we passed to the limit, using the dominated convergence theorem. Recall, that the dominated convergence theorem allows us to commute abstract integration \\(\\int\\) and \\(\\lim_{n \\to \\infty}\\).\n\\(\\lim_{n \\to \\infty} \\int f_n = \\lim_{n \\to \\infty} \\int f_n\\) as long as the \\(f_n\\)’s are dominated. \\(\\blacksquare\\)\n\n\n\nThe gambler’s ruin problem is known in different forms. Roughly speaking, it refers to the problem of computing the probability of a gambler making a series of bets reaching a certain amount before going broke. In terms of Brownian motion (and stochastic processes in general), it translates to the following questions: Let \\((B_{t}:t\\geq0)\\) be a standard brownian motion starting at \\(B_{0}=0\\) and \\(a,b&gt;0\\).\n(1) What is the probability that a Brownian path reaches \\(a\\) before \\(-b\\)?\n(2) What is the expected waiting time for the path to reach \\(a\\) or \\(-b\\)?\nFor the first question, it is a simple computation using stopping time and martingale properties. Define the hitting time:\n\\[\\begin{aligned}\n\\tau(\\omega) & =\\inf\\{t\\geq0:B_{t}(\\omega)\\geq a\\text{ or }B_{t}(\\omega)\\leq-b\\}\n\\end{aligned}\\]\nNote that \\(\\tau\\) is the minimum between the first passage time at \\(a\\) and the one at \\(-b\\).\nWe first show that \\(\\tau&lt;\\infty\\) almost surely. In other words, all Brownian paths reach \\(a\\) or \\(-b\\) eventually. To see this, consider the event \\(E_{n}\\) that the \\(n\\)-th increment exceeds \\(a+b\\)\n\\[\\begin{aligned}\nE_{n} & :=\\left\\{ |B_{n}-B_{n-1}|&gt;a+b\\right\\}\n\\end{aligned}\\]\nNote that, if \\(E_{n}\\) occurs, then we must have that the Brownian motion path exits the interval \\([-b,a].\\) Moreover, we have \\(\\mathbb{P}(E_{n})=\\mathbb{P}(E_{1})\\) for all \\(n\\). Call this probability \\(p\\).\nSince the events \\(E_{n}\\) are independent, we have:\n\\[\\begin{aligned}\n\\mathbb{P}(E_{1}^{C}\\cap E_{2}^{C}\\cap\\ldots\\cap E_{n}^{C}) & =(1-p)^{n}\n\\end{aligned}\\]\nAs \\(n\\to\\infty\\) we have:\n\\[\\begin{aligned}\n\\lim_{n\\to\\infty}\\mathbb{P}(E_{1}^{C}\\cap E_{2}^{C}\\cap\\ldots\\cap E_{n}^{C}) & =0\n\\end{aligned}\\]\nThe sequence of events \\((F_{n})\\) where \\(F_{n}=E_{1}^{C}\\cap E_{2}^{C}\\cap\\ldots\\cap E_{n}^{C}\\) is a decreasing sequence of events. By the continuity of probability measure lemma, we conclude that:\n\\[\\begin{aligned}\n\\lim_{n\\to\\infty}\\mathbb{P}\\left(F_{n}\\right) & =\\mathbb{P}\\left(\\bigcap_{n=1}^{\\infty}F_{n}\\right)=0\n\\end{aligned}\\]\nTherefore, it must be the case \\(\\mathbb{P}(\\cup_{n=1}^{\\infty}E_{n})=1\\). So, \\(E_{n}\\) must occur for some \\(n\\), so all brownian motion paths reach \\(a\\) or \\(-b\\) almost surely.\nSince \\(\\tau&lt;\\infty\\) with probability one, the random variable \\(B_{\\tau}\\) is well-defined : \\(B_{\\tau}(\\omega)=B_{t}(\\omega)\\) if \\(\\tau(\\omega)=t\\). It can only take two values: \\(a\\) or \\(-b\\). Question (1) above translates into computing \\(\\mathbb{P}(B_{\\tau}=a)\\). On one hand, we have:\n\\[\\begin{aligned}\n\\mathbf{E}[B_{\\tau}] & =a\\mathbb{P}(B_{\\tau}=a)+(-b)(1-\\mathbb{P}(B_{\\tau}=a))\n\\end{aligned}\\]\nOn the other hand, by Doob’s optional stopping theorem (Theorem 1), we have \\(\\mathbf{E}[B_{\\tau}]=\\mathbf{E}[B_{0}]=0\\). (Note that the stopped process \\((B_{t\\land\\tau}:t\\geq0)\\) is bounded above by \\(a\\) and by \\(-b\\) below). Putting these two observations together, we get:\n\\[\\begin{aligned}\n\\mathbb{P}(B_{\\tau}=a) & =\\frac{b}{a+b}\n\\end{aligned}\\]\nA very simple and elegant answer!\nWe will revisit this problem again and again. In particular, we will answer the question above for Brownian motion with a drift at length further ahead.\n\n\nExample 1 (Expected Waiting Time.) Let \\(\\tau\\) be as in the last example. We now answer question (2) of the gambler’s ruin problem:\n\\[\\begin{aligned}\n\\mathbf{E}[\\tau] & =ab\n\\end{aligned}\\]\nNote that the expected waiting time is consistent with the rough heuristic that Brownian motion travels a distance \\(\\sqrt{t}\\) by time \\(t\\). We now use the martingale \\(M_{t}=B_{t}^{2}-t\\). On the one hand, if we apply optional stopping Theorem 1, we get:\n\\[\\begin{aligned}\n\\mathbf{E}[M_{\\tau}] & =M_{0}=0\n\\end{aligned}\\]\nMoreover, we know the distribution of \\(B_{\\tau}\\), thanks to the probability calculated in the last example. We can therefore compute \\(\\mathbf{E}[M_{\\tau}]\\) directly:\n\\[\\begin{aligned}\n0 & =\\mathbf{E}[M_{\\tau}]\\\\\n& =\\mathbf{E}[B_{\\tau}^{2}-\\tau]\\\\\n& =\\mathbf{E}[B_{\\tau}^{2}]-\\mathbf{E}[\\tau]\\\\\n& =a^{2}\\cdot\\frac{b}{a+b}+b^{2}\\cdot\\frac{a}{a+b}-\\mathbf{E}[\\tau]\\\\\n\\mathbf{E}[\\tau] & =\\frac{a^{2}b+b^{2}a}{a+b}\\\\\n& =\\frac{ab\\cancel{(a+b)}}{\\cancel{(a+b)}}=ab\n\\end{aligned}\\]\nWhy can we apply optional stopping here? The random variable \\(\\tau\\) is finite with probability \\(1\\) as before. However, the stopped martingale is not necessarily bounded as before: \\(B_{\\tau\\land t}\\) is bounded but \\(\\tau\\) is not. However, the conclusion of optional stopping still holds. Indeed, we have:\n\\[\\begin{aligned}\n\\mathbf{E}[M_{t\\land\\tau}] & =\\mathbf{E}[B_{t\\land\\tau}^{2}]-\\mathbf{E}[t\\land\\tau]\n\\end{aligned}\\]\nBy the bounded convergence theorem, we get \\(\\lim_{t\\to\\infty}\\mathbf{E}[B_{t\\land\\tau}^{2}]=\\mathbf{E}[\\lim_{t\\to\\infty}B_{t\\land\\tau}^{2}]=\\mathbf{E}[B_{\\tau}^{2}]\\). Since \\(\\tau\\land t\\) is a non-decreasing sequence and as \\(t\\to\\infty\\), \\(t\\land\\tau\\to\\tau\\) almost surely, as \\(\\tau&lt;\\infty\\), by the monotone convergence theorem, \\(\\lim_{t\\to\\infty}\\mathbf{E}[t\\land\\tau]=\\mathbf{E}[\\tau]\\).\n\n\nExample 2 (First passage time of Brownian Motion.) We can use the previous two examples to get some very interesting information on the first passage time:\n\\[\\begin{aligned}\n\\tau_{a} & =\\inf\\{t\\geq0:B_{t}\\geq a\\}\n\\end{aligned}\\]\nLet \\(\\tau=\\tau_{a}\\land\\tau_{-b}\\) be as in the previous examples with \\(\\tau_{-b}=\\inf\\{t\\geq0:B_{t}\\leq-b\\}\\). Note that \\((\\tau_{-b},b\\in\\mathbf{R}_{+})\\) is a sequence of random variables that is increasing in \\(b\\). A brownian motion path must cross through \\(-1\\) before it hits \\(-2\\) for the first time and in general \\(\\tau_{-n}(\\omega)\\leq\\tau_{-(n+1)}(\\omega)\\). Moreover, we have \\(\\tau_{-b}\\to\\infty\\) almost surely as \\(b\\to\\infty\\). That’s because, \\(\\mathbb{P}\\{\\tau&lt;\\infty\\}=1\\). Moreover, the event \\(\\{B_{\\tau}=a\\}\\) is the same as \\(\\{\\tau_{a}&lt;\\tau_{-b}\\}\\). Now, the events \\(\\{\\tau_{a}&lt;\\tau_{-b}\\}\\) are increasing in \\(b\\), since if a path reaches \\(a\\) before \\(-b\\), it will do so as well for a more negative value of \\(-b\\). On one hand, this means by the continuity of probability measure lemma ([th:continuity-property-of-lebesgue-measure]) that:\n\\[\\begin{aligned}\n\\lim_{b\\to\\infty}\\mathbb{P}\\left\\{ \\tau_{a}&lt;\\tau_{-b}\\right\\}  & =\\mathbb{P}\\{\\lim_{b\\to\\infty}\\tau_{a}&lt;\\tau_{-b}\\}\\\\\n& =\\mathbb{P}\\{\\tau_{a}&lt;\\infty\\}\n\\end{aligned}\\]\nOn the other hand, we have by example ([example:probability-of-hitting-times])\n\\[\\begin{aligned}\n\\lim_{b\\to\\infty}\\mathbb{P}\\left\\{ \\tau_{a}&lt;\\tau_{-b}\\right\\}  & =\\lim_{b\\to\\infty}\\mathbb{P}\\{B_{\\tau}=a\\}\\\\\n& =\\lim_{b\\to\\infty}\\frac{b}{b+a}\\\\\n& =1\n\\end{aligned}\\]\nWe just showed that:\n\\[\\begin{aligned}\n\\mathbb{P}\\left\\{ \\tau_{a}&lt;\\infty\\right\\}  & =1\\label{eq:first-passage-time-to-a-is-finite-almost-surely}\n\\end{aligned}\\]\nIn other words, every Brownian path will reach \\(a\\), no matter how large \\(a\\) is!\nHow long will it take to reach \\(a\\) on average? Well, we know from example ([ex:expected-waiting-times]) that \\(\\mathbf{E}[\\tau_{a}\\land\\tau_{-b}]=ab\\). On one hand this means,\n\\[\\begin{aligned}\n\\lim_{b\\to\\infty}\\mathbf{E}[\\tau_{a}\\land\\tau_{-b}] & =\\lim_{b\\to\\infty}ab=\\infty\n\\end{aligned}\\]\nOn the other hand, since the random variables \\(\\tau_{-b}\\) are increasing,\n\\[\\begin{aligned}\n\\lim_{b\\to\\infty}\\mathbf{E}[\\tau_{a}\\land\\tau_{-b}] & =\\mathbf{E}\\left[\\lim_{b\\to\\infty}\\tau_{a}\\land\\tau_{-b}\\right]=\\mathbf{E}[\\tau_{a}]\n\\end{aligned}\\]\nby the monotone convergence theorem ([th:monotone-convergence-theorem]). We just proved that:\n\\[\\begin{aligned}\n\\mathbf{E}[\\tau_{a}] & =\\infty\n\\end{aligned}\\]\nIn other words, any Brownian motion path will reach \\(a\\), but the expected waiting time for this to occur is infinite, no matter, how small \\(a\\) is! What is happening here? No matter, how small \\(a\\) is, there is always paths that reach very large negative values before hitting \\(a\\). These paths might be unlikely. However, the first passage time for these paths is so large that they affect the value of the expectation substantially. In other words, \\(\\tau_{a}\\) is a heavy-tailed random variable. We look at the distribution of \\(\\tau_{a}\\) in more detail in the next section.\n\n\n(When option stopping fails). Consider \\(\\tau_{a}\\), the first passage time at \\(a&gt;0\\). The random variable \\(B_{\\tau_{a}}\\) is well-defined since \\(\\tau_{a}&lt;\\infty\\). In fact, we have \\(B_{\\tau_{a}}=a\\) with probability one. Therefore, the following must hold:\n\\[\\begin{aligned}\n\\mathbf{E}[B_{\\tau_{a}}] & =a\\neq B_{0}\n\\end{aligned}\\]\nOptional stopping theorem corollary ([th:doob's-optional-sampling-theorem]) does not apply here, since the stopped process \\((B_{t\\land\\tau_{a}}:t\\geq0)\\) is not bounded. \\(B_{t\\land\\tau_{a}}\\) can become infinitely negative before hitting \\(a\\)."
  },
  {
    "objectID": "posts/martingales/index.html#reflection-principle-for-brownian-motion.",
    "href": "posts/martingales/index.html#reflection-principle-for-brownian-motion.",
    "title": "Martingales",
    "section": "",
    "text": "(Bachelier’s formula). Let \\((B_{t}:t\\leq T)\\) be a standard brownian motion on \\([0,T].\\) Then, the CDF of the random variable \\(\\sup_{0\\leq t\\leq T}B_{t}\\) is:\n\\[\\begin{aligned}\n\\mathbb{P}\\left(\\sup_{0\\leq t\\leq T}B_{t}\\leq a\\right) & =\\mathbb{P}\\left(|B_{T}|\\leq a\\right)\n\\end{aligned}\\]\nIn particular, its PDF is:\n\\[\\begin{aligned}\nf_{\\max}(a) & =\\frac{2}{\\sqrt{2\\pi T}}e^{-\\frac{a^{2}}{2T}}\n\\end{aligned}\\]\n\n\nWe can verify these results empirically. Note that the paths of the random variables \\(\\max_{0\\leq s\\leq t}B_{s}\\) and \\(|B_{t}|\\) are very different as \\(t\\) varies for a given \\(\\omega\\). One is increasing and the other is not. The equality holds in distribution for a fixed \\(t\\). As a bonus corollary, we get the distribution of the first passage time at \\(a\\).\n\n\nLet \\(a\\geq0\\) and \\(\\tau_{a}=\\inf\\{t\\geq0:B_{t}\\geq a\\}\\). Then:\n\\[\\begin{aligned}\n\\mathbb{P}\\left(\\tau_{a}\\leq T\\right) & =\\mathbb{P}\\left(\\max_{0\\leq t\\leq T}B_{t}\\geq a\\right)=\\int_{a}^{\\infty}\\frac{2}{\\sqrt{2\\pi T}}e^{-\\frac{x^{2}}{2T}}dx\n\\end{aligned}\\]\nIn particular, the random variable \\(\\tau_{a}\\) has the PDF:\n\\[\\begin{aligned}\nf_{\\tau_{a}}(t) & =\\frac{a}{\\sqrt{2\\pi}}\\frac{e^{-\\frac{a^{2}}{2t}}}{t^{3/2}},\\quad t&gt;0\n\\end{aligned}\\]\nThis implies that it is heavy-tailed with \\(\\mathbf{E}[\\tau_{a}]=\\infty\\).\n\n\nProof. Proof. The maximum on \\([0,T]\\) is larger than or equal to \\(a\\) if and only if \\(\\tau_{a}\\leq T\\). Therefore, the events \\(\\{\\max_{0\\leq t\\leq T}B_{t}\\geq a\\}\\) and \\(\\{\\tau_{a}\\leq T\\}\\) are the same. So, the CDF \\(\\mathbb{P}(\\tau_{a}\\leq t)\\) of \\(\\tau_{a}\\), by proposition ([prop:bacheliers-formula]) \\(\\int_{a}^{\\infty}f_{\\max}(x)dx=\\int_{a}^{\\infty}\\frac{2}{\\sqrt{2\\pi T}}e^{-\\frac{x^{2}}{2T}}dx\\).\n\\[\\begin{aligned}\nf_{\\tau_{a}}(t) & =-2\\phi(a/\\sqrt{t})\\cdot a\\cdot\\left(-\\frac{1}{2t^{3/2}}\\right)\\\\\n& =\\frac{a}{t^{3/2}}\\phi\\left(\\frac{a}{\\sqrt{t}}\\right)\\\\\n& =\\frac{a}{t^{3/2}}\\cdot\\frac{1}{\\sqrt{2\\pi}}e^{-\\frac{a^{2}}{2t}}\n\\end{aligned}\\]\nTo estimate the expectation, it suffices to realize that for \\(t\\geq1\\), \\(e^{-\\frac{a^{2}}{2t}}\\) is larger than \\(e^{-\\frac{a^{2}}{2}}\\). Therefore, we have:\n\\[\\begin{aligned}\n\\mathbf{E}[\\tau_{a}] & =\\int_{0}^{\\infty}t\\frac{a}{\\sqrt{2\\pi}}\\frac{e^{-a^{2}/2t}}{t^{3/2}}dt\\geq\\frac{ae^{-a^{2}/2}}{\\sqrt{2\\pi}}\\int_{1}^{\\infty}t^{-1/2}dt\n\\end{aligned}\\]\nThis is an improper integral and it diverges like \\(\\sqrt{t}\\) and is infinite as claimed. ◻\n\nTo prove proposition ([prop:bacheliers-formula]), we will need an important property of Brownian motion called the reflection principle. To motivate it, recall the reflection symmetry of Brownian motion at time \\(s\\) in proposition ([prop:brownian-motion-symmetry-of-reflection-at-time-s]). It turns out that this reflection property also holds if \\(s\\) is replaced by a stopping time.\n\n(Reflection principle). Let \\((B_{t}:t\\geq0)\\) be a standard Brownian motion and let \\(\\tau\\) be a stopping time for its filtration. Then, the process \\((\\tilde{B}_{t}:t\\geq0)\\) defined by the reflection at time \\(\\tau\\):\n\\[\\begin{aligned}\n\\tilde{B}_{t} & =\\begin{cases}\nB_{t} & \\text{if \\ensuremath{t\\leq\\tau}}\\\\\nB_{\\tau}-(B_{t}-B_{\\tau}) & \\text{if \\ensuremath{t&gt;\\tau}}\n\\end{cases}\n\\end{aligned}\\]\nis also a standard brownian motion.\n\n\nWe defer the proof of the reflection property of Brownian motion to a further section. It is intuitive and instructive to quickly picture this in the discrete-time setting. I adopt the approach as in Shreve-I.\nWe repeatedly toss a fair coin (\\(p\\), the probability of \\(H\\) on each toss, and \\(q=1-p\\), the probability of \\(T\\) on each toss, are both equal to \\(\\frac{1}{2}\\)). We denote the successive outcomes of the tosses by \\(\\omega_{1}\\omega_{2}\\omega_{3}\\ldots\\). Let\n\\[\\begin{aligned}\nX_{j} & =\\begin{cases}\n-1 & \\text{if \\ensuremath{\\omega_{j}=H}}\\\\\n+1 & \\text{if \\ensuremath{\\omega_{j}=T}}\n\\end{cases}\n\\end{aligned}\\]\nand define \\(M_{0}=0\\), \\(M_{n}=\\sum_{j=1}^{n}X_{n}\\). The process \\((M_{n}:n\\in\\mathbf{N})\\) is a symmetric random walk.\nSuppose we toss a coin an odd number \\((2j-1)\\) of times. Some of the paths will reach level \\(1\\) in the first \\(2j-1\\) steps and other will not reach. In the case of \\(3\\) tosses, there are \\(2^{3}=8\\) possible paths and \\(5\\) of these reach level \\(1\\) at some time \\(\\tau_{1}\\leq2j-1\\). From that moment on, we can create a reflected path, which steps up each time the original path steps down and steps down each time the original path steps up. If the original path ends above \\(1\\) at the final time \\(2j-1\\), the reflected path ends below \\(1\\) and vice versa. If the original path ends at \\(1\\), the reflected path does also. In fact, the reflection at the first hitting time has the same distribution as the original random walk.\nThe key here is, out of the \\(5\\) paths that reach level \\(1\\) at some time, there are as many reflected paths that exceed \\(1\\) at time \\((2j-1)\\) as there are original paths that exceed \\(1\\) at time \\((2j-1)\\). So, to count the total number of paths that reach level \\(1\\) by time \\((2j-1)\\), we can count the paths that are at \\(1\\) at time \\((2j-1)\\) and then add on twice the number of paths that exceed \\(1\\) at time \\((2j-1)\\).\n\nWith this new tool, we can now prove proposition ([prop:bacheliers-formula]).\n\nProof. Proof. Consider \\(\\mathbb{P}(\\max_{t\\leq T}B_{t}\\geq a)\\). By splitting this probability over the event of the endpoint, we have:\n\\[\\begin{aligned}\n\\mathbb{P}\\left(\\max_{t\\leq T}B_{t}\\geq a\\right) & =\\mathbb{P}\\left(\\max_{t\\leq T}B_{t}\\geq a,B_{T}&gt;a\\right)+\\mathbb{P}\\left(\\max_{t\\leq T}B_{t}\\geq a,B_{T}\\leq a\\right)\n\\end{aligned}\\]\nNote also, that \\(\\mathbb{P}(B_{T}=a)=0\\). Hence, the first probability equals \\(\\mathbb{P}(B_{T}\\geq a)\\). As for the second, consider the time \\(\\tau_{a}\\). On the event considered, we have \\(\\tau_{a}\\leq T\\) and using lemma ([lemma:BM-reflection-principle]) at that time, we get\n\\[\\begin{aligned}\n\\mathbb{P}\\left(\\max_{t\\leq T}B_{t}\\geq a,B_{T}\\leq a\\right) & =\\mathbb{P}\\left(\\max_{t\\leq T}B_{t}\\geq a,\\tilde{B}_{T}\\geq a\\right)\n\\end{aligned}\\]\nObserve that the event \\(\\{\\max_{t\\leq T}B_{t}\\geq a\\}\\) is the same as \\(\\{\\max_{t\\leq T}\\tilde{B}_{T}\\geq a\\}\\). (A rough picture might help here.) Thereforem the above probability is\n\\[\\begin{aligned}\n\\mathbb{P}\\left(\\max_{t\\leq T}B_{t}\\geq a,B_{T}\\leq a\\right) & =\\mathbb{P}\\left(\\max_{t\\leq T}\\tilde{B}_{t}\\geq a,\\tilde{B}_{T}\\geq a\\right)=\\mathbb{P}\\left(\\max_{t\\leq T}B_{t}\\geq a,B_{T}\\geq a\\right)\n\\end{aligned}\\]\nwhere the last equality follows from the reflection principle (\\(\\tilde{B}_{t}\\) is also a standard brownian motion, and \\(B_{T}\\) and \\(\\tilde{B}_{T}\\) have the same distribution.) But, as above, the last probability is equal to \\(\\mathbb{P}(B_{T}\\geq a)\\). We conclude that:\n\\[\\begin{aligned}\n\\mathbb{P}\\left(\\max_{t\\leq T}B_{t}\\geq a\\right) & =2\\mathbb{P}(B_{T}\\geq a)=\\frac{2}{\\sqrt{2\\pi T}}\\int_{a}^{\\infty}e^{-\\frac{x^{2}}{2T}}dx=\\mathbb{P}(|B_{T}|\\geq a)\n\\end{aligned}\\]\nThis implies in particular that \\(\\mathbb{P}\\left(\\max_{t\\leq T}B_{t}=a\\right)=0\\). Thus, we also have \\(\\mathbb{P}(\\max_{t\\leq T}B_{t}\\leq a)=\\mathbb{P}(|B_{T}|\\leq a)\\) as claimed. ◻"
  },
  {
    "objectID": "posts/martingales/index.html#numerical-simulations",
    "href": "posts/martingales/index.html#numerical-simulations",
    "title": "Martingales",
    "section": "",
    "text": "(Simulating Martingales) Sample \\(10\\) paths of the following process with a step-size of \\(0.01\\):\n(a) \\(B_{t}^{2}-t\\), \\(t\\in[0,1]\\)\n(b) Geometric Brownian motion : \\(S_{t}=\\exp(B_{t}-t/2)\\), \\(t\\in[0,1]\\).\nLet’s write a simple \\(\\texttt{BrownianMotion}\\) class, that we shall use to generate sample paths.\n\n\nimport numpy as np\nimport matplotlib.pyplot as plt\n\nimport attrs\nfrom attrs import define, field\n\n@define\nclass BrownianMotion:\n    _step_size = field(validator=attrs.validators.and_(attrs.validators.instance_of(float),\n                                                       attrs.validators.ge(0.0)))\n    # Time T\n    _T = field(validator=attrs.validators.and_(attrs.validators.instance_of(float),\n                                               attrs.validators.ge(0.0)))\n    # number of paths\n    _N = field(validator=attrs.validators.and_(attrs.validators.instance_of(int),\n                                               attrs.validators.gt(0)))\n\n    _num_steps = field(init=False)\n\n    def __attrs_post_init__(self):\n        self._num_steps = int(self._T/self._step_size)\n\n    def covariance_matrix(self):\n        C = np.zeros((self._num_steps,self._num_steps))\n\n        for i in range(self._num_steps):\n            for j in range(self._num_steps):\n                s = (i+1) * self._step_size\n                t = (j+1) * self._step_size\n                C[i,j] = min(s,t)\n        return C\n\n    # Each column vector represents a sample path\n    def generate_paths(self):\n        C = self.covariance_matrix()\n        A = np.linalg.cholesky(C)\n        Z = np.random.standard_normal((self._num_steps, self._N))\n        X = np.matmul(A,Z)\n        X = np.concatenate((np.zeros((1,self._N)),X),axis=0)\n        return X.transpose()\n\nNow, the process \\(B_{t}^{2}-t\\) can be sampled as follows:\n\ndef generateSquareOfBMCompensated(numOfPaths,stepSize,T):\n    N = int(T/stepSize)\n\n    X = []\n    brownianMotion = BrownianMotion(stepSize,T)\n    for n in range(numOfPaths):\n\n        B_t = brownianMotion.samplePath()\n\n        B_t_sq = np.square(B_t)\n\n        t = np.linspace(start=0.0,stop=1.0,num=N+1)\n        M_t = np.subtract(B_t_sq,t)\n        X.append(M_t)\n\n    return X\nThe gBM process can be sampled similarly, with \\(\\texttt{\\ensuremath{M_{t}} = np.exp(np.subtract(\\ensuremath{B_{t}},t/2))}\\).\n\n(Maximum of Brownian Motion.) Consider the maximum of Brownian motion on \\([0,1]\\): \\(\\max_{s\\leq1}B_{s}\\).\n(a) Draw the histogram of the random variable \\(\\max_{s\\leq1}B_{s}\\)using \\(10,0000\\) sampled Brownian paths with a step size of \\(0.01\\).\n(b) Compare this to the PDF of the random variable \\(|B_{1}|\\).\n\nSolution.\nI use the \\(\\texttt{itertools}\\) python library to compute the running maximum of a brownian motion path.\n\nbrownianMotion = BrownianMotion(stepSize=0.01,T=1)\ndata = []\n\nfor i in range(10000):\n    B_t = brownianMotion.samplePath()\n    max_B_t = list(itertools.accumulate(B_t,max))\n    data.append(max_B_t[100])\nAnalytically, we know that \\(B_{1}\\) is a gaussian random variable with mean \\(0\\) and variance \\(1\\).\n\\[\\begin{aligned}\n\\mathbb{P}(|B_{1}|\\leq z) & =\\mathbb{P}(|Z|\\leq z)\\\\\n& =\\mathbb{P}(-z\\leq Z\\leq z)\\\\\n& =\\mathbb{P}(Z\\leq z)-\\mathbb{P}(Z\\leq-z)\\\\\n& =\\mathbb{P}(Z\\leq z)-(1-\\mathbb{P}(Z\\leq z))\\\\\nF_{|B_{1}|}(z) & =2\\Phi(z)-1\n\\end{aligned}\\]\nDifferentiating on both sides, we get:\n\\[\\begin{aligned}\nf_{|B_{1}|}(z) & =2\\phi(z)=\\frac{2}{\\sqrt{2\\pi}}e^{-\\frac{z^{2}}{2}},\\quad z\\in[0,\\infty)\n\\end{aligned}\\]\n\n(First passage time.) Let \\((B_{t}:t\\geq0)\\) be a standard brownian motion. Consider the random variable:\n\\[\\begin{aligned}\n\\tau & =\\min\\{t\\geq0:B_{t}\\geq1\\}\n\\end{aligned}\\]\nThis is the first time that \\(B_{t}\\) reaches \\(1\\).\n(a) Draw a histogram for the distribution of \\(\\tau\\land10\\) on the time-interval \\([0,10]\\) using \\(10,000\\) brownian motion paths on \\([0,10]\\) with discretization \\(0.01\\).\nThe notation \\(\\tau\\land10\\) means that if the path does not reach \\(1\\) on \\([0,10]\\), then give the value \\(10\\) to the stopping time.\n(b) Estimate \\(\\mathbf{E}[\\tau\\land10]\\).\n(c) What proportion of paths never reach \\(1\\) in the time interval \\([0,10]\\)?\n\nSolution.\nTo compute the expectation, we classify the hitting times of all paths into \\(50\\) bins. I simply did\n\\(\\texttt{frequency, bins = np.histogram(firstPassageTimes,bins=50,range=(0,10))}\\)\nand then computed\n\\(\\texttt{expectation=np.dot(frequency,bins[1:])/10000}\\).\nThis expectation estimate on my machine is \\(\\mathbf{E}[\\tau\\land10]=4.34\\) secs. There were approximately \\(2600\\) paths out of \\(10,000\\) that did not reach \\(1\\)."
  },
  {
    "objectID": "posts/martingales/index.html#problems-and-puzzles",
    "href": "posts/martingales/index.html#problems-and-puzzles",
    "title": "Martingales",
    "section": "",
    "text": "Example 3 (Doob’s maximal inequalities.) We prove the following: Let \\((M_{k}:k\\geq1)\\) be positive submartingale for the filtration \\((\\mathcal{F}_{k}:k\\in\\mathbf{N})\\). Then, for any \\(1\\leq p&lt;\\infty\\) and \\(a&gt;0\\)\n\\[\\begin{aligned}\n\\mathbb{P}\\left(\\max_{k\\leq n}M_{k}&gt;a\\right) & \\leq\\frac{1}{a^{p}}\\mathbf{E}[M_{n}^{p}]\n\\end{aligned}\\]\n(a) Use Jensen’s inequality to show that if \\((M_{k}:k\\geq1)\\) is a positive submartingale, then so is \\((M_{k}^{p}:k\\geq1)\\) for \\(1\\leq p&lt;\\infty\\). Conclude that it suffices to prove the statement for \\(p=1\\).\n\nSolution.\nThe function \\(f(x)=x^{p}\\) is convex. By conditional Jensen’s inequality,\n\\[\\begin{aligned}\n\\left(\\mathbf{E}[M_{k+1}|\\mathcal{F}_{k}]\\right)^{p} & \\leq\\mathbf{E}[M_{k}^{p}|\\mathcal{F}_{k}]\n\\end{aligned}\\]\nThus,\n\\[\\begin{aligned}\n\\mathbf{E}[M_{k+1}^{p}|\\mathcal{F}_{k}] & \\geq\\left(\\mathbf{E}[M_{k+1}|\\mathcal{F}_{k}]\\right)^{p}\\geq M_{k}^{p}\n\\end{aligned}\\]\nwhere the last inequality follows from the fact that \\((M_{k}:k\\geq1)\\) is a positive submartingale, so \\(\\mathbf{E}[M_{k+1}|\\mathcal{F}_{k}]\\geq M_{k}\\). Consequently, \\((M_{k}^{p}:k\\geq1)\\) is also a positive submartingale.\n(b) Consider the events\n\\[\\begin{aligned}\nB_{k} & =\\bigcap_{j&lt;k}\\{\\omega:M_{j}(\\omega)\\leq a\\}\\cap\\{\\omega:M_{k}(\\omega)&gt;a\\}\n\\end{aligned}\\]\nArgue that the \\(B_{k}\\)’s are disjoint and that \\(\\bigcup_{k\\leq n}B_{k}=\\{\\max_{k\\leq n}M_{k}&gt;a\\}=B\\).\nSolution.\nClearly, \\(B_{k}\\) is the event that the first time to cross \\(a\\) is \\(k\\). If \\(B_{k}\\) occurs, \\(B_{k+1},B_{k+2},\\ldots\\) fail to occur. Hence, all \\(B_{k}'s\\) are pairwise disjoint. The event \\(\\bigcup_{k\\leq n}B_{k}\\) is the event that the random walk crosses \\(a\\) at any time \\(k\\leq n\\). Thus, the running maximum of the Brownian motion at time \\(n\\) exceeds \\(a\\).\n(c) Show that\n\\[\\begin{aligned}\n\\mathbf{E}[M_{n}]\\geq\\mathbf{E}[M_{n}\\mathbf{1}_{B}] & \\geq a\\sum_{k\\leq n}\\mathbb{P}(B_{k})=a\\mathbb{P}(B)\n\\end{aligned}\\]\nby decomposing \\(B\\) in \\(B_{k}\\)’s and by using the properties of expectations, as well as the submartingale property.\nSolution.\nClearly, \\(M_{n}\\geq M_{n}\\mathbf{1}_{B}\\geq a\\mathbf{1}_{B}\\). And \\(M_{n}\\) is a positive random variable. By monotonicity of expectations, \\(\\mathbf{E}[M_{n}]\\geq\\mathbf{E}[M_{n}\\mathbf{1}_{B}]\\geq a\\mathbf{E}[\\mathbf{1}_{B}]=a\\mathbb{P}(B)=a\\sum_{k\\leq n}\\mathbb{P}(B_{k})\\), where the last equality holds because the \\(B_{k}\\)’s are disjoint.\n(d) Argue that the inequality holds for continuous paths by discretizing time and using convergence theorems : If \\((M_{t}:t\\geq0)\\) is a positive submartingale with continuous paths for the filtration \\((\\mathcal{F}_{t}:t\\geq0)\\), then for any \\(1\\leq p&lt;\\infty\\) and \\(a&gt;0\\):\n\\[\\begin{aligned}\n\\mathbb{P}\\left(\\max_{s\\leq t}M_{s}&gt;a\\right) & \\leq\\frac{1}{a^{p}}\\mathbf{E}[M_{t}^{p}]\n\\end{aligned}\\]\nSolution.\nLet \\((M_{t}:t\\geq0)\\) be a positive submartingale with continuous paths for the filtration \\((\\mathcal{F}_{t}:t\\geq0)\\). Consider a sequence of partitions of the interval \\([0,t]\\) into \\(2^{r}\\) subintervals :\n\\[\\begin{aligned}\nD_{r} & =\\left\\{ \\frac{kt}{2^{r}}:k=0,1,2,\\ldots,2^{n}\\right\\}\n\\end{aligned}\\]\nAnd consider a sequence of discrete positive sub-martingales:\n\\[\\begin{aligned}\nM_{kt/2^{r}}^{(r)} & =M_{kt/2^{r}},\\quad k\\in\\mathbf{N},0\\leq k\\leq2^{r}\n\\end{aligned}\\]\nNext, we define for \\(r=1,2,3,\\ldots\\)\n\\[\\begin{aligned}\nA_{r} & =\\left\\{ \\sup_{s\\in D_{r}}|M_{s}^{(r)}|&gt;a\\right\\}\n\\end{aligned}\\]\nBy using the maximal inequality in discrete time, gives us:\n\\[\\begin{aligned}\n\\mathbb{P}(A_{r})=\\mathbb{P}\\left\\{ \\sup_{s\\in D_{r}}|M_{s}^{(r)}|&gt;a\\right\\}  & \\leq\\frac{1}{a^{p}}\\mathbf{E}\\left[\\left(M_{s}^{(r)}\\right)^{p}\\right]=\\frac{1}{a^{p}}\\mathbf{E}\\left[M_{t}^{p}\\right]\n\\end{aligned}\\]\n\\[\\begin{aligned}\n\\mathbb{P}\\left(\\max_{s\\leq t}M_{s}&gt;a\\right) & =\\mathbb{P}\\left(\\bigcup_{r=1}^{\\infty}A_{r}\\right)\\\\\n& =\\lim_{r\\to\\infty}\\mathbb{P}\\left(A_{r}\\right)\\\\\n& \\left\\{ \\text{Continuity of probability measure}\\right\\} \\\\\n& \\leq\\lim_{r\\to\\infty}\\frac{1}{a^{p}}\\mathbf{E}\\left[M_{t}^{p}\\right]\n\\end{aligned}\\]\n\nExample 4 Let \\((S_n,n=0,1,2,\\ldots)\\) be a simple random walk starting at \\(S_0 = 100\\) with \\(S_n = S_0 + X_1 + X_2 + \\ldots + X_n\\), where \\(P(X_i = 1) = p\\) and \\(P(X_i = -1) = q = 1 - p\\).\n\nProve that \\(M_n = \\left(\\frac{q}{p}\\right)^{S_n}\\) is a martingale.\nLet \\(\\tau = \\min\\{n \\geq 0 : S_n = 200 \\text{ or } S_n = 0\\}\\). Prove that \\(\\mathbb{E}[\\tau] &lt; \\infty\\).\nFind \\(P(S_\\tau = 200)\\).\n\n\nProof.\n\nClearly, \\((S_n, n=0,1,2,\\ldots)\\) is a martingale. For we have:\n\n\\[\n\\begin{align*}\n\\mathbb{E}\\left[\\left.\\frac{M_{n+1}}{M_n}\\right|\\mathcal{F}_n\\right] &= \\mathbb{E}\\left[\\left.\\left(\\frac{q}{p}\\right)\\right|\\mathcal{F}_n\\right]\\\\\n&= p\\frac{q}{p} + q \\frac{p}{q}\\\\\n&=1\n\\end{align*}\n\\]\nMultiplying both sides by \\(M_n\\), we have the desired result:\n\\[\n\\mathbb{E}[M_{n+1} | \\mathcal{F}_n] = M_n\n\\]"
  },
  {
    "objectID": "posts/kirks_approximation_a_numerical_experiment/index.html",
    "href": "posts/kirks_approximation_a_numerical_experiment/index.html",
    "title": "Margrabe’s formula",
    "section": "",
    "text": "Let \\(S_1(t)\\) and \\(S_2(t)\\) denote the prices of two risky assets which have dynamics:\n\\[\n\\begin{align*}\ndS_1(t)/ S_1(t) &= r dt + \\sigma_1 dW_1^{\\mathbb{Q}}(t) \\\\\ndS_2(t)/ S_2(t) &= r dt + \\sigma_2 dW_2^{\\mathbb{Q}}(t)\n\\end{align*}\n\\]\nwhere \\(r\\) is the constant risk-free rate, \\(W_1^{\\mathbb{Q}}(t)\\) and \\(W_2^{\\mathbb{Q}}(t)\\) are brownian motions with instantaneous correlation \\(\\rho\\).\nWe are interested to price the payoff\n\\[\nV_T = (S_1(T) - S_2(T))^+\n\\]\nBy the risk-neutral pricing formula,\n\\[\n\\begin{align*}\nV_0 &= M(0)\\mathbb{E}^{\\mathbb{Q}}\\left[\\frac{V(T)}{M(T)}\\right]\\\\\n&= S_2(0)\\mathbb{E}^{\\mathbb{Q}^{S_2}}\\left[\\frac{V(T)}{S_2(T)}\\right]\\\\\n& \\quad \\{\\text{Switching from }\\mathbb{Q}\\text{ to }\\mathbb{Q}^{S_2}\\text{-measure.}\\}\\\\\n&= S_2(0)\\mathbb{E}^{\\mathbb{Q}^{S_2}}\\left[\\frac{1}{S_2(T)}S_1(T) - S_2(T) 1_{S_1(T) &gt; S_2(T)}\\right]\\\\\n&= S_2(0)\\mathbb{E}^{\\mathbb{Q}^{S_2}}\\left[\\left(\\frac{S_1(T)}{S_2(T)} - 1 \\right) 1_{S_1(T) &gt; S_2(T)}\\right]\\\\\n\\end{align*}\n\\]\nDefine the asset price process \\(Y(t)\\) as:\n\\[\nY(t) := \\frac{S_1(t)}{S_2(t)}\n\\]\nSo, we want to compute the expectation\n\\[\nV_0 = S_2(0) \\mathbb{E}^{\\mathbb{Q}^{S_2}} \\left[(Y_T - 1)^+\\right]\n\\]\n\n\nWe know that \\((Y_t,t\\geq 0)\\) is a \\(\\mathbb{Q}^{S_2}\\) martingale. The \\(\\mathbb{Q}\\)-dynamics of \\((Y_t)\\) is:\n\\[\n\\begin{aligned}\ndY_{t} & =d\\left(\\frac{S_{1}( t)}{S_{2}( t)}\\right)\\\\\n& \\left\\{\\text{Applying Ito's product rule }\\right\\}\\\\\n& =S_{1}( t) d\\left(\\frac{1}{S_{2}( t)}\\right) +\\frac{1}{S_{2}( t)} dS_{1}( t) +dS_{1}( t) d\\left(\\frac{1}{S_{2}( t)}\\right)\\\\\n& =-S_{1}( t)\\left[\\frac{1}{S_{2}( t)^{2}} dS_{2}( t) +\\frac{1}{2}\\left(\\frac{2}{S_{2}( t)^{3}}\\right) dS_{2}( t) \\cdot dS_{2}( t)\\right] +\\frac{1}{S_{2}( t)}\\left( rS_{1}( t) dt+\\sigma _{1} S_{1}( t) dW_{1}^{\\mathbb{Q}}( t)\\right)\\\\\n& +S_{1}\\left( rdt+\\sigma _{1} dW_{1}^{\\mathbb{Q}}( t)\\right)\\left[ -\\frac{1}{S_{2}( t)^{2}} dS_{2}( t) +\\frac{1}{2}\\left(\\frac{2}{S_{2}( t)^{3}}\\right) dS_{2}( t) \\cdot dS_{2}( t)\\right]\\\\\n& =-\\frac{S_{1}( t)}{S_{2}( t)}\\left(\\cancel{rdt} +\\sigma _{2} dW_{2}^{\\mathbb{Q}}( t)\\right) -\\frac{S_{1}( t)}{S_{2}( t)} \\sigma _{2}^{2} dt+\\frac{S_{1}( t)}{S_{2}( t)}\\left(\\cancel{rdt} +\\sigma _{1} dW_{1}^{\\mathbb{Q}}( t)\\right)\\\\\n& +\\frac{S_{1}}{S_{2}}\\left( rdt+\\sigma _{1} dW_{1}^{\\mathbb{Q}}( t)\\right)\\left[ -\\left( rdt+\\sigma _{2} dW_{2}^{\\mathbb{Q}}( t)\\right) +\\sigma _{2}^{2} dt\\right]\\\\\n& =\\frac{S_{1}}{S_{2}}\\left[ -\\sigma _{2} dW_{2}^{\\mathbb{Q}}( t) +\\sigma _{1} dW_{1}^{\\mathbb{Q}}( t) -\\rho \\sigma _{1} \\sigma _{2} dt-\\sigma _{2}^{2} dt\\right]\\\\\n&=Y_t\\left[ -\\sigma _{2} dW_{2}^{\\mathbb{Q}}( t) +\\sigma _{1} dW_{1}^{\\mathbb{Q}}( t) -\\rho \\sigma _{1} \\sigma _{2} dt-\\sigma _{2}^{2} dt\\right]\n\\end{aligned}\n\\]\nSince we know, the \\(Y_t\\) is the price of \\(S_1(t)\\) expressed in units of \\(S_2(t)\\), it is a \\(\\mathbb{Q}^{S_2}\\)-martingale. So, we can just drop the \\((...)dt\\) terms and write:\n\\[\ndY_t = Y_t \\left[ -\\sigma_{2} dW_{2}^{\\mathbb{Q}^{S_2}}( t) +\\sigma_{1} dW_{1}^{\\mathbb{Q}^{S_2}}(t) \\right]\n\\]\nWe can perform an orthogonal decomposition of the correlated brownian motions \\(W_1^{\\mathbb{Q}^{S_2}}(t)\\) and \\(W_2^{\\mathbb{Q}^{S_2}}(t)\\) and write:\n\\[\n\\begin{align*}\ndY_t = Y_t \\left[ -\\sigma_{2} (\\rho dB_1^{\\mathbb{Q}^{S_2}} (t) + \\sqrt{1 - \\rho^2} dB_2^{\\mathbb{Q}^{S_2}}(t)) +\\sigma_{1} dB_{1}^{\\mathbb{Q}^{S_2}}(t) \\right]\\\\\ndY_t = Y_t \\left[(\\sigma_1 - \\rho \\sigma_2) dB_1^{\\mathbb{Q}^{S_2}} (t) - \\sigma_2 \\sqrt{1 - \\rho^2}dB_2^{\\mathbb{Q}^{S_2}}(t)\\right]\n\\end{align*}\n\\]\nDefine the process \\((X_t,t\\geq 0)\\) as:\n\\[\ndX_t = \\frac{1}{\\sigma} \\left[(\\sigma_1 - \\rho \\sigma_2) dB_1^{\\mathbb{Q}^{S_2}} (t) - \\sigma_2 \\sqrt{1 - \\rho^2}dB_2^{\\mathbb{Q}^{S_2}}(t)\\right]\n\\]\nwhere \\(\\sigma = \\sqrt{\\sigma_1^2 + \\sigma_2^2 - 2\\rho \\sigma_1 \\sigma_2}\\).\nIt follows that \\((X_t,t\\geq 0)\\) is a martingale and\n\\[\n\\begin{align*}\ndX_t \\cdot dX_t &=\\frac{1}{\\sigma^2}\\left[ \\sigma_2^2(\\rho dB_1^{\\mathbb{Q}^{S_2}} (t) + \\sqrt{1 - \\rho^2} dB_2^{\\mathbb{Q}^{S_2}}(t))^2 + \\sigma_1^2 dt - 2\\rho \\sigma_1 \\sigma_2 dt\\right]\\\\\n&=\\frac{1}{\\sigma^2}(\\sigma_1^2 + \\sigma_2^2 - 2\\rho \\sigma_1 \\sigma_2)dt \\\\\n&= dt\n\\end{align*}\n\\]\nBy Levy’s characterization theorem, \\((X_t,t\\geq 0)\\) is a standard brownian motion. Hence, \\((Y_t)\\) given by the SDE:\n\\[\ndY_t = \\sigma Y_t dX_t\n\\]\nfollows lognormal dynamics.\n\n\n\nWe can thus price the claim \\(\\mathbb{E}^{\\mathbb{Q}^{S_2}}\\left[(Y_T - 1)^+\\right]\\) using the Black formula for a european call option with the asset price given by \\(Y_t = S_1(t)/S_2(t)\\), strike \\(K = 1\\), the volatility parameter \\(\\sigma = \\sqrt{\\sigma_1^2 + \\sigma_2^2 - 2\\rho \\sigma_1 \\sigma_2}\\) and riskfree rate \\(r=0\\). Subbing these quantities in the Black formula, we have:\n\\[\n\\begin{align*}\nV(0) &= S_2(0) (F\\Phi(d_{+}) - K\\Phi(d_{-})) \\\\\n&= S_2(0)\\left(\\frac{S_1(0)}{S_2(0)}\\Phi(d_{+}) - \\Phi(d_{-})\\right)\\\\\n&=S_1(0)\\Phi(d_{+}) - S_2(0)\\Phi(d_{-})\n\\end{align*}\n\\]\nwhere\n\\[\nd_{\\pm} = \\frac{\\ln\\left(\\frac{S_1(0)}{S_2(0)}\\right) \\pm \\frac{\\sigma^2}{2}T}{\\sigma\\sqrt{T}}\n\\]"
  },
  {
    "objectID": "posts/kirks_approximation_a_numerical_experiment/index.html#margrabes-formula",
    "href": "posts/kirks_approximation_a_numerical_experiment/index.html#margrabes-formula",
    "title": "Margrabe’s formula",
    "section": "",
    "text": "Let \\(S_1(t)\\) and \\(S_2(t)\\) denote the prices of two risky assets which have dynamics:\n\\[\n\\begin{align*}\ndS_1(t)/ S_1(t) &= r dt + \\sigma_1 dW_1^{\\mathbb{Q}}(t) \\\\\ndS_2(t)/ S_2(t) &= r dt + \\sigma_2 dW_2^{\\mathbb{Q}}(t)\n\\end{align*}\n\\]\nwhere \\(r\\) is the constant risk-free rate, \\(W_1^{\\mathbb{Q}}(t)\\) and \\(W_2^{\\mathbb{Q}}(t)\\) are brownian motions with instantaneous correlation \\(\\rho\\).\nWe are interested to price the payoff\n\\[\nV_T = (S_1(T) - S_2(T))^+\n\\]\nBy the risk-neutral pricing formula,\n\\[\n\\begin{align*}\nV_0 &= M(0)\\mathbb{E}^{\\mathbb{Q}}\\left[\\frac{V(T)}{M(T)}\\right]\\\\\n&= S_2(0)\\mathbb{E}^{\\mathbb{Q}^{S_2}}\\left[\\frac{V(T)}{S_2(T)}\\right]\\\\\n& \\quad \\{\\text{Switching from }\\mathbb{Q}\\text{ to }\\mathbb{Q}^{S_2}\\text{-measure.}\\}\\\\\n&= S_2(0)\\mathbb{E}^{\\mathbb{Q}^{S_2}}\\left[\\frac{1}{S_2(T)}S_1(T) - S_2(T) 1_{S_1(T) &gt; S_2(T)}\\right]\\\\\n&= S_2(0)\\mathbb{E}^{\\mathbb{Q}^{S_2}}\\left[\\left(\\frac{S_1(T)}{S_2(T)} - 1 \\right) 1_{S_1(T) &gt; S_2(T)}\\right]\\\\\n\\end{align*}\n\\]\nDefine the asset price process \\(Y(t)\\) as:\n\\[\nY(t) := \\frac{S_1(t)}{S_2(t)}\n\\]\nSo, we want to compute the expectation\n\\[\nV_0 = S_2(0) \\mathbb{E}^{\\mathbb{Q}^{S_2}} \\left[(Y_T - 1)^+\\right]\n\\]\n\n\nWe know that \\((Y_t,t\\geq 0)\\) is a \\(\\mathbb{Q}^{S_2}\\) martingale. The \\(\\mathbb{Q}\\)-dynamics of \\((Y_t)\\) is:\n\\[\n\\begin{aligned}\ndY_{t} & =d\\left(\\frac{S_{1}( t)}{S_{2}( t)}\\right)\\\\\n& \\left\\{\\text{Applying Ito's product rule }\\right\\}\\\\\n& =S_{1}( t) d\\left(\\frac{1}{S_{2}( t)}\\right) +\\frac{1}{S_{2}( t)} dS_{1}( t) +dS_{1}( t) d\\left(\\frac{1}{S_{2}( t)}\\right)\\\\\n& =-S_{1}( t)\\left[\\frac{1}{S_{2}( t)^{2}} dS_{2}( t) +\\frac{1}{2}\\left(\\frac{2}{S_{2}( t)^{3}}\\right) dS_{2}( t) \\cdot dS_{2}( t)\\right] +\\frac{1}{S_{2}( t)}\\left( rS_{1}( t) dt+\\sigma _{1} S_{1}( t) dW_{1}^{\\mathbb{Q}}( t)\\right)\\\\\n& +S_{1}\\left( rdt+\\sigma _{1} dW_{1}^{\\mathbb{Q}}( t)\\right)\\left[ -\\frac{1}{S_{2}( t)^{2}} dS_{2}( t) +\\frac{1}{2}\\left(\\frac{2}{S_{2}( t)^{3}}\\right) dS_{2}( t) \\cdot dS_{2}( t)\\right]\\\\\n& =-\\frac{S_{1}( t)}{S_{2}( t)}\\left(\\cancel{rdt} +\\sigma _{2} dW_{2}^{\\mathbb{Q}}( t)\\right) -\\frac{S_{1}( t)}{S_{2}( t)} \\sigma _{2}^{2} dt+\\frac{S_{1}( t)}{S_{2}( t)}\\left(\\cancel{rdt} +\\sigma _{1} dW_{1}^{\\mathbb{Q}}( t)\\right)\\\\\n& +\\frac{S_{1}}{S_{2}}\\left( rdt+\\sigma _{1} dW_{1}^{\\mathbb{Q}}( t)\\right)\\left[ -\\left( rdt+\\sigma _{2} dW_{2}^{\\mathbb{Q}}( t)\\right) +\\sigma _{2}^{2} dt\\right]\\\\\n& =\\frac{S_{1}}{S_{2}}\\left[ -\\sigma _{2} dW_{2}^{\\mathbb{Q}}( t) +\\sigma _{1} dW_{1}^{\\mathbb{Q}}( t) -\\rho \\sigma _{1} \\sigma _{2} dt-\\sigma _{2}^{2} dt\\right]\\\\\n&=Y_t\\left[ -\\sigma _{2} dW_{2}^{\\mathbb{Q}}( t) +\\sigma _{1} dW_{1}^{\\mathbb{Q}}( t) -\\rho \\sigma _{1} \\sigma _{2} dt-\\sigma _{2}^{2} dt\\right]\n\\end{aligned}\n\\]\nSince we know, the \\(Y_t\\) is the price of \\(S_1(t)\\) expressed in units of \\(S_2(t)\\), it is a \\(\\mathbb{Q}^{S_2}\\)-martingale. So, we can just drop the \\((...)dt\\) terms and write:\n\\[\ndY_t = Y_t \\left[ -\\sigma_{2} dW_{2}^{\\mathbb{Q}^{S_2}}( t) +\\sigma_{1} dW_{1}^{\\mathbb{Q}^{S_2}}(t) \\right]\n\\]\nWe can perform an orthogonal decomposition of the correlated brownian motions \\(W_1^{\\mathbb{Q}^{S_2}}(t)\\) and \\(W_2^{\\mathbb{Q}^{S_2}}(t)\\) and write:\n\\[\n\\begin{align*}\ndY_t = Y_t \\left[ -\\sigma_{2} (\\rho dB_1^{\\mathbb{Q}^{S_2}} (t) + \\sqrt{1 - \\rho^2} dB_2^{\\mathbb{Q}^{S_2}}(t)) +\\sigma_{1} dB_{1}^{\\mathbb{Q}^{S_2}}(t) \\right]\\\\\ndY_t = Y_t \\left[(\\sigma_1 - \\rho \\sigma_2) dB_1^{\\mathbb{Q}^{S_2}} (t) - \\sigma_2 \\sqrt{1 - \\rho^2}dB_2^{\\mathbb{Q}^{S_2}}(t)\\right]\n\\end{align*}\n\\]\nDefine the process \\((X_t,t\\geq 0)\\) as:\n\\[\ndX_t = \\frac{1}{\\sigma} \\left[(\\sigma_1 - \\rho \\sigma_2) dB_1^{\\mathbb{Q}^{S_2}} (t) - \\sigma_2 \\sqrt{1 - \\rho^2}dB_2^{\\mathbb{Q}^{S_2}}(t)\\right]\n\\]\nwhere \\(\\sigma = \\sqrt{\\sigma_1^2 + \\sigma_2^2 - 2\\rho \\sigma_1 \\sigma_2}\\).\nIt follows that \\((X_t,t\\geq 0)\\) is a martingale and\n\\[\n\\begin{align*}\ndX_t \\cdot dX_t &=\\frac{1}{\\sigma^2}\\left[ \\sigma_2^2(\\rho dB_1^{\\mathbb{Q}^{S_2}} (t) + \\sqrt{1 - \\rho^2} dB_2^{\\mathbb{Q}^{S_2}}(t))^2 + \\sigma_1^2 dt - 2\\rho \\sigma_1 \\sigma_2 dt\\right]\\\\\n&=\\frac{1}{\\sigma^2}(\\sigma_1^2 + \\sigma_2^2 - 2\\rho \\sigma_1 \\sigma_2)dt \\\\\n&= dt\n\\end{align*}\n\\]\nBy Levy’s characterization theorem, \\((X_t,t\\geq 0)\\) is a standard brownian motion. Hence, \\((Y_t)\\) given by the SDE:\n\\[\ndY_t = \\sigma Y_t dX_t\n\\]\nfollows lognormal dynamics.\n\n\n\nWe can thus price the claim \\(\\mathbb{E}^{\\mathbb{Q}^{S_2}}\\left[(Y_T - 1)^+\\right]\\) using the Black formula for a european call option with the asset price given by \\(Y_t = S_1(t)/S_2(t)\\), strike \\(K = 1\\), the volatility parameter \\(\\sigma = \\sqrt{\\sigma_1^2 + \\sigma_2^2 - 2\\rho \\sigma_1 \\sigma_2}\\) and riskfree rate \\(r=0\\). Subbing these quantities in the Black formula, we have:\n\\[\n\\begin{align*}\nV(0) &= S_2(0) (F\\Phi(d_{+}) - K\\Phi(d_{-})) \\\\\n&= S_2(0)\\left(\\frac{S_1(0)}{S_2(0)}\\Phi(d_{+}) - \\Phi(d_{-})\\right)\\\\\n&=S_1(0)\\Phi(d_{+}) - S_2(0)\\Phi(d_{-})\n\\end{align*}\n\\]\nwhere\n\\[\nd_{\\pm} = \\frac{\\ln\\left(\\frac{S_1(0)}{S_2(0)}\\right) \\pm \\frac{\\sigma^2}{2}T}{\\sigma\\sqrt{T}}\n\\]"
  },
  {
    "objectID": "posts/kirks_approximation_a_numerical_experiment/index.html#references",
    "href": "posts/kirks_approximation_a_numerical_experiment/index.html#references",
    "title": "Margrabe’s formula",
    "section": "References",
    "text": "References\n\n\nMargrabe’s formula, Wikipedia."
  },
  {
    "objectID": "posts/ito-processes-and-stochastic-diff-eqs/index.html",
    "href": "posts/ito-processes-and-stochastic-diff-eqs/index.html",
    "title": "Ito Processes and Stochastic Differential Equations",
    "section": "",
    "text": "Let’s start with the definition of Ito processes.\n\nDefinition 1 (Ito Process) Let \\((B(t):t\\geq0)\\) be a standard brownian motion defined on \\((\\Omega,\\mathcal{F},\\mathbb{P})\\). An Ito process \\((X(t):t\\geq0)\\) is of the form:\n\\[\\begin{aligned}\nX(t) & =X(0)+\\int_{0}^{t}V(s)dB(s)+\\int_{0}^{t}D(s)ds\n\\end{aligned} \\tag{1}\\]\nwhere \\((V(t),t\\geq0)\\) and \\((D(t),t\\geq0)\\) are two adapted processes for which the integrals make sense in the sense of Ito and Riemann. We refer to \\((V(t):t\\geq0)\\) as the local volatility and to \\((D(t):t\\geq0)\\) as the local drift.\n\nWe will often denote an Ito process \\((X(t):t\\geq0)\\) in differential form as:\n\\[\\begin{aligned}\ndX(t) & =D(t)dt+V(t)dB(t)\n\\end{aligned} \\tag{2}\\]\nThis form makes no rigorous sense; when we write it, we mean Equation 1. Nevertheless, the differential equation has two great advantages:\n(1) It gives some intuition on what drives the variation of \\(X(t)\\). On one hand, there is a contribution of the Brownian increments which are modulated by the volatility \\(V(t)\\). On the other hand, there is a smoother contribution coming from the time variation which is modulated by the drift \\(D(t)\\).\n(2) The differential notation has computational power. In particular, evaluating Ito’s formula is reduced to computing differentials, as in classical calculus, but by doing it upto the second order.\nAn important class of Ito processes is given by processes for which the volatility and the drift are simply functions of the position of the process.\n\nDefinition 2 Let \\((B(t):t\\geq0)\\) be a standard Brownian motion. An Ito process \\((X(t):t\\geq0)\\) of the form\n\\[\\begin{aligned}\ndX(t) & =\\mu(X(t))dt+\\sigma(X(t))dB(t),\\quad X(0)=x\n\\end{aligned} \\tag{3}\\]\nwhere \\(\\mu\\) and \\(\\sigma\\) are functions from \\(\\mathbf{R}\\) to \\(\\mathbf{R}\\), is called a time-homogenous diffusion.\n\n\nDefinition 3 An Ito-process \\((Y(t),t\\geq0)\\) of the form:\n\\[\\begin{aligned}\n{1}\ndY(t) & =\\mu(t,X(t))dt+\\sigma(t,X(t))dB(t)\\quad Y(0)=y\n\\end{aligned} \\tag{4}\\]\nwhere \\(\\mu\\) and \\(\\sigma\\) are now functions \\([0,\\infty)\\times\\mathbf{R}\\to\\mathbf{R}\\) is called a time-inhomogenous diffusion.\n\nThe equations above are called stochastic differential equations (SDE) of the respective process \\((X(t))\\) and \\((Y(t))\\).\nIn other words, a diffusion \\((X(t),t\\geq 0)\\) is an Ito process whose local volatility \\(V(t)\\) and local drift \\(D(t)\\) at time \\(t\\) depend only on the position of the process at time \\(t\\) and possibly on the time \\(t\\) itself. It cannot depend on the path of the process before time \\(t\\) or on the explicit values of the driving Brownian motion at that time (which is not the process \\(X(t)\\) itself). The class of diffusions, and of the Ito processes in general, constitutes a huge collection of stochastic processes for stochastic modelling.\nNote that an SDE is a generalization of ordinary differential equations or ODEs. Indeed, if there were no randomness, that is, no Brownian motion, the SDE would be reduced to\n\\[\\begin{aligned}\ndX(t) & =\\mu(X(t))dt\n\\end{aligned}\\]\nThis can be written for \\(X(t)=f(t)\\) as:\n\\[\\begin{aligned}\n\\frac{df}{dt} & =\\mu(f)\n\\end{aligned}\\]\nThis is a first-order ordinary differential equation. It governs the deterministic evolution of the function \\(X(t)=f(t)\\) in time. An SDE adds a random term to this evolution that is formally written as:\n\\[\\begin{aligned}\n\\frac{dX}{dt} & =\\mu(X(t))+\\sigma(X(t))\\frac{dB(t)}{dt}\n\\end{aligned}\\]\nWe know very well, that Brownian motion is not differentiable; hence the above is not well-defined. The ill-defined term \\(dB(t)/dt\\) is sometimes called white noise. However, equation Equation 3 is well-defined in the sense of the Ito process. These types of equations are well-suited to model phenomena with intrinsic randomness.\nHere are some examples of diffusions:\n\nExample 1 (Brownian Motion with a drift). If we take \\(X(t)=\\sigma B(t)+\\mu t\\) for some \\(\\sigma&gt;0\\) and \\(\\mu\\in\\mathbf{R}\\), then we can write \\(X(t)\\) as:\n\\[\\begin{aligned}\nX(t) & =\\int_{0}^{t}\\sigma dB(t)+\\int_{0}^{t}\\mu dt,\\quad X(0)=0\n\\end{aligned}\\]\nIn the differential form this becomes\n\\[\\begin{aligned}\ndX(t) & =\\mu dt+\\sigma dB(t)\n\\end{aligned}\\]\nIn this case, the local drift and the local volatility are constant.\n\n\nExample 2 (Geometric Brownian Motion). We consider the process \\(S(t)=\\exp((\\mu-\\sigma^{2}/2)t+\\sigma B(t))\\). To find the stochastic differential equation, we apply the Ito’s Lemma to\n\\[\\begin{aligned}\nf(t,x) & =\\exp((\\mu-\\sigma^{2}/2)t+\\sigma x)\n\\end{aligned}\\]\nWe have:\n\\[\\begin{aligned}\ndf(t,x) & =\\left((\\mu-\\sigma^{2}/2)+\\frac{1}{2}\\sigma^{2}\\right)\\exp((\\mu-\\sigma^{2}/2)t+\\sigma x)dt+\\sigma\\exp((\\mu-\\sigma^{2}/2)t+\\sigma x)dB(t)\\\\\n& =\\mu S(t)dt+\\sigma S(t)dB(t)\n\\end{aligned}\\]\nNote that the local drift and the local volatility are now proportional to the position. So, the higher \\(S(t)\\), the higher the volatility and drift.\n\n\nExample 3 (Any smooth function of Brownian motion). Ito’s formula gurarantees that any smooth function \\(f(t,B(t))\\) of time and a Brownian motion is an Ito process with volatility \\(V(t)=\\partial_{t}f(t,B(t))\\) and drift \\(D(t)=\\partial_{x}f(t,B(t))+\\frac{1}{2}\\partial_{xx}f(t,B(t))\\). We will see in further ahead, that, in general, any reasonable function of an Ito process remains an Ito process.\n\n\nExample 4 (An Ito process that is not a diffusion) Consider the process\n\\[\\begin{aligned}\nX(t) & =\\int_{0}^{t}B^{2}(s)dB(s)\n\\end{aligned}\\]\nThis is an Ito process with local volatility \\(V(t)=B(t)^{2}\\) and local drift \\(D(t)=0\\). However, it is not a diffusion, because the local volatility is not an explicit function of \\(X(t)\\).\nIt turns out that the Brownian bridge is a time-inhomogenous diffusion and that the Ornstein-Uhlenbeck process is a time-homogenous diffusion. To understand these examples, we need to extend Ito’s formula to Ito processes.\n\n\n\nThe first step towards a general Ito’s formula is the quadratic variation of an Ito process.\n\nProposition 1 (Quadratic variation of an Ito process.) Let \\((B(t),t\\geq0)\\) be a standard Brownian motion and \\((X(t):t\\geq0)\\) be an Ito process of the form \\(dX(t)=V(t)dB(t)+D(t)dt\\). Then, the quadratic variation of the process \\((X(t):t\\geq0)\\) is:*\n\\[\\begin{aligned}\n&lt;X,X&gt;_{t} & =\\lim_{n\\to\\infty}\\sum_{j=0}^{n-1}(X(t_{j+1})-X(t_{j}))^{2}=\\int_{0}^{t}V(s)^{2}ds\n\\end{aligned} \\tag{5}\\]\nfor any partition \\((t_{j},j\\leq n)\\) of \\([0,t]\\), where the limit is in probability.\n\n\nNote that the quadratic variation is increasing in \\(t\\), but it is not deterministic in general! \\(V_t\\) is a random variable. The quadratic variation is a smooth stochastic process. (It is differentiable) Observe that we recover the quadratic variation for the Brownian motion for \\(V(t)=1\\) as expected. We also notice that the formula follows easily from the rules of Ito Calculus, thereby showing the consistency of the theory. Indeed we have:\n\\[\\begin{aligned}\nd&lt;X,X&gt;_{t} & =(dX(t))^{2}=(V(t)dB(t)+D(t)dt)^{2}\\\\\n& =V(t)^{2}(dB(t))^{2}+2V(t)D(t)dB(t)\\cdot dt+D^{2}(t)(dt)^{2}\\\\\n& =V(t)^{2}dt\n\\end{aligned}\\]\n\n\nProof. Proof. The proof is involved, but it reviews some important concepts of stochastic calculus. We prove the case when the process \\(V\\) is in \\(\\mathcal{L}_{c}^{2}(T)\\) for some \\(T&gt;0\\). We write \\(I(t)=\\int_{0}^{t}V(s)dB(s)\\) and \\(R(t)=\\int_{0}^{t}D(s)ds\\). We first show that only the Ito integral contributes to the quadratic variation and the Riemann integral does not contribute, so that:\n\\[\\begin{aligned}\n&lt;X,X&gt;_{t} & =&lt;I,I&gt;_{t}\n\\end{aligned} \\tag{6}\\]\nWe have that the increment square of \\(X(t)\\) is:\n\\[\\begin{aligned}\n(X(t_{j+1})-X(t_{j}))^{2} & =(I(t_{j+1})-I(t_{j}))^{2}+2(I(t_{j+1})-I(t_{j}))(R(t_{j+1})-R(t_{j}))+(R(t_{j+1})-R(t_{j}))^{2}\n\\end{aligned}\\]\nThe Cauchy-Schwarz inequality implies :\n\\[\\begin{aligned}\n\\sum_{j=0}^{n-1}(I(t_{j+1})-I(t_{j}))(R(t_{j+1})-R(t_{j})) & \\leq\\left(\\sum_{j=0}^{n-1}(I(t_{j+1})-I(t_{j}))^{2}\\right)^{1/2}\\left(\\sum_{j=0}^{n-1}(R(t_{j+1})-R(t_{j}))^{2}\\right)^{1/2}\n\\end{aligned}\\]\nTherefore, to prove equation Equation 5, it suffices to show that \\(\\sum_{j=0}^{n-1}(R(t_{j+1})-R(t_{j}))^{2}\\to 0\\) almost surely. Since \\(D(s)\\) is an almost surely continuous process, the stochastic process \\(R(t)=\\int_{0}^{t}D(s)ds\\) has continuous paths with probability \\(1\\). Therefore:\n\\[\\begin{aligned}\n\\sum_{j=0}^{n-1}(R(t_{j+1})-R(t_{j}))^{2} & =\\max_{1\\leq j\\leq n}|R(t_{j+1})-R(t_{j})|\\sum_{j=0}^{n-1}(R(t_{j+1})-R(t_{j}))\n\\end{aligned}\\]\nSince, \\(R(t)\\) is continuous on the compact set \\([0,t]\\), it is uniformly continuous a.s. So, as \\(|t_{j+1}-t_{j}|\\to 0\\), by uniform continuity it follows that \\(\\max|R(t_{j+1})-R(t_{j})|\\to 0\\) a.s.\nIt remains to prove that \\(&lt;I,I&gt;_{t}=\\int_{0}^{t}V(s)^{2}ds\\). We first prove the case when \\(V\\in\\mathcal{S}(T)\\) is a simple adapted process. Consider a partition \\((t_{j}:j\\leq n)\\) of \\([0,t]\\). Without loss of generality, we can suppose that \\(V\\) is constant on each \\([t_{j},t_{j+1})\\) by refining the partition. We then have:\n\\[\\begin{aligned}\n\\sum_{j=0}^{n-1}(I(t_{j+1})-I(t_{j}))^{2} & =\\sum_{j=0}^{n-1}V(t_{j})^{2}(B(t_{j+1})-B(t_{j}))^{2}\n\\end{aligned}\\]\nNow, we have seen in the proof of Ito’s formula that \\(\\mathbb{E}\\left[\\left\\{ \\sum_{j=0}^{n-1}V(t_{j})^{2}((B(t_{j+1})-B(t_{j}))^{2}-(t_{j+1}-t_{j})\\right\\} ^{2}\\right]\\to 0\\), so \\(\\sum_{j=0}^{n-1}V(t_{j})^{2}(B(t_{j+1})-B(t_{j}))^{2}\\) approaches \\(\\sum_{j=0}^{n-1}V(t_{j})^{2}(t_{j+1}-t_{j})\\) in the mean square sense. As the mesh size becomes finer, the \\(L^{2}\\)-limit is \\(\\int_{0}^{t}V(t)^{2}dt\\).\nThe case \\(V\\in\\mathcal{L}_{c}^{2}(T)\\) is proved by approximating \\(V\\) by a simple process in \\(\\mathcal{S}(T)\\). More precisely, we can find a simple process \\(V^{(\\epsilon)}(t)\\) that is \\(\\epsilon\\)-close to \\(V\\) in the sense:\n\\[\\begin{aligned}\n||I^{(\\epsilon)}-I|| & =||\\int V^{\\epsilon}dB(t)-\\int VdB(t)||=\\int_{0}^{t}\\mathbb{E}[(V^{(\\epsilon)}(t)-V(t))^{2}]ds&lt;\\epsilon\n\\end{aligned} \\tag{7}\\]\nTo prove the claim, we need to show that for \\(t\\leq T\\),\n\\[\\begin{aligned}\n\\mathbb{E}\\left[\\left|\\sum_{j=0}^{n-1}(I(t_{j+1})-I(t_{j}))^{2}-\\int_{0}^{t}(V(s))^{2}ds\\right|\\right] & \\to0\\quad\\text{as }\\quad n\\to\\infty\n\\end{aligned}\\]\n\\(L^{1}\\)-convergence implies convergence in probability of the sequence \\(\\sum_{j=0}^{n-1}(I(t_{j+1})-I(t_{j}))^{2}\\). We now introduce the \\(V^{(\\epsilon)}(t)\\) approximation inside the absolute value as well as its corresponding integral \\(I^{(\\epsilon)}(t)=\\int_{0}^{t}V^{(\\epsilon)}(s)ds\\). By the triangle inequality, we have:\n\\[\\begin{aligned}\n& \\mathbb{E}\\left[\\left|\\sum_{j=0}^{n-1}(I(t_{j+1})-I(t_{j}))^{2}-\\int_{0}^{t}(V(s))^{2}ds\\right|\\right]\\nonumber \\\\\n= & \\mathbb{E}\\left[\\Biggl|\\sum_{j=0}^{n-1}(I(t_{j+1})-I(t_{j}))^{2}-(I^{(\\epsilon)}(t_{j+1})-I^{(\\epsilon)}(t_{j}))^{2}+(I^{(\\epsilon)}(t_{j+1})-I^{(\\epsilon)}(t_{j}))^{2}-\\int_{0}^{t}(V^{(\\epsilon)}(s))^{2}ds\\right.\\nonumber \\\\\n& +\\int_{0}^{t}(V^{(\\epsilon)}(s))^{2}ds-\\int_{0}^{t}(V(s))^{2}ds\\Biggr|\\Biggr]\\nonumber \\\\\n\\leq & \\mathbb{E}\\left[\\left|\\sum_{j=0}^{n-1}(I(t_{j+1})-I(t_{j}))^{2}-(I^{(\\epsilon)}(t_{j+1})-I^{(\\epsilon)}(t_{j}))^{2}\\right|\\right]+\\mathbb{E}\\left[\\left|\\sum_{j=0}^{n-1}(I^{(\\epsilon)}(t_{j+1})-I^{(\\epsilon)}(t_{j}))^{2}-\\int_{0}^{t}(V^{(\\epsilon)}(s))^{2}ds\\right|\\right]\\\\\n& +\\mathbb{E}\\left[\\Biggl|\\int_{0}^{t}(V^{(\\epsilon)}(s))^{2}ds-\\int_{0}^{t}(V(s))^{2}ds\\Biggr|\\right]\\nonumber\n\\end{aligned} \\tag{8}\\]\nWe show that the first and third terms converge uniformly and that the second term goes to \\(0\\) as \\(n\\to\\infty\\).\nThe second term goes to \\(0\\) as \\(n\\to\\infty\\) by the argument for simple processes.\n\\(&lt;I^{(\\epsilon)},I^{(\\epsilon)}&gt;_{t}=\\int_{0}^{t}V^{(\\epsilon)}(s)^{2}ds\\).\nFor the third term, the linearity of the integral and the Cauchy Schwarz inequality (applied to \\(\\mathbb{E}\\int_{0}^{t}\\)) imply that it is:\n\\[\\begin{aligned}\n\\mathbb{E}\\left[\\Biggl|\\int_{0}^{t}(V^{(\\epsilon)}(s))^{2}ds-\\int_{0}^{t}(V(s))^{2}ds\\Biggr|\\right] & \\leq\\mathbb{E}\\left[\\Biggl|\\int_{0}^{t}(V^{(\\epsilon)}(s)-V(s))^{2}ds\\Biggr|\\right]^{1/2}\\mathbb{E}\\left[\\Biggl|\\int_{0}^{t}(V^{(\\epsilon)}(s)+V(s))^{2}ds\\Biggr|\\right]^{1/2}\n\\end{aligned}\\]\nThe first factor is smaller than the square root of \\(\\epsilon\\) by Equation 7, whereas the second factor is bounded.\nThe first term in equation Equation 8 is handled similarly. The linearity of the Ito integral and the Cauchy-Schwarz inequality applied to \\(\\mathbb{E}\\left[\\sum_{j=0}^{n-1}\\left(\\int_{t_{j}}^{t_{j+1}}\\cdot\\right)\\right]\\) give that the first term is:\n\\[\\begin{aligned}\n& \\mathbb{E}\\left[\\left|\\sum_{j=0}^{n-1}\\int_{t_{j}}^{t_{j+1}}(V(s))^{2}dB(s)-\\int_{t_{j}}^{t_{j+1}}(V^{\\epsilon}(s))^{2}dB(s)\\right|\\right]\\\\\n= & \\mathbb{E}\\left[\\left|\\sum_{j=0}^{n-1}\\int_{t_{j}}^{t_{j+1}}(V(s)-V^{\\epsilon}(s))dB(s)\\int_{t_{j}}^{t_{j+1}}(V(s)+V^{\\epsilon}(s))dB(s)\\right|\\right]\\\\\n\\leq & \\mathbb{E}\\left[\\sum_{j=0}^{n-1}\\left(\\int_{t_{j}}^{t_{j+1}}(V(s)-V^{\\epsilon}(s))dB(s)\\right)^{2}\\right]^{1/2}\\mathbb{E}\\left[\\Biggl|\\sum_{j=0}^{n-1}\\left(\\int_{t_{j}}^{t_{j+1}}(V(s)+V^{\\epsilon}(s))dB(s)\\right)^{2}\\Biggr|\\right]^{1/2}\n\\end{aligned}\\]\nBy Ito isometry, the first factor in the above expression can be simplified:\n\\[\\begin{aligned}\n\\mathbb{E}\\left[\\sum_{j=0}^{n-1}\\left(\\int_{t_{j}}^{t_{j+1}}(V(s)-V^{\\epsilon}(s))dB(s)\\right)^{2}\\right]^{1/2} & =\\sum_{j=0}^{n-1}\\mathbb{E}\\left(\\int_{t_{j}}^{t_{j+1}}(V(s)-V^{\\epsilon}(s))dB(s)\\right)^{2}\\\\\n& =\\sum_{j=0}^{n-1}\\int_{t_{j}}^{t_{j+1}}\\mathbb{E}[(V(s)-V^{\\epsilon}(s))^{2}]ds\n\\end{aligned}\\]\nBy Equation 7, this factor is smaller than \\(\\epsilon\\). The second factor equals \\(\\sum_{j=0}^{n-1}\\int_{t_{j}}^{t_{j+1}}\\mathbb{E}[(V(s)+V^{\\epsilon}(s))^{2}]ds\\) by Ito-isometry and is uniformly bounded. This concludes the proof of the proposition. \\(\\blacksquare\\)\n\nNote that quadratic variation \\(&lt;I,I&gt;_{t}=\\int(V(s))^{2}ds\\) is computed path-by-path and hence the result is random. On the other the variance of the Ito integral \\(Var(I(t))=\\mathbb{E}[I_{t}^{2}]=\\int\\mathbb{E}[V_{s}^{2}]ds\\) is the mean value of all possible paths of the quadratic variation and hence is non-random. We are now ready to state Ito’s formula for Ito processes. We write the result in differential form for conciseness.\n\nTheorem 1 (Ito’s formula for Ito processes) Let \\((B(t):t\\geq0)\\) be a standard brownian motion, and let \\((X(t):t\\geq0)\\) be an Ito process of the form \\(dX(t)=V(t)dB(t)+D(t)dt\\). Consider a function \\(f(t,x)\\in\\mathcal{C}^{1,2}([0,T]\\times\\mathbf{R})\\). Then we have with probability one for all \\(t\\leq T\\):*\n\\[\\begin{aligned}\ndf(t,X(t)) & =\\partial_{x}f(t,X(t))dX(t)+\\partial_{t}f(t,X(t))dt+\\frac{1}{2}\\partial_{xx}f(t,X(t))d&lt;X,X&gt;_{t}\n\\end{aligned}\\]\nThis can also be written as:\n\\[\\begin{aligned}\ndf(t,X(t))= & \\partial_{x}f(t,X(t))V(t)dB(t)+\\left[\\partial_{x}f(t,X(t))D(t)+\\partial_{t}f(t,X(t))+\\frac{1}{2}(V(t))^{2}\\partial_{xx}f(t,X(t))\\right]dt\n\\end{aligned}\\]\n\nThe proof of the Theorem 1 is again a Taylor approximation with the form of the quadratic variation of the process. We will omit it.\n\nExample 5 (Ornstein-Uhlenbeck Process). Consider the Ornstein-Uhlenbeck process \\((Y(t):t\\geq0)\\):\n\\[\\begin{aligned}\nY(t) & =Y(0)e^{-t}+e^{-t}\\int_{0}^{t}e^{s}dB(s)\n\\end{aligned}\\]\nNote that this process is an explicit function of \\(t\\) and of the Ito process \\(X(t)=Y(0)+\\int_{0}^{t}e^{s}dB(s)\\). Indeed, we have:\n\\[\\begin{aligned}\nY(t) & =e^{-t}X(t)\n\\end{aligned}\\]\nLet \\(f(t,x)=e^{-t}x\\). Then, \\(f_{x}(t,x)=e^{-t}\\), \\(f_{xx}(t,x)=0\\) and \\(f_{t}(t,x)=-e^{-t}x\\). So, by Ito’s lemma,\n\\[\\begin{aligned}\ndf(t,x) & =f_{t}(t,X(t))dt+f_{x}(t,X(t))dX(t)+\\frac{1}{2}f_{xx}(t,X(t))d&lt;X,X&gt;_{t}\\nonumber \\\\\ndY(t) & =-Y(t)dt+e^{-t}dX(t)\\nonumber \\\\\ndY(t) & =-Y(t)dt+e^{-t}(e^{t}dB(t))\\nonumber \\\\\ndY(t) & =-Y(t)dt+dB(t)\n\\end{aligned} \\tag{9}\\]\nThis is the SDE for the Ornstein Uhlenbeck process.\nThe SDE has a very nice interpretation: The drift is positive if \\(Y(t)&lt;0\\) and negative if \\(Y(t)&gt;0\\). Moreover, the drift is proportional to the position (exactly like a spring pulling the process back to the \\(x\\)-axis following the Hooke’s law!). This is the mechanism that ensures that the process does not venture too far from \\(0\\) and is eventually stationary.\nThe SDE Equation 9 is now easily generalized by adding two parameters for the volatility and the drift:\n\\[\\begin{aligned}\ndY(t) & =-kY(t)dt+\\sigma dB(t),\\quad k\\in\\mathbf{R},\\sigma&gt;0\n\\end{aligned} \\tag{10}\\]\nIt is not hard to check that the solution to the SDE is:\n\\[\\begin{aligned}\nY(t) & =Y(0)e^{-kt}+e^{-kt}\\int_{0}^{t}e^{ks}\\sigma dB(s)\n\\end{aligned} \\tag{11}\\]\n\n\nExercise 1 The Ornstein-Uhlenbeck process with parameters. Use the Ito’s formula to show that the Equation 11 is the solution to the Ornstein-Uhlenbeck SDE Equation 10.\n\nSolution.\nLet \\(X(t)=Y(0)+\\int_{0}^{t}e^{ks}\\sigma dB(s)\\), so \\(dX(t)=e^{kt}\\sigma dB(t)\\). Then, \\(Y(t)=e^{-kt}X(t)\\). Let \\(f(t,x)=e^{-kt}x\\). Then, by Ito’s formula:\n\\[\\begin{aligned}\ndf(t,x) & =-ke^{-kt}X(t)dt+e^{-kt}dX(t)\\\\\ndY(t) & =-kY(t)dt+e^{-kt}e^{kt}\\sigma dB(t)\\\\\ndY(t) & =-kY(t)dt+\\sigma dB(t)\n\\end{aligned}\\]\nThe latest version of Ito’s formula is another useful tool for producing martingales from a function of an Ito process. We start with two examples generalizing martingales for Brownian motion.\n\nExample 6 (A generalization of \\((B(t))^{2}-t\\)). Let \\((V(t):t\\leq T)\\) be a process in \\(\\mathcal{L}_{c}^{2}(T)\\). Consider an Ito process \\((X(t):t\\leq T)\\) given by \\(dX(t)=V(t)dB(t)\\). Note that \\(((X(t))^{2}:t\\leq T)\\) is a submartingale by Jensen’s inequality, since \\(\\mathbb{E}[X^{2}(t)|\\mathcal{F}_{s}]\\geq(\\mathbb{E}[X(t)|\\mathcal{F}_{s})^{2}=X^{2}(s)\\). We show that the compensated process\n\\[\\begin{aligned}\nM(t) & =X^{2}(t)-\\int_{0}^{t}V^{2}(s)ds,\\quad t\\leq T\n\\end{aligned}\\]\nis a martingale for the Brownian filtration. (This is another instance of the Doob-Meyer decomposition). By the Ito’s formula for \\(f(x)=x^{2}\\), we have:\n\\[\\begin{aligned}\ndf(x) & =f_{x}(X(t)dX(t)+\\frac{1}{2}f_{xx}(X(t))d&lt;X,X&gt;_{t}\\\\\n& =2X(t)dX(t)+(V(t))^{2}dt\\\\\ndf(X(t)) & =2X(t)V(t)dB(t)+(V(t))^{2}dt\n\\end{aligned}\\]\nIn Integral form this implies:\n\\[\\begin{aligned}\n(X(t))^{2} & =(X(0))^{2}+2\\int_{0}^{t}X(s)V(s)dB(s)+\\int_{0}^{t}(V(s))^{2}ds\\\\\nM(t)=(X(t))^{2}-\\int_{0}^{t}(V(s))^{2}ds & =(X(0))^{2}+2\\int_{0}^{t}X(s)V(s)dB(s)\n\\end{aligned}\\]\nWe conclude that \\((M(t):t\\leq T)\\) is a martingale, provided \\(X(t)V(t)\\in L_{c}^{2}(T)\\).\nThere is another more direct way to prove that \\((M(t):t\\leq T)\\) is a martingale whenever \\((V(t):t\\leq T)\\in\\mathcal{L}_{c}^{2}(T)\\). This is by using increments: for \\(t'&lt;t\\leq T\\),\n\\[\\begin{aligned}\n\\mathbb{E}[X_{t'}^{2}|\\mathcal{F}_{t}] & =\\mathbb{E}[(X_{t}+(X_{t'}-X_{t}))^{2}|\\mathcal{F}_{t}]\\\\\n& =\\mathbb{E}[X_{t}^{2}+2X_{t}(X_{t'}-X_{t})+(X_{t'}-X_{t})^{2}|\\mathcal{F}_{t}]\\\\\n& =X_{t}^{2}+2X_{t}\\mathbb{E}[X_{t'}-X_{t}|\\mathcal{F}_{t}]+\\mathbb{E}[(X_{t'}-X_{t})^{2}|\\mathcal{F}_{t}]\n\\end{aligned}\\]\nSince \\((X_{t}:t\\geq0)\\) is a martingale, \\(\\mathbb{E}[(X_{t'}-X_{t})|M_{t}]=0\\), so the middle term equals zero and we are left with:\n\\[\\begin{aligned}\n\\mathbb{E}[X_{t'}^{2}|\\mathcal{F}_{t}] & =X_{t}^{2}+\\mathbb{E}[(X_{t'}-X_{t})^{2}|\\mathcal{F}_{t}]\n\\end{aligned}\\]\nBy conditional Ito Isometry,\n\\[\\begin{aligned}\n\\mathbb{E}[(X_{t'}-X_{t})^{2}|\\mathcal{F}_{t}] & =\\int_{0}^{t'}V_{s}^{2}ds-\\int_{0}^{t}V_{s}^{2}ds=\\int_{t}^{t'}V_{s}^{2}ds\n\\end{aligned}\\]\n\n\nExample 7 (A generalization of the geometric Brownian motion). Let \\(\\sigma(t)\\) be a continuous, deterministic function such that \\(|\\sigma(t)|\\leq1\\), \\(t\\in[0,T]\\). The process\n\\[\\begin{aligned}\nM(t) & =\\exp\\left(\\int_{0}^{t}\\sigma(s)dB(s)-\\frac{1}{2}\\int_{0}^{t}\\sigma^{2}(s)ds\\right),\\quad t\\leq T\n\\end{aligned}\\]\nis a martingale for the Brownian filtration. To see this, note that we can write \\(M(t)=f(t,X(t))\\) where \\(f(t,x)=\\exp(x-\\frac{1}{2}\\int\\sigma^{2}(s)ds)\\) and \\(X(t)=\\int_{0}^{t}\\sigma(s)dB(s)\\), so \\(dX(t)=\\sigma(t)dB(t)\\). Ito’s formula gives:\n\\[\\begin{aligned}\ndf(t,x) & =f_{t}(t,X(t)dt+f_{x}(t,X(t))dX(t)+\\frac{1}{2}f_{xx}(t,X(t))d&lt;X,X&gt;_{t}\\\\\ndM(t) & =-\\frac{1}{2}\\sigma^{2}(t)M(t)dt+M(t)\\sigma(t)dB(t)+\\frac{1}{2}M(t)\\sigma^{2}(t)dt\\\\\n& =M(t)\\sigma(t)dB(t)\\\\\nM(t) & =M(0)+\\int_{0}^{t}M(s)\\sigma(s)dB(s)\n\\end{aligned}\\]\nObserve also that:\n\\[\\begin{aligned}\n\\mathbb{E}[M_{t}^{2}] & =e^{-\\int_{0}^{t}\\sigma^{2}(s)ds}\\mathbb{E}[e^{2\\int_{0}^{t}\\sigma(s)dB(s)}]=e^{\\int_{0}^{t}\\sigma^{2}(s)ds}\n\\end{aligned}\\]\nsince \\(\\int_{0}^{t}\\sigma(s)dB(s)\\) is a Gaussian random variable with mean \\(0\\) and variance \\(\\int_{0}^{t}\\sigma^{2}(s)ds\\).\nWe conclude from the equation that \\((M(t),t\\geq0)\\) is a martingale.\n\n\nExample 8 (Martingales of Geometric Brownian Motion). Let\n\\[\\begin{aligned}\nS(t) & =S(0)\\exp(\\sigma B(t)-\\sigma^{2}t/2)\n\\end{aligned}\\]\nbe a geometric brownian motion. We find a PDE satisfied by \\(f(t,x)\\) for \\(f(t,S(t))\\) to be a martingale. It suffices to apply Ito’s formula of Theorem 1. We get:\n\\[\\begin{aligned}\ndf(t,S(t)) & =f_{t}(t,S(t))dt+f_{x}(t,S(t))dS(t)+\\frac{1}{2}f_{xx}(t,S(t))dS(t)\\cdot dS(t)\n\\end{aligned}\\]\nNow note from the earlier result that \\(dS(t)=S(t)\\sigma dB(t)\\). So, \\(dS(t)\\cdot dS(t)=\\frac{1}{2}\\sigma^{2}(S(t))^{2}dt\\). So,\n\\[\\begin{aligned}\ndf(t,S(t)) & =\\left\\{ \\frac{\\partial f}{\\partial t}+\\frac{1}{2}\\sigma^{2}(S(t))^{2}\\frac{\\partial^{2}f}{\\partial x^{2}}\\right\\} dt+\\sigma S(t)\\frac{\\partial f}{\\partial x}dB(t)\n\\end{aligned}\\]\nFinally, the PDE for \\(f(t,x)\\) is obtained by setting the factor in front of \\(dt\\) to \\(0\\), because we want \\(f\\) to be a martingale process. It is important to keep in mind, that the PDE should always be written in terms of the time variable \\(t\\) and the space variable \\(x\\). Therefore, the PDE of \\(f\\) as a function of time and space is:\n\\[\\begin{aligned}\n\\frac{1}{2}\\sigma^{2}x^{2}\\frac{\\partial^{2}f}{\\partial x^{2}}(t,x)+\\frac{\\partial f}{\\partial t}(t,x) & =0\n\\end{aligned}\\]\nNo more randomness appears in the PDE!\n\nHere is a specific case where we can apply the Ito’s formula to construct martingales of Ito processes.\n\nExample 9 Consider the process given by the SDE:\n\\[\\begin{aligned}\ndX(t) & =X(t)dB(t),\\quad X(0)=2\n\\end{aligned}\\]\nLet’s find a PDE for which \\(f(t,X(t))\\) is a martingale for the Brownian filtration. We have by Ito’s formula that:\n\\[\\begin{aligned}\ndf(t,X(t)) & =f_{t}(t,X(t))dt+f_{x}(t,X(t))dX(t)+\\frac{1}{2}f_{xx}(t,X(t))d&lt;X,X&gt;_{t}\\\\\n& =\\left(\\frac{\\partial f}{\\partial t}+\\frac{1}{2}(X(t))^{2}\\frac{\\partial^{2}f}{\\partial x^{2}}\\right)dt+X(t)\\frac{\\partial f}{\\partial x}dB(t)\n\\end{aligned}\\]\nSetting the drift term to \\(0\\) gives the PDE:\n\\[\\begin{aligned}\n\\frac{\\partial f}{\\partial t}+\\frac{1}{2}x^{2}\\frac{\\partial^{2}f}{\\partial x^{2}} & =0\n\\end{aligned}\\]\nIt is then easy to check that \\(X(t)\\) is a martingale and so is \\(t+\\log(X(t))^{2}\\), since the functions \\(f(t,x)=x\\) and \\(f(t,x)=t+\\log x^{2}\\) satisfy the PDE. However, the process \\(tX(t)\\) is not, as the function \\(f(t,x)=xt\\) is not a solution of the PDE.\n\n\n\n\nIto’s formula can be generalized to several Ito processes. Let’s start by stating an example of a function of two Ito processes. Such a function \\(f(x_{1},x_{2})\\) will be a function of two space variables. Not surprisingly, it needs to have two derivatives in each variable and they need to be a continuous function; we need \\(f\\in\\mathcal{C}^{2\\times2}(\\mathbf{R}\\times\\mathbf{R})\\).\n\nTheorem 2 (Ito’s formula for many Ito processes) Let \\((X(t):t\\geq0)\\) and (Y(t):t)$ be two Ito processes of the form:\n\\[\\begin{aligned}\ndX(t) & =V(t)dB(t)+D(t)dt\\nonumber \\\\\ndY(t) & =U(t)dB(t)+R(t)dt\n\\end{aligned} \\tag{12}\\]\nwhere \\((B(t):t\\geq0)\\) is a standard Brownian motion. Then, for \\(f\\in\\mathcal{C}^{2\\times2}(\\mathbf{R}\\times\\mathbf{R})\\), we have:\n\\[\\begin{aligned}\ndf(X(t),Y(t)) & =f_{x}(X(t),Y(t))dX(t)+f_{y}(X(t),Y(t))dY(t)+\\frac{1}{2}f_{xx}(X(t),Y(t))d&lt;X,X&gt;_{t}\\\\\n& +f_{xy}(X(t),Y(t))d&lt;X,Y&gt;_{t}+\\frac{1}{2}f_{yy}(X(t),Y(t))d&lt;Y,Y&gt;_{t}\n\\end{aligned}\\]\n\nThe idea of the proof is the same as in Theorem 1 : Taylor’s expansion and quadratic variation, together with the cross-variation of two processes.\n\\[\\begin{aligned}\ndX(t)\\cdot dY(t) & =(V(t)dB(t)+D(t)dt)(U(t)dB(t)+R(t)dt)\\\\\n& =U(t)V(t)dt\n\\end{aligned}\\]\n\nExample 10 (Product Rule) An important example of this formula is Ito’s product rule. Let \\(X(t)\\) and \\(Y(t)\\) be as in Equation 12. Then:\n\\[\\begin{aligned}\nd(X(t)Y(t)) & =Y(t)dX(t)+X(t)dY(t)+dX(t)\\cdot dY(t)\n\\end{aligned}\\]\n\n\nExercise 2 Let \\((\\Omega,\\mathcal{F},\\mathbb{P})\\) be a probability space and let \\((B_{t}:t\\geq0)\\) be a standard brownian motion. Using integration by parts, show that\n\\[\\begin{aligned}\n\\int_{0}^{t}B(s)ds & =\\int_{0}^{t}(t-s)dB(s)\n\\end{aligned}\\]\nand prove that \\(\\int_{0}^{t}B(s)ds\\sim\\mathcal{N}(0,t^{3}/3)\\).\nIs\n\\[\\begin{aligned}\nX(t) & =\\begin{cases}\n0 & t=0\\\\\n\\frac{\\sqrt{3}}{t}\\int_{0}^{t}B(s)ds & t&gt;0\n\\end{cases}\n\\end{aligned}\\]\na standard Wiener process?\nSolution.\nClearly, \\(B(s,\\omega)\\) is a random variable and the Riemann integral \\(\\int_0^t B(s,\\omega)ds\\) depends on the sample path \\(\\omega\\). So, \\((\\int_0^t B_s ds, t\\leq T)\\) is a stochastic process. Using integration by parts:\n\\[\\begin{aligned}\n\\int u\\left(\\frac{dv}{ds}\\right)ds & =uv-\\int v\\left(\\frac{du}{ds}\\right)ds\n\\end{aligned}\\]\nWe set \\(u=B(s)\\) and \\(dv/ds=1\\). Then:\n\\[\\begin{aligned}\n\\int_{0}^{t}B(s)ds & =sB(s)|_{0}^{t}-\\int_{0}^{t}sdB(s)\\\\\n& =tB(t)-\\int_{0}^{t}sdB(s)\\\\\n& =\\int_{s=0}^{s=t}tdB(s)-\\int_{0}^{t}sdB(s)\\\\\n& =\\int_{0}^{t}(t-s)dB(s)\n\\end{aligned}\\]\nThus, \\(\\int_{0}^{t}B(s)ds\\) is a Gaussian random variable with:\n\\[\\begin{aligned}\n\\mathbb{E}\\left[\\int_{0}^{t}B(s)ds\\right] & =\\mathbb{E}\\left[\\int_{0}^{t}(t-s)dB(s)\\right]\\\\\n& =0\n\\end{aligned}\\]\nand\n\\[\\begin{aligned}\n\\mathbb{E}\\left[\\left(\\int_{0}^{t}B(s)ds\\right)^{2}\\right] & =\\int_{0}^{t}(t-s)^{2}ds\\\\\n& =\\left.\\frac{(t-s)^{3}}{-3}\\right|_{0}^{t}\\\\\n& =\\frac{t^{3}}{3}\n\\end{aligned}\\]\nThus, using the properties of Ito Integral, \\(\\int_{0}^{t}B(s)ds=\\int_{0}^{t}(t-s)dB(s)\\) is a martingale. Now the quadratic variation \\(&lt;M,M&gt;_{t}=0\\), and this can be a bit tricky. Remember, \\(\\left\\langle \\int_{0}^{t}f(s,B_{s})dB(s),\\int_{0}^{t}f(s,B_{s})dB(s)\\right\\rangle =\\int_{0}^{t}f^{2}(s,B_{s})ds\\) if and only if \\(f\\) is a function of the time \\(s\\) and the position of the Brownian motion \\(B(s)\\). Since, \\(f\\) is a function of \\(t\\) as well, this rule cannot be applied.\nBy first principles, we can show that, the quadratic variation is indeed \\(0\\): \\[\\begin{aligned}\n\\lim_{n\\to\\infty}\\mathbb{E}\\left[\\sum_{j=0}^{n-1}\\left(I(t_{j+1})-I(t_{j})\\right)^{2}\\right] & =\\lim_{n\\to\\infty}\\mathbb{E}\\left[\\sum_{j=0}^{n-1}B_{t_{j}}^{2}(t_{j+1}-t_{j})^{2}\\right]\\\\\n& =\\lim_{n\\to\\infty}\\max_{1\\leq j\\leq n}|t_{j+1}-t_{j}|\\cdot\\mathbb{E}\\left[\\sum_{j=0}^{n-1}B_{t_{j}}^{2}(t_{j+1}-t_{j})\\right]\n\\end{aligned}\\]\nSince the paths of \\(B_{t}\\) are continuous, so are the paths \\(B_{t}^{2}\\) on the compact interval \\([0,t]\\). So, \\((B_{s}^{2},s\\in[0,t])\\) is uniformly bounded. Thus, the expectation term is bounded. As \\(n\\to\\infty\\), the mesh size approaches zero, and consequently the quadratic variation approaches zero.\n\n\nExample 11 Let \\(X_{t}=\\int_{0}^{t}B_{s}dB_{s}\\) and \\(Y_{t}=\\int_{0}^{t}B_{s}^{2}dB_{s}\\). Is \\((X_{t}Y_{t},t\\geq0)\\) a martingale?\n\nSolution.\nBy Ito’s product rule, we have:\n\\[\\begin{aligned}\nd(X_{t}Y_{t}) & =X_{t}dY_{t}+Y_{t}dX_{t}+dX_{t}\\cdot dY_{t}\\\\\n& =X_{t}B_{s}^{2}dB_{s}+Y_{t}B_{s}dB_{s}+(B_{s}dB_{s})\\cdot(B_{s}^{2}dB_{s})\\\\\n& =X_{t}B_{s}^{2}dB_{s}+Y_{t}B_{s}dB_{s}+B_{s}^{3}dt\\\\\nX_{t}Y_{t} & =X_{0}Y_{0}+\\int_{0}^{t}X_{t}B_{s}^{2}dB_{s}+\\int_{0}^{t}Y_{t}B_{s}dB_{s}+\\int_{0}^{t}B_{s}^{3}dt\n\\end{aligned}\\]\nThe term in \\(dt\\) is not zero, so the product cannot be a martingale.\n\nExample 12 (A generalization of Geometric Brownian Motion). Consider \\((\\int_{0}^{t}V_{s}dB_{s},t\\geq0)\\) an Ito process. Define the positive process:\n\\[\\begin{aligned}\nM_{t} & =\\exp\\left(\\int_{0}^{t}V_{s}dB_{s}-\\frac{1}{2}\\int_{0}^{t}V_{s}^{2}ds\\right),\\quad t\\geq0\n\\end{aligned} \\tag{13}\\]\n\nSolution.\nIto’s formula applied to the processes \\(X_{t}=\\int_{0}^{t}V_{s}dB_{s}\\) and \\(Y_{t}=\\frac{1}{2}\\int_{0}^{t}V_{s}^{2}ds\\) with the function \\(f(x,y)=e^{x-y}\\) yields:\n\\[\\begin{aligned}\ndf(x,y) & =f_{x}(X_{t},Y_{t})dX_{t}+f_{y}(X_{t},Y_{t})dY_{t}\\\\\n& +\\frac{1}{2}f_{xx}(X_{t},Y_{t})dX_{t}\\cdot dX_{t}+\\frac{1}{2}f_{yy}(X_{t},Y_{t})dY_{t}\\cdot dY_{t}\\\\\n& +f_{xy}(X_{t},Y_{t})dX_{t}\\cdot dY_{t}\n\\end{aligned}\\]\nNow, all first and second order derivatives are \\(\\partial_{x}(e^{x-y})=M_{t}\\), \\(\\partial_{y}(e^{x-y})=-e^{x-y}=-M_{t}\\), \\(\\partial_{xx}(e^{x-y})=M_{t}\\)\n\\(dX_{t}=V_{t}dB_{t}\\). \\(dY_{t}=\\frac{1}{2}V_{t}^{2}dt\\).\n\\(dX_{t}\\cdot dX_{t}=V_{t}^{2}dt\\), \\(dX_{t}\\cdot dY_{t}=0\\),\n\\(dY_{t}\\cdot dY_{t}=0\\).\nConsequently, we have:\n\\[\\begin{aligned}\ndM_{t} & =M_{t}V_{t}dB_{t}-\\frac{1}{2}M_{t}V_{t}^{2}dt\\\\\n& +\\frac{1}{2}M_{t}V_{t}^{2}dt\\\\\n& =M_{t}V_{t}dB_{t}\n\\end{aligned}\\]\nThus, \\((M_{t},t\\geq0)\\) is a martingale.\n\nExercise 3 (Generalized Ito Integral). Let \\((\\Omega,\\mathcal{F},\\mathbb{P})\\) be a probability space and let \\((B_{t}:t\\geq0)\\) be a standard brownian motion. Given that \\(f\\) is a simple process, show that:\n\\[\\begin{aligned}\n\\int_{0}^{t}f(s,B_{s})dB_{s} & =B_{t}f(t,B_{t})-\\int_{0}^{t}\\left[B_{s}\\frac{\\partial f}{\\partial t}+\\frac{\\partial f}{\\partial x}+\\frac{1}{2}B_{s}\\frac{\\partial^{2}f}{\\partial x^{2}}\\right]ds\\\\\n& -\\int_{0}^{t}B_{s}\\frac{\\partial f}{\\partial x}dB_{s}\n\\end{aligned}\\]\nand\n\\[\\begin{aligned}\n\\int_{0}^{t}f(s,B_{s})ds & =tf(t,B_{t})-\\int_{0}^{t}s\\left[\\frac{\\partial f}{\\partial t}+\\frac{1}{2}\\frac{\\partial^{2}f}{\\partial x^{2}}\\right]ds-\\int_{0}^{t}s\\frac{\\partial f}{\\partial x}dB_{s}\n\\end{aligned}\\]\n\nSolution.\nI suppress \\((t,B_{t})\\) for simplicity. Applying the product rule to \\(B_{t}f\\), we get:\n\\[\\begin{aligned}\nd(B_{t}f) & =fdB_{t}+B_{t}df+dB_{t}\\cdot df\\\\\n& =fdB_{t}+B_{t}\\left(\\frac{\\partial f}{\\partial t}dt+\\frac{\\partial f}{\\partial x}dB_{t}+\\frac{1}{2}\\frac{\\partial^{2}f}{\\partial x^{2}}(dB_{t})^{2}\\right)\\\\\n& +dB_{t}\\cdot\\left(\\frac{\\partial f}{\\partial t}dt+\\frac{\\partial f}{\\partial x}dB_{t}+\\frac{1}{2}\\frac{\\partial^{2}f}{\\partial x^{2}}(dB_{t})^{2}\\right)\\\\\n& =fdB_{t}+\\left(B_{t}\\frac{\\partial f}{\\partial t}+\\frac{\\partial f}{\\partial x}+\\frac{1}{2}B_{t}\\right)dt+B_{t}\\frac{\\partial f}{\\partial x}dB_{t}\\\\\nB_{t}f & =\\int_{0}^{t}fdB_{s}+\\int_{0}^{t}\\left(B_{s}\\frac{\\partial f}{\\partial t}+\\frac{\\partial f}{\\partial x}+\\frac{1}{2}\\frac{\\partial^{2}f}{\\partial x^{2}}B_{s}\\right)ds+\\int_{0}^{t}B_{s}\\frac{\\partial f}{\\partial x}dB_{s}\\\\\n\\int_{0}^{t}fdB_{s} & =B_{t}f-\\int_{0}^{t}\\left(B_{s}\\frac{\\partial f}{\\partial t}+\\frac{\\partial f}{\\partial x}+\\frac{1}{2}\\frac{\\partial^{2}f}{\\partial x^{2}}B_{s}\\right)ds-\\int_{0}^{t}B_{s}\\frac{\\partial f}{\\partial x}dB_{s}\n\\end{aligned}\\]\nApplying product rule to \\(tf(t,B_{t})\\), we get:\n\\[\\begin{aligned}\nd(tf) & =fdt+tdf+dt\\cdot df\\\\\n& =fdt+t\\left(\\frac{\\partial f}{\\partial t}dt+\\frac{\\partial f}{\\partial x}dB_{t}+\\frac{1}{2}\\frac{\\partial^{2}f}{\\partial x^{2}}(dB_{t})^{2}\\right)\\\\\n& +dt\\left(\\frac{\\partial f}{\\partial t}dt+\\frac{\\partial f}{\\partial x}dB_{t}+\\frac{1}{2}\\frac{\\partial^{2}f}{\\partial x^{2}}(dB_{t})^{2}\\right)\\\\\n& =fdt+t\\left(\\frac{\\partial f}{\\partial t}+\\frac{1}{2}\\frac{\\partial^{2}f}{\\partial x^{2}}\\right)dt+t\\frac{\\partial f}{\\partial x}dB_{t}\\\\\ntf & =\\int_{0}^{t}fds+\\int_{0}^{t}s\\left(\\frac{\\partial f}{\\partial t}+\\frac{1}{2}\\frac{\\partial^{2}f}{\\partial x^{2}}\\right)ds+\\int_{0}^{t}s\\frac{\\partial f}{\\partial x}dB_{s}\\\\\n\\int_{0}^{t}fds & =tf-\\int_{0}^{t}s\\left(\\frac{\\partial f}{\\partial t}+\\frac{1}{2}\\frac{\\partial^{2}f}{\\partial x^{2}}\\right)ds-\\int_{0}^{t}s\\frac{\\partial f}{\\partial x}dB_{s}\n\\end{aligned}\\]\nThe following example will be important when we discuss the Girsanov theorem.\n\nTheorem 3 (Ito’s formula for many Ito processes) Let \\(X_t = (X_t^{(j)},j\\leq d,j\\in\\mathbf{N})\\) be Ito processes constructed on \\((\\Omega,\\mathcal{F},\\mathbb{P})\\) and \\(f \\in C^{1,2}([0,T]\\times \\mathbb{R}^d)\\). Then for \\(t \\in [0,T]\\), we have:\n\\[\ndf(t,X_t) = \\partial_t f(t,X_t) dt + \\sum_{j=1}^{d} \\partial_{x_j} f(t,X_t) dX_t^{(j)} + \\frac{1}{2}\\sum_{j=1}^{d} \\sum_{k=1}^d \\partial_{x_j x_k}^2 f(t,X_t) dX_t^{(j)}\\cdot dX_t^{(k)}\n\\]\n\n\n\n\nThe good news is that it is not too hard to implement iterative schemes to sample paths of a diffusion. Consider \\((X_t,t\\leq T)\\) a solution to the SDE:\n\\[\ndX_t = \\sigma(X_t) dB_t + \\mu(X_t) dt\n\\]\nTo keep the notation to a minimum, we consider a time-homogeonous diffusion. For a partition \\((t_j,j\\leq n)\\) of \\([0,T]\\) with \\(t_n = T\\), consider the increment\n\\[\nX_{t_{j+1}} - X_{t_j} = \\int_{t_j}^{t_{j+1}} \\sigma(X_s) dB(s) + \\int_{t_j}^{t_{j+1}} \\mu(X_s) ds\n\\tag{14}\\]\nNote that, if \\(\\sigma\\) and \\(\\mu\\) are smooth functions, we can apply Ito’s formula to \\(\\sigma(X_s)\\) and \\(\\mu(X_s)\\) for \\(s\\in (t_j,t_{j+1}]\\)! We get:\n\\[\n\\begin{align*}\n\\sigma(X_s) &= \\sigma(X_{t_j}) + \\int_{t_j}^{s}\\sigma'(X_u) dX_u + \\frac{1}{2}\\int_{t_j}^{s} \\sigma''(X_u)(dX_u)^2\\\\\n\\mu(X_s) &= \\mu(X_{t_j}) + \\int_{t_j}^{s}\\mu'(X_u) dX_u + \\frac{1}{2}\\int_{t_j}^{s} \\mu''(X_u)(dX_u)^2\n\\end{align*}\n\\tag{15}\\]\nNow, we can approximate the increment in Equation 14 at different levels of precision by considering a different estimate for Equation 15.\n\nExample 13 (Euler-Maruyama Scheme). This scheme consists of taking \\(\\sigma(X_s) \\approx \\sigma(X_{t_j})\\) and \\(\\mu(X_s) \\approx \\mu(X_{t_j})\\) for \\(s \\in [t_j,t_{j+1})\\) in Equation 15. Putting this back in Equation 14, we get:\n\\[\nX_{t_{j+1}} - X_{t_j} \\approx \\sigma(X_{t_j})(B_{t_{j+1}}-B_{t_j}) + \\mu(X_{t_j})(t_{j+1} - t_j)\n\\tag{16}\\]\nThe process \\(X_t\\) can then be constructed recursively on the discrete set \\((t_j,j \\leq n)\\) as follows:\n\\[\n\\begin{align*}\nX_0 &= x\\\\\nX_{t_1} &= (X_{t_1} - X_0) + X_0\\\\\nX_{t_2} &= (X_{t_2} - X_{t_1}) + (X_{t_1} - X_0) + X_0\\\\\n\\vdots\\\\\nX_{t_n} &= \\sum_{j=0}^{n-1}(X_{t_{j+1}} - X_{t_j}) + X_0\n\\end{align*}\n\\]\n\n\nExample 14 (Milstein Scheme). In this scheme, we go an order further for the approximation of the volatility in Equation 15 and consider also the integral in \\(dX_u\\). We take \\(dX_u = \\sigma(X_{t_j})dB_u\\). We then express \\(\\sigma(X_s)\\) in Equation 15 as:\n\\[\n\\begin{align*}\n\\sigma(X_s) &\\approx \\sigma(X_{t_j}) + \\int_{t_j}^{s} \\sigma'(X_{t_j}) (\\sigma(X_{t_j})dB_u)\\\\\n&= \\sigma(X_{t_j}) + \\sigma'(X_{t_j}) \\sigma(X_{t_j}) \\int_{t_j}^{s}  dB_u\\\\\n&= \\sigma(X_{t_j}) + \\sigma'(X_{t_j}) \\sigma(X_{t_j}) (B_s - B_{t_j})\n\\end{align*}\n\\]\nIf we put this back in Equation 14, we get:\n\\[\n\\begin{align*}\nX_{t_{j+1}} - X_{t_j} &\\approx \\sigma(X_{t_j})(B_{t_{j+1}}-B_{t_j}) + \\mu(X_{t_j})(t_{j+1} - t_j) \\\\\n&+ \\sigma'(X_{t_j}) \\sigma(X_{t_j}) \\int_{t_j}^{t_{j+1}} (B(s) - B(t_j))dB(s)\n\\end{align*}\n\\tag{17}\\]\nNow, consider the function \\(f(x)=x^2\\). We have:\n\\[\n\\begin{align*}\nf_x(x) &= 2x\\\\\nf_{xx}(x) &= 2\n\\end{align*}\n\\]\nSo, we get:\n\\[\nB^2(t_{j+1}) - B^2(t_j) = 2 \\int_{t_j}^{t_{j+1}} B(s) dB(s) + \\frac{1}{2} \\int_{t_j}^{t_{j+1}} (2) ds\n\\]\nThus,\n\\[\n\\int_{t_j}^{t_{j+1}} B(s) dB(s) = \\frac{1}{2}[(B_{t_{j+1}}^2 - B_{t_j}^2)-(t_{j+1}-t_j)]\n\\tag{18}\\]\nSubstituting Equation 18 into Equation 17, we get the Milstein approximation:\n\\[\n\\begin{align*}\nX_{t_{j+1}} - X_{t_j} &\\approx \\sigma(X_{t_j})(B_{t_{j+1}}-B_{t_j}) + \\mu(X_{t_j})(t_{j+1} - t_j) \\\\\n&+\\sigma'(X_{t_j}) \\sigma(X_{t_j})  \\left[\\frac{1}{2}((B_{t_{j+1}}^2 - B_{t_j}^2)-(t_{j+1}-t_j)) -  B_{t_j}(B_{t_{j+1}}-B_{t_j})\\right]\\\\\n&= \\sigma(X_{t_j})(B_{t_{j+1}}-B_{t_j}) + \\mu(X_{t_j})(t_{j+1} - t_j) \\\\\n&+ \\frac{\\sigma'(X_{t_j}) \\sigma(X_{t_j})}{2}  \\left[(B_{t_{j+1}}^2 - B_{t_j}^2)-(t_{j+1}-t_j) -  2B_{t_j}B_{t_{j+1}}+2B_{t_j}^2\\right]\\\\\n&= \\sigma(X_{t_j})(B_{t_{j+1}}-B_{t_j}) + \\mu(X_{t_j})(t_{j+1} - t_j) \\\\\n&+ \\frac{\\sigma'(X_{t_j}) \\sigma(X_{t_j})}{2}  \\left[(B_{t_{j+1}} - B_{t_j})^2-(t_{j+1}-t_j)\\right]\n\\end{align*}\n\\]\nThus, under the Milstein scheme\n\\[\n\\begin{align*}\nX_{t_{j+1}} - X_{t_j} &\\approx \\sigma(X_{t_j})(B_{t_{j+1}}-B_{t_j}) + \\mu(X_{t_j})(t_{j+1} - t_j) \\\\\n&+ \\frac{\\sigma'(X_{t_j}) \\sigma(X_{t_j})}{2}  \\left[(B_{t_{j+1}} - B_{t_j})^2-(t_{j+1}-t_j)\\right]\n\\end{align*}\n\\tag{19}\\]\nThe recursive nature of these two schemes makes them easy to implement numerically. The Milstein scheme is not much more costly to implement as it contains only one more term than the Euler scheme.\n\n\n\nLet’s code an SIVP class and an abstract base class Solver.\n\nfrom dataclasses import dataclass\nfrom abc import ABC, abstractmethod\nfrom typing import Callable, Optional\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nsns.set_style(\"whitegrid\")\n\n# More descriptive type hints\nT = np.ndarray\nX = np.ndarray\n\n@dataclass\nclass SIVP:\n    \"\"\"\n    An abstraction for a stochastic initial value problem\n    \"\"\"\n    t_start : float\n    t_end : float\n    initial_condition: float\n\n    drift: Callable[[float, np.ndarray], np.ndarray]\n    vol: Callable[[float, np.ndarray], np.ndarray]\n    dvol_dx: Optional[Callable[[float, np.ndarray], np.ndarray]] = None\n\n\n\n@dataclass\nclass Solver(ABC):\n    \"\"\"\n    An abstract base class for all numerical schemes\n    \"\"\"\n\n    num_steps: int = 100\n    num_paths: int = 100\n\n    def __post_init__(self):\n        self.iter = 0\n\n        # x_values is a matrix of shape [num_paths,num_steps]\n        self.x_values = np.zeros((self.num_paths, self.num_steps + 1))\n        self.step_size = 1.0 / self.num_steps\n\n        # gaussian increments\n        self.brownian_increments = np.sqrt(self.step_size) * np.random.standard_normal(\n            size=(self.num_paths, self.num_steps)\n        )\n        self.brownian = np.cumsum(self.brownian_increments, axis=1)\n        self.brownian = np.concatenate(\n            [np.zeros(shape=(self.num_paths, 1)), self.brownian], axis=1\n        )\n\n    @abstractmethod\n    def iterate(self, sivp: SIVP) -&gt; X:\n        \"\"\"\n        Compute the next iterate X(n+1)\n        \"\"\"\n\n    def solve(self, sivp: SIVP) -&gt; (T, X):\n        \"\"\"\n        Solve the SIVP\n        \"\"\"\n        self.x_values[:, 0] = np.full(\n            shape=(self.num_paths,), fill_value=sivp.initial_condition\n        )\n        while self.iter &lt; self.num_steps:\n            self.x_values[:, self.iter + 1] = self.iterate(sivp)\n            self.iter += 1\n\n        times = np.linspace(sivp.t_start, sivp.t_end, self.num_steps + 1)\n        return times, self.x_values\n\n    def reset(self):\n        self.__post_init__()\n\nThe EulerMaruyama and Milstein methods will derive from the abstract base class Solver.\n\n@dataclass\nclass EulerMaruyama(Solver):\n    \"\"\"\n    Numerical solver for a stochastic differential equation(SDE) using\n    the Euler-Maruyama method.\n\n    Consider an SDE of the form :\n\n    dX_t = mu(t,X_t) dt + sigma(t,X_t) dB_t\n\n    with initial condition X_0 = x_0\n\n    The solution to the SDE can be computed using the increments\n\n    X_{n+1} - X_n = mu(n,X_n)(t_{n+1}-t_n) + sigma(n,X_n)(B(n+1)-B(n))\n\n    \"\"\"\n\n    def iterate(self, sivp: SIVP) -&gt; X:\n        \"\"\"\n        Generate the next iterate X(n+1)\n        \"\"\"\n        current_time = self.iter * self.step_size\n        mu_n = sivp.drift(current_time, self.x_values[:, self.iter])\n        sigma_n = sivp.vol(current_time, self.x_values[:, self.iter])\n        delta_x = (\n            mu_n * self.step_size + sigma_n * self.brownian_increments[:, self.iter]\n        )\n        return self.x_values[:, self.iter] + delta_x\n\n\n@dataclass\nclass Milstein(Solver):\n    \"\"\"\n    Numerical solver for a stochastic differential equation(SDE) using\n    the Euler-Maruyama method.\n\n    Consider an SDE of the form :\n\n    dX_t = mu(t,X_t) dt + sigma(t,X_t) dB_t\n\n    with initial condition X_0 = x_0\n\n    The solution to the SDE can be computed using the increments\n\n    X_{n+1} - X_n = mu(n,X_n)(t_{n+1}-t_n) + sigma(n,X_n)(B(n+1)-B(n))\n    + 0.5 * sigma(n,X_n) * sigma'(n,X_n) * ((B(n+1) - B(n))**2 - (t_{n+1} - t_n))\n\n    \"\"\"\n\n    def iterate(self, sivp: SIVP):\n        \"\"\"\n        Generate the next iterate X(n+1)\n        \"\"\"\n        current_time = self.iter * self.step_size\n        mu_n = sivp.drift(current_time, self.x_values[:, self.iter])\n        sigma_n = sivp.vol(current_time, self.x_values[:, self.iter])\n        dvol_dx_n = sivp.dvol_dx(current_time, self.x_values[:, self.iter])\n\n        delta_x = (\n            mu_n * self.step_size\n            + sigma_n * self.brownian_increments[:, self.iter]\n            + 0.5\n            * sigma_n\n            * dvol_dx_n\n            * (self.brownian_increments[:, self.iter] ** 2 - self.step_size)\n        )\n\n        return self.x_values[:, self.iter] + delta_x\n\n\nExercise 4 (Simulating SDEs) Simulate 100 paths for the following diffusions given by their SDEs on \\([0,1]\\) using the Euler-Maruyama scheme and the Milstein scheme for a discretization of \\(0.01\\).\n\nGeometric Brownian Motion:\n\n\\[\ndS_t = S_t dB_t + \\left(\\mu + \\frac{\\sigma^2}{2}\\right)S_t dt, \\quad S_0 = 1\n\\]\nfor \\(\\mu=-1/2\\), \\(\\mu=-2\\), and \\(\\mu=0\\)\n\nOrnstein-Uhlenbeck process:\n\n\\[\ndX_t = -X_t dt + dB_t, \\quad X_0 = 1\n\\]\n\nThe diffusion:\n\n\\[\ndX_t = \\sqrt{1+X_t^2}dB_t + \\sin X_t dt, \\quad X_0 = 0\n\\]\n\nSolution.\nWe can now use EulerMaruyama and Milstein solvers and generate some sample paths.\n\n\nShow the code\ndef plot_trajectories(ts, xs, title):\n    plt.xlabel(r'Time $t$')\n    plt.ylabel(r'$X(t)$')\n    plt.title(title)\n    plt.grid(True)\n    plt.plot(ts, xs.transpose())\n    plt.show()\n\n# mu = -0.5 case\neuler = EulerMaruyama(num_paths=10, num_steps=100)\n\ngbm_sde = SIVP(\n    t_start=0.0,\n    t_end=1.0,\n    initial_condition=1.0,\n    drift=lambda t, s_t: np.zeros(10),\n    vol=lambda t, s_t: s_t,\n    dvol_dx=lambda t, s_t: np.ones(10),\n)\n\n\nts, xs = euler.solve(gbm_sde)\neuler.reset()\n\nplot_trajectories(ts, xs, r'10 sample paths of Geometric Brownian Motion, $\\mu=-0.5$')\n\n# mu = -2 case\ngbm_sde.drift = lambda t, s_t : -1.5 * s_t\nts, xs = euler.solve(gbm_sde)\neuler.reset()\n\nplot_trajectories(ts, xs, r'10 sample paths of Geometric Brownian Motion, $\\mu=-2.0$')\n\n# mu = 0 case\ngbm_sde.drift = lambda t, s_t : 0.5 * s_t\nts, xs = euler.solve(gbm_sde)\neuler.reset()\n\nplot_trajectories(ts, xs, r'10 sample paths of Geometric Brownian Motion, $\\mu=0.0$')\n\n# ornstein-uhlenbeck\nornstein_uhlenbeck_sde = SIVP(\n    t_start=0.0,\n    t_end=1.0,\n    initial_condition=1.0,\n    drift = lambda t, s_t : -s_t,\n    vol = lambda t, s_t : np.ones(10),\n    dvol_dx = lambda t, s_t : np.zeros(10)\n)\n\nts, xs = euler.solve(ornstein_uhlenbeck_sde)\neuler.reset()\n\nplot_trajectories(ts, xs, r'10 sample paths of Ornstein-Uhlenbeck')\n\n# diffusion\ndiffusion_sde = SIVP(\n    t_start=0.0,\n    t_end=1.0,\n    initial_condition=0.0,\n    drift = lambda t, s_t : np.sin(s_t),\n    vol = lambda t, s_t : np.sqrt(1+s_t**2),\n    dvol_dx = lambda t, s_t : s_t / np.sqrt(1 + s_t**2) \n)\n\nts,xs = euler.solve(diffusion_sde)\neuler.reset()\n\nplot_trajectories(ts, xs, r'10 sample paths of the diffusion')\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nIt is of course possible go beyond the Milstein scheme to improve the approximation. However, it turns out that the above schemes already converge quite rapidly to the process itself. To see this, consider the mean absolute error between the approximation \\(X_T^{(n)}\\) at time \\(T\\) and \\(X_T\\). Suppose that the approximation \\(X^{(n)}\\) is obtained for a partition with discretization \\(t_{j+1}-t_j = 1/n\\). It is possible to show that for the Euler scheme, we have:\n\\[\n\\begin{align*}\n\\mathbb{E}[|X_T^{(n)} - X_T|] \\leq \\frac{C}{\\sqrt{n}}\n\\end{align*}\n\\]\nwhereas for the Milstein scheme\n\\[\n\\begin{align*}\n\\mathbb{E}[|X_T^{(n)} - X_T|] \\leq \\frac{C'}{n}\n\\end{align*}\n\\]\nfor some constants \\(C,C'&gt;0\\). Note that the mean error between the two process must be the worst at the last point, since the errors add up.\n\n\n\n\nAs for the differential equations in standard calculus, SDEs play an important role in modelling stochastic phenomena. To model a trajectory \\(X_t, t\\leq T\\), it suffices to write down the variation due to the deterministic change \\(\\mu(X_t)dt\\) for some function \\(\\mu(X_t)\\) and the variation due to local fluctuations \\(\\sigma(X_t)dB_t\\) for some function \\(\\sigma(X_t)\\). Here, we assume that the local drift and volatility are time-homogenous for simplicity. This gives the SDE:\n\\[\ndX_t = \\mu(X_t) dt + \\sigma(X_t) dB_t\n\\]\nDo we get one nice Ito process for any choice of functions \\(\\sigma\\) and \\(\\mu\\)? The short answer is no. Here are sufficient conditions for the existence of a unique process.\n\nTheorem 4 (Existence and Uniqueness of solutions to SDE) Consider the SDE\n\\[\ndX_t = \\mu(X_t) dt  + \\sigma(X_t)dB_t, \\quad X_0 = x, \\quad t\\in [0,T]\n\\]\nIf the functions \\(\\sigma\\) and \\(\\mu\\) grow not faster than \\(Kx^2\\) for some \\(K&gt;0\\) and are differentiable with bounded derivatives on \\(\\mathbb{R}^1\\), then there exists a unique solution \\((X_t,t\\in[0,T])\\) to the SDE. In other words, there exists a continuous process \\((X_t, t \\leq T)\\) adapted to the filtration of the Brownian motion given by:\n\\[\nX_t = x + \\int_0^t \\mu(X_s) ds + \\int_0^t \\sigma(X_s) dB_s, \\quad t\\leq T\n\\]\n\n\nExample 15 Consider the SDE :\n\\[\ndX_t = \\sqrt{1 + X_t^2}dB_t + \\sin X_t dt\n\\tag{20}\\]\nThere exists a unique diffusion process \\((X_t,t\\geq 0)\\) that is a solution of this SDE. To see this, we verify the conditions of the Theorem 4. We have:\n\\[\n\\sigma(x) = \\sqrt{1 + x^2}, \\quad \\mu(x) = \\sin x\n\\]\nClearly, these functions satisfy the growth condition since \\(\\mu\\) is bounded and \\(\\sigma\\) grows like \\(|x|\\) for large \\(x\\). As for the derivatives, we have \\(\\sigma'(x)=\\frac{x}{\\sqrt{1+x^2}}\\) and \\(\\mu'(x)=\\cos x\\). The two derivatives are bounded.\n\nThe assumptions of Theorem 4 are not too surprising, since similar ones are found in the classical case of ODE. For example, if we have the ODE\n\\[\n\\frac{dX_t}{dt} = X_t^{1/2}, \\quad X_0 = 0\n\\]\nthen clearly \\(X_t = 0\\) for all \\(t\\) is a solution. But, we also have by integrating that:\n\\[\nX_t = \\frac{t^2}{4}, t \\geq 0\n\\]\nTherefore, the uniqueness breaks down. Note, that the function \\(\\mu(x)=\\sqrt{x}\\) does not have bounded derivatives at \\(0\\). Similarly, consider the ODE:\n\\[\n\\frac{dX_t}{dt} = e^{X_t}, X_0 = 0\n\\]\nHere, the function \\(\\mu(x)\\) grows much faster than \\(x^2\\). The solution of the ODE is by integrating\n\\[\n\\begin{align*}\n-(e^{-X_t} - 1) &= t\\\\\ne^{-X_t} &= (1 - t)\\\\\n-X_t &= \\log(1 - t)\\\\\nX_t &= \\log \\left(\\frac{1}{1-t}\\right)\n\\end{align*}\n\\]\nThe solution explodes at \\(t=1\\). The same phenomenon may occur for SDE; that is the process will almost surely go \\(\\infty\\) in finite time. These times are called explosion times. Note that it is possible to consider the paths of the diffusion upto these explosion times. It is important to keep in mind that the conditions of Theorem 4 are sufficient, but not necessary. In particular, it is sometimes possible to explicitly construct a diffusion whose local volatility and drift do not satisfy the conditions. Let’s look at two important instances of such diffusions.\n\nLet \\(B_t\\) be a brownian motion in \\(\\mathbb{R}^d\\) for \\(d&gt;1\\). Consider the process giving the distance at time \\(t\\) of \\(B_t\\) to the origin; that is:\n\\[\nR_t = ||B_t|| = \\left(\\sum_{j=1}^d B_t^{(j)}\\right)^2\n\\]\n(For \\(d=1\\), this is simply \\(|B_t|\\). Ito’s formula cannot be applied in this case, since the absolute value is not differentiable at the origin.) In higher dimensions, the function is smooth enough as long as we stay away from the origin. This is not a problem as long as \\(R_0 &gt; 0\\).\n\nLet’s find out the SDE that this process satisfies.\nLet \\(r=f(x_1,x_2,\\ldots,x_d)=\\sqrt{\\sum_{j=1}^d x_j^2}\\). We have:\n\\[\\begin{align*}\n\\frac{\\partial r}{\\partial x_j} &= \\frac{x_j}{\\sqrt{\\sum_{j=1}^d x_j^2}}\\\\\n\\frac{\\partial^2 r}{\\partial x_j^2} &= \\frac{||x|| - x_j \\cdot \\frac{x_j}{||x||}}{||x||^2}\\\\\n&= \\frac{||x||^2 - x_j^2}{||x||^3}\n\\end{align*}\\]\nBy Ito’s formula,\n\\[\\begin{align*}\ndR_t &= \\sum_{j=1}^{d} \\frac{B_t^{j}}{R_t} dB_t^{(j)} + \\frac{1}{2} \\sum_{j=1}^{d} \\frac{R_t^2 - (B_t^{(j)})^2}{R_t^3}\\\\\n&= \\sum_{j=1}^{d} \\frac{B_t^{j}}{R_t} dB_t^{(j)} + \\frac{1}{2} \\frac{d R_t^2 - R_t^2}{R_t^3}\\\\\n&= \\sum_{j=1}^{d} \\frac{B_t^{j}}{R_t} dB_t^{(j)} + \\frac{1}{2} \\frac{(d-1)}{R_t}\n\\end{align*}\\]\nWe can define \\(dW_t = \\sum_{j=1}^{d} \\frac{B_t^{(j)}}{R_t} dB_t^{(j)}\\). Then, \\(dR_t = dW_t + \\frac{d-1}{2R_t}dt\\)\nIt turns out that \\((W_t,t \\geq 0)\\) is a standard Brownian motion by Levy’s characterization theorem. This is the subject of the next section. The SDE shows that \\(dR_t\\) is a diffusion. The SDE makes sense for any real number \\(d &gt; 1\\), not only integers. Moreover, the SDE is well-defined since \\(R_t\\) is never equal to \\(0\\). However, the SDE does not satisfy the assumption of the existence and uniqueness of the solution of SDEs since \\(1/x\\) diverges at \\(0\\). The solution to the SDE still exists since we constructed it! We sample paths of this process in numerical project.\n\nExample 16 (The Cox-Ingersoll-Ross (CIR) model.) Consider the SDE:\n\\[\ndS_t = \\sigma \\sqrt{S_t} dW_t + (a - bS_t)dt, \\quad S_0 &gt; 0\n\\tag{21}\\]\nfor some parameters \\(a,b &gt; 0\\) where \\((W_t,t \\geq 0)\\) is a standard Brownian motion. The local volatility \\(\\sigma(x)=\\sigma \\sqrt{x}\\) does not have a bounded derivative close to \\(0\\), since \\(\\sigma'(x)=\\frac{\\sigma}{2\\sqrt{x}}\\). We will nevertheless construct a diffusion that is a solution to the SDE. Consider independent Ornstein-Uhlenbeck processes \\(X_t^{(j)}, j \\leq d\\), with SDE:\n\\[\ndX_t^{(j)} = \\frac{-b}{2}X_t^{(j)}dt + \\frac{\\sigma}{2}dB_t^{(j)}, \\quad X_0^{(j)} &gt; 0\n\\]\nwhere \\(B_t = (B_t^{(j)},j\\leq d)\\) is a Brownian motion in \\(\\mathbb{R}^d\\). We consider the process\n\\[\nS_t = \\sum_{j \\leq d} (X_t^{(j)})^2\n\\]\nClearly, \\(S_t\\) is nongegative for all \\(t \\geq 0\\) by design, so \\(\\sqrt{S_t}\\) is well-defined. Let’s compute the SDE of the process. By Ito’s formula, we have:\n\\[\n\\begin{align*}\ndS_t &= 2\\sum_{j=1}^{d}X_t^{(j)} dX_t^{(j)} + \\frac{1}{2}\\sum_{j=1}^{d} 2 (dX_t^{(j)})^2\\\\\n&=2\\sum_{j=1}^{d}X_t^{(j)} dX_t^{(j)} + \\frac{\\sigma^2}{4}\\sum_{j=1}^{d} dt \\\\\n&=2\\sum_{j=1}^{d}X_t^{(j)} \\left(\\frac{-b}{2}X_t^{(j)}dt + \\frac{\\sigma}{2}dB_t^{(j)}\\right) + \\frac{d\\sigma^2}{4} dt\\\\\n&=\\left[\\left(\\sum_{j=1}^d (-b)(X_t^{(j)})^2\\right) + \\frac{d\\sigma^2}{4}\\right] dt + \\sigma \\sum_{j=1}^{d} X_t^{(j)} dB_t^{(j)}\\\\\n&=\\sigma \\sum_{j=1}^{d} X_t^{(j)} dB_t^{(j)} + \\left[\\frac{d\\sigma^2}{4} - b S_t\\right] dt \\\\\n&= \\sigma \\sqrt{S_t} \\sum_{j=1}^{d} \\frac{X_t^{(j)}}{\\sqrt{S_t}} dB_t^{(j)}  + \\left[\\frac{d\\sigma^2}{4} - b S_t\\right] dt \\\\\n&= \\sigma \\sqrt{S_t} dW_t  + \\left[\\frac{d\\sigma^2}{4} - b S_t\\right] dt \\\\\n\\end{align*}\n\\]\nwhere we have defined \\(dW_t = \\sum_{j=1}^d \\frac{X_t^{(j)}}{\\sqrt{S_t}} dB_t^{(j)}\\). It turns out that the process \\((W_t,t\\geq 0)\\) is a standard brownian motion by Levy’s characterization theorem. If we accept this for a moment, we have the SDE:\n\\[\ndS_t = \\sigma \\sqrt{S_t} dW_t + \\left(\\frac{d \\sigma^2}{4} - bS_t\\right) dt, \\quad S_0 &gt; 0\n\\tag{22}\\]\nThis is a time-homogenous diffusion called the Cox-Ingersoll-Ross (CIR) process. Again, notice that there are no issues with square root, since \\(S_t\\) is positive by construction! The SDE also makes sense if replace \\(d\\sigma^2/4\\) by a parameter \\(a\\) in Equation 21 as long as \\(a \\geq \\frac{d\\sigma^2}{4}\\). This process is important for interest rates and stochastic volatility models.\nNote that the local drift is \\(a - bS_t, a\\ge \\frac{d\\sigma^2}{4}\\). This can be written as:\n\\[\\begin{align*}\na - bS_t = b\\left(\\frac{b}{a} - S_t \\right)\n\\end{align*}\\]\nThis means that the local drift is negative if \\(S_t &gt; \\frac{a}{b}\\) and it is positive if \\(S_t &lt; \\frac{a}{b}\\). So, the SDE exhibits the same phenomenon as for the SDE of the Ornstein-Uhlenbeck process in Example 5. In particular we should expect that for \\(t\\) large, the process should fluctuate around the mean value \\(\\frac{a}{b}\\). The CIR model is therefore an example of a mean-reverting process. More generally, this hints to the fact, that the process is stationary in the long run.\n\n\n\n\nWe know very well by now, that an Ito integral is continuous martingale with respect to the Brownian filtration, whenever the integrand is in \\(\\mathcal{L}_c^2(T)\\). What can we say about the converse? In other words, if we have a martingale with respect to the Brownian filtration, can it be expressed as an Ito integral for some integrand \\((V_t,t\\leq T)\\)? Amazingly, the answer to this question is yes!\n\nTheorem 5 (Martingale Representation Theorem.) Let \\((B_t,t \\geq 0)\\) be a Brownian motion with filtration \\((\\mathcal{F}_t,t\\geq 0)\\) on \\((\\Omega,\\mathcal{F},\\mathbb{P})\\). Consider a martingale \\((M_t,t\\leq T)\\) with respect to this filtration. Then, there exists an adapted process \\((V_t,t \\leq T)\\) such that:\n\\[\nM_t = M_0 + \\int_0^t V_s dB_s, \\quad t \\leq T\n\\tag{23}\\]\nOne striking fact of the result is that \\((M_t,t\\leq T)\\) ought to be continuous. In other words, we cannot construct a process with a jump that is a martingale adapted to Brownian motion!\nInstead of the proving the theorem, we will see how the result is not too surprising with stronger assumptions. Instead of supposing that \\(M_t\\) is \\(\\mathcal{F}_t\\) measurable, take that \\(M_t\\) is \\(\\sigma(B_t)\\)-measurable. In other words, \\(M_t=h(B_t)\\) for some function \\(h\\). In the case where \\(h\\) is smooth, then it is clear by Ito’s formula that the representation Equation 23 holds with \\(V_s = h'(B_s)\\).\n\nAn important consequence of Theorem 5 is a third definition of Brownian motion.\n\nTheorem 6 (One-dimensional Levy’s Characterization theorem) Let \\((M_t,t\\in [0,T])\\) be a continuous martingale with respect to the filtration \\((\\mathcal{F}_t,t \\leq T)\\) with \\(M_0 = 0\\) and with quadratic variation \\(&lt;M&gt;_t = t\\). Then, \\((M_t,t\\leq T)\\) is a standard brownian motion.\n\nProof.\nWe first need to show that \\(M_t - M_s \\sim \\mathcal{N}(0,t - s)\\) or using the characteristic function approach, we need to show that \\(f_{(M_t - M_s)}(\\theta)=\\mathbb{E}[e^{\\theta (M_t - M_s)}] = e^{\\frac{1}{2}\\theta^2 (t-s)}\\) for constant \\(\\theta\\).\nLet \\(f(t,x) = e^{\\theta x - \\frac{1}{2}\\theta^2 t}\\).\nBy Ito’s formula, we have:\n\\[\\begin{align*}\ndf(t,M_t) &= \\theta e^{\\theta M_t - \\frac{1}{2}\\theta^2 t} dM_t + \\left(-\\frac{1}{2}\\theta^2 + \\frac{1}{2} \\theta^2 \\right)e^{\\theta M_t - \\frac{1}{2}\\theta^2 t}dt\\\\\n&= \\theta f(t,M_t) dM_t\n\\end{align*}\\]\nIntegrating on both sides, we get:\n\\[\\begin{align*}\nf(t,M_t) - f(s,M_s) &= \\theta \\int_0^t f(u,M_u) dM_u\n\\end{align*}\\]\nThe ito integral \\(\\int_0^t f(s,M_s) dM_s\\) is well-defined and its expectation is \\(0\\). Hence, applying expectation operator on both sides, we get:\n\\[\\begin{align*}\n\\mathbb{E}[f(t,M_t) - f(s,M_s)] &= \\theta \\mathbb{E} \\left[ \\int_0^t f(s,M_s) dM_s\\right]\\\\\n&= 0\n\\end{align*}\\]\nSince \\(e^{x} \\neq 0\\) for all \\(x\\), dividing by \\(f(s,M_s)\\), we get:\n\\[\\begin{align*}\n\\mathbb{E}\\left[\\frac{f(t,M_t)}{f(s,M_s)}\\right] &= 1\\\\\n\\mathbb{E}\\left[\\frac{e^{\\theta M_t - \\frac{1}{2}\\theta^2 t}}{e^{\\theta M_s - \\frac{1}{2}\\theta^2 s}}\\right] &= 1\\\\\n\\mathbb{E}\\left[e^{\\theta(M_t - M_s)}\\right] &= e^{\\frac{1}{2}\\theta^2(t-s)}\n\\end{align*}\\]\nwhich is the moment generating function for the normal distribution with mean zero and variance \\(t-s\\). So, \\(M_t - M_s \\sim \\mathcal{N}(0, t - s)\\).\nFurther, consider \\(t_1 \\leq t_2 \\leq t_3\\). We have:\n\\[\\begin{align*}\n\\mathbb{E}[(M_{t_3} - M_{t_2})(M_{t_2} - M_{t_1})] &= \\mathbb{E}[\\mathbb{E}[(M_{t_3} - M_{t_2})(M_{t_2} - M_{t_1})|\\mathcal{F}_{t_2}]] \\\\\n&= \\mathbb{E}[(M_{t_2} - M_{t_1})\\mathbb{E}[(M_{t_3} - M_{t_2})|\\mathcal{F}_{t_2}]] \\\\\n&= \\mathbb{E}[(M_{t_2} - M_{t_1})(M_{t_2} - M_{t_2})] \\\\\n&= 0\n\\end{align*}\\]\nwhere \\(\\mathbb{E}[M_{t_3} - M_{t_2}|\\mathcal{F}_{t_2}] = 0\\) follows from the fact that \\((M_t,t\\geq 0)\\) is a martingale. Consequently, \\(M_{t_3} - M_{t_2} \\perp M_{t_2} - M_{t_1}\\) and non-overlapping increments are independent.\nMoreover, \\(M(0) = 0\\). So, \\((M_t,t\\geq 0)\\) is a standard brownian motion. This closes the proof. \\(\\blacksquare\\)\n\n\n\n\nExercise 5 Let \\((\\Omega,\\mathcal{F},\\mathbb{P})\\) be a probability space and \\((W_t,t\\geq 0)\\) be a standard Wiener process. Find the SDE for the random process \\(X_t = W_t^n, n \\in \\mathbb{Z}^{+}\\).\nShow that\n\\[\n\\mathbb{E}[W_t^n] = \\frac{1}{2}n(n-1) \\int_0^t \\mathbb{E}\\left[W_s^{(n-2)}\\right] ds\n\\]\nand using mathematical induction prove that:\n\\[\n\\mathbb{E}[W_t^n] = \\begin{cases}\n\\frac{n! t^{n/2}}{2^{n/2} \\left(\\frac{n}{2}\\right)!}, & n=2,4,6,\\ldots\\\\\n0, & n=1,3,5,\\ldots\n\\end{cases}\n\\]\n\nSolution."
  },
  {
    "objectID": "posts/ito-processes-and-stochastic-diff-eqs/index.html#itos-formula.",
    "href": "posts/ito-processes-and-stochastic-diff-eqs/index.html#itos-formula.",
    "title": "Ito Processes and Stochastic Differential Equations",
    "section": "",
    "text": "The first step towards a general Ito’s formula is the quadratic variation of an Ito process.\n\nProposition 1 (Quadratic variation of an Ito process.) Let \\((B(t),t\\geq0)\\) be a standard Brownian motion and \\((X(t):t\\geq0)\\) be an Ito process of the form \\(dX(t)=V(t)dB(t)+D(t)dt\\). Then, the quadratic variation of the process \\((X(t):t\\geq0)\\) is:*\n\\[\\begin{aligned}\n&lt;X,X&gt;_{t} & =\\lim_{n\\to\\infty}\\sum_{j=0}^{n-1}(X(t_{j+1})-X(t_{j}))^{2}=\\int_{0}^{t}V(s)^{2}ds\n\\end{aligned} \\tag{5}\\]\nfor any partition \\((t_{j},j\\leq n)\\) of \\([0,t]\\), where the limit is in probability.\n\n\nNote that the quadratic variation is increasing in \\(t\\), but it is not deterministic in general! \\(V_t\\) is a random variable. The quadratic variation is a smooth stochastic process. (It is differentiable) Observe that we recover the quadratic variation for the Brownian motion for \\(V(t)=1\\) as expected. We also notice that the formula follows easily from the rules of Ito Calculus, thereby showing the consistency of the theory. Indeed we have:\n\\[\\begin{aligned}\nd&lt;X,X&gt;_{t} & =(dX(t))^{2}=(V(t)dB(t)+D(t)dt)^{2}\\\\\n& =V(t)^{2}(dB(t))^{2}+2V(t)D(t)dB(t)\\cdot dt+D^{2}(t)(dt)^{2}\\\\\n& =V(t)^{2}dt\n\\end{aligned}\\]\n\n\nProof. Proof. The proof is involved, but it reviews some important concepts of stochastic calculus. We prove the case when the process \\(V\\) is in \\(\\mathcal{L}_{c}^{2}(T)\\) for some \\(T&gt;0\\). We write \\(I(t)=\\int_{0}^{t}V(s)dB(s)\\) and \\(R(t)=\\int_{0}^{t}D(s)ds\\). We first show that only the Ito integral contributes to the quadratic variation and the Riemann integral does not contribute, so that:\n\\[\\begin{aligned}\n&lt;X,X&gt;_{t} & =&lt;I,I&gt;_{t}\n\\end{aligned} \\tag{6}\\]\nWe have that the increment square of \\(X(t)\\) is:\n\\[\\begin{aligned}\n(X(t_{j+1})-X(t_{j}))^{2} & =(I(t_{j+1})-I(t_{j}))^{2}+2(I(t_{j+1})-I(t_{j}))(R(t_{j+1})-R(t_{j}))+(R(t_{j+1})-R(t_{j}))^{2}\n\\end{aligned}\\]\nThe Cauchy-Schwarz inequality implies :\n\\[\\begin{aligned}\n\\sum_{j=0}^{n-1}(I(t_{j+1})-I(t_{j}))(R(t_{j+1})-R(t_{j})) & \\leq\\left(\\sum_{j=0}^{n-1}(I(t_{j+1})-I(t_{j}))^{2}\\right)^{1/2}\\left(\\sum_{j=0}^{n-1}(R(t_{j+1})-R(t_{j}))^{2}\\right)^{1/2}\n\\end{aligned}\\]\nTherefore, to prove equation Equation 5, it suffices to show that \\(\\sum_{j=0}^{n-1}(R(t_{j+1})-R(t_{j}))^{2}\\to 0\\) almost surely. Since \\(D(s)\\) is an almost surely continuous process, the stochastic process \\(R(t)=\\int_{0}^{t}D(s)ds\\) has continuous paths with probability \\(1\\). Therefore:\n\\[\\begin{aligned}\n\\sum_{j=0}^{n-1}(R(t_{j+1})-R(t_{j}))^{2} & =\\max_{1\\leq j\\leq n}|R(t_{j+1})-R(t_{j})|\\sum_{j=0}^{n-1}(R(t_{j+1})-R(t_{j}))\n\\end{aligned}\\]\nSince, \\(R(t)\\) is continuous on the compact set \\([0,t]\\), it is uniformly continuous a.s. So, as \\(|t_{j+1}-t_{j}|\\to 0\\), by uniform continuity it follows that \\(\\max|R(t_{j+1})-R(t_{j})|\\to 0\\) a.s.\nIt remains to prove that \\(&lt;I,I&gt;_{t}=\\int_{0}^{t}V(s)^{2}ds\\). We first prove the case when \\(V\\in\\mathcal{S}(T)\\) is a simple adapted process. Consider a partition \\((t_{j}:j\\leq n)\\) of \\([0,t]\\). Without loss of generality, we can suppose that \\(V\\) is constant on each \\([t_{j},t_{j+1})\\) by refining the partition. We then have:\n\\[\\begin{aligned}\n\\sum_{j=0}^{n-1}(I(t_{j+1})-I(t_{j}))^{2} & =\\sum_{j=0}^{n-1}V(t_{j})^{2}(B(t_{j+1})-B(t_{j}))^{2}\n\\end{aligned}\\]\nNow, we have seen in the proof of Ito’s formula that \\(\\mathbb{E}\\left[\\left\\{ \\sum_{j=0}^{n-1}V(t_{j})^{2}((B(t_{j+1})-B(t_{j}))^{2}-(t_{j+1}-t_{j})\\right\\} ^{2}\\right]\\to 0\\), so \\(\\sum_{j=0}^{n-1}V(t_{j})^{2}(B(t_{j+1})-B(t_{j}))^{2}\\) approaches \\(\\sum_{j=0}^{n-1}V(t_{j})^{2}(t_{j+1}-t_{j})\\) in the mean square sense. As the mesh size becomes finer, the \\(L^{2}\\)-limit is \\(\\int_{0}^{t}V(t)^{2}dt\\).\nThe case \\(V\\in\\mathcal{L}_{c}^{2}(T)\\) is proved by approximating \\(V\\) by a simple process in \\(\\mathcal{S}(T)\\). More precisely, we can find a simple process \\(V^{(\\epsilon)}(t)\\) that is \\(\\epsilon\\)-close to \\(V\\) in the sense:\n\\[\\begin{aligned}\n||I^{(\\epsilon)}-I|| & =||\\int V^{\\epsilon}dB(t)-\\int VdB(t)||=\\int_{0}^{t}\\mathbb{E}[(V^{(\\epsilon)}(t)-V(t))^{2}]ds&lt;\\epsilon\n\\end{aligned} \\tag{7}\\]\nTo prove the claim, we need to show that for \\(t\\leq T\\),\n\\[\\begin{aligned}\n\\mathbb{E}\\left[\\left|\\sum_{j=0}^{n-1}(I(t_{j+1})-I(t_{j}))^{2}-\\int_{0}^{t}(V(s))^{2}ds\\right|\\right] & \\to0\\quad\\text{as }\\quad n\\to\\infty\n\\end{aligned}\\]\n\\(L^{1}\\)-convergence implies convergence in probability of the sequence \\(\\sum_{j=0}^{n-1}(I(t_{j+1})-I(t_{j}))^{2}\\). We now introduce the \\(V^{(\\epsilon)}(t)\\) approximation inside the absolute value as well as its corresponding integral \\(I^{(\\epsilon)}(t)=\\int_{0}^{t}V^{(\\epsilon)}(s)ds\\). By the triangle inequality, we have:\n\\[\\begin{aligned}\n& \\mathbb{E}\\left[\\left|\\sum_{j=0}^{n-1}(I(t_{j+1})-I(t_{j}))^{2}-\\int_{0}^{t}(V(s))^{2}ds\\right|\\right]\\nonumber \\\\\n= & \\mathbb{E}\\left[\\Biggl|\\sum_{j=0}^{n-1}(I(t_{j+1})-I(t_{j}))^{2}-(I^{(\\epsilon)}(t_{j+1})-I^{(\\epsilon)}(t_{j}))^{2}+(I^{(\\epsilon)}(t_{j+1})-I^{(\\epsilon)}(t_{j}))^{2}-\\int_{0}^{t}(V^{(\\epsilon)}(s))^{2}ds\\right.\\nonumber \\\\\n& +\\int_{0}^{t}(V^{(\\epsilon)}(s))^{2}ds-\\int_{0}^{t}(V(s))^{2}ds\\Biggr|\\Biggr]\\nonumber \\\\\n\\leq & \\mathbb{E}\\left[\\left|\\sum_{j=0}^{n-1}(I(t_{j+1})-I(t_{j}))^{2}-(I^{(\\epsilon)}(t_{j+1})-I^{(\\epsilon)}(t_{j}))^{2}\\right|\\right]+\\mathbb{E}\\left[\\left|\\sum_{j=0}^{n-1}(I^{(\\epsilon)}(t_{j+1})-I^{(\\epsilon)}(t_{j}))^{2}-\\int_{0}^{t}(V^{(\\epsilon)}(s))^{2}ds\\right|\\right]\\\\\n& +\\mathbb{E}\\left[\\Biggl|\\int_{0}^{t}(V^{(\\epsilon)}(s))^{2}ds-\\int_{0}^{t}(V(s))^{2}ds\\Biggr|\\right]\\nonumber\n\\end{aligned} \\tag{8}\\]\nWe show that the first and third terms converge uniformly and that the second term goes to \\(0\\) as \\(n\\to\\infty\\).\nThe second term goes to \\(0\\) as \\(n\\to\\infty\\) by the argument for simple processes.\n\\(&lt;I^{(\\epsilon)},I^{(\\epsilon)}&gt;_{t}=\\int_{0}^{t}V^{(\\epsilon)}(s)^{2}ds\\).\nFor the third term, the linearity of the integral and the Cauchy Schwarz inequality (applied to \\(\\mathbb{E}\\int_{0}^{t}\\)) imply that it is:\n\\[\\begin{aligned}\n\\mathbb{E}\\left[\\Biggl|\\int_{0}^{t}(V^{(\\epsilon)}(s))^{2}ds-\\int_{0}^{t}(V(s))^{2}ds\\Biggr|\\right] & \\leq\\mathbb{E}\\left[\\Biggl|\\int_{0}^{t}(V^{(\\epsilon)}(s)-V(s))^{2}ds\\Biggr|\\right]^{1/2}\\mathbb{E}\\left[\\Biggl|\\int_{0}^{t}(V^{(\\epsilon)}(s)+V(s))^{2}ds\\Biggr|\\right]^{1/2}\n\\end{aligned}\\]\nThe first factor is smaller than the square root of \\(\\epsilon\\) by Equation 7, whereas the second factor is bounded.\nThe first term in equation Equation 8 is handled similarly. The linearity of the Ito integral and the Cauchy-Schwarz inequality applied to \\(\\mathbb{E}\\left[\\sum_{j=0}^{n-1}\\left(\\int_{t_{j}}^{t_{j+1}}\\cdot\\right)\\right]\\) give that the first term is:\n\\[\\begin{aligned}\n& \\mathbb{E}\\left[\\left|\\sum_{j=0}^{n-1}\\int_{t_{j}}^{t_{j+1}}(V(s))^{2}dB(s)-\\int_{t_{j}}^{t_{j+1}}(V^{\\epsilon}(s))^{2}dB(s)\\right|\\right]\\\\\n= & \\mathbb{E}\\left[\\left|\\sum_{j=0}^{n-1}\\int_{t_{j}}^{t_{j+1}}(V(s)-V^{\\epsilon}(s))dB(s)\\int_{t_{j}}^{t_{j+1}}(V(s)+V^{\\epsilon}(s))dB(s)\\right|\\right]\\\\\n\\leq & \\mathbb{E}\\left[\\sum_{j=0}^{n-1}\\left(\\int_{t_{j}}^{t_{j+1}}(V(s)-V^{\\epsilon}(s))dB(s)\\right)^{2}\\right]^{1/2}\\mathbb{E}\\left[\\Biggl|\\sum_{j=0}^{n-1}\\left(\\int_{t_{j}}^{t_{j+1}}(V(s)+V^{\\epsilon}(s))dB(s)\\right)^{2}\\Biggr|\\right]^{1/2}\n\\end{aligned}\\]\nBy Ito isometry, the first factor in the above expression can be simplified:\n\\[\\begin{aligned}\n\\mathbb{E}\\left[\\sum_{j=0}^{n-1}\\left(\\int_{t_{j}}^{t_{j+1}}(V(s)-V^{\\epsilon}(s))dB(s)\\right)^{2}\\right]^{1/2} & =\\sum_{j=0}^{n-1}\\mathbb{E}\\left(\\int_{t_{j}}^{t_{j+1}}(V(s)-V^{\\epsilon}(s))dB(s)\\right)^{2}\\\\\n& =\\sum_{j=0}^{n-1}\\int_{t_{j}}^{t_{j+1}}\\mathbb{E}[(V(s)-V^{\\epsilon}(s))^{2}]ds\n\\end{aligned}\\]\nBy Equation 7, this factor is smaller than \\(\\epsilon\\). The second factor equals \\(\\sum_{j=0}^{n-1}\\int_{t_{j}}^{t_{j+1}}\\mathbb{E}[(V(s)+V^{\\epsilon}(s))^{2}]ds\\) by Ito-isometry and is uniformly bounded. This concludes the proof of the proposition. \\(\\blacksquare\\)\n\nNote that quadratic variation \\(&lt;I,I&gt;_{t}=\\int(V(s))^{2}ds\\) is computed path-by-path and hence the result is random. On the other the variance of the Ito integral \\(Var(I(t))=\\mathbb{E}[I_{t}^{2}]=\\int\\mathbb{E}[V_{s}^{2}]ds\\) is the mean value of all possible paths of the quadratic variation and hence is non-random. We are now ready to state Ito’s formula for Ito processes. We write the result in differential form for conciseness.\n\nTheorem 1 (Ito’s formula for Ito processes) Let \\((B(t):t\\geq0)\\) be a standard brownian motion, and let \\((X(t):t\\geq0)\\) be an Ito process of the form \\(dX(t)=V(t)dB(t)+D(t)dt\\). Consider a function \\(f(t,x)\\in\\mathcal{C}^{1,2}([0,T]\\times\\mathbf{R})\\). Then we have with probability one for all \\(t\\leq T\\):*\n\\[\\begin{aligned}\ndf(t,X(t)) & =\\partial_{x}f(t,X(t))dX(t)+\\partial_{t}f(t,X(t))dt+\\frac{1}{2}\\partial_{xx}f(t,X(t))d&lt;X,X&gt;_{t}\n\\end{aligned}\\]\nThis can also be written as:\n\\[\\begin{aligned}\ndf(t,X(t))= & \\partial_{x}f(t,X(t))V(t)dB(t)+\\left[\\partial_{x}f(t,X(t))D(t)+\\partial_{t}f(t,X(t))+\\frac{1}{2}(V(t))^{2}\\partial_{xx}f(t,X(t))\\right]dt\n\\end{aligned}\\]\n\nThe proof of the Theorem 1 is again a Taylor approximation with the form of the quadratic variation of the process. We will omit it.\n\nExample 5 (Ornstein-Uhlenbeck Process). Consider the Ornstein-Uhlenbeck process \\((Y(t):t\\geq0)\\):\n\\[\\begin{aligned}\nY(t) & =Y(0)e^{-t}+e^{-t}\\int_{0}^{t}e^{s}dB(s)\n\\end{aligned}\\]\nNote that this process is an explicit function of \\(t\\) and of the Ito process \\(X(t)=Y(0)+\\int_{0}^{t}e^{s}dB(s)\\). Indeed, we have:\n\\[\\begin{aligned}\nY(t) & =e^{-t}X(t)\n\\end{aligned}\\]\nLet \\(f(t,x)=e^{-t}x\\). Then, \\(f_{x}(t,x)=e^{-t}\\), \\(f_{xx}(t,x)=0\\) and \\(f_{t}(t,x)=-e^{-t}x\\). So, by Ito’s lemma,\n\\[\\begin{aligned}\ndf(t,x) & =f_{t}(t,X(t))dt+f_{x}(t,X(t))dX(t)+\\frac{1}{2}f_{xx}(t,X(t))d&lt;X,X&gt;_{t}\\nonumber \\\\\ndY(t) & =-Y(t)dt+e^{-t}dX(t)\\nonumber \\\\\ndY(t) & =-Y(t)dt+e^{-t}(e^{t}dB(t))\\nonumber \\\\\ndY(t) & =-Y(t)dt+dB(t)\n\\end{aligned} \\tag{9}\\]\nThis is the SDE for the Ornstein Uhlenbeck process.\nThe SDE has a very nice interpretation: The drift is positive if \\(Y(t)&lt;0\\) and negative if \\(Y(t)&gt;0\\). Moreover, the drift is proportional to the position (exactly like a spring pulling the process back to the \\(x\\)-axis following the Hooke’s law!). This is the mechanism that ensures that the process does not venture too far from \\(0\\) and is eventually stationary.\nThe SDE Equation 9 is now easily generalized by adding two parameters for the volatility and the drift:\n\\[\\begin{aligned}\ndY(t) & =-kY(t)dt+\\sigma dB(t),\\quad k\\in\\mathbf{R},\\sigma&gt;0\n\\end{aligned} \\tag{10}\\]\nIt is not hard to check that the solution to the SDE is:\n\\[\\begin{aligned}\nY(t) & =Y(0)e^{-kt}+e^{-kt}\\int_{0}^{t}e^{ks}\\sigma dB(s)\n\\end{aligned} \\tag{11}\\]\n\n\nExercise 1 The Ornstein-Uhlenbeck process with parameters. Use the Ito’s formula to show that the Equation 11 is the solution to the Ornstein-Uhlenbeck SDE Equation 10.\n\nSolution.\nLet \\(X(t)=Y(0)+\\int_{0}^{t}e^{ks}\\sigma dB(s)\\), so \\(dX(t)=e^{kt}\\sigma dB(t)\\). Then, \\(Y(t)=e^{-kt}X(t)\\). Let \\(f(t,x)=e^{-kt}x\\). Then, by Ito’s formula:\n\\[\\begin{aligned}\ndf(t,x) & =-ke^{-kt}X(t)dt+e^{-kt}dX(t)\\\\\ndY(t) & =-kY(t)dt+e^{-kt}e^{kt}\\sigma dB(t)\\\\\ndY(t) & =-kY(t)dt+\\sigma dB(t)\n\\end{aligned}\\]\nThe latest version of Ito’s formula is another useful tool for producing martingales from a function of an Ito process. We start with two examples generalizing martingales for Brownian motion.\n\nExample 6 (A generalization of \\((B(t))^{2}-t\\)). Let \\((V(t):t\\leq T)\\) be a process in \\(\\mathcal{L}_{c}^{2}(T)\\). Consider an Ito process \\((X(t):t\\leq T)\\) given by \\(dX(t)=V(t)dB(t)\\). Note that \\(((X(t))^{2}:t\\leq T)\\) is a submartingale by Jensen’s inequality, since \\(\\mathbb{E}[X^{2}(t)|\\mathcal{F}_{s}]\\geq(\\mathbb{E}[X(t)|\\mathcal{F}_{s})^{2}=X^{2}(s)\\). We show that the compensated process\n\\[\\begin{aligned}\nM(t) & =X^{2}(t)-\\int_{0}^{t}V^{2}(s)ds,\\quad t\\leq T\n\\end{aligned}\\]\nis a martingale for the Brownian filtration. (This is another instance of the Doob-Meyer decomposition). By the Ito’s formula for \\(f(x)=x^{2}\\), we have:\n\\[\\begin{aligned}\ndf(x) & =f_{x}(X(t)dX(t)+\\frac{1}{2}f_{xx}(X(t))d&lt;X,X&gt;_{t}\\\\\n& =2X(t)dX(t)+(V(t))^{2}dt\\\\\ndf(X(t)) & =2X(t)V(t)dB(t)+(V(t))^{2}dt\n\\end{aligned}\\]\nIn Integral form this implies:\n\\[\\begin{aligned}\n(X(t))^{2} & =(X(0))^{2}+2\\int_{0}^{t}X(s)V(s)dB(s)+\\int_{0}^{t}(V(s))^{2}ds\\\\\nM(t)=(X(t))^{2}-\\int_{0}^{t}(V(s))^{2}ds & =(X(0))^{2}+2\\int_{0}^{t}X(s)V(s)dB(s)\n\\end{aligned}\\]\nWe conclude that \\((M(t):t\\leq T)\\) is a martingale, provided \\(X(t)V(t)\\in L_{c}^{2}(T)\\).\nThere is another more direct way to prove that \\((M(t):t\\leq T)\\) is a martingale whenever \\((V(t):t\\leq T)\\in\\mathcal{L}_{c}^{2}(T)\\). This is by using increments: for \\(t'&lt;t\\leq T\\),\n\\[\\begin{aligned}\n\\mathbb{E}[X_{t'}^{2}|\\mathcal{F}_{t}] & =\\mathbb{E}[(X_{t}+(X_{t'}-X_{t}))^{2}|\\mathcal{F}_{t}]\\\\\n& =\\mathbb{E}[X_{t}^{2}+2X_{t}(X_{t'}-X_{t})+(X_{t'}-X_{t})^{2}|\\mathcal{F}_{t}]\\\\\n& =X_{t}^{2}+2X_{t}\\mathbb{E}[X_{t'}-X_{t}|\\mathcal{F}_{t}]+\\mathbb{E}[(X_{t'}-X_{t})^{2}|\\mathcal{F}_{t}]\n\\end{aligned}\\]\nSince \\((X_{t}:t\\geq0)\\) is a martingale, \\(\\mathbb{E}[(X_{t'}-X_{t})|M_{t}]=0\\), so the middle term equals zero and we are left with:\n\\[\\begin{aligned}\n\\mathbb{E}[X_{t'}^{2}|\\mathcal{F}_{t}] & =X_{t}^{2}+\\mathbb{E}[(X_{t'}-X_{t})^{2}|\\mathcal{F}_{t}]\n\\end{aligned}\\]\nBy conditional Ito Isometry,\n\\[\\begin{aligned}\n\\mathbb{E}[(X_{t'}-X_{t})^{2}|\\mathcal{F}_{t}] & =\\int_{0}^{t'}V_{s}^{2}ds-\\int_{0}^{t}V_{s}^{2}ds=\\int_{t}^{t'}V_{s}^{2}ds\n\\end{aligned}\\]\n\n\nExample 7 (A generalization of the geometric Brownian motion). Let \\(\\sigma(t)\\) be a continuous, deterministic function such that \\(|\\sigma(t)|\\leq1\\), \\(t\\in[0,T]\\). The process\n\\[\\begin{aligned}\nM(t) & =\\exp\\left(\\int_{0}^{t}\\sigma(s)dB(s)-\\frac{1}{2}\\int_{0}^{t}\\sigma^{2}(s)ds\\right),\\quad t\\leq T\n\\end{aligned}\\]\nis a martingale for the Brownian filtration. To see this, note that we can write \\(M(t)=f(t,X(t))\\) where \\(f(t,x)=\\exp(x-\\frac{1}{2}\\int\\sigma^{2}(s)ds)\\) and \\(X(t)=\\int_{0}^{t}\\sigma(s)dB(s)\\), so \\(dX(t)=\\sigma(t)dB(t)\\). Ito’s formula gives:\n\\[\\begin{aligned}\ndf(t,x) & =f_{t}(t,X(t)dt+f_{x}(t,X(t))dX(t)+\\frac{1}{2}f_{xx}(t,X(t))d&lt;X,X&gt;_{t}\\\\\ndM(t) & =-\\frac{1}{2}\\sigma^{2}(t)M(t)dt+M(t)\\sigma(t)dB(t)+\\frac{1}{2}M(t)\\sigma^{2}(t)dt\\\\\n& =M(t)\\sigma(t)dB(t)\\\\\nM(t) & =M(0)+\\int_{0}^{t}M(s)\\sigma(s)dB(s)\n\\end{aligned}\\]\nObserve also that:\n\\[\\begin{aligned}\n\\mathbb{E}[M_{t}^{2}] & =e^{-\\int_{0}^{t}\\sigma^{2}(s)ds}\\mathbb{E}[e^{2\\int_{0}^{t}\\sigma(s)dB(s)}]=e^{\\int_{0}^{t}\\sigma^{2}(s)ds}\n\\end{aligned}\\]\nsince \\(\\int_{0}^{t}\\sigma(s)dB(s)\\) is a Gaussian random variable with mean \\(0\\) and variance \\(\\int_{0}^{t}\\sigma^{2}(s)ds\\).\nWe conclude from the equation that \\((M(t),t\\geq0)\\) is a martingale.\n\n\nExample 8 (Martingales of Geometric Brownian Motion). Let\n\\[\\begin{aligned}\nS(t) & =S(0)\\exp(\\sigma B(t)-\\sigma^{2}t/2)\n\\end{aligned}\\]\nbe a geometric brownian motion. We find a PDE satisfied by \\(f(t,x)\\) for \\(f(t,S(t))\\) to be a martingale. It suffices to apply Ito’s formula of Theorem 1. We get:\n\\[\\begin{aligned}\ndf(t,S(t)) & =f_{t}(t,S(t))dt+f_{x}(t,S(t))dS(t)+\\frac{1}{2}f_{xx}(t,S(t))dS(t)\\cdot dS(t)\n\\end{aligned}\\]\nNow note from the earlier result that \\(dS(t)=S(t)\\sigma dB(t)\\). So, \\(dS(t)\\cdot dS(t)=\\frac{1}{2}\\sigma^{2}(S(t))^{2}dt\\). So,\n\\[\\begin{aligned}\ndf(t,S(t)) & =\\left\\{ \\frac{\\partial f}{\\partial t}+\\frac{1}{2}\\sigma^{2}(S(t))^{2}\\frac{\\partial^{2}f}{\\partial x^{2}}\\right\\} dt+\\sigma S(t)\\frac{\\partial f}{\\partial x}dB(t)\n\\end{aligned}\\]\nFinally, the PDE for \\(f(t,x)\\) is obtained by setting the factor in front of \\(dt\\) to \\(0\\), because we want \\(f\\) to be a martingale process. It is important to keep in mind, that the PDE should always be written in terms of the time variable \\(t\\) and the space variable \\(x\\). Therefore, the PDE of \\(f\\) as a function of time and space is:\n\\[\\begin{aligned}\n\\frac{1}{2}\\sigma^{2}x^{2}\\frac{\\partial^{2}f}{\\partial x^{2}}(t,x)+\\frac{\\partial f}{\\partial t}(t,x) & =0\n\\end{aligned}\\]\nNo more randomness appears in the PDE!\n\nHere is a specific case where we can apply the Ito’s formula to construct martingales of Ito processes.\n\nExample 9 Consider the process given by the SDE:\n\\[\\begin{aligned}\ndX(t) & =X(t)dB(t),\\quad X(0)=2\n\\end{aligned}\\]\nLet’s find a PDE for which \\(f(t,X(t))\\) is a martingale for the Brownian filtration. We have by Ito’s formula that:\n\\[\\begin{aligned}\ndf(t,X(t)) & =f_{t}(t,X(t))dt+f_{x}(t,X(t))dX(t)+\\frac{1}{2}f_{xx}(t,X(t))d&lt;X,X&gt;_{t}\\\\\n& =\\left(\\frac{\\partial f}{\\partial t}+\\frac{1}{2}(X(t))^{2}\\frac{\\partial^{2}f}{\\partial x^{2}}\\right)dt+X(t)\\frac{\\partial f}{\\partial x}dB(t)\n\\end{aligned}\\]\nSetting the drift term to \\(0\\) gives the PDE:\n\\[\\begin{aligned}\n\\frac{\\partial f}{\\partial t}+\\frac{1}{2}x^{2}\\frac{\\partial^{2}f}{\\partial x^{2}} & =0\n\\end{aligned}\\]\nIt is then easy to check that \\(X(t)\\) is a martingale and so is \\(t+\\log(X(t))^{2}\\), since the functions \\(f(t,x)=x\\) and \\(f(t,x)=t+\\log x^{2}\\) satisfy the PDE. However, the process \\(tX(t)\\) is not, as the function \\(f(t,x)=xt\\) is not a solution of the PDE."
  },
  {
    "objectID": "posts/ito-processes-and-stochastic-diff-eqs/index.html#multivariate-extension.",
    "href": "posts/ito-processes-and-stochastic-diff-eqs/index.html#multivariate-extension.",
    "title": "Ito Processes and Stochastic Differential Equations",
    "section": "",
    "text": "Ito’s formula can be generalized to several Ito processes. Let’s start by stating an example of a function of two Ito processes. Such a function \\(f(x_{1},x_{2})\\) will be a function of two space variables. Not surprisingly, it needs to have two derivatives in each variable and they need to be a continuous function; we need \\(f\\in\\mathcal{C}^{2\\times2}(\\mathbf{R}\\times\\mathbf{R})\\).\n\nTheorem 2 (Ito’s formula for many Ito processes) Let \\((X(t):t\\geq0)\\) and (Y(t):t)$ be two Ito processes of the form:\n\\[\\begin{aligned}\ndX(t) & =V(t)dB(t)+D(t)dt\\nonumber \\\\\ndY(t) & =U(t)dB(t)+R(t)dt\n\\end{aligned} \\tag{12}\\]\nwhere \\((B(t):t\\geq0)\\) is a standard Brownian motion. Then, for \\(f\\in\\mathcal{C}^{2\\times2}(\\mathbf{R}\\times\\mathbf{R})\\), we have:\n\\[\\begin{aligned}\ndf(X(t),Y(t)) & =f_{x}(X(t),Y(t))dX(t)+f_{y}(X(t),Y(t))dY(t)+\\frac{1}{2}f_{xx}(X(t),Y(t))d&lt;X,X&gt;_{t}\\\\\n& +f_{xy}(X(t),Y(t))d&lt;X,Y&gt;_{t}+\\frac{1}{2}f_{yy}(X(t),Y(t))d&lt;Y,Y&gt;_{t}\n\\end{aligned}\\]\n\nThe idea of the proof is the same as in Theorem 1 : Taylor’s expansion and quadratic variation, together with the cross-variation of two processes.\n\\[\\begin{aligned}\ndX(t)\\cdot dY(t) & =(V(t)dB(t)+D(t)dt)(U(t)dB(t)+R(t)dt)\\\\\n& =U(t)V(t)dt\n\\end{aligned}\\]\n\nExample 10 (Product Rule) An important example of this formula is Ito’s product rule. Let \\(X(t)\\) and \\(Y(t)\\) be as in Equation 12. Then:\n\\[\\begin{aligned}\nd(X(t)Y(t)) & =Y(t)dX(t)+X(t)dY(t)+dX(t)\\cdot dY(t)\n\\end{aligned}\\]\n\n\nExercise 2 Let \\((\\Omega,\\mathcal{F},\\mathbb{P})\\) be a probability space and let \\((B_{t}:t\\geq0)\\) be a standard brownian motion. Using integration by parts, show that\n\\[\\begin{aligned}\n\\int_{0}^{t}B(s)ds & =\\int_{0}^{t}(t-s)dB(s)\n\\end{aligned}\\]\nand prove that \\(\\int_{0}^{t}B(s)ds\\sim\\mathcal{N}(0,t^{3}/3)\\).\nIs\n\\[\\begin{aligned}\nX(t) & =\\begin{cases}\n0 & t=0\\\\\n\\frac{\\sqrt{3}}{t}\\int_{0}^{t}B(s)ds & t&gt;0\n\\end{cases}\n\\end{aligned}\\]\na standard Wiener process?\nSolution.\nClearly, \\(B(s,\\omega)\\) is a random variable and the Riemann integral \\(\\int_0^t B(s,\\omega)ds\\) depends on the sample path \\(\\omega\\). So, \\((\\int_0^t B_s ds, t\\leq T)\\) is a stochastic process. Using integration by parts:\n\\[\\begin{aligned}\n\\int u\\left(\\frac{dv}{ds}\\right)ds & =uv-\\int v\\left(\\frac{du}{ds}\\right)ds\n\\end{aligned}\\]\nWe set \\(u=B(s)\\) and \\(dv/ds=1\\). Then:\n\\[\\begin{aligned}\n\\int_{0}^{t}B(s)ds & =sB(s)|_{0}^{t}-\\int_{0}^{t}sdB(s)\\\\\n& =tB(t)-\\int_{0}^{t}sdB(s)\\\\\n& =\\int_{s=0}^{s=t}tdB(s)-\\int_{0}^{t}sdB(s)\\\\\n& =\\int_{0}^{t}(t-s)dB(s)\n\\end{aligned}\\]\nThus, \\(\\int_{0}^{t}B(s)ds\\) is a Gaussian random variable with:\n\\[\\begin{aligned}\n\\mathbb{E}\\left[\\int_{0}^{t}B(s)ds\\right] & =\\mathbb{E}\\left[\\int_{0}^{t}(t-s)dB(s)\\right]\\\\\n& =0\n\\end{aligned}\\]\nand\n\\[\\begin{aligned}\n\\mathbb{E}\\left[\\left(\\int_{0}^{t}B(s)ds\\right)^{2}\\right] & =\\int_{0}^{t}(t-s)^{2}ds\\\\\n& =\\left.\\frac{(t-s)^{3}}{-3}\\right|_{0}^{t}\\\\\n& =\\frac{t^{3}}{3}\n\\end{aligned}\\]\nThus, using the properties of Ito Integral, \\(\\int_{0}^{t}B(s)ds=\\int_{0}^{t}(t-s)dB(s)\\) is a martingale. Now the quadratic variation \\(&lt;M,M&gt;_{t}=0\\), and this can be a bit tricky. Remember, \\(\\left\\langle \\int_{0}^{t}f(s,B_{s})dB(s),\\int_{0}^{t}f(s,B_{s})dB(s)\\right\\rangle =\\int_{0}^{t}f^{2}(s,B_{s})ds\\) if and only if \\(f\\) is a function of the time \\(s\\) and the position of the Brownian motion \\(B(s)\\). Since, \\(f\\) is a function of \\(t\\) as well, this rule cannot be applied.\nBy first principles, we can show that, the quadratic variation is indeed \\(0\\): \\[\\begin{aligned}\n\\lim_{n\\to\\infty}\\mathbb{E}\\left[\\sum_{j=0}^{n-1}\\left(I(t_{j+1})-I(t_{j})\\right)^{2}\\right] & =\\lim_{n\\to\\infty}\\mathbb{E}\\left[\\sum_{j=0}^{n-1}B_{t_{j}}^{2}(t_{j+1}-t_{j})^{2}\\right]\\\\\n& =\\lim_{n\\to\\infty}\\max_{1\\leq j\\leq n}|t_{j+1}-t_{j}|\\cdot\\mathbb{E}\\left[\\sum_{j=0}^{n-1}B_{t_{j}}^{2}(t_{j+1}-t_{j})\\right]\n\\end{aligned}\\]\nSince the paths of \\(B_{t}\\) are continuous, so are the paths \\(B_{t}^{2}\\) on the compact interval \\([0,t]\\). So, \\((B_{s}^{2},s\\in[0,t])\\) is uniformly bounded. Thus, the expectation term is bounded. As \\(n\\to\\infty\\), the mesh size approaches zero, and consequently the quadratic variation approaches zero.\n\n\nExample 11 Let \\(X_{t}=\\int_{0}^{t}B_{s}dB_{s}\\) and \\(Y_{t}=\\int_{0}^{t}B_{s}^{2}dB_{s}\\). Is \\((X_{t}Y_{t},t\\geq0)\\) a martingale?\n\nSolution.\nBy Ito’s product rule, we have:\n\\[\\begin{aligned}\nd(X_{t}Y_{t}) & =X_{t}dY_{t}+Y_{t}dX_{t}+dX_{t}\\cdot dY_{t}\\\\\n& =X_{t}B_{s}^{2}dB_{s}+Y_{t}B_{s}dB_{s}+(B_{s}dB_{s})\\cdot(B_{s}^{2}dB_{s})\\\\\n& =X_{t}B_{s}^{2}dB_{s}+Y_{t}B_{s}dB_{s}+B_{s}^{3}dt\\\\\nX_{t}Y_{t} & =X_{0}Y_{0}+\\int_{0}^{t}X_{t}B_{s}^{2}dB_{s}+\\int_{0}^{t}Y_{t}B_{s}dB_{s}+\\int_{0}^{t}B_{s}^{3}dt\n\\end{aligned}\\]\nThe term in \\(dt\\) is not zero, so the product cannot be a martingale.\n\nExample 12 (A generalization of Geometric Brownian Motion). Consider \\((\\int_{0}^{t}V_{s}dB_{s},t\\geq0)\\) an Ito process. Define the positive process:\n\\[\\begin{aligned}\nM_{t} & =\\exp\\left(\\int_{0}^{t}V_{s}dB_{s}-\\frac{1}{2}\\int_{0}^{t}V_{s}^{2}ds\\right),\\quad t\\geq0\n\\end{aligned} \\tag{13}\\]\n\nSolution.\nIto’s formula applied to the processes \\(X_{t}=\\int_{0}^{t}V_{s}dB_{s}\\) and \\(Y_{t}=\\frac{1}{2}\\int_{0}^{t}V_{s}^{2}ds\\) with the function \\(f(x,y)=e^{x-y}\\) yields:\n\\[\\begin{aligned}\ndf(x,y) & =f_{x}(X_{t},Y_{t})dX_{t}+f_{y}(X_{t},Y_{t})dY_{t}\\\\\n& +\\frac{1}{2}f_{xx}(X_{t},Y_{t})dX_{t}\\cdot dX_{t}+\\frac{1}{2}f_{yy}(X_{t},Y_{t})dY_{t}\\cdot dY_{t}\\\\\n& +f_{xy}(X_{t},Y_{t})dX_{t}\\cdot dY_{t}\n\\end{aligned}\\]\nNow, all first and second order derivatives are \\(\\partial_{x}(e^{x-y})=M_{t}\\), \\(\\partial_{y}(e^{x-y})=-e^{x-y}=-M_{t}\\), \\(\\partial_{xx}(e^{x-y})=M_{t}\\)\n\\(dX_{t}=V_{t}dB_{t}\\). \\(dY_{t}=\\frac{1}{2}V_{t}^{2}dt\\).\n\\(dX_{t}\\cdot dX_{t}=V_{t}^{2}dt\\), \\(dX_{t}\\cdot dY_{t}=0\\),\n\\(dY_{t}\\cdot dY_{t}=0\\).\nConsequently, we have:\n\\[\\begin{aligned}\ndM_{t} & =M_{t}V_{t}dB_{t}-\\frac{1}{2}M_{t}V_{t}^{2}dt\\\\\n& +\\frac{1}{2}M_{t}V_{t}^{2}dt\\\\\n& =M_{t}V_{t}dB_{t}\n\\end{aligned}\\]\nThus, \\((M_{t},t\\geq0)\\) is a martingale.\n\nExercise 3 (Generalized Ito Integral). Let \\((\\Omega,\\mathcal{F},\\mathbb{P})\\) be a probability space and let \\((B_{t}:t\\geq0)\\) be a standard brownian motion. Given that \\(f\\) is a simple process, show that:\n\\[\\begin{aligned}\n\\int_{0}^{t}f(s,B_{s})dB_{s} & =B_{t}f(t,B_{t})-\\int_{0}^{t}\\left[B_{s}\\frac{\\partial f}{\\partial t}+\\frac{\\partial f}{\\partial x}+\\frac{1}{2}B_{s}\\frac{\\partial^{2}f}{\\partial x^{2}}\\right]ds\\\\\n& -\\int_{0}^{t}B_{s}\\frac{\\partial f}{\\partial x}dB_{s}\n\\end{aligned}\\]\nand\n\\[\\begin{aligned}\n\\int_{0}^{t}f(s,B_{s})ds & =tf(t,B_{t})-\\int_{0}^{t}s\\left[\\frac{\\partial f}{\\partial t}+\\frac{1}{2}\\frac{\\partial^{2}f}{\\partial x^{2}}\\right]ds-\\int_{0}^{t}s\\frac{\\partial f}{\\partial x}dB_{s}\n\\end{aligned}\\]\n\nSolution.\nI suppress \\((t,B_{t})\\) for simplicity. Applying the product rule to \\(B_{t}f\\), we get:\n\\[\\begin{aligned}\nd(B_{t}f) & =fdB_{t}+B_{t}df+dB_{t}\\cdot df\\\\\n& =fdB_{t}+B_{t}\\left(\\frac{\\partial f}{\\partial t}dt+\\frac{\\partial f}{\\partial x}dB_{t}+\\frac{1}{2}\\frac{\\partial^{2}f}{\\partial x^{2}}(dB_{t})^{2}\\right)\\\\\n& +dB_{t}\\cdot\\left(\\frac{\\partial f}{\\partial t}dt+\\frac{\\partial f}{\\partial x}dB_{t}+\\frac{1}{2}\\frac{\\partial^{2}f}{\\partial x^{2}}(dB_{t})^{2}\\right)\\\\\n& =fdB_{t}+\\left(B_{t}\\frac{\\partial f}{\\partial t}+\\frac{\\partial f}{\\partial x}+\\frac{1}{2}B_{t}\\right)dt+B_{t}\\frac{\\partial f}{\\partial x}dB_{t}\\\\\nB_{t}f & =\\int_{0}^{t}fdB_{s}+\\int_{0}^{t}\\left(B_{s}\\frac{\\partial f}{\\partial t}+\\frac{\\partial f}{\\partial x}+\\frac{1}{2}\\frac{\\partial^{2}f}{\\partial x^{2}}B_{s}\\right)ds+\\int_{0}^{t}B_{s}\\frac{\\partial f}{\\partial x}dB_{s}\\\\\n\\int_{0}^{t}fdB_{s} & =B_{t}f-\\int_{0}^{t}\\left(B_{s}\\frac{\\partial f}{\\partial t}+\\frac{\\partial f}{\\partial x}+\\frac{1}{2}\\frac{\\partial^{2}f}{\\partial x^{2}}B_{s}\\right)ds-\\int_{0}^{t}B_{s}\\frac{\\partial f}{\\partial x}dB_{s}\n\\end{aligned}\\]\nApplying product rule to \\(tf(t,B_{t})\\), we get:\n\\[\\begin{aligned}\nd(tf) & =fdt+tdf+dt\\cdot df\\\\\n& =fdt+t\\left(\\frac{\\partial f}{\\partial t}dt+\\frac{\\partial f}{\\partial x}dB_{t}+\\frac{1}{2}\\frac{\\partial^{2}f}{\\partial x^{2}}(dB_{t})^{2}\\right)\\\\\n& +dt\\left(\\frac{\\partial f}{\\partial t}dt+\\frac{\\partial f}{\\partial x}dB_{t}+\\frac{1}{2}\\frac{\\partial^{2}f}{\\partial x^{2}}(dB_{t})^{2}\\right)\\\\\n& =fdt+t\\left(\\frac{\\partial f}{\\partial t}+\\frac{1}{2}\\frac{\\partial^{2}f}{\\partial x^{2}}\\right)dt+t\\frac{\\partial f}{\\partial x}dB_{t}\\\\\ntf & =\\int_{0}^{t}fds+\\int_{0}^{t}s\\left(\\frac{\\partial f}{\\partial t}+\\frac{1}{2}\\frac{\\partial^{2}f}{\\partial x^{2}}\\right)ds+\\int_{0}^{t}s\\frac{\\partial f}{\\partial x}dB_{s}\\\\\n\\int_{0}^{t}fds & =tf-\\int_{0}^{t}s\\left(\\frac{\\partial f}{\\partial t}+\\frac{1}{2}\\frac{\\partial^{2}f}{\\partial x^{2}}\\right)ds-\\int_{0}^{t}s\\frac{\\partial f}{\\partial x}dB_{s}\n\\end{aligned}\\]\nThe following example will be important when we discuss the Girsanov theorem.\n\nTheorem 3 (Ito’s formula for many Ito processes) Let \\(X_t = (X_t^{(j)},j\\leq d,j\\in\\mathbf{N})\\) be Ito processes constructed on \\((\\Omega,\\mathcal{F},\\mathbb{P})\\) and \\(f \\in C^{1,2}([0,T]\\times \\mathbb{R}^d)\\). Then for \\(t \\in [0,T]\\), we have:\n\\[\ndf(t,X_t) = \\partial_t f(t,X_t) dt + \\sum_{j=1}^{d} \\partial_{x_j} f(t,X_t) dX_t^{(j)} + \\frac{1}{2}\\sum_{j=1}^{d} \\sum_{k=1}^d \\partial_{x_j x_k}^2 f(t,X_t) dX_t^{(j)}\\cdot dX_t^{(k)}\n\\]"
  },
  {
    "objectID": "posts/ito-processes-and-stochastic-diff-eqs/index.html#numerical-simulation-of-sdes",
    "href": "posts/ito-processes-and-stochastic-diff-eqs/index.html#numerical-simulation-of-sdes",
    "title": "Ito Processes and Stochastic Differential Equations",
    "section": "",
    "text": "The good news is that it is not too hard to implement iterative schemes to sample paths of a diffusion. Consider \\((X_t,t\\leq T)\\) a solution to the SDE:\n\\[\ndX_t = \\sigma(X_t) dB_t + \\mu(X_t) dt\n\\]\nTo keep the notation to a minimum, we consider a time-homogeonous diffusion. For a partition \\((t_j,j\\leq n)\\) of \\([0,T]\\) with \\(t_n = T\\), consider the increment\n\\[\nX_{t_{j+1}} - X_{t_j} = \\int_{t_j}^{t_{j+1}} \\sigma(X_s) dB(s) + \\int_{t_j}^{t_{j+1}} \\mu(X_s) ds\n\\tag{14}\\]\nNote that, if \\(\\sigma\\) and \\(\\mu\\) are smooth functions, we can apply Ito’s formula to \\(\\sigma(X_s)\\) and \\(\\mu(X_s)\\) for \\(s\\in (t_j,t_{j+1}]\\)! We get:\n\\[\n\\begin{align*}\n\\sigma(X_s) &= \\sigma(X_{t_j}) + \\int_{t_j}^{s}\\sigma'(X_u) dX_u + \\frac{1}{2}\\int_{t_j}^{s} \\sigma''(X_u)(dX_u)^2\\\\\n\\mu(X_s) &= \\mu(X_{t_j}) + \\int_{t_j}^{s}\\mu'(X_u) dX_u + \\frac{1}{2}\\int_{t_j}^{s} \\mu''(X_u)(dX_u)^2\n\\end{align*}\n\\tag{15}\\]\nNow, we can approximate the increment in Equation 14 at different levels of precision by considering a different estimate for Equation 15.\n\nExample 13 (Euler-Maruyama Scheme). This scheme consists of taking \\(\\sigma(X_s) \\approx \\sigma(X_{t_j})\\) and \\(\\mu(X_s) \\approx \\mu(X_{t_j})\\) for \\(s \\in [t_j,t_{j+1})\\) in Equation 15. Putting this back in Equation 14, we get:\n\\[\nX_{t_{j+1}} - X_{t_j} \\approx \\sigma(X_{t_j})(B_{t_{j+1}}-B_{t_j}) + \\mu(X_{t_j})(t_{j+1} - t_j)\n\\tag{16}\\]\nThe process \\(X_t\\) can then be constructed recursively on the discrete set \\((t_j,j \\leq n)\\) as follows:\n\\[\n\\begin{align*}\nX_0 &= x\\\\\nX_{t_1} &= (X_{t_1} - X_0) + X_0\\\\\nX_{t_2} &= (X_{t_2} - X_{t_1}) + (X_{t_1} - X_0) + X_0\\\\\n\\vdots\\\\\nX_{t_n} &= \\sum_{j=0}^{n-1}(X_{t_{j+1}} - X_{t_j}) + X_0\n\\end{align*}\n\\]\n\n\nExample 14 (Milstein Scheme). In this scheme, we go an order further for the approximation of the volatility in Equation 15 and consider also the integral in \\(dX_u\\). We take \\(dX_u = \\sigma(X_{t_j})dB_u\\). We then express \\(\\sigma(X_s)\\) in Equation 15 as:\n\\[\n\\begin{align*}\n\\sigma(X_s) &\\approx \\sigma(X_{t_j}) + \\int_{t_j}^{s} \\sigma'(X_{t_j}) (\\sigma(X_{t_j})dB_u)\\\\\n&= \\sigma(X_{t_j}) + \\sigma'(X_{t_j}) \\sigma(X_{t_j}) \\int_{t_j}^{s}  dB_u\\\\\n&= \\sigma(X_{t_j}) + \\sigma'(X_{t_j}) \\sigma(X_{t_j}) (B_s - B_{t_j})\n\\end{align*}\n\\]\nIf we put this back in Equation 14, we get:\n\\[\n\\begin{align*}\nX_{t_{j+1}} - X_{t_j} &\\approx \\sigma(X_{t_j})(B_{t_{j+1}}-B_{t_j}) + \\mu(X_{t_j})(t_{j+1} - t_j) \\\\\n&+ \\sigma'(X_{t_j}) \\sigma(X_{t_j}) \\int_{t_j}^{t_{j+1}} (B(s) - B(t_j))dB(s)\n\\end{align*}\n\\tag{17}\\]\nNow, consider the function \\(f(x)=x^2\\). We have:\n\\[\n\\begin{align*}\nf_x(x) &= 2x\\\\\nf_{xx}(x) &= 2\n\\end{align*}\n\\]\nSo, we get:\n\\[\nB^2(t_{j+1}) - B^2(t_j) = 2 \\int_{t_j}^{t_{j+1}} B(s) dB(s) + \\frac{1}{2} \\int_{t_j}^{t_{j+1}} (2) ds\n\\]\nThus,\n\\[\n\\int_{t_j}^{t_{j+1}} B(s) dB(s) = \\frac{1}{2}[(B_{t_{j+1}}^2 - B_{t_j}^2)-(t_{j+1}-t_j)]\n\\tag{18}\\]\nSubstituting Equation 18 into Equation 17, we get the Milstein approximation:\n\\[\n\\begin{align*}\nX_{t_{j+1}} - X_{t_j} &\\approx \\sigma(X_{t_j})(B_{t_{j+1}}-B_{t_j}) + \\mu(X_{t_j})(t_{j+1} - t_j) \\\\\n&+\\sigma'(X_{t_j}) \\sigma(X_{t_j})  \\left[\\frac{1}{2}((B_{t_{j+1}}^2 - B_{t_j}^2)-(t_{j+1}-t_j)) -  B_{t_j}(B_{t_{j+1}}-B_{t_j})\\right]\\\\\n&= \\sigma(X_{t_j})(B_{t_{j+1}}-B_{t_j}) + \\mu(X_{t_j})(t_{j+1} - t_j) \\\\\n&+ \\frac{\\sigma'(X_{t_j}) \\sigma(X_{t_j})}{2}  \\left[(B_{t_{j+1}}^2 - B_{t_j}^2)-(t_{j+1}-t_j) -  2B_{t_j}B_{t_{j+1}}+2B_{t_j}^2\\right]\\\\\n&= \\sigma(X_{t_j})(B_{t_{j+1}}-B_{t_j}) + \\mu(X_{t_j})(t_{j+1} - t_j) \\\\\n&+ \\frac{\\sigma'(X_{t_j}) \\sigma(X_{t_j})}{2}  \\left[(B_{t_{j+1}} - B_{t_j})^2-(t_{j+1}-t_j)\\right]\n\\end{align*}\n\\]\nThus, under the Milstein scheme\n\\[\n\\begin{align*}\nX_{t_{j+1}} - X_{t_j} &\\approx \\sigma(X_{t_j})(B_{t_{j+1}}-B_{t_j}) + \\mu(X_{t_j})(t_{j+1} - t_j) \\\\\n&+ \\frac{\\sigma'(X_{t_j}) \\sigma(X_{t_j})}{2}  \\left[(B_{t_{j+1}} - B_{t_j})^2-(t_{j+1}-t_j)\\right]\n\\end{align*}\n\\tag{19}\\]\nThe recursive nature of these two schemes makes them easy to implement numerically. The Milstein scheme is not much more costly to implement as it contains only one more term than the Euler scheme.\n\n\n\nLet’s code an SIVP class and an abstract base class Solver.\n\nfrom dataclasses import dataclass\nfrom abc import ABC, abstractmethod\nfrom typing import Callable, Optional\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nsns.set_style(\"whitegrid\")\n\n# More descriptive type hints\nT = np.ndarray\nX = np.ndarray\n\n@dataclass\nclass SIVP:\n    \"\"\"\n    An abstraction for a stochastic initial value problem\n    \"\"\"\n    t_start : float\n    t_end : float\n    initial_condition: float\n\n    drift: Callable[[float, np.ndarray], np.ndarray]\n    vol: Callable[[float, np.ndarray], np.ndarray]\n    dvol_dx: Optional[Callable[[float, np.ndarray], np.ndarray]] = None\n\n\n\n@dataclass\nclass Solver(ABC):\n    \"\"\"\n    An abstract base class for all numerical schemes\n    \"\"\"\n\n    num_steps: int = 100\n    num_paths: int = 100\n\n    def __post_init__(self):\n        self.iter = 0\n\n        # x_values is a matrix of shape [num_paths,num_steps]\n        self.x_values = np.zeros((self.num_paths, self.num_steps + 1))\n        self.step_size = 1.0 / self.num_steps\n\n        # gaussian increments\n        self.brownian_increments = np.sqrt(self.step_size) * np.random.standard_normal(\n            size=(self.num_paths, self.num_steps)\n        )\n        self.brownian = np.cumsum(self.brownian_increments, axis=1)\n        self.brownian = np.concatenate(\n            [np.zeros(shape=(self.num_paths, 1)), self.brownian], axis=1\n        )\n\n    @abstractmethod\n    def iterate(self, sivp: SIVP) -&gt; X:\n        \"\"\"\n        Compute the next iterate X(n+1)\n        \"\"\"\n\n    def solve(self, sivp: SIVP) -&gt; (T, X):\n        \"\"\"\n        Solve the SIVP\n        \"\"\"\n        self.x_values[:, 0] = np.full(\n            shape=(self.num_paths,), fill_value=sivp.initial_condition\n        )\n        while self.iter &lt; self.num_steps:\n            self.x_values[:, self.iter + 1] = self.iterate(sivp)\n            self.iter += 1\n\n        times = np.linspace(sivp.t_start, sivp.t_end, self.num_steps + 1)\n        return times, self.x_values\n\n    def reset(self):\n        self.__post_init__()\n\nThe EulerMaruyama and Milstein methods will derive from the abstract base class Solver.\n\n@dataclass\nclass EulerMaruyama(Solver):\n    \"\"\"\n    Numerical solver for a stochastic differential equation(SDE) using\n    the Euler-Maruyama method.\n\n    Consider an SDE of the form :\n\n    dX_t = mu(t,X_t) dt + sigma(t,X_t) dB_t\n\n    with initial condition X_0 = x_0\n\n    The solution to the SDE can be computed using the increments\n\n    X_{n+1} - X_n = mu(n,X_n)(t_{n+1}-t_n) + sigma(n,X_n)(B(n+1)-B(n))\n\n    \"\"\"\n\n    def iterate(self, sivp: SIVP) -&gt; X:\n        \"\"\"\n        Generate the next iterate X(n+1)\n        \"\"\"\n        current_time = self.iter * self.step_size\n        mu_n = sivp.drift(current_time, self.x_values[:, self.iter])\n        sigma_n = sivp.vol(current_time, self.x_values[:, self.iter])\n        delta_x = (\n            mu_n * self.step_size + sigma_n * self.brownian_increments[:, self.iter]\n        )\n        return self.x_values[:, self.iter] + delta_x\n\n\n@dataclass\nclass Milstein(Solver):\n    \"\"\"\n    Numerical solver for a stochastic differential equation(SDE) using\n    the Euler-Maruyama method.\n\n    Consider an SDE of the form :\n\n    dX_t = mu(t,X_t) dt + sigma(t,X_t) dB_t\n\n    with initial condition X_0 = x_0\n\n    The solution to the SDE can be computed using the increments\n\n    X_{n+1} - X_n = mu(n,X_n)(t_{n+1}-t_n) + sigma(n,X_n)(B(n+1)-B(n))\n    + 0.5 * sigma(n,X_n) * sigma'(n,X_n) * ((B(n+1) - B(n))**2 - (t_{n+1} - t_n))\n\n    \"\"\"\n\n    def iterate(self, sivp: SIVP):\n        \"\"\"\n        Generate the next iterate X(n+1)\n        \"\"\"\n        current_time = self.iter * self.step_size\n        mu_n = sivp.drift(current_time, self.x_values[:, self.iter])\n        sigma_n = sivp.vol(current_time, self.x_values[:, self.iter])\n        dvol_dx_n = sivp.dvol_dx(current_time, self.x_values[:, self.iter])\n\n        delta_x = (\n            mu_n * self.step_size\n            + sigma_n * self.brownian_increments[:, self.iter]\n            + 0.5\n            * sigma_n\n            * dvol_dx_n\n            * (self.brownian_increments[:, self.iter] ** 2 - self.step_size)\n        )\n\n        return self.x_values[:, self.iter] + delta_x\n\n\nExercise 4 (Simulating SDEs) Simulate 100 paths for the following diffusions given by their SDEs on \\([0,1]\\) using the Euler-Maruyama scheme and the Milstein scheme for a discretization of \\(0.01\\).\n\nGeometric Brownian Motion:\n\n\\[\ndS_t = S_t dB_t + \\left(\\mu + \\frac{\\sigma^2}{2}\\right)S_t dt, \\quad S_0 = 1\n\\]\nfor \\(\\mu=-1/2\\), \\(\\mu=-2\\), and \\(\\mu=0\\)\n\nOrnstein-Uhlenbeck process:\n\n\\[\ndX_t = -X_t dt + dB_t, \\quad X_0 = 1\n\\]\n\nThe diffusion:\n\n\\[\ndX_t = \\sqrt{1+X_t^2}dB_t + \\sin X_t dt, \\quad X_0 = 0\n\\]\n\nSolution.\nWe can now use EulerMaruyama and Milstein solvers and generate some sample paths.\n\n\nShow the code\ndef plot_trajectories(ts, xs, title):\n    plt.xlabel(r'Time $t$')\n    plt.ylabel(r'$X(t)$')\n    plt.title(title)\n    plt.grid(True)\n    plt.plot(ts, xs.transpose())\n    plt.show()\n\n# mu = -0.5 case\neuler = EulerMaruyama(num_paths=10, num_steps=100)\n\ngbm_sde = SIVP(\n    t_start=0.0,\n    t_end=1.0,\n    initial_condition=1.0,\n    drift=lambda t, s_t: np.zeros(10),\n    vol=lambda t, s_t: s_t,\n    dvol_dx=lambda t, s_t: np.ones(10),\n)\n\n\nts, xs = euler.solve(gbm_sde)\neuler.reset()\n\nplot_trajectories(ts, xs, r'10 sample paths of Geometric Brownian Motion, $\\mu=-0.5$')\n\n# mu = -2 case\ngbm_sde.drift = lambda t, s_t : -1.5 * s_t\nts, xs = euler.solve(gbm_sde)\neuler.reset()\n\nplot_trajectories(ts, xs, r'10 sample paths of Geometric Brownian Motion, $\\mu=-2.0$')\n\n# mu = 0 case\ngbm_sde.drift = lambda t, s_t : 0.5 * s_t\nts, xs = euler.solve(gbm_sde)\neuler.reset()\n\nplot_trajectories(ts, xs, r'10 sample paths of Geometric Brownian Motion, $\\mu=0.0$')\n\n# ornstein-uhlenbeck\nornstein_uhlenbeck_sde = SIVP(\n    t_start=0.0,\n    t_end=1.0,\n    initial_condition=1.0,\n    drift = lambda t, s_t : -s_t,\n    vol = lambda t, s_t : np.ones(10),\n    dvol_dx = lambda t, s_t : np.zeros(10)\n)\n\nts, xs = euler.solve(ornstein_uhlenbeck_sde)\neuler.reset()\n\nplot_trajectories(ts, xs, r'10 sample paths of Ornstein-Uhlenbeck')\n\n# diffusion\ndiffusion_sde = SIVP(\n    t_start=0.0,\n    t_end=1.0,\n    initial_condition=0.0,\n    drift = lambda t, s_t : np.sin(s_t),\n    vol = lambda t, s_t : np.sqrt(1+s_t**2),\n    dvol_dx = lambda t, s_t : s_t / np.sqrt(1 + s_t**2) \n)\n\nts,xs = euler.solve(diffusion_sde)\neuler.reset()\n\nplot_trajectories(ts, xs, r'10 sample paths of the diffusion')\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nIt is of course possible go beyond the Milstein scheme to improve the approximation. However, it turns out that the above schemes already converge quite rapidly to the process itself. To see this, consider the mean absolute error between the approximation \\(X_T^{(n)}\\) at time \\(T\\) and \\(X_T\\). Suppose that the approximation \\(X^{(n)}\\) is obtained for a partition with discretization \\(t_{j+1}-t_j = 1/n\\). It is possible to show that for the Euler scheme, we have:\n\\[\n\\begin{align*}\n\\mathbb{E}[|X_T^{(n)} - X_T|] \\leq \\frac{C}{\\sqrt{n}}\n\\end{align*}\n\\]\nwhereas for the Milstein scheme\n\\[\n\\begin{align*}\n\\mathbb{E}[|X_T^{(n)} - X_T|] \\leq \\frac{C'}{n}\n\\end{align*}\n\\]\nfor some constants \\(C,C'&gt;0\\). Note that the mean error between the two process must be the worst at the last point, since the errors add up."
  },
  {
    "objectID": "posts/ito-processes-and-stochastic-diff-eqs/index.html#existence-and-uniqueness-of-sdes",
    "href": "posts/ito-processes-and-stochastic-diff-eqs/index.html#existence-and-uniqueness-of-sdes",
    "title": "Ito Processes and Stochastic Differential Equations",
    "section": "",
    "text": "As for the differential equations in standard calculus, SDEs play an important role in modelling stochastic phenomena. To model a trajectory \\(X_t, t\\leq T\\), it suffices to write down the variation due to the deterministic change \\(\\mu(X_t)dt\\) for some function \\(\\mu(X_t)\\) and the variation due to local fluctuations \\(\\sigma(X_t)dB_t\\) for some function \\(\\sigma(X_t)\\). Here, we assume that the local drift and volatility are time-homogenous for simplicity. This gives the SDE:\n\\[\ndX_t = \\mu(X_t) dt + \\sigma(X_t) dB_t\n\\]\nDo we get one nice Ito process for any choice of functions \\(\\sigma\\) and \\(\\mu\\)? The short answer is no. Here are sufficient conditions for the existence of a unique process.\n\nTheorem 4 (Existence and Uniqueness of solutions to SDE) Consider the SDE\n\\[\ndX_t = \\mu(X_t) dt  + \\sigma(X_t)dB_t, \\quad X_0 = x, \\quad t\\in [0,T]\n\\]\nIf the functions \\(\\sigma\\) and \\(\\mu\\) grow not faster than \\(Kx^2\\) for some \\(K&gt;0\\) and are differentiable with bounded derivatives on \\(\\mathbb{R}^1\\), then there exists a unique solution \\((X_t,t\\in[0,T])\\) to the SDE. In other words, there exists a continuous process \\((X_t, t \\leq T)\\) adapted to the filtration of the Brownian motion given by:\n\\[\nX_t = x + \\int_0^t \\mu(X_s) ds + \\int_0^t \\sigma(X_s) dB_s, \\quad t\\leq T\n\\]\n\n\nExample 15 Consider the SDE :\n\\[\ndX_t = \\sqrt{1 + X_t^2}dB_t + \\sin X_t dt\n\\tag{20}\\]\nThere exists a unique diffusion process \\((X_t,t\\geq 0)\\) that is a solution of this SDE. To see this, we verify the conditions of the Theorem 4. We have:\n\\[\n\\sigma(x) = \\sqrt{1 + x^2}, \\quad \\mu(x) = \\sin x\n\\]\nClearly, these functions satisfy the growth condition since \\(\\mu\\) is bounded and \\(\\sigma\\) grows like \\(|x|\\) for large \\(x\\). As for the derivatives, we have \\(\\sigma'(x)=\\frac{x}{\\sqrt{1+x^2}}\\) and \\(\\mu'(x)=\\cos x\\). The two derivatives are bounded.\n\nThe assumptions of Theorem 4 are not too surprising, since similar ones are found in the classical case of ODE. For example, if we have the ODE\n\\[\n\\frac{dX_t}{dt} = X_t^{1/2}, \\quad X_0 = 0\n\\]\nthen clearly \\(X_t = 0\\) for all \\(t\\) is a solution. But, we also have by integrating that:\n\\[\nX_t = \\frac{t^2}{4}, t \\geq 0\n\\]\nTherefore, the uniqueness breaks down. Note, that the function \\(\\mu(x)=\\sqrt{x}\\) does not have bounded derivatives at \\(0\\). Similarly, consider the ODE:\n\\[\n\\frac{dX_t}{dt} = e^{X_t}, X_0 = 0\n\\]\nHere, the function \\(\\mu(x)\\) grows much faster than \\(x^2\\). The solution of the ODE is by integrating\n\\[\n\\begin{align*}\n-(e^{-X_t} - 1) &= t\\\\\ne^{-X_t} &= (1 - t)\\\\\n-X_t &= \\log(1 - t)\\\\\nX_t &= \\log \\left(\\frac{1}{1-t}\\right)\n\\end{align*}\n\\]\nThe solution explodes at \\(t=1\\). The same phenomenon may occur for SDE; that is the process will almost surely go \\(\\infty\\) in finite time. These times are called explosion times. Note that it is possible to consider the paths of the diffusion upto these explosion times. It is important to keep in mind that the conditions of Theorem 4 are sufficient, but not necessary. In particular, it is sometimes possible to explicitly construct a diffusion whose local volatility and drift do not satisfy the conditions. Let’s look at two important instances of such diffusions.\n\nLet \\(B_t\\) be a brownian motion in \\(\\mathbb{R}^d\\) for \\(d&gt;1\\). Consider the process giving the distance at time \\(t\\) of \\(B_t\\) to the origin; that is:\n\\[\nR_t = ||B_t|| = \\left(\\sum_{j=1}^d B_t^{(j)}\\right)^2\n\\]\n(For \\(d=1\\), this is simply \\(|B_t|\\). Ito’s formula cannot be applied in this case, since the absolute value is not differentiable at the origin.) In higher dimensions, the function is smooth enough as long as we stay away from the origin. This is not a problem as long as \\(R_0 &gt; 0\\).\n\nLet’s find out the SDE that this process satisfies.\nLet \\(r=f(x_1,x_2,\\ldots,x_d)=\\sqrt{\\sum_{j=1}^d x_j^2}\\). We have:\n\\[\\begin{align*}\n\\frac{\\partial r}{\\partial x_j} &= \\frac{x_j}{\\sqrt{\\sum_{j=1}^d x_j^2}}\\\\\n\\frac{\\partial^2 r}{\\partial x_j^2} &= \\frac{||x|| - x_j \\cdot \\frac{x_j}{||x||}}{||x||^2}\\\\\n&= \\frac{||x||^2 - x_j^2}{||x||^3}\n\\end{align*}\\]\nBy Ito’s formula,\n\\[\\begin{align*}\ndR_t &= \\sum_{j=1}^{d} \\frac{B_t^{j}}{R_t} dB_t^{(j)} + \\frac{1}{2} \\sum_{j=1}^{d} \\frac{R_t^2 - (B_t^{(j)})^2}{R_t^3}\\\\\n&= \\sum_{j=1}^{d} \\frac{B_t^{j}}{R_t} dB_t^{(j)} + \\frac{1}{2} \\frac{d R_t^2 - R_t^2}{R_t^3}\\\\\n&= \\sum_{j=1}^{d} \\frac{B_t^{j}}{R_t} dB_t^{(j)} + \\frac{1}{2} \\frac{(d-1)}{R_t}\n\\end{align*}\\]\nWe can define \\(dW_t = \\sum_{j=1}^{d} \\frac{B_t^{(j)}}{R_t} dB_t^{(j)}\\). Then, \\(dR_t = dW_t + \\frac{d-1}{2R_t}dt\\)\nIt turns out that \\((W_t,t \\geq 0)\\) is a standard Brownian motion by Levy’s characterization theorem. This is the subject of the next section. The SDE shows that \\(dR_t\\) is a diffusion. The SDE makes sense for any real number \\(d &gt; 1\\), not only integers. Moreover, the SDE is well-defined since \\(R_t\\) is never equal to \\(0\\). However, the SDE does not satisfy the assumption of the existence and uniqueness of the solution of SDEs since \\(1/x\\) diverges at \\(0\\). The solution to the SDE still exists since we constructed it! We sample paths of this process in numerical project.\n\nExample 16 (The Cox-Ingersoll-Ross (CIR) model.) Consider the SDE:\n\\[\ndS_t = \\sigma \\sqrt{S_t} dW_t + (a - bS_t)dt, \\quad S_0 &gt; 0\n\\tag{21}\\]\nfor some parameters \\(a,b &gt; 0\\) where \\((W_t,t \\geq 0)\\) is a standard Brownian motion. The local volatility \\(\\sigma(x)=\\sigma \\sqrt{x}\\) does not have a bounded derivative close to \\(0\\), since \\(\\sigma'(x)=\\frac{\\sigma}{2\\sqrt{x}}\\). We will nevertheless construct a diffusion that is a solution to the SDE. Consider independent Ornstein-Uhlenbeck processes \\(X_t^{(j)}, j \\leq d\\), with SDE:\n\\[\ndX_t^{(j)} = \\frac{-b}{2}X_t^{(j)}dt + \\frac{\\sigma}{2}dB_t^{(j)}, \\quad X_0^{(j)} &gt; 0\n\\]\nwhere \\(B_t = (B_t^{(j)},j\\leq d)\\) is a Brownian motion in \\(\\mathbb{R}^d\\). We consider the process\n\\[\nS_t = \\sum_{j \\leq d} (X_t^{(j)})^2\n\\]\nClearly, \\(S_t\\) is nongegative for all \\(t \\geq 0\\) by design, so \\(\\sqrt{S_t}\\) is well-defined. Let’s compute the SDE of the process. By Ito’s formula, we have:\n\\[\n\\begin{align*}\ndS_t &= 2\\sum_{j=1}^{d}X_t^{(j)} dX_t^{(j)} + \\frac{1}{2}\\sum_{j=1}^{d} 2 (dX_t^{(j)})^2\\\\\n&=2\\sum_{j=1}^{d}X_t^{(j)} dX_t^{(j)} + \\frac{\\sigma^2}{4}\\sum_{j=1}^{d} dt \\\\\n&=2\\sum_{j=1}^{d}X_t^{(j)} \\left(\\frac{-b}{2}X_t^{(j)}dt + \\frac{\\sigma}{2}dB_t^{(j)}\\right) + \\frac{d\\sigma^2}{4} dt\\\\\n&=\\left[\\left(\\sum_{j=1}^d (-b)(X_t^{(j)})^2\\right) + \\frac{d\\sigma^2}{4}\\right] dt + \\sigma \\sum_{j=1}^{d} X_t^{(j)} dB_t^{(j)}\\\\\n&=\\sigma \\sum_{j=1}^{d} X_t^{(j)} dB_t^{(j)} + \\left[\\frac{d\\sigma^2}{4} - b S_t\\right] dt \\\\\n&= \\sigma \\sqrt{S_t} \\sum_{j=1}^{d} \\frac{X_t^{(j)}}{\\sqrt{S_t}} dB_t^{(j)}  + \\left[\\frac{d\\sigma^2}{4} - b S_t\\right] dt \\\\\n&= \\sigma \\sqrt{S_t} dW_t  + \\left[\\frac{d\\sigma^2}{4} - b S_t\\right] dt \\\\\n\\end{align*}\n\\]\nwhere we have defined \\(dW_t = \\sum_{j=1}^d \\frac{X_t^{(j)}}{\\sqrt{S_t}} dB_t^{(j)}\\). It turns out that the process \\((W_t,t\\geq 0)\\) is a standard brownian motion by Levy’s characterization theorem. If we accept this for a moment, we have the SDE:\n\\[\ndS_t = \\sigma \\sqrt{S_t} dW_t + \\left(\\frac{d \\sigma^2}{4} - bS_t\\right) dt, \\quad S_0 &gt; 0\n\\tag{22}\\]\nThis is a time-homogenous diffusion called the Cox-Ingersoll-Ross (CIR) process. Again, notice that there are no issues with square root, since \\(S_t\\) is positive by construction! The SDE also makes sense if replace \\(d\\sigma^2/4\\) by a parameter \\(a\\) in Equation 21 as long as \\(a \\geq \\frac{d\\sigma^2}{4}\\). This process is important for interest rates and stochastic volatility models.\nNote that the local drift is \\(a - bS_t, a\\ge \\frac{d\\sigma^2}{4}\\). This can be written as:\n\\[\\begin{align*}\na - bS_t = b\\left(\\frac{b}{a} - S_t \\right)\n\\end{align*}\\]\nThis means that the local drift is negative if \\(S_t &gt; \\frac{a}{b}\\) and it is positive if \\(S_t &lt; \\frac{a}{b}\\). So, the SDE exhibits the same phenomenon as for the SDE of the Ornstein-Uhlenbeck process in Example 5. In particular we should expect that for \\(t\\) large, the process should fluctuate around the mean value \\(\\frac{a}{b}\\). The CIR model is therefore an example of a mean-reverting process. More generally, this hints to the fact, that the process is stationary in the long run."
  },
  {
    "objectID": "posts/ito-processes-and-stochastic-diff-eqs/index.html#martingale-representation-and-levys-characterization",
    "href": "posts/ito-processes-and-stochastic-diff-eqs/index.html#martingale-representation-and-levys-characterization",
    "title": "Ito Processes and Stochastic Differential Equations",
    "section": "",
    "text": "We know very well by now, that an Ito integral is continuous martingale with respect to the Brownian filtration, whenever the integrand is in \\(\\mathcal{L}_c^2(T)\\). What can we say about the converse? In other words, if we have a martingale with respect to the Brownian filtration, can it be expressed as an Ito integral for some integrand \\((V_t,t\\leq T)\\)? Amazingly, the answer to this question is yes!\n\nTheorem 5 (Martingale Representation Theorem.) Let \\((B_t,t \\geq 0)\\) be a Brownian motion with filtration \\((\\mathcal{F}_t,t\\geq 0)\\) on \\((\\Omega,\\mathcal{F},\\mathbb{P})\\). Consider a martingale \\((M_t,t\\leq T)\\) with respect to this filtration. Then, there exists an adapted process \\((V_t,t \\leq T)\\) such that:\n\\[\nM_t = M_0 + \\int_0^t V_s dB_s, \\quad t \\leq T\n\\tag{23}\\]\nOne striking fact of the result is that \\((M_t,t\\leq T)\\) ought to be continuous. In other words, we cannot construct a process with a jump that is a martingale adapted to Brownian motion!\nInstead of the proving the theorem, we will see how the result is not too surprising with stronger assumptions. Instead of supposing that \\(M_t\\) is \\(\\mathcal{F}_t\\) measurable, take that \\(M_t\\) is \\(\\sigma(B_t)\\)-measurable. In other words, \\(M_t=h(B_t)\\) for some function \\(h\\). In the case where \\(h\\) is smooth, then it is clear by Ito’s formula that the representation Equation 23 holds with \\(V_s = h'(B_s)\\).\n\nAn important consequence of Theorem 5 is a third definition of Brownian motion.\n\nTheorem 6 (One-dimensional Levy’s Characterization theorem) Let \\((M_t,t\\in [0,T])\\) be a continuous martingale with respect to the filtration \\((\\mathcal{F}_t,t \\leq T)\\) with \\(M_0 = 0\\) and with quadratic variation \\(&lt;M&gt;_t = t\\). Then, \\((M_t,t\\leq T)\\) is a standard brownian motion.\n\nProof.\nWe first need to show that \\(M_t - M_s \\sim \\mathcal{N}(0,t - s)\\) or using the characteristic function approach, we need to show that \\(f_{(M_t - M_s)}(\\theta)=\\mathbb{E}[e^{\\theta (M_t - M_s)}] = e^{\\frac{1}{2}\\theta^2 (t-s)}\\) for constant \\(\\theta\\).\nLet \\(f(t,x) = e^{\\theta x - \\frac{1}{2}\\theta^2 t}\\).\nBy Ito’s formula, we have:\n\\[\\begin{align*}\ndf(t,M_t) &= \\theta e^{\\theta M_t - \\frac{1}{2}\\theta^2 t} dM_t + \\left(-\\frac{1}{2}\\theta^2 + \\frac{1}{2} \\theta^2 \\right)e^{\\theta M_t - \\frac{1}{2}\\theta^2 t}dt\\\\\n&= \\theta f(t,M_t) dM_t\n\\end{align*}\\]\nIntegrating on both sides, we get:\n\\[\\begin{align*}\nf(t,M_t) - f(s,M_s) &= \\theta \\int_0^t f(u,M_u) dM_u\n\\end{align*}\\]\nThe ito integral \\(\\int_0^t f(s,M_s) dM_s\\) is well-defined and its expectation is \\(0\\). Hence, applying expectation operator on both sides, we get:\n\\[\\begin{align*}\n\\mathbb{E}[f(t,M_t) - f(s,M_s)] &= \\theta \\mathbb{E} \\left[ \\int_0^t f(s,M_s) dM_s\\right]\\\\\n&= 0\n\\end{align*}\\]\nSince \\(e^{x} \\neq 0\\) for all \\(x\\), dividing by \\(f(s,M_s)\\), we get:\n\\[\\begin{align*}\n\\mathbb{E}\\left[\\frac{f(t,M_t)}{f(s,M_s)}\\right] &= 1\\\\\n\\mathbb{E}\\left[\\frac{e^{\\theta M_t - \\frac{1}{2}\\theta^2 t}}{e^{\\theta M_s - \\frac{1}{2}\\theta^2 s}}\\right] &= 1\\\\\n\\mathbb{E}\\left[e^{\\theta(M_t - M_s)}\\right] &= e^{\\frac{1}{2}\\theta^2(t-s)}\n\\end{align*}\\]\nwhich is the moment generating function for the normal distribution with mean zero and variance \\(t-s\\). So, \\(M_t - M_s \\sim \\mathcal{N}(0, t - s)\\).\nFurther, consider \\(t_1 \\leq t_2 \\leq t_3\\). We have:\n\\[\\begin{align*}\n\\mathbb{E}[(M_{t_3} - M_{t_2})(M_{t_2} - M_{t_1})] &= \\mathbb{E}[\\mathbb{E}[(M_{t_3} - M_{t_2})(M_{t_2} - M_{t_1})|\\mathcal{F}_{t_2}]] \\\\\n&= \\mathbb{E}[(M_{t_2} - M_{t_1})\\mathbb{E}[(M_{t_3} - M_{t_2})|\\mathcal{F}_{t_2}]] \\\\\n&= \\mathbb{E}[(M_{t_2} - M_{t_1})(M_{t_2} - M_{t_2})] \\\\\n&= 0\n\\end{align*}\\]\nwhere \\(\\mathbb{E}[M_{t_3} - M_{t_2}|\\mathcal{F}_{t_2}] = 0\\) follows from the fact that \\((M_t,t\\geq 0)\\) is a martingale. Consequently, \\(M_{t_3} - M_{t_2} \\perp M_{t_2} - M_{t_1}\\) and non-overlapping increments are independent.\nMoreover, \\(M(0) = 0\\). So, \\((M_t,t\\geq 0)\\) is a standard brownian motion. This closes the proof. \\(\\blacksquare\\)"
  },
  {
    "objectID": "posts/ito-processes-and-stochastic-diff-eqs/index.html#exercise-problems",
    "href": "posts/ito-processes-and-stochastic-diff-eqs/index.html#exercise-problems",
    "title": "Ito Processes and Stochastic Differential Equations",
    "section": "",
    "text": "Exercise 5 Let \\((\\Omega,\\mathcal{F},\\mathbb{P})\\) be a probability space and \\((W_t,t\\geq 0)\\) be a standard Wiener process. Find the SDE for the random process \\(X_t = W_t^n, n \\in \\mathbb{Z}^{+}\\).\nShow that\n\\[\n\\mathbb{E}[W_t^n] = \\frac{1}{2}n(n-1) \\int_0^t \\mathbb{E}\\left[W_s^{(n-2)}\\right] ds\n\\]\nand using mathematical induction prove that:\n\\[\n\\mathbb{E}[W_t^n] = \\begin{cases}\n\\frac{n! t^{n/2}}{2^{n/2} \\left(\\frac{n}{2}\\right)!}, & n=2,4,6,\\ldots\\\\\n0, & n=1,3,5,\\ldots\n\\end{cases}\n\\]\n\nSolution."
  },
  {
    "objectID": "posts/interpolation-and-approximation/index.html",
    "href": "posts/interpolation-and-approximation/index.html",
    "title": "Interpolation and Approximation",
    "section": "",
    "text": "In this blog post, I would like to implement some interpolation algorithms using modern C++. It’s important we understand how and why these algorithms work. Because there are nuances, exceptions and corner-cases, we need to understand. It’s a great learning experience! You never fully understand something like the \\(QR\\)-algorithm (which is actually incredibly complicated to get the details right), unless you spend some time implementing it. A lot of the skills you pick up will translate when you write numerical codes.\nEven if you have excellent implementations of any algorithm, you still need to understand some of the internals in order to make good use of your library. For example, any linear algebra library can compute an inverse matrix really fast and as accurately as mathematics allows. But, you have to know a little theory in order to know that you should still avoid using that if at all possible. (Matrix decomposition and solving without explicitly computing the inverse is better, generally speaking)."
  },
  {
    "objectID": "posts/interpolation-and-approximation/index.html#introduction",
    "href": "posts/interpolation-and-approximation/index.html#introduction",
    "title": "Interpolation and Approximation",
    "section": "",
    "text": "In this blog post, I would like to implement some interpolation algorithms using modern C++. It’s important we understand how and why these algorithms work. Because there are nuances, exceptions and corner-cases, we need to understand. It’s a great learning experience! You never fully understand something like the \\(QR\\)-algorithm (which is actually incredibly complicated to get the details right), unless you spend some time implementing it. A lot of the skills you pick up will translate when you write numerical codes.\nEven if you have excellent implementations of any algorithm, you still need to understand some of the internals in order to make good use of your library. For example, any linear algebra library can compute an inverse matrix really fast and as accurately as mathematics allows. But, you have to know a little theory in order to know that you should still avoid using that if at all possible. (Matrix decomposition and solving without explicitly computing the inverse is better, generally speaking)."
  },
  {
    "objectID": "posts/interpolation-and-approximation/index.html#the-interpolation-problem",
    "href": "posts/interpolation-and-approximation/index.html#the-interpolation-problem",
    "title": "Interpolation and Approximation",
    "section": "The Interpolation Problem",
    "text": "The Interpolation Problem\nPolynomials are used as the basic means of approximation and are ubiquitous in nearly all areas of computational science.\nLet \\(a=x_1 &lt; x_2 &lt; \\ldots &lt; x_n = b\\) be a grid of distinct points. Let \\(\\mathcal{P}_n\\) be the vector space of of polynomials in one variable with degree \\(\\leq n - 1\\). We are interested to find a polynomial \\(p \\in \\mathcal{P}_n\\) such that:\n\\[\n\\begin{align*}\np(x_i) = f(x_i), \\quad i = 1 : n\n\\end{align*}\n\\tag{1}\\]\n\nTheorem 1 (Uniqueness of the interpolating polynomial) If \\(x_1,\\ldots,x_n\\) are distinct real numbers, then for arbitrary values \\(y_1,\\ldots,y_n\\), there is a unique polynomial \\(p\\in \\mathcal{P}_{n}\\) of degree at most \\(n-1\\) such that:\n\\[p(x_i) = y_i,  \\quad i = 1 : n\\]\n\nProof.\nSuppose that there were two such polynomials \\(p\\) and \\(q\\). Then, the polynomial \\(p-q\\) would have the property \\((p-q)(x_i)=0\\) for \\(1 \\leq i \\leq n\\). Since, the degree of \\((p-q)\\) can be at most \\(n-1\\), this polynomial can have atmost \\((n-1)\\) zeroes, if is not the \\(0\\) polynomial. Since the \\(x_i\\)’s are distinct, it follows that:\n\\[\n(p-q)(x) = (x - x_1)(x - x_2)\\ldots(x-x_n) = \\prod_{i=1}^n (x-x_i)\n\\]\nand it has atleast \\(n\\) zeroes. Hence, \\((p-q)(x)\\equiv 0\\) - it must be identically equal to zero. So, \\(p(x) = q(x)\\) for all \\(x\\). This closes the proof. \\(\\blacksquare\\)\n\nBases for polynomial interpolation\nA set of polynomials \\(\\{p_1(x), p_2(x), \\ldots, p_n(x)\\}\\) such that the polynomial \\(p \\in \\mathcal{P}_n\\) can be expressed as a linear combination :\n\\[\np(x) = \\sum_{j=1} c_j p_j(x)\n\\]\nis called a basis for \\(\\mathcal{P}_n\\). The column vector \\(c=(c_1,c_2,\\ldots,c_n)^T\\) can be viewed as the coordinate vector of \\(p\\) in the polynomial space \\(\\mathcal{P}_n\\). The inerpolation problem leads to a system of equations:\n\\[\n\\begin{align*}\nc_1 p_1(x_i) + c_2 p_2(x_i) + \\ldots + c_n p_n(x_i) = f(x_i), \\quad i=1:n\n\\end{align*}\n\\tag{2}\\]\nIf we introduce the matrix :\n\\[\n\\begin{align*}\nP_n = [p_j(x_i)]_{i,j=1}^n\n\\end{align*}\n\\tag{3}\\]\nand the column vector \\(f=(f(x_1),\\ldots,f(x_n))^T\\), then the linear system becomes:\n\\[\n\\begin{align*}\nP_n c = f\n\\end{align*}\n\\tag{4}\\]\nMathematically, the choice of a basis (for a finite-dimensional space) makes no difference. Computationally, when working with rounded values of coefficients, the choice of basis can make a great difference. If the purpose is to compute derivatives or integrals of the interpolation polynomial, the power basis or the shifted power basis, where \\(p_j(x) = (x - c)^{j-1}\\) that is:\n\\[\np(x)= \\sum_{j=1}^n c_j(x)(x - c)^{j-1}\n\\]\nis convenient although not always the best. If a shifted power basis is to be used for polynomial approximation on an interval \\([a,b]\\), it is often the best to choose \\(c = (a + b)/2\\), equal to the midpoint of the interval.\nFor the power basis \\(p_j(x) = x^{j-1}\\), the coefficients of the interpolation polynomial are given by the solution of the linear system \\(V_n^T c = f\\), where \\(V_n\\) is the Vandermonde matrix\n\\[\nV_n = [x_j^{i-1}]_{i,j=1}^n =\n\\begin{bmatrix}\n1 & 1 & \\ldots & 1\\\\\nx_1 & x_2 & \\ldots & x_n \\\\\n\\vdots & \\vdots & \\ldots & \\vdots\\\\\nx_1^{n-1} & x_2^{n-1} & \\ldots & x_n^{n-1}\n\\end{bmatrix}\n\\tag{5}\\]"
  },
  {
    "objectID": "posts/interpolation-and-approximation/index.html#piecewise-polynomial-interpolation",
    "href": "posts/interpolation-and-approximation/index.html#piecewise-polynomial-interpolation",
    "title": "Interpolation and Approximation",
    "section": "Piecewise Polynomial Interpolation",
    "text": "Piecewise Polynomial Interpolation\nInterpolating a given function by a single polynomial over its entire range can be an ill-conditioned problem, as illustrated by Runge’s phenomenon. On the other hand, polynomials of low degree can give good approximations locally in a small interval. I would like to discuss approximation schemes for piecewise polynomial interpolation with different degrees of global continuity.\nWith the use of piecewise polynomials, there is no reason to fear equidistant data, as opposed to the situation with higher-degree polynomials. In computer graphics and computer-aided design(CAD), curves and surfaces have to be represented mathematically, so that they can be manipulated and visualized easily. In 1962, Bezier and de Casteljau, working for French car companies Renault and Citroen, independently developed Bezier curves for fitting curves and surfaces. Similar work, using bicubic splines, was done in USA at general motors by Garret Birkhoff and Henry Garabedian.\nToday, Bezier curves and spline functions are used extensively in all aircraft and automotive industries. Spline functions can also be used in the numerical treatment of boundary value problems for differential equations. Bezier curves have found use in computer graphics and typography. Trutype font glyphs are made of quadratic bezier curves.\n\nBernstein Polynomials and Bezier Curves\nParametric curves are often used find the functional form of a curve given geometrically by a set of points \\(p_i \\in \\mathbf{R}^d\\), \\(i=0:n\\).\nLet \\(c(t) \\in \\mathbf{R}^d\\), \\(t\\in[0,1]\\), be a parameteric curve. In the simplest case, \\(n=1\\), we take \\(c(t)\\) to be linear:\n\\[\nc(t) = (1-t)p_0 + tp_1\n\\]\nand connecting the two points \\(p_0\\) and \\(p_1\\), so that \\(p(0)=c_0\\) and \\(p_1 = c(1)\\). It is the parametric equation for a straight-line.\nFor \\(n &gt; 1\\), this will not give a smooth curve and is therefore of limited interest.\nWe can generalize this approach and take \\(c(t)\\) to be a polynomial of degree \\(n\\):\n\\[\nc(t) =\\sum_{i=0}^{n-1} p_i B_i(t),\\quad t\\in[0,1]\n\\]\nwhere \\(B_i(t)\\), \\(i=0 : n\\) are the Bernstein polynomials defined by :\n\\[\nB_i^{n}(t) = {n \\choose i} t^{i} (1-t)^{n-i}, \\quad i=0:n\n\\]\nUsing the binomial theorem, we have:\n\\[\n1 = ((1-t) + t)^n = \\sum_{i=0}^n {n \\choose i}t^i (1-t)^{n-i} = \\sum_{i=0}^n B_i^{n}(t)\n\\]\nThus, the Bernstein polynomials of degree \\(n\\) are non-negative on \\([0,1]\\) and give a partition of unity.\nFor \\(n=3\\), the four cubic Bernstein polynmials are:\n\\[\n\\begin{align*}\nB_0^3 &= (1-t)^3\\\\\nB_1^3 &= 3(1-t)^2 t\\\\\nB_2^3 &= 3(1-t)t^2\\\\\nB_3^3 &= t^3\n\\end{align*}\n\\]\n\nusing Plots\nusing LaTeXStrings\n\nB₀(t) = (1-t)^3\nB₁(t) = 3*(1-t)^2*t\nB₂(t) = 3*(1-t)*t^2\nB₃(t) = t^3\n\nplot([B₀, B₁, B₂, B₃], 0.0, 1.0, label=[L\"B_0\" L\"B_1\" L\"B_2\" L\"B_3\"])\n\n\n\n\n  \n    \n  \n\n\n\n  \n    \n  \n\n\n\n  \n    \n  \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nSome important properties of the Bernstein polynomials are given in the following theorem.\n\nTheorem 2 (Berstein polynomial properties) The Bernstein polynomials \\(B_i^{n}(t)\\) have the following properties:\n\nNon-negativity: \\(B_i^{n}(t) &gt; 0\\), \\(t\\in(0,1)\\)\nSymmetry: \\(B_i^{n}(t)=B_{n-i}^{n}(1-t)\\)\n\\(B_i^{n}(t)\\) has a root \\(t=0\\) of multiplicity \\(i\\) and a root \\(t=1\\) of multiplicity \\(n-i\\)\nThe Bernstein polynomials \\(B_i^{n}(t)\\) have a unique maximum value at \\(t=i/n\\) on \\([0,1]\\)\nThe Bernstein polynomials satisfy the following recursion formula: \\[\n\\begin{align*}\nB_i^n(t) = (1-t)B_i^{n-1}(t) + tB_{i-1}^{n-1}(t),\\quad i=0:n\n\\end{align*}\n\\tag{6}\\]\n\n\n\nThe Bernstein polynomials of degree \\(n\\) form a basis for the space of polynomials of degree \\(\\leq n\\).\n\nProof.\nNon-negativity: For \\(t\\in[0,1]\\), \\(0&lt;1-t&lt;1\\), so \\(B_i^{n}(t) \\geq 0\\).\nSymmetry: Since \\({n \\choose k} = {n \\choose n-k}\\), we have:\n\\[\nB_k^{n}(t) = {n \\choose k}t^k (1-t)^{n-k} = {n \\choose (n-k)} (1-t)^{n-k} t^k = B_{n-k}^n(1-t)\n\\]\nRoots. By definition, \\(B_k^{n}(t) = {n \\choose k}t^k (1-t)^{n-k}\\) so it has a root \\(t=0\\) with multiplicity \\(k\\) and a root \\(t=1\\) with multiplicity \\((n-k)\\).\nMoreover, differentiating \\(B_k^{n}(t)\\) with respect to \\(t\\), setting the first derivative equal to \\(0\\), we have:\n\\[\n\\begin{align*}\n\\frac{d}{dt}(B_k^{n}(t)) &= {n \\choose k} kt^{k-1} (1-t)^{n-k} - (n-k)t^k(1-t)^{n-k-1} = 0 \\\\\n0 &= k(1-t) - (n-k)t \\\\\n0 &= k - kt - nt + kt \\\\\nnt &= k \\\\\nt &= \\frac{k}{n}\n\\end{align*}\n\\]\nConsider the combinatorial identity:\n\\[\n{n \\choose k} = {n-1 \\choose k} + {n - 1\\choose k - 1}\n\\]\nAssume that we would like to assemble team of size \\(k\\) from a population of size \\(n\\). There are \\({n \\choose k}\\) distinguishable teams. Another way to count is as follows. Label one member of the population as president. Then, there are \\({n - 1 \\choose k}\\) distinguishable teams that always include the president and \\({n - 1 \\choose k - 1}\\) distinct teams excluding the president. The sum must equal \\({n \\choose k}\\).\nWe can use this to prove the recursion formula:\n\\[\n\\begin{align*}\n{n \\choose k}t^k(1-t)^{n-k} &= {n-1 \\choose k}t^k(1-t)^{n-k} + {n - 1\\choose k - 1}t^k(1-t)^{n-k}\\\\\n&= (1-t) {n-1 \\choose k}t^k(1-t)^{n-1-k} + t{n - 1\\choose k - 1}t^{k-1}(1-t)^{(n-1)-(k-1)}\\\\\n&= (1-t)B_{k}^{n-1}(t) + tB_{k-1}^{n-1}(t)\n\\end{align*}\n\\]\nTo show the linear independence, we observe that if:\n\\[\n\\begin{align*}\n\\sum_{i=0}^n a_i B_i^{n}(t) &\\equiv 0\n\\end{align*}\n\\tag{7}\\]\nfor all \\(t \\in [0,1]\\). Then, expanding and substituting \\(t=1\\) in the above expression, we have:\n\\[\n\\begin{align*}\n\\sum_{i=0}^n a_i B_i^{n}(i) &= 0\\\\\na_0 (1-t)^n + a_1 {n \\choose 1} (1-t)^{n-1}t + \\ldots + a_n t^n &= 0\\\\\na_n &= 0\n\\end{align*}\n\\]\nSubstituting \\(a_n = 0\\) in Equation 7, we get:\n\\[\n\\begin{align*}\na_0 (1-t)^n + a_1 {n \\choose 1} (1-t)^{n-1} t + \\ldots + a_{n-1}(1-t)t^{n-1} &= 0\\\\\na_0 (1-t)^{n-1} + a_1 {n \\choose 1} (1-t)^{n-2} t + \\ldots + a_{n-1}t^{n-1} &= 0\n\\end{align*}\n\\]\nAgain, subbing \\(t=1\\), we find that \\(a_{n-1}=0\\). By repeatedly dividing by \\((1-t)\\) and using the same argument, we find that:\n\\[\na_0 = a_1 = \\ldots = a_n = 0\n\\]\nThis closes the proof. \\(\\blacksquare\\)\nThe unique parametric Bezier curve corresponding to a given set of \\(n+1\\) control points \\(p_i\\), \\(i=0:n\\), equals:\n\\[\n\\begin{align*}\nc(t) = \\sum_{i=0}^n p_i B_i^{n}(t), \\quad t\\in[0,1]\n\\end{align*}\n\\tag{8}\\]\nwhere \\(B_i^{n}(t)\\) are Bernstein polynomials of degree \\(n\\). By property 3, in Theorem 2, the Bezier curve interpolates the first and last control points \\(p_0\\) and \\(p_n\\). Often, a curve is constructed by smoothly patching together several Bezier curves of low order.\n\n\nIntuition\n\nThe case \\(n=1\\)\nImagine a particle travelling in a straight line joining the points \\(p_0=(x_0,y_0)\\) and \\(p_1=(x_1,y_1)\\), where the time \\(t\\in[0,1]\\). Let’s compute the position \\(c(t)=(x(t),y(t))\\) of the particle at time \\(t\\). The point \\(c(t)\\) divides the straight-line \\(p_0p_1\\) in the proportion \\(t:(1-t)\\). By the section formula, the position vector of \\(c(t)\\) is:\n\\[\n\\begin{align*}\n(x(t),y(t)) &= ((1-t)x_0 + tx_1, (1-t)y_0 + ty_1)\\\\\n&= (1-t)(x_0,y_0) + t(x_1,y_1)\\\\\n&= (1-t)p_0 + tp_1\n\\end{align*}\n\\]\nThis is the parametric equation of motion of the particle. It is the Bezier curve for \\(n=1\\). The points \\(p_0\\) and \\(p_1\\) control what the straight-line path looks like, so they are called control-points.\n\nusing Plots\nusing LaTeXStrings\n\nfunction bezier_1(t, a, b)\n    @. (1-t)*a + t*b\nend\n\ntvec = range(0.0, 1.0, 101)\npts = [\n    0.0 1.0;\n    1.0 0.0;\n]\n\nx = bezier_1(tvec, pts[1,1], pts[2,1])\ny = bezier_1(tvec, pts[1,2], pts[2,2])\n\n@gif for (xVal, yVal) in zip(x,y)\n    plot(x, y, line=(:path,:dash,:gray))\n    scatter!([xVal], [yVal], marker=(:circle,3,:green,:green))\nend\n\n[ Info: Saved animation to C:\\Data\\dev\\repo\\quantinsights.github.io\\posts\\interpolation-and-approximation\\tmp.gif\n\n\n\n\n\n\n\n\nThe case \\(n=2\\)\nAssume that, we have 3 points \\(p_0=(0.0, 1.0)\\), \\(p_1=(1.3, 1.3)\\) and \\(p_2=(1.0, 0.0)\\). Imagine a red particle \\(p_R\\) moving from \\(p_0\\) towards \\(p_1\\) on a straight-line, a blue particle \\(p_B\\) moving from \\(p_1\\) towards \\(p_2\\). Suppose, a third green particle \\(p_G\\) moves along the straight-line joining the blue and green particles instantaneously:\n\n\nShow the code\nfunction bezier_2(t, a, b, c)\n    @. (1-t)^2 *a + 2*(1-t)*t*b + t^2 * c\nend\n\npts = [\n    0.0 1.0;\n    1.3 1.3;\n    1.0 0.0;\n]\n\nxRed = bezier_1(tvec, pts[1,1], pts[2,1])\nyRed = bezier_1(tvec, pts[1,2], pts[2,2])\n\nxBlue = bezier_1(tvec, pts[2,1], pts[3,1])\nyBlue = bezier_1(tvec, pts[2,2], pts[3,2])\n\nxGreen = bezier_2(tvec, pts[1,1], pts[2,1], pts[3,1])\nyGreen = bezier_2(tvec, pts[1,2], pts[2,2], pts[3,2])\n\n@gif for ((xr, yr),(xb,yb),(xg,yg)) in zip(zip(xRed,yRed),zip(xBlue,yBlue),zip(xGreen,yGreen))\n        plot(xRed, yRed, line=(:path,:dash,:gray))\n        scatter!([xr], [yr], marker=(:circle,3,:red,:red))\n        plot!(xBlue, yBlue, line=(:path,:dash,:gray))\n        scatter!([xb], [yb], marker=(:circle,3,:blue,:blue))\n        x = bezier_1(tvec, xr, xb)\n        y = bezier_1(tvec, yr, yb)\n        plot!(x, y, line=(:path,:dash,:gray))\n        plot!(xGreen, yGreen, line=(:path,:solid,:gray))\n        scatter!([xg], [yg], marker=(:circle,3,:green,:green))\nend\n\n\n[ Info: Saved animation to C:\\Data\\dev\\repo\\quantinsights.github.io\\posts\\interpolation-and-approximation\\tmp.gif\n\n\n\n\n\nHow might we compute the trajectory of the green particle? By a double-application of the section formula, we have:\n\\[\n\\begin{align*}\np_G(t) &= (1-t)\\cdot p_R(t) + t\\cdot p_B(t)\\\\\n&= (1-t)((1-t)p_0 + tp_1) + t((1-t)p_1 + t p_2)\\\\\n&= (1-t)^2 p_0 +2t(1-t)p_1 + t^2 p_2\n\\end{align*}\n\\]\nThus, the trajectory of the green particle is a quadratic Bezier curve with \\(n+1=3\\) control points. The quadratic Bezier curve interpolates between the points \\(p_0\\) and \\(p_2\\), whereas \\(p_1\\) is an off-curve point.\nComputer graphics(CG) aficionados reserve the term control point for an off-curve point such as \\(p_1\\) and refer to the on-curve points, as anchor points. In CG editors such as Adobe Illustrator, not all control points are known in advance. The shape of the quadratic curve is controlled by moving around the control points using the Pen tool (Bezier tool) until the curve has the desired shape. Thus, using the Bernstein basis to represent degree 2 polynomials is advantageous. Moving \\(p_1\\) has a direct and intuitive effect on the curve.\nThe Bezier polygon is the closed piecewise linear curve connecting the control points \\(p_i\\) and \\(p_{i+1}\\), \\(i=0:n-1\\) and finally \\(p_n\\) and back to \\(p_0\\). This polygon provides a rough idea of the shape of the curve. From the definition(Equation 8) of the Bezier curve, it follows that for all \\(t\\in[0,1]\\), the curve \\(c(t)\\) is a convex combination of the control points. Therefore, \\(c(t)\\) lies within the convex hull of the control points.\n\nTheorem 3 The Bezier curve \\(c(t)\\) is tangent to \\(p_1- p_0\\) and \\(p_n - p_{n-1}\\) for \\(t=0\\) and \\(t=1\\) respectively.\n\nProof."
  },
  {
    "objectID": "posts/interpolation-and-approximation/index.html#spline-functions",
    "href": "posts/interpolation-and-approximation/index.html#spline-functions",
    "title": "Interpolation and Approximation",
    "section": "Spline Functions",
    "text": "Spline Functions\nThe mathematical concept of spline functions was introduced in 1946 by Schoenberg. The importance of the B-spline basis for approximation was also first appreciated by Schoenberg. Today, B-Splines enable the mathematical representation of surfaces far beyond hand-techniques. In aircraft design computations, they may involve more than \\(50,000\\) data points.\n\nLinear and Cubic Splines\nWe start by formally defining a spline function of order \\(k \\geq 1\\).\n\nDefinition 1 A spline function \\(S(x)\\) of order \\(k \\geq 1\\) (degree \\(k-1 \\geq 0\\)), on a grid\n\\[\n\\Delta = \\{a=x_0 &lt; x_1 &lt; \\ldots &lt; x_n = b\\}\n\\]\nof distinct knots is a real function \\(s\\) with the following properties:\n\nFor \\(x \\in [x_i, x_{i+1}]\\), \\(i=0:m-1\\), \\(S(x)\\) is a polynomial of degree \\(&lt;k\\)."
  },
  {
    "objectID": "posts/girsanov-theorem/index.html",
    "href": "posts/girsanov-theorem/index.html",
    "title": "A gentle introduction to the Girsanov Theorem - Back to the basics",
    "section": "",
    "text": "One of the most popular technical tools in financial engineering is the Girsanov theorem. In this blog-post, I intend to provide the dear reader a beginner-friendly introduction and an intuitive gut feel for these tools.\nThe change of measure technique was used by Heylette Geman, Nicole El Karoui and Jean-Charles Rochet in their seminal note Changes of Numeraire, Changes of Probability Measure and Option Pricing.\n\n%load_ext itikz"
  },
  {
    "objectID": "posts/girsanov-theorem/index.html#change-of-probability-for-a-random-variable.",
    "href": "posts/girsanov-theorem/index.html#change-of-probability-for-a-random-variable.",
    "title": "A gentle introduction to the Girsanov Theorem - Back to the basics",
    "section": "Change of Probability for a Random Variable.",
    "text": "Change of Probability for a Random Variable.\nConsider a random variable \\(X\\) defined on a sample space \\(\\Omega\\) having zero mean. We want to change the mean of \\(X\\) so that \\(\\mu\\neq 0\\). Of course, it is easy to change the mean of a random variable: If \\(X\\) has mean \\(0\\), then the random variable \\(X+\\mu\\) has mean \\(\\mu\\). However, it might be that the variable \\(X+\\mu\\) does not share the same possible values as \\(X\\). For example, take \\(X\\) to be a uniform random variable on \\([-1,1]\\). While \\(X+1\\) has mean \\(1\\), the density of \\(X+1\\) would be non-zero on \\([0,2]\\) instead of \\([-1,1]\\).\nOur goal is to find a good way to change the underlying probability \\(\\mathbb{P}\\), and thus the distribution of \\(X\\), so that the set of outcomes is unchanged. If \\(X\\) is a discrete random variable, say with \\(\\mathbb{P}(X=-1)=\\mathbb{P}(X=1)=1/2\\), we can change the probability in order to change the mean easily. It suffices to take \\(\\tilde{\\mathbb{P}}\\) so that \\(\\tilde{\\mathbb{P}}(X=1)=p\\) and \\(\\mathbb{P}(X=-1)=1-p\\) for some appropriate \\(0\\leq p\\leq1\\).\nIf \\(X\\) is a continuous random variable, with a PDF \\(f_{X}\\), the probabilities can be changed by modifying the PDF. Consider the a new PDF:\n\\[\\begin{aligned}\n\\tilde{f}_{X}(x) & =f_{X}(x)g(x)\n\\end{aligned}\\]\nfor some function \\(g(x)&gt;0\\) such that \\(\\int f(x)g(x)dx=1\\). Clearly, \\(f_{X}(x)g(x)\\) is also a PDF and \\(f_{X}(x)&gt;0\\) if and only if \\(f_{X}(x)g(x)&gt;0\\), so that the possible values of \\(X\\) are unchanged. A convenient (and important!) choice of function \\(g\\) is:\n\\[\\begin{aligned}\ng(x) & =\\frac{e^{ax}}{\\int_{\\mathbf{R}}e^{ax}f_{X}(x)dx}=\\frac{e^{ax}}{\\mathbb{E}[e^{aX}]},\\quad a\\in\\mathbf{R}\n\\end{aligned} \\tag{1}\\]\nassuming \\(X\\) has a well-defined MGF. Here \\(a\\) is a parameter that can be tuned to fit to a specific mean. The normalization factor in the denominator is the MGF of \\(X\\). It ensures that \\(f_{X}(x)g(x)\\) is a PDF. Note that if \\(a&gt;0\\), the function \\(g\\) gives a bigger weight to large values of \\(X\\). We say that \\(g\\) is biased towards the large values.\n\nExample 1 (Biasing a uniform random variable) Let \\(X\\) be a uniform random variable on \\([0,1]\\) defined on \\((\\Omega,\\mathcal{F},\\mathbb{P})\\). Clearly, \\(\\mathbb{E}[X]=1/2\\). How can we change the PDF of \\(X\\) so that the possible values are still \\([0,1]\\), but the mean is \\(1/4\\). We have that the PDF is \\(f_{X}(x)=1\\) if \\(x\\in[0,1]\\) and \\(0\\) elsewhere. Therefore, the mean with the new PDF with parameter \\(a\\) as in the Equation 1 is:\n\\[\\begin{aligned}\n\\tilde{\\mathbb{E}}[X] & =\\int_{0}^{1}x\\tilde{f}(x)dx\\\\\n& =\\int_{0}^{1}\\frac{xe^{ax}}{\\mathbb{E}[e^{aX}]}dx\\\\\n& =\\frac{a}{e^{a}-1}\\int_{0}^{1}xe^{ax}dx\\\\\n& =\\frac{a}{e^{a}-1}\\left(\\left[x\\frac{e^{ax}}{a}\\right]_{0}^{1}-\\frac{1}{a}\\int_{0}^{1}e^{ax}dx\\right)\\\\\n& =\\frac{a}{e^{a}-1}\\left(\\frac{e^{a}}{a}-\\frac{1}{a}\\frac{e^{a}-1}{a}\\right)\\\\\n& =\\frac{e^{a}}{e^{a}-1}-\\frac{1}{a}\n\\end{aligned}\\]\nFor \\(\\tilde{\\mathbb{E}[X]}\\)to be equal to \\(1/4\\), we get numerically \\(a\\approx-3.6\\). Note that the possible values of \\(X\\) remain the same under the new probability. However, the new distribution is no longer uniform! It has bias towards values closer to zero, as it should.\n\n\nExample 2 (Biasing a Gaussian random variable.) Let \\(X\\) be a Gaussian random variable with mean \\(\\mu\\) and variance \\(\\sigma^{2}\\). How can we change the PDF of \\(X\\) to have mean \\(0\\)? Going back to Equation 1, the mean \\(\\mu\\) under the new PDF with parameter \\(a\\) is:\n\\[\\begin{aligned}\n\\tilde{\\mathbb{E}}[X] & =\\int_{-\\infty}^{\\infty}x\\tilde{f}(x)dx\\\\\n& =\\int_{-\\infty}^{\\infty}xg(x)f(x)dx\\\\\n& =\\int_{-\\infty}^{\\infty}x\\cdot\\frac{e^{ax}}{\\mathbb{E}[e^{aX}]}\\frac{1}{\\sqrt{2\\pi}\\sigma}e^{-\\frac{1}{2}\\left(\\frac{x-\\mu}{\\sigma}\\right)^{2}}dx\\\\\n& =\\frac{1}{e^{\\mu a+\\frac{1}{2}a^{2}\\sigma^{2}}}\\frac{1}{\\sqrt{2\\pi}\\sigma}\\int_{-\\infty}^{\\infty}x\\cdot\\exp\\left[-\\frac{1}{2}\\left(\\frac{x^{2}-2\\mu x+\\mu^{2}-2a\\sigma^{2}x}{\\sigma^{2}}\\right)\\right]dx\\\\\n& =\\frac{1}{e^{\\mu a+\\frac{1}{2}a^{2}\\sigma^{2}}}\\frac{1}{\\sqrt{2\\pi}\\sigma}\\int_{-\\infty}^{\\infty}x\\cdot\\exp\\left[-\\frac{1}{2}\\left(\\frac{x^{2}-2(\\mu+a\\sigma^{2})x+(\\mu+a\\sigma^{2})^{2}-2\\mu a\\sigma^{2}-a^{2}\\sigma^{4}}{\\sigma^{2}}\\right)\\right]dx\\\\\n& =\\frac{e^{\\mu a+a^{2}\\sigma^{2}/2}}{e^{\\mu a+\\frac{1}{2}a^{2}\\sigma^{2}}}\\frac{1}{\\sqrt{2\\pi}\\sigma}\\int_{-\\infty}^{\\infty}x\\exp\\left[-\\frac{1}{2}\\left(\\frac{x-(\\mu+a\\sigma^{2})}{\\sigma}\\right)^{2}\\right]dx\\\\\n& =\\frac{1}{\\sqrt{2\\pi}\\sigma}\\int_{-\\infty}^{\\infty}x\\exp\\left[-\\frac{1}{2}\\left(\\frac{x-(\\mu+a\\sigma^{2})}{\\sigma}\\right)^{2}\\right]dx\n\\end{aligned}\\]\nFor the specific choice of the parameter \\(a=\\mu/\\sigma^{2}\\), we recover the PDF of a Gaussian random variable with mean \\(0\\). But, we can deduce more. The new PDF is also Gaussian. This was not the case for uniform random variables. In fact, the new PDF is exactly the same as the one of \\(X-\\mu\\). For if, \\(a=\\mu/\\sigma^{2}\\), we have:\n\\[\\begin{aligned}\n\\tilde{\\mathbb{E}}[X] & =\\frac{1}{\\sqrt{2\\pi}\\sigma}\\int_{-\\infty}^{\\infty}x\\exp\\left[-\\frac{x^{2}}{2\\sigma^{2}}\\right]dx\n\\end{aligned}\\]\nand observe that if \\(Y=X-\\mu\\), then:\n\\[\\begin{aligned}\nF_{Y}(x) & =\\mathbb{P}(X-\\mu&lt;x)\\\\\n& =\\mathbb{P}(X\\leq x+\\mu)\\\\\n& =F_{X}(x+\\mu)\\\\\n\\frac{d}{dx}(F_{Y}(x)) & =\\frac{d}{dx}(F_{X}(x+\\mu))\\\\\nf_{Y}(x) & =f_{X}(x+\\mu)\\cdot\\frac{d}{dx}(x+\\mu)\\\\\nf_{Y}(x) & =f_{X}(x+\\mu)\\\\\n& =\\frac{1}{\\sqrt{2\\pi}\\sigma}\\exp\\left[-\\frac{1}{2}\\left(\\frac{x+\\mu-\\mu}{\\sigma}\\right)^{2}\\right]\\\\\n& =\\frac{1}{\\sqrt{2\\pi}\\sigma}\\exp\\left[-\\frac{x^{2}}{2\\sigma^{2}}\\right]\n\\end{aligned}\\]\nIn other words:\nFor Gaussians, changing the mean by recentering is equivalent to changing the probability as in Equation 1.\n\nVisualization\nLet \\(X\\) be gaussian with mean \\(\\mu=1\\) and variance \\(\\sigma^2 = 1\\). The PDF of \\(X\\) is:\n\n\nShow the code\n%%itikz --temp-dir --tex-packages=tikz,pgfplots --tikz-libraries=arrows --implicit-standalone\n\\begin{tikzpicture}[scale=1.5]\n\\begin{axis}[xlabel = $x$, ylabel={$f_X(x)$}, title={The PDF of $X \\sim \\mathcal{N}^{P}(\\mu=1,\\sigma^2=1)$},domain=-3:3]\n\\addplot[color=black,samples=100]{1/(sqrt(2*3.14))*exp(-0.5*((x-1)*(x-1))};\n\\end{axis}\n\\end{tikzpicture}\n\n\n\n\n\nI choose \\(g(x) = \\frac{e^{ax}}{\\mathbb{E}[e^{aX}]} = \\frac{e^{ax}}{e^{\\mu a + \\frac{1}{2}a^2 \\sigma^2}}\\), \\(\\mu=1\\), \\(\\sigma^2 = 1\\) and set the value of the parameter \\(a = \\frac{\\mu}{\\sigma^2} = -1\\).\n\n\nShow the code\n%%itikz --temp-dir --tex-packages=tikz,pgfplots --tikz-libraries=arrows --implicit-standalone\n\\begin{tikzpicture}[scale=1.5]\n\\begin{axis}[xlabel = $x$, ylabel={$g(x)$}, title={The density scaling $g(x)=\\frac{e^{ax}}{E[e^{ax}]}$, with parameter value $a=-\\frac{\\mu}{\\sigma^2}$},domain=-3:3]\n\\addplot[color=black,samples=100]{exp(-x)/exp(-0.5)};\n\\end{axis}\n\\end{tikzpicture}\n\n\n\n\n\nThe new density \\(\\tilde{f}_X(x)\\) obtained multiplying \\(f_X(x)\\) by the weights \\(g(x)\\) is the same as a gaussian centered at \\(0\\) with variance \\(1\\) :\n\n\nShow the code\n%%itikz --temp-dir --tex-packages=tikz,pgfplots --tikz-libraries=arrows --implicit-standalone\n\\begin{tikzpicture}[scale=1.5]\n\\begin{axis}[xlabel = $x$, ylabel={$\\tilde{f}_X(x)$}, title={The new PDF of $X$, after multiplying the density ${f}_X(x)$ by weights $g(x)$.},domain=-3:3]\n\\addplot[color=black,samples=100]{1/(sqrt(2*3.14))*exp(-0.5*(x*x))};\n\\end{axis}\n\\end{tikzpicture}\n\n\n\n\n\n\n\nThis is a very special property of the Gaussian distribution. The exponential and Poisson distributions have a similar property.\nIntuitively, if we have a brownian motion with a drift \\(dX_t = \\mu dt + dB_t\\), we can apply this idea to each time-slice \\((X_t - X_s)\\) of the process, we can recenter the gaussians to have mean \\(0\\), so the paths are driftless and it has the same distribution as a standard brownian motion."
  },
  {
    "objectID": "posts/girsanov-theorem/index.html#change-of-probability-measure",
    "href": "posts/girsanov-theorem/index.html#change-of-probability-measure",
    "title": "A gentle introduction to the Girsanov Theorem - Back to the basics",
    "section": "Change of probability measure",
    "text": "Change of probability measure\nExample 2 is very important and we will state it as a theorem. Before doing so, we notice that the change of PDF (Equation 1) can be expressed more generally by changing the underlying probability measure(length, area, weights) \\(\\mathbb{P}\\) on the sample space \\(\\Omega\\) on which the random variables are defined. More precisely, let \\((\\Omega,\\mathcal{F},\\mathbb{P})\\) be a probability space, and let \\(X\\) be a random variable defined on \\(\\Omega\\). We define a new probability \\(\\tilde{\\mathbb{P}}\\) on \\(\\Omega\\) as follows:\nIf \\(\\mathcal{E}\\) is an event in \\(\\mathcal{F}\\), then:\n\\[\\begin{aligned}\n\\mathbb{\\tilde{P}}(\\mathcal{E}) & =\\mathbb{\\tilde{E}}[1_{\\mathcal{E}}]=\\int_{\\mathbf{R}}1_{\\mathcal{E}}\\cdot\\tilde{f}(x)dx\\nonumber \\\\\n& =\\int_{\\mathbf{R}}1_{\\mathcal{E}}\\cdot g(x)f_{X}(x)dx\\nonumber \\\\\n& =\\int_{\\mathbf{R}}1_{\\mathcal{E}}\\cdot\\frac{e^{ax}}{\\mathbb{E}[e^{aX}]}f_{X}(x)dx\\nonumber \\\\\n& =\\mathbb{E}\\left[1_{\\mathcal{E}}\\frac{e^{aX}}{\\mathbb{E}[e^{aX}]}\\right]\n\\end{aligned}\\]\nIntuitively, we are changing the probability of each outcome \\(\\omega\\in\\mathcal{E}\\), by the factor\n\\[\n\\begin{aligned}\n\\frac{e^{aX(\\omega)}}{\\mathbb{E}[e^{aX}]}\n\\end{aligned}\n\\tag{2}\\]\nIn other words, if \\(a&gt;0\\), the outcomes \\(\\omega\\) for which \\(X\\) has large values are favored. Note that equation (Equation 1) for the PDF is recovered, since for any function \\(h\\) of \\(X\\), we have:\n\\[\\begin{aligned}\n\\tilde{\\mathbb{E}}[h(X)] & =\\mathbb{E}\\left[\\frac{e^{aX}}{\\mathbb{E}[e^{aX}]}h(X)\\right]\\\\\n& =\\int_{\\mathbf{R}}h(x)\\frac{e^{ax}}{\\mathbb{E}[e^{aX}]}f_{X}(x)dx\n\\end{aligned}\\]\nIn this setting, the above example becomes the preliminary version of the Cameron-Martin-Girsanov theorem:\n\nTheorem 1 (Change of probability for a random variable) Let \\(X\\) be a Gaussian random variable with mean \\(\\mu\\) and variance \\(\\sigma^{2}\\) defined on \\((\\Omega,\\mathcal{F},\\mathbb{P})\\). Then, under the probability \\(\\mathbb{\\tilde{P}}\\) given by:\n\\[\\begin{aligned}\n\\mathbb{\\tilde{P}}(\\mathcal{E}) & =\\mathbb{E}\\left[1_{\\mathcal{E}}e^{-\\frac{\\mu}{\\sigma^{2}}X+\\frac{1}{2}\\frac{\\mu^{2}}{\\sigma^{2}}}\\right],\\quad\\mathcal{E}\\in\\mathcal{F}\n\\end{aligned} \\tag{3}\\]\nthe random variable \\(X\\) is Gaussian with mean \\(0\\) and variance \\(\\sigma^{2}\\).\nMoreover, since \\(X\\) can be written as \\(X=Y+\\mu\\) where \\(Y\\) is Gaussian with mean \\(0\\) and variance \\(\\sigma^{2}\\) under \\(\\mathbb{P}\\), we have that \\(\\mathbb{\\tilde{P}}\\) can be written as:\n\\[\\begin{aligned}\n\\mathbb{\\tilde{P}}(\\mathcal{E}) & =\\mathbb{E}\\left[1_{\\mathcal{E}}e^{-\\frac{\\mu}{\\sigma^{2}}Y-\\frac{1}{2}\\frac{\\mu^{2}}{\\sigma^{2}}}\\right],\\quad\\mathcal{E}\\in\\mathcal{F}\n\\end{aligned} \\tag{4}\\]\n\nIt is good to pause for a second and look at the signs in the exponential of equations (Equation 3) and (Equation 4). The signs in the exponential might be very confusing and is the source of many mistakes in the Cameron-Martin-Girsanov theorem. A good trick is to say that, if we want to remove \\(\\mu\\), then the sign in front of \\(X\\) or \\(Y\\) must be negative. Then, we add the exponential factor needed for \\(\\tilde{\\mathbb{P}}\\) to be a probability. This is given by the MGF of \\(X\\) or \\(Y\\) depending on how we want to express it.\nThe probabilities \\(\\mathbb{P}\\) and \\(\\tilde{\\mathbb{P}}\\), as defined in the equation (Equation 3) are obviously not equal since they differ by a factor in (Equation 2). However, they share some similarities. Most notably, if \\(\\mathcal{E}\\) is an event of positive \\(\\mathbb{P}\\)-probability, \\(\\mathbb{P}(\\mathcal{E})&gt;0\\), then we must have \\(\\tilde{\\mathbb{P}}(\\mathcal{E})&gt;0\\), since the factor in () is always strictly positive. The converse is also true: if \\(\\mathcal{E}\\) is an event of positive \\(\\tilde{\\mathbb{P}}\\)-probability, \\(\\tilde{\\mathbb{P}}(\\mathcal{E})&gt;0\\), then we must have that \\(\\mathbb{P}(\\mathcal{E})&gt;0\\). This is because the factor in (Equation 2) can be inverted, being strictly positive. More precisely, we have:\n\\[\\begin{aligned}\n\\mathbb{P}(\\mathcal{E}) & =\\mathbb{E}[1_{\\mathcal{E}}]\\\\\n& =\\mathbb{E}\\left[1_{\\mathcal{E}}\\frac{e^{aX(\\omega)}}{\\mathbb{E}[e^{aX}]}\\left(\\frac{e^{aX(\\omega)}}{\\mathbb{E}[e^{aX}]}\\right)^{-1}\\right]\\\\\n& =\\tilde{\\mathbb{E}}\\left[1_{\\mathcal{E}}\\left(\\frac{e^{aX(\\omega)}}{\\mathbb{E}[e^{aX}]}\\right)^{-1}\\right]\n\\end{aligned}\\]\nThe factor \\(\\left(\\frac{e^{aX(\\omega)}}{\\mathbb{E}[e^{aX}]}\\right)^{-1}\\) is also strictly positive, proving the claim. To sum it all up, the probabilities \\(\\mathbb{P}\\) and \\(\\tilde{\\mathbb{P}}\\) essentially share the same possible outcomes. Such probability measures are said to be equivalent measures.\n\nDefinition 1 Consider the two probabilities \\(\\mathbb{P}\\) and \\(\\tilde{\\mathbb{P}}\\) on \\((\\Omega,\\mathcal{F})\\). They are said to be equivalent, if for any event \\(\\mathcal{E}\\in\\mathcal{F}\\), we have \\(\\mathbb{P}(\\mathcal{E})&gt;0\\) if and only if \\(\\mathbb{P}(\\mathcal{E})&gt;0\\). Thus, \\(\\mathbb{P}\\) and \\(\\tilde{\\mathbb{P}}\\) agree on the null sets. If \\(A\\in\\mathcal{F}\\) is such that \\(\\mathbb{P}(A)=0\\), then \\(\\mathbb{\\tilde{P}}(A)=0\\) and vice-versa.\n\nKeep in mind that two probabilities that are equivalent might still be very far from being equal!"
  },
  {
    "objectID": "posts/girsanov-theorem/index.html#the-cameron-martin-theorem.",
    "href": "posts/girsanov-theorem/index.html#the-cameron-martin-theorem.",
    "title": "A gentle introduction to the Girsanov Theorem - Back to the basics",
    "section": "The Cameron-Martin Theorem.",
    "text": "The Cameron-Martin Theorem.\n\nTheorem 2 (Cameron-Martin Theorem for constant drift.) Let \\((\\tilde{B(t)},t\\in[0,T])\\) be a \\(\\mathbb{P}-\\)Brownian motion with constant drift \\(\\theta\\) defined on \\((\\Omega,\\mathcal{F},\\mathbb{P})\\). Consider the probability \\(\\tilde{\\mathbb{P}}\\)on \\(\\Omega\\) given by:\n\\[\\begin{aligned}\n\\tilde{\\mathbb{P}}(\\mathcal{E}) & =\\mathbb{E}\\left[e^{-\\theta\\tilde{B}(T)+\\frac{\\theta^{2}}{2}T}1_{\\mathcal{E}}\\right],\\quad\\mathcal{E}\\in\\mathcal{F}\n\\end{aligned} \\tag{5}\\]\nThen, the process \\((\\tilde{B}(t),t\\in[0,T])\\) under \\(\\mathbb{\\tilde{P}}\\)is distributed like a standard brownian motion. Moreover, since we can write \\(\\tilde{B_{t}}=\\theta t+B_{t}\\) for some standard brownian motion \\((B_{t},t\\in[0,T])\\) on \\((\\Omega,\\mathcal{F},\\mathbb{P})\\), the probability \\(\\tilde{\\mathbb{P}}\\) can also be written as:\n\\[\\begin{aligned}\n\\tilde{\\mathbb{P}}(\\mathcal{E}) & =\\mathbb{E}\\left[e^{-\\theta B(T)-\\frac{\\theta^{2}}{2}T}1_{\\mathcal{E}}\\right]\n\\end{aligned} \\tag{6}\\]\n\nIt is a good idea to pause again and look at the signs in the exponential in equations (Equation 5) and (Equation 6). They behave the same way as in Theorem 1. There is a minus sign in front of \\(B_{T}\\) to remove the drift. Before proving the theorem, we make some important remarks.\n(1) The end-point. Note that only the endpoint \\(\\tilde{B}(T)\\) of the Brownian motion is involved in the change of probability. In particular, \\(T\\) cannot be \\(+\\infty\\). The Cameron-Martin theorem can only be applied on a finite interval.\n(2) A martingale. The factor \\(M_{T}=e^{-\\theta B(T)-\\frac{\\theta^{2}}{2}T}=e^{-\\theta\\tilde{B}(T)+\\frac{1}{2}\\theta^{2}T}\\) involved in the change of probability is the end-point of a \\(\\mathbb{P}-\\)martingale, that is, it is a martingale under the original probability \\(\\mathbb{P}\\). To see this:\n\\[\\begin{aligned}\n\\mathbb{E}[M_{T}|\\mathcal{F}_{t}] & =\\mathbb{E}\\left[e^{-\\theta B(T)-\\frac{1}{2}\\theta^{2}T}|\\mathcal{F}_{t}\\right]\\\\\n& =e^{-\\theta B(t)}\\mathbb{E}\\left[e^{-\\theta(B(T)-B(t))}|\\mathcal{F}_{t}\\right]e^{-\\frac{\\theta^{2}}{2}T}\\\\\n& \\{\\text{Using }B(T)-B(t)\\perp\\mathcal{F}_{t}\\}\\\\\n& =e^{-\\theta B(t)}\\mathbb{E}\\left[e^{-\\theta(B(T)-B(t))}\\right]e^{-\\frac{\\theta^{2}}{2}T}\\\\\n& =e^{-\\theta B(t)}e^{\\frac{\\theta^{2}}{2}(T-t)}e^{-\\frac{\\theta^{2}}{2}T}\\\\\n& =e^{-\\theta B(t)-\\frac{\\theta^{2}}{2}t}\n\\end{aligned}\\]\nIn fact, since \\(B(t)\\) is a \\(\\mathbb{P}\\)-standard Brownian motion, \\(M(t)=e^{-\\theta B(t)-\\frac{\\theta^{2}}{2}t}\\) is a geometric brownian motion.\nInterestingly, the drift of \\(\\tilde{B}(t)\\) becomes the volatility factor in \\(M_{T}\\)! \\(\\mathbb{E}[M_{T}^{2}]=\\mathbb{E}[e^{-2\\theta B(T)-\\theta^{2}T}]=e^{-\\theta^{2}T}\\cdot\\mathbb{E}[e^{-2\\theta B(T)}]=e^{-\\theta^{2}T}\\cdot e^{2\\theta^{2}T}=e^{\\theta^{2}T}\\).\nThe fact that \\(M(t)\\) is a martingale is very helpful in calculations. Indeed, suppose we want to compute the expectation of a function \\(F(\\tilde{B}(s))\\) of a Brownian motion with drift at time \\(s&lt;T\\). Then, we have by Theorem 2:\n\\[\\begin{aligned}\n\\mathbb{E}[F(\\tilde{B}(s))] & =\\mathbb{E}[M_{T}M_{T}^{-1}F(\\tilde{B}(s))]\\\\\n& =\\tilde{\\mathbb{E}}[M_{T}^{-1}F(\\tilde{B}(s))]\\\\\n& =\\tilde{\\mathbb{E}}[e^{\\theta\\tilde{B}(T)-\\frac{1}{2}\\theta^{2}T}F(\\tilde{B}(s))]\n\\end{aligned}\\]\nNow, we know that under \\(\\tilde{\\mathbb{P}}\\)probability, \\((\\tilde{B}(t),t\\in[0,T])\\) is a standard brownian motion, or \\(\\tilde{\\mathbb{P}}\\)-standard brownian motion for short. Therefore, the process \\(e^{\\theta\\tilde{B}(t)-\\frac{1}{2}\\theta^{2}t}\\) is a martingale under the new probability measure \\(\\tilde{\\mathbb{P}}\\), or a \\(\\tilde{\\mathbb{P}}\\)-martingale for short. By conditioning over \\(\\mathcal{F}_{s}\\) and applying the martingale property, we get:\n\\[\\begin{aligned}\n\\mathbb{E}\\left[F(\\tilde{B}_{s})\\right] & =\\tilde{\\mathbb{E}}[e^{\\theta\\tilde{B}(T)-\\frac{1}{2}\\theta^{2}T}F(\\tilde{B}(s))]\\\\\n& =\\tilde{\\mathbb{E}}[\\tilde{\\mathbb{E}}[e^{\\theta\\tilde{B}(T)-\\frac{1}{2}\\theta^{2}T}F(\\tilde{B}(s))|\\mathcal{F}_{s}]]\\\\\n& =\\tilde{\\mathbb{E}}[e^{\\theta\\tilde{B}(s)-\\frac{1}{2}\\theta^{2}s}F(\\tilde{B}(s))]\\\\\n& =\\mathbb{E}[e^{\\theta B(s)-\\frac{1}{2}\\theta^{2}s}F(B(s))]\n\\end{aligned}\\]\nThe last equality may seem wrong as removed all the tildes. It is not! It holds because \\((\\tilde{B}(t))\\) under \\(\\tilde{\\mathbb{P}}\\) has the same distribution as \\((B(t))\\) under \\(\\mathbb{P}\\): a standard brownian motion. Of course, it would be possible to directly evaluate \\(\\mathbb{E}[F(\\tilde{B}(s))]\\) here as we know the distribution of a Brownian motion with drift. However, when the function will involve more than one point (such as the maximum of the path), the Cameron-Martin theorem is a powerful tool to evaluate expectations.\n(3) The paths with or without the drift are the same. Let \\((B(t),t\\leq T)\\) be a standard Brownian motion defined on \\((\\Omega,\\mathcal{F},\\mathbb{P})\\). Heuristically, it is fruitful to think of the sample space of \\(\\Omega\\) as the different continuous paths of Brownian motion. Since, the change of probability from \\(\\mathbb{P}\\) to \\(\\tilde{\\mathbb{P}}\\)simply changes the relative weights of the paths (and this change of weight is never zero, similarly to equation ([eq:girsanov-probability-scaling]) for a single random variable), the theorem suggests that the paths of a standard Brownian motion and those of a Brownian motion with a constant drift \\(\\theta\\) (with volatility \\(1\\)) are essentially the same.\nThe form of the factor \\(M_{T}=e^{-\\theta\\tilde{B}_{T}+\\theta^{2}T}\\) can be easily understood at the heuristic level. For each outcome \\(\\omega\\), it is proportional to \\(e^{-\\theta\\tilde{B}_{T}(\\omega)}\\) (The term \\(e^{(\\theta^{2}/2)T}\\) is simply to ensure that \\(\\mathbb{P}(\\Omega)=1\\)) Therefore, the factor \\(M_{T}\\) penalizes the paths for which \\(\\tilde{B}_{T}(\\omega)\\) is large and positive (if \\(\\theta&gt;0\\)). In particular, it is conceivable that the Brownian motion with positive drift is reduced to standard Brownian motion under the new probability.\n(4) Changing the volatility. What about the volatility? Is it possible to change the probability \\(\\mathbb{P}\\) to \\(\\tilde{\\mathbb{P}}\\) in such a way that the Brownian motion under \\(\\mathbb{P}\\) has volatility \\(\\sigma\\neq1\\) under \\(\\tilde{\\mathbb{P}}\\)? The answer is no! The paths of the Brownian motions with different volatilities are inherently different. Indeed, it suffices to compute the quadratic variation. If \\((B_{t}:t\\in[0,T])\\) has volatility \\(1\\) and \\((\\tilde{B_{t}},t\\in[0,T])\\) has volatility \\(2\\). then the following convergence holds for \\(\\omega\\) in a set of probability one (for a partition fine enough, say \\(t_{j+1}-t_{j}=2^{-n}\\). Then \\(B_{t}=\\int1\\cdot dB_{t}\\) and \\(\\tilde{B_{t}}=\\int2\\cdot dB_{t}\\)\n\\[\\begin{aligned}\n\\lim_{n\\to\\infty}\\sum_{j=0}^{n-1}(B_{t_{j+1}}(\\omega)-B_{t_{j}}(\\omega))^{2} & =\\int_{0}^{T}1^{2}\\cdot ds=T\n\\end{aligned}\\]\n\\[\\begin{aligned}\n\\lim_{n\\to\\infty}\\sum_{j=0}^{n-1}(\\tilde{B}_{t_{j+1}}(\\omega)-\\tilde{B}_{t_{j}}(\\omega))^{2} & =\\int_{0}^{T}2^{2}\\cdot ds=4T\n\\end{aligned}\\]\nIn other words, the distribution of the standard brownian motion on \\([0,T]\\) is supported on paths whose quadratic variation is \\(T\\), whereas the distribution of \\((\\tilde{B}_{t},t\\geq0)\\) is supported on paths where the quadratic variation is \\(4T\\). These paths are very different. We conclude that the distributions of the two processes are not equivalent. Hence, a change of probability from \\(\\mathbb{P}\\) to \\(\\mathbb{\\tilde{P}}\\) is not possible. In fact, we say that they are mutually singular, meaning the set of paths on which they are supported are disjoint.\nProof.\nLet \\((\\tilde{B}_{t}:t\\in[0,T])\\) be a Brownian motion with constant drift \\(\\theta\\) defined on \\((\\Omega,\\mathcal{F},\\mathbb{P})\\). Thus, \\(\\tilde{B}_{t}=\\theta t+B_{t}\\).\nClaim. \\(\\tilde{B}_{t}\\) is a \\(\\mathbb{\\tilde{P}}\\)-martingale.\nLet\n\\[\\begin{aligned}\nM_{t} & =f(t,B_{t})=\\exp(-\\theta B_{t}-(\\theta^{2}/2)t)\n\\end{aligned}\\]\nSo:\n\\[\\begin{aligned}\ndM_{t} & =-\\frac{\\theta^{2}}{2}M_{t}dt-\\theta M_{t}dB_{t}+\\frac{1}{2}\\theta^{2}M(t)dt\\\\\n& =-\\theta M_{t}dB_{t}\n\\end{aligned}\\]\nConsider the product \\((M_{t}\\tilde{B}_{t})\\). We have:\n\\[\\begin{aligned}\nd(M_{t}\\tilde{B}_{t}) & =\\tilde{B}_{t}dM_{t}+M_{t}d\\tilde{B}_{t}+dM_{t}\\cdot d\\tilde{B}_{t}\\\\\n& =-\\tilde{B}_{t}\\theta M_{t}dB_{t}+M_{t}(\\theta dt+dB_{t})-\\theta M_{t}dB_{t}(\\theta dt+dB_{t})\\\\\n& =-\\tilde{B}_{t}\\theta M_{t}dB_{t}+\\theta M_{t}dt+M_{t}dB_{t}-\\theta M_{t}dt\\\\\n& =(-\\tilde{B}_{t}\\theta+1)M_{t}dB_{t}\n\\end{aligned}\\]\nThus, by the properties of Ito integral,\\(M_{t}\\tilde{B}_{t}\\) is a martingale under \\(\\mathbb{P}\\). By the abstract Bayes formula ([th:abstract-bayes-formula]):\n\\[\\begin{aligned}\n\\tilde{\\mathbb{E}}[\\tilde{B}_{t}|\\mathcal{F}_{s}] & =\\frac{1}{M_{s}}\\mathbb{E}[M_{t}\\tilde{B}_{t}|\\mathcal{F}_{s}]\\\\\n& =\\frac{1}{M_{s}}\\cdot M_{s}\\tilde{B}_{s}\\\\\n& =\\tilde{B}_{s}\n\\end{aligned}\\]\nThus, \\(\\tilde{B}_{t}\\) is a \\(\\tilde{\\mathbb{P}}\\)-martingale.\nClaim. Our claim is that under the \\(\\tilde{\\mathbb{P}}\\) measure, \\(\\tilde{B}_{t}\\sim\\mathcal{N}^{\\mathbb{\\tilde{P}}}(0,t)\\) and to do this we rely on the the moment-generating function.\nBy definition, for a constant \\(\\Psi\\):\n\\[\\begin{aligned}\nM_{\\tilde{B}_{t}}(\\Psi) & =\\tilde{\\mathbb{E}}\\left[\\exp\\left(\\Psi\\tilde{B}_{t}\\right)\\right]\\\\\n& =\\mathbb{E}\\left[M_{T}\\exp\\left(\\Psi\\tilde{B}_{t}\\right)\\right]\\\\\n& =\\mathbb{E}\\left[\\exp\\left(-\\theta\\tilde{B}_{T}+\\frac{\\theta^{2}}{2}T+\\Psi\\tilde{B}_{t}\\right)\\right]\\\\\n& =\\mathbb{E}\\left[\\exp\\left(-\\theta(\\theta T+B_{T})+\\frac{\\theta^{2}}{2}T+\\Psi(\\theta t+B_{t})\\right)\\right]\\\\\n& =\\mathbb{E}\\left[\\exp\\left(-\\theta B_{T}-\\frac{\\theta^{2}}{2}T+\\Psi\\theta t+\\Psi B_{t})\\right)\\right]\\\\\n& =\\mathbb{E}\\left[\\exp\\left(-\\theta(B_{T}-B_{t})-\\frac{\\theta^{2}}{2}T+\\Psi\\theta t+(\\Psi-\\theta)B_{t})\\right)\\right]\\\\\n& =\\exp\\left(-\\frac{\\theta^{2}}{2}T+\\Psi\\theta t\\right)\\mathbb{E}\\left(-\\theta(B_{T}-B_{t})\\right)\\mathbb{E}\\left((\\Psi-\\theta)B_{t}\\right)\\\\\n& =\\exp\\left(-\\frac{\\theta^{2}}{2}T+\\Psi\\theta t\\right)\\exp\\left[\\frac{1}{2}\\theta^{2}(T-t)\\right]\\exp\\left[\\frac{1}{2}(\\Psi-\\theta)^{2}t\\right]\\\\\n& =\\exp\\left[-\\frac{1}{2}\\left(\\theta^{2}-2\\Psi\\theta-(\\Psi-\\theta)^{2}\\right)t\\right]\\\\\n& =\\exp\\left[-\\frac{1}{2}\\left(\\theta^{2}-2\\Psi\\theta-(\\Psi^{2}-2\\Psi\\theta+\\theta^{2}\\right)t\\right]\\\\\n& =\\exp(-\\Psi^{2}t)\n\\end{aligned}\\]\nThus, \\(\\tilde{B}_{t}\\sim\\mathcal{N}^{\\tilde{\\mathbb{P}}}(0,t)\\).\nClaim. Finally, to show that \\(\\tilde{B}_{t}\\) is indeed a \\(\\mathbb{\\tilde{P}}-\\)standard brownian motion, we have the following:\n(a) \\(\\tilde{B}_{0}=\\theta(0)+B_{0}=0\\) and \\(\\tilde{B}_{t}\\) has almost surely continuous paths.\n(b) We would like to prove that, for \\(s&lt;t\\), \\(\\tilde{B}_{t}-\\tilde{B}_{s}\\sim\\mathcal{N}^{\\tilde{\\mathbb{P}}}(0,t-s)\\). We have:\n\\[\\begin{aligned}\n\\mathbb{E}[\\tilde{B}_{t}-\\tilde{B}_{s}] & =\\tilde{\\mathbb{E}}[\\tilde{B}_{t}]-\\tilde{\\mathbb{E}}[B_{s}]\\\\\n& =0\n\\end{aligned}\\]\nAnd,\n\\[\\begin{aligned}\n\\tilde{\\mathbb{E}}[(\\tilde{B}_{t}-\\tilde{B}_{s})^{2}] & =\\tilde{\\mathbb{E}}[\\tilde{B}_{t}^{2}-2\\tilde{B}_{t}\\tilde{B}_{s}+\\tilde{B}_{s}^{2}]\\\\\n& =\\tilde{\\mathbb{E}}[B_{t}^{2}]-2\\tilde{\\mathbb{E}}[\\tilde{B}_{t}\\tilde{B}_{s}]+\\tilde{\\mathbb{E}}[\\tilde{B}_{s}^{2}]\\\\\n& =t+s-2\\tilde{\\mathbb{E}}[\\tilde{B}_{t}\\tilde{B}_{s}]\n\\end{aligned}\\]\n(c) The non-overlapping increments of a \\(\\tilde{\\mathbb{P}}\\)-martingale are independent. To see this, suppose \\(t_{1}\\leq t_{2}\\leq t_{3}\\):\n\\[\\begin{aligned}\n\\tilde{\\mathbb{E}}[(B_{t_{3}}-B_{t_{2}})(B_{t_{2}}-B_{t_{1}})] & =\\tilde{\\mathbb{E}}[\\tilde{\\mathbb{E}}[(B_{t_{3}}-B_{t_{2}})(B_{t_{2}}-B_{t_{1}})|\\mathcal{F}_{t_{2}}]]\\\\\n& =\\tilde{\\mathbb{E}}[(B_{t_{2}}-B_{t_{1}})\\tilde{\\mathbb{E}}[(B_{t_{3}}-B_{t_{2}})|\\mathcal{F}_{t_{2}}]]\\\\\n& =\\tilde{\\mathbb{E}}[(B_{t_{2}}-B_{t_{1}})(B_{t_{2}}-B_{t_{2}})]]=0\n\\end{aligned}\\]\nAlso, the covariance\n\\[\\begin{aligned}\n\\tilde{\\mathbb{E}}[\\tilde{B}_{t}\\tilde{B}_{s}] & =\\tilde{\\mathbb{E}}[(\\tilde{B}_{t}-\\tilde{B}_{s})\\tilde{B}_{s}]+\\tilde{\\mathbb{E}}[\\tilde{B}_{s}^{2}]\\\\\n& =0+s\n\\end{aligned}\\]\nSo, \\(\\mathbb{E}[(\\tilde{B}_{t}-\\tilde{B}_{s})^{2}]=t+s-2s=t-s\\).\nConsequently, \\(\\tilde{B}_{t}\\) is a \\(\\tilde{\\mathbb{P}}\\)-standard brownian motion."
  },
  {
    "objectID": "posts/function-currying/index.html",
    "href": "posts/function-currying/index.html",
    "title": "Currying and partial function application",
    "section": "",
    "text": "Let \\(u=f(x_1,\\ldots,x_n)\\) be a function of \\(n\\) variables. curry&lt;n&gt;(f) is an operator form of the function \\(f\\), such that:\n\\[\n\\begin{align*}\n\\text{curry&lt;n&gt;}(f)(a_1)(a_2)\\ldots(a_n) = f(a_1,\\ldots,a_n)\n\\end{align*}\n\\]\nand\n\\[\n\\begin{align*}\n\\text{curry&lt;n&gt;}(f)(a_1) &= \\text{curry&lt;n-1&gt;}(g(x_2,\\ldots,x_n)), & \\quad g(x_2,\\ldots,x_n) &= f(a_1,x_2,\\ldots,x_n) \\\\\n\\text{curry&lt;n-1&gt;}(g)(a_2) &= \\text{curry&lt;n-2&gt;}(h(x_3,\\ldots,x_n)),  &\\quad h(x_3,\\ldots,x_n) &= g(a_2,x_3,\\ldots,x_n)\n\\end{align*}\n\\]\n\n\n#include &lt;iostream&gt;\n#include &lt;functional&gt;\n#include &lt;cmath&gt;\n#include &lt;cassert&gt;\n\n/* curry&lt;N&gt;(f) is an operator form of the function of N variables,\n   so that curry&lt;N&gt;(f)(x_1)(x_2)...(x_N) = f(x_1,...,x_N).\n\n   Also, curry&lt;N&gt;(f)(a_1) = curry&lt;N-1&gt;(f')\n\n   where f' is a function of N-1 variables obtained by partial\n   function application, that is, substituting the value x_1=a_1 in f.\n*/\n\ntemplate&lt;int N&gt;\nauto curry (auto f){\n    if constexpr(N == 1){\n        return [=](auto x){\n            return f(x);\n        };\n    }else{\n        return [=](auto x){\n            return curry&lt;N-1&gt;(\n                [=](auto... rest){\n                    return f(x, rest...);\n            });\n        };\n    }\n};\n\nint main()\n{\n    auto norm = [](double x, double y, double z) -&gt; double {\n        return sqrt(x*x + y*y + z*z);\n    };\n\n    assert(curry&lt;3&gt;(norm)(1)(2)(2) == 3.0);\n    return 0;\n}\nCompiler Explorer"
  },
  {
    "objectID": "posts/function-currying/index.html#c-implementation-using-lambda",
    "href": "posts/function-currying/index.html#c-implementation-using-lambda",
    "title": "Currying and partial function application",
    "section": "",
    "text": "#include &lt;iostream&gt;\n#include &lt;functional&gt;\n#include &lt;cmath&gt;\n#include &lt;cassert&gt;\n\n/* curry&lt;N&gt;(f) is an operator form of the function of N variables,\n   so that curry&lt;N&gt;(f)(x_1)(x_2)...(x_N) = f(x_1,...,x_N).\n\n   Also, curry&lt;N&gt;(f)(a_1) = curry&lt;N-1&gt;(f')\n\n   where f' is a function of N-1 variables obtained by partial\n   function application, that is, substituting the value x_1=a_1 in f.\n*/\n\ntemplate&lt;int N&gt;\nauto curry (auto f){\n    if constexpr(N == 1){\n        return [=](auto x){\n            return f(x);\n        };\n    }else{\n        return [=](auto x){\n            return curry&lt;N-1&gt;(\n                [=](auto... rest){\n                    return f(x, rest...);\n            });\n        };\n    }\n};\n\nint main()\n{\n    auto norm = [](double x, double y, double z) -&gt; double {\n        return sqrt(x*x + y*y + z*z);\n    };\n\n    assert(curry&lt;3&gt;(norm)(1)(2)(2) == 3.0);\n    return 0;\n}\nCompiler Explorer"
  },
  {
    "objectID": "posts/first_passage_time_of_BM/index.html",
    "href": "posts/first_passage_time_of_BM/index.html",
    "title": "The distribution of the first passage time of Brownian Motion",
    "section": "",
    "text": "The distribution of Brownian motion enjoys many interesting symmetries. The reflection of a Brownian motion about any time \\(s\\) is also a Brownian motion.\nLemma 1. (Reflection at time \\(s\\)) Let \\(B_t\\) be a standard Brownian motion. Then, the process \\((-B_t,t \\geq 0)\\) is a Brownian motion. More generally, for any \\(s \\geq 0\\), the process \\((\\tilde{B_t},t\\geq 0)\\) defined by:\n\\[\\begin{align*}\n\\tilde{B}_t = \\begin{cases}\nB_t & \\text{ if } t\\leq s\\\\\nB_s - (B_t - B_s) & \\text{ if }t &gt; s\n\\end{cases}\n\\end{align*}\\]\nis a Brownian motion.\nClaim. \\((-B_t,t\\geq 0)\\) is a Brownian motion.\nProof.\nWe have, \\(-B(0) = 0\\).\nFor any increment \\(s &lt; t\\), the increment \\((-B_t) - (-B_s) = B_s - B_t\\) is a Gaussian random variable with mean \\(0\\) and variance \\(t - s\\).\nFor any choice of \\(n\\) times, \\(0 \\leq t_1 \\leq t_2 \\leq \\ldots \\leq t_n\\), the increments:\n\\[\\begin{align*}\n(B_{0} - B_{t_1}), (B_{t_1} - B_{t_2}), \\ldots, (B_{t_n} - B_{t_{n-1}})\n\\end{align*}\\]\nare independent\nThe paths \\(-B_t(\\omega)\\) are continuous.\nThus, \\((-B_t,t\\geq 0)\\) is a standard Brownian motion.\nClaim. \\((\\tilde{B_t},t\\geq 0)\\) is a Brownian motion.\nProof.\nLet \\(s \\geq 0\\) be any arbitrary time.\nWe have, \\(\\tilde{B}(0) = 0\\).\nConsider any increment \\(\\tilde{B}(t_2) - \\tilde{B}(t_1)\\), \\(t_2 &lt; t_1\\).\nCase I. \\(s \\leq t_1 &lt; t_2\\)\nHere\n\\[\\begin{align*}\n\\tilde{B}(t_2) - \\tilde{B}(t_1) &= B(s) - (B(t_2) - B(s)) - (B(s) - (B(t_1) - B(s))) \\\\\n&= -(B(t_2) - B(t_1))\n\\end{align*}\\]\nHence, \\(\\tilde{B}(t_2) - \\tilde{B}(t_1) \\sim \\mathcal{N}(0,t_2 - t_1)\\).\nCase II. \\(t_1 &lt; s &lt; t_2\\)\nHere\n\\[\\begin{align*}\n\\tilde{B}(t_2) - \\tilde{B}(t_1) &= B(s) - (B(t_2) - B(s)) - B(t_1)\\\\\n&= (B(s) - B(t_1)) - (B(t_2) - B(s))\n\\end{align*}\\]\n\\(B(s) - B(t_1)\\) and \\(B(t_2) - B(s)\\) are independent random variables. Moreover, \\(B(s) - B(t_1) \\sim \\mathcal{N}(0,s - t_1)\\) and \\(B(t_2) - B(s) \\sim \\mathcal{N}(0,t_2 - s)\\). Consequently, \\(\\tilde{B}(t_2) - \\tilde{B}(t_1) \\sim \\mathcal{N}(0,t_2 - t_1)\\).\nCase III. \\(t_1 &lt; t_2 \\leq s\\)\nHere\n\\[\\begin{align*}\n\\tilde{B}(t_2) - \\tilde{B}(t_1) &= B(t_2) - B(t_1)\n\\end{align*}\\]\nso \\(\\tilde{B}(t_2) - \\tilde{B}(t_1) \\sim \\mathcal{N}(0,t_2 - t_1)\\).\nFinally, the paths \\(\\tilde{B}(t,\\omega)\\) are continuous. Hence, \\((\\tilde{B}(t),t\\geq 0)\\) is a standard brownian motion."
  },
  {
    "objectID": "posts/first_passage_time_of_BM/index.html#reflection-principle",
    "href": "posts/first_passage_time_of_BM/index.html#reflection-principle",
    "title": "The distribution of the first passage time of Brownian Motion",
    "section": "Reflection Principle",
    "text": "Reflection Principle\nIt turns out that the above reflection property holds even if \\(s\\) is replaced by a stopping time. I prove this here.\nLemma 2. (Reflection Principle) Let \\((B_t,t \\geq 0)\\) be a standard Brownian motion and \\(\\tau\\) be a stopping time for its filtration. Then, the process \\((\\tilde{B}(t),t\\geq 0)\\) defined by the reflection at time \\(\\tau\\):\n\\[\\begin{align*}\n\\tilde{B}(t) &= \\begin{cases}\nB_t & \\text{ if } t\\leq \\tau\\\\\nB_\\tau - (B_t - B_\\tau) & \\text{ if }t &gt; \\tau\n\\end{cases}\n\\end{align*}\\]\nis also a standard Brownian motion."
  },
  {
    "objectID": "posts/first_passage_time_of_BM/index.html#bacheliers-formula",
    "href": "posts/first_passage_time_of_BM/index.html#bacheliers-formula",
    "title": "The distribution of the first passage time of Brownian Motion",
    "section": "Bachelier’s formula",
    "text": "Bachelier’s formula\nIt is an amazing fact, that some simple manipulations using stopping time yield the complete distribution of the first passage time \\(\\tau_a\\) of a Brownian motion as well as the distribution of the running maximum of the Brownian path on an interval of time \\([0,T]\\). This is surprising since the maximum of the Brownian path on \\([0,T]\\), denoted by \\(\\sup_{0\\leq t \\leq T} B_t\\) is a random variable that depends on the whole path on \\([0,T]\\). This beautiful result is due to Bachelier.\nProposition 3. (Bachelier’s formula) Let \\((B_t,t\\leq T)\\) be a standard Brownian motion on \\([0,T]\\). Then, the CDF of the random variable \\(\\sup_{0 \\leq t\\leq T} B_t\\) is:\n\\[\\begin{align*}\n\\mathbb{P}\\left(\\sup_{0\\leq t \\leq T} B_t \\leq a\\right) = \\mathbb{P}(|B_T| \\leq a) \\quad \\text{ for any }a\\geq 0\n\\end{align*}\\]\nIn particular, its PDF is:\n\\[\\begin{align*}\nf_{max}(a) = \\frac{2}{\\sqrt{2\\pi T}} e^{-a^2/2T}\n\\end{align*}\\]\nIn other words, the random variable \\(\\sup_{0 \\leq t \\leq T} B_t\\) (the maximum of the brownian motion at any time \\(t\\)) has the same distribution as \\(|B_T|\\) (the terminal distribution of the absolute value of the brownian motion).\nThis equality holds in distribution for a fixed \\(t\\). As a bonus corollary, we get the distribution of the first passage time at \\(a\\).\nProof. Consider \\(\\mathbb{P}(\\sup_{t \\leq T} B_t \\geq a)\\). By splitting this probability over the event of the endpoint, we have:\n\\[\\begin{align*}\n\\mathbb{P}(\\sup_{t \\leq T} B_t \\geq a) &= \\mathbb{P}(\\sup_{t \\leq T} B_t \\geq a, B_T &gt; a) + \\mathbb{P}(\\sup_{t \\leq T} B_t \\geq a, B_T \\leq a)\n\\end{align*}\\]\nNote also that \\(\\mathbb{P}(B_T = a) = 0\\). Hence, the first probability equals \\(\\mathbb{P}(B_T \\geq a)\\). As for the second, consider the time \\(\\tau_a\\). On the event considered, we have \\(\\tau_a \\leq T\\) and using the reflection principle (lemma 2), we get:\n\\[\\begin{align*}\n\\mathbb{P}(\\sup_{t \\leq T} B_t \\geq a, B_T \\leq a) &= \\mathbb{P}(\\sup_{t \\leq T} B_t \\geq a, \\tilde{B}_T \\geq a)\n\\end{align*}\\]\nObserve that, since \\(\\tau_a \\leq T\\), the event \\(\\{\\sup_{t \\leq T} B_t \\geq a\\}\\) is the same as \\(\\{\\sup_{t\\leq T} \\tilde{B}(t) \\geq a\\}\\). Therefore the above probability is:\n\\[\\begin{align*}\n\\mathbb{P}(\\sup_{t \\leq T} B_t \\geq a) &= \\mathbb{P}(B_T &gt; a) + \\mathbb{P}(\\sup_{t \\leq T} \\tilde{B}_t \\geq a, \\tilde{B}_T \\geq a)\n\\end{align*}\\]\nBut, \\(\\tilde{B}_t\\) is also a standard brownian motion and has the same distribution as \\(B_t\\). \\(\\mathbb{P}(B_t \\in S) = \\mathbb{P}(\\tilde{B}_t \\in S)\\) by the reflection principle. So, we can simply drop the tilde signs and write:\n\\[\\begin{align*}\n\\mathbb{P}(\\sup_{t \\leq T} B_t \\geq a) &= \\mathbb{P}(B_T &gt; a) + \\mathbb{P}(\\sup_{t \\leq T} {B}_t \\geq a, {B}_T \\geq a)\\\\\n&=\\mathbb{P}(B_T &gt; a) + \\mathbb{P}({B}_T \\geq a)\\\\\n&= \\mathbb{P}(B_T \\leq -a) + \\mathbb{P}(B_T \\geq a) \\\\\n& \\quad \\{\\text{ By symmetry of the Gaussian distribution }\\}\\\\\n&= \\mathbb{P}(B_T \\leq -a \\cup B_T \\geq a) \\\\\n&= \\mathbb{P}(|B_T| \\geq a)\n\\end{align*}\\]\nWe conclude that:\n\\[\\begin{align*}\n\\mathbb{P}(\\sup B_t \\leq a) = \\mathbb{P}(|B_T| \\leq a)\n\\end{align*}\\]\nas claimed.\nTo derive the PDF, we can always write:\n\\[\\begin{align*}\n\\mathbb{P}(\\sup_{t \\leq T} B_t \\geq a) &= \\mathbb{P}(B_T &gt; a) + \\mathbb{P}({B}_T \\geq a)\\\\\n&= 2\\mathbb{P}(B_T \\geq a)\\\\\n&= 2(1 - F_{B_T}(a))\n\\end{align*}\\]\nSo:\n\\[\\begin{align*}\nF_{\\sup B_t}(a) &= 1 - 2(1 - F_{B_T}(a))\\\\\n\\frac{d}{da}(F_{\\sup B_t}(a)) &= 2 \\frac{d}{da}(F_{B_T}(a))\\\\\nf_{\\sup B_t}(a) &= 2 f_{B_T}(a)\\\\\n&= \\frac{2}{\\sqrt{2\\pi T}}\\exp\\left[-\\frac{a^2}{2T}\\right]\n\\end{align*}\\]"
  },
  {
    "objectID": "posts/first_passage_time_of_BM/index.html#distribution-of-the-first-passage-time-tau_a",
    "href": "posts/first_passage_time_of_BM/index.html#distribution-of-the-first-passage-time-tau_a",
    "title": "The distribution of the first passage time of Brownian Motion",
    "section": "Distribution of the first passage time \\(\\tau_a\\)",
    "text": "Distribution of the first passage time \\(\\tau_a\\)\nCorollary 4. Let \\(a \\geq 0\\) and let \\(\\tau_a = \\min \\{t \\geq 0: B_t \\geq a\\}\\). Then:\n\\[\\begin{align*}\n\\mathbb{P}(\\tau_a \\leq T) = \\mathbb{P}\\left(\\sup_{0 \\leq t \\leq T} B_t \\geq a\\right) = \\int_{a}^{\\infty} \\frac{2}{\\sqrt{2\\pi T}}e^{-x^2/2T} dx\n\\end{align*}\\]\nIn particular, the random variable \\(\\tau_a\\) has PDF:\n\\[\\begin{align*}\nf_{\\tau_a}(t) = \\frac{a}{\\sqrt{2\\pi}} \\frac{e^{-a^2/2t}}{t^{3/2}}\n\\end{align*}\\]\nThis implies that it is heavy-tailed and \\(\\mathbb{E}[\\tau_a] = \\infty\\).\nProof.\nThe maximum on \\([0,T]\\) is larger than or equal to \\(a\\), if and only if, \\(\\tau_a \\leq T\\). Therefore, the events \\(\\{\\sup_{0 \\leq t \\leq T} B_t \\geq a\\}\\) and \\(\\{\\tau_a \\leq T\\}\\) are the same. So, the CDF \\(\\mathbb{P}(\\tau_a \\leq t)\\) of \\(\\tau_a\\) is\n\\[\\begin{align*}\nF_{\\tau_a}(t) = \\int_{a}^{\\infty} \\frac{2}{\\sqrt{2\\pi t}} e^{-\\frac{x^2}{2t}} dx\n\\end{align*}\\]\nTo get the PDF, it remains to differentiate the integral with respect to \\(t\\). This is easy to do, once we realise a change of variable \\(u = x/\\sqrt{t}\\), \\(du = dx/\\sqrt{t}\\) that:\n\\[\\begin{align*}\nF_{\\tau_a}(t) &= \\int_{a/\\sqrt{t}}^{\\infty} \\frac{2}{\\sqrt{2\\pi}} e^{-\\frac{u^2}{2}}du\\\\\n&= 2(1 - \\Phi\\left(\\frac{a}{\\sqrt{t}}\\right))\n\\end{align*}\\]\nDifferentiating on both sides with respect to \\(t\\), we get:\n\\[\\begin{align*}\nf_{\\tau_a}(t) &= - 2\\phi\\left(\\frac{a}{\\sqrt{t}}\\right) \\left(-\\frac{1}{2}\\right) \\frac{a}{t^{3/2}}\\\\\n&= \\frac{a}{t^{3/2}} \\frac{e^{-a^2/2t}}{\\sqrt{2\\pi}}\n\\end{align*}\\]\nThis closes the proof."
  },
  {
    "objectID": "posts/diy-asyncio/index.html",
    "href": "posts/diy-asyncio/index.html",
    "title": "DIY asyncio",
    "section": "",
    "text": "In single-core processors, the machine can only perform one task at a time, but can switch between many tasks many times per second. By doing a bit of one task and then a bit of another and so on, it appears that the tasks are happening concureently. This is called task switching. Because the task switches are so fast, it provides an illusion of concurrency to both the user and the applications.\nOn a single-core maching doing task switching, chunks from each task are interleaved. But, they are also spaced out a bit; in order to do the interleaving, the operating system has to perform a context switch every time it changes from one task to another, and this takes time. In order to perform a context switch, the OS has to save the CPU state and the instruction pointer for the currently running task, work out which task to switch to, and reload the CPU state for the task being switched to.\nMulti-core processors are genuinely capable of running more than one task in parallel. This is called hardware concurrency.\n\n\nThe rate of doing work (operations per second) is called throughput. The response time it takes for a system to process a request is called latency.\n\n\n\nSynchronous execution is sequential.\n\ndef foo():\n    print(f\"Inside foo.\")\n\ndef main():\n    print(f\"Starting work.\")\n    foo()\n    print(f\"Finishing work.\")\n\nmain()\n\nStarting work.\nInside foo.\nFinishing work.\n\n\nIn the main() code-path, the call to foo() is a blocking call, the execution jumps to foo() and main() resumes when foo() returns.\nAsynchronous(or async) execution refers to execution that doesn't block when invoking subroutines. It is a fire-and-forget technique. Any work package runs separately from the main application thread and notifies the calling thread of its completion, failure or progress.\nUsually, such methods return an entity called future or promise that is the representation of an in-progress computation. The calling thread can query for the status of the computation via the returned future or promise and retrieve the result once completed.\nAnother pattern is to pass a callback function to the asynchronous functional call, which is invoked with the results when the asynchronous function is done processing.\nAsynchronous programming is an execllent choice for applications that do extensive network or disk I/O and spend most of their time waiting.\n\n\n\n\n\nPrograms that are compute-intensive are called CPU bound programs. This could involve numerical optimizations, Monte-Carlo simulations, data-crunching etc.\n\n\n\nI/O bound programs spend most of their time doing network or main memory and file I/O operations. Since the CPU and main memory are separate, a bus exists between the two to transfer bits. Similarly, data needs to moved from the NIC to CPU/memory. Even though these physical distances are small, the time taken to transfer the data can waste a few thousand CPU cycles. This is why I/O bound programs show relatively lower CPU utilization than CPU bound programs.\n\n\n\n\nThe most common cause of bugs in concurrent code is a race-condition.\n\nimport concurrent.futures\nimport logging\nimport time\nimport concurrent\nimport threading\n\nclass Account:\n    def __init__(self):\n        self.value = 0\n\n    @property\n    def value(self):\n        return self._value\n    \n    @value.setter\n    def value(self, x):\n        self._value = x\n    \n    def credit(self, name : str, amount : float):\n        logging.info(\"Thread %s: starting update\", name)\n        \n        # ----- Critical section -----\n        local_copy = self.value     \n        local_copy += amount\n        time.sleep(0.1)\n        self.value = local_copy\n        # ----- End of critical section -----\n\n        logging.info(\"Thread %s: finishing update\", name)\n\nif __name__ == \"__main__\":\n    format = \"%(asctime)s: %(message)s\"\n    logging.basicConfig(format=format, level=logging.INFO, datefmt=\"%H:%M:%S\")\n    account = Account()\n    logging.info(\"Testing update. Starting value is %d.\", account.value)\n\n    with concurrent.futures.ThreadPoolExecutor(max_workers=2) as executor:\n        for index in range(2):\n            executor.submit(account.credit, index, 100)\n\n    logging.info(\"Testing update. Ending value is %d\", account.value)\n\n11:49:59: Testing update. Starting value is 0.\n11:49:59: Thread 0: starting update\n11:49:59: Thread 1: starting update\n11:49:59: Thread 1: finishing update\n11:49:59: Thread 0: finishing update\n11:49:59: Testing update. Ending value is 100\n\n\nThe above logic can be made thread-safe by fencing off the critical section using a mutex and enforcing that only a single thread can enter at a time.\n\n\n\nImagine that you have a toy that comes in two parts, and you need both parts to play with it - a toy drum and a drumstick, for example. Now, imagine that you ave two small children, both of whom like playing with it. If one of them gets both the drum and the drumstick, that child can merrily play the drum until titing of it. If the other child wants to play, they have wait, however sad that makes them. Now, imagine one child has the drum and other has the drumstick. They’re stuck, unless one decides to be nice and let the other play, each will hold on to whatver they have and demand that they be given the other piece, so neither gets to play. This is a deadlock.\nImagine two threads arguing over locks on mutexes: each of a pair of threads needs to lock both of a pair of mutexes to perform some operation, and each thread has one mutex and is waiting for the other. Neither thread can proceed, because each is waiting for the other to release its mutex. This scenario is called deadlock.\n\nimport threading\nimport concurrent\nimport time\n\nif __name__ == \"__main__\":\n    drum = threading.Lock()\n    drumstick = threading.Lock()\n\n    def child1_plays_drums():\n        print(f\"\\nChild-1 waiting for drums\")\n        drum.acquire()\n        print(f\"\\nChild-1 acquired drums\")\n        print(f\"\\nChild-1 waiting for drumstick\")\n        drumstick.acquire()\n        print(f\"\\nChild-1 is playing drums\")\n\n    def child2_plays_drums():\n        print(f\"\\nChild-2 waiting for drumstick\")\n        drumstick.acquire()\n        print(f\"\\nChild-2 acquired drumstick\")\n        print(f\"\\nChild-2 waiting for drums\")\n        drum.acquire()\n        print(f\"\\nChild-2 acquired drums\")\n        print(f\"\\nChild-2 is playing drums\")\n\n    t1 = threading.Thread(target=child1_plays_drums)\n    t2 = threading.Thread(target=child2_plays_drums)\n    \n    t1.start()\n    t2.start()\n\n    time.sleep(1)\n\n\nChild-1 waiting for drums\n\nChild-1 acquired drums\n\nChild-1 waiting for drumstick\n\nChild-1 is playing drums\n\nChild-2 waiting for drumstick\n\n\n\n\n\nA mutex is an programming construct that allows only a single thread to access a shared resource or critical section. Once a thread acquires a mutex, all other threads attempting to acquire the same mutex are blocked until the thread releases the mutex.\nA semaphore on the hand is used to limit access to a collection of resources. Think of semaphore as having a limited number of permits to give out. If a semaphore has given out all the permits it has, then any new thread that comes along requesting a permit will be blocked till an earlier thread with a permit returns it to the semaphore. A protoypical example is a ConnectionPool that hands out database connects to requesting threads.\nA semaphore with a single permit is called a binary semaphore. Semaphores can also be used for signaling among threads. This is an important distinction as it allows threads to cooperatively work towards completing a task. A mutex on the other hand, is strictly limted to serializing access to shared data among competing threads.\n\n\nA semaphore can potentially act as a mutex if the number of permits it can give is at most \\(1\\). However, the most important difference is that, the thread that calls acquire() on a mutex must subsequently release() the mutex. A mutex is owned by the thread acquiring it, upto the point the owning thread releases it. Whilst, in the case of a binary semaphore, different threads can call acquire() and release() on the semaphore.\n\n\n\n\nAnother distinction between a semaphore and a mutex is that semaphores can be used for signaling amongst threads. For example, in case of the classical producer-consumer problem, the producer thread can signal the consumer thread by incrementing the semaphore count to indicate to the consumer thread to read items from the queue. Threads can coordinate tasks using semaphores. A mutex, in contrast, only guards access to shared data."
  },
  {
    "objectID": "posts/diy-asyncio/index.html#basics",
    "href": "posts/diy-asyncio/index.html#basics",
    "title": "DIY asyncio",
    "section": "",
    "text": "In single-core processors, the machine can only perform one task at a time, but can switch between many tasks many times per second. By doing a bit of one task and then a bit of another and so on, it appears that the tasks are happening concureently. This is called task switching. Because the task switches are so fast, it provides an illusion of concurrency to both the user and the applications.\nOn a single-core maching doing task switching, chunks from each task are interleaved. But, they are also spaced out a bit; in order to do the interleaving, the operating system has to perform a context switch every time it changes from one task to another, and this takes time. In order to perform a context switch, the OS has to save the CPU state and the instruction pointer for the currently running task, work out which task to switch to, and reload the CPU state for the task being switched to.\nMulti-core processors are genuinely capable of running more than one task in parallel. This is called hardware concurrency.\n\n\nThe rate of doing work (operations per second) is called throughput. The response time it takes for a system to process a request is called latency.\n\n\n\nSynchronous execution is sequential.\n\ndef foo():\n    print(f\"Inside foo.\")\n\ndef main():\n    print(f\"Starting work.\")\n    foo()\n    print(f\"Finishing work.\")\n\nmain()\n\nStarting work.\nInside foo.\nFinishing work.\n\n\nIn the main() code-path, the call to foo() is a blocking call, the execution jumps to foo() and main() resumes when foo() returns.\nAsynchronous(or async) execution refers to execution that doesn't block when invoking subroutines. It is a fire-and-forget technique. Any work package runs separately from the main application thread and notifies the calling thread of its completion, failure or progress.\nUsually, such methods return an entity called future or promise that is the representation of an in-progress computation. The calling thread can query for the status of the computation via the returned future or promise and retrieve the result once completed.\nAnother pattern is to pass a callback function to the asynchronous functional call, which is invoked with the results when the asynchronous function is done processing.\nAsynchronous programming is an execllent choice for applications that do extensive network or disk I/O and spend most of their time waiting.\n\n\n\n\n\nPrograms that are compute-intensive are called CPU bound programs. This could involve numerical optimizations, Monte-Carlo simulations, data-crunching etc.\n\n\n\nI/O bound programs spend most of their time doing network or main memory and file I/O operations. Since the CPU and main memory are separate, a bus exists between the two to transfer bits. Similarly, data needs to moved from the NIC to CPU/memory. Even though these physical distances are small, the time taken to transfer the data can waste a few thousand CPU cycles. This is why I/O bound programs show relatively lower CPU utilization than CPU bound programs.\n\n\n\n\nThe most common cause of bugs in concurrent code is a race-condition.\n\nimport concurrent.futures\nimport logging\nimport time\nimport concurrent\nimport threading\n\nclass Account:\n    def __init__(self):\n        self.value = 0\n\n    @property\n    def value(self):\n        return self._value\n    \n    @value.setter\n    def value(self, x):\n        self._value = x\n    \n    def credit(self, name : str, amount : float):\n        logging.info(\"Thread %s: starting update\", name)\n        \n        # ----- Critical section -----\n        local_copy = self.value     \n        local_copy += amount\n        time.sleep(0.1)\n        self.value = local_copy\n        # ----- End of critical section -----\n\n        logging.info(\"Thread %s: finishing update\", name)\n\nif __name__ == \"__main__\":\n    format = \"%(asctime)s: %(message)s\"\n    logging.basicConfig(format=format, level=logging.INFO, datefmt=\"%H:%M:%S\")\n    account = Account()\n    logging.info(\"Testing update. Starting value is %d.\", account.value)\n\n    with concurrent.futures.ThreadPoolExecutor(max_workers=2) as executor:\n        for index in range(2):\n            executor.submit(account.credit, index, 100)\n\n    logging.info(\"Testing update. Ending value is %d\", account.value)\n\n11:49:59: Testing update. Starting value is 0.\n11:49:59: Thread 0: starting update\n11:49:59: Thread 1: starting update\n11:49:59: Thread 1: finishing update\n11:49:59: Thread 0: finishing update\n11:49:59: Testing update. Ending value is 100\n\n\nThe above logic can be made thread-safe by fencing off the critical section using a mutex and enforcing that only a single thread can enter at a time.\n\n\n\nImagine that you have a toy that comes in two parts, and you need both parts to play with it - a toy drum and a drumstick, for example. Now, imagine that you ave two small children, both of whom like playing with it. If one of them gets both the drum and the drumstick, that child can merrily play the drum until titing of it. If the other child wants to play, they have wait, however sad that makes them. Now, imagine one child has the drum and other has the drumstick. They’re stuck, unless one decides to be nice and let the other play, each will hold on to whatver they have and demand that they be given the other piece, so neither gets to play. This is a deadlock.\nImagine two threads arguing over locks on mutexes: each of a pair of threads needs to lock both of a pair of mutexes to perform some operation, and each thread has one mutex and is waiting for the other. Neither thread can proceed, because each is waiting for the other to release its mutex. This scenario is called deadlock.\n\nimport threading\nimport concurrent\nimport time\n\nif __name__ == \"__main__\":\n    drum = threading.Lock()\n    drumstick = threading.Lock()\n\n    def child1_plays_drums():\n        print(f\"\\nChild-1 waiting for drums\")\n        drum.acquire()\n        print(f\"\\nChild-1 acquired drums\")\n        print(f\"\\nChild-1 waiting for drumstick\")\n        drumstick.acquire()\n        print(f\"\\nChild-1 is playing drums\")\n\n    def child2_plays_drums():\n        print(f\"\\nChild-2 waiting for drumstick\")\n        drumstick.acquire()\n        print(f\"\\nChild-2 acquired drumstick\")\n        print(f\"\\nChild-2 waiting for drums\")\n        drum.acquire()\n        print(f\"\\nChild-2 acquired drums\")\n        print(f\"\\nChild-2 is playing drums\")\n\n    t1 = threading.Thread(target=child1_plays_drums)\n    t2 = threading.Thread(target=child2_plays_drums)\n    \n    t1.start()\n    t2.start()\n\n    time.sleep(1)\n\n\nChild-1 waiting for drums\n\nChild-1 acquired drums\n\nChild-1 waiting for drumstick\n\nChild-1 is playing drums\n\nChild-2 waiting for drumstick\n\n\n\n\n\nA mutex is an programming construct that allows only a single thread to access a shared resource or critical section. Once a thread acquires a mutex, all other threads attempting to acquire the same mutex are blocked until the thread releases the mutex.\nA semaphore on the hand is used to limit access to a collection of resources. Think of semaphore as having a limited number of permits to give out. If a semaphore has given out all the permits it has, then any new thread that comes along requesting a permit will be blocked till an earlier thread with a permit returns it to the semaphore. A protoypical example is a ConnectionPool that hands out database connects to requesting threads.\nA semaphore with a single permit is called a binary semaphore. Semaphores can also be used for signaling among threads. This is an important distinction as it allows threads to cooperatively work towards completing a task. A mutex on the other hand, is strictly limted to serializing access to shared data among competing threads.\n\n\nA semaphore can potentially act as a mutex if the number of permits it can give is at most \\(1\\). However, the most important difference is that, the thread that calls acquire() on a mutex must subsequently release() the mutex. A mutex is owned by the thread acquiring it, upto the point the owning thread releases it. Whilst, in the case of a binary semaphore, different threads can call acquire() and release() on the semaphore.\n\n\n\n\nAnother distinction between a semaphore and a mutex is that semaphores can be used for signaling amongst threads. For example, in case of the classical producer-consumer problem, the producer thread can signal the consumer thread by incrementing the semaphore count to indicate to the consumer thread to read items from the queue. Threads can coordinate tasks using semaphores. A mutex, in contrast, only guards access to shared data."
  },
  {
    "objectID": "posts/diy-asyncio/index.html#threading-module",
    "href": "posts/diy-asyncio/index.html#threading-module",
    "title": "DIY asyncio",
    "section": "threading module",
    "text": "threading module\nData-parallelism can be achieved using multi-threading.\n\nimport numpy as np\nimport threading\nimport typing\n\ndef accumulate(a : np.array, idx : int):\n    result = np.sum(a)\n    print(f\"\\nSum of the subarray {idx} = {result}\")\n\nif __name__ == \"__main__\":\n    data = np.random.rand(1000000)\n    num_chunks = 4\n    chunk_size = int(len(data) / num_chunks)\n    num_threads = num_chunks\n\n    threads = []\n    for i in range(num_threads):\n        start = i * chunk_size\n        end = start + chunk_size\n        thread = threading.Thread(target=accumulate(data[start:end], i))\n        threads.append(thread)\n\n    for t in threads:\n        t.start()\n\n    for t in threads:\n        t.join()\n\n\nSum of the subarray 0 = 124776.70127165115\n\nSum of the subarray 1 = 125051.88402552163\n\nSum of the subarray 2 = 125194.03813575335\n\nSum of the subarray 3 = 125021.25239279671\n\n\nAnother way to create threads is subclassing the threading.Thread class.\n\nfrom threading import Thread\nfrom threading import current_thread\n\nclass MyTask(Thread):\n\n    def __init__(self):\n        Thread.__init__(self, name=\"subClassThread\", args=(2,3))\n\n    def run(self):\n        print(f\"{current_thread().name} is executing\")\n\nmyTask = MyTask()\nmyTask.start()  # start the thread\nmyTask.join()   # wait for the thread to complete\n\nThe important caveats to remember when subclassing Thread class are:\n\nWe can only override the run() method and the constructor of the Thread class.\nThread.__init__() must be invoked if the subclass chooses to override the constructor.\n\n\nDaemon Thread\nDaemon threads are background threads. When the main thread is about to exit, it cycles through all regular non-daemon threads and waits for them to complete. In the implementation of the threading module, the _shutdown() method iterates through non-daemon threads and invokes join() on each of them. join() is a blocking call, which returns when a thread’s work package is complete.\n\nimport threading\nimport time\n\ndef daemon_task():\n    while(True):\n        print(f\"Executing daemon task\")\n        time.sleep(1)\n    print(f\"Completed daemon task\")\n\nif __name__ == \"__main__\":\n    daemon_thread = threading.Thread(\n        target=daemon_task,\n        name=\"daemon thread\",\n        daemon=True\n    )\n\n    daemon_thread.start()\n\nExecuting daemon task\n\n\n\n\nImplementation of a thread-safe LIFO stack\n\nimport threading\nimport time\nfrom typing import Any, Optional\n\nclass StackFull(Exception):\n    pass\n\nclass StackEmpty(Exception):\n    pass\n    \nclass Stack:\n    def __init__(self, maxsize : int = None):\n        self._mutex = threading.RLock()\n        self.maxsize = maxsize\n        self._data = list()\n\n    @property\n    def maxsize(self):\n        with self._mutex:\n            value = self._maxsize\n\n        return value\n\n    @maxsize.setter\n    def maxsize(self, value : int):\n        with self._mutex:\n            self._maxsize = value\n\n    def size(self) -&gt; int:\n        with self._mutex:\n            size = len(self._data)\n        \n        return size\n\n    def empty(self) -&gt; bool:\n        with self._mutex:\n            isEmpty = len(self._data) == 0\n        \n        return isEmpty\n\n    def full(self) -&gt; bool:\n        with self._mutex:\n            if(self.maxsize is not None):\n                isFull = len(self._data) == self.maxsize\n            else:\n                isFull = False\n        \n        return isFull\n\n    def put(\n        self,\n        item : Any, \n        block : bool = True, \n        timeout : float = -1\n    ) -&gt; None:\n        self._mutex.acquire(blocking=True,timeout=timeout)\n        print(f\"\\nPushing item {item} to the stack\")\n        if self.full():\n            print(\"Stack full!\")\n            self._mutex.release()\n            raise StackFull(\"Stack full!\")\n        \n        self._data.append(item)\n        print(f\"\\nPush complete\")\n        print(f\"stack : {self._data}\")\n        self._mutex.release()\n    \n    def put_nowait(self, item:Any):\n        self.put(item, block=False)\n\n    def get(self, block : bool = True, timeout : float = -1) -&gt; Any:\n        self._mutex.acquire(blocking=block, timeout=timeout)\n        print(f\"\\nPopping from the stack\")\n        if self.empty():\n            print(\"Stack empty!\")\n            self._mutex.release()\n            raise StackEmpty(\"Stack empty!\")\n        \n        value = self._data[self.size() - 1]\n        del self._data[self.size() - 1]\n        print(f\"\\nPopped item {value} from the stack\")\n        print(f\"stack : {self._data}\")\n        self._mutex.release()\n\n        return value\n\n    def get_no_wait(self):\n        return self.get(block=False)\n\n    def top(self) -&gt; Any:\n        self._mutex.acquire()\n        if self.empty():\n            self._mutex.release()\n            print(\"Stack empty!\")\n            raise StackEmpty(\"Stack empty!\")  \n\n        value = self._data[self.size() - 1]\n        self._mutex.release()\n        return value\n\ndef push_thread(stack : Stack):\n    \n    for i in range(10):\n        try:\n            stack.put(i)\n            time.sleep(0.1)\n        except Exception:\n            pass\n\ndef pop_thread(stack: Stack):\n    for i in range(10):\n        try:\n            item = stack.get()\n            time.sleep(0.12)\n        except Exception:\n            pass\n\nif __name__ == \"__main__\":\n    stack = Stack()\n    \n    t1 = threading.Thread(target=push_thread, args=(stack,))\n    t2 = threading.Thread(target=pop_thread, args=(stack,))\n    \n    t1.start()\n    t2.start()\n\n    t1.join()\n    t2.join()\n    \n    print(\"main() thread finished.\")\n\n\nPushing item 0 to the stack\n\nPush complete\nstack : [0]\n\nPopping from the stack\n\nPopped item 0 from the stack\nstack : []\n\nPushing item 1 to the stack\n\nPush complete\nstack : [1]\n\nPopping from the stack\n\nPopped item 1 from the stack\nstack : []\n\nPushing item 2 to the stack\n\nPush complete\nstack : [2]\n\nPopping from the stack\n\nPopped item 2 from the stack\nstack : []\n\nPushing item 3 to the stack\n\nPush complete\nstack : [3]\n\nPopping from the stack\n\nPopped item 3 from the stack\nstack : []\n\nPushing item 4 to the stack\n\nPush complete\nstack : [4]\n\nPopping from the stack\n\nPopped item 4 from the stack\nstack : []\n\nPushing item 5 to the stack\n\nPush complete\nstack : [5]\n\nPopping from the stack\n\nPopped item 5 from the stack\nstack : []\n\nPushing item 6 to the stack\n\nPush complete\nstack : [6]\n\nPushing item 7 to the stack\n\nPush complete\nstack : [6, 7]\n\nPopping from the stack\n\nPopped item 7 from the stack\nstack : [6]\n\nPushing item 8 to the stack\n\nPush complete\nstack : [6, 8]\n\nPopping from the stack\n\nPopped item 8 from the stack\nstack : [6]\n\nPushing item 9 to the stack\n\nPush complete\nstack : [6, 9]\n\nPopping from the stack\n\nPopped item 9 from the stack\nstack : [6]\n\nPopping from the stack\n\nPopped item 6 from the stack\nstack : []\nmain() thread finished.\n\n\nIn the above implementation, I used RLock - a reentrant lock. If a thread acquires a RLock object, it can choose to reacquire it as many times as possible. It is implicit to call release() as many times as lock() was called.\n\n\nCondition variables\nWe looked at various ways of protecting the data that’s shared between threads. But, sometimes we don’t just need to protect the data, we also need to synchronize actions on separate threads. One thread might need to wait for another thread to complete a task before the first thread can complete its own. In general, its common to want a thread to wait for a specific event to happen or a condition to be true. Although it would be possible to do this by periodically checking a task-complete flag or something like that, it is far from ideal. The need to synchronize operations between threads like this is a common scenario and the python standard standard library provides facilities to handle it, in the form of condition variables and futures.\nA condition variable is always associated with some kind of lock; this can be passed in, or one will be created on the fly. Passing one in is useful when several condition variables must share the same lock. The two important methods of a condition variable are:\n\nwait() - The wait() method releases the lock held, then block until another thread awakens it by calling notify() or notify_all(). Once awakened, wait() reqacquires the lock and returns.\nnotify() - The notify() method arbitrarily wakes up any one of the threads waiting on the condition variable. The notify_all() method wakes up all the threads.\n\nThe typical programming style using condition variables uses the lock to synchronize access to some shared state; threads that are interest in a particular change of state call wait() repeatedly until they see the desired state, while threads that modify the state call notify() or notify_all() when they change the state in such a way that it could possibly be a desired state for one of the waiters.\nNote: The notify() and notify_all() methods don’t release the lock; this means that the thread or threads awakened will not return from their wait() call immediately, but only when the waited-for thread finally relinquishes the ownership of the lock.\nFor example, the following code is a generic producer-consumer situation with unlimited buffer capacity:\n# consumer\nwith cond_var:\n    while item_is_not_available:\n        cond_var.wait()\n    \n    get_the_available_item()\n\n# producer\nwith cond_var:\n    produce_an_item()\n    cond_var.notify()\n\n\nImplementation of a thread-based SPSC bounded ring-buffer\n\nimport threading\nimport time\nfrom typing import Any, Optional\nfrom threading import Condition\n\nclass QueueFull(Exception):\n    pass\n\nclass QueueEmpty(Exception):\n    pass\n    \nclass Queue:\n    def __init__(self, maxsize : int = None):\n        self._lck = threading.RLock()\n        self._queue_not_empty_condition = Condition(self._lck)\n        self._queue_not_full_condition = Condition(self._lck)\n        self.maxsize = maxsize\n        self._data = list()\n\n    @property\n    def maxsize(self):\n        with self._lck:\n            value = self._maxsize\n\n        return value\n\n    @maxsize.setter\n    def maxsize(self, value : int):\n        with self._lck:\n            self._maxsize = value\n\n    def size(self) -&gt; int:\n        with self._lck:\n            size = len(self._data)\n        \n        return size\n\n    def empty(self) -&gt; bool:\n        with self._lck:\n            isEmpty = len(self._data) == 0\n        \n        return isEmpty\n\n    def full(self) -&gt; bool:\n        with self._lck:\n            if(self.maxsize is not None):\n                isFull = len(self._data) == self.maxsize\n            else:\n                isFull = False\n        \n        return isFull\n\n    def put(\n        self,\n        item : Any, \n    ) -&gt; None:\n        print(f\"\\nPushing item {item} to the queue\")\n        \n        self._queue_not_full_condition.acquire()\n        \n        while (self.full()):\n            self._queue_not_full_condition.wait()\n        \n        self._data.append(item)\n\n        print(f\"\\nPush complete\")\n        print(f\"queue : {self._data}\")\n        \n        self._queue_not_empty_condition.notify()\n\n        self._queue_not_full_condition.release()\n        return\n\n\n    def get(self) -&gt; Any:\n        \n        self._queue_not_empty_condition.acquire()\n\n        while (self.empty()):\n            self._queue_not_empty_condition.wait()\n\n        print(f\"\\nPopping from the queue\")\n        \n        value = self._data[0]\n        del self._data[0]\n        print(f\"\\nPopped item {value} from the queue\")\n        print(f\"queue : {self._data}\")\n\n        self._queue_not_full_condition.notify()\n\n        self._queue_not_empty_condition.release()\n        return value\n\n    def top(self) -&gt; Any:\n        self._lck.acquire()\n        if self.empty():\n            self._lck.release()\n            raise QueueEmpty(\"queue empty!\")  \n\n        value = self._data[self.size() - 1]\n        self._lck.release()\n        return value\n\ndef push_thread(queue : Queue):\n    \n    for i in range(10):\n        try:\n            queue.put(i)\n            time.sleep(0.07)\n        except Exception:\n            pass\n\ndef pop_thread(queue: Queue):\n    for i in range(10):\n        try:\n            item = queue.get()\n            time.sleep(0.1)\n        except Exception:\n            pass\n\nif __name__ == \"__main__\":\n    queue = Queue()\n   \n    \n    t1 = threading.Thread(target=push_thread, args=(queue,))\n    t2 = threading.Thread(target=pop_thread, args=(queue,))\n    \n    t1.start()\n    t2.start()\n\n    t1.join()\n    t2.join()\n    \n    print(\"main() thread finished.\")\n\n\nPushing item 0 to the queue\n\nPush complete\nqueue : [0]\n\nPopping from the queue\n\nPopped item 0 from the queue\nqueue : []\n\nPushing item 1 to the queue\n\nPush complete\nqueue : [1]\n\nPopping from the queue\n\nPopped item 1 from the queue\nqueue : []\n\nPushing item 2 to the queue\n\nPush complete\nqueue : [2]\n\nPopping from the queue\n\nPopped item 2 from the queue\nqueue : []\n\nPushing item 3 to the queue\n\nPush complete\nqueue : [3]\n\nPushing item 4 to the queue\n\nPush complete\nqueue : [3, 4]\n\nPopping from the queue\n\nPopped item 3 from the queue\nqueue : [4]\n\nPushing item 5 to the queue\n\nPush complete\nqueue : [4, 5]\n\nPopping from the queue\n\nPopped item 4 from the queue\nqueue : [5]\n\nPushing item 6 to the queue\n\nPush complete\nqueue : [5, 6]\n\nPushing item 7 to the queue\n\nPush complete\nqueue : [5, 6, 7]\n\nPopping from the queue\n\nPopped item 5 from the queue\nqueue : [6, 7]\n\nPushing item 8 to the queue\n\nPush complete\nqueue : [6, 7, 8]\n\nPopping from the queue\n\nPopped item 6 from the queue\nqueue : [7, 8]\n\nPushing item 9 to the queue\n\nPush complete\nqueue : [7, 8, 9]\n\nPopping from the queue\n\nPopped item 7 from the queue\nqueue : [8, 9]\n\nPopping from the queue\n\nPopped item 8 from the queue\nqueue : [9]\n\nPopping from the queue\n\nPopped item 9 from the queue\nqueue : []\nmain() thread finished.\n\n\n\n\nSemaphores\nThis is one of the oldest synchronization primitices in the history of CS, invented by the Dutch computer scientist Edsger W. Djikstra. A semaphore manages an internal counter which is decremented by each acquire() and incremented by each release() call."
  },
  {
    "objectID": "posts/diy-asyncio/index.html#events",
    "href": "posts/diy-asyncio/index.html#events",
    "title": "DIY asyncio",
    "section": "Events",
    "text": "Events\nAn Event object is one of the simplest primitives available for synchronization. Internally, the CPython implementation manages a flag that can be set to True with the set() method and reset to False using the clear() method. The wait() method blocks until the flag is True.\nWhen the internal flag is set to True, all threads waiting on the Event are awakened. Threads that call wait() once the flag is True will not block at all.\nWhen the internal flag is reset to False, threads calling wait() will block until set() is called to set the internal flag to True again."
  },
  {
    "objectID": "posts/diy-asyncio/index.html#the-global-interpreter-lockgil",
    "href": "posts/diy-asyncio/index.html#the-global-interpreter-lockgil",
    "title": "DIY asyncio",
    "section": "The Global Interpreter Lock(GIL)",
    "text": "The Global Interpreter Lock(GIL)\nThe Python interpreter maintains a reference count of each object in Python code. When references go out of scope, the reference count of the object is decremented and if the reference count equals \\(0\\), memory is deallocated(reclaimed). These reference counts are shared state and executing Python bytecode requires acquiring an exclusive lock on the interpreter (shared state). The implication is that the threading library does not offer true hardware concurrency even on multi-core CPUs."
  },
  {
    "objectID": "posts/diy-asyncio/index.html#asyncio-from-scratch",
    "href": "posts/diy-asyncio/index.html#asyncio-from-scratch",
    "title": "DIY asyncio",
    "section": "asyncio from scratch",
    "text": "asyncio from scratch\n\nGenerators\n\ndef fib(count: int):\n    a, b = 1, 0\n    for i in range(count):\n        a, b = b, a + b\n        yield b\n\ndef main():\n    gen = fib(5)\n    print(gen)\n    while True:\n        print(next(gen))\n\ntry:\n    main()        \nexcept StopIteration:\n    print(\"Stop Iteration.\")\n\n&lt;generator object fib at 0x11e043ca0&gt;\n1\n1\n2\n3\n5\nStop Iteration.\n\n\nThe fibonacci sequence is a staple of generator examples. Each time through the loop we add the previous two numbers together and yield that value resulting in the sequence \\(\\{1, 1, 2, 3, 5, \\ldots \\}\\). But, when we call this function, we don’t get any of these values directly, instead we get a compiled version of the generator object. The actual code in our function hasn’t even started executing yet.\nThe generator object can then be iterated over just like a list and the standard next() function from the standard library can be used to iterate just once at a time. Each time we call next() on our generator object, it’s re-entering the function where we left off, preserving the full state and if the function yields another value we get that value as the result value or the return value from the next call. When the generator function completes or returns, it raises a StopIteration exception, just like any other iterator would.\nIt’s quite common to see generators that yield values out, but it’s also possible to communicate or send values back into the generator from the outside. To do this, we have to replace the use of the next() function with the generator’s send() function.\n\ndef counter(start = 0, stop = 10, step = 1):\n    value = start\n    while value &lt; stop:\n        value = yield value\n        value += step\n    yield value\n\ndef main():\n    gen = counter()\n    \n    # prime the generator\n    # advance to the next yield statement\n    value = gen.send(None)\n    print(f\"sent None, got {value}\")\n\n    try:\n        while(True):\n            next_value = gen.send(value)\n            print(f\"sent {value}, got {next_value}\")\n            value = next_value\n    except StopIteration:\n        print(\"StopIteration.\")\n\nmain()\n\nsent None, got 0\nsent 0, got 1\nsent 1, got 2\nsent 2, got 3\nsent 3, got 4\nsent 4, got 5\nsent 5, got 6\nsent 6, got 7\nsent 7, got 8\nsent 8, got 9\nsent 9, got 10\nStopIteration.\n\n\nCongratulation, now you’ve just discovered coroutines. Python’s had them hiding in plain sight for years. But, how do we actually use this to run concurrent tasks?\nWe are going to write an event loop that calls send on each generator object. And rather than looking for a flag, we catch the StopIteration exception and mark those generators and tasks as completed. The StopIteration itself contains the return value from these generators. So, we save those for the final result. Lastly, we also capture intermediate yielded values and send them back on the next iteration, which enables coroutines to call other coroutines.\n\nfrom typing import Generator, Any, List, Iterable\nimport time\n\n\ndef wait(tasks: Iterable[Generator]) -&gt; List[Any]:\n    pending = list(tasks)\n    tasks = {task: None for task in pending}\n    before = time.time()\n\n    while pending:\n        for gen in pending:\n            try:\n                tasks[gen] = gen.send(tasks[gen])\n            except StopIteration as e:\n                tasks[gen] = e.args[0]\n                pending.remove(gen)\n\n    print(f\"duration = {time.time() - before:.3}\")\n    return list(tasks.values())\n\nThis means that we can now yield from another coroutine to call into it. Together, this makes our coroutines look and feel more like standard functions. But, they are still yielding control on their terms, and get to continue where they left off when its their turn again.\n\ndef sleep(duration: float):\n    now = time.time()\n    threshold = now + duration\n\n    while now &lt; threshold:\n        yield\n        now = time.time()\n\ndef bar():\n    yield from sleep(0.1)\n    return 123\n\ndef foo():\n    value = yield from bar()\n    return value\n\ndef main():\n    tasks = [foo(), foo()]\n    print(wait(tasks))\n\nmain()\n\nduration = 0.1\n[123, 123]\n\n\nWe can create a pair of coroutines from the foo() functions and pass them to the event loop. It will follow execution from foo into bar and then into the sleep coroutine. In there, it will continue yielding back into the event loop until the time duration is up. Then, on the next iteration, it will return control to bar() which returns the value back to foo() which finally completes and returns the value.\nTo be clear, at each yield(), our event loop is cycling to the next pending task, giving us the cooperative multitasking concurrency that we have been looking for."
  },
  {
    "objectID": "posts/derivation-for-the-least-squares-estimate-of-beta-/index.html",
    "href": "posts/derivation-for-the-least-squares-estimate-of-beta-/index.html",
    "title": "Derivation of the Least Squares Estimate Beta in Linear Regression",
    "section": "",
    "text": "The following post is going to derive the least squares estimate of the coefficients of linear regression. Our data consists of \\(p\\) predictors or features \\(X_1,\\ldots,X_p\\) and a response \\(Y\\), and there are \\(n\\) observations in our dataset. Assume that the data arises from the real world model:\n\\[\\begin{align}\n\\begin{bmatrix}\ny_1 \\\\\ny_2 \\\\\n\\ldots \\\\\ny_n\n\\end{bmatrix} =\n\\begin{bmatrix}\nx_{11} & x_{12} & \\ldots & x_{1p} \\\\\nx_{21} & x_{22} & \\ldots & x_{2p} \\\\\n\\vdots \\\\\nx_{n1} & x_{n2} & \\ldots & x_{np}\n\\end{bmatrix}\n\\begin{bmatrix}\n\\beta_1 \\\\\n\\beta_2 \\\\\n\\vdots \\\\\n\\beta_p\n\\end{bmatrix} +\n\\begin{bmatrix}\n\\epsilon_1 \\\\\n\\epsilon_2 \\\\\n\\ldots \\\\\n\\epsilon_n\n\\end{bmatrix} \\tag{1}\n\\end{align}\\]\nor in matrix notation,\n\\[Y = X \\beta + \\epsilon \\tag{2}\\]\n\n\nThe real world model in equation (1) is called the population regression line.\nIn statistics, we quite often do not know the population mean \\(\\mu\\), but we try to estimate it using the sample mean \\(\\hat{\\mu}\\).\nIn a similar vein, we do not know the true values of the regression coefficients \\(\\beta_1,\\beta_2,\\ldots,\\beta_p\\). Instead, we estimate them from the data as \\(\\hat{\\beta_1},\\hat{\\beta_2},\\ldots,\\hat{\\beta_p}\\).\nSo, our linear regression model would predict an outcome:\n\\[\\hat{Y} = \\hat{\\beta_1}X_1 + \\hat{\\beta_2} X_2 + \\ldots +\\hat{\\beta_p} X_p \\tag{3}\\]"
  },
  {
    "objectID": "posts/derivation-for-the-least-squares-estimate-of-beta-/index.html#introduction",
    "href": "posts/derivation-for-the-least-squares-estimate-of-beta-/index.html#introduction",
    "title": "Derivation of the Least Squares Estimate Beta in Linear Regression",
    "section": "",
    "text": "The following post is going to derive the least squares estimate of the coefficients of linear regression. Our data consists of \\(p\\) predictors or features \\(X_1,\\ldots,X_p\\) and a response \\(Y\\), and there are \\(n\\) observations in our dataset. Assume that the data arises from the real world model:\n\\[\\begin{align}\n\\begin{bmatrix}\ny_1 \\\\\ny_2 \\\\\n\\ldots \\\\\ny_n\n\\end{bmatrix} =\n\\begin{bmatrix}\nx_{11} & x_{12} & \\ldots & x_{1p} \\\\\nx_{21} & x_{22} & \\ldots & x_{2p} \\\\\n\\vdots \\\\\nx_{n1} & x_{n2} & \\ldots & x_{np}\n\\end{bmatrix}\n\\begin{bmatrix}\n\\beta_1 \\\\\n\\beta_2 \\\\\n\\vdots \\\\\n\\beta_p\n\\end{bmatrix} +\n\\begin{bmatrix}\n\\epsilon_1 \\\\\n\\epsilon_2 \\\\\n\\ldots \\\\\n\\epsilon_n\n\\end{bmatrix} \\tag{1}\n\\end{align}\\]\nor in matrix notation,\n\\[Y = X \\beta + \\epsilon \\tag{2}\\]\n\n\nThe real world model in equation (1) is called the population regression line.\nIn statistics, we quite often do not know the population mean \\(\\mu\\), but we try to estimate it using the sample mean \\(\\hat{\\mu}\\).\nIn a similar vein, we do not know the true values of the regression coefficients \\(\\beta_1,\\beta_2,\\ldots,\\beta_p\\). Instead, we estimate them from the data as \\(\\hat{\\beta_1},\\hat{\\beta_2},\\ldots,\\hat{\\beta_p}\\).\nSo, our linear regression model would predict an outcome:\n\\[\\hat{Y} = \\hat{\\beta_1}X_1 + \\hat{\\beta_2} X_2 + \\ldots +\\hat{\\beta_p} X_p \\tag{3}\\]"
  },
  {
    "objectID": "posts/derivation-for-the-least-squares-estimate-of-beta-/index.html#residual-sum-of-squares",
    "href": "posts/derivation-for-the-least-squares-estimate-of-beta-/index.html#residual-sum-of-squares",
    "title": "Derivation of the Least Squares Estimate Beta in Linear Regression",
    "section": "Residual sum of squares",
    "text": "Residual sum of squares\nThe difference between the observed response value and the predicted response value is called as the residual.\nWe define the residual sum of squares as:\n\\[\\begin{align*}\n(Y - X\\hat{\\beta})'(Y - X\\hat{\\beta})&= (Y' - \\hat{\\beta}' X')(Y - X\\hat{\\beta})\\\\\n&= Y'Y - Y'X \\hat{\\beta} - \\hat{\\beta}' X' Y + \\hat{\\beta}'X'X\\hat{\\beta}\n\\end{align*}\\]\nThe \\(j\\)-th column of \\(Y'X\\) is \\(\\sum_{i=1}^{n}y_i x_{ij}\\) and therefore the product \\(Y'X\\hat{\\beta}\\) equals \\(\\sum_{j=1}^{p}\\sum_{i=1}^{n}y_i x_{ij}\\hat{\\beta_j}\\). But, \\((x_{ij}) = (x_{ji})^T\\). The same sum can be re-written \\(\\sum_{i=1}^{n}\\sum_{j=1}^{p}\\hat{\\beta_j} x_{ji}^T y_i\\). Thus, \\(\\hat{\\beta}' X' Y = Y' X \\hat{\\beta}\\).\nConsequently,\n\\[\\begin{align*}\n(Y - X\\hat{\\beta})'(Y - X\\hat{\\beta})&= Y'Y - 2Y'X \\hat{\\beta} + \\hat{\\beta}'X'X\\hat{\\beta} \\tag{4}\n\\end{align*}\\]"
  },
  {
    "objectID": "posts/derivation-for-the-least-squares-estimate-of-beta-/index.html#aside-proof-i",
    "href": "posts/derivation-for-the-least-squares-estimate-of-beta-/index.html#aside-proof-i",
    "title": "Derivation of the Least Squares Estimate Beta in Linear Regression",
    "section": "Aside proof I",
    "text": "Aside proof I\nClaim. Let \\(A \\in \\mathbf{R}^{m \\times n}\\) be a rectangular matrix and \\(\\vec{x}\\) be a vector of \\(n\\) elements and let \\(\\vec{y}\\) be the matrix-vector product:\n\\[\\vec{y} = A \\vec{x}\\]\nThen,\n\\[\\frac{\\partial \\vec{y}}{\\partial \\vec{x}} = A\\]\nProof.\nLet \\(A_1,\\ldots,A_n\\) be the columns of \\(A\\). Then,\n\\[\\begin{align*}\n\\vec{y} &= [A_1, A_2, \\ldots, A_n] \\begin{bmatrix}\nx_1 \\\\\nx_2 \\\\\n\\vdots \\\\\nx_n\n\\end{bmatrix} \\\\\n&= A_1 x_1 + A_2 x_2 + \\ldots + A_n x_n\n\\end{align*}\\]\nThus,\n\\[\\frac{\\partial \\vec{y}}{\\partial x_i} = A_i\\]\nConsequently,\n\\[\\frac{\\partial \\vec{y}}{\\partial \\vec{x}} = A\\]"
  },
  {
    "objectID": "posts/derivation-for-the-least-squares-estimate-of-beta-/index.html#aside-proof-ii",
    "href": "posts/derivation-for-the-least-squares-estimate-of-beta-/index.html#aside-proof-ii",
    "title": "Derivation of the Least Squares Estimate Beta in Linear Regression",
    "section": "Aside proof II",
    "text": "Aside proof II\nClaim. Consider the quadratic form \\(Q(\\vec{x}) = \\vec{x}^T A^T A \\vec{x}\\). Then, we have:\n\\[\\frac{\\partial Q}{\\partial \\vec{x}} = 2A^T A\\vec{x}\\]\nProof.\nThe matrix \\(K = A^T A\\) is symmetric, since \\((A^T A)^T = A^T (A^T)^T = A^T A\\). So, \\(Q = \\vec{x}^T K \\vec{x}\\). Now, let \\(A = (A_1, A_2, \\ldots, A_n)\\) in the block form, \\(A_j\\) denotes the \\(j\\)-th column of \\(A\\). Thus, \\(A \\vec{x} =\\sum_j A_j x_j\\). and \\(\\vec{x}^T A^T = \\sum_j A_j x_j\\) as well. So, \\(Q = \\left(\\sum_j A_j x_j\\right)^2\\). Consequently,\n\\[\\begin{align}\n\\frac{\\partial Q}{\\partial x_j} &= 2 A_j \\left(\\sum_{j} A_j x_j\\right)\n\\end{align}\\]\nThus,\n\\[\\begin{align}\n\\frac{\\partial Q}{\\partial \\vec{x}} &= 2 \\begin{bmatrix}A_1 \\\\ A_2 \\\\ \\vdots \\\\\nA_n\\end{bmatrix} \\left(\\sum_{j} A_j x_j\\right) \\\\\n&= 2 A^T A \\vec{x}\n\\end{align}\\]"
  },
  {
    "objectID": "posts/derivation-for-the-least-squares-estimate-of-beta-/index.html#least-squares-estimate",
    "href": "posts/derivation-for-the-least-squares-estimate-of-beta-/index.html#least-squares-estimate",
    "title": "Derivation of the Least Squares Estimate Beta in Linear Regression",
    "section": "Least squares estimate",
    "text": "Least squares estimate\nWe proceed with minimizing the RSS expression in equation (4). Taking derivatives with respect to the vector \\(\\hat{\\beta}\\) on both sides, and equating to zero, we have:\n\\[\\begin{align*}\n\\frac{\\partial (RSS)}{\\hat{\\beta}}&= - 2Y'X + 2X'X\\hat{\\beta} = 0 \\\\\nX^T X \\hat{\\beta} &= Y^T X \\\\\n\\hat{\\beta} &= (X^T X)^{-1} Y^T X\n\\end{align*}\\]"
  },
  {
    "objectID": "posts/crtp/index.html",
    "href": "posts/crtp/index.html",
    "title": "CRTP(Curiously recurring template pattern)",
    "section": "",
    "text": "CRTP consists in\n\nInheriting from a template class\nuse the derived class itself as a template parameter of the base class\n\nThis is what it looks like in code:\ntemplate&lt;typename DerivedType&gt;\nstruct Base{\n    /* ... */\n};\n\nstruct Derived : Base&lt;Derived&gt;{\n    /* ... */\n};\nThe purpose of doing this is to use the derived class in the base class. From the perspective of the base object, the derived object is itself but downcasted. Therefore, the base class can access the derived class by static_casting itself into the derived class.\ntemplate&lt;typename DerivedType&gt;\nclass Base{\n    public:\n    void doWorkHelper(){\n        DerivedType& derived = static_cast&lt;DerivedType&&gt;(*this);\n        // use derived\n    }\n};\n\nclass Derived : Base&lt;Derived&gt;{\n    /* ... */\n};\nOn Jonathan Boccara’s fluentcpp blog, he talks about how to avoid some slip ups. For example, let’s say you have two derived classes Bisection and NewtonRaphson. Suppose you accidentally end up inheriting from the wrong base class.\ntemplate&lt;typename Derived&gt;\nstruct Solver{\n    double solver_helper(auto func, double epsilon){\n        Derived& solverImpl = static_cast&lt;Derived&&gt;(*this);\n        solverImpl.solve();\n    }\n}\n\nstruct Bisection : Solver&lt;Bisection&gt;{\n    double solve(auto func, double epsilon){\n        std::cout &lt;&lt; \"\\n\" &lt;&lt; \"Bisection::solve()\";\n        return 0;\n    }\n};\n\nstruct NewtonRaphson : Solver&lt;Bisection&gt;{\n    double solve(auto func, double epsilon){\n        std::cout &lt;&lt; \"\\n\" &lt;&lt; \"NewtonRaphson::solve()\";\n        return 0;\n    }\n};\nTo create objects of the derived types Bisection and NewtonRaphson, the derived class constructors have to call the base class constructors. Suppose we make the constructor of the base class private and the Base&lt;DerivedType&gt; class friends with the DerivedType class. Then, Bisection will be friends with Solver&lt;Bisection&gt;, thus Bisection constructor can only invoke the private constructor of Solver&lt;Bisection&gt;. And NewtonRaphson will be friends with Solver&lt;NewtonRaphson&gt;, and it can invoke the private c’tor of only Solver&lt;NewtonRaphson, not Solver&lt;BisectionRaphson&gt;.\n#include &lt;iostream&gt;\n\ntemplate&lt;typename DerivedType&gt;\nstruct Solver{\n    private:\n    Solver() = default;\n    ~Solver() = default;\n    friend DerivedType;\n\n    public:\n    double solver_helper(auto func, double epsilon){\n        DerivedType& solverImpl = static_cast&lt;DerivedType&&gt;(*this);\n        solverImpl.solve();\n    }\n};\n\nstruct Bisection : Solver&lt;Bisection&gt;{\n    double solve(auto func, double epsilon){\n        std::cout &lt;&lt; \"\\n\" &lt;&lt; \"Bisection::solve()\";\n        return 0;\n    }\n};\n\nstruct NewtonRaphson : Solver&lt;Bisection&gt;{\n    double solve(auto func, double epsilon){\n        std::cout &lt;&lt; \"\\n\" &lt;&lt; \"NewtonRaphson::solve()\";\n        return 0;\n    }\n};\n\nint main(){\n    Bisection bisectSolver;\n    // NewtonRaphson nrSolver;   compile-error\n    return 0;\n}\nCompiler Explorer"
  },
  {
    "objectID": "posts/crtp/index.html#adding-functionality",
    "href": "posts/crtp/index.html#adding-functionality",
    "title": "CRTP(Curiously recurring template pattern)",
    "section": "Adding functionality",
    "text": "Adding functionality\nLet’s take the example of a class representing vector \\(\\mathbf{x} \\in \\mathbf{R}^n\\). It\n#include &lt;cmath&gt;\n#include &lt;iostream&gt;\n#include &lt;array&gt;\n\ntemplate&lt;typename ContainerType&gt;\nstruct Vector{\n    ContainerType m_x;\n\n    Vector() = default;\n\n    Vector(ContainerType v)\n    : m_x{v}\n    {}\n\n    auto operator+(auto& other){\n        ContainerType result;\n        size_t k{0};\n        static_assert(m_x.size() == other.m_x.size());\n        for(auto i{m_x.begin()}, j{other.m_x.begin()};i!=m_x.end();++i,++j)\n            result[k] = *i + *j;\n\n        return result;\n    }\n\n    Vector(const Vector& v)\n    : m_x{v.m_x}\n    {}\n\n    auto scalarMultiply(double k){\n        ContainerType result{m_x};\n        for(size_t i{0};i&lt;m_x.size();++i)\n            result[i] = k * m_x[i];\n        return result;\n    }\n};\n\nint main(){\n    Vector v1{std::array&lt;double,3&gt;{1,2,3}};\n    Vector v2{std::array&lt;double,3&gt;{6,7,8}};\n    Vector result = v1 + v2;\n\n    Vector v4 = v1.scalarMultiply(2.0);\n    return 0;\n}\nCompiler Explorer\nNow, imagine that we have another class, for example Complex that also needs element-wise addition and scalar multiplication. This is where CRTP comes into play. We can factor out the operator+() and scalarMultiply() functions into a separate class:\n#include &lt;cmath&gt;\n#include &lt;iostream&gt;\n#include &lt;array&gt;\n\ntemplate&lt;typename DerivedType, typename ContainerType&gt;\nstruct ComponentWiseOperations{\n    auto operator+(auto& other){\n        DerivedType& derived = static_cast&lt;DerivedType&&gt;(*this);\n        ContainerType result;\n        size_t k{0};\n\n        for(auto i{derived.m_x.begin()}, j{other.m_x.begin()};i!=derived.m_x.end();++i,++j)\n            result[k] = *i + *j;\n\n        return result;\n    }\n\n    auto scalarMultiply(double k){\n        DerivedType& derived = static_cast&lt;DerivedType&&gt;(*this);\n        ContainerType result{derived.m_x};\n        for(size_t i{0};i&lt;derived.m_x.size();++i)\n            result[i] = k * derived.m_x[i];\n        return result;\n    }\n};\nand use the CRTP to allow Vector to use it.\ntemplate&lt;typename ContainerType&gt;\nstruct Vector : public ComponentWiseOperations&lt;Vector&lt;ContainerType&gt;,ContainerType&gt;{\n    ContainerType m_x;\n\n    Vector() = default;\n\n    Vector(ContainerType v)\n    : m_x{v}\n    {}\n\n    Vector(const Vector& v)\n    : m_x{v.m_x}\n    {}\n\n    auto operator[](int n){\n        return m_x[n];\n    }\n};\nCompiler Explorer"
  },
  {
    "objectID": "posts/copy-and-swap-idiom/index.html",
    "href": "posts/copy-and-swap-idiom/index.html",
    "title": "Copy-and-swap idiom",
    "section": "",
    "text": "The canonical way to write the copy assignment operator is the following:\nstruct Point3D{\n    double x;\n    double y;\n    double z;\n\n    /* Rule of five */\n    Point3D() = default;\n    Point3D(const Point3D&) = default;\n    \n    Point3D& operator=(const Point3d& p){\n        if(this != &p){\n            // Copy member variables\n            x = p.x;\n            y = p.y;\n            z = p.z;\n        }\n\n        return (*this);\n    }\n\n    Point3D(Point3D&& ) = default;\n    Point3D& operator=(Point3D&& ) = default;\n};\nThe problem is, what if the member-wise copy assignment fails? If constructing any of the members x, y or z fails, the object we want to assign-to remains in an inconsistent state."
  },
  {
    "objectID": "posts/copy-and-swap-idiom/index.html#introduction.",
    "href": "posts/copy-and-swap-idiom/index.html#introduction.",
    "title": "Copy-and-swap idiom",
    "section": "",
    "text": "The canonical way to write the copy assignment operator is the following:\nstruct Point3D{\n    double x;\n    double y;\n    double z;\n\n    /* Rule of five */\n    Point3D() = default;\n    Point3D(const Point3D&) = default;\n    \n    Point3D& operator=(const Point3d& p){\n        if(this != &p){\n            // Copy member variables\n            x = p.x;\n            y = p.y;\n            z = p.z;\n        }\n\n        return (*this);\n    }\n\n    Point3D(Point3D&& ) = default;\n    Point3D& operator=(Point3D&& ) = default;\n};\nThe problem is, what if the member-wise copy assignment fails? If constructing any of the members x, y or z fails, the object we want to assign-to remains in an inconsistent state."
  },
  {
    "objectID": "posts/copy-and-swap-idiom/index.html#exception-safety-in-c",
    "href": "posts/copy-and-swap-idiom/index.html#exception-safety-in-c",
    "title": "Copy-and-swap idiom",
    "section": "Exception Safety in C++",
    "text": "Exception Safety in C++\nThe C++ standard library provides several levels of exception safety (in decreasing order of exception safety):\n\nNo-throw guarantee, also known as failure transparency: Operations are guaranteed to succeed and satisfy all requirements even in exceptional situations. If an exception occurs, it will be handled internally and not observed by clients.\nStrong exception safety, also known as commit or rollback semantics: Operations can fail, but failed operations are guaranteed to have no side effects, leaving the original values intact.\nBasic exception safety: Partial execution of failed operations can result in side-effects, but all invariants are preserved.\nNo exception safety: No guarantees are made."
  },
  {
    "objectID": "posts/copy-and-swap-idiom/index.html#achieving-strong-exception-safety",
    "href": "posts/copy-and-swap-idiom/index.html#achieving-strong-exception-safety",
    "title": "Copy-and-swap idiom",
    "section": "Achieving strong exception safety",
    "text": "Achieving strong exception safety\nOur copy-assignment operator provides basic exception safety at best. If we want strong-exception safety, the copy-and-swap idiom will help us achieve that.\nThe constructions might fail, but the destruction must not. Therefore, first, we should create a new object on its own and then swap it with old one. If the construction fails, the original object is not modified at all. We are on the safe-side. Then, we should switch the handles and we know that the destruction of the temporary object with the old data will not fail.\nWe need 3 things to implement the copy-and-swap idiom. We need\n\nA copy constructor.\nA swap function that swaps two objects member-by-member, without throwing an exception.\nA destructor.\n\nWe want the copy-assignment operator to look like this:\nPoint3D& Point3D::operator=(const Point3D& other){\n    Point3D temp{other};\n    swap(*this, temp);\n    return (*this);\n} // temp goes out of scope, its destructor is called\n  // any memory held by it is automatically released.\nThe swap function should swap, or in other words, exchange the content of two objects member by member. For that, we cannot use std::swap, because std::swap requires an implementation of a the copy-constructor and a copy-assignment operator. Instead, we write it by hand:\nfriend void swap(const Point3D& lhs, const Point3D& rhs){\n    using std::swap;\n    swap(lhs.x, rhs.x);\n    swap(lhs.y, rhs.y);\n    swap(lhs.z, rhs.z);\n}"
  },
  {
    "objectID": "posts/class-template-argument-deduction/index.html",
    "href": "posts/class-template-argument-deduction/index.html",
    "title": "Class Template Argument Deduction(CTAD)",
    "section": "",
    "text": "Its super-helpful to have a good low-level hang of the template argument deduction rules (more on deduction guides in another post). Essentially, since C++17, you can just declare, std::vector{1.0, 2.0, 3.0, 4.0, 5.0} - clean and nice instead of std::vector&lt;double&gt;{1.0, 2.0, 3.0, 4.0, 5.0}.\nWhen the compiler tries to deduce the template arguments, it performs matching of the type template parameters with the types of arguments used to invoke the function.\nVery succinctly, the compiler can match: - Types of the form T, T const, T volatile - Pointers T*, lvalue references T& and universal references T&& - Arrays such as T[5] and C[5][n] - Pointers to functions - Pointers to member-functions and data-members.\n#include &lt;iostream&gt;\n#include &lt;vector&gt;\n#include &lt;chrono&gt;\n#include &lt;tuple&gt;\n\nusing namespace std::chrono;\n\ntemplate&lt;typename T&gt;\nstd::ostream& operator&lt;&lt;(std::ostream& out, const std::vector&lt;T&gt; vec){\n    for(int i{0}; i &lt; vec.size(); ++ i){\n        out &lt;&lt; \"\\n[\" &lt;&lt; i &lt;&lt; \"] = \" &lt;&lt; vec[i];\n    }\n    return out;\n}\n\nstruct BondDiscountingCurve{\n    std::vector&lt;std::pair&lt;year_month_day,double&gt;&gt; discountFactorCurve;\n};\n\nstruct CustomBond{\n    std::vector&lt;double&gt; cashflows;\n    std::vector&lt;std::chrono::year_month_day&gt; cashflow_dates;\n\n    double pv(BondDiscountingCurve disc){\n        double result{0.0};\n        for(int i{0};i &lt; cashflows.size(); ++i)\n        {\n            double df = std::get&lt;1&gt;(disc.discountFactorCurve[i]);\n            result += cashflows[i] * df;\n        }\n        return result;\n    }\n};\n\nstruct Leg{\n    // A cashflow is a 4-tuple (Cashflow date, Cashflow amount, Cap, Floor)\n    using flow = std::tuple&lt;year_month_day, double, double, double&gt;;\n    std::vector&lt;flow&gt; flows;\n};\n\nstruct AssetSwap{\n    Leg bondLeg;\n    Leg fundingLeg;\n\n    Leg getBondLeg() { return bondLeg; }\n    Leg getFundingLeg() { return fundingLeg; }\n};\n\ntemplate&lt;typename T&gt;\nvoid process01(T bond){ std::cout &lt;&lt; \"T\\n\"; }\n\ntemplate&lt;typename T&gt;\nvoid process02(T const){ std::cout &lt;&lt; \"T const\\n\"; }\n\ntemplate&lt;typename T&gt;\nvoid process03(T volatile) { std::cout &lt;&lt; \"T volatile\\n\"; }\n\ntemplate&lt;typename T&gt;\nvoid process04(T*) { std::cout &lt;&lt; \"T*\\n\"; }\n\ntemplate&lt;typename T&gt;\nvoid process04(T&) { std::cout &lt;&lt; \"T&\\n\"; }\n\n// Universal reference\ntemplate&lt;typename T&gt;\nvoid process05(T&&) { std::cout &lt;&lt; \"T&&\\n\"; }\n\ntemplate&lt;typename T&gt;\nvoid process06(T[5]) { std::cout &lt;&lt; \"T[5]\\n\"; }\n\ntemplate&lt;typename T&gt;\nvoid process07(T[3][5]) { std::cout &lt;&lt; \"T[3][5]\\n\"; }\n\ntemplate&lt;typename T&gt;\nvoid process08(T(*)()) { std::cout &lt;&lt; \"T (*)()\\n\"; }\n\ntemplate&lt;typename T&gt;\nvoid process08(CustomBond (*)(T)) { std::cout &lt;&lt; \"C (*)(T)\\n\"; }\n\ntemplate&lt;typename T, typename U&gt;\nvoid process08(T(*)(U)) { std::cout &lt;&lt; \"T (*)(U)\\n\"; }\n\ntemplate&lt;typename T&gt;\nvoid process09(T(CustomBond::*)()) { std::cout &lt;&lt; \"T (C::*)()\\n\"; }\n\ntemplate&lt;typename T, typename U&gt;\nvoid process09(T(CustomBond::*)(U)) { std::cout &lt;&lt; \"T (C::*)(U)\\n\"; }\n\ntemplate&lt;typename T, typename U&gt;\nvoid process09(T(U::*)()) { std::cout &lt;&lt; \"T (U::*)()\\n\"; }\n\ntemplate&lt;typename T, typename U, typename V&gt;\nvoid process09(T(U::*)(V)) { std::cout &lt;&lt; \"T (U::*)(V)\\n\"; }\n\ntemplate&lt;typename T&gt;\nvoid process09(Leg(T::*)()) { std::cout &lt;&lt; \"C (T::*)()\\n\"; }\n\ntemplate&lt;typename T, typename U&gt;\nvoid process09(Leg(T::*)(U)) { std::cout &lt;&lt; \"C (T::*)(U)\\n\"; }\n\ntemplate&lt;typename T&gt;\nvoid process09(Leg(AssetSwap::*)(T)) { std::cout &lt;&lt; \"D (C::*)(T)\\n\"; }\n\ntemplate&lt;typename T&gt;\nvoid process10(T CustomBond::*) { std::cout &lt;&lt; \"T C::*\\n\"; }\n\ntemplate&lt;typename T&gt;\nvoid process10(Leg T::*) { std::cout &lt;&lt; \"C T::*\\n\"; }\n\ntemplate&lt;typename T, typename U&gt;\nvoid process10(T U::*) { std::cout &lt;&lt; \"T U::*\\n\"; }\n\nint main()\n{\n    CustomBond bond(\n        {0.05, 0.05, 0.05, 1.05},\n        {2024y/June/20d, 2024y/December/20d, 2025y/June/20d, 2025y/December/20d}\n    );\n\n    AssetSwap assetSwap;\n\n    process01(bond);    // T\n    process02(bond);    // T const\n    process03(bond);    // T volatile\n    process04(&bond);   // T*\n    process04(bond);    // T&\n    process05(bond);    // T&&; deduced as CustomBond& \n\n    CustomBond bondsArray[5] {};  //Create an array of custom bonds\n    process06(bondsArray);  // T[5]\n    process06(&bond);       // T[5]\n\n    CustomBond bondsByMaturityAndRating[3][5] {}; \n    process07(bondsByMaturityAndRating);    //C[5][n]\n\n    CustomBond (*funcptr1)() = nullptr;\n    CustomBond (*funcptr2)(int) = nullptr;\n    double     (*funcptr3)(int) = nullptr;\n\n    process08(funcptr1);    //T(*)()\n    process08(funcptr2);    //C(*)(T)\n    process08(funcptr3);    //T(*)(U)\n\n    double (CustomBond::*ptrmemfunc1) () = nullptr;\n    double (CustomBond::*ptrmemfunc2)(BondDiscountingCurve) = &CustomBond::pv;\n    std::vector&lt;double&gt; (Leg::*ptrmemfunc3)() = nullptr;\n    double(AssetSwap::*getLegPv)(Leg) = nullptr;\n    Leg(AssetSwap::*ptrmemfunc4)() = &AssetSwap::getFundingLeg;\n    Leg(Leg::*applyScaleToAllCoupons)(double) = nullptr;\n    Leg(AssetSwap::*applyFixedSpreadToAllCoupons)(double) = nullptr;\n    //Leg(AssetSwap::*)()\n\n    process09(ptrmemfunc1);     // T(C::*)()\n    process09(ptrmemfunc2);     // T(C::*)(U)\n    process09(ptrmemfunc3);     // T(U::*)()\n    process09(getLegPv);        // T(U::*)(V)\n    process09(ptrmemfunc4);     // C(T::*)()\n    process09(applyScaleToAllCoupons);          //C(T::*)(U)\n    process09(applyFixedSpreadToAllCoupons);    //D(C::*)(T)\n\n    process10(&CustomBond::cashflows);\n    process10(&AssetSwap::bondLeg);\n    process10(&Leg::flows);\n    return 0;\n}\nCompiler Explorer"
  },
  {
    "objectID": "posts/class-template-argument-deduction/index.html#function-template-argument-deduction.",
    "href": "posts/class-template-argument-deduction/index.html#function-template-argument-deduction.",
    "title": "Class Template Argument Deduction(CTAD)",
    "section": "",
    "text": "Its super-helpful to have a good low-level hang of the template argument deduction rules (more on deduction guides in another post). Essentially, since C++17, you can just declare, std::vector{1.0, 2.0, 3.0, 4.0, 5.0} - clean and nice instead of std::vector&lt;double&gt;{1.0, 2.0, 3.0, 4.0, 5.0}.\nWhen the compiler tries to deduce the template arguments, it performs matching of the type template parameters with the types of arguments used to invoke the function.\nVery succinctly, the compiler can match: - Types of the form T, T const, T volatile - Pointers T*, lvalue references T& and universal references T&& - Arrays such as T[5] and C[5][n] - Pointers to functions - Pointers to member-functions and data-members.\n#include &lt;iostream&gt;\n#include &lt;vector&gt;\n#include &lt;chrono&gt;\n#include &lt;tuple&gt;\n\nusing namespace std::chrono;\n\ntemplate&lt;typename T&gt;\nstd::ostream& operator&lt;&lt;(std::ostream& out, const std::vector&lt;T&gt; vec){\n    for(int i{0}; i &lt; vec.size(); ++ i){\n        out &lt;&lt; \"\\n[\" &lt;&lt; i &lt;&lt; \"] = \" &lt;&lt; vec[i];\n    }\n    return out;\n}\n\nstruct BondDiscountingCurve{\n    std::vector&lt;std::pair&lt;year_month_day,double&gt;&gt; discountFactorCurve;\n};\n\nstruct CustomBond{\n    std::vector&lt;double&gt; cashflows;\n    std::vector&lt;std::chrono::year_month_day&gt; cashflow_dates;\n\n    double pv(BondDiscountingCurve disc){\n        double result{0.0};\n        for(int i{0};i &lt; cashflows.size(); ++i)\n        {\n            double df = std::get&lt;1&gt;(disc.discountFactorCurve[i]);\n            result += cashflows[i] * df;\n        }\n        return result;\n    }\n};\n\nstruct Leg{\n    // A cashflow is a 4-tuple (Cashflow date, Cashflow amount, Cap, Floor)\n    using flow = std::tuple&lt;year_month_day, double, double, double&gt;;\n    std::vector&lt;flow&gt; flows;\n};\n\nstruct AssetSwap{\n    Leg bondLeg;\n    Leg fundingLeg;\n\n    Leg getBondLeg() { return bondLeg; }\n    Leg getFundingLeg() { return fundingLeg; }\n};\n\ntemplate&lt;typename T&gt;\nvoid process01(T bond){ std::cout &lt;&lt; \"T\\n\"; }\n\ntemplate&lt;typename T&gt;\nvoid process02(T const){ std::cout &lt;&lt; \"T const\\n\"; }\n\ntemplate&lt;typename T&gt;\nvoid process03(T volatile) { std::cout &lt;&lt; \"T volatile\\n\"; }\n\ntemplate&lt;typename T&gt;\nvoid process04(T*) { std::cout &lt;&lt; \"T*\\n\"; }\n\ntemplate&lt;typename T&gt;\nvoid process04(T&) { std::cout &lt;&lt; \"T&\\n\"; }\n\n// Universal reference\ntemplate&lt;typename T&gt;\nvoid process05(T&&) { std::cout &lt;&lt; \"T&&\\n\"; }\n\ntemplate&lt;typename T&gt;\nvoid process06(T[5]) { std::cout &lt;&lt; \"T[5]\\n\"; }\n\ntemplate&lt;typename T&gt;\nvoid process07(T[3][5]) { std::cout &lt;&lt; \"T[3][5]\\n\"; }\n\ntemplate&lt;typename T&gt;\nvoid process08(T(*)()) { std::cout &lt;&lt; \"T (*)()\\n\"; }\n\ntemplate&lt;typename T&gt;\nvoid process08(CustomBond (*)(T)) { std::cout &lt;&lt; \"C (*)(T)\\n\"; }\n\ntemplate&lt;typename T, typename U&gt;\nvoid process08(T(*)(U)) { std::cout &lt;&lt; \"T (*)(U)\\n\"; }\n\ntemplate&lt;typename T&gt;\nvoid process09(T(CustomBond::*)()) { std::cout &lt;&lt; \"T (C::*)()\\n\"; }\n\ntemplate&lt;typename T, typename U&gt;\nvoid process09(T(CustomBond::*)(U)) { std::cout &lt;&lt; \"T (C::*)(U)\\n\"; }\n\ntemplate&lt;typename T, typename U&gt;\nvoid process09(T(U::*)()) { std::cout &lt;&lt; \"T (U::*)()\\n\"; }\n\ntemplate&lt;typename T, typename U, typename V&gt;\nvoid process09(T(U::*)(V)) { std::cout &lt;&lt; \"T (U::*)(V)\\n\"; }\n\ntemplate&lt;typename T&gt;\nvoid process09(Leg(T::*)()) { std::cout &lt;&lt; \"C (T::*)()\\n\"; }\n\ntemplate&lt;typename T, typename U&gt;\nvoid process09(Leg(T::*)(U)) { std::cout &lt;&lt; \"C (T::*)(U)\\n\"; }\n\ntemplate&lt;typename T&gt;\nvoid process09(Leg(AssetSwap::*)(T)) { std::cout &lt;&lt; \"D (C::*)(T)\\n\"; }\n\ntemplate&lt;typename T&gt;\nvoid process10(T CustomBond::*) { std::cout &lt;&lt; \"T C::*\\n\"; }\n\ntemplate&lt;typename T&gt;\nvoid process10(Leg T::*) { std::cout &lt;&lt; \"C T::*\\n\"; }\n\ntemplate&lt;typename T, typename U&gt;\nvoid process10(T U::*) { std::cout &lt;&lt; \"T U::*\\n\"; }\n\nint main()\n{\n    CustomBond bond(\n        {0.05, 0.05, 0.05, 1.05},\n        {2024y/June/20d, 2024y/December/20d, 2025y/June/20d, 2025y/December/20d}\n    );\n\n    AssetSwap assetSwap;\n\n    process01(bond);    // T\n    process02(bond);    // T const\n    process03(bond);    // T volatile\n    process04(&bond);   // T*\n    process04(bond);    // T&\n    process05(bond);    // T&&; deduced as CustomBond& \n\n    CustomBond bondsArray[5] {};  //Create an array of custom bonds\n    process06(bondsArray);  // T[5]\n    process06(&bond);       // T[5]\n\n    CustomBond bondsByMaturityAndRating[3][5] {}; \n    process07(bondsByMaturityAndRating);    //C[5][n]\n\n    CustomBond (*funcptr1)() = nullptr;\n    CustomBond (*funcptr2)(int) = nullptr;\n    double     (*funcptr3)(int) = nullptr;\n\n    process08(funcptr1);    //T(*)()\n    process08(funcptr2);    //C(*)(T)\n    process08(funcptr3);    //T(*)(U)\n\n    double (CustomBond::*ptrmemfunc1) () = nullptr;\n    double (CustomBond::*ptrmemfunc2)(BondDiscountingCurve) = &CustomBond::pv;\n    std::vector&lt;double&gt; (Leg::*ptrmemfunc3)() = nullptr;\n    double(AssetSwap::*getLegPv)(Leg) = nullptr;\n    Leg(AssetSwap::*ptrmemfunc4)() = &AssetSwap::getFundingLeg;\n    Leg(Leg::*applyScaleToAllCoupons)(double) = nullptr;\n    Leg(AssetSwap::*applyFixedSpreadToAllCoupons)(double) = nullptr;\n    //Leg(AssetSwap::*)()\n\n    process09(ptrmemfunc1);     // T(C::*)()\n    process09(ptrmemfunc2);     // T(C::*)(U)\n    process09(ptrmemfunc3);     // T(U::*)()\n    process09(getLegPv);        // T(U::*)(V)\n    process09(ptrmemfunc4);     // C(T::*)()\n    process09(applyScaleToAllCoupons);          //C(T::*)(U)\n    process09(applyFixedSpreadToAllCoupons);    //D(C::*)(T)\n\n    process10(&CustomBond::cashflows);\n    process10(&AssetSwap::bondLeg);\n    process10(&Leg::flows);\n    return 0;\n}\nCompiler Explorer"
  },
  {
    "objectID": "posts/class-template-argument-deduction/index.html#ctad-class-template-argument-deduction.",
    "href": "posts/class-template-argument-deduction/index.html#ctad-class-template-argument-deduction.",
    "title": "Class Template Argument Deduction(CTAD)",
    "section": "CTAD (Class Template Argument Deduction).",
    "text": "CTAD (Class Template Argument Deduction).\n\nThe basic mechanics.\nCTAD(Class Template Argument Deduction) has \\(2\\) phases:\n\nDeduction (CTAD) - The first step is, the compiler is going to deduce the types that you didn’t write.\nInitialization - The second step is, it’s going to initialize the object.\n\nLet’s take a templated class pair, this is just a fictional class, it is not actually how std::pair&lt;&gt; looks like:\n\ntemplate&lt;typename T, typename U&gt;\nstruct pair{\n    T first;\n    U second;\n\n    pair(const T& _first, const U& _second) \n    : first(_first)\n    , second(_second)\n    {}\n\n    pair(T&& _first, U&& _second) \n    : first(std::move&lt;T&gt;(_first))\n    , second(std::move&lt;U&gt;(_second))\n    {}\n\n    //other stuff\n};\n\nThis is an oversimplification that is enough for our purposes. So, you have a templated class with two template parameters T and U and then you have a bunch of constructors. Now, we want to instantiate one of these things:\npair p1{\"OptionVolQuote\"s, 0.50};\nYou want to construct an object of type pair. The next thing the compiler sees is, pair is a template. And we didn’t specify any template arguments. Probably, you wanna do class template argument deduction.\nThe next thing happens. pair has a bunch of constructors. Probably, you wanna call one of those constructors. And this where step 1 kicks in, which is the actual Class Template Argument Deduction(CTAD).\nSo, how does the compiler figure out, what you actually want to instantiate? So, it’s going to look at those constructors. Let’s pretend for a minute, that those constructors are ordinary functions - just free-standing functions. Now, these functions use class template parameters. Let’s pretend for a moment, that those template parameters are template parameters for the function.\n\ntemplate&lt;typename T, typename U&gt;\nstruct pair{\n    T first;\n    U second;\n\n    // Imagine this to be a function template\n    template&lt;typename T, typename U&gt;  \n    pair(const T& _first, const T& _second) \n    : first(_first)\n    , second(_second)\n    {}\n\n    // Imagine this to be a function template\n    template&lt;typename T, typename U&gt;\n    pair(T&& _first, U&& _second) \n    : first(std::move&lt;T&gt;(_first))\n    , second(std::move&lt;U&gt;(_second))\n    {}\n\n    //other stuff\n};\n\nSo, this code doesn’t exist. It’s just what the compiler temporarily does for you. And it generates these template functions from the constructors and they are called the deduction candidates.\nAnd now, if we have a call like this:\n\npair p1{\"OptionVolQuote\"s, 0.50};\n\nwe know, how to deal with functions right. So, it’s going to look at these functions and apply the usual template arguments deduction and the usual overload resolution.\n\"OptionVolQuote\"s is a lvalue that gets converted to an xvalue (by the std::string() constructor) and 0.50 is a prvalue. these arguments bind to universal references. So, the pair(T&&, U&&) version is chosen by the compiler from the overload set, during overload resolution. Further, T is deduced as std::string and U is deduced as double. The compiler literally inserts them as:\n\npair&lt;std::string,double&gt; p1{\"OptionVolQuote\"s, 0.50};\n\nThen, its going to do, what it would have done, if you would have written pair&lt;std::string,double&gt;. So, now we know, that this pair is actually pair&lt;std::string,int&gt;. So, the step 1 is done.\nNow, what we can do is, we can actually instantiate the function template! That’s step 2. So, you have an actual constructor and it will be called by the run-time to create an object of pair&lt;std::string,int&gt;. And we are done.\nIf we write:\n\nconst auto s{\"5YSwapRate\"s};\nconst auto rate{0.0125};\npair p2{s,rate};\n\nHere, s and rate are identifiers, so these are glvalues and can bind to const T&. So, the compiler instantiates the first overload of the constructor as pair(const std::string&, const double&).\nThere’s no need to use std::make_pair anymore. This make_pair thing is a basically a work-around for the fact that up until C++14, you could only do this with functions. So, you had to use a function to deduce the class template arguments. So, it was kind of hacky. And now we don’t need to use that anymore.\nThe same goes for std::tuple, you can instantiate a std::tuple with a bunch of arguments and it’s going to deduce the correct types for you, so you don’t need to use std::make_tuple anymore.\n\nstd::tuple point{1.00, -1.00}\n\nLet’s look at std::vector. So, for example, if you just give it an std::initializer_list of ints, its gonna correctly deduce back to std::vector&lt;int&gt;.\n\nstd::vector v{3, 5, 7, 11, 13};\n// deduces std::vector&lt;int&gt;\n\nOf course, with std::vector, there’s a trap. std::vector has this other constructor which takes a std::size_t, and it initializes a vector with that many elements in it.\n\nstd::vector&lt;int&gt; v1{3};\n// content is {3}\n\nstd::vector&lt;int&gt; v2(3);\n// content is {0,0,0}\n\nSo, in C++14, if you write std::vector&lt;int&gt; v{3} with curly braces, it’s going to be an initializer list, so its going to initialize the vector with one int, which is 3. If you std::vector&lt;int&gt; v(3) with parenthesis, it’s going to call the size_t constructor, and you’re gonna have 3 ints, which are initialized to 0.0.\nNow, what happens if you omit the int and use class-template argument deduction? Then if you write the curlies, its going to do the deduction. But if you use round parenthesis, it says, well you’re calling the constructor that takes a size_t, so you are going to have 3 elements, but 3 elements of what type? You didn’t specify! So, you get a compiler error.\n\nstd::vector v1{3};\n// Ok- deduces std::vector&lt;int&gt;, content is {3}\n\n// std::vector v2(3);\n// Error : 3 elements of what?\n\nstd::vector has another constructor, which is really cool! Now, some real magic happens here! So, if you have a range of ints, any range, then there’s this constructor that takes a pair of iterators like begin() and end() and if you don’t specify the int, it is still going to figure out, that those iterators are iterators to int range and it is going correctly deduce std::vector&lt;int&gt; for you.\n\nstd::vector range{2, 3, 5, 7, 11};\nstd::vector v(range.begin(), range.end());\n// deduces std::vector&lt;int&gt;\n\nHow does that work? It has this constructor which looks like the below. It takes two iterators.\n\ntemplate&lt;typename T&gt;\nstruct vector\n{\n    // range c'tor\n    template&lt;typename Iter&gt;\n    vector&lt;Iter begin, Iter end&gt; { /* ... */ }\n\n    // other stuff\n};\n\nIf you have a constructor that also has template arguments, the compiler is going to pretend that this is a function and it’s going to take the template argument of the class and concatenate it with the constructor’s template argument. It’s going to put them one after the other.\n\n// This is magic code, generated by the compiler\ntemplate&lt;typename T&gt;\nstruct vector\n{\n    // range c'tor\n    template&lt;typename T, typename Iter&gt;\n    vector&lt;Iter begin, Iter end&gt; { /* ... */ }\n\n    // other stuff\n};\n\nNow, if you call it like this:\n\nstd::vector range{2, 3, 5, 7, 11};\nstd::vector v(range.begin(), range.end());\n\nit’s going to say, well okay, you are giving me two iterators, so I can deduce the type of iterators as std::vector&lt;&gt;::iterator. But, you didn’t specify T, so I still don’t know what T is. So, how is it able to figure this out?"
  },
  {
    "objectID": "posts/class-template-argument-deduction/index.html#list-initialization-has-priority",
    "href": "posts/class-template-argument-deduction/index.html#list-initialization-has-priority",
    "title": "Class Template Argument Deduction(CTAD)",
    "section": "List initialization has priority",
    "text": "List initialization has priority\nYou really have to be careful with the parenthesis and the curlies.\n\nstd::vector range{2, 3, 5, 7, 11};\nstd::vector v(range.begin(), range.end());\n// deduces std::vector&lt;int&gt;\n\nstd::vector v{range.begin(), range.end()};\n// list initialization has a priority, so the compiler deduces it\n// as std::vector&lt;std::vector&lt;int&gt;::iterator&gt;, which is \n// probably not what we want"
  },
  {
    "objectID": "posts/c++20-concepts/index.html",
    "href": "posts/c++20-concepts/index.html",
    "title": "C++20 concepts",
    "section": "",
    "text": "A class template, function template (including lambdas) may be associated with a constraint, which specifies requirements on the template arguments. This can be used to select the most appropriate function overload or template specialization.\nA concept is a named set of such constraints. A concept is ultimately a logical predicate \\(P(x)\\), evaluated at compile-time, where \\(x\\) represents template parameters. A function or class template constrained by the concept \\(P\\), will work only for template arguments that satisfy \\(P\\).\nConsider the templated function:\n#include &lt;iostream&gt;\n#include &lt;complex&gt;\n\ntemplate&lt;typename T&gt;\nT sum(T const a, T const b){\n    return (a + b);\n}\n\nint main()\n{\n    using namespace std::literals::complex_literals;\n\n    int x{2}, y{3};\n\n    sum(x, y);\n    sum(2.71828, 3.14159);\n    sum(std::complex{1.0 + 1.0i}, std::complex{1.0 - 1.0i});\n    //sum(\"42\", \"1\");       //Error cannot add two strings\n\n    return 0;\n}\nCompiler Explorer\nThe sum function returns the result of applying the binary operator+(T,T) on its arguments. The sum function only makes sense when we discuss mathematical types such as integers, floating-point numbers, std::complex&lt;double&gt;, vectors and matrices. For most types, overloading the operator + makes no sense at all.\nTherefore, just by looking at the declaration of this function, without inspecting its body, we cannot really say what this function may accept as input and what it does.\nThe intention for our sum function template is to allow passing only types that support arithmetic operations. One way is to use std::enable_if:\n#include &lt;iostream&gt;\n#include &lt;complex&gt;\n#include &lt;type_traits&gt;\n\ntemplate&lt;typename T, \n        typename = typename std::enable_if&lt;std::is_arithmetic_v&lt;T&gt;,T&gt;&gt;\nT sum(T const a, T const b){\n    return (a + b);\n}\n\nint main()\n{\n    using namespace std::literals::complex_literals;\n\n    int x{2}, y{3};\n\n    sum(x, y);\n    sum(2.71828, 3.14159);\n    sum(std::complex{1.0 + 1.0i}, std::complex{1.0 - 1.0i});\n    sum(\"42\", \"1\");    \n\n    return 0;\n}\nCompiler Explorer\nWe added an anonymous template parameter which calls the type metafunction std::enable_if&lt;C,T&gt; from the type_traits library. If the condition C evaluates to std::true_type, then std::enable_if&lt;C,T&gt; returns T. Since std::is_arithmetic_v&lt;const char*&gt; returns false_type, enable_if meta-function doesn’t return anything and the code will not build.\nWith this implementation, the code readability has decreased. The second type template parameter is difficult to read and certainly requires good TMP knowledge. The compiler error messages could also be cryptic.\nWe can improve these two aspects (code readability and compiler error messages) in C++ 20 by using constraints. These are introduced with the requires keyword as follows:\n#include &lt;iostream&gt;\n#include &lt;complex&gt;\n#include &lt;type_traits&gt;\n#include &lt;concepts&gt;\n\ntemplate&lt;typename T&gt;\nrequires std::is_arithmetic_v&lt;T&gt;\nT sum(T const a, T const b){\n    return (a + b);\n}\n\nint main()\n{\n    int x{2}, y{3};\n\n    sum(x, y);\n    sum(2.71828, 3.14159);\n    sum(\"42\", \"1\");    \n\n    return 0;\n}\nCompiler Explorer\nThe compiler error message is more meaningful and states that the constraint is_arithmetic_v&lt;const char*&gt; evaluates to false.\nThe requires keyword introduces a clause, called the requires clasuse, that defines constraints on the template parameters. A constraint is a predicate that evaluates to true or false at compile-time. The expression used in the previous example, std::is_arithmetic_v&lt;T&gt; is simply using a standard type-trait."
  },
  {
    "objectID": "posts/c++20-concepts/index.html#simple-requirements",
    "href": "posts/c++20-concepts/index.html#simple-requirements",
    "title": "C++20 concepts",
    "section": "Simple requirements",
    "text": "Simple requirements\nA simple requirement is an expression that is not evaluated but only checked for correctness. The expression must be valid for the requirement to be evaluated to true.\ntemplate&lt;typename T&gt;\nconcept arithmetic requires(T a){\n  std::is_arithmetic_v&lt;T&gt;;\n};"
  },
  {
    "objectID": "posts/c++20-concepts/index.html#type-requirements",
    "href": "posts/c++20-concepts/index.html#type-requirements",
    "title": "C++20 concepts",
    "section": "Type requirements",
    "text": "Type requirements\nType requirements are introduced with the typename keyword followed by the name of a type. We can use it verify if :\n\nA nested type exists(such as in typename T::value_type).\nA class template specialization names a type.\nAn alias template specialization names a type.\n\nLet’s code up a few examples.\ntemplate&lt;typename T&gt;\nconcept KeyValuePair = requires{\n  typename T::key_type;\n  typename T::value_type;\n}\n\ntemplate&lt;typename T, typename U&gt;\nstruct Pair{\n\n  using key_type = T;\n  using value_type = U;\n\n  key_type key;\n  value_type value;\n};\nPair satisfies the concept KeyValuePair, as it has inner types key_type and value_type. To verify this is indeed the case, we can use KeyValuePair as a compile-time metafunction.\nstatic_assert(KeyValuePair&lt;Pair&gt;);\nstatic_assert(!KeyValuePair&lt;std::pair&gt;);\nstd::pair&lt;T,U&gt; does have inner types, but they are called first_type and second_type.\n#include&lt;iostream&gt;\n#include&lt;type_traits&gt;\n#include&lt;concepts&gt;\n\ntemplate&lt;typename T&gt;\nconcept arithmetic = std::is_arithmetic_v&lt;T&gt;;\n\ntemplate&lt;arithmetic T&gt;\nstruct Point2D{\n    T x;\n    T y;\n};\n\ntemplate&lt;typename T&gt;\nusing Ref = T&;\n\ntemplate&lt;typename T&gt;\nconcept C = requires(T t){\n    typename T::inner; // required nested member name\n    typename Point2D&lt;T&gt;; // required class template specialization\n    typename Ref&lt;T&gt;;     // required alias template specialization\n};"
  },
  {
    "objectID": "posts/c++20-concepts/index.html#compound-requirements",
    "href": "posts/c++20-concepts/index.html#compound-requirements",
    "title": "C++20 concepts",
    "section": "Compound requirements",
    "text": "Compound requirements\nA compound requirement has the form:\n{expression} noexcept -&gt; return_type_requirement\nand asserts the properties of the named expression. Both the noexcept and the return_type_requirement are optional.\nLet’s code up a couple of examples.\nIn the below example, we define a NonThrowing to check if a function is marked with the noexcept specifier.\n#include&lt;iostream&gt;\n#include&lt;type_traits&gt;\n#include&lt;concepts&gt;\n\n/* \nTemplate Metaprogramming \nMariusz Bancila  \n*/\ntemplate&lt;typename T&gt;\nvoid f(T) noexcept {}\n\ntemplate&lt;typename T&gt;\nvoid g(T) {}\n\ntemplate &lt;typename F, typename... T&gt;\nconcept NonThrowing = requires(F&& func, T... t){\n  {func(t...)} noexcept;\n};\n\ntemplate&lt;typename F, typename... T&gt;\nrequires NonThrowing&lt;F,T...&gt;\nvoid invoke(F&& func, T... t)\n{\n  func(t...);\n}\n\nint main()\n{\n    invoke(f&lt;double&gt;, 100.0);\n    // invoke(g&lt;double&gt;, 100.0); //Error\n    return 0;\n}\nCompiler Explorer\nThe call invoke(g&lt;double&gt;,100.0) is not valid, because g&lt;double&gt; may throw an exception, which results in NonThrowing&lt;F,T...&gt; to evaluating as false."
  },
  {
    "objectID": "posts/c++20-concepts/index.html#nested-requirements",
    "href": "posts/c++20-concepts/index.html#nested-requirements",
    "title": "C++20 concepts",
    "section": "Nested requirements",
    "text": "Nested requirements\nA nested requirement has the form:\nrequires constraint_expression;\nIt is introduced by the requires keyword. Suppose we want to define a function that performs addition on a variable number of arguments. However, we want to impose some conditions:\n\nThere is more than one argument.\nAll arguments have the same type.\nThe expression arg1 + arg2 + ... + argn is valid.\n\nWe define a concept called HomogenousRange as follows:\n/* \nTemplate Metaprogramming \nMariusz Bancila  \n*/\ntemplate&lt;typename T, typename... Ts&gt;\ninline constexpr bool are_same_v = \n  std::conjunction_v&lt;std::is_same&lt;T,Ts&gt;...&gt;;\n\ntemplate &lt;typename... T&gt;\nconcept HomogenousRange = requires(T... t)\n{\n  (... + t);\n  requires are_same_v&lt;T...&gt;;\n  requires sizeof...(T) &gt; 1;\n}\nThis concept contains one simple requirement and two nested requirements. std::conjunction_v&lt;B1,...,BN&gt; is a type metafunction that forms the logical conjunction of conditions B1,…,BN, effectively performing a logical AND on the sequence. It works as follows:\n\nIf sizeof...(B)==0, std::true_type otherwise\nThe first type Bi in B1,...,BN for which Bi is false or BN if there is no such type.\n\nThe pattern std::is_same&lt;T,Ts&gt;... is expanded as\nstd::is_same&lt;T,T1&gt;,std::is_same&lt;T,T2&gt;,...,std::is_same&lt;T,Tn&gt;\nAkin to the logical AND operation, if all of them evaluate to std::true_type, the type metafunction std::conjunction_v&lt;B1,...,Bn returns std::true_type.\nThe simple requirement (... + t) specifies that left fold expression (adding all the arguments) is a valid operation.\nUsing this concept, we can define the variadic function template:\n#include&lt;iostream&gt;\n#include&lt;type_traits&gt;\n#include&lt;concepts&gt;\n\n/* \nTemplate Metaprogramming \nMariusz Bancila  \n*/\ntemplate&lt;typename T, typename... Ts&gt;\ninline constexpr bool are_same_v = \n  std::conjunction_v&lt;std::is_same&lt;T,Ts&gt;...&gt;;\n\ntemplate &lt;typename... T&gt;\nconcept HomogenousRange = requires(T... t)\n{\n  (... + t);\n  requires are_same_v&lt;T...&gt;;\n  requires sizeof...(T) &gt; 1;\n};\n\ntemplate&lt;typename... T&gt;\nrequires HomogenousRange&lt;T...&gt;\nstd::common_type_t&lt;T...&gt; sum(T&&... args){\n    return (... + args);\n}\n\nint main()\n{\n    auto result = sum(1, 2, 3, 4, 5);\n    return 0;\n}\nCompiler Explorer"
  },
  {
    "objectID": "posts/black-scholes-formula-for-a-european-call/index.html",
    "href": "posts/black-scholes-formula-for-a-european-call/index.html",
    "title": "Black Scholes Formula for a European Call",
    "section": "",
    "text": "The mean rate of growth of all assets under the risk-neutral measure \\(\\mathbb{Q}\\) is risk-free rate \\(r\\).\nThe stock price process has the \\(\\mathbb{Q}\\)-dynamics:\n\\[dS_t = r S_t dt + \\sigma S_t dW^{\\mathbb{Q}}(t) \\tag{1}\\]\nThe solution to this SDE is:\n\\[S(t) = S(0)\\exp \\left[ \\left(r - \\frac{\\sigma^2}{2}\\right)t + \\sigma W^{\\mathbb{Q}}(t)\\right]\\tag{2}\\]\nConsider a call option with maturity time \\(T\\). Then, the stock price at \\(T\\) is:\n\\[S(T) = S(0)\\exp \\left[ \\left(r - \\frac{\\sigma^2}{2}\\right)T + \\sigma W^{\\mathbb{Q}}(T)\\right]\\tag{3}\\]\nDenoting \\(\\tau = T - t\\), we have:\n\\[S(T) = S(t)\\exp \\left[ \\left(r - \\frac{\\sigma^2}{2}\\right)\\tau + \\sigma (W^{\\mathbb{Q}}(T)-W^{\\mathbb{Q}}(t))\\right]\\tag{4}\\]\nSince, \\(W^{\\mathbb{Q}}(T)-W^{\\mathbb{Q}}(t)\\) is a gaussian random variable with mean \\(0\\) and variance \\(\\tau = T-t\\), we can write \\(-(W^{\\mathbb{Q}}(T)-W^{\\mathbb{Q}}(t)) = \\sqrt{\\tau}Z\\), where \\(Z\\) is a standard normal random variable. Thus,\n\\[S(T) = S(t)\\exp \\left[ \\left(r - \\frac{\\sigma^2}{2}\\right)\\tau - \\sigma \\sqrt{\\tau}Z\\right]\\tag{5}\\]\nBy the risk-neutral pricing formula, the time-\\(t\\) price of the European call option is:\n\\[\n\\begin{align*}\nV(t) &= \\mathbb{E}^{\\mathbb{Q}}\\left[e^{-r(T-t)}\\max(S(T) - K,0)|\\mathcal{F}_t\\right] \\\\\n&= e^{-r(T-t)}\\mathbb{E}^{\\mathbb{Q}}\\left[\\left(S(t)\\exp \\left\\{ \\left(r - \\frac{\\sigma^2}{2}\\right)\\tau - \\sigma \\sqrt{\\tau}Z\\right\\} - K\\right)\\cdot 1_{S(T)&gt;K}|\\mathcal{F}_t\\right]\\\\\n&= e^{-r(T-t)}\\mathbb{E}^{\\mathbb{Q}}\\left[\\left(S(t)\\exp \\left\\{ \\left(r - \\frac{\\sigma^2}{2}\\right)\\tau - \\sigma \\sqrt{\\tau}Z\\right\\} - K\\right)\\cdot 1_{S_t e^{(r-\\sigma^2/2) - \\sigma\\tau Z}&gt;K}\\right]\n\\end{align*}\n\\]\nIn the last-but-one step, everything is \\(\\mathcal{F}_t\\)-measurable.\nThe domain of integration is all \\(z\\) satisfying:\n\\[\n\\begin{align*}\nS(t)\\exp \\left[ \\left(r - \\frac{\\sigma^2}{2}\\right)\\tau - \\sigma \\sqrt{\\tau}Z\\right] &&gt;  K\\\\\n\\log \\frac{S(t)}{K} + \\left(r - \\frac{\\sigma^2}{2}\\right)\\tau  &&gt; \\sigma \\sqrt{\\tau}Z\n\\end{align*}\n\\]\nDefine \\(d_{-} = \\frac{\\log \\frac{S(t)}{K} +(r-\\sigma^2/2)\\tau}{\\sigma\\sqrt{\\tau}}\\).\nThen, the region \\(D\\) is:\n\\[Z &lt; d_{-}\\]\nSo, we can expand the expectation in (6) as:\n\\[\n\\begin{align*}\nV(t) &=  \\int_{-\\infty}^{d_{-}} e^{-r\\tau}\\left(S(t)\\exp \\left\\{\\left(r - \\frac{\\sigma^2}{2}\\right)\\tau - \\sigma \\sqrt{\\tau}z \\right\\} - K\\right)d\\mathbb{Q} \\\\\n&=\\int_{-\\infty}^{d_{-}} e^{-r\\tau}\\left(S(t)\\exp \\left\\{ \\left(r - \\frac{\\sigma^2}{2}\\right)\\tau - \\sigma \\sqrt{\\tau}z\\right\\} - K\\right) f_Z^{\\mathbb{Q}}(z) dz \\\\\n&=\\frac{1}{\\sqrt{2\\pi}}\\int_{-\\infty}^{d_{-}}e^{-r\\tau} \\left(S(t)\\exp \\left\\{ \\left(r - \\frac{\\sigma^2}{2}\\right)\\tau - \\sigma \\sqrt{\\tau}z\\right\\} - K\\right) e^{-\\frac{z^2}{2}} dz\n\\\\\n&=\\frac{1}{\\sqrt{2\\pi}}\\int_{-\\infty}^{d_{-}} e^{-r\\tau}S(t)\\exp \\left\\{ \\left(r - \\frac{\\sigma^2}{2}\\right)\\tau - \\sigma \\sqrt{\\tau}z\\right\\}e^{-\\frac{z^2}{2}} dz \\\\\n&- Ke^{-r\\tau}\\cdot \\frac{1}{\\sqrt{2\\pi}}\\int_{-\\infty}^{d_{-}} e^{-\\frac{z^2}{2}} dz \\\\\n&=\\frac{1}{\\sqrt{2\\pi}}\\int_{-\\infty}^{d_{-}} e^{-r\\tau}S(t)\\exp \\left\\{ \\left(r - \\frac{\\sigma^2}{2}\\right)\\tau - \\sigma \\sqrt{\\tau}z\\right\\}e^{-\\frac{z^2}{2}} dz - Ke^{-r\\tau}\\Phi(d_{-})\\tag{7}\n\\end{align*}\n\\]\nWe have:\n\\[\n\\begin{align*}\n&\\exp \\left[-\\frac{\\sigma^2}{2}\\tau - \\sigma\\sqrt{\\tau} z - \\frac{z^2}{2}\\right]\\\\\n=&\\exp\\left[-\\frac{\\sigma^2 \\tau + 2\\sigma \\sqrt{\\tau}z + z^2}{2}\\right]\\\\\n=&\\exp\\left[-\\frac{(z+\\sigma\\sqrt{\\tau})^2}{2}\\right] \\tag{8}\n\\end{align*}\n\\]\nSubstituting (8) into (7), we get:\n\\[\n\\begin{align*}\nV(t) &=\\frac{1}{\\sqrt{2\\pi}}\\int_{-\\infty}^{d_{-}} S(t)\\exp\\left[-\\frac{(z+\\sigma\\sqrt{\\tau})^2}{2}\\right] dz - Ke^{-r\\tau}\\Phi(d_{-}) \\tag{9}\n\\end{align*}\n\\]\nPut \\(u = z + \\sigma \\sqrt{\\tau}\\). Then, \\(dz = du\\). The upper limit of integration is \\(d_{+} = d_{-} + \\sigma \\sqrt{\\tau}\\), which is:\n\\[\n\\begin{align*}\nd_{+} &=\\frac{\\log \\frac{S(t)}{K} + (r-\\sigma^2/2)\\tau}{\\sigma \\sqrt{\\tau}} + \\sigma \\sqrt{\\tau}\\\\\n&= \\frac{\\log \\frac{S(t)}{K} + (r+\\sigma^2/2)\\tau}{\\sigma \\sqrt{\\tau}}\n\\end{align*}\n\\]\nSo, the equation (9) can be written as:\n\\[\n\\begin{align*}\nV(t) &=\\frac{1}{\\sqrt{2\\pi}}\\int_{-\\infty}^{d_{+}} S(t)e^{-\\frac{u^2}{2}} du - Ke^{-r\\tau}\\Phi(d_{-}) \\\\\n&= S(t)\\Phi(d_{+}) - Ke^{-r\\tau} \\Phi(d_{-})\n\\end{align*}\n\\]"
  },
  {
    "objectID": "posts/black-scholes-formula-for-a-european-call/index.html#the-black-scholes-formula-for-a-european-call",
    "href": "posts/black-scholes-formula-for-a-european-call/index.html#the-black-scholes-formula-for-a-european-call",
    "title": "Black Scholes Formula for a European Call",
    "section": "",
    "text": "The mean rate of growth of all assets under the risk-neutral measure \\(\\mathbb{Q}\\) is risk-free rate \\(r\\).\nThe stock price process has the \\(\\mathbb{Q}\\)-dynamics:\n\\[dS_t = r S_t dt + \\sigma S_t dW^{\\mathbb{Q}}(t) \\tag{1}\\]\nThe solution to this SDE is:\n\\[S(t) = S(0)\\exp \\left[ \\left(r - \\frac{\\sigma^2}{2}\\right)t + \\sigma W^{\\mathbb{Q}}(t)\\right]\\tag{2}\\]\nConsider a call option with maturity time \\(T\\). Then, the stock price at \\(T\\) is:\n\\[S(T) = S(0)\\exp \\left[ \\left(r - \\frac{\\sigma^2}{2}\\right)T + \\sigma W^{\\mathbb{Q}}(T)\\right]\\tag{3}\\]\nDenoting \\(\\tau = T - t\\), we have:\n\\[S(T) = S(t)\\exp \\left[ \\left(r - \\frac{\\sigma^2}{2}\\right)\\tau + \\sigma (W^{\\mathbb{Q}}(T)-W^{\\mathbb{Q}}(t))\\right]\\tag{4}\\]\nSince, \\(W^{\\mathbb{Q}}(T)-W^{\\mathbb{Q}}(t)\\) is a gaussian random variable with mean \\(0\\) and variance \\(\\tau = T-t\\), we can write \\(-(W^{\\mathbb{Q}}(T)-W^{\\mathbb{Q}}(t)) = \\sqrt{\\tau}Z\\), where \\(Z\\) is a standard normal random variable. Thus,\n\\[S(T) = S(t)\\exp \\left[ \\left(r - \\frac{\\sigma^2}{2}\\right)\\tau - \\sigma \\sqrt{\\tau}Z\\right]\\tag{5}\\]\nBy the risk-neutral pricing formula, the time-\\(t\\) price of the European call option is:\n\\[\n\\begin{align*}\nV(t) &= \\mathbb{E}^{\\mathbb{Q}}\\left[e^{-r(T-t)}\\max(S(T) - K,0)|\\mathcal{F}_t\\right] \\\\\n&= e^{-r(T-t)}\\mathbb{E}^{\\mathbb{Q}}\\left[\\left(S(t)\\exp \\left\\{ \\left(r - \\frac{\\sigma^2}{2}\\right)\\tau - \\sigma \\sqrt{\\tau}Z\\right\\} - K\\right)\\cdot 1_{S(T)&gt;K}|\\mathcal{F}_t\\right]\\\\\n&= e^{-r(T-t)}\\mathbb{E}^{\\mathbb{Q}}\\left[\\left(S(t)\\exp \\left\\{ \\left(r - \\frac{\\sigma^2}{2}\\right)\\tau - \\sigma \\sqrt{\\tau}Z\\right\\} - K\\right)\\cdot 1_{S_t e^{(r-\\sigma^2/2) - \\sigma\\tau Z}&gt;K}\\right]\n\\end{align*}\n\\]\nIn the last-but-one step, everything is \\(\\mathcal{F}_t\\)-measurable.\nThe domain of integration is all \\(z\\) satisfying:\n\\[\n\\begin{align*}\nS(t)\\exp \\left[ \\left(r - \\frac{\\sigma^2}{2}\\right)\\tau - \\sigma \\sqrt{\\tau}Z\\right] &&gt;  K\\\\\n\\log \\frac{S(t)}{K} + \\left(r - \\frac{\\sigma^2}{2}\\right)\\tau  &&gt; \\sigma \\sqrt{\\tau}Z\n\\end{align*}\n\\]\nDefine \\(d_{-} = \\frac{\\log \\frac{S(t)}{K} +(r-\\sigma^2/2)\\tau}{\\sigma\\sqrt{\\tau}}\\).\nThen, the region \\(D\\) is:\n\\[Z &lt; d_{-}\\]\nSo, we can expand the expectation in (6) as:\n\\[\n\\begin{align*}\nV(t) &=  \\int_{-\\infty}^{d_{-}} e^{-r\\tau}\\left(S(t)\\exp \\left\\{\\left(r - \\frac{\\sigma^2}{2}\\right)\\tau - \\sigma \\sqrt{\\tau}z \\right\\} - K\\right)d\\mathbb{Q} \\\\\n&=\\int_{-\\infty}^{d_{-}} e^{-r\\tau}\\left(S(t)\\exp \\left\\{ \\left(r - \\frac{\\sigma^2}{2}\\right)\\tau - \\sigma \\sqrt{\\tau}z\\right\\} - K\\right) f_Z^{\\mathbb{Q}}(z) dz \\\\\n&=\\frac{1}{\\sqrt{2\\pi}}\\int_{-\\infty}^{d_{-}}e^{-r\\tau} \\left(S(t)\\exp \\left\\{ \\left(r - \\frac{\\sigma^2}{2}\\right)\\tau - \\sigma \\sqrt{\\tau}z\\right\\} - K\\right) e^{-\\frac{z^2}{2}} dz\n\\\\\n&=\\frac{1}{\\sqrt{2\\pi}}\\int_{-\\infty}^{d_{-}} e^{-r\\tau}S(t)\\exp \\left\\{ \\left(r - \\frac{\\sigma^2}{2}\\right)\\tau - \\sigma \\sqrt{\\tau}z\\right\\}e^{-\\frac{z^2}{2}} dz \\\\\n&- Ke^{-r\\tau}\\cdot \\frac{1}{\\sqrt{2\\pi}}\\int_{-\\infty}^{d_{-}} e^{-\\frac{z^2}{2}} dz \\\\\n&=\\frac{1}{\\sqrt{2\\pi}}\\int_{-\\infty}^{d_{-}} e^{-r\\tau}S(t)\\exp \\left\\{ \\left(r - \\frac{\\sigma^2}{2}\\right)\\tau - \\sigma \\sqrt{\\tau}z\\right\\}e^{-\\frac{z^2}{2}} dz - Ke^{-r\\tau}\\Phi(d_{-})\\tag{7}\n\\end{align*}\n\\]\nWe have:\n\\[\n\\begin{align*}\n&\\exp \\left[-\\frac{\\sigma^2}{2}\\tau - \\sigma\\sqrt{\\tau} z - \\frac{z^2}{2}\\right]\\\\\n=&\\exp\\left[-\\frac{\\sigma^2 \\tau + 2\\sigma \\sqrt{\\tau}z + z^2}{2}\\right]\\\\\n=&\\exp\\left[-\\frac{(z+\\sigma\\sqrt{\\tau})^2}{2}\\right] \\tag{8}\n\\end{align*}\n\\]\nSubstituting (8) into (7), we get:\n\\[\n\\begin{align*}\nV(t) &=\\frac{1}{\\sqrt{2\\pi}}\\int_{-\\infty}^{d_{-}} S(t)\\exp\\left[-\\frac{(z+\\sigma\\sqrt{\\tau})^2}{2}\\right] dz - Ke^{-r\\tau}\\Phi(d_{-}) \\tag{9}\n\\end{align*}\n\\]\nPut \\(u = z + \\sigma \\sqrt{\\tau}\\). Then, \\(dz = du\\). The upper limit of integration is \\(d_{+} = d_{-} + \\sigma \\sqrt{\\tau}\\), which is:\n\\[\n\\begin{align*}\nd_{+} &=\\frac{\\log \\frac{S(t)}{K} + (r-\\sigma^2/2)\\tau}{\\sigma \\sqrt{\\tau}} + \\sigma \\sqrt{\\tau}\\\\\n&= \\frac{\\log \\frac{S(t)}{K} + (r+\\sigma^2/2)\\tau}{\\sigma \\sqrt{\\tau}}\n\\end{align*}\n\\]\nSo, the equation (9) can be written as:\n\\[\n\\begin{align*}\nV(t) &=\\frac{1}{\\sqrt{2\\pi}}\\int_{-\\infty}^{d_{+}} S(t)e^{-\\frac{u^2}{2}} du - Ke^{-r\\tau}\\Phi(d_{-}) \\\\\n&= S(t)\\Phi(d_{+}) - Ke^{-r\\tau} \\Phi(d_{-})\n\\end{align*}\n\\]"
  },
  {
    "objectID": "posts/black-scholes-formula-for-a-european-call/index.html#appendix",
    "href": "posts/black-scholes-formula-for-a-european-call/index.html#appendix",
    "title": "Black Scholes Formula for a European Call",
    "section": "Appendix",
    "text": "Appendix\nLemma. The discounted stock-price process \\((D(t)S(t),t\\geq 0)\\) is a \\(\\mathbb{Q}\\)-martingale.\nSuppose we have a risk-free money-market account with the dynamics:\n\\[dM(t) = rM(t)dt\\]\nand the dynamics of the stock-price process is:\n\\[dS(t) = \\mu S(t) dt + \\sigma S(t) dW^\\mathbb{P}(t)\\]\nThus, the discounting process is:\n\\[dD(t) = -rD(t)dt\\]\nwhere the instantaneous interest rate \\(r\\) is a constant.\nBy Ito’s product rule:\n\\[\n\\begin{align*}\nd(D(t)S(t)) &= dD(t) S(t) + D(t)dS(t)\\\\\n&= -rD(t)S(t)dt + D(t)(\\mu S(t) dt + \\sigma S(t)dW^\\mathbb{P}(t))\\\\\n&= D(t)S(t)((\\mu - r)dt + \\sigma dW^\\mathbb{P}(t))\\\\\n\\end{align*}\n\\]\nWe are interested to write:\n\\[\n\\begin{align*}\nd(D(t)S(t)) &= D(t)S(t)\\sigma dW^\\mathbb{Q}(t)\n\\end{align*}\n\\]\nComparing the right hand sides, we have: \\[\n\\begin{align*}\n\\sigma dW^\\mathbb{Q}(t) &= (\\mu - r)dt + \\sigma dW^\\mathbb{P}(t)\n\\end{align*}\n\\]\nLet’s define:\n\\[dW^\\mathbb{Q}(t) = \\theta dt + dW^\\mathbb{P}(t)\\]\nwhere \\(\\theta = (\\mu - r)/\\sigma\\) and the Radon-Nikodym derivative \\(Z\\) as:\n\\[Z = \\exp\\left[-\\int_0^T \\theta dW^\\mathbb{P}(u) - \\frac{1}{2}\\int_0^T \\theta^2 du \\right]\\]\nBy the Girsanov theorem, \\(W^\\mathbb{Q}(t)\\) is a \\(\\mathbb{Q}\\)-standard brownian motion. Hence, we can write:\n\\[\n\\begin{align*}\nd(D(t)S(t)) &= D(t)S(t)\\sigma dW^\\mathbb{Q}(t)\n\\end{align*}\n\\]\nSince the Ito integral is a martingale, \\(D(t)S(t)\\) is a \\(\\mathbb{Q}\\)-martingale. This closes the proof.\nClaim. The \\(\\mathbb{Q}\\)-dynamics of \\(S_t\\) satisfy :\n\\[dS(t) = rS(t) dt + \\sigma S(t) dW^{\\mathbb{Q}}(t)\\]\nProof.\nWe have:\n\\[\n\\begin{align*}dS(t) &= d(S(t)D(t)M(t))\\\\\n&= d(S(t)D(t))M(t) + S(t)D(t)dM(t)\\\\\n&= D(t)M(t) S(t)\\sigma dW^\\mathbb{Q}(t) + S(t)D(t)r M(t)dt\\\\\n&= S(t)(rdt + \\sigma dW^\\mathbb{Q}(t))\n\\end{align*}\n\\]\nWe can easily solve this linear SDE; its solution is:\n\\[S(t) = S(0)\\exp\\left[\\left(\\mu - \\frac{\\sigma^2}{2}\\right)dt + \\sigma W^\\mathbb{Q}(t)\\right]\\]"
  },
  {
    "objectID": "posts/SFINAE/index.html",
    "href": "posts/SFINAE/index.html",
    "title": "SFINAE",
    "section": "",
    "text": "When we write templates, we sometimes need to restrict the template arguments. For instance, we have a function that should work for any numeric type, therefore integral and floating point, but should not work with anything else. Or we may have a class template that should only accept trivial types for an argument.\nThere are also cases where we have overloaded function templates that should work with some types only. For instance, one overload should work with integral types and the other for floating-point types only. There are different ways to achieve that goal.\nType traits are, however, involved in one way or the other. The first one that will be discussed in this chapter is called SFINAE. C++20 concepts are an approach superior to SFINAE, that I am going to blog about in another post.\nSFINAE stands for Substitution Failure Is Not An Error. When the compiler encounters the use of a function template, it substitutes the arguments in order to instantiate the template. If an error occurs at this point, it is not regarded as ill-informed code, only as a deduction failure. The function is removed from the overload set instead of causing an error. Only if there is no match in the overload set does an error occur.\n\n\nIn C++11, there are free-standing functions std::begin() and std::end() that return iterators to the first and the one-past-last elements of the container. These functions also work with arrays. How might we implement begin() to work both with STL containers and arrays?\nWe need two overloads of the function template:\n#include &lt;array&gt;\n#include &lt;iterator&gt;\n#include &lt;iostream&gt;\n\ntemplate&lt;typename T&gt;\nauto beginIter(T& c) { return c.begin(); }      //[1]\n\ntemplate&lt;typename T, std::size_t N&gt;\nT* beginIter(T(&arr)[N]){ return arr; }         //[2]\nThe first overload calls the member function begin() and returns the value. Therefore, this overload is restricted to types that have a member function begin(), otherwise a compiler error would occur. The second overload simply returns a pointer to the first element of the array. This is restricted to array types; anything else would produce a compiler error.\nWe can use these overloads as follows:\nint main()\n{\n    std::array&lt;int, 5&gt; arr1{1, 2, 3, 4, 5};     \n    std::cout &lt;&lt; *beginIter(arr1) &lt;&lt; \"\\n\";          //[3] prints 1\n\n    int arr2[] {5, 4, 3, 2, 1};\n    std::cout &lt;&lt; *beginIter(arr2) &lt;&lt; \"\\n\";          //[5] prints 5\n}\nCompiler Explorer\nIf you compile this piece of code, no error, not even a warning occurs! The reason for that is SFINAE. When resolving the call to beginIter(arr1), substituting std::array&lt;int,5&gt; to the first overload at [1] succeeds, but the substitution for the second (at [2]) fails. Instead of issuing an error at this point, the compiler just ignores it, so it builds an overload set with a single instantiation, and therefore it can find a match for the invocation. Similarly, when resolving the call to beginIter(arr2), the substitution of int[5] for the first overload fails and is ignored, but it succeeds for the second and is added to the overload set, eventually finding a good match for the invocation. Therefore, both calls can be successfully made. Should one of the two overloads not be present, either beginIter(arr1) or beginIter(arr2) would fail to match the function template and a compiler error would occur.\n\n\n\nThere are two categories of type traits in C++:\n\nType traits that enable us to query properties of the type at compile-time.\nType traits that enable us to perform type transformations at compile-time(such as adding or removing the const qualifier, or adding or removing pointer or reference from a type). These type traits are also called meta-functions.\n\nOne important type trait is std::enable_if. This is used to enable SFINAE and remove candidates from a function’s overload set. Recall that, enable_if&lt;B,T&gt; is a type metafunction. If B is true, it returns T.\ntemplate&lt;bool B, typename T=void&gt;\nstruct enable_if{};\n\ntemplate&lt;typename t&gt;\nstruct enable_if&lt;true,T&gt;{\n    using type = T;\n};\nRecall, the example in my blog post on type traits on the creating a serializer that exposes a uniform API to prirint an object to the output stream. To achieve that, we coded up a uses_write type trait.\nWith std::enable_if, we can implement that idea in a simple way:\ntemplate&lt;typename T,\n            typename std::enable_if&lt;\n                uses_write&lt;T&gt;::value&gt;::type* = nullptr&gt;\n\nvoid serialize(std::ostream& os, T const & value){\n    value.write(os);\n}\n\ntemplate&lt;typename T,\n            typename std::enable_if&lt;\n                !uses_write&lt;T&gt;::value&gt;::type* = nullptr&gt;\n\nvoid serialize(std::ostream& os, T const & value){\n    os &lt;&lt; value;\n}\nThere are two overloaded function templates in this implementation. They both have two template parameters. The first parameter is the usual template type parameter T. The second is an anonymous non-type template parameter of a pointer type that also has the default value nullptr. We use std::enable_if to define the member called type only if the uses_write metafunction evaluates to true. Therefore, for classes that have the member function write, the substitution succeeds for the first overload but fails for the second overload, because typename* = nullptr is not a valid parameter. For classses for which the output stream operator &lt;&lt; is overload, we have the opposite situation.\nThe std::enable_if metafunction can be used in several scenarios:\n\nTo define a template parameter that has a default argument.\nTo define a function parameter that has a default argument.\nTo specify the return type of a function.\n\nLet’s use std::enable_if to define a function parameter with a default argument. For instance, we can write:\ntemplate&lt;typename T&gt;\nvoid serialize(\n    std::ostream& os, \n    T const & value,\n    typename std::enable_if&lt;use_write&lt;T&gt;::value&gt;::type* value == nullptr\n){\n    value.write(os);\n}\n\ntemplate&lt;typename T&gt;\nvoid serialize(\n    std::ostream& os, \n    T const & value,\n    typename std::enable_if&lt;!use_write&lt;T&gt;::value&gt;::type* value == nullptr\n){\n    os &lt;&lt; value;\n}\nWe basically moved the parameter from the template parameter list to the function parameter list. The third alternative is to use std::enable_if&lt;T&gt; to wrap the return type of the function. This implementation is only slightly different(the default argument does not make sense for a return type.) Here is how it looks:\ntemplate&lt;typename T&gt;\ntypename std::enable_if&lt;use_write&lt;T&gt;::value&gt;::type serialize(\n    std::ostream& os,\n    T const & value\n){\n    value.write(os);\n}\n\ntemplate&lt;typename T&gt;\ntypename std::enable_if&lt;!use_write&lt;T&gt;::value&gt;::type serialize(\n    std::ostream& os,\n    T const & value\n){\n    os &lt;&lt; value;\n}\nIn all these examples, the enable_if type trait was used to enable SFINAE during the overload resolution for the function templates. This type metafunction can also be used to restrict instantiations of class templates. In the following example, we have a class called integral_wrapper that is supposed to be instantiated only with integral types, and a class called floating_wrapper that is supposed to be instantiated only with only with floating point types:\n#include &lt;type_traits&gt;\n\ntemplate&lt;\n    typename T,\n    typename=std::enable_if&lt;std::is_integral_v&lt;T&gt;&gt;::type&gt;\nstruct integral_wrapper{\n    T value;\n};\n\ntemplate&lt;\n    typename T,\n    typename=std::enable_if&lt;std::is_floating_point_v&lt;T&gt;&gt;::type&gt;\nstruct floating_point_wrapper{\n    T value;\n};\nBoth these templates have two type template parameters. The first one is called T, but the second one is anonymous and has a default argument. The value of this argument is defined or not with the help of the std::enable_if&lt;B,T&gt; type metafunction, based on the value of a boolean expression.\nWe can use the wrapper class templates as follows:\nint main()\n{\n    integral_wrapper w1{ 42 };          //OK\n    //integral_wrapper w2{ 42.0 };      //error\n    //integral_wrapper w3{ \"42\" };      //error\n\n    //floating_point_wrapper w4{ 42 };  //error\n    floating_point_wrapper w5{ 42.0 };  //OK\n    //floating_point_wrapper w6{ \"42\" };//error\n    return 0;\n}\nCompiler Explorer\n\n\n\nThe C++17 feature if constexpr is a compile-time version of the if statement and makes SFINAE much easier. It helps replace complex template code with simpler versions. Let’s look at a C++17 implementation of the serialize function that can uniformly serialize both widgets and gadgets:\ntemplate&lt;typename T&gt;\nvoid serialize(std::ostream& os, T const & value){\n    if constexpr (uses_write&lt;T&gt;::value){\n        value.write(os);\n    }else{\n        os &lt;&lt; value;\n    }\n}\nconstexpr if enables us to discard a branch, at compile-time, based on the value of the expression. In our example, when the uses_write_v variable is true, the else branch is discarded, and the body of the first branch is retained. Otherwise, the opposite occurs. We end up with following specializations for the widget and gadget classes:\ntemplate&lt;&gt;\nvoid serialize&lt;widget&gt;(std::ostream&& os, widget const & value){\n    if constexpr(true)\n    {\n        value.write(os);\n    }\n}\n\nvoid serialize&lt;widget&gt;(std::ostream&& os, widget const & value){\n    if constexpr(false)\n    {\n        os &lt;&lt; write;\n    }\n}"
  },
  {
    "objectID": "posts/SFINAE/index.html#an-example-of-implementing-the-begin-method",
    "href": "posts/SFINAE/index.html#an-example-of-implementing-the-begin-method",
    "title": "SFINAE",
    "section": "",
    "text": "In C++11, there are free-standing functions std::begin() and std::end() that return iterators to the first and the one-past-last elements of the container. These functions also work with arrays. How might we implement begin() to work both with STL containers and arrays?\nWe need two overloads of the function template:\n#include &lt;array&gt;\n#include &lt;iterator&gt;\n#include &lt;iostream&gt;\n\ntemplate&lt;typename T&gt;\nauto beginIter(T& c) { return c.begin(); }      //[1]\n\ntemplate&lt;typename T, std::size_t N&gt;\nT* beginIter(T(&arr)[N]){ return arr; }         //[2]\nThe first overload calls the member function begin() and returns the value. Therefore, this overload is restricted to types that have a member function begin(), otherwise a compiler error would occur. The second overload simply returns a pointer to the first element of the array. This is restricted to array types; anything else would produce a compiler error.\nWe can use these overloads as follows:\nint main()\n{\n    std::array&lt;int, 5&gt; arr1{1, 2, 3, 4, 5};     \n    std::cout &lt;&lt; *beginIter(arr1) &lt;&lt; \"\\n\";          //[3] prints 1\n\n    int arr2[] {5, 4, 3, 2, 1};\n    std::cout &lt;&lt; *beginIter(arr2) &lt;&lt; \"\\n\";          //[5] prints 5\n}\nCompiler Explorer\nIf you compile this piece of code, no error, not even a warning occurs! The reason for that is SFINAE. When resolving the call to beginIter(arr1), substituting std::array&lt;int,5&gt; to the first overload at [1] succeeds, but the substitution for the second (at [2]) fails. Instead of issuing an error at this point, the compiler just ignores it, so it builds an overload set with a single instantiation, and therefore it can find a match for the invocation. Similarly, when resolving the call to beginIter(arr2), the substitution of int[5] for the first overload fails and is ignored, but it succeeds for the second and is added to the overload set, eventually finding a good match for the invocation. Therefore, both calls can be successfully made. Should one of the two overloads not be present, either beginIter(arr1) or beginIter(arr2) would fail to match the function template and a compiler error would occur."
  },
  {
    "objectID": "posts/SFINAE/index.html#enabling-sfinae-with-the-enable_if-type-trait",
    "href": "posts/SFINAE/index.html#enabling-sfinae-with-the-enable_if-type-trait",
    "title": "SFINAE",
    "section": "",
    "text": "There are two categories of type traits in C++:\n\nType traits that enable us to query properties of the type at compile-time.\nType traits that enable us to perform type transformations at compile-time(such as adding or removing the const qualifier, or adding or removing pointer or reference from a type). These type traits are also called meta-functions.\n\nOne important type trait is std::enable_if. This is used to enable SFINAE and remove candidates from a function’s overload set. Recall that, enable_if&lt;B,T&gt; is a type metafunction. If B is true, it returns T.\ntemplate&lt;bool B, typename T=void&gt;\nstruct enable_if{};\n\ntemplate&lt;typename t&gt;\nstruct enable_if&lt;true,T&gt;{\n    using type = T;\n};\nRecall, the example in my blog post on type traits on the creating a serializer that exposes a uniform API to prirint an object to the output stream. To achieve that, we coded up a uses_write type trait.\nWith std::enable_if, we can implement that idea in a simple way:\ntemplate&lt;typename T,\n            typename std::enable_if&lt;\n                uses_write&lt;T&gt;::value&gt;::type* = nullptr&gt;\n\nvoid serialize(std::ostream& os, T const & value){\n    value.write(os);\n}\n\ntemplate&lt;typename T,\n            typename std::enable_if&lt;\n                !uses_write&lt;T&gt;::value&gt;::type* = nullptr&gt;\n\nvoid serialize(std::ostream& os, T const & value){\n    os &lt;&lt; value;\n}\nThere are two overloaded function templates in this implementation. They both have two template parameters. The first parameter is the usual template type parameter T. The second is an anonymous non-type template parameter of a pointer type that also has the default value nullptr. We use std::enable_if to define the member called type only if the uses_write metafunction evaluates to true. Therefore, for classes that have the member function write, the substitution succeeds for the first overload but fails for the second overload, because typename* = nullptr is not a valid parameter. For classses for which the output stream operator &lt;&lt; is overload, we have the opposite situation.\nThe std::enable_if metafunction can be used in several scenarios:\n\nTo define a template parameter that has a default argument.\nTo define a function parameter that has a default argument.\nTo specify the return type of a function.\n\nLet’s use std::enable_if to define a function parameter with a default argument. For instance, we can write:\ntemplate&lt;typename T&gt;\nvoid serialize(\n    std::ostream& os, \n    T const & value,\n    typename std::enable_if&lt;use_write&lt;T&gt;::value&gt;::type* value == nullptr\n){\n    value.write(os);\n}\n\ntemplate&lt;typename T&gt;\nvoid serialize(\n    std::ostream& os, \n    T const & value,\n    typename std::enable_if&lt;!use_write&lt;T&gt;::value&gt;::type* value == nullptr\n){\n    os &lt;&lt; value;\n}\nWe basically moved the parameter from the template parameter list to the function parameter list. The third alternative is to use std::enable_if&lt;T&gt; to wrap the return type of the function. This implementation is only slightly different(the default argument does not make sense for a return type.) Here is how it looks:\ntemplate&lt;typename T&gt;\ntypename std::enable_if&lt;use_write&lt;T&gt;::value&gt;::type serialize(\n    std::ostream& os,\n    T const & value\n){\n    value.write(os);\n}\n\ntemplate&lt;typename T&gt;\ntypename std::enable_if&lt;!use_write&lt;T&gt;::value&gt;::type serialize(\n    std::ostream& os,\n    T const & value\n){\n    os &lt;&lt; value;\n}\nIn all these examples, the enable_if type trait was used to enable SFINAE during the overload resolution for the function templates. This type metafunction can also be used to restrict instantiations of class templates. In the following example, we have a class called integral_wrapper that is supposed to be instantiated only with integral types, and a class called floating_wrapper that is supposed to be instantiated only with only with floating point types:\n#include &lt;type_traits&gt;\n\ntemplate&lt;\n    typename T,\n    typename=std::enable_if&lt;std::is_integral_v&lt;T&gt;&gt;::type&gt;\nstruct integral_wrapper{\n    T value;\n};\n\ntemplate&lt;\n    typename T,\n    typename=std::enable_if&lt;std::is_floating_point_v&lt;T&gt;&gt;::type&gt;\nstruct floating_point_wrapper{\n    T value;\n};\nBoth these templates have two type template parameters. The first one is called T, but the second one is anonymous and has a default argument. The value of this argument is defined or not with the help of the std::enable_if&lt;B,T&gt; type metafunction, based on the value of a boolean expression.\nWe can use the wrapper class templates as follows:\nint main()\n{\n    integral_wrapper w1{ 42 };          //OK\n    //integral_wrapper w2{ 42.0 };      //error\n    //integral_wrapper w3{ \"42\" };      //error\n\n    //floating_point_wrapper w4{ 42 };  //error\n    floating_point_wrapper w5{ 42.0 };  //OK\n    //floating_point_wrapper w6{ \"42\" };//error\n    return 0;\n}\nCompiler Explorer"
  },
  {
    "objectID": "posts/SFINAE/index.html#c17-constexpr-if",
    "href": "posts/SFINAE/index.html#c17-constexpr-if",
    "title": "SFINAE",
    "section": "",
    "text": "The C++17 feature if constexpr is a compile-time version of the if statement and makes SFINAE much easier. It helps replace complex template code with simpler versions. Let’s look at a C++17 implementation of the serialize function that can uniformly serialize both widgets and gadgets:\ntemplate&lt;typename T&gt;\nvoid serialize(std::ostream& os, T const & value){\n    if constexpr (uses_write&lt;T&gt;::value){\n        value.write(os);\n    }else{\n        os &lt;&lt; value;\n    }\n}\nconstexpr if enables us to discard a branch, at compile-time, based on the value of the expression. In our example, when the uses_write_v variable is true, the else branch is discarded, and the body of the first branch is retained. Otherwise, the opposite occurs. We end up with following specializations for the widget and gadget classes:\ntemplate&lt;&gt;\nvoid serialize&lt;widget&gt;(std::ostream&& os, widget const & value){\n    if constexpr(true)\n    {\n        value.write(os);\n    }\n}\n\nvoid serialize&lt;widget&gt;(std::ostream&& os, widget const & value){\n    if constexpr(false)\n    {\n        os &lt;&lt; write;\n    }\n}"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "quantdev.blog",
    "section": "",
    "text": "Hi there! I’m Quasar. I am a software engineer turned quantitative analyst.\nThis blog is a no-fluff collection of C++ code snippets, tips, puzzles and C++ projects. Here, I have also documented my deep-dives on concurrency, performance and computer architecture topics.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nMove semantics and perfect forwarding\n\n\n\nC++\n\n\n\n\n\n\n\nQuasar\n\n\nDec 23, 2025\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nstd::variant\n\n\n\nC++\n\n\n\n\n\n\n\nQuasar\n\n\nDec 23, 2025\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nauto type deduction rules\n\n\n\nC++\n\n\n\n\n\n\n\nQuasar\n\n\nDec 21, 2025\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nC++ Type erasure\n\n\n\nC++\n\n\n\n\n\n\n\nQuasar\n\n\nDec 18, 2025\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nImplementing string\n\n\n\nC++\n\n\n\n\n\n\n\nQuasar\n\n\nDec 18, 2025\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nImplementing LRU Cache\n\n\n\nC++\n\n\n\n\n\n\n\nQuasar\n\n\nDec 17, 2025\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nHow libstdc++ std::unordered_map is implemented?\n\n\n\nC++\n\n\n\n\n\n\n\nQuasar\n\n\nDec 16, 2025\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nImplementing vector&lt;T&gt;\n\n\n\nC++\n\n\n\n\n\n\n\nQuasar\n\n\nDec 15, 2025\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nLambda Functions\n\n\n\nC++\n\n\n\n\n\n\n\nQuasar\n\n\nDec 13, 2025\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nFloating-point numbers\n\n\n\nC++\n\n\n\n\n\n\n\nQuasar\n\n\nDec 13, 2025\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nObjects, Pointers and References\n\n\n\nC++\n\n\n\n\n\n\n\nQuasar\n\n\nDec 12, 2025\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nThe C++ casts\n\n\n\nC++\n\n\n\n\n\n\n\nQuasar\n\n\nDec 12, 2025\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nLock-free SPSC Queue\n\n\n\nC++\n\n\n\n\n\n\n\nQuasar\n\n\nDec 5, 2025\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nPymalloc - Down the rabit hole\n\n\n\nPython\n\n\n\n\n\n\n\nQuasar\n\n\nNov 27, 2025\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nGenerators, iterators and asynchronous programming\n\n\n\nPython\n\n\n\n\n\n\n\nQuasar\n\n\nNov 24, 2025\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nPythonic code\n\n\n\nPython\n\n\n\n\n\n\n\nQuasar\n\n\nNov 21, 2025\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCreating a tiny C++ Task Library\n\n\n\nC++\n\n\n\n\n\n\n\nQuasar\n\n\nNov 18, 2025\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nA crash course in Rust - I\n\n\n\nRust\n\n\n\n\n\n\n\nQuasar\n\n\nNov 17, 2025\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nMemory Barriers\n\n\n\nConcurrency\n\n\n\n\n\n\n\nQuasar\n\n\nNov 16, 2025\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCoroutines\n\n\n\nC++\n\n\n\n\n\n\n\nQuasar\n\n\nNov 12, 2025\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nAAD(Adjoint Algorithmic Differentiation)\n\n\n\nFin Math\n\n\n\n\n\n\n\nQuasar\n\n\nOct 23, 2025\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nContinuous probability puzzles\n\n\n\nQuant Puzzles\n\n\n\n\n\n\n\nQuasar\n\n\nOct 22, 2025\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nDiscrete probability and counting puzzles\n\n\n\nQuant Puzzles\n\n\n\n\n\n\n\nQuasar\n\n\nOct 22, 2025\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nUniformly sampling from the unit disk\n\n\n\nQuant Puzzles\n\n\n\n\n\n\n\nQuasar\n\n\nOct 21, 2025\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nGaussian Processes\n\n\n\nFin Math\n\n\n\n\n\n\n\nQuasar\n\n\nOct 19, 2025\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nA short note on the Dupire PDE\n\n\n\nFin Math\n\n\n\n\n\n\n\nQuasar\n\n\nOct 1, 2025\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nChallenging exercises in Template Metaprogramming\n\n\n\nC++\n\n\n\n\n\n\n\nQuasar\n\n\nAug 23, 2025\n\n\n\n\n\n\n\n\n\n\n\n\n\n\ndeducing this\n\n\n\nC++\n\n\n\n\n\n\n\nQuasar\n\n\nJun 20, 2025\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nStorage Durations in C++\n\n\n\nC++\n\n\n\n\n\n\n\nQuasar\n\n\nMay 22, 2025\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nThe virtual keyword\n\n\n\nC++\n\n\n\n\n\n\n\nQuasar\n\n\nMay 22, 2025\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nQuanto Options\n\n\n\nFin Math\n\n\n\n\n\n\n\nQuasar\n\n\nMay 16, 2025\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCustom iterators and Iterator concepts\n\n\n\nC++\n\n\n\n\n\n\n\nQuasar\n\n\nMay 5, 2025\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nA note on make_shared&lt;T&gt;(Args&&...) and make_unique&lt;T&gt;(Args&&...)\n\n\n\nC++\n\n\n\n\n\n\n\nQuasar\n\n\nMay 4, 2025\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nunique_ptr - A custom implementation\n\n\n\nC++\n\n\n\n\n\n\n\nQuasar\n\n\nApr 21, 2025\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nImplementing shared_ptr&lt;T&gt;\n\n\n\nC++\n\n\n\n\n\n\n\nQuasar\n\n\nApr 21, 2025\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nnumpy and pandas CheatSheet\n\n\n\nPython\n\n\n\n\n\n\n\nQuasar\n\n\nMar 6, 2025\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nDIY asyncio\n\n\n\nPython\n\n\n\n\n\n\n\nQuasar\n\n\nFeb 28, 2025\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nA thread-safe queue implementation\n\n\n\nC++\n\n\n\n\n\n\n\nQuasar\n\n\nFeb 23, 2025\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nThread-Safe Stack Implementation\n\n\n\nC++\n\n\n\n\n\n\n\nQuasar\n\n\nFeb 23, 2025\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nMargrabe’s formula\n\n\n\nFin Math\n\n\n\n\n\n\n\nQuasar\n\n\nFeb 22, 2025\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nLevenberg-Marquardt Algorithm\n\n\n\nNumerics\n\n\n\n\n\n\n\nQuasar\n\n\nFeb 1, 2025\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nC++ Ranges\n\n\n\nC++\n\n\n\n\n\n\n\nQuasar\n\n\nJan 31, 2025\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCollateralized Discounting\n\n\n\nFin Math\n\n\n\n\n\n\n\nQuasar\n\n\nJan 27, 2025\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nIRS, Caps, Floors and Swaptions\n\n\n\nFin Math\n\n\n\n\n\n\n\nQuasar\n\n\nJan 24, 2025\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCRTP(Curiously recurring template pattern)\n\n\n\nC++\n\n\n\n\n\n\n\nQuasar\n\n\nDec 28, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nRule of Five\n\n\n\nC++\n\n\n\n\n\n\n\nQuasar\n\n\nDec 27, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCurrying and partial function application\n\n\n\nC++\n\n\n\n\n\n\n\nQuasar\n\n\nDec 11, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCopy-and-swap idiom\n\n\n\nC++\n\n\n\n\n\n\n\nQuasar\n\n\nDec 10, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nSFINAE\n\n\n\nC++\n\n\n\n\n\n\n\nQuasar\n\n\nDec 7, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nC++20 concepts\n\n\n\nC++\n\n\n\n\n\n\n\nQuasar\n\n\nDec 7, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nA gentle introduction to the Girsanov Theorem - Back to the basics\n\n\n\nFin Math\n\n\n\n\n\n\n\nQuasar\n\n\nDec 1, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nFun with numeraires!\n\n\n\nFin Math\n\n\n\n\n\n\n\nQuasar\n\n\nNov 28, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nClass Template Argument Deduction(CTAD)\n\n\n\nC++\n\n\n\n\n\n\n\nQuasar\n\n\nNov 25, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nType Traits 101\n\n\n\nC++\n\n\n\n\n\n\n\nQuasar\n\n\nNov 25, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nTridiagonal Systems\n\n\n\nNumerics\n\n\n\n\n\n\n\nQuasar\n\n\nNov 15, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nInterpolation and Approximation\n\n\n\nNumerics\n\n\n\n\n\n\n\nQuasar\n\n\nNov 13, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nNumerical Integration\n\n\n\nNumerics\n\n\n\n\n\n\n\nQuasar\n\n\nNov 11, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nTemplate programming\n\n\n\nC++\n\n\n\n\n\n\n\nQuasar\n\n\nNov 10, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nNorms\n\n\n\nNumerics\n\n\n\n\n\n\n\nQuasar\n\n\nJul 25, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nSingular Value Decomposition(SVD)\n\n\n\nLinear Algebra\n\n\n\n\n\n\n\nQuasar\n\n\nJul 24, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nEigenthingies and Diagonalizability\n\n\n\nLinear Algebra\n\n\n\n\n\n\n\nQuasar\n\n\nJul 23, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nThe Spectral Theorem\n\n\n\nLinear Algebra\n\n\n\n\n\n\n\nQuasar\n\n\nJul 23, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nIto Calculus\n\n\n\nFin Math\n\n\n\n\n\n\n\nQuasar\n\n\nJul 12, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nMartingales\n\n\n\nFin Math\n\n\n\n\n\n\n\nQuasar\n\n\nJul 12, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nThe Markov Property\n\n\n\nFin Math\n\n\n\n\n\n\n\nQuasar\n\n\nJul 12, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nIto Processes and Stochastic Differential Equations\n\n\n\nFin Math\n\n\n\n\n\n\n\nQuasar\n\n\nJul 8, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nMultivariate Ito Calculus\n\n\n\nFin Math\n\n\n\n\n\n\n\nQuasar\n\n\nJul 4, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nThe distribution of the first passage time of Brownian Motion\n\n\n\nFin Math\n\n\n\n\n\n\n\nQuasar\n\n\nJul 2, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nBorel-Cantelli Lemmas\n\n\n\nFin Math\n\n\n\n\n\n\n\nQuasar\n\n\nJun 28, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nPositive Definiteness\n\n\n\nLinear Algebra\n\n\n\n\n\n\n\nQuasar\n\n\nJun 20, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nOptimization Algorithms\n\n\n\nMachine Learning\n\n\n\n\n\n\n\nQuasar\n\n\nJun 10, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nBackpropogation\n\n\n\nMachine Learning\n\n\n\n\n\n\n\nQuasar\n\n\nJun 5, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCoding a neural network layer\n\n\n\nMachine Learning\n\n\n\n\n\n\n\nQuasar\n\n\nMay 28, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nClassification Algorithms\n\n\n\nMachine Learning\n\n\n\n\n\n\n\nQuasar\n\n\nMay 28, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nDerivation of the Least Squares Estimate Beta in Linear Regression\n\n\n\nMachine Learning\n\n\n\n\n\n\n\nQuasar\n\n\nMay 16, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nStandard CDS Pricing Theory\n\n\n\nFin Math\n\n\n\n\n\n\n\nQuasar\n\n\nMay 8, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCox-Ingersoll-Ross (CIR) model\n\n\n\nFin Math\n\n\n\n\n\n\n\nQuasar\n\n\nMay 8, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nBlack Scholes Formula for a European Call\n\n\n\nFin Math\n\n\n\n\n\n\n\nQuasar\n\n\nMay 3, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nExploring Option Greeks\n\n\n\nFin Math\n\n\n\n\n\n\n\nQuasar\n\n\nMay 3, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nProperties of Brownian Motion\n\n\n\nFin Math\n\n\n\n\n\n\n\nQuasar\n\n\nApr 27, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nImplementing Vanna Volga\n\n\n\nFin Math\n\n\n\n\n\n\n\nQuasar\n\n\nNov 26, 2023\n\n\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "About this blog"
  },
  {
    "objectID": "notebooks/ho_lee.html",
    "href": "notebooks/ho_lee.html",
    "title": "quantdev.blog",
    "section": "",
    "text": "import numpy as np\nimport matplotlib.pyplot as plt\n\"\"\"\nHo-Lee Model - Ensuring that model price of the ZCBs matches the market price\n\"\"\"\n\n# Discounting curve\ndef P(t,T):\n    r = 0.05\n    return np.exp(-r * (T-t))\n\nclass HoLee:\n    def __init__( self\n                 ,discountingCurve : np.array\n                 ,numOfSteps : int\n                 ,numOfPaths : int\n                 ,simulationCutoffDate : float\n                 ,sigma: float\n                 ):\n        self.discountingCurve = discountingCurve\n        self.numOfSteps = numOfSteps\n        self.numOfPaths = numOfPaths\n        self.T = simulationCutoffDate\n        self.sigma = sigma\n    \n    def F0T(self, T : float):\n        dt = 0.0001\n        return -(np.log(P(0,T+dt)) - np.log(P(0,T-dt)))/(2 * dt)\n        \n    def generatePaths(self):\n        dt = self.T / self.numOfSteps\n        timeGrid = np.linspace(dt, self.T, self.numOfSteps)\n\n        # Initial interest rate is a forward rate at time t -&gt; 0\n        r0 = self.F0T(0.0) * np.ones([self.numOfPaths, 1])\n        theta = lambda t : (self.F0T(t + dt) - self.F0T(t - dt))/(2 * dt) + self.sigma**2 * t\n        theta = np.array([theta(t) for t in timeGrid])\n        theta = np.tile(theta, [self.numOfPaths,1])\n        \n        dZt = np.random.standard_normal([self.numOfPaths, self.numOfSteps])\n        dWt = np.sqrt(dt) * dZt\n        dr_t = dt * theta + self.sigma * dWt\n        dr_t = np.concat([r0, dr_t], axis=1)\n        r_t = np.cumsum(dr_t, axis=1)\n        return r_t\n\n    # Price a ZCB in the Ho-Lee model, by computing expectations \n    # under the risk-neutral valuation formula\n    def ZCB(self, t1, t2, r_t : np.matrix):\n        idx_t1 = int(t1 * 365)\n        idx_t2 = int(t2 * 365)\n        dt = self.T / self.numOfSteps\n        return np.average(np.exp(np.sum([-(r_t[:,t] * dt) for t in range(idx_t1, idx_t2)], axis=0)))\n\n\n\nT = 10.0                # Simulation cutoff time T in years\nnumOfSteps = int(365 * T)    # Number of steps\nnumOfPaths = 100\n\ntimeGrid = np.linspace(0.0, T, numOfSteps + 1)\ndiscountingCurve = np.array([P(0,t) for t in timeGrid])\n\n# In this experiment we compare the ZCB from the market and Monte Carlo\nengine = HoLee(\n    discountingCurve=discountingCurve,\n    numOfSteps = numOfSteps,\n    numOfPaths = numOfPaths,\n    simulationCutoffDate = T,\n    sigma = 0.001\n)\n\npaths = engine.generatePaths()\n\nplt.xlabel(r'$t$')\nplt.ylabel(r'$r(t)$')\nplt.title(r'Simulating short rate in the Ho-Lee model')\nplt.grid(True)\nfor path in paths:\n    plt.plot(timeGrid, path)\n\nplt.show()\n\n\n\n\n\n\n\n# Computing ZCB Model prices\nZCBPriceVector = np.array([engine.ZCB(0,T, paths) for T in timeGrid])\n\n# Plot Discount curve and Model ZCB Prices\nplt.close()\n\nplt.xlabel(r'$t$')\nplt.ylabel(r'$P(0,T)$')\nplt.grid(True)\n\nplt.plot(timeGrid, discountingCurve)\nplt.plot(timeGrid, ZCBPriceVector)\nplt.legend([r'$P(0,t)$ market', r'$P(0,t)$ model'])\nplt.show()"
  },
  {
    "objectID": "posts/backpropogation/index.html",
    "href": "posts/backpropogation/index.html",
    "title": "Backpropogation",
    "section": "",
    "text": "With a randomly initialized model, or even a model initialized with more sophisticated approaches, our goal is to train, or teach a model over time. To train a model, we tweak the weights and biases to improve the model’s accuracy and confidence. To do this, we calculate the error in our model. The loss function also referred to as the cost function quantifies the error.\n\n\nLet \\(\\vec{l} = \\mathbf{w}\\cdot \\mathbf{x} + \\mathbf{b}\\) be the result of the last dense layer of a neural network (the inner product between an input feature vector and the weights vector of the layer, added to the bias factor). This is commonly referred to as the logit vector in machine learning literature.\n\n\n\nLet \\(X\\) be a random variable with possible outcomes \\(\\mathcal{X}\\). Let \\(P\\) be the true probability distribution of \\(X\\) with probability mass function \\(p(x)\\). Let \\(Q\\) be an approximating distribution with probability mass function \\(q(x)\\).\nDefinition. The entropy of \\(P\\) is defined as:\n\\[\\begin{align*}\nH(P) = -\\sum_{x\\in\\mathcal{X}} p(x) \\cdot \\log p(x)\n\\end{align*}\\]\nIn information theory, entropy is the measure of uncertainty, surprise of a system. By taking the logarithm \\(\\log p(x)\\), we concentrate on the order of the surprise. Entropy, then, is an expectation over the uncertainties or the expected surprise.\nDefinition. The cross-entropy of \\(Q\\) relative to \\(P\\) is defined as:\n\\[\\begin{align*}\nH(P,Q) = -\\sum_{x\\in\\mathcal{X}} p(x) \\cdot \\log q(x)\n\\end{align*}\\]\nDefinition. For discrete distributions \\(P\\) and \\(Q\\) defined on the sample space \\(\\mathcal{X}\\), the Kullback-Leibler(KL) divergence (or relative entropy) from \\(Q\\) to \\(P\\) is defined as:\n\\[\\begin{align*}\nD_{KL}(P||Q) = -\\sum_{x\\in\\mathcal{X}} p(x) \\cdot \\log \\frac{p(x)}{q(x)}\n\\end{align*}\\]\nIntuitively, it is the expected excess surprise from using \\(Q\\) as a model instead of \\(P\\), when the actual distribution is \\(P\\). Note that, \\(D_{KL}(P||Q) \\neq D_{KL}(Q||P)\\), so it is not symmetric and hence it is not a norm.\n\n\n\nWe are going to work on a multi-class classification problem.\nFor any input \\(\\mathbf{x}_i\\), the target vector \\(\\mathbf{y}_i\\) could be specified using one-hot encoding or an integer in the range [0,numClasses).\nLet’s say, we have numClasses = 3.\nIn one-hot encoding, the target vector y_true is an array like [1, 0, 0], [0, 1, 0], or [0, 0, 1]. The category/class is determined by the index which is hot. For example, if y_true equals [0, 1, 0], then the sample belongs to class \\(1\\), whilst if y_true equals [0, 0, 1], the sample belongs to class \\(2\\).\nIn integer encoding, the target vector y_true is an integer. For example, if y_true equals \\(1\\), the sample belongs to class \\(1\\), whilst if y_true equals \\(2\\), the sample belongs to class \\(2\\).\nThe categorical_crossentropy is defined as:\n\\[\\begin{align*}\nL_i = -\\sum_{j} y_{i,j} \\log(\\hat{y}_{i,j})\n\\end{align*}\\]\nAssume that we have a softmax output \\(\\hat{\\mathbf{y}}_i\\), [0.7, 0.1, 0.2] and target vector \\(\\mathbf{y}_i\\) [1, 0, 0]. Then, we can compute the categorical cross entropy loss as:\n\\[\\begin{align*}\n-\\left(1\\cdot \\log (0.7) + 0 \\cdot \\log (0.1) + 0 \\cdot \\log(0.2)\\right) = 0.35667494\n\\end{align*}\\]\nLet’s that we have a batch of \\(3\\) samples. Additionally, suppose the target y_true is integer encoded. After running through the softmax activation function, the network’s output layer yields:\n\n%load_ext itikz\n\n\nimport numpy as np\n\ny_pred = np.array(\n    [\n        [0.7, 0.1, 0.2],\n        [0.1, 0.5, 0.4],\n        [0.02, 0.9, 0.08]\n    ]\n)\n\ny_true = [0, 1, 2]\n\nWith a collection of softmax outputs and their intended targets, we can map these indices to retrieve the predicted probabilities of the true class labels:\n\nfor targ_index, distribution in zip(y_true,y_pred):\n    print(distribution[targ_index])\n\n0.7\n0.5\n0.08\n\n\nThis can be simplified.\n\nprint(y_pred[[0,1,2],y_true])\n\n[0.7  0.5  0.08]\n\n\nnumpy lets us index an 2D-array in multiple ways. One of them is to use a list filled with row indices and a list with column indices. We could, thus, write:\n\nprint(y_pred[range(len(y_pred)),y_true])\n\n[0.7  0.5  0.08]\n\n\nThe categorical cross-entropy loss for each of the samples is:\n\nprint(-np.log(y_pred[range(len(y_pred)),y_true]))\n\n[0.35667494 0.69314718 2.52572864]\n\n\nFinally, we want an average loss for the entire batch, to have an idea about how our model is doing during the training phase. Therefore, we have:\n\nneg_log = -np.log(y_pred[range(len(y_pred)),y_true])\naverage_loss = np.mean(neg_log)\nprint(average_loss)\n\n1.191850256268978\n\n\nIn the case, that the targets are one-hot encoded, we need to handle this case a bit differently. If y_true.shape has \\(2\\) dimensions, then it implies, we have a set of one-hot encoded vectors. On the other hand, if y_true is a list, that is y_true.shape has \\(1\\) dimension, then it means, we have sparse labels/integer encoding.\n\nimport numpy as np\n\ny_pred = np.array(\n    [\n        [0.7, 0.1, 0.2],\n        [0.1, 0.5, 0.4],\n        [0.02, 0.9, 0.08]\n    ]\n)\n\ny_true = np.array(\n    [\n        [1, 0, 0],\n        [0, 1, 0],\n        [0, 0, 1]\n    ]\n)\n\ncorrect_confidences = np.array([])\n\n# If categorical labels\nif(len(y_pred.shape) == 1):\n    correct_confidences = y_pred[range(len(y_pred)), y_true]\nelif(len(y_pred.shape)==2):\n    correct_confidences = np.sum(y_pred * y_true, axis=1)\n\nneg_log = -np.log(correct_confidences)\naverage_loss = np.mean(neg_log)\nprint(average_loss)\n\n1.191850256268978\n\n\nIf the neural network output y_pred for some reason is the vector [1, 0, 0], this would result in numpy.log function returning a negative infinity. To avoid such situations, it’s safer to apply a ceil and floor to y_pred.\n\nepsilon = 1e-7\ny_pred_clipped = np.clip(y_pred, epsilon, 1-epsilon)"
  },
  {
    "objectID": "posts/backpropogation/index.html#calculating-the-network-error-with-loss",
    "href": "posts/backpropogation/index.html#calculating-the-network-error-with-loss",
    "title": "Backpropogation",
    "section": "",
    "text": "With a randomly initialized model, or even a model initialized with more sophisticated approaches, our goal is to train, or teach a model over time. To train a model, we tweak the weights and biases to improve the model’s accuracy and confidence. To do this, we calculate the error in our model. The loss function also referred to as the cost function quantifies the error.\n\n\nLet \\(\\vec{l} = \\mathbf{w}\\cdot \\mathbf{x} + \\mathbf{b}\\) be the result of the last dense layer of a neural network (the inner product between an input feature vector and the weights vector of the layer, added to the bias factor). This is commonly referred to as the logit vector in machine learning literature.\n\n\n\nLet \\(X\\) be a random variable with possible outcomes \\(\\mathcal{X}\\). Let \\(P\\) be the true probability distribution of \\(X\\) with probability mass function \\(p(x)\\). Let \\(Q\\) be an approximating distribution with probability mass function \\(q(x)\\).\nDefinition. The entropy of \\(P\\) is defined as:\n\\[\\begin{align*}\nH(P) = -\\sum_{x\\in\\mathcal{X}} p(x) \\cdot \\log p(x)\n\\end{align*}\\]\nIn information theory, entropy is the measure of uncertainty, surprise of a system. By taking the logarithm \\(\\log p(x)\\), we concentrate on the order of the surprise. Entropy, then, is an expectation over the uncertainties or the expected surprise.\nDefinition. The cross-entropy of \\(Q\\) relative to \\(P\\) is defined as:\n\\[\\begin{align*}\nH(P,Q) = -\\sum_{x\\in\\mathcal{X}} p(x) \\cdot \\log q(x)\n\\end{align*}\\]\nDefinition. For discrete distributions \\(P\\) and \\(Q\\) defined on the sample space \\(\\mathcal{X}\\), the Kullback-Leibler(KL) divergence (or relative entropy) from \\(Q\\) to \\(P\\) is defined as:\n\\[\\begin{align*}\nD_{KL}(P||Q) = -\\sum_{x\\in\\mathcal{X}} p(x) \\cdot \\log \\frac{p(x)}{q(x)}\n\\end{align*}\\]\nIntuitively, it is the expected excess surprise from using \\(Q\\) as a model instead of \\(P\\), when the actual distribution is \\(P\\). Note that, \\(D_{KL}(P||Q) \\neq D_{KL}(Q||P)\\), so it is not symmetric and hence it is not a norm.\n\n\n\nWe are going to work on a multi-class classification problem.\nFor any input \\(\\mathbf{x}_i\\), the target vector \\(\\mathbf{y}_i\\) could be specified using one-hot encoding or an integer in the range [0,numClasses).\nLet’s say, we have numClasses = 3.\nIn one-hot encoding, the target vector y_true is an array like [1, 0, 0], [0, 1, 0], or [0, 0, 1]. The category/class is determined by the index which is hot. For example, if y_true equals [0, 1, 0], then the sample belongs to class \\(1\\), whilst if y_true equals [0, 0, 1], the sample belongs to class \\(2\\).\nIn integer encoding, the target vector y_true is an integer. For example, if y_true equals \\(1\\), the sample belongs to class \\(1\\), whilst if y_true equals \\(2\\), the sample belongs to class \\(2\\).\nThe categorical_crossentropy is defined as:\n\\[\\begin{align*}\nL_i = -\\sum_{j} y_{i,j} \\log(\\hat{y}_{i,j})\n\\end{align*}\\]\nAssume that we have a softmax output \\(\\hat{\\mathbf{y}}_i\\), [0.7, 0.1, 0.2] and target vector \\(\\mathbf{y}_i\\) [1, 0, 0]. Then, we can compute the categorical cross entropy loss as:\n\\[\\begin{align*}\n-\\left(1\\cdot \\log (0.7) + 0 \\cdot \\log (0.1) + 0 \\cdot \\log(0.2)\\right) = 0.35667494\n\\end{align*}\\]\nLet’s that we have a batch of \\(3\\) samples. Additionally, suppose the target y_true is integer encoded. After running through the softmax activation function, the network’s output layer yields:\n\n%load_ext itikz\n\n\nimport numpy as np\n\ny_pred = np.array(\n    [\n        [0.7, 0.1, 0.2],\n        [0.1, 0.5, 0.4],\n        [0.02, 0.9, 0.08]\n    ]\n)\n\ny_true = [0, 1, 2]\n\nWith a collection of softmax outputs and their intended targets, we can map these indices to retrieve the predicted probabilities of the true class labels:\n\nfor targ_index, distribution in zip(y_true,y_pred):\n    print(distribution[targ_index])\n\n0.7\n0.5\n0.08\n\n\nThis can be simplified.\n\nprint(y_pred[[0,1,2],y_true])\n\n[0.7  0.5  0.08]\n\n\nnumpy lets us index an 2D-array in multiple ways. One of them is to use a list filled with row indices and a list with column indices. We could, thus, write:\n\nprint(y_pred[range(len(y_pred)),y_true])\n\n[0.7  0.5  0.08]\n\n\nThe categorical cross-entropy loss for each of the samples is:\n\nprint(-np.log(y_pred[range(len(y_pred)),y_true]))\n\n[0.35667494 0.69314718 2.52572864]\n\n\nFinally, we want an average loss for the entire batch, to have an idea about how our model is doing during the training phase. Therefore, we have:\n\nneg_log = -np.log(y_pred[range(len(y_pred)),y_true])\naverage_loss = np.mean(neg_log)\nprint(average_loss)\n\n1.191850256268978\n\n\nIn the case, that the targets are one-hot encoded, we need to handle this case a bit differently. If y_true.shape has \\(2\\) dimensions, then it implies, we have a set of one-hot encoded vectors. On the other hand, if y_true is a list, that is y_true.shape has \\(1\\) dimension, then it means, we have sparse labels/integer encoding.\n\nimport numpy as np\n\ny_pred = np.array(\n    [\n        [0.7, 0.1, 0.2],\n        [0.1, 0.5, 0.4],\n        [0.02, 0.9, 0.08]\n    ]\n)\n\ny_true = np.array(\n    [\n        [1, 0, 0],\n        [0, 1, 0],\n        [0, 0, 1]\n    ]\n)\n\ncorrect_confidences = np.array([])\n\n# If categorical labels\nif(len(y_pred.shape) == 1):\n    correct_confidences = y_pred[range(len(y_pred)), y_true]\nelif(len(y_pred.shape)==2):\n    correct_confidences = np.sum(y_pred * y_true, axis=1)\n\nneg_log = -np.log(correct_confidences)\naverage_loss = np.mean(neg_log)\nprint(average_loss)\n\n1.191850256268978\n\n\nIf the neural network output y_pred for some reason is the vector [1, 0, 0], this would result in numpy.log function returning a negative infinity. To avoid such situations, it’s safer to apply a ceil and floor to y_pred.\n\nepsilon = 1e-7\ny_pred_clipped = np.clip(y_pred, epsilon, 1-epsilon)"
  },
  {
    "objectID": "posts/backpropogation/index.html#categorical-cross-entropy-loss-class",
    "href": "posts/backpropogation/index.html#categorical-cross-entropy-loss-class",
    "title": "Backpropogation",
    "section": "Categorical Cross-Entropy Loss Class",
    "text": "Categorical Cross-Entropy Loss Class\nI first create an abstract base class Loss. Every Loss object exposes the calculate method which in turn calls Loss object’s forward method to compute the log-loss for each sample and then takes an average of the sample losses.\nCategoricalCrossEntropyLoss class is a child class of Loss and provides an implementation of the forward method.\n\nimport numpy as np\nimport nnfs\nfrom nnfs.datasets import spiral_data\nfrom abc import abstractmethod\n\n\n# Abstract base class for losses\nclass Loss:\n    @abstractmethod\n    def forward(self, y_pred, y_true):\n        pass\n\n    @abstractmethod\n    def backward(self, y_pred, y_true):\n        pass\n\n    # Calculates the data and regularization losses\n    # given model output and ground truth values\n    def calculate(self, output, y):\n\n        # Calculate the sample losses\n        sample_losses = self.forward(output, y)\n\n        # Calculate the mean loss\n        data_loss = np.mean(sample_losses)\n\n        # Return loss\n        return data_loss\n\n\n# Cross-Entropy loss\nclass CategoricalCrossEntropyLoss(Loss):\n\n    # Forward pass\n    def forward(self, y_pred, y_true):\n        num_samples = len(y_pred)\n\n        # Clip data to prevent division by 0\n        # Clip both sides to not drag mean towards any value\n        epsilon = 1e-7\n        y_pred_clipped = np.clip(y_pred, epsilon, 1 - epsilon)\n\n        # If categorical labels\n        if len(y_pred.shape) == 1:\n            correct_confidences = y_pred[range(len(y_pred)), y_true]\n        # else if one-hot encoding\n        elif len(y_pred.shape) == 2:\n            correct_confidences = np.sum(y_pred * y_true, axis=1)\n\n        neg_log = -np.log(correct_confidences)\n        return neg_log\n\nUsing the manual created outputs and targets, we have:\n\ny_pred = np.array(\n    [\n        [0.7, 0.1, 0.2],\n        [0.1, 0.5, 0.4],\n        [0.02, 0.9, 0.08]\n    ]\n)\n\ny_true = np.array(\n    [\n        [1, 0, 0],\n        [0, 1, 0],\n        [0, 0, 1]\n    ]\n)\n\nloss_function = CategoricalCrossEntropyLoss()\nloss = loss_function.calculate(y_pred, y_true)\nprint(loss)\n\n1.191850256268978"
  },
  {
    "objectID": "posts/backpropogation/index.html#backpropogation",
    "href": "posts/backpropogation/index.html#backpropogation",
    "title": "Backpropogation",
    "section": "Backpropogation",
    "text": "Backpropogation\nBackpropogation consists going backwards along the edges and passing along gradients. We are going to chop up a neuron into it’s elementary operations and draw a computational graph. Each node in the graph receives an upstream gradient. The goal is pass on the correct downstream gradient.\nEach node has a local gradient - the gradient of it’s output with respect to it’s input. Consider a node receiving an input \\(z\\) and producing an output \\(h=f(z)\\). Then, we have:\n\n\nShow the code\n%%itikz --temp-dir --tex-packages=tikz --tikz-libraries=arrows --implicit-standalone\n\\begin{tikzpicture}\n    \\node [circle,minimum size=40mm,draw] (f) at (0,0) {\\huge $f$};\n    \\node [blue] (localgrad) at (-1,0) {\\huge $\\frac{\\partial h}{\\partial z}$};\n    \\node [blue] (lgrad) at (0.0,1) {\\large Local gradient};\n    \\draw [-&gt;, shorten &gt;=1pt] (1.80,1) -- node [above,midway] {\\huge $h$} (5,1);\n    \\draw [-&gt;, shorten &gt;=1pt] (5,-1) -- node [below,midway] {\\huge $\\frac{\\partial s}{\\partial h}$} (1.80,-1);\n    \\node [] (upgrad) at (4.0,-3) {\\huge Upstream gradient};\n    \\draw [-&gt;, shorten &gt;=1pt] (-5,1) -- node [above,midway] {\\huge $z$} (-1.80,1);\n    \\draw [-&gt;, shorten &gt;=1pt] (-1.80,-1) -- node [below,midway] {\\huge $\\frac{\\partial s}{\\partial z} = \\frac{\\partial s}{\\partial h} \\cdot \\frac{\\partial h}{\\partial z}$} (-5,-1);\n    \\node [] (downgrad) at (-4.0,-3) {\\huge Downstream gradient};\n\\end{tikzpicture}\n\n\n\n\n\nThe downstream gradient \\(\\frac{\\partial s}{\\partial z}\\) equals the upstream graient \\(\\frac{\\partial s}{\\partial h}\\) times the local gradient \\(\\frac{\\partial h}{\\partial z}\\).\nWhat about nodes with multiple inputs? Say that, \\(h=f(x,y)\\). Multiple inputs imply multiple local gradients.\n\n\nShow the code\n%%itikz --temp-dir --tex-packages=tikz --tikz-libraries=arrows --implicit-standalone\n\\begin{tikzpicture}[x=0.75pt,y=0.75pt,yscale=-1,scale=1.75]\n%uncomment if require: \\path (0,216); %set diagram left start at 0, and has height of 216\n\n%Shape: Circle [id:dp08328772161506959] \n\\draw   (302.75,83.38) .. controls (302.75,53.62) and (326.87,29.5) .. (356.63,29.5) .. controls (386.38,29.5) and (410.5,53.62) .. (410.5,83.38) .. controls (410.5,113.13) and (386.38,137.25) .. (356.63,137.25) .. controls (326.87,137.25) and (302.75,113.13) .. (302.75,83.38) -- cycle ;\n%Straight Lines [id:da2730189357413113] \n\\draw    (406,59.38) -- (513.5,59.74) ;\n\\draw [shift={(515.5,59.75)}, rotate = 180.2] [color={rgb, 255:red, 0; green, 0; blue, 0 }  ][line width=0.75]    (10.93,-3.29) .. controls (6.95,-1.4) and (3.31,-0.3) .. (0,0) .. controls (3.31,0.3) and (6.95,1.4) .. (10.93,3.29)   ;\n%Straight Lines [id:da21080101466010737] \n\\draw    (515,110.75) -- (405,110.26) ;\n\\draw [shift={(403,110.25)}, rotate = 0.26] [color={rgb, 255:red, 0; green, 0; blue, 0 }  ][line width=0.75]    (10.93,-3.29) .. controls (6.95,-1.4) and (3.31,-0.3) .. (0,0) .. controls (3.31,0.3) and (6.95,1.4) .. (10.93,3.29)   ;\n%Straight Lines [id:da05192158713361961] \n\\draw    (209,1.75) -- (309.71,51.37) ;\n\\draw [shift={(311.5,52.25)}, rotate = 206.23] [color={rgb, 255:red, 0; green, 0; blue, 0 }  ][line width=0.75]    (10.93,-3.29) .. controls (6.95,-1.4) and (3.31,-0.3) .. (0,0) .. controls (3.31,0.3) and (6.95,1.4) .. (10.93,3.29)   ;\n%Straight Lines [id:da3568530309648137] \n\\draw    (305,68.25) -- (204.31,20.61) ;\n\\draw [shift={(202.5,19.75)}, rotate = 25.32] [color={rgb, 255:red, 0; green, 0; blue, 0 }  ][line width=0.75]    (10.93,-3.29) .. controls (6.95,-1.4) and (3.31,-0.3) .. (0,0) .. controls (3.31,0.3) and (6.95,1.4) .. (10.93,3.29)   ;\n%Straight Lines [id:da4437541566257528] \n\\draw    (205,167.25) -- (311.2,116.12) ;\n\\draw [shift={(313,115.25)}, rotate = 154.29] [color={rgb, 255:red, 0; green, 0; blue, 0 }  ][line width=0.75]    (10.93,-3.29) .. controls (6.95,-1.4) and (3.31,-0.3) .. (0,0) .. controls (3.31,0.3) and (6.95,1.4) .. (10.93,3.29)   ;\n%Straight Lines [id:da2672766038605987] \n\\draw    (304.5,101.75) -- (205.82,146.92) ;\n\\draw [shift={(204,147.75)}, rotate = 335.41] [color={rgb, 255:red, 0; green, 0; blue, 0 }  ][line width=0.75]    (10.93,-3.29) .. controls (6.95,-1.4) and (3.31,-0.3) .. (0,0) .. controls (3.31,0.3) and (6.95,1.4) .. (10.93,3.29)   ;\n\n% Text Node\n\\draw (352,76.4) node [anchor=north west][inner sep=0.75pt]    {\\huge $f$};\n% Text Node\n\\draw (318.5,44.4) node [anchor=north west][inner sep=0.75pt]  [font=\\small,color={rgb, 255:red, 0; green, 28; blue, 247 }  ,opacity=1 ]  {\\huge $\\frac{\\partial h}{\\partial x}$};\n% Text Node\n\\draw (318.5,88.9) node [anchor=north west][inner sep=0.75pt]  [font=\\small,color={rgb, 255:red, 0; green, 36; blue, 255 }  ,opacity=1 ]  {\\huge $\\frac{\\partial h}{\\partial y}$};\n% Text Node\n\\draw (258.5,7.4) node [anchor=north west][inner sep=0.75pt]    {\\huge $x$};\n% Text Node\n\\draw (264,136.9) node [anchor=north west][inner sep=0.75pt]    {\\huge $y$};\n% Text Node\n\\draw (151.5,96.9) node [anchor=north west][inner sep=0.75pt]  [font=\\small,color={rgb, 255:red, 0; green, 28; blue, 247 }  ,opacity=1 ]  {\\huge $\\frac{\\partial s}{\\partial y} =\\frac{\\partial s}{\\partial h} \\cdot \\frac{\\partial h}{\\partial y}$};\n% Text Node\n\\draw (150,33.4) node [anchor=north west][inner sep=0.75pt]  [font=\\small,color={rgb, 255:red, 0; green, 28; blue, 247 }  ,opacity=1 ]  {\\huge $\\frac{\\partial s}{\\partial x} =\\frac{\\partial s}{\\partial h} \\cdot \\frac{\\partial h}{\\partial x}$};\n% Text Node\n\\draw (322.5,4.9) node [anchor=north west][inner sep=0.75pt]    {\\huge $h=f(x,y)$};\n% Text Node\n\\draw (449.5,39.9) node [anchor=north west][inner sep=0.75pt]    {\\huge $h$};\n% Text Node\n\\draw (451.5,112.9) node [anchor=north west][inner sep=0.75pt]    {\\huge $\\frac{\\partial s}{\\partial h}$};\n% Text Node\n\\draw (164.5,172.9) node [anchor=north west][inner sep=0.75pt]    {\\huge $ \\begin{array}{l}\nDownstream\\ \\\\\ngradients\n\\end{array}$};\n% Text Node\n\\draw (430.5,175.4) node [anchor=north west][inner sep=0.75pt]    {\\huge $ \\begin{array}{l}\nUpstream\\ \\\\\ngradients\n\\end{array}$};\n% Text Node\n\\draw (318.5,173.9) node [anchor=north west][inner sep=0.75pt]  [color={rgb, 255:red, 3; green, 50; blue, 255 }  ,opacity=1 ]  {\\huge $ \\begin{array}{l}\nLocal\\ \\\\\ngradients\n\\end{array}$};\n\n\n\\end{tikzpicture}\n\n\n\n\n\nLet’s start with a simple forward pass with \\(1\\) neuron. Let’s say, we have the following input vector, weights and bias:\n\nx = [1.0, -2.0, 3.0]  # input values\nw = [-3.0, -1.0, 2.0] # weights\nb = 1.0\n\n# Forward pass\nz = np.dot(x,w) + b\n\n# ReLU Activation function\ny = max(z, 0)\n\n\n\nShow the code\n%%itikz --temp-dir --tex-packages=tikz --tikz-libraries=arrows --implicit-standalone\n\\begin{tikzpicture}\n\\foreach \\i in {0,...,2}\n{\n    \\node[] (Input-\\i) at (0,-\\i * 4) {\\large $x[\\i]$};\n}\n\\foreach \\i in {0,...,2}\n{\n    \\node[] (Weight-\\i) at (0,-\\i * 4-2) {\\large $w[\\i]$};\n}\n\\foreach \\i in {0,...,2}\n{\n    \\node[circle, \n        minimum size = 15mm,\n        draw,\n        ] (Mult-\\i) at (3.0,-\\i * 4 - 1) {\\large $\\times$};\n        \n}\n\n\\node [] (bias) at (0,-12) {\\large $b$};\n\n\\node [circle,minimum size=15mm,draw] (Add) at (6,-5) {\\large +};\n\\node [circle,minimum size=15mm,draw] (ReLU) at (9,-5) {\\large $\\max(x,0)$};\n\\node [] (NextLayer) at (12,-5) {};\n\n\\draw[-&gt;, shorten &gt;=1pt] (Input-0) -- node[midway,above,blue] {\\large $1.0$} (Mult-0);   \n\\draw[-&gt;, shorten &gt;=1pt] (Weight-0) -- node[midway,above,blue] {\\large $-3.0$} (Mult-0);   \n\\draw[-&gt;, shorten &gt;=1pt] (Input-1) -- node[midway,above,blue] {\\large $-2.0$}(Mult-1);   \n\\draw[-&gt;, shorten &gt;=1pt] (Weight-1) -- node[midway,above,blue] {\\large $-1.0$}(Mult-1);   \n\\draw[-&gt;, shorten &gt;=1pt] (Input-2) -- node[midway,above,blue] {\\large $3.0$}(Mult-2);   \n\\draw[-&gt;, shorten &gt;=1pt] (Weight-2) -- node[midway,above,blue] {\\large $2.0$}(Mult-2);   \n\n\\draw (bias) -- node[midway,above,blue] {\\large $1.0$}(6,-12);\n\\draw[-&gt;, shorten &gt;=1pt] (6,-12) -- (Add);\n\n\\draw[-&gt;, shorten &gt;=1pt] (Mult-0) -- node[midway,above,blue] {\\large $-3.0$}(Add);   \n\\draw[-&gt;, shorten &gt;=1pt] (Mult-1) -- node[midway,above,blue] {\\large $2.0$}(Add);   \n\\draw[-&gt;, shorten &gt;=1pt] (Mult-2) -- node[midway,above,blue] {\\large $6.0$}(Add);   \n\n\\draw[-&gt;, shorten &gt;=1pt] (Add) -- node[midway,above,blue] {\\large $6.0$}(ReLU);   \n\\draw[-&gt;, shorten &gt;=1pt] (ReLU) -- node[midway,above,blue] {\\large $6.0$}(NextLayer);\n\\node [red] (A) at (11,-5.5) {\\large $1.00$};\n\\end{tikzpicture}\n\n\n\n\n\nThe ReLU function \\(f(x)=\\max(x,0)\\) is differentiable everywhere except at \\(x = 0\\). We define \\(f'(x)\\) as:\n\\[\\begin{align*}\nf'(x) =\n\\begin{cases}\n1 & x &gt; 0 \\\\\n0 & \\text{otherwise}\n\\end{cases}\n\\end{align*}\\]\nIn Python, we write:\n\nrelu_dz = (1. if z &gt; 0 else 0.)\n\nThe input to the ReLU function is \\(6.00\\), so the derivative equals \\(1.00\\). We multiply this local gradient by the upstream gradient to calculate the downstream gradient.\n\nimport numpy as np\n\nx = [1.0, -2.0, 3.0]  # input values\nw = [-3.0, -1.0, 2.0]  # weights\nb = 1.0\n\n# Forward pass\nz = np.dot(x, w) + b\n\n# ReLU Activation function\ny = max(z, 0)\n\n# Backward pass\n# Upstream gradient\nds_drelu = 1.0\n\n# Derivative of the ReLU and the chain rule\ndrelu_dz = 1.0 if z &gt; 0 else 0.0\nds_dz = ds_drelu * drelu_dz\nprint(ds_dz)\n\n1.0\n\n\nThe results with the derivative of the ReLU function and chain rule look as follows:\n\n\nShow the code\n%%itikz --temp-dir --tex-packages=tikz --tikz-libraries=arrows --implicit-standalone\n\\begin{tikzpicture}\n\\foreach \\i in {0,...,2}\n{\n    \\node[] (Input-\\i) at (0,-\\i * 4) {\\large $x[\\i]$};\n}\n\\foreach \\i in {0,...,2}\n{\n    \\node[] (Weight-\\i) at (0,-\\i * 4-2) {\\large $w[\\i]$};\n}\n\\foreach \\i in {0,...,2}\n{\n    \\node[circle, \n        minimum size = 15mm,\n        draw,\n        ] (Mult-\\i) at (3.0,-\\i * 4 - 1) {\\large $\\times$};\n        \n}\n\n\\node [] (bias) at (0,-12) {\\large $b$};\n\n\\node [circle,minimum size=15mm,draw] (Add) at (6,-5) {\\large +};\n\\node [circle,minimum size=15mm,draw] (ReLU) at (9,-5) {\\large $\\max(x,0)$};\n\\node [] (NextLayer) at (12,-5) {};\n\n\\draw[-&gt;, shorten &gt;=1pt] (Input-0) -- node[midway,above,blue] {\\large $1.0$} (Mult-0);   \n\\draw[-&gt;, shorten &gt;=1pt] (Weight-0) -- node[midway,above,blue] {\\large $-3.0$} (Mult-0);   \n\\draw[-&gt;, shorten &gt;=1pt] (Input-1) -- node[midway,above,blue] {\\large $-2.0$}(Mult-1);   \n\\draw[-&gt;, shorten &gt;=1pt] (Weight-1) -- node[midway,above,blue] {\\large $-1.0$}(Mult-1);   \n\\draw[-&gt;, shorten &gt;=1pt] (Input-2) -- node[midway,above,blue] {\\large $3.0$}(Mult-2);   \n\\draw[-&gt;, shorten &gt;=1pt] (Weight-2) -- node[midway,above,blue] {\\large $2.0$}(Mult-2);   \n\n\\draw (bias) -- node[midway,above,blue] {\\large $1.0$}(6,-12);\n\\draw[-&gt;, shorten &gt;=1pt] (6,-12) -- (Add);\n\n\\draw[-&gt;, shorten &gt;=1pt] (Mult-0) -- node[midway,above,blue] {\\large $-3.0$}(Add);   \n\\draw[-&gt;, shorten &gt;=1pt] (Mult-1) -- node[midway,above,blue] {\\large $2.0$}(Add);   \n\\draw[-&gt;, shorten &gt;=1pt] (Mult-2) -- node[midway,above,blue] {\\large $6.0$}(Add);   \n\n\\draw[-&gt;, shorten &gt;=1pt] (Add) -- node[midway,above,blue] {\\large $6.0$}(ReLU);   \n\\draw[-&gt;, shorten &gt;=1pt] (ReLU) -- node[midway,above,blue] {\\large $6.0$}(NextLayer);\n\\node [red] (A) at (11,-5.5) {\\large $1.00$};\n\\node [red] (B) at (7,-5.5) {\\large $1.00$};\n\\end{tikzpicture}\n\n\n\n\n\nMoving backward through our neural network, consider the add function \\(f(x,y,z)=x + y + z\\). The partial derivatives \\(\\frac{\\partial f}{\\partial x}\\), \\(\\frac{\\partial f}{\\partial y}\\) and \\(\\frac{\\partial f}{\\partial z}\\) are all equal to \\(1\\). So, the add gate always takes on the gradient on its output and distributes it equally to all of its inputs, regardless of what their values were during the forward pass.\n\n# Local gradients for the + function\ndz_dw0x0 = 1\ndz_dw1x1 = 1\ndz_dw2x2 = 1\ndz_db = 1\n\n# Calculate the downstream gradients\nds_dw0x0 = ds_dz * dz_dw0x0\nds_dw1x1 = ds_dz * dz_dw1x1\nds_dw2x2 = ds_dz * dz_dw2x2\nds_db = ds_dz * dz_db\nprint(ds_dw0x0, ds_dw1x1, ds_dw2x2, ds_db)\n\n1.0 1.0 1.0 1.0\n\n\nWe can update the computation graph as:\n\n\nShow the code\n%%itikz --temp-dir --tex-packages=tikz --tikz-libraries=arrows --implicit-standalone\n\\begin{tikzpicture}\n\\foreach \\i in {0,...,2}\n{\n    \\node[] (Input-\\i) at (0,-\\i * 4) {\\large $x[\\i]$};\n}\n\\foreach \\i in {0,...,2}\n{\n    \\node[] (Weight-\\i) at (0,-\\i * 4-2) {\\large $w[\\i]$};\n}\n\\foreach \\i in {0,...,2}\n{\n    \\node[circle, \n        minimum size = 15mm,\n        draw,\n        ] (Mult-\\i) at (3.0,-\\i * 4 - 1) {\\large $\\times$};\n        \n}\n\n\\node [] (bias) at (0,-12) {\\large $b$};\n\n\\node [circle,minimum size=15mm,draw] (Add) at (6,-5) {\\large +};\n\\node [circle,minimum size=15mm,draw] (ReLU) at (9,-5) {\\large $\\max(x,0)$};\n\\node [] (NextLayer) at (12,-5) {};\n\n\\draw[-&gt;, shorten &gt;=1pt] (Input-0) -- node[midway,above,blue] {\\large $1.0$} (Mult-0);   \n\\draw[-&gt;, shorten &gt;=1pt] (Weight-0) -- node[midway,above,blue] {\\large $-3.0$} (Mult-0);   \n\\draw[-&gt;, shorten &gt;=1pt] (Input-1) -- node[midway,above,blue] {\\large $-2.0$}(Mult-1);   \n\\draw[-&gt;, shorten &gt;=1pt] (Weight-1) -- node[midway,above,blue] {\\large $-1.0$}(Mult-1);   \n\\draw[-&gt;, shorten &gt;=1pt] (Input-2) -- node[midway,above,blue] {\\large $3.0$}(Mult-2);   \n\\draw[-&gt;, shorten &gt;=1pt] (Weight-2) -- node[midway,above,blue] {\\large $2.0$}(Mult-2);   \n\n\\draw (bias) -- node[midway,above,blue] {\\large $1.0$}(6,-12);\n\\draw[-&gt;, shorten &gt;=1pt] (6,-12) -- (Add);\n\n\\draw[-&gt;, shorten &gt;=1pt] (Mult-0) -- node[midway,above,blue] {\\large $-3.0$}(Add);   \n\\draw[-&gt;, shorten &gt;=1pt] (Mult-1) -- node[midway,above,blue] {\\large $2.0$}(Add);   \n\\draw[-&gt;, shorten &gt;=1pt] (Mult-2) -- node[midway,above,blue] {\\large $6.0$}(Add);   \n\n\\draw[-&gt;, shorten &gt;=1pt] (Add) -- node[midway,above,blue] {\\large $6.0$}(ReLU);   \n\\draw[-&gt;, shorten &gt;=1pt] (ReLU) -- node[midway,above,blue] {\\large $6.0$}(NextLayer);\n\\node [red] (A) at (11,-5.5) {\\large $1.00$};\n\\node [red] (B) at (7,-5.5) {\\large $1.00$};\n\\node [red] (C) at (5,-3.5) {\\large $1.00$};\n\\node [red] (D) at (5,-5.5) {\\large $1.00$};\n\\node [red] (E) at (5,-7.5) {\\large $1.00$};\n\\node [red] (f) at (5,-12.5) {\\large $1.00$};\n\\end{tikzpicture}\n\n\n\n\n\nNow, consider the production function \\(f(x,y) = x * y\\). The gradients of \\(f\\) are \\(\\frac{\\partial f}{\\partial x} = y\\), \\(\\frac{\\partial f}{\\partial y} = x\\). The multiply gate is therefore a little less easy to interpret. Its local gradients are the input values, except switched and this is multiplied by the upstream gradient.\n\n# Local gradients for the * function\ndw0x0_dx0 = w[0]\ndw0x0_dw0 = x[0]\ndw1x1_dx1 = w[1]\ndw1x1_dw1 = x[1]\ndw2x2_dx2 = w[2]\ndw2x2_dw2 = x[2]\n\n# Calculate the downstream gradients\nds_dx0 = ds_dw0x0 * dw0x0_dx0\nds_dw0 = ds_dw0x0 * dw0x0_dw0\nds_dx1 = ds_dw1x1 * dw1x1_dx1\nds_dw1 = ds_dw1x1 * dw1x1_dw1\nds_dx2 = ds_dw2x2 * dw2x2_dx2\nds_dw2 = ds_dw2x2 * dw2x2_dw2\n\nprint(ds_dx0, ds_dw0, ds_dx1, ds_dw1, ds_dx2, ds_dw2)\n\n-3.0 1.0 -1.0 -2.0 2.0 3.0\n\n\nWe can update the computation graph as follows:\n\n\nShow the code\n%%itikz --temp-dir --tex-packages=tikz --tikz-libraries=arrows --implicit-standalone\n\\begin{tikzpicture}\n\\foreach \\i in {0,...,2}\n{\n    \\node[] (Input-\\i) at (0,-\\i * 4) {\\large $x[\\i]$};\n}\n\\foreach \\i in {0,...,2}\n{\n    \\node[] (Weight-\\i) at (0,-\\i * 4-2) {\\large $w[\\i]$};\n}\n\\foreach \\i in {0,...,2}\n{\n    \\node[circle, \n        minimum size = 15mm,\n        draw,\n        ] (Mult-\\i) at (3.0,-\\i * 4 - 1) {\\large $\\times$};\n        \n}\n\n\\node [] (bias) at (0,-12) {\\large $b$};\n\n\\node [circle,minimum size=15mm,draw] (Add) at (6,-5) {\\large +};\n\\node [circle,minimum size=15mm,draw] (ReLU) at (9,-5) {\\large $\\max(x,0)$};\n\\node [] (NextLayer) at (12,-5) {};\n\n\\draw[-&gt;, shorten &gt;=1pt] (Input-0) -- node[midway,above,blue] {\\large $1.0$} (Mult-0);   \n\\draw[-&gt;, shorten &gt;=1pt] (Weight-0) -- node[midway,above,blue] {\\large $-3.0$} (Mult-0);   \n\\draw[-&gt;, shorten &gt;=1pt] (Input-1) -- node[midway,above,blue] {\\large $-2.0$}(Mult-1);   \n\\draw[-&gt;, shorten &gt;=1pt] (Weight-1) -- node[midway,above,blue] {\\large $-1.0$}(Mult-1);   \n\\draw[-&gt;, shorten &gt;=1pt] (Input-2) -- node[midway,above,blue] {\\large $3.0$}(Mult-2);   \n\\draw[-&gt;, shorten &gt;=1pt] (Weight-2) -- node[midway,above,blue] {\\large $2.0$}(Mult-2);   \n\n\\draw (bias) -- node[midway,above,blue] {\\large $1.0$}(6,-12);\n\\draw[-&gt;, shorten &gt;=1pt] (6,-12) -- (Add);\n\n\\draw[-&gt;, shorten &gt;=1pt] (Mult-0) -- node[midway,above,blue] {\\large $-3.0$}(Add);   \n\\draw[-&gt;, shorten &gt;=1pt] (Mult-1) -- node[midway,above,blue] {\\large $2.0$}(Add);   \n\\draw[-&gt;, shorten &gt;=1pt] (Mult-2) -- node[midway,above,blue] {\\large $6.0$}(Add);   \n\n\\draw[-&gt;, shorten &gt;=1pt] (Add) -- node[midway,above,blue] {\\large $6.0$}(ReLU);   \n\\draw[-&gt;, shorten &gt;=1pt] (ReLU) -- node[midway,above,blue] {\\large $6.0$}(NextLayer);\n\\node [red] (A) at (11,-5.5) {\\large $1.00$};\n\\node [red] (B) at (7,-5.5) {\\large $1.00$};\n\\node [red] (C) at (5,-3.5) {\\large $1.00$};\n\\node [red] (D) at (5,-5.5) {\\large $1.00$};\n\\node [red] (E) at (5,-7.5) {\\large $1.00$};\n\\node [red] (F) at (5,-12.5) {\\large $1.00$};\n\\node [red] (G) at (1,-0.75) {\\large $-3.0$};\n\\node [red] (H) at (1,-2) {\\large $1.0$};\n\\node [red] (I) at (1,-4.75) {\\large $-1.0$};\n\\node [red] (J) at (1,-6) {\\large $-2.0$};\n\\node [red] (K) at (1,-8.75) {\\large $2.0$};\n\\node [red] (L) at (1,-10) {\\large $3.0$};\n\\end{tikzpicture}\n\n\n\n\n\nGradients sum at outward branches. Consider the following computation graph:\n\n\nShow the code\n%%itikz --temp-dir --tex-packages=tikz --tikz-libraries=arrows --implicit-standalone\n\\begin{tikzpicture}[x=0.75pt,y=0.75pt,yscale=-1,xscale=1]\n%uncomment if require: \\path (0,211); %set diagram left start at 0, and has height of 211\n\n%Shape: Ellipse [id:dp4612472925724298] \n\\draw   (444.62,95) .. controls (444.62,81.19) and (455.38,70) .. (468.64,70) .. controls (481.91,70) and (492.66,81.19) .. (492.66,95) .. controls (492.66,108.81) and (481.91,120) .. (468.64,120) .. controls (455.38,120) and (444.62,108.81) .. (444.62,95) -- cycle ;\n%Shape: Ellipse [id:dp4844626229099638] \n\\draw   (299.33,31.5) .. controls (299.33,17.69) and (310.08,6.5) .. (323.35,6.5) .. controls (336.61,6.5) and (347.37,17.69) .. (347.37,31.5) .. controls (347.37,45.31) and (336.61,56.5) .. (323.35,56.5) .. controls (310.08,56.5) and (299.33,45.31) .. (299.33,31.5) -- cycle ;\n%Shape: Ellipse [id:dp2271780920027553] \n\\draw   (303.25,94.7) .. controls (303.25,80.89) and (314,69.7) .. (327.27,69.7) .. controls (340.53,69.7) and (351.29,80.89) .. (351.29,94.7) .. controls (351.29,108.51) and (340.53,119.7) .. (327.27,119.7) .. controls (314,119.7) and (303.25,108.51) .. (303.25,94.7) -- cycle ;\n%Shape: Ellipse [id:dp150108609534231] \n\\draw   (299.25,167.7) .. controls (299.25,153.89) and (310,142.7) .. (323.27,142.7) .. controls (336.53,142.7) and (347.29,153.89) .. (347.29,167.7) .. controls (347.29,181.51) and (336.53,192.7) .. (323.27,192.7) .. controls (310,192.7) and (299.25,181.51) .. (299.25,167.7) -- cycle ;\n%Straight Lines [id:da7844123205705824] \n\\draw    (347.37,31.5) -- (450.04,76.06) ;\n\\draw [shift={(452.79,77.25)}, rotate = 203.46] [fill={rgb, 255:red, 0; green, 0; blue, 0 }  ][line width=0.08]  [draw opacity=0] (6.25,-3) -- (0,0) -- (6.25,3) -- cycle    ;\n%Straight Lines [id:da814168086414518] \n\\draw    (351.29,94.7) -- (441.62,94.99) ;\n\\draw [shift={(444.62,95)}, rotate = 180.18] [fill={rgb, 255:red, 0; green, 0; blue, 0 }  ][line width=0.08]  [draw opacity=0] (6.25,-3) -- (0,0) -- (6.25,3) -- cycle    ;\n%Straight Lines [id:da7411937688169676] \n\\draw    (347.29,167.7) -- (446.35,110.75) ;\n\\draw [shift={(448.95,109.25)}, rotate = 150.1] [fill={rgb, 255:red, 0; green, 0; blue, 0 }  ][line width=0.08]  [draw opacity=0] (6.25,-3) -- (0,0) -- (6.25,3) -- cycle    ;\n%Shape: Circle [id:dp515320046458885] \n\\draw   (163,96) .. controls (163,82.19) and (174.19,71) .. (188,71) .. controls (201.81,71) and (213,82.19) .. (213,96) .. controls (213,109.81) and (201.81,121) .. (188,121) .. controls (174.19,121) and (163,109.81) .. (163,96) -- cycle ;\n%Straight Lines [id:da6219161786925074] \n\\draw    (492.66,95) -- (567,94.52) ;\n\\draw [shift={(570,94.5)}, rotate = 179.63] [fill={rgb, 255:red, 0; green, 0; blue, 0 }  ][line width=0.08]  [draw opacity=0] (6.25,-3) -- (0,0) -- (6.25,3) -- cycle    ;\n%Straight Lines [id:da5694521418691749] \n\\draw    (84.5,95.75) -- (160,95.99) ;\n\\draw [shift={(163,96)}, rotate = 180.18] [fill={rgb, 255:red, 0; green, 0; blue, 0 }  ][line width=0.08]  [draw opacity=0] (8.04,-3.86) -- (0,0) -- (8.04,3.86) -- (5.34,0) -- cycle    ;\n%Straight Lines [id:da08990804845355682] \n\\draw    (210.69,85.5) -- (296.86,31.4) ;\n\\draw [shift={(299.4,29.8)}, rotate = 147.88] [fill={rgb, 255:red, 0; green, 0; blue, 0 }  ][line width=0.08]  [draw opacity=0] (6.25,-3) -- (0,0) -- (6.25,3) -- cycle    ;\n%Straight Lines [id:da1505672958459916] \n\\draw    (212.61,96) -- (300.4,95.03) ;\n\\draw [shift={(303.4,95)}, rotate = 179.37] [fill={rgb, 255:red, 0; green, 0; blue, 0 }  ][line width=0.08]  [draw opacity=0] (6.25,-3) -- (0,0) -- (6.25,3) -- cycle    ;\n%Straight Lines [id:da23258128449735227] \n\\draw    (203,116.5) -- (296.36,167.17) ;\n\\draw [shift={(299,168.6)}, rotate = 208.49] [fill={rgb, 255:red, 0; green, 0; blue, 0 }  ][line width=0.08]  [draw opacity=0] (6.25,-3) -- (0,0) -- (6.25,3) -- cycle    ;\n\n% Text Node\n\\draw (464.08,84.4) node [anchor=north west][inner sep=0.75pt]    {\\huge $s$};\n% Text Node\n\\draw (317.25,18.9) node [anchor=north west][inner sep=0.75pt]    {\\huge $z^{1}$};\n% Text Node\n\\draw (321.65,82.6) node [anchor=north west][inner sep=0.75pt]    {\\huge $z^{2}$};\n% Text Node\n\\draw (317.65,155.6) node [anchor=north west][inner sep=0.75pt]    {\\huge $z^{3}$};\n% Text Node\n\\draw (365.04,44.2) node [anchor=north west][inner sep=0.75pt]  [color={rgb, 255:red, 0; green, 13; blue, 247 }  ,opacity=1 ]  {\\huge $\\frac{\\partial s}{\\partial z^{1}}$};\n% Text Node\n\\draw (365.52,94.3) node [anchor=north west][inner sep=0.75pt]  [color={rgb, 255:red, 0; green, 13; blue, 247 }  ,opacity=1 ]  {\\huge $\\frac{\\partial s}{\\partial z^{2}}$};\n% Text Node\n\\draw (366.72,154) node [anchor=north west][inner sep=0.75pt]  [color={rgb, 255:red, 0; green, 13; blue, 247 }  ,opacity=1 ]  {\\huge $\\frac{\\partial s}{\\partial z^{3}}$};\n% Text Node\n\\draw (183.5,85.4) node [anchor=north west][inner sep=0.75pt]    {\\huge $a$};\n% Text Node\n\\draw (304.78,21.4) node [anchor=north west][inner sep=0.75pt]  [font=\\tiny,color={rgb, 255:red, 0; green, 13; blue, 247 }  ,opacity=1 ]  {\\normalsize $\\frac{\\partial z^{1}}{\\partial a}$};\n% Text Node\n\\draw (305.82,84.6) node [anchor=north west][inner sep=0.75pt]  [font=\\tiny,color={rgb, 255:red, 0; green, 13; blue, 247 }  ,opacity=1 ]  {\\normalsize $\\frac{\\partial z^{2}}{\\partial a}$};\n% Text Node\n\\draw (303.26,156.6) node [anchor=north west][inner sep=0.75pt]  [font=\\tiny,color={rgb, 255:red, 0; green, 13; blue, 247 }  ,opacity=1 ]  {\\normalsize $\\frac{\\partial z^{3}}{\\partial a}$};\n% Text Node\n\\draw (251.38,53.4) node [anchor=north west][inner sep=0.75pt]  [font=\\tiny,color={rgb, 255:red, 0; green, 13; blue, 247 }  ,opacity=1 ]  {\\normalsize $\\frac{\\partial s}{\\partial z^{1}} \\cdot \\frac{\\partial z^{1}}{\\partial a}$};\n% Text Node\n\\draw (249.38,99.8) node [anchor=north west][inner sep=0.75pt]  [font=\\tiny,color={rgb, 255:red, 0; green, 13; blue, 247 }  ,opacity=1 ]  {\\normalsize $\\frac{\\partial s}{\\partial z^{2}} \\cdot \\frac{\\partial z^{2}}{\\partial a}$};\n% Text Node\n\\draw (245.78,165.8) node [anchor=north west][inner sep=0.75pt]  [font=\\tiny,color={rgb, 255:red, 0; green, 13; blue, 247 }  ,opacity=1 ]  {\\normalsize $\\frac{\\partial s}{\\partial z^{3}} \\cdot \\frac{\\partial z^{3}}{\\partial a}$};\n\n\n\\end{tikzpicture}\n\n\n\n\n\nThe upstream gradient for the node \\(a\\) is \\(\\frac{ds}{da}\\). By the law of total derivatives:\n\\[\\begin{align*}\n\\frac{ds}{da} = \\frac{\\partial s}{\\partial z^1} \\cdot \\frac{\\partial z^1}{\\partial a} + \\frac{\\partial s}{\\partial z^2} \\cdot \\frac{\\partial z^2}{\\partial a} + \\frac{\\partial s}{\\partial z^3} \\cdot \\frac{\\partial z^3}{\\partial a}\n\\end{align*}\\]"
  },
  {
    "objectID": "posts/backpropogation/index.html#backprop-for-a-single-neuron---a-python-implementation",
    "href": "posts/backpropogation/index.html#backprop-for-a-single-neuron---a-python-implementation",
    "title": "Backpropogation",
    "section": "Backprop for a single neuron - a python implementation",
    "text": "Backprop for a single neuron - a python implementation\nWe can write a naive implementation for the backprop algorithm for a single neuron.\n\nimport numpy as np\n\nweights = np.array([-3.0, -1.0, 2.0])\nbias = 1.0\ninputs = np.array([1.0, -2.0, 3.0])\ntarget_output = 0.0\nlearning_rate = 0.001\n\n\ndef relu(x):\n    return np.maximum(x, 0)\n\n\ndef relu_derivative(x):\n    return np.where(x &gt; 0, 1.0, 0.0)\n\n\nfor iter in range(200):\n    # Forward pass\n    z = np.dot(weights, inputs) + bias\n    a = relu(z)\n    loss = (a - target_output) ** 2\n\n    # Backward pass\n    dloss_da = 2 * (a - target_output)\n    dloss_dz = dloss_da * relu_derivative(z)\n    dz_dx = weights\n    dz_dw = inputs\n    dz_db = 1.0\n    dloss_dx = dloss_dz * dz_dx\n    dloss_dw = dloss_dz * dz_dw\n    dloss_db = dloss_dz * dz_db\n\n    # Update the weights and bias\n    weights -= learning_rate * dloss_dw\n    bias -= learning_rate * dloss_db\n\n    # print the loss for this iteration\n    if (iter + 1) % 10 == 0:\n        print(f\"Iteration {iter + 1}, loss: {loss}\")\n\nprint(\"Final weights : \", weights)\nprint(\"Final bias : \", bias)\n\nIteration 10, loss: 20.80624545154949\nIteration 20, loss: 11.314318574097976\nIteration 30, loss: 6.152662434665503\nIteration 40, loss: 3.345783025909011\nIteration 50, loss: 1.8194178821496518\nIteration 60, loss: 0.9893891517327431\nIteration 70, loss: 0.5380242236653578\nIteration 80, loss: 0.29257452918677535\nIteration 90, loss: 0.1591003738562249\nIteration 100, loss: 0.08651788326054576\nIteration 110, loss: 0.04704793547908108\nIteration 120, loss: 0.025584401159906914\nIteration 130, loss: 0.013912652617925996\nIteration 140, loss: 0.007565621788733219\nIteration 150, loss: 0.004114142329436494\nIteration 160, loss: 0.00223724732474303\nIteration 170, loss: 0.0012166024389232565\nIteration 180, loss: 0.0006615815238773228\nIteration 190, loss: 0.0003597642900693548\nIteration 200, loss: 0.00019563778572677352\nFinal weights :  [-3.3990955  -0.20180899  0.80271349]\nFinal bias :  0.6009044964039992"
  },
  {
    "objectID": "posts/backpropogation/index.html#backprop-for-a-layer-of-neurons",
    "href": "posts/backpropogation/index.html#backprop-for-a-layer-of-neurons",
    "title": "Backpropogation",
    "section": "Backprop for a layer of neurons",
    "text": "Backprop for a layer of neurons\nWe are now in a position to write a naive implementation of the backprop algorithm for a layer of neurons.\nA neural network with a single hidden layer is shown below.\n\n\n\nbackprop\n\n\nLet \\(\\mathcal{L}\\) be a loss function of a neural network to minimize. Let \\(x \\in \\mathbf{R}^{d_0}\\) be a single sample(input). Let \\(d_{l}\\) be number of neurons(inputs) in layer \\(l\\). In our example, \\(x \\in \\mathbf{R}^4\\).\nLet’s derive expressions for all the derivatives we want to compute.\n\nGradient of the loss with respect to \\(\\hat{y}\\)\nThe gradient of the loss function \\(\\mathcal{L}\\) with respect to \\(\\hat{y}\\) is:\n\\[\\begin{align*}\n\\frac{\\partial \\mathcal{L}}{\\partial \\hat{y}} &= 2*(\\hat{y} - y)\n\\end{align*}\\]\n\n\nGradient of the loss with respect to \\(a\\)\nThe gradient of \\(\\hat{y}\\) with respect to \\(a_1, a_2, a_3\\) is:\n\\[\\begin{align*}\n\\frac{\\partial \\hat{y}}{\\partial a} &= \\left[\\frac{\\partial \\hat{y}}{\\partial a_1}, \\frac{\\partial \\hat{y}}{\\partial a_2}, \\frac{\\partial \\hat{y}}{\\partial a_3}\\right] = [1, 1, 1]\n\\end{align*}\\]\nSo, by chain rule:\n\\[\\begin{align*}\n\\frac{\\partial \\mathcal{L}}{\\partial a} &= \\left[\\frac{\\partial \\mathcal{L}}{\\partial a_1}, \\frac{\\partial \\mathcal{L}}{\\partial a_2}, \\frac{\\partial \\mathcal{L}}{\\partial a_3}\\right] \\\\\n&=\\left[\\frac{\\partial \\mathcal{L}}{\\partial \\hat{y}} \\cdot \\frac{\\partial \\hat{y}}{\\partial a_1}, \\frac{\\partial \\mathcal{L}}{\\partial \\hat{y}} \\cdot \\frac{\\partial \\hat{y}}{\\partial a_2}, \\frac{\\partial \\mathcal{L}}{\\partial \\hat{y}} \\cdot \\frac{\\partial \\hat{y}}{\\partial a_3}\\right] \\\\\n&= \\frac{\\partial \\mathcal{L}}{\\partial \\hat{y}} \\cdot \\frac{\\partial \\hat{y}}{\\partial a}\n\\end{align*}\\]\nThis vector has the shape [1,layer_width]. In this example, it’s dimensions are (1,3).\n\n\nGradient of the loss with respect to \\(z\\)\nIn our example, \\(a_1 = max(z_1,0)\\), \\(a_2 = max(z_2,0)\\) and \\(a_3 = max(z_3,0)\\). Consequently, the derivative:\n\\[\\begin{align*}\n\\frac{\\partial a}{\\partial z} &= \\left[\\frac{\\partial a_1}{\\partial z_1}, \\frac{\\partial a_2}{\\partial z_2}, \\frac{\\partial a_3}{\\partial z_3}\\right]\\\\\n&= \\left[1_{(z_1 &gt; 0)}, 1_{(z_2 &gt; 0)}, 1_{(z_3 &gt; 0)}\\right]\n\\end{align*}\\]\nAgain this vector has shape [1,layer_width], which in our example equals (1,3).\nBy the chain rule:\n\\[\\begin{align*}\n\\frac{\\partial \\mathcal{L}}{\\partial z} &= \\left[\\frac{\\partial \\mathcal{L}}{\\partial a_1} \\cdot \\frac{\\partial a_1}{\\partial z_1}, \\frac{\\partial \\mathcal{L}}{\\partial a_2} \\cdot \\frac{\\partial a_2}{\\partial z_2}, \\frac{\\partial \\mathcal{L}}{\\partial a_3} \\cdot \\frac{\\partial a_3}{\\partial z_3}\\right]\\\\\n&= \\frac{\\partial \\mathcal{L}}{\\partial a} \\odot \\frac{\\partial \\mathcal{a}}{\\partial z}\n\\end{align*}\\]\nwhere \\(\\odot\\) denotes the element wise product of the two vectors. The gradient of the loss with respect to \\(z\\), is also a vector of shape [1,layer_width].\n\n\nGradient of the loss with respect to weights \\(W\\)\nSince\n\\[\\begin{align*}\nz_1 &= w_{11}x_1 + w_{12}x_2 + w_{13}x_3 + w_{14}x_4 + b_1 \\\\\nz_2 &= w_{21}x_1 + w_{22}x_2 + w_{23}x_3 + w_{24}x_4 + b_2 \\\\\nz_3 &= w_{31}x_1 + w_{32}x_2 + w_{23}x_3 + w_{24}x_4 + b_3\n\\end{align*}\\]\nit follows that: \\[\\begin{align*}\n\\frac{\\partial z_i}{\\partial w_{ij}} = x_j\n\\end{align*}\\]\nNow,\n\\[\\begin{align*}\n\\frac{\\partial \\mathcal{L}}{\\partial w_{ij}} &= \\frac{\\partial \\mathcal{L}}{\\partial z_i} \\cdot \\frac{\\partial z_i}{\\partial w_{ij}} \\\\\n&= \\frac{\\partial \\mathcal{L}}{\\partial z_i} \\cdot x_j\n\\end{align*}\\]\nIn other words:\n\\[\\begin{align*}\n\\begin{bmatrix}\n\\frac{\\partial \\mathcal{L}}{\\partial w_{11}} \\\\\n\\frac{\\partial \\mathcal{L}}{\\partial w_{12}} \\\\\n\\frac{\\partial \\mathcal{L}}{\\partial w_{13}} \\\\\n\\frac{\\partial \\mathcal{L}}{\\partial w_{14}}\n\\end{bmatrix}\n&= \\begin{bmatrix}\n\\frac{\\partial \\mathcal{L}}{\\partial z_1} \\cdot \\frac{\\partial z_1}{\\partial w_{11}}\\\\\n\\frac{\\partial \\mathcal{L}}{\\partial z_1} \\cdot \\frac{\\partial z_1}{\\partial w_{12}}\\\\\n\\frac{\\partial \\mathcal{L}}{\\partial z_1} \\cdot \\frac{\\partial z_1}{\\partial w_{13}}\\\\\n\\frac{\\partial \\mathcal{L}}{\\partial z_1} \\cdot \\frac{\\partial z_1}{\\partial w_{14}}\n\\end{bmatrix}\\\\\n&= \\begin{bmatrix}\n\\frac{\\partial \\mathcal{L}}{\\partial z_1} \\cdot x_1\\\\\n\\frac{\\partial \\mathcal{L}}{\\partial z_1} \\cdot x_2\\\\\n\\frac{\\partial \\mathcal{L}}{\\partial z_1} \\cdot x_3\\\\\n\\frac{\\partial \\mathcal{L}}{\\partial z_1} \\cdot x_4\n\\end{bmatrix}\n\\end{align*}\\]\nPutting this together, we define the jacobian matrix \\(\\frac{\\partial \\mathcal{L}}{\\partial W}\\) as:\n\\[\\begin{align*}\n\\frac{\\partial \\mathcal{L}}{\\partial W}&=\\begin{bmatrix}\n\\frac{\\partial \\mathcal{L}}{\\partial w_{11}} & \\frac{\\partial \\mathcal{L}}{\\partial w_{21}} & \\frac{\\partial \\mathcal{L}}{\\partial w_{31}} & \\frac{\\partial \\mathcal{L}}{\\partial w_{41}} \\\\\n\\frac{\\partial \\mathcal{L}}{\\partial w_{12}} & \\frac{\\partial \\mathcal{L}}{\\partial w_{22}} & \\frac{\\partial \\mathcal{L}}{\\partial w_{32}} & \\frac{\\partial \\mathcal{L}}{\\partial w_{42}} \\\\\n\\frac{\\partial \\mathcal{L}}{\\partial w_{13}} & \\frac{\\partial \\mathcal{L}}{\\partial w_{23}} & \\frac{\\partial \\mathcal{L}}{\\partial w_{33}} & \\frac{\\partial \\mathcal{L}}{\\partial w_{43}} \\\\\n\\frac{\\partial \\mathcal{L}}{\\partial w_{14}} & \\frac{\\partial \\mathcal{L}}{\\partial w_{24}} & \\frac{\\partial \\mathcal{L}}{\\partial w_{34}} & \\frac{\\partial \\mathcal{L}}{\\partial w_{44}} \\\\\n\\end{bmatrix}\\\\\n&= \\begin{bmatrix}\n\\frac{\\partial \\mathcal{L}}{\\partial z_1} \\cdot \\frac{\\partial z_1}{\\partial w_{11}} & \\frac{\\partial \\mathcal{L}}{\\partial z_2} \\cdot \\frac{\\partial z_2}{\\partial w_{21}} & \\frac{\\partial \\mathcal{L}}{\\partial z_3} \\cdot \\frac{\\partial z_3}{\\partial w_{31}}\\\\\n\\frac{\\partial \\mathcal{L}}{\\partial z_1} \\cdot \\frac{\\partial z_1}{\\partial w_{12}} & \\frac{\\partial \\mathcal{L}}{\\partial z_2} \\cdot \\frac{\\partial z_2}{\\partial w_{22}} & \\frac{\\partial \\mathcal{L}}{\\partial z_3} \\cdot \\frac{\\partial z_3}{\\partial w_{32}}\\\\\n\\frac{\\partial \\mathcal{L}}{\\partial z_1} \\cdot \\frac{\\partial z_1}{\\partial w_{13}} & \\frac{\\partial \\mathcal{L}}{\\partial z_2} \\cdot \\frac{\\partial z_2}{\\partial w_{23}} & \\frac{\\partial \\mathcal{L}}{\\partial z_3} \\cdot \\frac{\\partial z_3}{\\partial w_{33}}\\\\\n\\frac{\\partial \\mathcal{L}}{\\partial z_1} \\cdot \\frac{\\partial z_1}{\\partial w_{14}} & \\frac{\\partial \\mathcal{L}}{\\partial z_2} \\cdot \\frac{\\partial z_2}{\\partial w_{24}} & \\frac{\\partial \\mathcal{L}}{\\partial z_3} \\cdot \\frac{\\partial z_3}{\\partial w_{34}}\n\\end{bmatrix}\\\\\n&= \\begin{bmatrix}\n\\frac{\\partial \\mathcal{L}}{\\partial z_1} \\cdot x_1 & \\frac{\\partial \\mathcal{L}}{\\partial z_2} \\cdot x_1 & \\frac{\\partial \\mathcal{L}}{\\partial z_3} \\cdot x_1 \\\\\n\\frac{\\partial \\mathcal{L}}{\\partial z_1} \\cdot x_2 & \\frac{\\partial \\mathcal{L}}{\\partial z_2} \\cdot x_2 & \\frac{\\partial \\mathcal{L}}{\\partial z_3} \\cdot x_2\\\\\n\\frac{\\partial \\mathcal{L}}{\\partial z_1} \\cdot x_3 & \\frac{\\partial \\mathcal{L}}{\\partial z_2} \\cdot x_3 & \\frac{\\partial \\mathcal{L}}{\\partial z_3} \\cdot x_3\\\\\n\\frac{\\partial \\mathcal{L}}{\\partial z_1} \\cdot x_4 & \\frac{\\partial \\mathcal{L}}{\\partial z_2} \\cdot x_4 & \\frac{\\partial \\mathcal{L}}{\\partial z_3} \\cdot x_4\n\\end{bmatrix}\\\\\n&= \\begin{bmatrix}\nx_1 \\\\\nx_2 \\\\\nx_3 \\\\\nx_4\n\\end{bmatrix} \\begin{bmatrix}\n\\frac{\\partial \\mathcal{L}}{\\partial z_1} & \\frac{\\partial \\mathcal{L}}{\\partial z_2} & \\frac{\\partial \\mathcal{L}}{\\partial z_3}\n\\end{bmatrix} \\\\\n&= X^T \\cdot \\frac{\\partial \\mathcal{L}}{\\partial z}\n\\end{align*}\\]\nThe dimensions of \\(X^T\\) and \\(\\frac{\\partial \\mathcal{L}}{\\partial z}\\) are [input_size,1] and [1,layer_width] respectively. Therefore, \\(\\frac{\\partial \\mathcal{L}}{\\partial W}\\) will be of dimensions [input_size,layer_width]. In our example this equals (4,3).\nThe first column of \\(X^T \\cdot \\frac{\\partial \\mathcal{L}}{\\partial z}\\) gives the derivative with respect to the first neuron’s weights, the second column gives the derivative with respect to the second neuron’s weights and so forth.\n\n\nGradient of the loss with respect to the biases \\(b\\)\nSince\n\\[\\begin{align*}\n\\frac{\\partial z}{\\partial b} &= \\left[\\frac{\\partial z_1}{\\partial b_1}, \\frac{\\partial z_2}{\\partial b_2}, \\frac{\\partial z_3}{\\partial b_3}\\right]\\\\\n&= [1,1,1]\n\\end{align*}\\]\nIt follows that:\n\\[\\begin{align*}\n\\frac{\\partial \\mathcal{L}}{\\partial b} &= \\left[\\frac{\\partial \\mathcal{L}}{\\partial b_1}, \\frac{\\partial \\mathcal{L}}{\\partial b_2}, \\frac{\\partial \\mathcal{L}}{\\partial b_3}\\right]\\\\\n&= \\left[\\frac{\\partial \\mathcal{L}}{\\partial z_1} \\cdot \\frac{\\partial z_1}{\\partial b_1}, \\frac{\\partial \\mathcal{L}}{\\partial b_2} \\cdot \\frac{\\partial z_2}{\\partial b_21}, \\frac{\\partial \\mathcal{L}}{\\partial b_3}\\cdot \\cdot \\frac{\\partial z_3}{\\partial b_3}\\right]\\\\\n&=\\left[\\frac{\\partial \\mathcal{L}}{\\partial z_1} \\cdot 1, \\frac{\\partial \\mathcal{L}}{\\partial b_2} \\cdot 1, \\frac{\\partial \\mathcal{L}}{\\partial b_3}\\cdot \\cdot 1\\right]\\\\\n&= \\frac{\\partial \\mathcal{L}}{\\partial z}\n\\end{align*}\\]\n\n\nNaive Python implementation\n\nimport numpy as np\n\ninputs = np.array([1, 2, 3, 4])\nweights = np.array([[0.1, 0.2, 0.3, 0.4], [0.5, 0.6, 0.7, 0.8], [0.9, 1.0, 1.1, 1.2]])\n\nbiases = np.array([0.1, 0.2, 0.3])\n\n# Learning rate\nlearning_rate = 0.001\n\n\n# ReLU Activation function and its derivative\ndef relu(x):\n    return np.maximum(x, 0)\n\n\ndef relu_derivative(z):\n    return np.where(z &gt; 0.0, 1.0, 0.0)\n\n\nfor iter in range(200):\n    # Forward pass\n    z = np.dot(weights, inputs) + biases\n    a = relu(z)\n    y_pred = np.sum(a)\n    y_true = 0.0\n    loss = (y_pred - y_true) ** 2\n\n    # Backward pass\n    # Gradient of loss with respect to y_pred\n    dloss_dy = 2 * (y_pred - y_true)\n\n    # Gradient of y_pred with respect to a\n    dy_da = np.ones_like(a)\n\n    # Gradient of the activation function with respect to z\n    da_dz = relu_derivative(z)\n\n    # Gradient of z with respect to the weights\n    dz_dw = inputs\n\n    # Gradient of z with respect to inputs\n    dz_dx = weights\n\n    # Gradient of loss with respect to a\n    dloss_da = dloss_dy * dy_da\n\n    # Gradient of loss with respect to z\n    dloss_dz = dloss_da * da_dz\n\n    # Gradient of loss with respect to the weights\n    dloss_dw = np.outer(dloss_dz, dz_dw)\n\n    # Gradient of loss with respect to biases\n    dloss_db = dloss_dz\n\n    weights -= learning_rate * dloss_dw\n    biases -= learning_rate * dloss_db\n\n    if (iter + 1) % 20 == 0:\n        print(f\"Iteration {iter+1}, loss = {loss}\")\n\nprint(\"Final weights : \", weights)\nprint(\"Final bias : \", biases)\n\nIteration 20, loss = 6.057433318678514\nIteration 40, loss = 0.4681684867419663\nIteration 60, loss = 0.03618392815029436\nIteration 80, loss = 0.0027965928794077364\nIteration 100, loss = 0.00021614380010564146\nIteration 120, loss = 1.670537841532316e-05\nIteration 140, loss = 1.2911296454618448e-06\nIteration 160, loss = 9.978916489916474e-08\nIteration 180, loss = 7.712531012091791e-09\nIteration 200, loss = 5.96088109107831e-10\nFinal weights :  [[-0.00698895 -0.01397789 -0.02096684 -0.02795579]\n [ 0.25975286  0.11950572 -0.02074143 -0.16098857]\n [ 0.53548461  0.27096922  0.00645383 -0.25806156]]\nFinal bias :  [-0.00698895 -0.04024714 -0.06451539]"
  },
  {
    "objectID": "posts/backpropogation/index.html#backprop-with-a-batch-of-inputs",
    "href": "posts/backpropogation/index.html#backprop-with-a-batch-of-inputs",
    "title": "Backpropogation",
    "section": "Backprop with a batch of inputs",
    "text": "Backprop with a batch of inputs\nLet \\(x\\) be a batch of inputs of dimensions [batch_size,input_size]. Consider\n\nx = np.array(\n    [\n        [1, 2, 3, 2.5],\n        [2, 5, -1, 2],\n        [-1.5, 2.7, 3.3, -0.8]\n    ]\n)\n\nof shape (3,4). Each sample will give one loss. Hence, the total loss \\(\\mathcal{L} = L_1 + L_2 + L_3\\).\n\nGradient of the loss with respect to weights \\(w\\)\nI am going to denote use the following convention for the \\(z\\)’s:\n\\[\\begin{align*}\n\\begin{array}[c|ccc]\n\\text{} & \\text{Neuron}-1 & \\text{Neuron}-2 & \\text{Neuron}-3\\\\\n\\hline\n\\text{Sample}-1 & z_{11} & z_{12} & z_{13} \\\\\n\\text{Sample}-2 & z_{21} & z_{22} & z_{23} \\\\\n\\text{Sample}-3 & z_{31} & z_{32} & z_{33} \\\\\n\\text{Sample}-4 & z_{41} & z_{42} & z_{43}\n\\end{array}\n\\end{align*}\\]\nIn this case \\(\\frac{d\\mathcal{L}}{dz}\\) will be a matrix of partial derivatives of shape [batch_size,layer_width].\nI can write:\n\\[\\begin{align*}\n\\frac{\\partial \\mathcal{L}}{\\partial w_{11}} &= \\frac{\\partial L_1}{\\partial w_{11}} + \\frac{\\partial L_2}{\\partial w_{11}} + \\frac{\\partial L_3}{\\partial w_{11}} \\\\\n&= \\frac{\\partial L_1}{\\partial z_{11}}\\cdot \\frac{\\partial z_{11}}{\\partial w_{11}} + \\frac{\\partial L_2}{\\partial z_{21}}\\cdot\\frac{\\partial z_{21}}{\\partial w_{11}} + \\frac{\\partial L_3}{\\partial z_{31}} \\cdot \\frac{\\partial z_{31}}{\\partial w_{11}}\\\\\n&=\\frac{\\partial L_1}{\\partial z_{11}}\\cdot x_{11} + \\frac{\\partial L_2}{\\partial z_{21}}\\cdot x_{21} + \\frac{\\partial L_3}{\\partial z_{31}} \\cdot x_{31}\n\\end{align*}\\]\nIf you work out the derivatives of the loss function with respect to each of the weights, you would find:\n\\[\\begin{align*}\n\\frac{\\partial \\mathcal{L}}{\\partial W} &= X^T \\cdot \\frac{\\partial \\mathcal{L}}{\\partial z}\n\\end{align*}\\]\nX.T has shape [input_size,batch_size] and dloss_dz has shape [batch_size,layer_width], so the matrix product will have dimensions [input_size,layer_width].\n\n\nGradient of the loss with respect to the biases \\(b\\)\nConsider again:\n\\[\\begin{align*}\n\\frac{\\partial \\mathcal{L}}{\\partial b_1} &= \\frac{\\partial L}{\\partial z_{11}} \\cdot \\frac{\\partial z_{11}}{\\partial b_1} + \\frac{\\partial L}{\\partial z_{21}} \\cdot \\frac{\\partial z_{21}}{\\partial b_1} + \\frac{\\partial L}{\\partial z_{31}} \\cdot \\frac{\\partial z_{31}}{\\partial b_1} \\\\\n&= \\frac{\\partial L}{\\partial z_{11}} \\cdot 1 + \\frac{\\partial L}{\\partial z_{21}} \\cdot 1 + \\frac{\\partial L}{\\partial z_{31}} \\cdot 1\n\\end{align*}\\]\nSo, to find the partial derivative of the loss with respect to \\(b_1\\), we will just look at the partial derivatives of the loss with respect to the first neuron and then add them up.\nIn python, we would write this as\ndloss_dbiases = np.sum(dloss_dz, axis=0, keepdims=True)\n\n\nGradient of the loss with respect to the inputs\nThe gradients of the loss with respect to the weights in the layer \\(l\\), require the gradients of the loss with respect to the inputs in layer \\(l+1\\). It’s easy to see that:\n\\[\\begin{align*}\n\\frac{\\partial L}{\\partial w_{11}^{(l)}} &= \\frac{\\partial L}{\\partial x_1^{(l+1)}}\\cdot \\frac{\\partial x_1^{(l+1)}}{\\partial z_{1}^{l}} \\cdot \\frac{\\partial z_1^{(l)}}{\\partial w_{11}^{(l)}}\n\\end{align*}\\]\nWhat is \\(\\frac{\\partial \\mathcal{L}}{\\partial x_1}\\), \\(\\frac{\\partial \\mathcal{L}}{\\partial x_2}\\), \\(\\frac{\\partial \\mathcal{L}}{\\partial x_3}\\) and \\(\\frac{\\partial \\mathcal{L}}{\\partial x_4}\\)?\nBy the chain rule:\n\\[\\begin{align*}\n\\frac{\\partial \\mathcal{L}}{\\partial x_1} &= \\frac{\\partial L}{\\partial z_1}\\cdot \\frac{\\partial z_1}{\\partial x_1} +  \\frac{\\partial L}{\\partial z_2}\\cdot \\frac{\\partial z_2}{\\partial x_1} +  \\frac{\\partial L}{\\partial z_3}\\cdot \\frac{\\partial z_3}{\\partial x_1} \\\\\n&= \\frac{\\partial L}{\\partial z_1}\\cdot w_{11} +  \\frac{\\partial L}{\\partial z_2}\\cdot w_{21} +  \\frac{\\partial L}{\\partial z_3}\\cdot w_{31}\n\\end{align*}\\]\nConsequently,\n\\[\\begin{align*}\n\\begin{bmatrix}\n\\frac{\\partial \\mathcal{L}}{\\partial x_1} & \\frac{\\partial \\mathcal{L}}{\\partial x_2} & \\frac{\\partial \\mathcal{L}}{\\partial x_3} & \\frac{\\partial \\mathcal{L}}{\\partial x_4}\n\\end{bmatrix} &=\n\\begin{bmatrix}\n\\frac{\\partial L}{\\partial z_1} & \\frac{\\partial L}{\\partial z_2} & \\frac{\\partial L}{\\partial z_3}\n\\end{bmatrix}\n\\begin{bmatrix}\nw_{11} & w_{12} & w_{13} & w_{14}\\\\\nw_{21} & w_{22} & w_{23} & w_{24}\\\\\nw_{31} & w_{32} & w_{33} & w_{34}\n\\end{bmatrix}\\\\\n\\frac{\\partial \\mathcal{L}}{\\partial x} &= \\frac{\\partial L}{\\partial z} \\cdot W\n\\end{align*}\\]\nWhat if we have a batch of input data of 3 examples? In such case, \\(\\frac{\\partial \\mathcal{L}}{\\partial z}\\) will have shape (3,3) and \\(W\\) will have shape (3,4). So, we can multiply them and the result would be (3,4)."
  },
  {
    "objectID": "posts/backpropogation/index.html#adding-backward-to-denselayer",
    "href": "posts/backpropogation/index.html#adding-backward-to-denselayer",
    "title": "Backpropogation",
    "section": "Adding backward() to DenseLayer",
    "text": "Adding backward() to DenseLayer\nWe will now add backward pass code to the DenseLayer and ReLUActivation classes.\n\nfrom nnfs.datasets import spiral_data\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport nnfs\n\nnnfs.init()\n\n\nclass DenseLayer:\n    def __init__(self, n_inputs, n_neurons):\n        self.width = n_neurons\n        # Weight vectors per neuron\n        self.weights = np.array(\n            [[0.1, 0.2, 0.3, 0.4], [0.5, 0.6, 0.7, 0.8], [0.9, 1.0, 1.1, 1.2]]\n        )\n        self.biases = np.array([0.1, 0.2, 0.3])\n\n    def forward(self, inputs):\n        self.inputs = inputs\n        self.output = np.dot(inputs, self.weights.T) + self.biases\n\n    def backward(self, dloss_dz):\n        self.dloss_dz = dloss_dz\n        self.dz_dweights = self.inputs\n        self.dz_dbiases = np.ones_like(self.inputs)\n        self.dz_dinputs = self.weights\n        self.dloss_dweights = np.dot(self.inputs.T, self.dloss_dz).T\n        self.dloss_dbiases = np.sum(self.dloss_dz, axis=0, keepdims=True)\n        self.dloss_dinputs = np.dot(self.dloss_dz, self.dz_dinputs)\n\n\nclass ReLUActivation:\n\n    # Forward pass\n    def forward(self, inputs):\n        # Calculate output values from the inputs\n        self.inputs = inputs\n        self.output = np.maximum(0, inputs)\n\n    # Backward pass\n    def backward(self, dloss_da):\n        self.dloss_da = dloss_da\n        self.da_dz = np.where(self.inputs &gt; 0.0, 1.0, 0.0)\n        self.dloss_dz = self.dloss_da * self.da_dz\n\n\n# Create dataset\nX = np.array([[1, 2, 3, 2.5], [2, 5, -1, 2], [-1.5, 2.7, 3.3, -0.8]])\n\n# Create a dense layer with 4 input features and 3 output values\ndense1 = DenseLayer(4, 3)\nrelu = ReLUActivation()\n\n# Perform a forward pass of our training data through this layer\ndense1.forward(X)\nrelu.forward(dense1.output)\n\n# Calculate loss\ny_pred = np.sum(relu.output)\ny_true = 0.0\nloss = (y_pred - y_true) ** 2\n\n# Gradient of the loss with respect to y\ndloss_dy = 2 * (y_pred - y_true)\ndy_da = np.ones_like(relu.output)\ndloss_da = dloss_dy * dy_da\n\nrelu.backward(dloss_da)\ndense1.backward(relu.dloss_dz)\nprint(f\"dloss_dweights = {dense1.dloss_dweights}\")\nprint(f\"dloss_dbiases = {dense1.dloss_dbiases}\")\nprint(f\"dloss_dinputs = {dense1.dloss_dinputs}\")\n\ndloss_dweights = [[124.560005 805.48804  440.112    307.24802 ]\n [124.560005 805.48804  440.112    307.24802 ]\n [124.560005 805.48804  440.112    307.24802 ]]\ndloss_dbiases = [[249.12000303 249.12000303 249.12000303]]\ndloss_dinputs = [[124.560005 149.472    174.384    199.296   ]\n [124.560005 149.472    174.384    199.296   ]\n [124.560005 149.472    174.384    199.296   ]]"
  },
  {
    "objectID": "posts/backpropogation/index.html#categorical-cross-entropy-loss-derivative",
    "href": "posts/backpropogation/index.html#categorical-cross-entropy-loss-derivative",
    "title": "Backpropogation",
    "section": "Categorical cross-entropy loss derivative",
    "text": "Categorical cross-entropy loss derivative\nThe cross-entropy loss of the \\(i\\)-th sample is given by:\n\\[\\begin{align*}\nL_i = -\\sum_k y_{ik}log(\\hat{y}_ik)\n\\end{align*}\\]\nDifferentiating with respect to \\(\\hat{y}_{ij}\\), we have:\n\\[\\begin{align*}\n\\frac{\\partial L_i}{\\partial \\hat{y}_{ij}} &= -\\frac{\\partial}{\\partial \\hat{y}_{ik}} \\left[\\sum_k y_{ik}\\log (\\hat{y}_{ik})\\right] \\\\\n&= -y_{ij} \\cdot \\frac{\\partial }{\\partial \\hat{y}_{ij}} \\log (\\hat{y}_{ij})\\\\\n&= -\\frac{y_{ij}}{\\hat{y}_{ij}}\n\\end{align*}\\]\n\nAdding backward() to CategoricalCrossEntropyLoss\n\n# Cross-Entropy loss\nclass CategoricalCrossEntropyLoss(Loss):\n\n    # Forward pass\n    def forward(self, y_pred, y_true):\n        num_samples = len(y_pred)\n\n        # Clip data to prevent division by 0\n        # Clip both sides to not drag mean towards any value\n        epsilon = 1e-7\n        y_pred_clipped = np.clip(y_pred, epsilon, 1 - epsilon)\n\n        # If categorical labels\n        if len(y_true.shape) == 1:\n            correct_confidences = y_pred_clipped[range(len(y_pred)), y_true]\n        # else if one-hot encoding\n        elif len(y_true.shape) == 2:\n            correct_confidences = np.sum(y_pred_clipped * y_true, axis=1)\n\n        neg_log = -np.log(correct_confidences)\n        return neg_log\n\n    # Backward pass\n    def backward(self, y_pred, y_true):\n\n        # number of samples\n        batch_size = len(y_pred)\n\n        # number of labels\n        num_labels = len(y_pred[0])\n\n        # If labels are sparse, turn them into a one-hot vector\n        if len(y_true.shape) == 1:\n            y_true = np.eye(num_labels)[y_true]\n\n        # Calculate gradient\n        self.dloss_da = -y_true / y_pred\n\n        # Normalize the gradient\n        self.dloss_da = self.dloss_da / batch_size"
  },
  {
    "objectID": "posts/backpropogation/index.html#softmax-activation-function-derivative",
    "href": "posts/backpropogation/index.html#softmax-activation-function-derivative",
    "title": "Backpropogation",
    "section": "Softmax Activation function derivative",
    "text": "Softmax Activation function derivative\nWe are interested to calculate the derivative of the softmax function. The softmax activation function is defined as:\n\\[\\begin{align*}\nS_{i,j} &= \\frac{e^{z_{i,j}}}{\\sum_{l=1}^{d_l} e^{z_{i,l}}}\n\\end{align*}\\]\nwhere \\(S_{i,j}\\) denotes the output of the \\(j\\)-th neuron for the \\(i\\)-th sample. Thus, \\(S_{i,j} = f(z_{i,1},\\ldots,z_{i,d_l})\\). Let’s calculate the partial derivative of \\(S_{i,j}\\) with respect to \\(z_{i,k}\\).\nBy the \\(u/v\\) rule:\n\\[\\begin{align*}\n\\frac{\\partial S_{i,j}}{\\partial z_{i,k}} &= \\frac{\\sum_{l=1}^{d_l} e^{z_{i,l}} \\cdot \\frac{\\partial e^{z_{i,j}}}{\\partial z_{i,k}}-e^{z_{i,j}} \\cdot \\frac{\\partial}{\\partial z_{i,k}} \\sum_{l=1}^{d_l} e^{z_{i,l}}}{\\left(\\sum_{l=1}^{d_l} e^{z_{i,l}}\\right)^2}\n\\end{align*}\\]\nWe have two cases. If \\(j=k\\), then \\(\\frac{\\partial e^{z_{i,j}}}{\\partial z_{i,k}} = e^{z_{i,k}}\\) and we get:\n\\[\\begin{align*}\n\\frac{\\partial S_{i,j}}{\\partial z_{i,k}} &= \\frac{e^{z_{i,k}} \\cdot \\sum_{l=1}^{d_l} e^{z_{i,l}} -e^{z_{i,k}} \\cdot e^{z_{i,k}}}{\\left(\\sum_{l=1}^{d_l} e^{z_{i,l}}\\right)^2}\\\\\n&=\\frac{e^{z_{i,k}}}{\\sum_{l=1}^{d_l} e^{z_{i,l}}} \\cdot \\frac{\\sum_{l=1}^{d_l} e^{z_{i,l}} -e^{z_{i,k}}}{\\sum_{l=1}^{d_l} e^{z_{i,l}}}\\\\\n&=S_{i,k}(1-S_{i,k})\n\\end{align*}\\]\nIn the case where \\(j \\neq k\\), \\(\\frac{\\partial e^{z_{i,j}}}{\\partial z_{i,k}} = 0\\) and we have:\n\\[\\begin{align*}\n\\frac{\\partial S_{i,j}}{\\partial z_{i,k}} &= -\\frac{e^{z_{i,j}}}{\\sum_{l=1}^{d_l}e^{z_{i,l}}}\\cdot \\frac{e^{z_{i,k}}}{\\sum_{l=1}^{d_l}e^{z_{i,l}}}\\\\\n&=-S_{i,j} S_{i,k}\n\\end{align*}\\]\nSo, the derivative of the softmax activation function can be expressed in terms of Kronecker’s delta as:\n\\[\\begin{align*}\n\\frac{\\partial S_{i,j}}{\\partial z_{i,k}} &= S_{i,j}(\\delta_{j,k} -  S_{i,k})\\\\\n&= S_{i,j} \\delta_{j,k} - S_{i,j}S_{i,k}\n\\end{align*}\\]\nNow, like before, let’s say we have neural network with a single hidden layer with \\(d_1 = 3\\) neurons. We apply the softmax activation function to the output of this layer. The jacobian matrix \\(\\frac{\\partial S_i}{\\partial z_i}\\) for the \\(i\\)-th sample can be expressed as:\n\\[\\begin{align*}\n\\frac{\\partial S_i}{\\partial z_i} &=\n\\begin{bmatrix}\n\\frac{\\partial S_{i1}}{\\partial z_{i1}} & \\frac{\\partial S_{i1}}{\\partial z_{i2}} & \\frac{\\partial S_{i1}}{\\partial z_{i3}} \\\\\n\\frac{\\partial S_{i2}}{\\partial z_{i1}} & \\frac{\\partial S_{i2}}{\\partial z_{i2}} & \\frac{\\partial S_{i2}}{\\partial z_{i3}} \\\\\n\\frac{\\partial S_{i3}}{\\partial z_{i1}} & \\frac{\\partial S_{i3}}{\\partial z_{i2}} & \\frac{\\partial S_{i3}}{\\partial z_{i3}}\n\\end{bmatrix}\\\\\n&=\\begin{bmatrix}\nS_{i1}(\\delta_{11} - S_{i1}) & S_{i1}(\\delta_{12} - S_{i2}) & S_{i1}(\\delta_{13} - S_{i3}) \\\\\nS_{i2}(\\delta_{21} - S_{i1}) & S_{i2}(\\delta_{22} - S_{i2}) & S_{i2}(\\delta_{23} - S_{i3}) \\\\\nS_{i3}(\\delta_{31} - S_{i1}) & S_{i3}(\\delta_{32} - S_{i2}) & S_{i3}(\\delta_{33} - S_{i3})\n\\end{bmatrix}\\\\\n&=\\begin{bmatrix}\nS_{i1}(1 - S_{i1}) & S_{i1}(0 - S_{i2}) & S_{i1}(0 - S_{i3}) \\\\\nS_{i2}(0 - S_{i1}) & S_{i2}(1 - S_{i2}) & S_{i2}(0 - S_{i3}) \\\\\nS_{i3}(0 - S_{i1}) & S_{i3}(0 - S_{i2}) & S_{i3}(1 - S_{i3})\n\\end{bmatrix}\\\\\n&=\\begin{bmatrix}\nS_{i1}\\\\\nS_{i2}\\\\\nS_{i3}\n\\end{bmatrix}\\odot\n\\begin{bmatrix}\n1 & 0 & 0 \\\\\n0 & 1 & 0 \\\\\n0 & 0 & 1\n\\end{bmatrix} -\n\\begin{bmatrix}\nS_{i1}\\\\\nS_{i2}\\\\\nS_{i3}\n\\end{bmatrix}\\begin{bmatrix}\nS_{i1} & S_{i2} & S_{i3}\n\\end{bmatrix}\n\\end{align*}\\]\nSay the softmax_output=[0.70, 0.10, 0.20]. Then, in python, we can find the Jacobian matrix as:\n\nimport numpy as np\n\nsoftmax_output = np.array([0.70, 0.10, 0.20])\n\n# Reshape as a column vector\nsoftmax_output = softmax_output.reshape(-1, 1)\n\nda_dz = np.diagflat(softmax_output) - np.dot(softmax_output, softmax_output.T)\n\nprint(f\"softmax_output = {softmax_output}\")\nprint(f\"da_dz = {da_dz}\")\n\nsoftmax_output = [[0.7]\n [0.1]\n [0.2]]\nda_dz = [[ 0.20999999 -0.07       -0.14      ]\n [-0.07        0.09       -0.02      ]\n [-0.14       -0.02        0.16      ]]\n\n\nWhat happens when we have a batch of inputs? By the chain rule:\n\\[\\begin{align*}\n\\frac{\\partial L}{\\partial z_{11}} &= \\frac{\\partial L}{\\partial S_{11}} \\cdot \\frac{\\partial S_{11}}{\\partial z_{11}} + \\frac{\\partial L}{\\partial S_{12}} \\cdot \\frac{\\partial S_{12}}{\\partial z_{11}} + \\frac{\\partial L}{\\partial S_{13}}\\cdot \\frac{\\partial S_{13}}{\\partial z_{11}}\n\\end{align*}\\]\nIn general,\n\\[\\begin{align*}\n\\frac{\\partial L}{\\partial z_{ij}} &= \\frac{\\partial L}{\\partial S_{i1}} \\cdot \\frac{\\partial S_{i1}}{\\partial z_{ij}} + \\frac{\\partial L}{\\partial S_{i2}} \\cdot \\frac{\\partial S_{i2}}{\\partial z_{ij}} + \\frac{\\partial L}{\\partial S_{i3}}\\cdot \\frac{\\partial S_{i3}}{\\partial z_{ij}}\\\\\n&=\\sum_{k=1}^{3} \\frac{\\partial L}{\\partial S_{ik}} \\cdot \\frac{\\partial S_{ik}}{\\partial z_{ij}}\n\\end{align*}\\]\nIt follows that:\n\\[\\begin{align*}\n\\frac{\\partial L}{\\partial z_i} &= \\begin{bmatrix}\n\\frac{\\partial L}{\\partial z_{i1}} & \\frac{\\partial L}{\\partial z_{i2}} & \\frac{\\partial L}{\\partial z_{i3}}\n\\end{bmatrix}\\\\\n&=\\begin{bmatrix}\n\\frac{\\partial L}{\\partial S_{i1}} & \\frac{\\partial L}{\\partial S_{i2}} & \\frac{\\partial L}{\\partial S_{i3}}\n\\end{bmatrix} \\begin{bmatrix}\n\\frac{\\partial S_{i1}}{\\partial z_{i1}} & \\frac{\\partial S_{i1}}{\\partial z_{i2}} & \\frac{\\partial S_{i1}}{\\partial z_{i3}} \\\\\n\\frac{\\partial S_{i2}}{\\partial z_{i1}} & \\frac{\\partial S_{i2}}{\\partial z_{i2}} & \\frac{\\partial S_{i2}}{\\partial z_{i3}} \\\\\n\\frac{\\partial S_{i3}}{\\partial z_{i1}} & \\frac{\\partial S_{i3}}{\\partial z_{i2}} & \\frac{\\partial S_{i3}}{\\partial z_{i3}}\n\\end{bmatrix}\\\\\n&=\\frac{\\partial L}{\\partial S_i} \\cdot \\frac{\\partial S_i}{\\partial z_i}\n\\end{align*}\\]\nNow, \\(\\partial L/\\partial S_i\\) has shape [1,3] and \\(\\partial S_i/\\partial z_i\\) is a matrix of size [3,3]. So, \\(\\partial L/\\partial z_i\\) will have dimensions [1,3]."
  },
  {
    "objectID": "posts/backpropogation/index.html#softmax-backward-implementation",
    "href": "posts/backpropogation/index.html#softmax-backward-implementation",
    "title": "Backpropogation",
    "section": "Softmax backward() implementation",
    "text": "Softmax backward() implementation\nWe are now in a position to add backward() pass to the SoftmaxActivation layer.\n\nclass SoftmaxActivation:\n\n    # Forward pass\n    def forward(self, inputs):\n        self.inputs = inputs\n        exp_values = np.exp(inputs - np.max(inputs, axis=1, keepdims=True))\n        probabilities = exp_values / np.sum(exp_values, axis=1, keepdims=True)\n        self.output = probabilities\n\n    # Backward pass\n    def backward(self, dloss_da):\n        dloss_dz = []\n        n = len(self.output)\n        for i in range(n):\n            softmax_output = self.output[i]\n\n            # Reshape as a column vector\n            softmax_output = softmax_output.reshape(-1, 1)\n\n            dsoftmax_dz = np.diagflat(softmax_output) - np.dot(\n                softmax_output, softmax_output.T\n            )\n            dloss_dz.append(np.dot(dloss_da[i], dsoftmax_dz))\n\n        self.dloss_dz = np.array(dloss_dz)"
  },
  {
    "objectID": "posts/backpropogation/index.html#categorical-cross-entropy-loss-and-softmax-activation-function-derivative",
    "href": "posts/backpropogation/index.html#categorical-cross-entropy-loss-and-softmax-activation-function-derivative",
    "title": "Backpropogation",
    "section": "Categorical cross-entropy loss and softmax activation function derivative",
    "text": "Categorical cross-entropy loss and softmax activation function derivative\nThe derivative of the categorical cross entropy loss and softmax activation function can be combined and results in a faster and simple implementation. The current implementation of the backward function in SoftMaxActivation is not vectorized and has a loop.\nLet’s focus again on \\(\\frac{\\partial L_{i}}{\\partial z_{ij}}\\). We have:\n\\[\\begin{align*}\n\\frac{\\partial L_i}{\\partial z_{ij}} &= \\sum_{k} \\frac{\\partial L_i}{\\partial S_{ik}} \\frac{\\partial S_{ik}}{\\partial z_{ij}} \\\\\n&= \\frac{\\partial L_i}{S_{ij}} \\cdot \\frac{\\partial S_{ij}}{\\partial z_{ij}} + \\sum_{k\\neq j}\\frac{\\partial L_i}{\\partial S_{ik}} \\frac{\\partial S_{ik}}{\\partial z_{ij}} \\\\\n&= -\\frac{y_{ij}}{\\hat{y}_{ij}}\\hat{y}_{ij}(1-\\hat{y}_{ij}) + \\sum_{k \\neq j}-\\frac{y_{ik}}{\\hat{y}_{ik}}\\cdot \\hat{y}_{ik}(0 - \\hat{y}_{ij})\\\\\n&= -\\frac{y_{ij}}{\\cancel{\\hat{y}_{ij}}}\\cancel{\\hat{y}_{ij}}(1-\\hat{y}_{ij}) + \\sum_{k \\neq j}-\\frac{y_{ik}}{\\cancel{\\hat{y}_{ik}}}\\cdot \\cancel{\\hat{y}_{ik}}(0 - \\hat{y}_{ij})\\\\\n&= -y_{ij} + y_{ij}\\hat{y}_{ij} + \\sum_{k\\neq j}y_{ik} \\hat{y}_{ij}\\\\\n&= -y_{ij} + \\hat{y}_{ij}(\\sum_{k}y_{ik})\\\\\n&= \\hat{y}_{ij} - y_{ij}\n\\end{align*}\\]\n\nclass CategoricalCrossEntropySoftmax:\n\n    # create activation and loss function objects\n    def __init__(self):\n        self.activation = SoftmaxActivation()\n        self.loss = CategoricalCrossEntropyLoss()\n\n    # forward pass\n    def forward(self, inputs, y_true):\n\n        self.inputs = inputs\n        self.activation.forward(inputs)\n\n        self.output = self.activation.output\n\n        return self.loss.calculate(self.output, y_true)\n\n    # Backward pass\n    def backward(self, y_pred, y_true):\n        # number of samples\n        batch_size = len(y_pred)\n\n        # number of labels\n        num_labels = len(y_pred[0])\n\n        # If labels are sparse, turn them into a one-hot vector\n        if len(y_true.shape) == 1:\n            y_true = np.eye(num_labels)[y_true]\n\n        # Calculate the gradient\n        self.dloss_dz = y_pred - y_true\n\n        # Normalize the gradient\n        self.dloss_dz = self.dloss_dz / batch_size\n\nWe can now test if the combined backward step returns the same values compared to when we backpropogate gradients through both of the functions separately.\n\nimport numpy as np\nimport nnfs\n\nnnfs.init()\n\nsoftmax_outputs = np.array([[0.7, 0.1, 0.2], [0.1, 0.5, 0.4], [0.02, 0.9, 0.08]])\n\nclass_targets = np.array([0, 1, 1])\n\n\nactivation = SoftmaxActivation()\nactivation.output = softmax_outputs\n\nloss = CategoricalCrossEntropyLoss()\nloss.backward(softmax_outputs, class_targets)\nprint(\"Gradients : separate loss and activation\")\nprint(f\"dloss_da = {loss.dloss_da}\")\n\nactivation.backward(loss.dloss_da)\nprint(f\"dloss_dz = {activation.dloss_dz}\")\n\nsoftmax_cce = CategoricalCrossEntropySoftmax()\nsoftmax_cce.backward(softmax_outputs, class_targets)\nprint(\"Gradients : combined loss and activation\")\nprint(f\"dloss_dz = {softmax_cce.dloss_dz}\")\n\nGradients : separate loss and activation\ndloss_da = [[-0.47619048 -0.         -0.        ]\n [-0.         -0.66666667 -0.        ]\n [-0.         -0.37037037 -0.        ]]\ndloss_dz = [[-0.09999999  0.03333334  0.06666667]\n [ 0.03333334 -0.16666667  0.13333334]\n [ 0.00666667 -0.03333333  0.02666667]]\nGradients : combined loss and activation\ndloss_dz = [[-0.1         0.03333333  0.06666667]\n [ 0.03333333 -0.16666667  0.13333333]\n [ 0.00666667 -0.03333333  0.02666667]]"
  },
  {
    "objectID": "posts/borel_cantelli_lemmas/index.html",
    "href": "posts/borel_cantelli_lemmas/index.html",
    "title": "Borel-Cantelli Lemmas",
    "section": "",
    "text": "Borel-Cantelli Lemmas.\n\n(First Borel-Cantelli Lemma) Let \\((A_n)\\) be a sequence of events such that the series \\(\\sum_n \\mathbb{P}(A_n)\\) converges to a finite value \\(L\\). Then, almost surely finitely many \\(A_n\\)’s will occur.\n(Second Borel-Cantelli Lemma) Let \\((A_n)\\) be a sequence of independent events, such that the infinite series \\(\\sum_n \\mathbb{P}(A_n)\\) diverges to \\(\\infty\\). Then, almost surely, infinitely many \\(A_n\\)’s will occur.\n\nFix a probability space \\((\\Omega,\\mathcal{F},\\mathbb{P})\\). Let \\(A_1, A_2, A_3, \\ldots\\) be an infinite sequence of events belonging to \\(\\mathcal{F}\\). We shall often be interested in finding out how many of the \\(A_n\\)’s occur.\nThe event \\(A_n\\) occurs infinitely often (\\(A_n\\hspace{2mm}i.o\\)) is the set of all \\(\\omega\\) that belong to infinitely many \\(A_n\\)’s.\nImagine that an infinite number of \\(A_n\\)’s occur. That is, \\((\\forall n)(\\exists m \\geq n)(\\text{s.t. }A_m \\text{ occurs})\\). In other words:\n\\[\\begin{align*}\n\\{A_n \\text{ infinitely often}\\} = \\bigcap_{n=1}^{\\infty} \\underbrace{\\bigcup_{m\\geq n} A_m}_{B_n} \\tag{1}\n\\end{align*}\\]\nHere, \\(B_n\\) is the event that atleast one of \\(A_n,A_{n+1},\\ldots\\) occur. For that reason, \\(B_n\\) is referred to as the \\(n\\)-th tail event. \\(\\{A_n \\hspace{2mm} i.o.\\}\\) is the intersection of all \\(B_n\\)’s, so it is the event that all the \\(B_n\\)’s occur. Therefore, no matter how far I go, no matter how big \\(n_0\\) is, atleast one of \\(A_{n_0}, A_{n_0}+1,\\ldots\\) occurs.\nTaking the complement of both sides in (1), we get the expression for the event that \\(A_n\\) occurs finitely many times.\n\\[\\begin{align*}\n\\{A_n \\text{ occurs finitely often}\\} = \\bigcup_{n_0=1}^{\\infty} \\bigcap_{n \\geq n_0} A_n^C\n\\end{align*}\\]\nIt means that, there exists an \\(n_0\\), such that each of the further \\(A_i\\)’s fail to occur.\nIn order to prove the Borel-Cantelli lemmas, we require the following lemma."
  },
  {
    "objectID": "posts/borel_cantelli_lemmas/index.html#borel-cantelli-lemmas",
    "href": "posts/borel_cantelli_lemmas/index.html#borel-cantelli-lemmas",
    "title": "Borel-Cantelli Lemmas",
    "section": "",
    "text": "Borel-Cantelli Lemmas.\n\n(First Borel-Cantelli Lemma) Let \\((A_n)\\) be a sequence of events such that the series \\(\\sum_n \\mathbb{P}(A_n)\\) converges to a finite value \\(L\\). Then, almost surely finitely many \\(A_n\\)’s will occur.\n(Second Borel-Cantelli Lemma) Let \\((A_n)\\) be a sequence of independent events, such that the infinite series \\(\\sum_n \\mathbb{P}(A_n)\\) diverges to \\(\\infty\\). Then, almost surely, infinitely many \\(A_n\\)’s will occur.\n\nFix a probability space \\((\\Omega,\\mathcal{F},\\mathbb{P})\\). Let \\(A_1, A_2, A_3, \\ldots\\) be an infinite sequence of events belonging to \\(\\mathcal{F}\\). We shall often be interested in finding out how many of the \\(A_n\\)’s occur.\nThe event \\(A_n\\) occurs infinitely often (\\(A_n\\hspace{2mm}i.o\\)) is the set of all \\(\\omega\\) that belong to infinitely many \\(A_n\\)’s.\nImagine that an infinite number of \\(A_n\\)’s occur. That is, \\((\\forall n)(\\exists m \\geq n)(\\text{s.t. }A_m \\text{ occurs})\\). In other words:\n\\[\\begin{align*}\n\\{A_n \\text{ infinitely often}\\} = \\bigcap_{n=1}^{\\infty} \\underbrace{\\bigcup_{m\\geq n} A_m}_{B_n} \\tag{1}\n\\end{align*}\\]\nHere, \\(B_n\\) is the event that atleast one of \\(A_n,A_{n+1},\\ldots\\) occur. For that reason, \\(B_n\\) is referred to as the \\(n\\)-th tail event. \\(\\{A_n \\hspace{2mm} i.o.\\}\\) is the intersection of all \\(B_n\\)’s, so it is the event that all the \\(B_n\\)’s occur. Therefore, no matter how far I go, no matter how big \\(n_0\\) is, atleast one of \\(A_{n_0}, A_{n_0}+1,\\ldots\\) occurs.\nTaking the complement of both sides in (1), we get the expression for the event that \\(A_n\\) occurs finitely many times.\n\\[\\begin{align*}\n\\{A_n \\text{ occurs finitely often}\\} = \\bigcup_{n_0=1}^{\\infty} \\bigcap_{n \\geq n_0} A_n^C\n\\end{align*}\\]\nIt means that, there exists an \\(n_0\\), such that each of the further \\(A_i\\)’s fail to occur.\nIn order to prove the Borel-Cantelli lemmas, we require the following lemma."
  },
  {
    "objectID": "posts/borel_cantelli_lemmas/index.html#limit-of-product-series",
    "href": "posts/borel_cantelli_lemmas/index.html#limit-of-product-series",
    "title": "Borel-Cantelli Lemmas",
    "section": "Limit of product series",
    "text": "Limit of product series\nLemma. If \\(\\sum_{i=1}^\\infty p_i = \\infty\\), then \\(\\lim \\prod_{i=1}^{n}(1-p_i) = 0\\).\nProof.\nWe know that:\nUsing Taylor’s series expansion of \\(\\ln(1+x)\\) about \\(a=0\\), we have:\n\\[\\begin{align*}\n\\ln(1+x) &= x - \\frac{f''(c)}{2!}x^2\\\\\n&= x - \\frac{1}{(1+c)^2} \\cdot \\frac{x^2}{2}\\\\\n&\\leq x\\\\\n&\\quad \\{\\text{since } \\left(\\frac{x}{1+c}\\right)^2 \\geq 0\\}\n\\end{align*}\\]\nSo,\n\\[\\begin{align*}\n\\ln(1 - p_i) &\\leq -p_i\\\\\n\\sum_{i=1}^{n} \\ln(1 - p_i) &\\leq \\sum_{i=1}^{n} (-p_i)\\\\\n\\ln\\left(\\prod_{i=1}^{n}(1-p_i)\\right) &\\leq \\sum_{i=1}^{n} (-p_i)\\\\\n\\prod_{i=1}^{n}(1-p_i) &\\leq e^{-\\sum_{i=1}^{n} p_i}\n\\end{align*}\\]\nSo,\n\\[\\begin{align*}\n0 \\leq \\prod_{i=1}^{n}(1-p_i) \\leq e^{-\\lim \\sum_{i=1}^{n} p_i}\n\\end{align*}\\]\nNow, \\(e^{-\\lim \\sum_{i=1}^{n} p_i} = 0\\), so by the squeeze theorem, \\(\\lim \\prod_{i=1}^{n}(1-p_i) = 0\\)."
  },
  {
    "objectID": "posts/borel_cantelli_lemmas/index.html#proof-of-the-first-borel-cantelli-lemma",
    "href": "posts/borel_cantelli_lemmas/index.html#proof-of-the-first-borel-cantelli-lemma",
    "title": "Borel-Cantelli Lemmas",
    "section": "Proof of the First Borel-Cantelli Lemma",
    "text": "Proof of the First Borel-Cantelli Lemma\nOur claim is that \\(\\mathbb{P}\\left(\\bigcap_{n=1}^{\\infty} B_n\\right) = 0\\). Observe that, \\(B_1 \\supseteq B_2 \\supseteq B_3 \\supseteq \\ldots\\). So, \\((B_n)\\) is a decreasing sequence of events.\n\\[\\begin{align*}\n\\mathbb{P}\\left(\\bigcap_{n=1}^{\\infty} B_n\\right) &= \\lim_{n \\to \\infty }\\mathbb{P}(B_n) \\\\\n& \\quad \\{ \\text{Continuity of probability measure} \\}\\\\\n&= \\lim_{n\\to\\infty} \\mathbb{P}\\left(\\bigcup_{n=1}^{\\infty}A_n\\right)\\\\\n&\\leq \\lim_{n\\to\\infty} \\sum_{n=1}^{\\infty} \\mathbb{P}\\left(A_n\\right)\\\\\n& \\quad \\{ \\text{Union bound} \\}\n\\end{align*}\\]\nThe infinite series \\(\\sum_{n=1}^{\\infty} \\mathbb{P}\\left(A_n\\right)\\) is convergent. The tail sum \\(\\lim_{k \\to \\infty} \\sum a_k\\) of a convergent series \\(\\sum a_k\\) is zero. Hence,\n\\[\\begin{align*}\n0 \\leq \\mathbb{P}\\left(\\bigcap_{n=1}^{\\infty} B_n\\right) \\leq 0\n\\end{align*}\\]\nConsequently,\n\\[\\begin{align*}\n\\mathbb{P}\\left(\\bigcap_{n=1}^{\\infty} B_n\\right) = 0\n\\end{align*}\\]\nHence, \\(A_n\\) occurs only finitely many times."
  },
  {
    "objectID": "posts/borel_cantelli_lemmas/index.html#proof-of-the-second-borel-cantelli-lemma",
    "href": "posts/borel_cantelli_lemmas/index.html#proof-of-the-second-borel-cantelli-lemma",
    "title": "Borel-Cantelli Lemmas",
    "section": "Proof of the second Borel-Cantelli Lemma",
    "text": "Proof of the second Borel-Cantelli Lemma\nOur claim is that \\(\\mathbb{P}\\left(A_n \\hspace{2mm} i.o.\\right) = 1\\). We must therefore prove that:\n\\[\\begin{align*}\n\\mathbb{P} \\left(\\bigcap_{m=1}^{\\infty} \\bigcup_{n=m}^{\\infty}A_n \\right) = \\mathbb{P} \\left(\\bigcap_{m=1}^{\\infty} B_m \\right) = 1\n\\end{align*}\\]\nOr:\n\\[\\begin{align*}\n\\mathbb{P} \\left(\\bigcup_{n=1}^{\\infty} B_n^C \\right) = 0\n\\end{align*}\\]\nSince \\((B_n^C)\\) is an increasing sequence of events, we have:\n\\[\\begin{align*}\n\\mathbb{P} \\left(\\bigcup_{n=1}^{\\infty} B_n^C\\right) &= \\lim \\mathbb{P}(B_n^C)\\\\\n&= \\lim \\mathbb{P}\\left\\{ \\left(\\bigcup_{m \\geq n} A_m\\right)^C \\right\\} \\\\\n&= \\lim \\mathbb{P} \\left\\{\\bigcap_{m \\geq n} A_m^C \\right\\}\\\\\n&= \\lim \\prod_{m=n}^{\\infty} \\mathbb{P} (A_m^C)\\\\\n&= \\lim \\prod_{m=n}^{\\infty} (1-P(A_m))\n\\end{align*}\\]\nSince \\(\\sum_i P(A_i)\\) diverges to \\(\\infty\\), \\(\\prod_i (1-P(A_i))\\) converges to zero. Consequently,\n\\[\\begin{align*}\n\\mathbb{P} \\left(\\bigcup_{n=1}^{\\infty} B_n^C \\right) = 0\n\\end{align*}\\]"
  },
  {
    "objectID": "posts/cd-swaptions/index.html",
    "href": "posts/cd-swaptions/index.html",
    "title": "Standard CDS Pricing Theory",
    "section": "",
    "text": "I summarize below standard CDS pricing formulas.\n\n\n\nIn CDS pricing, credit default events are modelled using a Poisson process, with an intensity (or hazard rate) \\(\\lambda(t)\\). If the default time is \\(\\tau\\), then the probability of default over an infinitesimal time period \\(dt\\), given no default to \\(t\\) is:\n\\[\n\\begin{align*}\n\\mathbb{P}(t &lt; \\tau &lt; t + dt | \\tau &gt; t) = \\lambda(t)dt\n\\end{align*}\n\\] {#eq-instantaneous probability of default}\nThe probability of surviving to at least time \\(T &gt; t\\) (assuming no default has occurred until time \\(t\\)) is given by:\n\\[\n\\begin{align*}\nQ(t,T) = \\mathbb{P}(\\tau &gt; T | \\tau &gt; t) = \\mathbb{E}[1_{\\tau &gt; T}|\\mathcal{F}_t] = \\exp\\left(-\\lambda(s)ds\\right)\n\\end{align*}\n\\tag{1}\\]\nUp until this point, we have assumed that the intensity is deterministic - if it is extended to be a stochastic process, then the survival probability is given by:\n\\[\n\\begin{align*}\nQ(t,T) = \\mathbb{E}\\left[e^{-\\int_{t}^T \\lambda(s)ds}|\\mathcal{F}_t\\right]\n\\end{align*}\n\\tag{2}\\]\nIt is quite clear that the survival probability \\(Q(t,T)\\) plays the same role as the discounting factor (risk-free zero-coupon bond) \\(P(t,T)\\), as is the intensity \\(\\lambda(t)\\) and the instantaneous short rate \\(r(t)\\). We may extend this analogy and define the forward hazard rate \\(h(t,T)\\) as:\n\\[\n\\begin{align*}\nQ(t,T) = e^{-\\int_{t}^T h(t,s) ds} \\implies h(t,s) = -\\frac{\\partial}{\\partial s}(\\ln Q(t,s)) = -\\frac{1}{Q(t,s)} \\frac{\\partial Q(t,s)}{\\partial s}\n\\end{align*}\n\\tag{3}\\]\nand the zero hazard rates \\(\\Lambda(t,T)\\) as:\n\\[\n\\begin{align*}\nQ(t,T) = e^{-(T-t)\\Lambda(t,T)}, \\quad \\Lambda(t,T) = -\\frac{1}{T-t}\\ln[Q(t,T)]\n\\end{align*}\n\\tag{4}\\]\nThe survival probability curve \\(Q(t,T)\\), the forward hazard rate curve \\(h(t,T)\\) and the zero hazard rate curve \\(\\Lambda(t,T)\\) are equivalent and we refer to them generically as credit curves.\nThe forward hazard rate represents the (infinitesimal) probability of default between times \\(T\\) and \\(T+dt\\), conditional on survival to time \\(T\\) as seen from time \\(t &lt; T\\). The unconditional probability of default between times \\(T\\) and \\(T+dT\\) (as seen from time \\(t\\)) is given by:\n\\[\n\\mathbb{P}(T &lt; \\tau \\leq T + dT | \\tau &gt; t ) = Q(t,T)h(t)\n\\]\n\n\n\n\n\nTHe protection leg of a CDS consists of a (random) payment of \\(N(1 - RR(\\tau))\\) at default time \\(\\tau\\) if this is before expiry of the CDS (time \\(T\\)) and nothing otherwise. The present value of this leg can be written as:\n\\[\n\\begin{align*}\nPV_{prot} = N \\mathbb{E}[e^{-\\int_0^\\tau r(s) ds} (1 - RR(\\tau))1_{\\tau &lt; T}]\n\\end{align*}\n\\tag{5}\\]\nUnder the assumption of a flat recovery curve, this can be rewritten as:\n\\[\n\\begin{align*}\nPV_{prot} = N(1-RR)\\mathbb{E}[e^{-\\int_0^\\tau r(s) ds} 1_{\\tau &lt; T}]\n\\end{align*}\n\\tag{6}\\]\nConsider first a contract that pays \\(N(1-RR)\\), if the default takes place in the small time interval \\([u,u+du]\\). The value of this cash-flow at time \\(0\\):\n\\[\nN(1-RR)\\mathbb{E}[e^{-\\int_0^u r(s)ds } 1_{\\tau\\in[u,u+du]}]\n\\]\nWe can rewrite it as:\n\\[\nN(1-RR)\\mathbb{E}[e^{-\\int_0^u r(s)ds } 1_{\\tau\\in[u,u+du]}] = N(1-RR)\\mathbb{E}[ \\lambda(u) e^{-\\int_0^u (r(s) + \\lambda(s))ds }]\n\\]\nIntegrating over \\(u\\) from \\(0\\) to \\(T\\), we find that:\n\\[\nV_{prot}(0,T) = N(1-RR)\\mathbb{E}\\left[\\int_0^T \\lambda(s) e^{-\\int_0^s (r(u) + \\lambda(u))du} ds \\right]\n\\]\nIf the short rate process and the credit default intensity processes are independent, we can write this expression as:\n\\[\nV_{prot}(0,T) = N(1-RR) \\int_0^T  P(0,s) Q(0,s)\\lambda(s) ds\n\\]\nThe last integral can be easily approximated numerically.\n\n\n\nConsider now the premium leg of a CDS maturing at \\(T\\) with the premium consisting of the periodic coupon payments only (no upfront fee).\nThe premium leg consists of two parts : Regular premium (or coupon) payments (e.g. every three months) up to the expiry of the CDS, which cease if a default occurs, and a single payment of the accrued premium in the event of a default.\nIf there are \\(M\\) remaining payments, with payment times \\(t_1,t_2,\\ldots,t_i,\\ldots,t_M\\), period end times \\(e_1,e_2,\\ldots,e_M\\) and year fractions \\(\\Delta_1, \\Delta_2,\\ldots,\\Delta_M\\), then the present value of the premiums only is:\n\\[\nV_{\\text{premiums-only}}(0,T) = NC\\mathbb{E}\\left[\\sum_{i=1}^M \\Delta_i e^{-\\int_0^{t_i} r(s) ds 1_{e_i &lt; \\tau}}\\right] = NC\\sum_{i=1}^M \\Delta_i P(0,t_i) Q(0,e_i)\n\\tag{7}\\]\n\n\n\n\nA forward starting CDS entered into at time \\(t\\) will give protection against the default of an obligor for the period \\(T_e &gt; t\\) to \\(T_m\\), in return for premium payments in that period. If the obligor defaults before the start of the protection \\(\\tau &lt; T_e\\), the contract cancels worthless. This can easily be replicated by entering a long protection CDS with maturity \\(T_m\\), and a short protection position with maturity \\(T_e\\), leaving only the coupons between \\(T_e\\) and \\(T_m\\) to pay. Furthermore, if a default occurs before \\(T_e\\), the protection payments will exactly cancel.\n\\[\nV(t,T_e, T_m) = V(t, T_m) - V(t,T_e)\n\\]"
  },
  {
    "objectID": "posts/cd-swaptions/index.html#credit-curves",
    "href": "posts/cd-swaptions/index.html#credit-curves",
    "title": "Standard CDS Pricing Theory",
    "section": "",
    "text": "In CDS pricing, credit default events are modelled using a Poisson process, with an intensity (or hazard rate) \\(\\lambda(t)\\). If the default time is \\(\\tau\\), then the probability of default over an infinitesimal time period \\(dt\\), given no default to \\(t\\) is:\n\\[\n\\begin{align*}\n\\mathbb{P}(t &lt; \\tau &lt; t + dt | \\tau &gt; t) = \\lambda(t)dt\n\\end{align*}\n\\] {#eq-instantaneous probability of default}\nThe probability of surviving to at least time \\(T &gt; t\\) (assuming no default has occurred until time \\(t\\)) is given by:\n\\[\n\\begin{align*}\nQ(t,T) = \\mathbb{P}(\\tau &gt; T | \\tau &gt; t) = \\mathbb{E}[1_{\\tau &gt; T}|\\mathcal{F}_t] = \\exp\\left(-\\lambda(s)ds\\right)\n\\end{align*}\n\\tag{1}\\]\nUp until this point, we have assumed that the intensity is deterministic - if it is extended to be a stochastic process, then the survival probability is given by:\n\\[\n\\begin{align*}\nQ(t,T) = \\mathbb{E}\\left[e^{-\\int_{t}^T \\lambda(s)ds}|\\mathcal{F}_t\\right]\n\\end{align*}\n\\tag{2}\\]\nIt is quite clear that the survival probability \\(Q(t,T)\\) plays the same role as the discounting factor (risk-free zero-coupon bond) \\(P(t,T)\\), as is the intensity \\(\\lambda(t)\\) and the instantaneous short rate \\(r(t)\\). We may extend this analogy and define the forward hazard rate \\(h(t,T)\\) as:\n\\[\n\\begin{align*}\nQ(t,T) = e^{-\\int_{t}^T h(t,s) ds} \\implies h(t,s) = -\\frac{\\partial}{\\partial s}(\\ln Q(t,s)) = -\\frac{1}{Q(t,s)} \\frac{\\partial Q(t,s)}{\\partial s}\n\\end{align*}\n\\tag{3}\\]\nand the zero hazard rates \\(\\Lambda(t,T)\\) as:\n\\[\n\\begin{align*}\nQ(t,T) = e^{-(T-t)\\Lambda(t,T)}, \\quad \\Lambda(t,T) = -\\frac{1}{T-t}\\ln[Q(t,T)]\n\\end{align*}\n\\tag{4}\\]\nThe survival probability curve \\(Q(t,T)\\), the forward hazard rate curve \\(h(t,T)\\) and the zero hazard rate curve \\(\\Lambda(t,T)\\) are equivalent and we refer to them generically as credit curves.\nThe forward hazard rate represents the (infinitesimal) probability of default between times \\(T\\) and \\(T+dt\\), conditional on survival to time \\(T\\) as seen from time \\(t &lt; T\\). The unconditional probability of default between times \\(T\\) and \\(T+dT\\) (as seen from time \\(t\\)) is given by:\n\\[\n\\mathbb{P}(T &lt; \\tau \\leq T + dT | \\tau &gt; t ) = Q(t,T)h(t)\n\\]"
  },
  {
    "objectID": "posts/cd-swaptions/index.html#pricing-a-cds",
    "href": "posts/cd-swaptions/index.html#pricing-a-cds",
    "title": "Standard CDS Pricing Theory",
    "section": "",
    "text": "THe protection leg of a CDS consists of a (random) payment of \\(N(1 - RR(\\tau))\\) at default time \\(\\tau\\) if this is before expiry of the CDS (time \\(T\\)) and nothing otherwise. The present value of this leg can be written as:\n\\[\n\\begin{align*}\nPV_{prot} = N \\mathbb{E}[e^{-\\int_0^\\tau r(s) ds} (1 - RR(\\tau))1_{\\tau &lt; T}]\n\\end{align*}\n\\tag{5}\\]\nUnder the assumption of a flat recovery curve, this can be rewritten as:\n\\[\n\\begin{align*}\nPV_{prot} = N(1-RR)\\mathbb{E}[e^{-\\int_0^\\tau r(s) ds} 1_{\\tau &lt; T}]\n\\end{align*}\n\\tag{6}\\]\nConsider first a contract that pays \\(N(1-RR)\\), if the default takes place in the small time interval \\([u,u+du]\\). The value of this cash-flow at time \\(0\\):\n\\[\nN(1-RR)\\mathbb{E}[e^{-\\int_0^u r(s)ds } 1_{\\tau\\in[u,u+du]}]\n\\]\nWe can rewrite it as:\n\\[\nN(1-RR)\\mathbb{E}[e^{-\\int_0^u r(s)ds } 1_{\\tau\\in[u,u+du]}] = N(1-RR)\\mathbb{E}[ \\lambda(u) e^{-\\int_0^u (r(s) + \\lambda(s))ds }]\n\\]\nIntegrating over \\(u\\) from \\(0\\) to \\(T\\), we find that:\n\\[\nV_{prot}(0,T) = N(1-RR)\\mathbb{E}\\left[\\int_0^T \\lambda(s) e^{-\\int_0^s (r(u) + \\lambda(u))du} ds \\right]\n\\]\nIf the short rate process and the credit default intensity processes are independent, we can write this expression as:\n\\[\nV_{prot}(0,T) = N(1-RR) \\int_0^T  P(0,s) Q(0,s)\\lambda(s) ds\n\\]\nThe last integral can be easily approximated numerically.\n\n\n\nConsider now the premium leg of a CDS maturing at \\(T\\) with the premium consisting of the periodic coupon payments only (no upfront fee).\nThe premium leg consists of two parts : Regular premium (or coupon) payments (e.g. every three months) up to the expiry of the CDS, which cease if a default occurs, and a single payment of the accrued premium in the event of a default.\nIf there are \\(M\\) remaining payments, with payment times \\(t_1,t_2,\\ldots,t_i,\\ldots,t_M\\), period end times \\(e_1,e_2,\\ldots,e_M\\) and year fractions \\(\\Delta_1, \\Delta_2,\\ldots,\\Delta_M\\), then the present value of the premiums only is:\n\\[\nV_{\\text{premiums-only}}(0,T) = NC\\mathbb{E}\\left[\\sum_{i=1}^M \\Delta_i e^{-\\int_0^{t_i} r(s) ds 1_{e_i &lt; \\tau}}\\right] = NC\\sum_{i=1}^M \\Delta_i P(0,t_i) Q(0,e_i)\n\\tag{7}\\]"
  },
  {
    "objectID": "posts/cd-swaptions/index.html#forward-starting-cds",
    "href": "posts/cd-swaptions/index.html#forward-starting-cds",
    "title": "Standard CDS Pricing Theory",
    "section": "",
    "text": "A forward starting CDS entered into at time \\(t\\) will give protection against the default of an obligor for the period \\(T_e &gt; t\\) to \\(T_m\\), in return for premium payments in that period. If the obligor defaults before the start of the protection \\(\\tau &lt; T_e\\), the contract cancels worthless. This can easily be replicated by entering a long protection CDS with maturity \\(T_m\\), and a short protection position with maturity \\(T_e\\), leaving only the coupons between \\(T_e\\) and \\(T_m\\) to pay. Furthermore, if a default occurs before \\(T_e\\), the protection payments will exactly cancel.\n\\[\nV(t,T_e, T_m) = V(t, T_m) - V(t,T_e)\n\\]"
  },
  {
    "objectID": "posts/cd-swaptions/index.html#references",
    "href": "posts/cd-swaptions/index.html#references",
    "title": "Standard CDS Pricing Theory",
    "section": "References",
    "text": "References\n\nPricing Single-name and Multi-name credit derivatives, Dominic O’ Kane"
  },
  {
    "objectID": "posts/coding-a-neural-network-layer/index.html",
    "href": "posts/coding-a-neural-network-layer/index.html",
    "title": "Coding a neural network layer",
    "section": "",
    "text": "In 1943, McCulloch and Pitts introduced artificial intelligence to the world. Their idea was to develop an algorithmic approach to mimic the functionality of the human brain. Due to the structure of the brain consisting of a net of neurons, they introduced the so-called artificial neurons as building blocks.\nIn it’s most simple form, the neuron consists of :\n\ndendrites, which receive the information from other neurons\nsoma, which processes the information\nsynapse, transmits the output of this neuron\naxon, point of connection to other neurons\n\nConsequently, a mathematical definition of an artificial neuron is as follows.\nDefinition. An artificial neuron with weights \\(w_1,\\ldots,w_n \\in \\mathbf{R}\\), bias \\(b\\in\\mathbf{R}\\) and an activation function \\(\\rho:\\mathbf{R} \\to \\mathbf{R}\\) is defined as the scalar-valued function \\(f:\\mathbf{R}^n \\to \\mathbf{R}\\) given by:\n\\[\\begin{align*}\nf(x_1,\\ldots,x_n) = \\rho \\left(\\sum_{i=1}^{n}w_i x_i + b\\right) = \\rho(\\mathbf{w}^T \\mathbf{x}+b) \\tag{1}\n\\end{align*}\\]\nwhere \\(\\mathbf{w} = (w_1,\\ldots,w_n)\\) and \\(\\mathbf{x}=(x_1,\\ldots,x_n)\\).\nA single neuron by itself is useless, but when combined with hundreds or thousands(or many more) of other neurons, the interconnectivity can approximate any complex function and frequently outperforms any other machine learning methods.\n\n%load_ext itikz\n\n\n\nShow the code\n%%itikz --temp-dir --tex-packages=tikz --tikz-libraries=arrows --implicit-standalone\n\\begin{tikzpicture}\n\\foreach \\i in {1,2}\n{\n    \\node[circle, \n        minimum size = 15mm,\n        fill=red!30\n        ] (Input-\\i) at (0,-\\i * 2) {\\large $x_\\i$};\n}\n\\foreach \\i in {1,2,...,5}\n{\n    \\node[circle, \n        minimum size = 15mm,\n        fill=blue!50,\n        yshift=30 mm\n        ] (Hidden1-\\i) at (3.0,-\\i * 2) {\\large $h_\\i^{(1)}$};\n        \n}\n\\foreach \\i in {1,2,...,5}\n{\n    \\node[circle, \n        minimum size = 15mm,\n        fill=blue!50,\n        yshift=30 mm\n        ] (Hidden2-\\i) at (6.0,-\\i * 2) {\\large $h_\\i^{(2)}$};\n}\n\\foreach \\i in {1,2}\n{\n    \\node[circle, \n        minimum size = 15mm,\n        fill=green!30] (Output-\\i) at (9.0,-\\i * 2) {\\large $\\hat{y}_\\i$};\n}\n\n% Connect neurons In-Hidden1\n\\foreach \\i in {1,...,2}\n{\n    \\foreach \\j in {1,...,5}\n    {\n        \\draw[-&gt;, shorten &gt;=1pt] (Input-\\i) -- (Hidden1-\\j);   \n    }\n}\n\\foreach \\i in {1,...,5}\n{\n    \\foreach \\j in {1,...,5}\n    {\n        \\draw[-&gt;, shorten &gt;=1pt] (Hidden1-\\i) -- (Hidden2-\\j);   \n    }\n}\n\\foreach \\i in {1,...,5}\n{\n    \\foreach \\j in {1,2}\n    {\n        \\draw[-&gt;, shorten &gt;=1pt] (Hidden2-\\i) -- (Output-\\j);   \n    }\n}\n\\end{tikzpicture}\n\n\n\n\n\nDense layers, the most common layers, consist of interconnected neurons. In a dense layer, each neuron of a given layer is connected to every neuron of the next layer, which means its output value becomes an input for the next neurons. Each connection between neurons has a weight associated with it, which is a trainable factor of how much of this input to use. Once all of the \\(\\text{inputs} \\cdot \\text{ weights}\\) flow into our neuron, they are summed and a bias, another trainable parameter is added.\nSay, we have an input \\(x_1\\) and weight \\(w_1\\), then the output \\(y_1 = w_1 x_1\\) is a straight-line with slope \\(w_1\\).\n\n\nShow the code\n%%itikz --temp-dir --tex-packages=tikz,pgfplots --tikz-libraries=arrows --implicit-standalone\n\\begin{tikzpicture}[scale=1.5]\n\\begin{axis}\n\\addplot[color=blue]{x};\n\\addlegendentry{\\(f(x)=x\\)}\n\\addplot[color=red]{2*x};\n\\addlegendentry{\\(f(x)=2x\\)}\n\\end{axis}\n\\end{tikzpicture}\n\n\n\n\n\nThe bias offsets the overall function.\n\n\nShow the code\n%%itikz --temp-dir --tex-packages=tikz,pgfplots --tikz-libraries=arrows --implicit-standalone\n\\begin{tikzpicture}[scale=1.5]\n\\begin{axis}\n\\addplot[color=black]{x+1};\n\\addlegendentry{\\(f(x)=x+1\\)}\n\\addplot[color=gray]{x-1};\n\\addlegendentry{\\(f(x)=x-1\\)}\n\\end{axis}\n\\end{tikzpicture}\n\n\n\n\n\n\n\nLet us now look at some examples of activation functions.\nThe heaviside function is defined as:\n\\[\\begin{align*}\n\\rho(x) &=\n\\begin{cases}\n1, & x &gt; 0 \\\\\n0, & x \\leq 0\n\\end{cases}\n\\end{align*}\\]\nThe sigmoid function is defined as:\n\\[\\begin{align*}\n\\rho(x) &= \\frac{1}{1+e^{-x}}\n\\end{align*}\\]\n\n\nShow the code\n%%itikz --temp-dir --tex-packages=tikz,pgfplots --tikz-libraries=arrows --implicit-standalone\n\\begin{tikzpicture}[scale=1.5]\n\\begin{axis}\n\\addplot[color=black]{1/(1+exp(-x))};\n\\end{axis}\n\\end{tikzpicture}\n\n\n\n\n\nThe Rectifiable Linear Unit (ReLU) function is defined as:\n\\[\\begin{align*}\n\\rho(x) &= \\max(0,x)\n\\end{align*}\\]\n\n\nShow the code\n%%itikz --temp-dir --tex-packages=tikz,pgfplots --tikz-libraries=arrows --implicit-standalone\n\\begin{tikzpicture}[scale=1.5]\n\\begin{axis}\n\\addplot[color=black]{max(0,x)};\n\\end{axis}\n\\end{tikzpicture}"
  },
  {
    "objectID": "posts/coding-a-neural-network-layer/index.html#introduction",
    "href": "posts/coding-a-neural-network-layer/index.html#introduction",
    "title": "Coding a neural network layer",
    "section": "",
    "text": "In 1943, McCulloch and Pitts introduced artificial intelligence to the world. Their idea was to develop an algorithmic approach to mimic the functionality of the human brain. Due to the structure of the brain consisting of a net of neurons, they introduced the so-called artificial neurons as building blocks.\nIn it’s most simple form, the neuron consists of :\n\ndendrites, which receive the information from other neurons\nsoma, which processes the information\nsynapse, transmits the output of this neuron\naxon, point of connection to other neurons\n\nConsequently, a mathematical definition of an artificial neuron is as follows.\nDefinition. An artificial neuron with weights \\(w_1,\\ldots,w_n \\in \\mathbf{R}\\), bias \\(b\\in\\mathbf{R}\\) and an activation function \\(\\rho:\\mathbf{R} \\to \\mathbf{R}\\) is defined as the scalar-valued function \\(f:\\mathbf{R}^n \\to \\mathbf{R}\\) given by:\n\\[\\begin{align*}\nf(x_1,\\ldots,x_n) = \\rho \\left(\\sum_{i=1}^{n}w_i x_i + b\\right) = \\rho(\\mathbf{w}^T \\mathbf{x}+b) \\tag{1}\n\\end{align*}\\]\nwhere \\(\\mathbf{w} = (w_1,\\ldots,w_n)\\) and \\(\\mathbf{x}=(x_1,\\ldots,x_n)\\).\nA single neuron by itself is useless, but when combined with hundreds or thousands(or many more) of other neurons, the interconnectivity can approximate any complex function and frequently outperforms any other machine learning methods.\n\n%load_ext itikz\n\n\n\nShow the code\n%%itikz --temp-dir --tex-packages=tikz --tikz-libraries=arrows --implicit-standalone\n\\begin{tikzpicture}\n\\foreach \\i in {1,2}\n{\n    \\node[circle, \n        minimum size = 15mm,\n        fill=red!30\n        ] (Input-\\i) at (0,-\\i * 2) {\\large $x_\\i$};\n}\n\\foreach \\i in {1,2,...,5}\n{\n    \\node[circle, \n        minimum size = 15mm,\n        fill=blue!50,\n        yshift=30 mm\n        ] (Hidden1-\\i) at (3.0,-\\i * 2) {\\large $h_\\i^{(1)}$};\n        \n}\n\\foreach \\i in {1,2,...,5}\n{\n    \\node[circle, \n        minimum size = 15mm,\n        fill=blue!50,\n        yshift=30 mm\n        ] (Hidden2-\\i) at (6.0,-\\i * 2) {\\large $h_\\i^{(2)}$};\n}\n\\foreach \\i in {1,2}\n{\n    \\node[circle, \n        minimum size = 15mm,\n        fill=green!30] (Output-\\i) at (9.0,-\\i * 2) {\\large $\\hat{y}_\\i$};\n}\n\n% Connect neurons In-Hidden1\n\\foreach \\i in {1,...,2}\n{\n    \\foreach \\j in {1,...,5}\n    {\n        \\draw[-&gt;, shorten &gt;=1pt] (Input-\\i) -- (Hidden1-\\j);   \n    }\n}\n\\foreach \\i in {1,...,5}\n{\n    \\foreach \\j in {1,...,5}\n    {\n        \\draw[-&gt;, shorten &gt;=1pt] (Hidden1-\\i) -- (Hidden2-\\j);   \n    }\n}\n\\foreach \\i in {1,...,5}\n{\n    \\foreach \\j in {1,2}\n    {\n        \\draw[-&gt;, shorten &gt;=1pt] (Hidden2-\\i) -- (Output-\\j);   \n    }\n}\n\\end{tikzpicture}\n\n\n\n\n\nDense layers, the most common layers, consist of interconnected neurons. In a dense layer, each neuron of a given layer is connected to every neuron of the next layer, which means its output value becomes an input for the next neurons. Each connection between neurons has a weight associated with it, which is a trainable factor of how much of this input to use. Once all of the \\(\\text{inputs} \\cdot \\text{ weights}\\) flow into our neuron, they are summed and a bias, another trainable parameter is added.\nSay, we have an input \\(x_1\\) and weight \\(w_1\\), then the output \\(y_1 = w_1 x_1\\) is a straight-line with slope \\(w_1\\).\n\n\nShow the code\n%%itikz --temp-dir --tex-packages=tikz,pgfplots --tikz-libraries=arrows --implicit-standalone\n\\begin{tikzpicture}[scale=1.5]\n\\begin{axis}\n\\addplot[color=blue]{x};\n\\addlegendentry{\\(f(x)=x\\)}\n\\addplot[color=red]{2*x};\n\\addlegendentry{\\(f(x)=2x\\)}\n\\end{axis}\n\\end{tikzpicture}\n\n\n\n\n\nThe bias offsets the overall function.\n\n\nShow the code\n%%itikz --temp-dir --tex-packages=tikz,pgfplots --tikz-libraries=arrows --implicit-standalone\n\\begin{tikzpicture}[scale=1.5]\n\\begin{axis}\n\\addplot[color=black]{x+1};\n\\addlegendentry{\\(f(x)=x+1\\)}\n\\addplot[color=gray]{x-1};\n\\addlegendentry{\\(f(x)=x-1\\)}\n\\end{axis}\n\\end{tikzpicture}\n\n\n\n\n\n\n\nLet us now look at some examples of activation functions.\nThe heaviside function is defined as:\n\\[\\begin{align*}\n\\rho(x) &=\n\\begin{cases}\n1, & x &gt; 0 \\\\\n0, & x \\leq 0\n\\end{cases}\n\\end{align*}\\]\nThe sigmoid function is defined as:\n\\[\\begin{align*}\n\\rho(x) &= \\frac{1}{1+e^{-x}}\n\\end{align*}\\]\n\n\nShow the code\n%%itikz --temp-dir --tex-packages=tikz,pgfplots --tikz-libraries=arrows --implicit-standalone\n\\begin{tikzpicture}[scale=1.5]\n\\begin{axis}\n\\addplot[color=black]{1/(1+exp(-x))};\n\\end{axis}\n\\end{tikzpicture}\n\n\n\n\n\nThe Rectifiable Linear Unit (ReLU) function is defined as:\n\\[\\begin{align*}\n\\rho(x) &= \\max(0,x)\n\\end{align*}\\]\n\n\nShow the code\n%%itikz --temp-dir --tex-packages=tikz,pgfplots --tikz-libraries=arrows --implicit-standalone\n\\begin{tikzpicture}[scale=1.5]\n\\begin{axis}\n\\addplot[color=black]{max(0,x)};\n\\end{axis}\n\\end{tikzpicture}"
  },
  {
    "objectID": "posts/coding-a-neural-network-layer/index.html#coding-a-layer-with-3-neurons",
    "href": "posts/coding-a-neural-network-layer/index.html#coding-a-layer-with-3-neurons",
    "title": "Coding a neural network layer",
    "section": "Coding a layer with 3-neurons",
    "text": "Coding a layer with 3-neurons\nLet’s code a simple layer with \\(n=3\\) neurons.\n\ninputs = [1, 2, 3, 2.5]\nweights = [[0.2, 0.8, -0.5, 1.0], [0.5, -0.91, 0.26, -0.5], [-0.26, -0.27, 0.17, 0.87]]\n\nbiases = [2, 3, 0.5]\n\n# Output of the current layer\nlayer_outputs = []\n\n# For each neuron\nfor neuron_weights, neuron_bias in zip(weights, biases):\n    # zeroed output of the neuron\n    neuron_output = 0.0\n    # for each input and weight to the neuron\n    for input, weight in zip(inputs, neuron_weights):\n        # multiply this input with the associated weight\n        # and add to the neuron's output variable\n        neuron_output += input * weight\n    # Add bias\n    neuron_output += neuron_bias\n    # Put the neuron's result to the layer's output list\n    layer_outputs.append(neuron_output)\n\nprint(layer_outputs)\n\n[4.8, 1.21, 2.385]\n\n\nWe can achieve the same results as in our pure Python implementation of multiplying each component in our input vector \\(\\mathbf{x}\\) and weights vector \\(\\mathbf{w}\\) element-wise, by taking an inner product \\(\\mathbf{w} \\cdot \\mathbf{x}\\).\n\nimport numpy as np\n\ninputs = [1, 2, 3, 2.5]\nweights = [\n    [0.2, 0.8, -0.5, 1.0], \n    [0.5, -0.91, 0.26, -0.5], \n    [-0.26, -0.27, 0.17, 0.87]\n]\n\nbiases = [2, 3, 0.5]\n\n# Output of the current layer\nlayer_outputs = np.dot(weights, inputs) + biases\n\nprint(layer_outputs)\n\n[4.8   1.21  2.385]\n\n\nTo train, neural networks tend to receive data in batches. So far, the example input data has only one sample (or observation) of various features called a feature set instance:\nsample = [1, 2, 3, 2.5]\nOften, neural networks expect to take in many samples at a time. One reason is its faster to train in batches in parallel processing. Also, if you fit on one sample at a time, you’re highly likely to keep fitting to that individual sample, rather than slowly producing general tweaks to the weights and biases that fit the entire dataset. Fitting or training in batches gives you a higher chance of making more meaningful changes to weights and biases."
  },
  {
    "objectID": "posts/coding-a-neural-network-layer/index.html#a-layer-of-neurons-and-a-batch-of-data",
    "href": "posts/coding-a-neural-network-layer/index.html#a-layer-of-neurons-and-a-batch-of-data",
    "title": "Coding a neural network layer",
    "section": "A layer of neurons and a batch of data",
    "text": "A layer of neurons and a batch of data\nCurrently, the weights matrix looks as follows:\n\\[\\begin{align*}\nW = \\begin{bmatrix}\n0.2 & 0.8 & -0.5 & 1.0 \\\\\n0.5 & -0.91 & 0.26 & -0.5 \\\\\n-0.26 & -0.27 & 0.17 & 0.87\n\\end{bmatrix}\n\\end{align*}\\]\nAnd say, that we have a batch of inputs:\n\\[\\begin{align*}\nX = \\begin{bmatrix}\n1.0 & 2.0 & 3.0 & 3.5 \\\\\n2.0 & 5.0 & -1.0 & 2.0\\\\\n-1.5 & 2.7 & 3.3 & -0.8\n\\end{bmatrix}\n\\end{align*}\\]\nWe need to take the inner products \\((1.0, 2.0, 3.0, 3.5) \\cdot (0.2, 0.8, -0.5, 1.0)\\), \\((2.0, 5.0, -1.0, 2.0) \\cdot (0.2, 0.8, -0.5, 1.0)\\) and \\((-1.5, 2.7, 3.3, -0.8) \\cdot (0.2, 0.8, -0.5, 1.0)\\) for the first neuron.\nWe need to take the inner products \\((1.0, 2.0, 3.0, 3.5) \\cdot (0.5, -0.91, 0.26, -0.5)\\), \\((2.0, 5.0, -1.0, 2.0) \\cdot (0.5, -0.91, 0.26, -0.5)\\) and \\((-1.5, 2.7, 3.3, -0.8) \\cdot (0.5, -0.91, 0.26, -0.5)\\) for the second neuron.\nAnd so forth.\nConsider the matrix product \\(XW^T\\):\n\\[\\begin{align*}\nXW^T &= \\begin{bmatrix}\n1.0 & 2.0 & 3.0 & 2.5 \\\\\n2.0 & 5.0 & -1.0 & 2.0\\\\\n-1.5 & 2.7 & 3.3 & -0.8\n\\end{bmatrix}\n\\begin{bmatrix}\n0.2 & 0.5 & -0.26 \\\\\n0.8 & -0.91 & -0.27 \\\\\n-0.5 & 0.26 & 0.17 \\\\\n1.0 & -0.5 & 0.87\n\\end{bmatrix}\\\\\n&= \\begin{bmatrix}\n2.8 & -1.79 & 1.885 \\\\\n6.9 & -4.81 & -0.3 \\\\\n-0.59 & -1.949 & -0.474\n\\end{bmatrix}\n\\end{align*}\\]\n\nimport numpy as np\n\nX = [\n    [1.0, 2.0, 3.0, 2.5],\n    [2.0, 5.0, -1.0, 2.0],\n    [-1.5, 2.7, 3.3, -0.8]\n]\n\nW = [\n    [0.2, 0.8, -0.5, 1.0],\n    [0.5, -0.91, 0.26, -0.5],\n    [-0.26, -0.27, 0.17, 0.87]\n]\n\nnp.dot(X,np.array(W).T)\n\narray([[ 2.8  , -1.79 ,  1.885],\n       [ 6.9  , -4.81 , -0.3  ],\n       [-0.59 , -1.949, -0.474]])\n\n\nSo, we can process a batch of inputs as:\n\nlayer_outputs = np.dot(X,np.array(W).T) + biases\nprint(layer_outputs)\n\n[[ 4.8    1.21   2.385]\n [ 8.9   -1.81   0.2  ]\n [ 1.41   1.051  0.026]]\n\n\nThe second argument for np.dot() is going to be our transposed weights. Before, we were computing the neuron output using a single sample of data, but now we’ve taken a step forward where we model the layer behavior on a batch of data."
  },
  {
    "objectID": "posts/coding-a-neural-network-layer/index.html#adding-layers",
    "href": "posts/coding-a-neural-network-layer/index.html#adding-layers",
    "title": "Coding a neural network layer",
    "section": "Adding Layers",
    "text": "Adding Layers\nThe neural network we have built is becoming more respectable, but at the moment, we have only one layer. Neural networks become deep when they have \\(2\\) or more hidden layers. At the moment, we have just one layer, which is effectively an output layer. Why we want two or more hidden layers will become apparent later on. Currently, we have no hidden layers. A hidden layer isn’t an input or output layer; as the scientist, you see the data as they are handed to the input layer and the resulting data from the output layer. Layers between these endpoints have values that we don’t necessarily deal with, and hence the name “hidden”. Don’t let this name convince you that you can’t access these values, though. You will often use them to diagnose issues or improve your neural network. To explore this concept, let’s add another layer to this neural network, and for now, let’s assume that these two layers that we’re going to have will be hidden layers, and we just coded our output layer yet.\nBefore we add another layer, let’s think about what’s coming. In the case of the first layer, we can see that we have an input with \\(4\\) features.\n\n\nShow the code\n%%itikz --temp-dir --tex-packages=tikz --tikz-libraries=arrows --implicit-standalone\n\\begin{tikzpicture}\n\\foreach \\i in {1,2,...,4}\n{\n    \\node[circle, \n        minimum size = 15mm,\n        fill=red!30\n        ] (Input-\\i) at (0,-\\i * 2) {\\large $x_\\i$};\n}\n\\foreach \\i in {1,2,...,3}\n{\n    \\node[circle, \n        minimum size = 15mm,\n        fill=blue!50,\n        yshift=-10 mm\n        ] (Hidden1-\\i) at (3.0,-\\i * 2) {\\large $h_\\i^{(1)}$};\n        \n}\n\n% Connect neurons In-Hidden1\n\\foreach \\i in {1,...,4}\n{\n    \\foreach \\j in {1,...,3}\n    {\n        \\draw[-&gt;, shorten &gt;=1pt] (Input-\\i) -- (Hidden1-\\j);   \n    }\n}\n\\end{tikzpicture}\n\n\n\n\n\nSamples(feature set data) get fed through the input, which does not change it in any way, to our first hidden layer, which we can see has \\(3\\) sets of weights with \\(4\\) values each.\nEach of those \\(3\\) unique weight sets is associated with its distinct neuron. Thus, since we have \\(3\\) weight sets, we have \\(3\\) neurons in the first hidden layer. Each neuron has a unique set of weights, of which we have \\(4\\) (as there are \\(4\\) inputs to this layer), which is why our initial weights have a shape of \\((3,4)\\).\nNow we wish to add another layer. To do that, we must make sure that the expected input to that layer matches the previous layer’s output. We have set the number of neurons in a layer by setting how many weights and biases we have. The previous layer’s influence on weight sets for the current layer is that each weight set needs to have a separate weight per input. This means a distinct weight per neuron from the previous layer (or feature if we’re talking the input). The previous layer has \\(3\\) weight sets and \\(3\\) biases, so we know it has \\(3\\) neurons. This then means, for the next layer, we can have as many weight sets as we want (because this is how many neurons this new layer will have), but each of those weight sets must have \\(3\\) discrete weights.\nTo create this new layer, we are going to copy and paste our weights and biases to weights2 and biases2, and change their values to new made up sets. Here’s an example:\n\ninputs = [\n    [1, 2, 3, 2.5],\n    [2.0, 5.0, -1.0, 2],\n    [-1.5, 2.7, 3.3, -0.8]\n]\n\nweights = [\n    [0.2, 0.8, -0.5, 1],\n    [0.5, -0.91, 0.26, -0.5],\n    [-0.26, -0.27, 0.17, 0.87]\n]\n\nbiases = [2, 3, 0.5]\n\nweights2 = [\n    [0.1, -0.14, 0.5],\n    [-0.5, 0.12, -0.33],\n    [-0.44, 0.73, -0.13]\n]\n\nbiases2 = [-1, 2, -0.5]\n\nNext, we will now call the outputs layer1_outputs.\n\nlayer1_outputs = np.dot(inputs, np.array(weights).T) + biases\n\nAs previously stated, inputs to the layers are either inputs from the actual dataset you’re training with, or outputs from a previous layer. That’s why we defined \\(2\\) versions of weights and biases, but only one of inputs.\n\nlayer2_outputs = np.dot(layer1_outputs, np.array(weights2).T) + biases2\n\nAt this point, our neural network could be visually represented as:\n\n\nShow the code\n%%itikz --temp-dir --tex-packages=tikz --tikz-libraries=arrows --implicit-standalone\n\\begin{tikzpicture}\n\\foreach \\i in {1,2,...,4}\n{\n    \\node[circle, \n        minimum size = 15mm,\n        fill=red!30\n        ] (Input-\\i) at (0,-\\i * 2) {\\large $x_\\i$};\n}\n\\foreach \\i in {1,2,...,3}\n{\n    \\node[circle, \n        minimum size = 15mm,\n        fill=blue!50,\n        yshift=-10 mm\n        ] (Hidden1-\\i) at (3.0,-\\i * 2) {\\large $h_\\i^{(1)}$};\n        \n}\n\\foreach \\i in {1,2,...,3}\n{\n    \\node[circle, \n        minimum size = 15mm,\n        fill=blue!50,\n        yshift=-10 mm\n        ] (Hidden2-\\i) at (6.0,-\\i * 2) {\\large $h_\\i^{(2)}$};\n        \n}\n\n% Connect neurons In-Hidden1\n\\foreach \\i in {1,...,4}\n{\n    \\foreach \\j in {1,...,3}\n    {\n        \\draw[-&gt;, shorten &gt;=1pt] (Input-\\i) -- (Hidden1-\\j);   \n    }\n}\n% Connect neurons Hidden1-Hidden2\n\\foreach \\i in {1,...,3}\n{\n    \\foreach \\j in {1,...,3}\n    {\n        \\draw[-&gt;, shorten &gt;=1pt] (Hidden1-\\i) -- (Hidden2-\\j);   \n    }\n}\n\\end{tikzpicture}"
  },
  {
    "objectID": "posts/coding-a-neural-network-layer/index.html#training-data",
    "href": "posts/coding-a-neural-network-layer/index.html#training-data",
    "title": "Coding a neural network layer",
    "section": "Training Data",
    "text": "Training Data\nNext, rather than hand-typing in random data, we’ll use a function that can create non-linear data. What do we mean by non-linear? Linear data can be fit or represented by a straight line. Non-linear data cannot be represented well by a straight line.\nWe shall use the python package nnfs to create data. You can install it with\npip install nnfs\nYou typically don’t generate training data from a package like nnfs for your neural networks. Generating a dataset this way is purely for convenience at this stage. I shall also use this package to ensure repeatability.\n\nimport numpy as np\nimport nnfs\n\nnnfs.init()\n\nThe nnfs.init() does three things: it sets the random seed to \\(0\\) by default, creates a float32 dtype default and overrides the original dot product from numpy. All of these are meant to ensure repeatable results for following along.\n\nfrom nnfs.datasets import spiral_data\nimport matplotlib.pyplot as plt\n\nX, y = spiral_data(samples=100, classes=3)\n\nplt.scatter(X[:,0], X[:,1])\nplt.show()\n\n\n\n\nThe spiral_data function allows us to create a dataset with as many classes as we want. The function has parameters to choose the number of classes and the number of points/observations per class in the resulting non-linear dataset.\nIf you trace from the center, you can determine all \\(3\\) classes separately, but this is a very challenging problem for a machine learning classifier to solve. Adding color to the chart makes this more clear:\n\nplt.scatter(X[:,0],X[:,1],c=y,cmap='brg')\nplt.show()\n\n\n\n\nKeep in mind that the neural network will not be aware of the color differences as the data have no class encodings. This is only made as an instruction for you. In the data above, each dot is an observation, that is, it’s coordinates are the samples that form the dataset. The classification for the dot has to do with which spiral it is a part of, depicted by red, blue or green color."
  },
  {
    "objectID": "posts/coding-a-neural-network-layer/index.html#dense-layer-class",
    "href": "posts/coding-a-neural-network-layer/index.html#dense-layer-class",
    "title": "Coding a neural network layer",
    "section": "Dense Layer Class",
    "text": "Dense Layer Class\nNow that we no longer need to hand-type our data, we should create something similar for our various types of neural network layers. So far, we’ve only used what’s called a dense or fully-connected layer. These layers are commonly referred to as dense layers in papers, literature and code, but you will see them called fully-connected or fc for short in the code I write. Our dense layer class begins with two methods:\n\nclass DenseLayer:\n    def __init__(self, n_inputs, n_neurons):\n        # Initialize weights and biases\n        pass # using pass statement as a placeholder\n\n    # Forward pass\n    def forward(self, inputs):\n        # Calculate output values from inputs, weights and biases\n        pass # using pass statement as a placeholder\n\nWeights are often initialized randomly for a model, but not always. If you wish to load a pre-trained model, you will initialize the parameters to whatever that pretrained model finished with. It’s also possible that, even for a new model, you have some other initialization rules besides random. From now, we’ll stick with random initialization. Next, we have the forward method. When we pass data through a model from beginning to end, this is called a forward pass. Just like everything else, this is not the only way to do things. You can have the data loop back around and do other interesting things. We’ll keep it usual and perform a regular forward pass.\nTo continue the LayerDense class code, let’s add the random initialization of weights and biases:\n#Layer initialization\ndef __init__(self,n_inputs, n_neurons):\n    self.weights = 0.01 * np.random.randn(n_inputs,n_neurons)\n    self.biases = np.zeros((1,n_neurons))\nHere, we are setting the weights to be random and the biases to be \\(0\\). Note that, we are initializing weights to be a matrix of dimensions \\(n_{inputs} \\times n_{neurons}\\), rather than \\(n_{neurons} \\times n_{inputs}\\). We’re doing this ahead instead of transposing everytime we perform a forward pass, as explained in the previous chapter.\nWe initialize the biases to zero, because with many samples containing values of \\(0\\), it will ensure that a neuron fires initially. The most common initialization for biases is zero. This will vary depending on our use-case and is just one of the many things we can tweak when trying to improve results. One situation where we might want to try something else is with what’s called dead neurons.\nImagine our step function again:\n\\[\\begin{align*}\ny = \\begin{cases}\n1, & x &gt; 0\\\\\n0, & x \\leq 0\n\\end{cases}\n\\end{align*}\\]\nIt’s possible for \\(\\text{weights} \\cdot \\text{inputs} + \\text{biases}\\) not to meet the threshold of the step function, which means the neuron will output a zero. On its own, this is not a big issue, but it becomes a problem if this happens to this neuron for every one of the input samples (it’ll become clear why once we learn about backpropogation). So, then this neuron’s \\(0\\) output is the input to another neuron. Any weight multiplied by zero will be zero. With an increasing number of neurons outputting \\(0\\), more inputs to the next neurons will be zeros, rendering the network essentially non-trainable or dead.\nOn to our forward method now.\n\nclass DenseLayer:\n    def __init__(self, n_inputs, n_neurons):\n        self.weights = 0.01 * np.random.randn(n_inputs,n_neurons)\n        self.biases = np.zeros((1,n_neurons))\n\n    def forward(self,inputs):\n        self.output = np.dot(inputs,self.weights) + self.biases\n\nWe are now ready to make use of this new class instead of hardcoded calculations, so let’s generate some data using the discussed dataset creation method and use our new layer to perform a forward pass:\n\n# Create dataset\nX, y = spiral_data(samples=100, classes=3)\n\n# Create a dense layer with 2 input features and 3 output values\ndense1 = DenseLayer(2, 3)\n\n# Perform a forward pass of our training data through this layer\ndense1.forward(X)\n\n# Let's see the output of the first few samples\nprint(dense1.output[:5])\n\n[[ 0.00000000e+00  0.00000000e+00  0.00000000e+00]\n [-1.11171044e-04 -5.11007493e-05 -1.12099799e-04]\n [ 2.99257295e-06 -2.69126613e-04 -1.45165104e-04]\n [ 8.95101766e-05 -4.30442247e-04 -1.68079801e-04]\n [-3.49893759e-04 -3.07208364e-04 -4.33002861e-04]]"
  },
  {
    "objectID": "posts/coding-a-neural-network-layer/index.html#activation-functions-1",
    "href": "posts/coding-a-neural-network-layer/index.html#activation-functions-1",
    "title": "Coding a neural network layer",
    "section": "Activation Functions",
    "text": "Activation Functions\nWe use activation functions because if the activation function itself is non-linear, it allows for neural networks with two or more layers to map non-linear functions. We’ll see how this works. In general, your neural network will have \\(2\\) types of activation functions. The first will be the activation function used in hidden layers, and the second will be used in the output layer. Usually, the activation function used for hidden neurons will be all the same for all of them, but it doesn’t have to.\n\nWhy use activation functions?\nLet’s discuss why we use activation functions in the first place? In most cases, for a neural network to fit a non-linear function, we need it to contain two or more hidden layers and we need those hidden layers to use a non-linear activation function.\nWhile there are certainly problems in life that are linear in nature, for example, trying to figure out the cost of some number of shirts, and we know the cost of an individual shirt, then the equation to calculate the price of any number of those products is a linear equation; other problems in life are not so simple.\nMany interesting and hard problems are non-linear. The main attraction of neural networks has to do with their ability to solve non-linear problems. If we allow only linear activation functions in a neural network, the output will just be a linear transformation of the input, which is not enough to form a universal function approximator.\nFor simplicity, suppose a neural network has \\(2\\) hidden layers with \\(1\\) neuron each.\n\n\nShow the code\n%%itikz --temp-dir --tex-packages=tikz --tikz-libraries=arrows --implicit-standalone\n\\begin{tikzpicture}[scale=1.5]\n    \\node[circle, \n        minimum size = 15mm,\n        fill=red!30\n        ] (Input) at (0,0) {\\large $x_1$};\n\n    \\node[circle, \n        minimum size = 15mm,\n        fill=blue!50\n        ] (Hidden1) at (3.0,0) {\\large $h_1^{(1)}$};\n        \n\n    \\node[circle, \n        minimum size = 15mm,\n        fill=blue!50\n        ] (Hidden2) at (6.0,0) {\\large $h_1^{(2)}$};\n\n    \\node[circle, \n        minimum size = 15mm,\n        fill=red!30\n        ] (Output) at (9.0,0) {\\large $\\hat{y}_1$};        \n        \n\n    \\draw[-&gt;, shorten &gt;=1pt] (Input) -- (Hidden1) node [midway,above] {\\large $w_1$};\n    \\draw[-&gt;, shorten &gt;=1pt] (Hidden1) -- (Hidden2) node [midway,above]  {\\large $w_2$};\n    \\draw[-&gt;, shorten &gt;=1pt] (Hidden2) -- (Output);\n    \\draw[-&gt;, shorten &gt;=1pt] (3.0, -2.0) node [below] {\\large $b_1$} -- (Hidden1);\n    \\draw[-&gt;, shorten &gt;=1pt] (6.0, -2.0) node [below] {\\large $b_2$} -- (Hidden2);\n\\end{tikzpicture}\n\n\n\n\n\n\\[\\begin{align*}\n\\hat{y}_1 &= h_1^{(2)} \\\\\n&= w_2 h_1^{(1)} + b_2 \\\\\n&= w_2 (w_1 x_1 + b_1) + b_2 \\\\\n&= w_2 w_1 x_1 + (w_2 b_1 + b_2)\n\\end{align*}\\]\nSo, \\(\\hat{y}_1\\) is a linear function of the inputs, no matter, what values we choose for weights and biases.\nThe composition of linear functions is linear. No matter what we do, however many layers we have, or neurons we have in each layer, this network can only model linear functions."
  },
  {
    "objectID": "posts/coding-a-neural-network-layer/index.html#relu-activation-in-a-pair-of-neurons",
    "href": "posts/coding-a-neural-network-layer/index.html#relu-activation-in-a-pair-of-neurons",
    "title": "Coding a neural network layer",
    "section": "ReLU Activation in a pair of Neurons",
    "text": "ReLU Activation in a pair of Neurons\nIt is less obvious how, with a barely non-linear activation function, like the rectified linear activation function, we can suddenly model non-linear relationships and functions. Let’s start with a single neuron. We’ll begin with both a weight of zero and a bias of zero:\n\n\nShow the code\n%%itikz --temp-dir --tex-packages=tikz --tikz-libraries=arrows --implicit-standalone\n\\begin{tikzpicture}[scale=1.5]\n    \\node[circle, \n        minimum size = 15mm,\n        draw=blue\n        ] (Input) at (0,0) {};\n    \n    \\node[] (w) at (-3,0) {};\n    \\node[] (b) at (0,-2) {};\n\n    \\draw[-&gt;, shorten &gt;=1pt] (w) -- (Input) node [midway,above] {\\large $0.00$};\n    \\draw[-&gt;, shorten &gt;=1pt] (b) node [below] {\\large $0.00$} -- (Input);\n\\end{tikzpicture}\n\n\n\n\n\nIn this case, no matter what input we pass, the output of this neuron will always be \\(0\\), because the weight is \\(0\\) and the bias is \\(0\\).\n\n\nShow the code\n%%itikz --temp-dir --tex-packages=tikz,pgfplots --tikz-libraries=arrows --implicit-standalone\n\\begin{tikzpicture}[scale=1.5]\n\\begin{axis}[grid]\n\\addplot[color=blue,thick]{0};\n\\end{axis}\n\\end{tikzpicture}\n\n\n\n\n\nLet’s set the weight to be \\(1.00\\).\n\n\nShow the code\n%%itikz --temp-dir --tex-packages=tikz --tikz-libraries=arrows --implicit-standalone\n\\begin{tikzpicture}[scale=1.5]\n    \\node[circle, \n        minimum size = 15mm,\n        draw=blue\n        ] (Input) at (0,0) {};\n    \n    \\node[] (w) at (-3,0) {};\n    \\node[] (b) at (0,-2) {};\n\n    \\draw[-&gt;, shorten &gt;=1pt] (w) -- (Input) node [midway,above] {\\large $1.00$};\n    \\draw[-&gt;, shorten &gt;=1pt] (b) node [below] {\\large $0.00$} -- (Input);\n\\end{tikzpicture}\n\n\n\n\n\nNow, it just looks like the basic rectified linear function. No surprises yet!\n\n\nShow the code\n%%itikz --temp-dir --tex-packages=tikz,pgfplots --tikz-libraries=arrows --implicit-standalone\n\\begin{tikzpicture}[scale=1.5]\n\\begin{axis}[grid,ymin=-2.0,ymax=2.0,xmin=-2.0,xmax=2.0]\n\\addplot[color=blue,thick]{max(x,0)};\n\\end{axis}\n\\end{tikzpicture}\n\n\n\n\n\nNow, let’s set the bias to \\(0.50\\):\n\n\nShow the code\n%%itikz --temp-dir --tex-packages=tikz --tikz-libraries=arrows --implicit-standalone\n\\begin{tikzpicture}[scale=1.5]\n    \\node[circle, \n        minimum size = 15mm,\n        draw=blue\n        ] (Input) at (0,0) {};\n    \n    \\node[] (w) at (-3,0) {};\n    \\node[] (b) at (0,-2) {};\n\n    \\draw[-&gt;, shorten &gt;=1pt] (w) -- (Input) node [midway,above] {\\large $1.00$};\n    \\draw[-&gt;, shorten &gt;=1pt] (b) node [below] {\\large $0.50$} -- (Input);\n\\end{tikzpicture}\n\n\n\n\n\nWe can see that in this case, with a single neuron, the bias offsets the overall function’s activation point horizontally.\n\n\nShow the code\n%%itikz --temp-dir --tex-packages=tikz,pgfplots --tikz-libraries=arrows --implicit-standalone\n\\begin{tikzpicture}[scale=1.5]\n\\begin{axis}[grid,ymin=-2.0,ymax=2.0,xmin=-2.0,xmax=2.0]\n\\addplot[color=blue,thick,samples=100]{max(x+0.50,0)};\n\\end{axis}\n\\end{tikzpicture}\n\n\n\n\n\nBy increasing bias, we’re making this neuron activate earlier. What happens when we negate the weight to \\(-1.0\\)?\n\n\nShow the code\n%%itikz --temp-dir --tex-packages=tikz --tikz-libraries=arrows --implicit-standalone\n\\begin{tikzpicture}[scale=1.5]\n    \\node[circle, \n        minimum size = 15mm,\n        draw=blue\n        ] (Input) at (0,0) {};\n    \n    \\node[] (w) at (-3,0) {};\n    \\node[] (b) at (0,-2) {};\n\n    \\draw[-&gt;, shorten &gt;=1pt] (w) -- (Input) node [midway,above] {\\large $-1.00$};\n    \\draw[-&gt;, shorten &gt;=1pt] (b) node [below] {\\large $0.50$} -- (Input);\n\\end{tikzpicture}\n\n\n\n\n\nWith a negative weight and this single neuron, the function has become a question of when this neuron deactivates.\n\n\nShow the code\n%%itikz --temp-dir --tex-packages=tikz,pgfplots --tikz-libraries=arrows --implicit-standalone\n\\begin{tikzpicture}[scale=1.5]\n\\begin{axis}[grid,ymin=-2.0,ymax=2.0,xmin=-2.0,xmax=2.0]\n\\addplot[color=blue,thick,samples=100]{max(-x+0.50,0)};\n\\end{axis}\n\\end{tikzpicture}\n\n\n\n\n\nWhat happens if modify the weight to \\(-2.00\\)?\n\n\nShow the code\n%%itikz --temp-dir --tex-packages=tikz --tikz-libraries=arrows --implicit-standalone\n\\begin{tikzpicture}[scale=1.5]\n    \\node[circle, \n        minimum size = 15mm,\n        draw=blue\n        ] (Input) at (0,0) {};\n    \n    \\node[] (w) at (-3,0) {};\n    \\node[] (b) at (0,-2) {};\n\n    \\draw[-&gt;, shorten &gt;=1pt] (w) -- (Input) node [midway,above] {\\large $-2.00$};\n    \\draw[-&gt;, shorten &gt;=1pt] (b) node [below] {\\large $0.50$} -- (Input);\n\\end{tikzpicture}\n\n\n\n\n\nThe neuron now deactivates at \\(0.25\\).\n\n\nShow the code\n%%itikz --temp-dir --tex-packages=tikz,pgfplots --tikz-libraries=arrows --implicit-standalone\n\\begin{tikzpicture}[scale=1.5]\n\\begin{axis}[grid,ymin=-2.0,ymax=2.0,xmin=-2.0,xmax=2.0]\n\\addplot[color=blue,thick,samples=100]{max(-2*x+0.50,0)};\n\\end{axis}\n\\end{tikzpicture}\n\n\n\n\n\nUpto this point, we’ve seen how we can use the bias to offset the function horizontally, and the weight to influence the slope of the activation. Moreover, we’re also able to control whether the function is one for determining where the neuron activates or deactivates. What happens when we have, rather than just one neuron, a pair of neurons? For example, let’s pretend that we have two hidden layers of \\(1\\) neuron each. Thinking back to the \\(y=x\\) activation function, we unsurprisingly discovered that a linear activation function produced linear results no matter what chain of neurons we made. Let’s see what happens with the rectified linear function for the activation.\nWe’ll begin with the last values for the first neuron and a weight of \\(1.00\\) and a bias of \\(0.00\\) for the second neuron.\n\n\nShow the code\n%%itikz --temp-dir --tex-packages=tikz --tikz-libraries=arrows --implicit-standalone\n\\begin{tikzpicture}[scale=1.5]\n    \\node[circle, \n        minimum size = 15mm,\n        draw=blue\n        ] (Input) at (0,0) {};\n\n    \\node[circle, \n        minimum size = 15mm,\n        draw=blue\n        ] (Hidden1) at (3,0) {};\n    \n    \\node[] (w1) at (-3,0) {};\n    \\node[] (b1) at (0,-2) {};\n    \\node[] (b2) at (3,-2) {};\n\n    \\draw[-&gt;, shorten &gt;=1pt] (w1) -- (Input) node [midway,above] {\\large $-1.00$};\n    \\draw[-&gt;, shorten &gt;=1pt] (b1) node [below] {\\large $0.50$} -- (Input);\n    \\draw[-&gt;, shorten &gt;=1pt] (Input) -- (Hidden1) node [midway,above] {\\large $1.00$};\n    \\draw[-&gt;, shorten &gt;=1pt] (b2) node [below] {\\large $0.00$} -- (Hidden1);\n\\end{tikzpicture}\n\n\n\n\n\nAs we can see so far, there’s no change. This is because the second neuron’s bias is doing no offsetting, and the second neuron’s weight is just multiplying the output by \\(1\\), so there’s no change. Let’s try to adjust the second neuron’s bias now:\n\n\nShow the code\n%%itikz --temp-dir --tex-packages=tikz,pgfplots --tikz-libraries=arrows --implicit-standalone\n\\begin{tikzpicture}[scale=1.5]\n\\begin{axis}[grid,ymin=-1,ymax=6,ytick={-1,0,...,6}]\n\\addplot[color=blue,thick,samples=100]{max(max(-x+0.50,0),0)};\n\\end{axis}\n\\end{tikzpicture}\n\n\n\n\n\nLet’s try to adjust the second neuron’s bias now:\n\n\nShow the code\n%%itikz --temp-dir --tex-packages=tikz --tikz-libraries=arrows --implicit-standalone\n\\begin{tikzpicture}[scale=1.5]\n    \\node[circle, \n        minimum size = 15mm,\n        draw=blue\n        ] (Input) at (0,0) {};\n\n    \\node[circle, \n        minimum size = 15mm,\n        draw=blue\n        ] (Hidden1) at (3,0) {};\n    \n    \\node[] (w1) at (-3,0) {};\n    \\node[] (b1) at (0,-2) {};\n    \\node[] (b2) at (3,-2) {};\n\n    \\draw[-&gt;, shorten &gt;=1pt] (w1) -- (Input) node [midway,above] {\\large $-1.00$};\n    \\draw[-&gt;, shorten &gt;=1pt] (b1) node [below] {\\large $0.50$} -- (Input);\n    \\draw[-&gt;, shorten &gt;=1pt] (Input) -- (Hidden1) node [midway,above] {\\large $1.00$};\n    \\draw[-&gt;, shorten &gt;=1pt] (b2) node [below] {\\large $1.00$} -- (Hidden1);\n\\end{tikzpicture}\n\n\n\n\n\nNow, we see some fairly interesting behavior. The bias of the second neuron indeed shifted the overall function but, rather than shifting it horizontally, it shifted vertically.\n\n\nShow the code\n%%itikz --temp-dir --tex-packages=tikz,pgfplots --tikz-libraries=arrows --implicit-standalone\n\\begin{tikzpicture}[scale=1.5]\n\\begin{axis}[grid,ymin=-1,ymax=6,ytick={-1,0,...,6}]\n\\addplot[color=blue,thick,samples=100]{max(max(-x+0.50,0)+1.00,0)};\n\\end{axis}\n\\end{tikzpicture}\n\n\n\n\n\nWhat then might happen, if we make the \\(2\\)nd neuron’s weight \\(-2\\) rather than \\(1\\)?\n\n\nShow the code\n%%itikz --temp-dir --tex-packages=tikz --tikz-libraries=arrows --implicit-standalone\n\\begin{tikzpicture}[scale=1.5]\n    \\node[circle, \n        minimum size = 15mm,\n        draw=blue\n        ] (Input) at (0,0) {};\n\n    \\node[circle, \n        minimum size = 15mm,\n        draw=blue\n        ] (Hidden1) at (3,0) {};\n    \n    \\node[] (w1) at (-3,0) {};\n    \\node[] (b1) at (0,-2) {};\n    \\node[] (b2) at (3,-2) {};\n\n    \\draw[-&gt;, shorten &gt;=1pt] (w1) -- (Input) node [midway,above] {\\large $-1.00$};\n    \\draw[-&gt;, shorten &gt;=1pt] (b1) node [below] {\\large $0.50$} -- (Input);\n    \\draw[-&gt;, shorten &gt;=1pt] (Input) -- (Hidden1) node [midway,above] {\\large $-2.00$};\n    \\draw[-&gt;, shorten &gt;=1pt] (b2) node [below] {\\large $1.00$} -- (Hidden1);\n\\end{tikzpicture}\n\n\n\n\n\nSomething exciting has occurred! What we have here is a neuron that has both an activation and a deactivation point. Now, the output after these two neurons will be variable, so long as it is inside of some specific range. So, basically if both neurons are activated then we actually sort of see this influence on the value. Otherwise, if both neurons aren’t activated, then the output is just a static value.\n\n\nShow the code\n%%itikz --temp-dir --tex-packages=tikz,pgfplots --tikz-libraries=arrows --implicit-standalone\n\\begin{tikzpicture}[scale=1.5]\n\\begin{axis}[grid,ymin=-1,ymax=2,ytick={-1,0,...,2},xmin=-2,xmax=2]\n\\addplot[color=blue,thick,samples=500]{max(-2.0*max(-x+0.50,0)+1.00,0)};\n\\end{axis}\n\\end{tikzpicture}\n\n\n\n\n\nSo, when we are below the activation of the first neuron, the output will be the bias of the second neuron \\(1.00\\).\n\n\nShow the code\n%%itikz --temp-dir --tex-packages=tikz --tikz-libraries=arrows --implicit-standalone\n\\begin{tikzpicture}[scale=1.5]\n    \\node[circle, \n        minimum size = 15mm,\n        draw=blue\n        ] (Input) at (0,0) {};\n\n    \\node[circle, \n        minimum size = 15mm,\n        draw=blue,\n        fill=green\n        ] (Hidden1) at (3,0) {};\n    \n    \\node[] (w1) at (-3,0) {};\n    \\node[] (b1) at (0,-2) {};\n    \\node[] (b2) at (3,-2) {};\n\n    \\draw[-&gt;, shorten &gt;=1pt] (w1) node [left] {\\large $0.50$} -- (Input) node [midway,above] {\\large $-1.00$};\n    \\draw[-&gt;, shorten &gt;=1pt] (b1) node [below] {\\large $0.50$} -- (Input);\n    \\draw[-&gt;, shorten &gt;=1pt] (Input) -- (Hidden1) node [midway,above] {\\large $-2.00$};\n    \\draw[-&gt;, shorten &gt;=1pt] (b2) node [below] {\\large $1.00$} -- (Hidden1);\n    \\draw[-&gt;, shorten &gt;=1pt] (Hidden1) -- (6,0) node [right] {$1.00$};\n\\end{tikzpicture}\n\n\n\n\n\nThe second neuron is activated if it’s input is smaller than \\(0.50\\).\nConsider what happens when the input to the first neuron is \\(0.00, -0.10, \\ldots\\). The output of the first neuron is \\(0.50, 0.60, \\ldots\\) which implies that the second neuron is deactivated, so the output of the second neuron is simply zero.\n\n\nShow the code\n%%itikz --temp-dir --tex-packages=tikz --tikz-libraries=arrows --implicit-standalone\n\\begin{tikzpicture}[scale=1.5]\n    \\node[circle, \n        minimum size = 15mm,\n        draw=blue,\n        fill=green\n        ] (Input) at (0,0) {};\n\n    \\node[circle, \n        minimum size = 15mm,\n        draw=blue\n        ] (Hidden1) at (3,0) {};\n    \n    \\node[] (w1) at (-3,0) {};\n    \\node[] (b1) at (0,-2) {};\n    \\node[] (b2) at (3,-2) {};\n\n    \\draw[-&gt;, shorten &gt;=1pt] (w1) node [left] {\\large $0.50$} -- (Input) node [midway,above] {\\large $-1.00$};\n    \\draw[-&gt;, shorten &gt;=1pt] (b1) node [below] {\\large $0.50$} -- (Input);\n    \\draw[-&gt;, shorten &gt;=1pt] (Input) -- (Hidden1) node [midway,above] {\\large $-2.00$};\n    \\draw[-&gt;, shorten &gt;=1pt] (b2) node [below] {\\large $1.00$} -- (Hidden1);\n    \\draw[-&gt;, shorten &gt;=1pt] (Hidden1) -- (6,0) node [right] {$0.00$};\n\\end{tikzpicture}"
  },
  {
    "objectID": "posts/coding-a-neural-network-layer/index.html#relu-activation-in-hidden-layers",
    "href": "posts/coding-a-neural-network-layer/index.html#relu-activation-in-hidden-layers",
    "title": "Coding a neural network layer",
    "section": "ReLU Activation in hidden layers",
    "text": "ReLU Activation in hidden layers\nLet’s now take this concept and use it to fit to a sine wave-like function using two hidden layers of \\(8\\) neurons each and we can hand-tune the values to fit the curve. We’ll do this by working with \\(1\\) pair of neurons at a time, which means \\(1\\) neuron from each layer individually. For simplicity, we are also going to assume that the layers are not densely connected, and each neuron from the first hidden layer connects to only one neuron from the second hidden layer. That’s usually not the case with the real models, but we want this simplification for the purpose of this demo. Additionally, this example model takes a single value as an input, the input to the sine function, and outputs a single value like the sine function. The output layer uses the linear activation function and the hidden layers will use the rectified linear activation function.\nTo start, we’ll set all weights to \\(0\\) and work with the first pair of neurons:\n\n\nShow the code\n%%itikz --temp-dir --tex-packages=tikz --tikz-libraries=arrows --implicit-standalone\n\\begin{tikzpicture}\n\n\\node[circle, \n    minimum size = 15mm,\n    fill=red!30\n    ] (Input) at (0,0) {\\large $x_1$};\n\n\\foreach \\i in {1,2,...,8}\n{\n    \\node[circle, \n        minimum size = 15mm,\n        fill=blue!50,\n        yshift=90 mm\n        ] (Hidden1-\\i) at (3.0,-\\i * 2) {\\large $h_\\i^{(1)}$};\n        \n}\n\\foreach \\i in {1,2,...,8}\n{\n    \\node[circle, \n        minimum size = 15mm,\n        fill=blue!50,\n        yshift=90 mm\n        ] (Hidden2-\\i) at (6.0,-\\i * 2) {\\large $h_\\i^{(2)}$};\n        \n}\n\n\\node[circle, \n    minimum size = 15mm,\n    fill=red!30\n    ] (Output) at (9,0) {\\large $\\hat{y}_1$};\n\n% Connect neurons In-Hidden1\n\\foreach \\j in {2,...,8}\n{\n    \\draw[-&gt;, shorten &gt;=1pt] (Input) -- (Hidden1-\\j);   \n}\n% Connect neurons Hidden1-Hidden2\n\\foreach \\i in {2,...,8}\n{\n    \n        \\draw[-&gt;, shorten &gt;=1pt] (Hidden1-\\i) -- (Hidden2-\\i);   \n    \n}\n\n\\foreach \\i in {2,...,8}\n{\n    \n        \\draw[-&gt;, shorten &gt;=1pt] (Hidden2-\\i) -- (Output);   \n}\n\\draw[-&gt;, shorten &gt;=1pt] (Input) -- node [midway] {$0.00$} (Hidden1-1);   \n\\draw[-&gt;, shorten &gt;=1pt] (Hidden1-1) -- node [midway] {$0.00$} (Hidden2-1); \n\\draw[-&gt;, shorten &gt;=1pt] (Hidden2-1) -- node [midway] {$0.00$} (Output); \n\\draw[-&gt;, shorten &gt;=1pt] (6,6) node [below] {$0.00$} --  (Hidden2-1); \n\\draw[-&gt;, shorten &gt;=1pt] (3,6) node [below] {$0.00$} --  (Hidden1-1); \n\\end{tikzpicture}\n\n\n\n\n\nNext, we can set the weight for the hidden layer neurons and the output neuron to \\(1.00\\), and we can see how this impacts the output:\n\n\nShow the code\n%%itikz --temp-dir --tex-packages=tikz --tikz-libraries=arrows --implicit-standalone\n\\begin{tikzpicture}\n\n\\node[circle, \n    minimum size = 15mm,\n    fill=red!30\n    ] (Input) at (0,0) {\\large $x_1$};\n\n\\foreach \\i in {1,2,...,8}\n{\n    \\node[circle, \n        minimum size = 15mm,\n        fill=blue!50,\n        yshift=90 mm\n        ] (Hidden1-\\i) at (3.0,-\\i * 2) {\\large $h_\\i^{(1)}$};\n        \n}\n\\foreach \\i in {1,2,...,8}\n{\n    \\node[circle, \n        minimum size = 15mm,\n        fill=blue!50,\n        yshift=90 mm\n        ] (Hidden2-\\i) at (6.0,-\\i * 2) {\\large $h_\\i^{(2)}$};\n        \n}\n\n\\node[circle, \n    minimum size = 15mm,\n    fill=red!30\n    ] (Output) at (9,0) {\\large $\\hat{y}_1$};\n\n% Connect neurons In-Hidden1\n\\foreach \\j in {2,...,8}\n{\n    \\draw[-&gt;, shorten &gt;=1pt] (Input) -- (Hidden1-\\j);   \n}\n% Connect neurons Hidden1-Hidden2\n\\foreach \\i in {2,...,8}\n{\n    \n        \\draw[-&gt;, shorten &gt;=1pt] (Hidden1-\\i) -- (Hidden2-\\i);   \n    \n}\n\n\\foreach \\i in {2,...,8}\n{\n    \n        \\draw[-&gt;, shorten &gt;=1pt] (Hidden2-\\i) -- (Output);   \n}\n\\draw[-&gt;, shorten &gt;=1pt] (Input) -- node [midway] {$1.00$} (Hidden1-1);   \n\\draw[-&gt;, shorten &gt;=1pt] (Hidden1-1) -- node [midway,above] {$1.00$} (Hidden2-1); \n\\draw[-&gt;, shorten &gt;=1pt] (Hidden2-1) -- node [midway] {$1.00$} (Output); \n\\draw[-&gt;, shorten &gt;=1pt] (6,6) node [below] {$0.00$} --  (Hidden2-1); \n\\draw[-&gt;, shorten &gt;=1pt] (3,6) node [below] {$0.00$} --  (Hidden1-1); \n\\end{tikzpicture}\n\n\n\n\n\nThe output is:\n\n\nShow the code\n%%itikz --temp-dir --tex-packages=tikz,pgfplots --tikz-libraries=arrows --implicit-standalone\n\\begin{tikzpicture}[scale=1.5]\n\\begin{axis}[grid,ymin=-2,ymax=2,ytick={-2,-1,...,2},xmin=0,xmax=1]\n\\addplot[color=blue,thick,samples=1000]{max(max(x,0),0)};\n\\addplot[color=green,samples=1000,domain=0:1]{sin(deg(2*3.14*x))};\n\\end{axis}\n\\end{tikzpicture}\n\n\n\n\n\nWe can increase the slope of the output by adjusting the weight of the first neuron of the first layer to \\(6.00\\).\n\n\nShow the code\n%%itikz --temp-dir --tex-packages=tikz --tikz-libraries=arrows --implicit-standalone\n\\begin{tikzpicture}\n\n\\node[circle, \n    minimum size = 15mm,\n    fill=red!30\n    ] (Input) at (0,0) {\\large $x_1$};\n\n\\foreach \\i in {1,2,...,8}\n{\n    \\node[circle, \n        minimum size = 15mm,\n        fill=blue!50,\n        yshift=90 mm\n        ] (Hidden1-\\i) at (3.0,-\\i * 2) {\\large $h_\\i^{(1)}$};\n        \n}\n\\foreach \\i in {1,2,...,8}\n{\n    \\node[circle, \n        minimum size = 15mm,\n        fill=blue!50,\n        yshift=90 mm\n        ] (Hidden2-\\i) at (6.0,-\\i * 2) {\\large $h_\\i^{(2)}$};\n        \n}\n\n\\node[circle, \n    minimum size = 15mm,\n    fill=red!30\n    ] (Output) at (9,0) {\\large $\\hat{y}_1$};\n\n% Connect neurons In-Hidden1\n\\foreach \\j in {2,...,8}\n{\n    \\draw[-&gt;, shorten &gt;=1pt] (Input) -- (Hidden1-\\j);   \n}\n% Connect neurons Hidden1-Hidden2\n\\foreach \\i in {2,...,8}\n{\n    \n        \\draw[-&gt;, shorten &gt;=1pt] (Hidden1-\\i) -- (Hidden2-\\i);   \n    \n}\n\n\\foreach \\i in {2,...,8}\n{\n    \n        \\draw[-&gt;, shorten &gt;=1pt] (Hidden2-\\i) -- (Output);   \n}\n\\draw[-&gt;, shorten &gt;=1pt] (Input) -- node [midway] {$6.00$} (Hidden1-1);   \n\\draw[-&gt;, shorten &gt;=1pt] (Hidden1-1) -- node [midway,above] {$1.00$} (Hidden2-1); \n\\draw[-&gt;, shorten &gt;=1pt] (Hidden2-1) -- node [midway] {$1.00$} (Output); \n\\draw[-&gt;, shorten &gt;=1pt] (6,6) node [below] {$0.00$} --  (Hidden2-1); \n\\draw[-&gt;, shorten &gt;=1pt] (3,6) node [below] {$0.00$} --  (Hidden1-1); \n\\end{tikzpicture}\n\n\n\n\n\nWe can now see, for example, that the initial slope of this function is what we’d like, but we have a problem.\n\n\nShow the code\n%%itikz --temp-dir --tex-packages=tikz,pgfplots --tikz-libraries=arrows --implicit-standalone\n\\begin{tikzpicture}[scale=1.5]\n\\begin{axis}[grid,ymin=-2,ymax=2,ytick={-2,-1,...,2},xmin=0,xmax=1]\n\\addplot[color=blue,thick,samples=1000]{max(max(6*x,0),0)};\n\\addplot[color=green,samples=1000,domain=0:1]{sin(deg(2*3.14*x))};\n\\end{axis}\n\\end{tikzpicture}\n\n\n\n\n\nCurrently, this function never ends because this neuron pair never deactivates. We can visually see where we’d like the deactivation to occur. It’s where the red fitment line diverges from our green sine wave. So now, while we have the correct slope, we need to set this spot as our deactivation point. To do that, we start by increasing the bias for the second neuron of the hidden layer to \\(0.70\\).\n\n\nShow the code\n%%itikz --temp-dir --tex-packages=tikz --tikz-libraries=arrows --implicit-standalone\n\\begin{tikzpicture}\n\n\\node[circle, \n    minimum size = 15mm,\n    fill=red!30\n    ] (Input) at (0,0) {\\large $x_1$};\n\n\\foreach \\i in {1,2,...,8}\n{\n    \\node[circle, \n        minimum size = 15mm,\n        fill=blue!50,\n        yshift=90 mm\n        ] (Hidden1-\\i) at (3.0,-\\i * 2) {\\large $h_\\i^{(1)}$};\n        \n}\n\\foreach \\i in {1,2,...,8}\n{\n    \\node[circle, \n        minimum size = 15mm,\n        fill=blue!50,\n        yshift=90 mm\n        ] (Hidden2-\\i) at (6.0,-\\i * 2) {\\large $h_\\i^{(2)}$};\n        \n}\n\n\\node[circle, \n    minimum size = 15mm,\n    fill=red!30\n    ] (Output) at (9,0) {\\large $\\hat{y}_1$};\n\n% Connect neurons In-Hidden1\n\\foreach \\j in {2,...,8}\n{\n    \\draw[-&gt;, shorten &gt;=1pt] (Input) -- (Hidden1-\\j);   \n}\n% Connect neurons Hidden1-Hidden2\n\\foreach \\i in {2,...,8}\n{\n    \n        \\draw[-&gt;, shorten &gt;=1pt] (Hidden1-\\i) -- (Hidden2-\\i);   \n    \n}\n\n\\foreach \\i in {2,...,8}\n{\n    \n        \\draw[-&gt;, shorten &gt;=1pt] (Hidden2-\\i) -- (Output);   \n}\n\\draw[-&gt;, shorten &gt;=1pt] (Input) -- node [midway] {$6.00$} (Hidden1-1);   \n\\draw[-&gt;, shorten &gt;=1pt] (Hidden1-1) -- node [midway,above] {$1.00$} (Hidden2-1); \n\\draw[-&gt;, shorten &gt;=1pt] (Hidden2-1) -- node [midway] {$1.00$} (Output); \n\\draw[-&gt;, shorten &gt;=1pt] (6,6) node [below] {$0.70$} --  (Hidden2-1); \n\\draw[-&gt;, shorten &gt;=1pt] (3,6) node [below] {$0.00$} --  (Hidden1-1); \n\\end{tikzpicture}\n\n\n\n\n\nRecall, that this offsets the overall function vertically:\n\n\nShow the code\n%%itikz --temp-dir --tex-packages=tikz,pgfplots --tikz-libraries=arrows --implicit-standalone\n\\begin{tikzpicture}[scale=1.5]\n\\begin{axis}[grid,ymin=-2,ymax=2,ytick={-2,-1,...,2},xmin=0,xmax=1]\n\\addplot[color=blue,thick,samples=1000]{max(max(6*x,0)+0.70,0)};\n\\addplot[color=green,samples=1000,domain=0:1]{sin(deg(2*3.14*x))};\n\\end{axis}\n\\end{tikzpicture}\n\n\n\n\n\nNow, we can set the weight for the second neuron to \\(-1\\), causing a deactivation point to occur, atleast horizontally, where we want it.\n\n\nShow the code\n%%itikz --temp-dir --tex-packages=tikz --tikz-libraries=arrows --implicit-standalone\n\\begin{tikzpicture}\n\n\\node[circle, \n    minimum size = 15mm,\n    fill=red!30\n    ] (Input) at (0,0) {\\large $x_1$};\n\n\\foreach \\i in {1,2,...,8}\n{\n    \\node[circle, \n        minimum size = 15mm,\n        fill=blue!50,\n        yshift=90 mm\n        ] (Hidden1-\\i) at (3.0,-\\i * 2) {\\large $h_\\i^{(1)}$};\n        \n}\n\\foreach \\i in {1,2,...,8}\n{\n    \\node[circle, \n        minimum size = 15mm,\n        fill=blue!50,\n        yshift=90 mm\n        ] (Hidden2-\\i) at (6.0,-\\i * 2) {\\large $h_\\i^{(2)}$};\n        \n}\n\n\\node[circle, \n    minimum size = 15mm,\n    fill=red!30\n    ] (Output) at (9,0) {\\large $\\hat{y}_1$};\n\n% Connect neurons In-Hidden1\n\\foreach \\j in {2,...,8}\n{\n    \\draw[-&gt;, shorten &gt;=1pt] (Input) -- (Hidden1-\\j);   \n}\n% Connect neurons Hidden1-Hidden2\n\\foreach \\i in {2,...,8}\n{\n    \n        \\draw[-&gt;, shorten &gt;=1pt] (Hidden1-\\i) -- (Hidden2-\\i);   \n    \n}\n\n\\foreach \\i in {2,...,8}\n{\n    \n        \\draw[-&gt;, shorten &gt;=1pt] (Hidden2-\\i) -- (Output);   \n}\n\\draw[-&gt;, shorten &gt;=1pt] (Input) -- node [midway] {$6.00$} (Hidden1-1);   \n\\draw[-&gt;, shorten &gt;=1pt] (Hidden1-1) -- node [midway,above] {$-1.00$} (Hidden2-1); \n\\draw[-&gt;, shorten &gt;=1pt] (Hidden2-1) -- node [midway] {$1.00$} (Output); \n\\draw[-&gt;, shorten &gt;=1pt] (6,6) node [below] {$0.70$} --  (Hidden2-1); \n\\draw[-&gt;, shorten &gt;=1pt] (3,6) node [below] {$0.00$} --  (Hidden1-1); \n\\end{tikzpicture}\n\n\n\n\n\nWe get:\n\n\nShow the code\n%%itikz --temp-dir --tex-packages=tikz,pgfplots --tikz-libraries=arrows --implicit-standalone\n\\begin{tikzpicture}[scale=1.5]\n\\begin{axis}[grid,ymin=-2,ymax=2,ytick={-2,-1,...,2},xmin=0,xmax=1]\n\\addplot[color=blue,thick,samples=1000]{max(-max(6*x,0)+0.70,0)};\n\\addplot[color=green,samples=1000,domain=0:1]{sin(deg(2*3.14*x))};\n\\end{axis}\n\\end{tikzpicture}\n\n\n\n\n\nNow, we’d like to flip this slope back. How might we flip the output of these two neurons?\n\n\nShow the code\n%%itikz --temp-dir --tex-packages=tikz --tikz-libraries=arrows --implicit-standalone\n\\begin{tikzpicture}\n\n\\node[circle, \n    minimum size = 15mm,\n    fill=red!30\n    ] (Input) at (0,0) {\\large $x_1$};\n\n\\foreach \\i in {1,2,...,8}\n{\n    \\node[circle, \n        minimum size = 15mm,\n        fill=blue!50,\n        yshift=90 mm\n        ] (Hidden1-\\i) at (3.0,-\\i * 2) {\\large $h_\\i^{(1)}$};\n        \n}\n\\foreach \\i in {1,2,...,8}\n{\n    \\node[circle, \n        minimum size = 15mm,\n        fill=blue!50,\n        yshift=90 mm\n        ] (Hidden2-\\i) at (6.0,-\\i * 2) {\\large $h_\\i^{(2)}$};\n        \n}\n\n\\node[circle, \n    minimum size = 15mm,\n    fill=red!30\n    ] (Output) at (9,0) {\\large $\\hat{y}_1$};\n\n% Connect neurons In-Hidden1\n\\foreach \\j in {2,...,8}\n{\n    \\draw[-&gt;, shorten &gt;=1pt] (Input) -- (Hidden1-\\j);   \n}\n% Connect neurons Hidden1-Hidden2\n\\foreach \\i in {2,...,8}\n{\n    \n        \\draw[-&gt;, shorten &gt;=1pt] (Hidden1-\\i) -- (Hidden2-\\i);   \n    \n}\n\n\\foreach \\i in {2,...,8}\n{\n    \n        \\draw[-&gt;, shorten &gt;=1pt] (Hidden2-\\i) -- (Output);   \n}\n\\draw[-&gt;, shorten &gt;=1pt] (Input) -- node [midway] {$6.00$} (Hidden1-1);   \n\\draw[-&gt;, shorten &gt;=1pt] (Hidden1-1) -- node [midway,above] {$-1.00$} (Hidden2-1); \n\\draw[-&gt;, shorten &gt;=1pt] (Hidden2-1) -- node [midway] {$-1.00$} (Output); \n\\draw[-&gt;, shorten &gt;=1pt] (6,6) node [below] {$0.70$} --  (Hidden2-1); \n\\draw[-&gt;, shorten &gt;=1pt] (3,6) node [below] {$0.00$} --  (Hidden1-1); \n\\end{tikzpicture}\n\n\n\n\n\nIt seems like we can take the weights of the connection to the output neuron, which is currently \\(1.0\\) and just flip it to a \\(-1\\), and that flips the function:\n\n\nShow the code\n%%itikz --temp-dir --tex-packages=tikz,pgfplots --tikz-libraries=arrows --implicit-standalone\n\\begin{tikzpicture}[scale=1.5]\n\\begin{axis}[grid,ymin=-2,ymax=2,ytick={-2,-1,...,2},xmin=0,xmax=1]\n\\addplot[color=blue,thick,samples=1000]{-max(-max(6*x,0)+0.70,0)};\n\\addplot[color=green,samples=1000,domain=0:1]{sin(deg(2*3.14*x))};\n\\end{axis}\n\\end{tikzpicture}\n\n\n\n\n\nWe’re certainly getting closer to making this first section fit how we want. Now, all we need to do is offset this up a bit. For this hand-optimized example, we’re going to use the first \\(7\\) pairs of neurons in the hidden layers to create the sine wave’s shape.\n\n\nShow the code\n%%itikz --temp-dir --tex-packages=tikz --tikz-libraries=arrows --implicit-standalone\n\\begin{tikzpicture}\n\n\\node[circle, \n    minimum size = 15mm,\n    fill=red!30\n    ] (Input) at (0,0) {\\large $x_1$};\n\n\\foreach \\i in {1,2,...,8}\n{\n    \\node[circle, \n        minimum size = 15mm,\n        fill=blue!50,\n        yshift=90 mm\n        ] (Hidden1-\\i) at (3.0,-\\i * 2) {\\large $h_\\i^{(1)}$};\n        \n}\n\\foreach \\i in {1,2,...,8}\n{\n    \\node[circle, \n        minimum size = 15mm,\n        fill=blue!50,\n        yshift=90 mm\n        ] (Hidden2-\\i) at (6.0,-\\i * 2) {\\large $h_\\i^{(2)}$};\n        \n}\n\n\\node[circle, \n    minimum size = 15mm,\n    fill=red!30\n    ] (Output) at (9,0) {\\large $\\hat{y}_1$};\n\n% Connect neurons In-Hidden1\n\\foreach \\j in {2,...,7}\n{\n    \\draw[-&gt;, shorten &gt;=1pt] (Input) -- (Hidden1-\\j);   \n}\n% Connect neurons Hidden1-Hidden2\n\\foreach \\i in {2,...,7}\n{\n    \n        \\draw[-&gt;, shorten &gt;=1pt] (Hidden1-\\i) -- (Hidden2-\\i);   \n    \n}\n\n\\foreach \\i in {2,...,7}\n{\n    \n        \\draw[-&gt;, shorten &gt;=1pt] (Hidden2-\\i) -- (Output);   \n}\n\\draw[-&gt;, shorten &gt;=1pt] (Input) -- node [midway] {$6.00$} (Hidden1-1);   \n\\draw[-&gt;, shorten &gt;=1pt] (Hidden1-1) -- node [midway,above] {$-1.00$} (Hidden2-1); \n\\draw[-&gt;, shorten &gt;=1pt] (Hidden2-1) -- node [midway] {$-1.00$} (Output); \n\\draw[-&gt;, shorten &gt;=1pt] (6,6) node [below] {$0.70$} --  (Hidden2-1); \n\\draw[-&gt;, shorten &gt;=1pt] (3,6) node [below] {$0.00$} --  (Hidden1-1); \n\n\\draw[-&gt;, shorten &gt;=1pt] (Input) -- node [midway] {$0.00$} (Hidden1-8); \n\\draw[-&gt;, shorten &gt;=1pt] (3,-9) node [below] {$0.00$} --  (Hidden1-8); \n\\draw[-&gt;, shorten &gt;=1pt] (Hidden1-8) -- node [midway,above] {$0.00$} (Hidden2-8); \n\\draw[-&gt;, shorten &gt;=1pt] (6,-9) node [below] {$1.00$} --  (Hidden2-8); \n\\draw[-&gt;, shorten &gt;=1pt] (Hidden2-8) -- node [midway] {$0.70$} (Output); \n\\end{tikzpicture}\n\n\n\n\n\nIf we set the bias of the second neuron in the bottom pair to \\(1.0\\) and the weight to the output neuron to \\(0.70\\), we can vertically shift the line like so:\n\n\nShow the code\n%%itikz --temp-dir --tex-packages=tikz,pgfplots --tikz-libraries=arrows --implicit-standalone\n\\begin{tikzpicture}[scale=1.5]\n\\begin{axis}[grid,ymin=-2,ymax=2,ytick={-2,-1,...,2},xmin=0,xmax=1]\n\\addplot[color=blue,thick,samples=1000]{-max(-max(6*x,0)+0.70,0))+0.70};\n\\addplot[color=green,samples=1000,domain=0:1]{sin(deg(2*3.14*x))};\n\\end{axis}\n\\end{tikzpicture}\n\n\n\n\n\nAt this point, we have completed the first section with an “area of effect” being the first upward section of the sine wave. We can start on the next section that we wish to do. We can start on the next section that we wish to do. We can start by setting all weights for this second pair of neurons to \\(1\\) including the output neuron.\n\n\nShow the code\n%%itikz --temp-dir --tex-packages=tikz --tikz-libraries=arrows --implicit-standalone\n\\begin{tikzpicture}\n\n\\node[circle, \n    minimum size = 15mm,\n    fill=red!30\n    ] (Input) at (0,0) {\\large $x_1$};\n\n\\foreach \\i in {1,2,...,8}\n{\n    \\node[circle, \n        minimum size = 15mm,\n        fill=blue!50,\n        yshift=90 mm\n        ] (Hidden1-\\i) at (3.0,-\\i * 2) {\\large $h_\\i^{(1)}$};\n        \n}\n\\foreach \\i in {1,2,...,8}\n{\n    \\node[circle, \n        minimum size = 15mm,\n        fill=blue!50,\n        yshift=90 mm\n        ] (Hidden2-\\i) at (6.0,-\\i * 2) {\\large $h_\\i^{(2)}$};\n        \n}\n\n\\node[circle, \n    minimum size = 15mm,\n    fill=red!30\n    ] (Output) at (9,0) {\\large $\\hat{y}_1$};\n\n% Connect neurons In-Hidden1\n\\foreach \\j in {3,...,7}\n{\n    \\draw[-&gt;, shorten &gt;=1pt] (Input) -- (Hidden1-\\j);   \n}\n% Connect neurons Hidden1-Hidden2\n\\foreach \\i in {3,...,7}\n{\n    \n        \\draw[-&gt;, shorten &gt;=1pt] (Hidden1-\\i) -- (Hidden2-\\i);   \n    \n}\n\n\\foreach \\i in {3,...,7}\n{\n    \n        \\draw[-&gt;, shorten &gt;=1pt] (Hidden2-\\i) -- (Output);   \n}\n\\draw[-&gt;, shorten &gt;=1pt] (Input) -- node [midway] {$6.00$} (Hidden1-1);   \n\\draw[-&gt;, shorten &gt;=1pt] (Hidden1-1) -- node [midway,above] {$-1.00$} (Hidden2-1); \n\\draw[-&gt;, shorten &gt;=1pt] (Hidden2-1) -- node [midway] {$-1.00$} (Output); \n\\draw[-&gt;, shorten &gt;=1pt] (6,6) node [below] {$0.70$} --  (Hidden2-1); \n\\draw[-&gt;, shorten &gt;=1pt] (3,6) node [below] {$0.00$} --  (Hidden1-1); \n\n\\draw[-&gt;, shorten &gt;=1pt] (Input) -- node [midway] {$0.00$} (Hidden1-8); \n\\draw[-&gt;, shorten &gt;=1pt] (3,-9) node [below] {$0.00$} --  (Hidden1-8); \n\\draw[-&gt;, shorten &gt;=1pt] (Hidden1-8) -- node [midway,above] {$0.00$} (Hidden2-8); \n\\draw[-&gt;, shorten &gt;=1pt] (6,-9) node [below] {$1.00$} --  (Hidden2-8); \n\\draw[-&gt;, shorten &gt;=1pt] (Hidden2-8) -- node [midway] {$0.70$} (Output); \n\n\\draw[-&gt;, shorten &gt;=1pt] (Input) -- node [midway] {$1.00$} (Hidden1-2); \n\\draw[-&gt;, shorten &gt;=1pt] (3,4) node [below] {$0.00$} --  (Hidden1-2); \n\\draw[-&gt;, shorten &gt;=1pt] (Hidden1-2) -- node [midway,above] {$1.00$} (Hidden2-2); \n\\draw[-&gt;, shorten &gt;=1pt] (6,4) node [below] {$0.00$} --  (Hidden2-2); \n\\draw[-&gt;, shorten &gt;=1pt] (Hidden2-2) -- node [midway] {$1.00$} (Output); \n\\end{tikzpicture}\n\n\n\n\n\nAt this point, this second pair of neurons activation is beginning too soon, which is impacting the area of effect of the top pair we already aligned.\n\n\nShow the code\n%%itikz --temp-dir --tex-packages=tikz,pgfplots --tikz-libraries=arrows --implicit-standalone\n\\begin{tikzpicture}[scale=1.5]\n\\begin{axis}[grid,ymin=-2,ymax=2,ytick={-2,-1,...,2},xmin=0,xmax=1]\n\\addplot[color=blue,thick,samples=1000]{-max(-max(6*x,0)+0.70,0))+0.70+max(max(x,0),0)};\n\\addplot[color=green,samples=1000,domain=0:1]{sin(deg(2*3.14*x))};\n\\end{axis}\n\\end{tikzpicture}\n\n\n\n\n\nTo fix this, we want this second pair to start influencing the output where the first pair deactivates, so we want to adjust the function horizontally. As you can recall from earlier, we adjust the first neuron’s bias in this neuron pair to achieve this. Also, to modify the slope, we’ll set the weight coming into that first neuron for the second pair, setting it to \\(3.50\\).\n\n\nShow the code\n%%itikz --temp-dir --tex-packages=tikz --tikz-libraries=arrows --implicit-standalone\n\\begin{tikzpicture}\n\n\\node[circle, \n    minimum size = 15mm,\n    fill=red!30\n    ] (Input) at (0,0) {\\large $x_1$};\n\n\\foreach \\i in {1,2,...,8}\n{\n    \\node[circle, \n        minimum size = 15mm,\n        fill=blue!50,\n        yshift=90 mm\n        ] (Hidden1-\\i) at (3.0,-\\i * 2) {\\large $h_\\i^{(1)}$};\n        \n}\n\\foreach \\i in {1,2,...,8}\n{\n    \\node[circle, \n        minimum size = 15mm,\n        fill=blue!50,\n        yshift=90 mm\n        ] (Hidden2-\\i) at (6.0,-\\i * 2) {\\large $h_\\i^{(2)}$};\n        \n}\n\n\\node[circle, \n    minimum size = 15mm,\n    fill=red!30\n    ] (Output) at (9,0) {\\large $\\hat{y}_1$};\n\n% Connect neurons In-Hidden1\n\\foreach \\j in {3,...,7}\n{\n    \\draw[-&gt;, shorten &gt;=1pt] (Input) -- (Hidden1-\\j);   \n}\n% Connect neurons Hidden1-Hidden2\n\\foreach \\i in {3,...,7}\n{\n    \n        \\draw[-&gt;, shorten &gt;=1pt] (Hidden1-\\i) -- (Hidden2-\\i);   \n    \n}\n\n\\foreach \\i in {3,...,7}\n{\n    \n        \\draw[-&gt;, shorten &gt;=1pt] (Hidden2-\\i) -- (Output);   \n}\n\\draw[-&gt;, shorten &gt;=1pt] (Input) -- node [midway] {$6.00$} (Hidden1-1);   \n\\draw[-&gt;, shorten &gt;=1pt] (Hidden1-1) -- node [midway,above] {$-1.00$} (Hidden2-1); \n\\draw[-&gt;, shorten &gt;=1pt] (Hidden2-1) -- node [midway] {$-1.00$} (Output); \n\\draw[-&gt;, shorten &gt;=1pt] (6,6) node [below] {$0.70$} --  (Hidden2-1); \n\\draw[-&gt;, shorten &gt;=1pt] (3,6) node [below] {$0.00$} --  (Hidden1-1); \n\n\\draw[-&gt;, shorten &gt;=1pt] (Input) -- node [midway] {$0.00$} (Hidden1-8); \n\\draw[-&gt;, shorten &gt;=1pt] (3,-9) node [below] {$0.00$} --  (Hidden1-8); \n\\draw[-&gt;, shorten &gt;=1pt] (Hidden1-8) -- node [midway,above] {$0.00$} (Hidden2-8); \n\\draw[-&gt;, shorten &gt;=1pt] (6,-9) node [below] {$1.00$} --  (Hidden2-8); \n\\draw[-&gt;, shorten &gt;=1pt] (Hidden2-8) -- node [midway] {$0.70$} (Output); \n\n\\draw[-&gt;, shorten &gt;=1pt] (Input) -- node [midway] {$3.50$} (Hidden1-2); \n\\draw[-&gt;, shorten &gt;=1pt] (3,4) node [below] {$-0.42$} --  (Hidden1-2); \n\\draw[-&gt;, shorten &gt;=1pt] (Hidden1-2) -- node [midway,above] {$1.00$} (Hidden2-2); \n\\draw[-&gt;, shorten &gt;=1pt] (6,4) node [below] {$0.00$} --  (Hidden2-2); \n\\draw[-&gt;, shorten &gt;=1pt] (Hidden2-2) -- node [midway] {$1.00$} (Output); \n\\end{tikzpicture}\n\n\n\n\n\nAfter these adjustments:\n\n\nShow the code\n%%itikz --temp-dir --tex-packages=tikz,pgfplots --tikz-libraries=arrows --implicit-standalone\n\\begin{tikzpicture}[scale=1.5]\n\\begin{axis}[grid,ymin=-2,ymax=2,ytick={-2,-1,...,2},xmin=0,xmax=1]\n\\addplot[color=blue,thick,samples=1000]{-max(-max(6*x,0)+0.70,0))+0.70+max(max(3.50*x - 0.42,0),0)};\n\\addplot[color=green,samples=1000,domain=0:1]{sin(deg(2*3.14*x))};\n\\end{axis}\n\\end{tikzpicture}\n\n\n\n\n\nWe will now use the same methodology as we did with the first pair of neurons to set the deactivation point. We set the weight for the second neuron in the hidden layer pair to \\(-1.00\\) and the bias to \\(0.27\\).\n\n\nShow the code\n%%itikz --temp-dir --tex-packages=tikz --tikz-libraries=arrows --implicit-standalone\n\\begin{tikzpicture}\n\n\\node[circle, \n    minimum size = 15mm,\n    fill=red!30\n    ] (Input) at (0,0) {\\large $x_1$};\n\n\\foreach \\i in {1,2,...,8}\n{\n    \\node[circle, \n        minimum size = 15mm,\n        fill=blue!50,\n        yshift=90 mm\n        ] (Hidden1-\\i) at (3.0,-\\i * 2) {\\large $h_\\i^{(1)}$};\n        \n}\n\\foreach \\i in {1,2,...,8}\n{\n    \\node[circle, \n        minimum size = 15mm,\n        fill=blue!50,\n        yshift=90 mm\n        ] (Hidden2-\\i) at (6.0,-\\i * 2) {\\large $h_\\i^{(2)}$};\n        \n}\n\n\\node[circle, \n    minimum size = 15mm,\n    fill=red!30\n    ] (Output) at (9,0) {\\large $\\hat{y}_1$};\n\n% Connect neurons In-Hidden1\n\\foreach \\j in {3,...,7}\n{\n    \\draw[-&gt;, shorten &gt;=1pt] (Input) -- (Hidden1-\\j);   \n}\n% Connect neurons Hidden1-Hidden2\n\\foreach \\i in {3,...,7}\n{\n    \n        \\draw[-&gt;, shorten &gt;=1pt] (Hidden1-\\i) -- (Hidden2-\\i);   \n    \n}\n\n\\foreach \\i in {3,...,7}\n{\n    \n        \\draw[-&gt;, shorten &gt;=1pt] (Hidden2-\\i) -- (Output);   \n}\n\\draw[-&gt;, shorten &gt;=1pt] (Input) -- node [midway] {$6.00$} (Hidden1-1);   \n\\draw[-&gt;, shorten &gt;=1pt] (Hidden1-1) -- node [midway,above] {$-1.00$} (Hidden2-1); \n\\draw[-&gt;, shorten &gt;=1pt] (Hidden2-1) -- node [midway] {$-1.00$} (Output); \n\\draw[-&gt;, shorten &gt;=1pt] (6,6) node [below] {$0.70$} --  (Hidden2-1); \n\\draw[-&gt;, shorten &gt;=1pt] (3,6) node [below] {$0.00$} --  (Hidden1-1); \n\n\\draw[-&gt;, shorten &gt;=1pt] (Input) -- node [midway] {$0.00$} (Hidden1-8); \n\\draw[-&gt;, shorten &gt;=1pt] (3,-9) node [below] {$0.00$} --  (Hidden1-8); \n\\draw[-&gt;, shorten &gt;=1pt] (Hidden1-8) -- node [midway,above] {$0.00$} (Hidden2-8); \n\\draw[-&gt;, shorten &gt;=1pt] (6,-9) node [below] {$1.00$} --  (Hidden2-8); \n\\draw[-&gt;, shorten &gt;=1pt] (Hidden2-8) -- node [midway] {$0.70$} (Output); \n\n\\draw[-&gt;, shorten &gt;=1pt] (Input) -- node [midway] {$3.50$} (Hidden1-2); \n\\draw[-&gt;, shorten &gt;=1pt] (3,4) node [below] {$-0.42$} --  (Hidden1-2); \n\\draw[-&gt;, shorten &gt;=1pt] (Hidden1-2) -- node [midway,above] {$-1.00$} (Hidden2-2); \n\\draw[-&gt;, shorten &gt;=1pt] (6,4) node [below] {$0.27$} --  (Hidden2-2); \n\\draw[-&gt;, shorten &gt;=1pt] (Hidden2-2) -- node [midway] {$1.00$} (Output); \n\\end{tikzpicture}\n\n\n\n\n\nThis results in:\n\n\nShow the code\n%%itikz --temp-dir --tex-packages=tikz,pgfplots --tikz-libraries=arrows --implicit-standalone\n\\begin{tikzpicture}[scale=1.5]\n\\begin{axis}[grid,ymin=-2,ymax=2,ytick={-2,-1,...,2},xmin=0,xmax=1]\n\\addplot[color=blue,thick,samples=1000]{-max(-max(6*x,0)+0.70,0))+0.70+max(-max(3.50*x - 0.42,0)+0.27,0)};\n\\addplot[color=green,samples=1000,domain=0:1]{sin(deg(2*3.14*x))};\n\\end{axis}\n\\end{tikzpicture}\n\n\n\n\n\nThen, we can flip this section’s function again the same way we did with the first one, by setting the weight to the output neuron from \\(1.0\\) to \\(-1.0\\).\n\n\nShow the code\n%%itikz --temp-dir --tex-packages=tikz --tikz-libraries=arrows --implicit-standalone\n\\begin{tikzpicture}\n\n\\node[circle, \n    minimum size = 15mm,\n    fill=red!30\n    ] (Input) at (0,0) {\\large $x_1$};\n\n\\foreach \\i in {1,2,...,8}\n{\n    \\node[circle, \n        minimum size = 15mm,\n        fill=blue!50,\n        yshift=90 mm\n        ] (Hidden1-\\i) at (3.0,-\\i * 2) {\\large $h_\\i^{(1)}$};\n        \n}\n\\foreach \\i in {1,2,...,8}\n{\n    \\node[circle, \n        minimum size = 15mm,\n        fill=blue!50,\n        yshift=90 mm\n        ] (Hidden2-\\i) at (6.0,-\\i * 2) {\\large $h_\\i^{(2)}$};\n        \n}\n\n\\node[circle, \n    minimum size = 15mm,\n    fill=red!30\n    ] (Output) at (9,0) {\\large $\\hat{y}_1$};\n\n% Connect neurons In-Hidden1\n\\foreach \\j in {3,...,7}\n{\n    \\draw[-&gt;, shorten &gt;=1pt] (Input) -- (Hidden1-\\j);   \n}\n% Connect neurons Hidden1-Hidden2\n\\foreach \\i in {3,...,7}\n{\n    \n        \\draw[-&gt;, shorten &gt;=1pt] (Hidden1-\\i) -- (Hidden2-\\i);   \n    \n}\n\n\\foreach \\i in {3,...,7}\n{\n    \n        \\draw[-&gt;, shorten &gt;=1pt] (Hidden2-\\i) -- (Output);   \n}\n\\draw[-&gt;, shorten &gt;=1pt] (Input) -- node [midway] {$6.00$} (Hidden1-1);   \n\\draw[-&gt;, shorten &gt;=1pt] (Hidden1-1) -- node [midway,above] {$-1.00$} (Hidden2-1); \n\\draw[-&gt;, shorten &gt;=1pt] (Hidden2-1) -- node [midway] {$-1.00$} (Output); \n\\draw[-&gt;, shorten &gt;=1pt] (6,6) node [below] {$0.70$} --  (Hidden2-1); \n\\draw[-&gt;, shorten &gt;=1pt] (3,6) node [below] {$0.00$} --  (Hidden1-1); \n\n\\draw[-&gt;, shorten &gt;=1pt] (Input) -- node [midway] {$0.00$} (Hidden1-8); \n\\draw[-&gt;, shorten &gt;=1pt] (3,-9) node [below] {$0.00$} --  (Hidden1-8); \n\\draw[-&gt;, shorten &gt;=1pt] (Hidden1-8) -- node [midway,above] {$0.00$} (Hidden2-8); \n\\draw[-&gt;, shorten &gt;=1pt] (6,-9) node [below] {$1.00$} --  (Hidden2-8); \n\\draw[-&gt;, shorten &gt;=1pt] (Hidden2-8) -- node [midway] {$0.70$} (Output); \n\n\\draw[-&gt;, shorten &gt;=1pt] (Input) -- node [midway] {$3.50$} (Hidden1-2); \n\\draw[-&gt;, shorten &gt;=1pt] (3,4) node [below] {$-0.42$} --  (Hidden1-2); \n\\draw[-&gt;, shorten &gt;=1pt] (Hidden1-2) -- node [midway,above] {$-1.00$} (Hidden2-2); \n\\draw[-&gt;, shorten &gt;=1pt] (6,4) node [below] {$0.27$} --  (Hidden2-2); \n\\draw[-&gt;, shorten &gt;=1pt] (Hidden2-2) -- node [midway] {$-1.00$} (Output); \n\\end{tikzpicture}\n\n\n\n\n\nConsequently, we have:\n\n\nShow the code\n%%itikz --temp-dir --tex-packages=tikz,pgfplots --tikz-libraries=arrows --implicit-standalone\n\\begin{tikzpicture}[scale=1.5]\n\\begin{axis}[grid,ymin=-2,ymax=2,ytick={-2,-1,...,2},xmin=0,xmax=1]\n\\addplot[color=blue,thick,samples=1000]{-max(-max(6*x,0)+0.70,0))+0.70-max(-max(3.50*x - 0.42,0)+0.27,0)};\n\\addplot[color=green,samples=1000,domain=0:1]{sin(deg(2*3.14*x))};\n\\end{axis}\n\\end{tikzpicture}\n\n\n\n\n\nAnd again, just like the first pair, we use the bottom pair to fix the vertical offset.\n\n\nShow the code\n%%itikz --temp-dir --tex-packages=tikz --tikz-libraries=arrows --implicit-standalone\n\\begin{tikzpicture}\n\n\\node[circle, \n    minimum size = 15mm,\n    fill=red!30\n    ] (Input) at (0,0) {\\large $x_1$};\n\n\\foreach \\i in {1,2,...,8}\n{\n    \\node[circle, \n        minimum size = 15mm,\n        fill=blue!50,\n        yshift=90 mm\n        ] (Hidden1-\\i) at (3.0,-\\i * 2) {\\large $h_\\i^{(1)}$};\n        \n}\n\\foreach \\i in {1,2,...,8}\n{\n    \\node[circle, \n        minimum size = 15mm,\n        fill=blue!50,\n        yshift=90 mm\n        ] (Hidden2-\\i) at (6.0,-\\i * 2) {\\large $h_\\i^{(2)}$};\n        \n}\n\n\\node[circle, \n    minimum size = 15mm,\n    fill=red!30\n    ] (Output) at (9,0) {\\large $\\hat{y}_1$};\n\n% Connect neurons In-Hidden1\n\\foreach \\j in {3,...,7}\n{\n    \\draw[-&gt;, shorten &gt;=1pt] (Input) -- (Hidden1-\\j);   \n}\n% Connect neurons Hidden1-Hidden2\n\\foreach \\i in {3,...,7}\n{\n    \n        \\draw[-&gt;, shorten &gt;=1pt] (Hidden1-\\i) -- (Hidden2-\\i);   \n    \n}\n\n\\foreach \\i in {3,...,7}\n{\n    \n        \\draw[-&gt;, shorten &gt;=1pt] (Hidden2-\\i) -- (Output);   \n}\n\\draw[-&gt;, shorten &gt;=1pt] (Input) -- node [midway] {$6.00$} (Hidden1-1);   \n\\draw[-&gt;, shorten &gt;=1pt] (Hidden1-1) -- node [midway,above] {$-1.00$} (Hidden2-1); \n\\draw[-&gt;, shorten &gt;=1pt] (Hidden2-1) -- node [midway] {$-1.00$} (Output); \n\\draw[-&gt;, shorten &gt;=1pt] (6,6) node [below] {$0.70$} --  (Hidden2-1); \n\\draw[-&gt;, shorten &gt;=1pt] (3,6) node [below] {$0.00$} --  (Hidden1-1); \n\n\\draw[-&gt;, shorten &gt;=1pt] (Input) -- node [midway] {$0.00$} (Hidden1-8); \n\\draw[-&gt;, shorten &gt;=1pt] (3,-9) node [below] {$0.00$} --  (Hidden1-8); \n\\draw[-&gt;, shorten &gt;=1pt] (Hidden1-8) -- node [midway,above] {$0.00$} (Hidden2-8); \n\\draw[-&gt;, shorten &gt;=1pt] (6,-9) node [below] {$1.00$} --  (Hidden2-8); \n\\draw[-&gt;, shorten &gt;=1pt] (Hidden2-8) -- node [midway] {$0.97$} (Output); \n\n\\draw[-&gt;, shorten &gt;=1pt] (Input) -- node [midway] {$3.50$} (Hidden1-2); \n\\draw[-&gt;, shorten &gt;=1pt] (3,4) node [below] {$-0.42$} --  (Hidden1-2); \n\\draw[-&gt;, shorten &gt;=1pt] (Hidden1-2) -- node [midway,above] {$-1.00$} (Hidden2-2); \n\\draw[-&gt;, shorten &gt;=1pt] (6,4) node [below] {$0.27$} --  (Hidden2-2); \n\\draw[-&gt;, shorten &gt;=1pt] (Hidden2-2) -- node [midway] {$-1.00$} (Output); \n\\end{tikzpicture}\n\n\n\n\n\nWe get:\n\n\nShow the code\n%%itikz --temp-dir --tex-packages=tikz,pgfplots --tikz-libraries=arrows --implicit-standalone\n\\begin{tikzpicture}[scale=1.5]\n\\begin{axis}[grid,ymin=-2,ymax=2,ytick={-2,-1,...,2},xmin=0,xmax=1]\n\\addplot[color=blue,thick,samples=1000]{-max(-max(6*x,0)+0.70,0))+0.97-max(-max(3.50*x - 0.42,0)+0.27,0)};\n\\addplot[color=green,samples=1000,domain=0:1]{sin(deg(2*3.14*x))};\n\\end{axis}\n\\end{tikzpicture}\n\n\n\n\n\nWe then just continue this methodology. It should begin to make more sense to you now, how more neurons can enable more unique areas of effect, why we need two or more hidden layers, and why we need nonlinear activation functions to map nonlinear problems.\nWe can write a ReLUActivation class to represent the ReLU activation function:\n\nclass ReLUActivation:\n\n    # Forward pass\n    def forward(self, inputs):\n        # Calculate output values from the inputs\n        self.output = np.maximum(0, inputs)\n\nLet’s apply this activation function to the DenseLayer’s outputs in our code:\n\nfrom nnfs.datasets import spiral_data\nimport numpy as np\n\n# Create dataset\nX, y = spiral_data(samples=100, classes=3)\n\n# Create Dense layer with 2 input features and 3 output values\ndense1 = DenseLayer(2, 3)\n\n# Create ReLU activation function (to be used with the DenseLayer)\nactivation1 = ReLUActivation()\n\n# Make a forward pass of our training data through this layer\ndense1.forward(X)\n\n# Forward pass through our activation function\n# Takes in output from the previous layer\nactivation1.forward(dense1.output)\n\n# Let's see output of the first few samples\nprint(activation1.output[:5])\n\n[[0.0000000e+00 0.0000000e+00 0.0000000e+00]\n [1.3520580e-04 1.8173116e-05 0.0000000e+00]\n [2.3245417e-04 0.0000000e+00 0.0000000e+00]\n [3.8226307e-04 0.0000000e+00 0.0000000e+00]\n [5.7436468e-04 0.0000000e+00 0.0000000e+00]]\n\n\nAs we can see, negative values have been clipped (modified to zero). That’s all there is to the rectified linear activation function used in the hidden layer. Let’s talk about the activation function that we are going to use on the output of the last layer."
  },
  {
    "objectID": "posts/coding-a-neural-network-layer/index.html#the-softmax-activation-function",
    "href": "posts/coding-a-neural-network-layer/index.html#the-softmax-activation-function",
    "title": "Coding a neural network layer",
    "section": "The Softmax Activation function",
    "text": "The Softmax Activation function\nIn our case, we’re looking to get this model to be a classifier, so we want an activation function meant for classification. One of these is the softmax activation function. First, why are we bothering with another activation function? It just depends on what our overall goals are.\nThe rectified linear unit is unbounded, not normalized with other units and exclusive. “Not normalized” implies the values can be anything, an output of [12,99,318] is without context, and exclusive means each output is independent of others. To address this lack of context, the softmax activation function on the output data can take in non-normalized, or uncalibrated, inputs and produce a normalized distribution of probabilities for our classes. In the case of classification, what we want to see is a prediction of which class the network thinks the input represents. This distribution returned by the softmax activation function represents confidence scores in our overarching algorithm/program that uses this network. For example, if our network has a confidence distirbution for two classes \\([0.45,0.55]\\), the prediction is the \\(2\\)nd class, but the confidence in this prediction isn’t very high.\nMaybe our program wouldn’t act in this case, since it’s not very confident.\nThe softmax function takes as input a vector of \\(L\\) real numbers and normalizes it into a probability distribution consisting of \\(L\\) probabilities proportional to the exponentials of the input numbers.\nDefinition. The standard(unit) softmax function \\(\\sigma:\\mathbf{R}^L \\to (0,1)^L\\) takes a vector \\(\\mathbf{z}=(z_1,\\ldots,z_l)\\in\\mathbf{R}^L\\) and computes each component of the vector \\(\\sigma(\\mathbf{z})\\in(0,1)^L\\) with:\n\\[\\begin{align*}\n\\sigma(\\mathbf{z})_i = \\frac{e^{z_{i}}}{\\sum_{l=1}^{L}e^{z_{l}}}\n\\end{align*}\\]\nThat might look daunting, but it’s easy to follow. Suppose the example outputs from a neural network layer are:\n\nlayer_outputs = [4.80, 1.21, 2.385]\n\nThen, the normalized values are:\n\nimport numpy as np\n\nnorm_values = np.exp(layer_outputs)/np.sum(np.exp(layer_outputs))\nprint(norm_values)\n\n[0.89528266 0.02470831 0.08000903]\n\n\nTo train in batches, we need to convert this functionality to accept layer outputs in batches. Do this is easy:\n\nlayer_outputs = np.random.randn(100,3)\nnorm_values = np.exp(layer_outputs)/np.sum(np.exp(layer_outputs),axis=1,keepdims=True)\n\nWe can now write a SoftmaxActivation class as:\n\n# Softmax activation\nclass SoftmaxActivation:\n\n    # Forward pass\n    def forward(self, inputs):\n        exp_values = np.exp(inputs - np.max(inputs, axis=1, keepdims=True))\n        probabilities = exp_values / np.sum(exp_values, axis=1, keepdims=True)\n        self.output = probabilities\n\nWe also included a subtraction of the largest of the inputs before we do the exponentiation. This does not affect the output of the softmax function, since:\n\\[\\begin{align*}\n\\frac{e^{z_{i}-||\\mathbf{z}||}}{\\sum_{l=1}^{L}e^{z_{l}-||\\mathbf{z}||}} = \\frac{e^{-||\\mathbf{z}||}\\cdot e^{z_{i}}}{e^{-||\\mathbf{z}||}\\cdot \\sum_{l=1}^{L}e^{z_{l}}} = \\sigma(\\mathbf{z})_i\n\\end{align*}\\]\nThere are two main pervasive challenges with neural networks : dead neurons and very large numbers (referred to as exploding values). Dead neurons and enormous numbers can wreak havoc down the line and render a network useless over time."
  },
  {
    "objectID": "posts/coding-a-neural-network-layer/index.html#the-output-layer",
    "href": "posts/coding-a-neural-network-layer/index.html#the-output-layer",
    "title": "Coding a neural network layer",
    "section": "The output layer",
    "text": "The output layer\nNow, we can add another DenseLayer as the output layer, setting it to contain as many inputs as the previous layer outputs and as many outputs as our data includes classes. Then, we can apply the softmax function to the output of this new layer.\n\nFull code upto this point\n\nimport numpy as np\nimport nnfs\nfrom nnfs.datasets import spiral_data\n\nclass DenseLayer:\n\n    def __init__(self, n_inputs, n_neurons):\n        # Initialize all weights and biases\n        self.weights = 0.01 * np.random.randn(n_inputs,n_neurons)\n        self.biases = np.zeros((1,n_neurons))\n    \n    def forward(self, inputs):\n        self.output = np.dot(inputs,self.weights) + self.biases\n\nclass ReLUActivation:\n\n    # Forward pass\n    def forward(self, inputs):\n        self.output = np.maximum(inputs, 0)\n\nclass SoftmaxActivation:\n\n    # Forward pass\n    def forward(self,inputs):\n        exp_values = np.exp(inputs - np.max(inputs, axis=1, keepdims=True))\n        probabilities = exp_values / np.sum(exp_values, axis=1, keepdims=True)\n        self.output = probabilities\n\n# Create dataset\nX, y = spiral_data(samples=100, classes=3)\n\n# Create a DenseLayer with 2 input features and 3 neurons\ndense1 = DenseLayer(2, 3)\n\n# Create ReLU Activation (to be used with DenseLayer)\nactivation1 = ReLUActivation()\n\n# Create a second DenseLayer with 3 input features and 3 output values\ndense2 = DenseLayer(3, 3)\n\n# Create Softmax activation to be used with the output layer\nactivation2 = SoftmaxActivation()\n\n# Make a forward pass of our training data through this layer\ndense1.forward(X)\n\n# Make a forward pass through the activation function \n# It takes the output of the first dense layer\nactivation1.forward(dense1.output)\n\n# Make a forward pass through the second DenseLayer\n# It takes outputs of the activation function of the first layer\n# as inputs\ndense2.forward(activation1.output)\n\n# Make a forward pass through activation function\n# It takes outputs of the second dense layer\nactivation2.forward(dense2.output)\n\n# Let's see output of the first few examples\nprint(activation2.output[:5])\n\n[[0.33333334 0.33333334 0.33333334]\n [0.33333322 0.3333335  0.33333322]\n [0.3333332  0.3333332  0.3333336 ]\n [0.3333332  0.3333336  0.3333332 ]\n [0.33333287 0.33333436 0.33333275]]\n\n\nWe’ve completed what we need for forward-passing data through the model.\nOur example model is currently random. To remedy this, we need a way to calculate how wrong the neural network is at current predictions and begin adjusting weights and biases to decrease error over time. Thus, our next step is to quantify how wrong the model is through what’s defined as a loss function."
  },
  {
    "objectID": "posts/cox-ingersoll-ross-model/index.html",
    "href": "posts/cox-ingersoll-ross-model/index.html",
    "title": "Cox-Ingersoll-Ross (CIR) model",
    "section": "",
    "text": "The short rate under the CIR model has the dynamics:\n\\[dr_t = \\kappa (\\theta - r_t)dt + \\sigma \\sqrt{r_t}dB_t\\]\nFor a moment, if we drop the stochastic term, and merely consider the first order linear ODE \\(\\frac{dr_t}{dt} + \\kappa r_t = \\kappa \\theta\\), the integrating factor for this differential equation is \\(e^{\\int \\kappa dt} = e^{\\kappa t}\\). Multiplying both sides by the integrating factor, we have:\n\\[\\begin{align*}\ne^{\\kappa t} dr_t &= \\kappa(\\theta - r_t) e^{\\kappa t}dt + \\sigma e^{\\kappa t}\\sqrt{r_t} dB_t \\\\\ne^{\\kappa t} dr_t + r_t e^{\\kappa t}dt &= \\kappa e^{\\kappa t}\\theta dt + \\sigma e^{\\kappa t}\\sqrt{r_t} dB_t \\\\\nd(e^{\\kappa t} r_t) &= \\kappa e^{\\kappa t}\\theta dt + \\sigma e^{\\kappa t}\\sqrt{r_t} dB_t \\\\\n\\int_{0}^{t} d(e^{\\kappa s} r_s) &= \\theta \\kappa\\int_{0}^{t}  e^{\\kappa s} ds + \\sigma \\int_{0}^{t}  e^{\\kappa s}\\sqrt{r_s} dB_s \\\\\n[e^{\\kappa s} r_s]_{0}^{t} &= \\kappa \\theta \\left[\\frac{e^{\\kappa s}}{\\kappa}\\right]_{0}^{t} + \\sigma \\int_{0}^{t}  e^{\\kappa s}\\sqrt{r_s} dB_s\\\\\ne^{\\kappa t}r_t - r_0 &= \\theta (e^{\\kappa t} - 1) + \\sigma \\int_{0}^{t}  e^{\\kappa s}\\sqrt{r_s} dB_s \\\\\ne^{\\kappa t} r_t &= r_0 + \\theta (e^{\\kappa t} - 1) + \\sigma \\int_{0}^{t}  e^{\\kappa s}\\sqrt{r_s} dB_s \\\\\nr_t &= r_0 e^{-\\kappa t} + \\theta (1 - e^{-\\kappa t}) + \\sigma \\int_{0}^{t}  e^{-\\kappa (t-s)}\\sqrt{r_s} dB_s\n\\end{align*}\\]\nThe mean is given by:\n\\[\\begin{align*}\n\\mathbf{E}[r_t] &= r_0 e^{-\\kappa t} + \\theta (1 - e^{-\\kappa t})\n\\end{align*}\\]\nThe random variable \\(\\sigma \\int_{0}^{t} e^{-\\kappa (t-s)}\\sqrt{r_s} dB_s\\) has mean \\(0\\) and variance:\n\\[\\begin{align*}\n\\mathbf{E}\\left[\\left(\\sigma \\int_{0}^{t}  e^{-\\kappa (t-s)}\\sqrt{r_s} dB_s\\right)^2\\right] &= \\sigma^2 \\int_{0}^{t}e^{-2\\kappa(t-s)} \\mathbf{E}[r_s] ds \\\\\n&= \\sigma^2 e^{-2\\kappa t}\\int_{0}^{t}e^{2\\kappa s} \\left(r_0 e^{-\\kappa s} + \\theta(1-e^{-\\kappa s})\\right) ds\\\\\n&= \\sigma^2 r_0 e^{-2\\kappa t} \\int_{0}^{t} e^{\\kappa s} ds + \\sigma^2 \\theta e^{-2\\kappa t} \\int_{0}^{t}(e^{2\\kappa s}-e^{\\kappa s}) ds \\\\\n&= \\sigma^2 r_0 e^{-2\\kappa t} \\left[\\frac{e^{\\kappa s}}{\\kappa} \\right]_{0}^{t} +\\sigma^2 \\theta e^{-2\\kappa t} \\left[\\frac{e^{2\\kappa s}}{2\\kappa} - \\frac{e^{\\kappa s}}{\\kappa}\\right]_{0}^{t}\\\\\n&= \\frac{\\sigma^2 r_0}{\\kappa} e^{-2\\kappa t} (e^{\\kappa t} - 1)+\\sigma^2 \\theta e^{-2\\kappa t} \\left[\\frac{e^{2\\kappa s}}{2\\kappa} - \\frac{2e^{\\kappa s}}{2\\kappa}\\right]_{0}^{t}\\\\\n&= \\frac{\\sigma^2 r_0}{\\kappa} e^{-2\\kappa t}(e^{\\kappa t} - 1)+\\frac{\\sigma^2 \\theta}{2\\kappa} e^{-2\\kappa t}(e^{2\\kappa t} - 2e^{\\kappa t} - (1 - 2))\\\\\n&= \\frac{\\sigma^2 r_0}{\\kappa} e^{-2\\kappa t}(e^{\\kappa t} - 1)+\\frac{\\sigma^2 \\theta}{2\\kappa}e^{-2\\kappa t} (1 + e^{2\\kappa t} - 2e^{\\kappa t})\\\\\n&= \\frac{\\sigma^2 r_0}{\\kappa} (e^{-\\kappa t} - e^{-2\\kappa t})+\\frac{\\sigma^2 \\theta}{2\\kappa} (1 - e^{-\\kappa t})^2\n\\end{align*}\\]"
  },
  {
    "objectID": "posts/cox-ingersoll-ross-model/index.html#short-rate-dynamics-mean-and-variance",
    "href": "posts/cox-ingersoll-ross-model/index.html#short-rate-dynamics-mean-and-variance",
    "title": "Cox-Ingersoll-Ross (CIR) model",
    "section": "",
    "text": "The short rate under the CIR model has the dynamics:\n\\[dr_t = \\kappa (\\theta - r_t)dt + \\sigma \\sqrt{r_t}dB_t\\]\nFor a moment, if we drop the stochastic term, and merely consider the first order linear ODE \\(\\frac{dr_t}{dt} + \\kappa r_t = \\kappa \\theta\\), the integrating factor for this differential equation is \\(e^{\\int \\kappa dt} = e^{\\kappa t}\\). Multiplying both sides by the integrating factor, we have:\n\\[\\begin{align*}\ne^{\\kappa t} dr_t &= \\kappa(\\theta - r_t) e^{\\kappa t}dt + \\sigma e^{\\kappa t}\\sqrt{r_t} dB_t \\\\\ne^{\\kappa t} dr_t + r_t e^{\\kappa t}dt &= \\kappa e^{\\kappa t}\\theta dt + \\sigma e^{\\kappa t}\\sqrt{r_t} dB_t \\\\\nd(e^{\\kappa t} r_t) &= \\kappa e^{\\kappa t}\\theta dt + \\sigma e^{\\kappa t}\\sqrt{r_t} dB_t \\\\\n\\int_{0}^{t} d(e^{\\kappa s} r_s) &= \\theta \\kappa\\int_{0}^{t}  e^{\\kappa s} ds + \\sigma \\int_{0}^{t}  e^{\\kappa s}\\sqrt{r_s} dB_s \\\\\n[e^{\\kappa s} r_s]_{0}^{t} &= \\kappa \\theta \\left[\\frac{e^{\\kappa s}}{\\kappa}\\right]_{0}^{t} + \\sigma \\int_{0}^{t}  e^{\\kappa s}\\sqrt{r_s} dB_s\\\\\ne^{\\kappa t}r_t - r_0 &= \\theta (e^{\\kappa t} - 1) + \\sigma \\int_{0}^{t}  e^{\\kappa s}\\sqrt{r_s} dB_s \\\\\ne^{\\kappa t} r_t &= r_0 + \\theta (e^{\\kappa t} - 1) + \\sigma \\int_{0}^{t}  e^{\\kappa s}\\sqrt{r_s} dB_s \\\\\nr_t &= r_0 e^{-\\kappa t} + \\theta (1 - e^{-\\kappa t}) + \\sigma \\int_{0}^{t}  e^{-\\kappa (t-s)}\\sqrt{r_s} dB_s\n\\end{align*}\\]\nThe mean is given by:\n\\[\\begin{align*}\n\\mathbf{E}[r_t] &= r_0 e^{-\\kappa t} + \\theta (1 - e^{-\\kappa t})\n\\end{align*}\\]\nThe random variable \\(\\sigma \\int_{0}^{t} e^{-\\kappa (t-s)}\\sqrt{r_s} dB_s\\) has mean \\(0\\) and variance:\n\\[\\begin{align*}\n\\mathbf{E}\\left[\\left(\\sigma \\int_{0}^{t}  e^{-\\kappa (t-s)}\\sqrt{r_s} dB_s\\right)^2\\right] &= \\sigma^2 \\int_{0}^{t}e^{-2\\kappa(t-s)} \\mathbf{E}[r_s] ds \\\\\n&= \\sigma^2 e^{-2\\kappa t}\\int_{0}^{t}e^{2\\kappa s} \\left(r_0 e^{-\\kappa s} + \\theta(1-e^{-\\kappa s})\\right) ds\\\\\n&= \\sigma^2 r_0 e^{-2\\kappa t} \\int_{0}^{t} e^{\\kappa s} ds + \\sigma^2 \\theta e^{-2\\kappa t} \\int_{0}^{t}(e^{2\\kappa s}-e^{\\kappa s}) ds \\\\\n&= \\sigma^2 r_0 e^{-2\\kappa t} \\left[\\frac{e^{\\kappa s}}{\\kappa} \\right]_{0}^{t} +\\sigma^2 \\theta e^{-2\\kappa t} \\left[\\frac{e^{2\\kappa s}}{2\\kappa} - \\frac{e^{\\kappa s}}{\\kappa}\\right]_{0}^{t}\\\\\n&= \\frac{\\sigma^2 r_0}{\\kappa} e^{-2\\kappa t} (e^{\\kappa t} - 1)+\\sigma^2 \\theta e^{-2\\kappa t} \\left[\\frac{e^{2\\kappa s}}{2\\kappa} - \\frac{2e^{\\kappa s}}{2\\kappa}\\right]_{0}^{t}\\\\\n&= \\frac{\\sigma^2 r_0}{\\kappa} e^{-2\\kappa t}(e^{\\kappa t} - 1)+\\frac{\\sigma^2 \\theta}{2\\kappa} e^{-2\\kappa t}(e^{2\\kappa t} - 2e^{\\kappa t} - (1 - 2))\\\\\n&= \\frac{\\sigma^2 r_0}{\\kappa} e^{-2\\kappa t}(e^{\\kappa t} - 1)+\\frac{\\sigma^2 \\theta}{2\\kappa}e^{-2\\kappa t} (1 + e^{2\\kappa t} - 2e^{\\kappa t})\\\\\n&= \\frac{\\sigma^2 r_0}{\\kappa} (e^{-\\kappa t} - e^{-2\\kappa t})+\\frac{\\sigma^2 \\theta}{2\\kappa} (1 - e^{-\\kappa t})^2\n\\end{align*}\\]"
  },
  {
    "objectID": "posts/cox-ingersoll-ross-model/index.html#naive-python-implementation",
    "href": "posts/cox-ingersoll-ross-model/index.html#naive-python-implementation",
    "title": "Cox-Ingersoll-Ross (CIR) model",
    "section": "Naive python implementation",
    "text": "Naive python implementation\n\nCIRProcess class\nThe class CIRProcess is designed as an engine to generate sample paths of the CIR process.\n\nimport math\nfrom dataclasses import dataclass\n\nimport joypy\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport pandas as pd\nfrom matplotlib import cm\nfrom tqdm import tqdm\n\n\n@dataclass\nclass CIRProcess:\n    \"\"\"An engine for generating sample paths of the Cox-Ingersoll-Ross process\"\"\"\n\n    kappa: float\n    theta: float\n    sigma: float\n    step_size: float\n    total_time: float\n    r_0: float\n\n    def generate_paths(self, paths: int):\n        \"\"\"Generate sample paths\"\"\"\n        num_steps = int(self.total_time / self.step_size)\n        dz = np.random.standard_normal((paths, num_steps))\n        r_t = np.zeros((paths, num_steps))\n        zero_vector = np.full(paths, self.r_0)\n        prev_r = zero_vector\n        for i in range(num_steps):\n            r_t[:, i] = (\n                prev_r\n                + self.kappa * np.subtract(self.theta, prev_r) * self.step_size\n                + self.sigma\n                * np.sqrt(np.abs(prev_r))\n                * math.sqrt(self.step_size)\n                * dz[:, i]\n            )\n\n            prev_r = r_t[:, i]\n\n        return r_t\n\n\n\nSample Paths\nWe generate \\(N=10\\) paths of the CIR process.\n\n\nShow the code\ncir_process = CIRProcess(\n    kappa=3,\n    r_0=9,\n    sigma=0.5,\n    step_size=10e-3,\n    theta=3,\n    total_time=1.0,\n)\n\nnum_paths = 10\n\npaths = cir_process.generate_paths(num_paths)\n\nt = np.linspace(0.01, 1.0, 100)\n\nplt.grid(True)\nplt.xlabel(r\"Time $t$\")\nplt.ylabel(r\"$R(t)$\")\nplt.title(r\"$N=10$ paths of the Cox-Ingersoll-Ross process\")\nfor path in paths:\n    plt.plot(t, path)\n\nplt.show()\n\n\n\n\n\n\n\nEvolution of the distribution.\nThe evolution of the distribution with time can be visualized.\n\n\nShow the code\n# TODO: - this is where slowness lies, generating paths is a brezze\n\n# Wrap the paths 2d-array in a dataframe\npaths_tr = paths.transpose()\n# Take 20 samples at times t=0.05, 0.10, 0.15, ..., 1.0 along each path\nsamples = paths_tr[4::5]\n# Reshape in a 1d column-vector\nsamples_arr = samples.reshape(num_paths * 20)\nsamples_df = pd.DataFrame(samples_arr, columns=[\"values\"])\nsamples_df[\"time\"] = [\n    \"t=\" + str((int(i / num_paths) + 1) / 20) for i in range(num_paths * 20)\n]\n\n# TODO: end\n\nfig, ax = joypy.joyplot(\n    samples_df,\n    by=\"time\",\n    colormap=cm.autumn_r,\n    column=\"values\",\n    grid=\"y\",\n    kind=\"kde\",\n    range_style=\"own\",\n    tails=10e-3,\n)\nplt.vlines(\n    [cir_process.theta, cir_process.r_0],\n    -0.2,\n    1,\n    color=\"k\",\n    linestyles=\"dashed\",\n)\nplt.show()"
  },
  {
    "objectID": "posts/custom-iterators/index.html",
    "href": "posts/custom-iterators/index.html",
    "title": "Custom iterators and Iterator concepts",
    "section": "",
    "text": "An iterator is a generalization of a pointer. C++ STL containers usually expose iterators as part of their interface. They abstract away lower-level implementation details of traversing through container types, thus freeing the container-user to focus on algorithm design/business logic."
  },
  {
    "objectID": "posts/custom-iterators/index.html#stdinput_or_output_iterator",
    "href": "posts/custom-iterators/index.html#stdinput_or_output_iterator",
    "title": "Custom iterators and Iterator concepts",
    "section": "std::input_or_output_iterator",
    "text": "std::input_or_output_iterator\nThe input_or_output_iterator is the basis of the iterator concept taxonomy. It only requires that an iterator type It supports the operations for dereferencing and incrementing the iterator."
  },
  {
    "objectID": "posts/custom-iterators/index.html#stdoutput_iterator",
    "href": "posts/custom-iterators/index.html#stdoutput_iterator",
    "title": "Custom iterators and Iterator concepts",
    "section": "std::output_iterator",
    "text": "std::output_iterator\nstd::output_iterator concept models the idea of a write-only iterator. E.g. such an iterator can be used to write to the standard output stream. Hence, they can only be dereferenced on the left-hand side of an assignment operator.\nSince, they are single pass, we don’t even need to implement an equality comparison operator, because they don’t have an end iterator or sentinel value to compare against.\n#include &lt;cstddef&gt;\n#include &lt;iterator&gt;\n#include &lt;concepts&gt;\n\ntemplate&lt;typename T&gt;\nstruct SimpleOutputIterator {\n    using difference_type = std::ptrdiff_t;\n    using value_type = T;\n    using pointer = T*;\n\n    pointer m_buffer_ptr;\n\n    // Default constructor\n    SimpleOutputIterator() = default;\n\n    // Constructor\n    SimpleOutputIterator(pointer start)\n        : m_buffer_ptr{start} {}\n\n    // Dereference operator\n    T& operator*() {\n        return *m_buffer_ptr;\n    }\n\n    // Pre-increment\n    SimpleOutputIterator& operator++() {\n        ++m_buffer_ptr;\n        return (*this);\n    }\n\n    // Post-increment\n    SimpleOutputIterator operator++(int) {\n        auto tmp = *this;\n        ++(*this);\n        return tmp;\n    }\n\n};\n\nstatic_assert(std::output_iterator&lt;SimpleOutputIterator&lt;int&gt;, int&gt;);\n\n\nint main(){\n    return 0;\n}\nCompiler Explorer"
  },
  {
    "objectID": "posts/custom-iterators/index.html#stdinput_iterator",
    "href": "posts/custom-iterators/index.html#stdinput_iterator",
    "title": "Custom iterators and Iterator concepts",
    "section": "std::input_iterator",
    "text": "std::input_iterator\nstd::input_iterator concept models the idea of a read-only iterator. Such an iterator, for example, can be used read packets data from a network socket.\nInput iterators are also single-pass, because once you’ve read a byte of data from a network socket, you can’t read it again. They must also be comparable to some sentinel value such as EOF, \\0, to signal the end of data etc.\nHowever, the equality comparison operator bool operator==(It, Sen) is only used by the algorithm operating on the container, and therefore it’s the responsibility of the algorithm writer to supply an implementation of bool operator==(It, Sen). This definition is not required in the container implementation.\n#include &lt;cstddef&gt;\n#include &lt;iterator&gt;\n#include &lt;concepts&gt;\n\ntemplate&lt;typename T&gt;\nstruct SimpleInputIterator {\n    using difference_type = std::ptrdiff_t;\n    using value_type = T;\n    using pointer = T*;\n    using reference = T&;\n\n    pointer m_socket_fd;\n\n    // Default constructor\n    SimpleInputIterator() = default;\n\n    // Constructor\n    SimpleInputIterator(pointer start)\n        : m_socket_fd{start} {}\n\n    // Dereference operator\n    const T& operator*() const {\n        return *m_socket_fd;\n    }\n\n    // Pre-increment\n    SimpleInputIterator& operator++() {\n        ++m_socket_fd;\n        return (*this);\n    }\n\n    // Post-increment\n    SimpleInputIterator operator++(int) {\n        auto tmp = *this;\n        ++(*this);\n        return tmp;\n    }\n\n};\n\nstatic_assert(std::input_iterator&lt;SimpleInputIterator&lt;int&gt;&gt;);\n\n\nint main(){\n    return 0;\n}\nCompiler Explorer"
  },
  {
    "objectID": "posts/custom-iterators/index.html#stdforward_iterator",
    "href": "posts/custom-iterators/index.html#stdforward_iterator",
    "title": "Custom iterators and Iterator concepts",
    "section": "std::forward_iterator",
    "text": "std::forward_iterator\nstd::forward_iterator requires that the iterator type be an input (read-only) iterator and also be std::incrementable.\nstd::input_iterator only requires the iterator be std::weakly_incrementable. So while it supports the increment operator++(), if i and j are two instances of the iterator type It, i == j does not imply ++i == ++j. That is, algorithms on weakly-incrementable types must be single-pass algorithms.\nstd::incrementable concept informally means that i == j \\(\\implies\\) ++i == ++j. Algorithms on incrementable types are multi-pass algorithms.\nYou might use an iterator satisfying std::forward_iterator concept to traverse through a std::forward_list (a singly linked-list).\n#include &lt;cstddef&gt;\n#include &lt;iterator&gt;\n#include &lt;concepts&gt;\n\ntemplate &lt;typename T&gt;\nstruct list_node {\n    T m_data;\n    list_node* m_next;\n};\n\ntemplate &lt;typename T&gt;\nstruct SimpleForwardIterator {\n    using difference_type = std::ptrdiff_t;\n    using value_type = T; // The value type is T, not list_node&lt;T&gt;\n    using pointer = T*;\n    using reference = T&;\n\n    list_node&lt;T&gt;* m_node_ptr;\n\n    // Default constructor\n    SimpleForwardIterator() = default;\n\n    // Constructor\n    SimpleForwardIterator(list_node&lt;T&gt;* start)\n        : m_node_ptr{start} {}\n\n    // Dereference operator\n    reference operator*() const {\n        return m_node_ptr-&gt;m_data; // Return the data stored in the node\n    }\n\n    // Pre-increment\n    SimpleForwardIterator& operator++() {\n        m_node_ptr = m_node_ptr-&gt;m_next;\n        return *this;\n    }\n\n    // Post-increment\n    SimpleForwardIterator operator++(int) {\n        auto tmp = *this;\n        ++(*this);\n        return tmp;\n    }\n\n    // Equality comparison\n    bool operator==(const SimpleForwardIterator& other) const {\n        return m_node_ptr == other.m_node_ptr;\n    }\n\n    // Inequality comparison\n    bool operator!=(const SimpleForwardIterator& other) const {\n        return !(*this == other);\n    }\n};\n\nstatic_assert(std::forward_iterator&lt;SimpleForwardIterator&lt;int&gt;&gt;);\n\nint main() {\n    return 0;\n}\nCompiler Explorer"
  },
  {
    "objectID": "posts/custom-iterators/index.html#stdbidirectional_iterator",
    "href": "posts/custom-iterators/index.html#stdbidirectional_iterator",
    "title": "Custom iterators and Iterator concepts",
    "section": "std::bidirectional_iterator",
    "text": "std::bidirectional_iterator\nA std::list is a doubly linked that supports both traversals in the forward as well as reverse direction. When we want to be able to move forward and backwards across our collection, we must implement an iterator satisfying std::bidirectional_iterator concept.\nYou need to implement pre-increment, post-increment, pre-decrement and post-decrement operations.\n#include &lt;cstddef&gt;\n#include &lt;iterator&gt;\n#include &lt;concepts&gt;\n\ntemplate &lt;typename T&gt;\nstruct list_node {\n    T m_data;\n    list_node* m_next;\n    list_node* m_prev;\n};\n\ntemplate &lt;typename T&gt;\nstruct SimpleBidirectionalIterator {\n    using difference_type = std::ptrdiff_t;\n    using value_type = T; // The value type is T, not list_node&lt;T&gt;\n    using pointer = T*;\n    using reference = T&;\n\n    list_node&lt;T&gt;* m_node_ptr;\n\n    // Default constructor\n    SimpleBidirectionalIterator() = default;\n\n    // Constructor\n    SimpleBidirectionalIterator(list_node&lt;T&gt;* start)\n        : m_node_ptr{start} {}\n\n    // Dereference operator\n    reference operator*() const {\n        return m_node_ptr-&gt;m_data; // Return the data stored in the node\n    }\n\n    // Pre-increment\n    SimpleBidirectionalIterator& operator++() {\n        m_node_ptr = m_node_ptr-&gt;m_next;\n        return *this;\n    }\n\n    // Post-increment\n    SimpleBidirectionalIterator operator++(int) {\n        auto tmp = *this;\n        ++(*this);\n        return tmp;\n    }\n\n    // Pre-decrement\n    SimpleBidirectionalIterator& operator--(){\n        m_node_ptr = m_node_ptr-&gt;m_prev;\n        return *this;\n    }\n\n    // Post-decrement\n    SimpleBidirectionalIterator operator--(int){\n        auto tmp = *this;\n        --(*this);\n        return tmp;\n    }\n\n    // Equality comparison\n    bool operator==(const SimpleBidirectionalIterator& other) const {\n        return m_node_ptr == other.m_node_ptr;\n    }\n\n    // Inequality comparison\n    bool operator!=(const SimpleBidirectionalIterator& other) const {\n        return !(*this == other);\n    }\n};\n\nstatic_assert(std::bidirectional_iterator&lt;SimpleBidirectionalIterator&lt;int&gt;&gt;);\n\nint main() {\n    return 0;\n}\nCompiler Explorer"
  },
  {
    "objectID": "posts/custom-iterators/index.html#stdrandom_access_iterator",
    "href": "posts/custom-iterators/index.html#stdrandom_access_iterator",
    "title": "Custom iterators and Iterator concepts",
    "section": "std::random_access_iterator",
    "text": "std::random_access_iterator\nContainers such as std::vector&lt;T&gt; and std::array&lt;T,N&gt; are a collection of elements that are stored contiguously in memory. Hence, the element at index i can be accessed in \\(O(1)\\) constant-time.\nWhat if I want to code up an iterator for jumping around the collection? Such an iterator must satisfy the std::random_access_iterator concept. The std::random_access_iterator concept requires that advancement with +=, -=, + and -, computation of distance between two elements and element access using the indexing operator [] be constant-time operations.\n#include &lt;cstddef&gt;\n#include &lt;iterator&gt;\n#include &lt;concepts&gt;\n\ntemplate &lt;typename T&gt;\nstruct SimpleRandomAccessIterator {\n    using difference_type = std::ptrdiff_t;\n    using value_type = T;\n    using pointer = T*;\n    using reference = T&;\n\n    T* m_raw_data_ptr;\n\n    // Default constructor\n    SimpleRandomAccessIterator() = default;\n\n    // Constructor\n    SimpleRandomAccessIterator(T* start)\n        : m_raw_data_ptr{start} {}\n\n    // Dereference operator\n    reference operator*() const {\n        return *m_raw_data_ptr;\n    }\n\n    // Pre-increment\n    SimpleRandomAccessIterator& operator++() {\n        ++m_raw_data_ptr;\n        return *this;\n    }\n\n    // Post-increment\n    SimpleRandomAccessIterator operator++(int) {\n        auto tmp = *this;\n        ++(*this);\n        return tmp;\n    }\n\n    // Pre-decrement\n    SimpleRandomAccessIterator& operator--() {\n        --m_raw_data_ptr;\n        return *this;\n    }\n\n    // Post-decrement\n    SimpleRandomAccessIterator operator--(int) {\n        auto tmp = *this;\n        --(*this);\n        return tmp;\n    }\n\n    // Array subscript operator\n    reference operator[](difference_type n) const {\n        return m_raw_data_ptr[n];\n    }\n\n    // Compound addition\n    SimpleRandomAccessIterator& operator+=(difference_type n) {\n        m_raw_data_ptr += n;\n        return *this;\n    }\n\n    // Compound subtraction\n    SimpleRandomAccessIterator& operator-=(difference_type n) {\n        m_raw_data_ptr -= n;\n        return *this;\n    }\n\n    // Addition\n    SimpleRandomAccessIterator operator+(difference_type n) const {\n        return SimpleRandomAccessIterator(m_raw_data_ptr + n);\n    }\n\n    // Subtraction\n    SimpleRandomAccessIterator operator-(difference_type n) const {\n        return SimpleRandomAccessIterator(m_raw_data_ptr - n);\n    }\n\n    // Distance between iterators\n    difference_type operator-(const SimpleRandomAccessIterator& other) const {\n        return m_raw_data_ptr - other.m_raw_data_ptr;\n    }\n\n    // Equality comparison\n    bool operator==(const SimpleRandomAccessIterator& other) const {\n        return m_raw_data_ptr == other.m_raw_data_ptr;\n    }\n\n    // Inequality comparison\n    bool operator!=(const SimpleRandomAccessIterator& other) const {\n        return !(*this == other);\n    }\n\n    // Relational operators\n    bool operator&lt;(const SimpleRandomAccessIterator& other) const {\n        return m_raw_data_ptr &lt; other.m_raw_data_ptr;\n    }\n\n    bool operator&lt;=(const SimpleRandomAccessIterator& other) const {\n        return m_raw_data_ptr &lt;= other.m_raw_data_ptr;\n    }\n\n    bool operator&gt;(const SimpleRandomAccessIterator& other) const {\n        return m_raw_data_ptr &gt; other.m_raw_data_ptr;\n    }\n\n    bool operator&gt;=(const SimpleRandomAccessIterator& other) const {\n        return m_raw_data_ptr &gt;= other.m_raw_data_ptr;\n    }\n\n    // Friend operator+ for n + iterator\n    template &lt;typename U&gt;\n    friend SimpleRandomAccessIterator&lt;U&gt; operator+(\n        typename SimpleRandomAccessIterator&lt;U&gt;::difference_type n,\n        const SimpleRandomAccessIterator&lt;U&gt;& it\n    ) {\n        return SimpleRandomAccessIterator&lt;U&gt;(it.m_raw_data_ptr + n);\n    }\n};\n\nstatic_assert(std::random_access_iterator&lt;SimpleRandomAccessIterator&lt;int&gt;&gt;);\n\nint main() {\n    return 0;\n}\nCompiler Explorer"
  },
  {
    "objectID": "posts/diagonalization/index.html",
    "href": "posts/diagonalization/index.html",
    "title": "Eigenthingies and Diagonalizability",
    "section": "",
    "text": "Each square matrix possesses a collection of one or more complex scalars, called eigenvalues and associated vectors called eigenvectors. A matrix is a concrete realization of a linear transformation on a vector space. The eigenvectors indicate the directions of pure stretch and the eigenvalues the extent of stretching."
  },
  {
    "objectID": "posts/diagonalization/index.html#eigenvalues-and-eigenvectors",
    "href": "posts/diagonalization/index.html#eigenvalues-and-eigenvectors",
    "title": "Eigenthingies and Diagonalizability",
    "section": "Eigenvalues and Eigenvectors",
    "text": "Eigenvalues and Eigenvectors\n\nDefinition 1 (Eigenvalue and Eigenvector) Let \\(A\\) be an \\(n \\times n\\) matrix. A scalar \\(\\lambda\\) is called an eigenvalue of \\(A\\) if there exists a non-zero vector \\(\\mathbf{v} \\neq \\mathbf{0}\\) such that\n\\[\nA\\mathbf{v} = \\lambda \\mathbf{v}\n\\tag{1}\\]\n\nIn geometric terms, the matrix \\(A\\) has the effect of stretching the eigenvector \\(\\mathbf{v}\\) by an amount specified by the eigenvalue \\(\\lambda\\).\nThe eigenvalue equation (Equation 1) is a system of linear equations is a system of linear equations for the entries of the eigenvector \\(\\mathbf{v}\\), provided that the eigenvaluen \\(\\lambda\\) is specified in advance. But, Gaussian elimination per se cannot solve the problem of determining two unknowns \\(\\lambda\\) and \\(\\mathbf{v}\\). We can rewrite the equation in the form:\n\\[\n(A- \\lambda I)\\mathbf{v} = \\mathbf{0}\n\\tag{2}\\]\nThis is a homogenous system of linear equations. It has the trivial solution \\(\\mathbf{v}=0\\). But, we are specifically seeking a non-zero solution. The homogenous system \\(R\\mathbf{x}=\\mathbf{0}\\) has a non-trivial solution, if and only if, \\(R\\) is singular, \\(rank(R) &lt; n\\) or equivalently \\(det(R) = 0\\). Consequently, we desire\n\\[\ndet(A-\\lambda I) = 0\n\\tag{3}\\]\nThis is called the characteristic equation and \\(p(\\lambda) = det(A-\\lambda I)\\) is called the characteristic polynomial.\nIn practice, one first solves the characteristic equation (Equation 3) to obtain a set of eigenvalues. Then, for each eigenvalue, we use standard linear algebra methods e.g. Gaussian elimination to solve the correponding linear system Equation 2 for the associated eigenvector \\(\\mathbf{v}\\)."
  },
  {
    "objectID": "posts/diagonalization/index.html#emhe",
    "href": "posts/diagonalization/index.html#emhe",
    "title": "Eigenthingies and Diagonalizability",
    "section": "EMHE",
    "text": "EMHE\n\nTheorem 1 Every matrix has atleast one eigenvalue, and a corresponding eigenvector.\n\nProof.\nThis is just the FTA(Fundamental Theorem of Algebra), but it’s still worth enumerating as a theorem.\nLet \\(A \\in \\mathbb{C}^{n \\times n}\\) and the scalar field \\(\\mathbb{F}= \\mathbb{R}\\).\nLet \\(\\mathbf{v}\\) be any non-zero vector in \\(\\mathbb{C}^n\\). Consider the list \\(\\{\\mathbf{v},A\\mathbf{v},\\ldots,A^n \\mathbf{v}\\}\\). These are \\(n+1\\) vectors and this must be a linearly dependent set. There exists \\(a_0, \\ldots, a_n\\) not all zero, such that:\n\\[\na_n A^n \\mathbf{v} + a_{n-1}A^{n-1}\\mathbf{v} + \\ldots + a_1 A \\mathbf{v} + a_0 I \\mathbf{v} = \\mathbf{0}\n\\]\nSince this holds for all \\(\\mathbf{v}\\neq \\mathbf{0}\\), the linear operator \\(a_n A^n + \\ldots + a_1 A + a_0 I\\) must be the zero transformation.\nBy FTA, the polynomial equation with complex coefficients of degree \\(n\\):\n\\[\np(x) = a_0 + a_1 x + a_2 x^2 + \\ldots + a_{n}x^n\n\\]\ncan be factorized as :\n\\[\np(x) = (x - \\lambda_1)(x - \\lambda_2)\\cdots(x - \\lambda_n)\n\\]\nPutting it all together,\n\\[\n\\begin{align*}\np(A)\\mathbf{v} &= (A - \\lambda_1 I)(A - \\lambda_2 I)\\cdots (A - \\lambda_n I)\\mathbf{v} = \\mathbf{0}\n\\end{align*}\n\\]\n\\(\\forall \\mathbf{v} \\neq \\mathbf{0}\\).\nSo, the composition of the factors \\((A-\\lambda_1 I)\\cdots (A - \\lambda_n I)\\) has a non-trivial null space.\n\\[\nker((A-\\lambda_1 I)(A-\\lambda_2 I)\\cdots (A - \\lambda_n I)) \\neq \\{\\mathbf{0}\\}\n\\]\nSo, atleast one of the factors must fail to be injective. There exists \\(\\lambda_i\\), such that \\((A-\\lambda_i I)\\mathbf{v}=\\mathbf{0}\\) such that \\(\\mathbf{v}\\neq \\mathbf{0}\\). Thus, \\(A\\) has atleast one eigenvalue and one eigenvector. \\(\\blacksquare\\)"
  },
  {
    "objectID": "posts/diagonalization/index.html#eigenvectors-as-the-basis-of-a-vector-space",
    "href": "posts/diagonalization/index.html#eigenvectors-as-the-basis-of-a-vector-space",
    "title": "Eigenthingies and Diagonalizability",
    "section": "Eigenvectors as the basis of a vector space",
    "text": "Eigenvectors as the basis of a vector space\n\nLemma 1 If \\(\\lambda_1 \\geq \\lambda_2 \\geq \\ldots \\geq \\lambda_n\\) are \\(n\\) distinct eigenvalues of a matrix \\(A\\), \\(\\lambda_i \\neq \\lambda_j\\), \\(\\forall i \\neq j\\), then the corresponding eigenvectors \\(\\{\\mathbf{v}_1,\\ldots,\\mathbf{v}_n\\}\\) are linearly independent.\n\nProof.\nWe use induction on the number of eigenvalues. The case \\(k=1\\) is immediate, since an eigenvector cannot be zero. Assume that we know that the result is valid for \\((k-1)\\) eigenvalues. Our claim is that \\(\\{\\mathbf{v}_1,\\ldots,\\mathbf{v}_{k-1},\\mathbf{v}_k\\}\\) are linearly independent.\nSuppose we have a vanishing linear combination:\n\\[\nc_1 \\mathbf{v}_1 + c_2 \\mathbf{v}_2 + \\ldots + c_{k} \\mathbf{v}_k = \\mathbf{0}\n\\tag{4}\\]\nLet us multiply this equation by the matrix \\(A\\):\n\\[\n\\begin{align*}\nc_1 A\\mathbf{v}_1 + c_2 A\\mathbf{v}_2 + \\ldots + c_{k} A\\mathbf{v}_k &= \\mathbf{0}\\\\\n\\Longrightarrow c_1 \\lambda_1 \\mathbf{v}_1 + c_2 \\lambda_2 \\mathbf{v}_2 + \\ldots + c_k \\lambda_k \\mathbf{v}_k &= \\mathbf{0}\n\\end{align*}\n\\]\nOn the other hand if we multiply the original Equation 4 by \\(\\lambda_k\\), we have:\n\\[\nc_1 \\lambda_k \\mathbf{v}_1 + c_2 \\lambda_k \\mathbf{v}_2 + \\ldots + c_{k} \\lambda_k \\mathbf{v}_k = \\mathbf{0}\n\\]\nUpon subtracting this from the previous equation, we obtain:\n\\[\nc_1 (\\lambda_1 - \\lambda_k) \\mathbf{v}_1 + c_2 (\\lambda_2 - \\lambda_k)\\mathbf{v}_2 + \\ldots + c_{k-1} (\\lambda_{k-1} - \\lambda_k)\\mathbf{v}_{k-1} = \\mathbf{0}\n\\]\nThis is a vanishing linear combination of the first \\((k-1)\\) eigenvectors, and so, by our induction hypothesis, it can only happen if all the coefficients are zero:\n\\[\nc_1(\\lambda_1 - \\lambda_k) = c_2(\\lambda_2 - \\lambda_k) = \\ldots = c_{k-1}(\\lambda_{k-1} - \\lambda_k) = 0\n\\]\nThe eigenvalues were assumed to be distinct, and consequently \\(c_1 = c_2 = \\ldots = c_{k-1} = 0\\). Substituting these values back into Equation 4, we find that \\(c_k \\mathbf{v}_k = 0\\), and so \\(c_k = 0\\) also, since \\(\\mathbf{v}_k \\neq \\mathbf{0}\\). Thus, we have proved that, if Equation 4 holds, then \\(c_1 = \\ldots = c_k = 0\\). Thus, \\(\\{\\mathbf{v}_1,\\ldots,\\mathbf{v}_k\\}\\) is a linearly independent set. \\(\\blacksquare\\)\n\nTheorem 2 If the \\(n \\times n\\) real matrix \\(A\\) has \\(n\\) distinct real eigenvalues \\(\\lambda_1,\\lambda_2,\\ldots,\\lambda_n\\), then the corresponding real eigenvectors \\(\\mathbf{v}_1,\\ldots,\\mathbf{v}_n\\) form a basis of \\(\\mathbb{R}^n\\). If \\(A\\) (which may be either real or complex-valued matrix) has \\(n\\) distinct complex eigenvalues, then the corresponding eigenvectors \\(\\mathbf{v}_1,\\ldots,\\mathbf{v}_n\\) form a basis of \\(\\mathbb{C}^n\\)."
  },
  {
    "objectID": "posts/diagonalization/index.html#diagonalization",
    "href": "posts/diagonalization/index.html#diagonalization",
    "title": "Eigenthingies and Diagonalizability",
    "section": "Diagonalization",
    "text": "Diagonalization\nConsider a square matrix \\(A \\in \\mathbb{R}^{n \\times n}\\) with \\(n\\) distinct eigenvalues. We can then write:\n\\[\nA\\begin{bmatrix}\\mathbf{v}_1 \\\\ \\mathbf{v}_2 \\\\ \\vdots \\\\ \\mathbf{v}_n\\end{bmatrix} =\n\\begin{bmatrix}\n\\lambda_1 \\\\\n& \\lambda_2 \\\\\n& & \\ddots \\\\\n& & & \\lambda_n\n\\end{bmatrix}\\begin{bmatrix}\\mathbf{v}_1 \\\\ \\mathbf{v}_2 \\\\ \\vdots \\\\ \\mathbf{v}_n\\end{bmatrix}\n\\]\nDefine \\(P\\) as \\((\\mathbf{v}_1,\\mathbf{v}_2,\\ldots,\\mathbf{v}_n)^T\\). So, we can write:\n\\[\n\\begin{align*}\nAP &= \\Lambda P\\\\\nA & = P^{-1}\\Lambda P\n\\end{align*}\n\\]\nor equivalently \\(A=P\\Lambda P^{-1}\\), where \\(\\Lambda = diag(\\lambda_1,\\ldots,\\lambda_n)\\) is a diagonal matrix. Consequently, if the matrix \\(A\\) has \\(n\\) distinct eigenvalues, then \\(A\\) is said to be diagonalizable.\n\nDefinition 2 A square matrix \\(A\\) is said to be diagonalizable, if and only if, there exists a non-singular matrix \\(P\\), such that \\(A\\) has a matrix factorization:\n\\[\nA = P\\Lambda P^{-1}\n\\]\nwhere \\(\\Lambda=diag(\\lambda_1,\\ldots,\\lambda_n)\\) ."
  },
  {
    "objectID": "posts/diagonalization/index.html#gershgorin-circle-theorem",
    "href": "posts/diagonalization/index.html#gershgorin-circle-theorem",
    "title": "Eigenthingies and Diagonalizability",
    "section": "Gershgorin-Circle Theorem",
    "text": "Gershgorin-Circle Theorem\nIn pratice, precisely computing the eigenvalues of a matrix is done using a numerical algorithm. In certain theoretical applications, we may not require numerical values, but only their approximate locations. The Gershgorin circle theorem, due to early 20th century Russian mathematician Semyon Gershgorin, serves to restrict the eigenvalues to a certain well-defined region in the complex plane.\n\nDefinition 3 Let \\(A \\in \\mathbb{C}^{n \\times n}\\) be a square matrix. For each \\(1 \\leq i \\leq n\\) , define the \\(i\\) th Gershgorin disk\n\\[\nD_i = \\{|z - a_{ii}|&lt;r_i:z\\in\\mathbb{C}\\}, \\quad r_i = \\sum_{j,j\\neq i} |a_{ij}|\n\\tag{5}\\]\nThe Gershgorin domain \\(D_A = \\bigcup_{i=1}^n D_i \\subset \\mathbb{C}\\) is the union of the Gershgorin disks.\n\nThus, the \\(i\\)th Gershgorin disk \\(D_i\\) is centered at the \\(i\\)-th diagonal entry of \\(A\\) and is an open ball of radius \\(r_i\\) equal to the sum of the absolute values of the off-diagonal entries that are in it’s \\(i\\)-th row.\nProof\nLet \\(\\mathbf{v}\\) be an eigenvector of \\(A\\) with eigenvalue \\(\\lambda\\). Let \\(\\mathbf{u}=\\mathbf{v}/||v||_{\\infty}\\) be the corresponding unit eigenvector with respect to the \\(\\infty\\)-norm, so that:\n\\[\n||u||_{\\infty} = \\max\\{|u|_1,|u|_2,\\ldots,|u|_n\\} = 1\n\\]\nLet \\(u_i\\) be an entry of \\(\\mathbf{u}\\) that achieves the maximum: \\(|u_i|=1\\). Writing out the \\(i\\)-th component of the eigenvalue equation \\(A\\mathbf{u}=\\lambda \\mathbf{u}\\), we obtain:\n\\[\n\\begin{align*}\n\\sum_{j=1}^{n} a_{ij}u_j &= \\lambda u_i \\\\\n\\sum_{j \\neq i} a_{ij}u_j &= (\\lambda - a_{ii}) u_i\n\\end{align*}\n\\]\nTherefore, since all \\(|u_j| \\leq 1\\), while \\(|u_i|=1\\), the distance between \\(\\lambda\\) and \\(a_{ii}\\) can be bounded from above as:\n\\[\n\\begin{align*}\n|\\lambda - a_{ii}| &= \\Bigg|\\sum_{j \\neq i} a_{ij}u_j \\Bigg|\\\\\n&\\leq \\sum_{j \\neq i} |a_{ij}||u_j| & \\{\\text{ Triangle Inequality }\\}\\\\\n&\\leq \\sum_{j \\neq i} |a_{ij}| & \\{ |u_j| \\leq 1 \\}\\\\\n&= r_i\n\\end{align*}\n\\]\nThis immediately implies that \\(\\lambda \\in D_i \\subset D_A\\) belongs to the \\(i\\)th Gershgorin disk."
  },
  {
    "objectID": "posts/exploring-option-greeks/index.html",
    "href": "posts/exploring-option-greeks/index.html",
    "title": "Exploring Option Greeks",
    "section": "",
    "text": "I derived the Black-Scholes formula for European style vanilla FX options in a previous post here. The Black-Scholes model \\(Bl(S_0,K,T,r_{DOM},r_{FOR},\\sigma)\\) equipped with a single flat volatility parameter \\(\\sigma\\) produces option prices which are NOT consistent with the observed market prices of FX options across different strikes and maturities.\nAlthough, the BS model suffers many flaws, it is still often used, at least for quoting purposes. Since all of the other inputs into the model - market data variables such as the stock price \\(S_0\\), the domestic depo rate \\(r_{DOM}\\), the foreign depo rate \\(r_{FOR}\\), and the parameters such as option strike \\(K\\), the time-to-maturity \\(T\\), can be either seen in the market or are known constants, we can easily solve for the value \\(\\sigma_{\\text{imp}}\\) of the parameter \\(\\sigma\\) such that:\n\\[Bl(S_0,K,T,r_{DOM},r_{FOR},\\sigma_{\\text{imp}}) = V_{\\text{market}}\\]\nThis value \\(\\sigma_{\\text{imp}}\\) implied from the market price of the option is called the implied volatility.\nThus, although the BS model suffers from flaws, it is mainly used as a quote converter. In the FX options market, option prices are quoted in terms of implied volatilities. The BS formula is used to convert implied vols \\(\\sigma_{\\text{imp}}\\) to prices and vice versa. The delta hedge to be exchanged between counterparties is calculated according to the BS formula, and this is also true for the Vega hedge of various exotic options. In many cases, the model is also used to run trading books.\nIn this note, I explore various delta conventions and derive the greeks. Check out FX Vol smile by Wyestup! The entire concept of the FX volatility smile is based on the parametrization with respect to delta."
  },
  {
    "objectID": "posts/exploring-option-greeks/index.html#introduction.",
    "href": "posts/exploring-option-greeks/index.html#introduction.",
    "title": "Exploring Option Greeks",
    "section": "",
    "text": "I derived the Black-Scholes formula for European style vanilla FX options in a previous post here. The Black-Scholes model \\(Bl(S_0,K,T,r_{DOM},r_{FOR},\\sigma)\\) equipped with a single flat volatility parameter \\(\\sigma\\) produces option prices which are NOT consistent with the observed market prices of FX options across different strikes and maturities.\nAlthough, the BS model suffers many flaws, it is still often used, at least for quoting purposes. Since all of the other inputs into the model - market data variables such as the stock price \\(S_0\\), the domestic depo rate \\(r_{DOM}\\), the foreign depo rate \\(r_{FOR}\\), and the parameters such as option strike \\(K\\), the time-to-maturity \\(T\\), can be either seen in the market or are known constants, we can easily solve for the value \\(\\sigma_{\\text{imp}}\\) of the parameter \\(\\sigma\\) such that:\n\\[Bl(S_0,K,T,r_{DOM},r_{FOR},\\sigma_{\\text{imp}}) = V_{\\text{market}}\\]\nThis value \\(\\sigma_{\\text{imp}}\\) implied from the market price of the option is called the implied volatility.\nThus, although the BS model suffers from flaws, it is mainly used as a quote converter. In the FX options market, option prices are quoted in terms of implied volatilities. The BS formula is used to convert implied vols \\(\\sigma_{\\text{imp}}\\) to prices and vice versa. The delta hedge to be exchanged between counterparties is calculated according to the BS formula, and this is also true for the Vega hedge of various exotic options. In many cases, the model is also used to run trading books.\nIn this note, I explore various delta conventions and derive the greeks. Check out FX Vol smile by Wyestup! The entire concept of the FX volatility smile is based on the parametrization with respect to delta."
  },
  {
    "objectID": "posts/exploring-option-greeks/index.html#quote-style-conversions.",
    "href": "posts/exploring-option-greeks/index.html#quote-style-conversions.",
    "title": "Exploring Option Greeks",
    "section": "Quote style conversions.",
    "text": "Quote style conversions.\nIn FX markets, options are quoted in one of 4 quote styles - domestic per foreign (d/f), percentage foreign (%f), percentage domestic (%d) and foreign per domestic (f/d).\nThe standard Black-Scholes formula is:\n\\[\n\\begin{align*}\nV_{d/f} &= \\omega [S_0 e^{-r_{FOR} T} \\Phi(d_{+}) - K e^{-r_{DOM}T} \\Phi(d_{-})\\\\\n&= \\omega e^{-r_{DOM}T}[F \\Phi(d_{+}) - K  \\Phi(d_{-})]\n\\end{align*}\n\\]\n\nImplementing the Bl Calculator and Option Greeks.\nimport numpy as np\nfrom scipy.stats import norm\nfrom enum import Enum\nimport datetime as dt\n\nclass CallPut(Enum):\n    CALL_OPTION = 1\n    PUT_OPTION = -1\n\nclass BlackCalculator:\n    \"\"\"Implements the Black formula to price a vanilla option\"\"\"\n    def __init__(\n        self,\n        s_t : float,\n        strike : float,\n        today : float,\n        expiry : float,\n        r_dom : float,\n        r_for : float,\n        sigma : float            \n    )\n        self._s_t = s_t\n        self._strike = strike\n        self._today = today\n        self._expiry = expiry\n        self._r_dom = r_dom\n        self._r_for = r_for\n        self._sigma = sigma\n\n    def at_the_money_forward(\n        self,\n    ) -&gt; float :\n        \"\"\"Computes the at-the-money forward\"\"\"\n\n        foreign_df = np.exp(self._r_for * (expiry - today))\n        domestic_df = np.exp(self._r_dom * (expiry - today))\n        fwd_points = foreign_df / domestic_df\n        return self._s_t * fwd_points \n            \n    def d_plus(S_t,K,t,T,r_DOM,r_FOR,sigma):\n        F = at_the_money_forward(S_t,K,t,T,r_DOM,r_FOR,sigma)\n        return (np.log(F/K) + (T-t)*(sigma**2)/2)/(sigma * np.sqrt(T - t))\n\n    def d_minus(S_t,K,t,T,r_DOM,r_FOR,sigma):\n        F = at_the_money_forward(S_t,K,t,T,r_DOM,r_FOR,sigma)\n        return (np.log(F/K) - (T-t)*(sigma**2)/2)/(sigma * np.sqrt(T - t))\n\n    def pv(S_t,K,t,T,r_DOM,r_FOR,sigma, CCY1Notional,callPut):\n        F = at_the_money_forward(S_t,K,t,T,r_DOM,r_FOR,sigma)\n        omega = callPut.value\n        d_plus = dPlus(S_t,K,t,T,r_DOM,r_FOR,sigma)\n        d_minus = dMinus(S_t,K,t,T,r_DOM,r_FOR,sigma)\n        domesticDF = np.exp(-r_DOM*(T-t))\n        \n        undiscountedPrice = omega* (F * norm.cdf(omega * d_plus) - K * norm.cdf(omega * d_minus))\n        pv = domesticDF * undiscountedPrice * CCY1Notional\n        return pv"
  },
  {
    "objectID": "posts/fun-with-numeraires/index.html",
    "href": "posts/fun-with-numeraires/index.html",
    "title": "Fun with numeraires!",
    "section": "",
    "text": "A proficiency in the change-of-measure technique is useful to the working quant. An excellent summary of the important results is the note Girsanov, Numeraires and all that, by Andrew Lesniewski. In this post, I would like to derive relevant results and then we can enjoy pricing some payoffs together!"
  },
  {
    "objectID": "posts/fun-with-numeraires/index.html#introduction",
    "href": "posts/fun-with-numeraires/index.html#introduction",
    "title": "Fun with numeraires!",
    "section": "",
    "text": "A proficiency in the change-of-measure technique is useful to the working quant. An excellent summary of the important results is the note Girsanov, Numeraires and all that, by Andrew Lesniewski. In this post, I would like to derive relevant results and then we can enjoy pricing some payoffs together!"
  },
  {
    "objectID": "posts/fun-with-numeraires/index.html#girsanov-theorem",
    "href": "posts/fun-with-numeraires/index.html#girsanov-theorem",
    "title": "Fun with numeraires!",
    "section": "Girsanov Theorem",
    "text": "Girsanov Theorem\n\nTheorem 1 (Girsanov Theorem) Let \\((W^{\\mathbb{P}},t\\geq 0)\\) be a \\(\\mathbb{P}\\) standard brownian motion on \\((\\Omega,\\mathcal{F},\\mathbb{P})\\) and let \\(\\phi\\) be any adapted process. Choose fixed \\(T\\) and defined the process \\(L\\) on \\([0,T]\\) by:\n\\[\n\\begin{align*}\ndL_t = \\phi_t L_t dW^{\\mathbb{P}}_t\n\\end{align*}\n\\tag{1}\\]\n\\[\n\\begin{align*}\nL_0 = 1\n\\end{align*}\n\\tag{2}\\]\nthat is:\n\\[\n\\begin{align*}\nL_t = \\exp\\left(\\int_0^t \\phi_s dW^{\\mathbb{P}}_s - \\int_0^t \\phi^2_s ds\\right)\n\\end{align*}\n\\tag{3}\\]\nAssume that:\n\\[\n\\begin{align*}\n\\mathbb{E}^{\\mathbb{P}}[L_T] = 1\n\\end{align*}\n\\tag{4}\\]\nand define the new probability measure \\(\\mathbb{Q}\\) on \\(\\mathcal{F}_t\\) by:\n\\[\nL_T = \\frac{d\\mathbb{Q}}{d\\mathbb{P}}\n\\tag{5}\\]\nThen,\n\\[\ndW^{\\mathbb{P}}_t = dW^{\\mathbb{Q}}_t + \\phi_t dt\n\\tag{6}\\]\nwhere \\(dW^{\\mathbb{Q}}_t\\) is a \\(\\mathbb{Q}\\)-standard brownian motion.\n\nProof.\nOur claim is that, under the \\(\\mathbb{Q}\\) measure, the increments \\((W^{\\mathbb{Q}}_t - W^{\\mathbb{Q}}_s)\\) are normally distributed with mean \\(0\\) and variance \\((t-s)\\). We start with the special case \\(s=0\\). Using moment generating functions, it is enough to show that:\nIt is straightforward to derive Equation 3 using Ito’s lemma. Let \\(f(x) = \\ln x\\). Then, \\(f_x = \\frac{1}{x}\\), \\(f_{xx} = -\\frac{1}{x^2}\\).\n\\[\n\\begin{align*}\nd(\\ln L_t) &= \\frac{1}{L_t}dL_t -\\frac{1}{2} \\frac{1}{L_t^2}(dL_t)^2 \\\\\n&= \\frac{1}{L_t}{\\phi_t L_t dW^{\\mathbb{P}}_t} - \\frac{1}{2L_t^2}\\phi_t^2 L_t^2 dt\\\\\n&= \\phi_t dW^{\\mathbb{P}}_t -\\frac{1}{2} \\phi_t^2 dt \\\\\nL_t &= \\exp\\left(\\int_0^t \\phi_s dW^{\\mathbb{P}}_s - \\frac{1}{2}\\int_0^t \\phi_s^2 ds \\right)\n\\end{align*}\n\\]\nTo prove our main result, we will now use the MGF of the increments. For \\(n \\in \\mathbb{N}\\) and \\((t_j,j\\leq n)\\) a partition of \\([0,T]\\), with \\(t_n = T\\), I will show that :\n\\[\n\\begin{align*}\n\\mathbb{E}^{\\mathbb{Q}}\\left[\\exp\\left(\\sum_{j=0}^{n-1}\\lambda_j (W^{\\mathbb{Q}}_{t_{j+1}} - W^{\\mathbb{Q}}_{t_{j}})\\right)\\right] = \\exp\\left[\\sum_{j=0}^{n-1}\\lambda_j^2(t_{j+1}-t_j)\\right]\n\\end{align*}\n\\tag{7}\\]\nThis proves that the increments are the ones of standard brownian motion.\nLet \\((\\mathcal{F}_{t_j},j\\leq n)\\) be the filtrations of the Brownian motion at the time of the partition. The proof is by successively conditioning from \\(t_{n-1}\\) to \\(t_1\\). We have:\n\\[\n\\begin{aligned}\n\\mathbb{E}^{\\mathbb{Q}}\\left[\\exp\\left(\\sum _{j=0}^{n-1} \\lambda _{j} (W_{t_{j+1}}^{\\mathbb{Q}} -W_{t_{j}}^{\\mathbb{Q}} )\\right)\\right] & =\\mathbb{E}^{\\mathbb{P}}\\left[\\mathbb{E}^{\\mathbb{P}}\\left[ L_{t_{n}}\\exp\\left(\\sum _{j=0}^{n-1} \\lambda _{j} (W_{t_{j+1}}^{\\mathbb{Q}} -W_{t_{j}}^{\\mathbb{Q}} )\\right) |\\mathcal{F}_{t_{n-1}}\\right]\\right]\\\\\n& =\\mathbb{E}^{\\mathbb{P}}\\left[\\sum _{j=0}^{n-2} \\lambda _{j} (W_{t_{j+1}}^{\\mathbb{Q}} -W_{t_{j}}^{\\mathbb{Q}} )\\mathbb{E}^{\\mathbb{P}}\\left[ L_{t_{n}}\\exp\\left( \\lambda _{n-1} (W_{t_{n}}^{\\mathbb{Q}} -W_{t_{n-1}}^{\\mathbb{Q}} )\\right) |\\mathcal{F}_{t_{n-1}}\\right]\\right]\\\\\n& =\\mathbb{E}^{\\mathbb{P}}\\left[\\sum _{j=0}^{n-2} \\lambda _{j} (W_{t_{j+1}}^{\\mathbb{Q}} -W_{t_{j}}^{\\mathbb{Q}} )\\mathbb{E}^{\\mathbb{P}}\\left[\\exp\\left(\\int _{t_{n-1}}^{t_{n}} \\phi _{s} dW_{s}^{\\mathbb{Q}} +\\frac{1}{2}\\int _{t_{n-1}}^{t_{n}} \\phi _{s}^{2} ds\\right)\\exp\\left( \\lambda _{n-1}\\int _{t_{n-1}}^{t_{n}} dW_{s}^{\\mathbb{Q}}\\right) |\\mathcal{F}_{t_{n-1}}\\right]\\right]\\\\\n& =\\mathbb{E}^{\\mathbb{P}}\\left[\\sum _{j=0}^{n-2} \\lambda _{j} (W_{t_{j+1}}^{\\mathbb{Q}} -W_{t_{j}}^{\\mathbb{Q}} )\\mathbb{E}^{\\mathbb{P}}\\left[\\exp\\left(\\int _{t_{n-1}}^{t_{n}}( \\phi _{s} +\\lambda _{n-1}) dW_{s}^{\\mathbb{Q}} +\\frac{1}{2}\\int _{t_{n-1}}^{t_{n}} \\phi _{s}^{2} ds\\right) |\\mathcal{F}_{t_{n-1}}\\right]\\right]\\\\\n& =\\mathbb{E}^{\\mathbb{P}}\\left[\\sum _{j=0}^{n-2} \\lambda _{j} (W_{t_{j+1}}^{\\mathbb{Q}} -W_{t_{j}}^{\\mathbb{Q}} )\\mathbb{E}^{\\mathbb{P}}\\left[\\exp\\left(\\int _{t_{n-1}}^{t_{n}}( \\phi _{s} +\\lambda _{n-1})\\left( dW_{s}^{\\mathbb{P}} -\\theta ds\\right) +\\frac{1}{2}\\int _{t_{n-1}}^{t_{n}} \\phi _{s}^{2} ds\\right) |\\mathcal{F}_{t_{n-1}}\\right]\\right]\\\\\n& =\\mathbb{E}^{\\mathbb{P}}\\left[\\sum _{j=0}^{n-2} \\lambda _{j} (W_{t_{j+1}}^{\\mathbb{Q}} -W_{t_{j}}^{\\mathbb{Q}} )\\exp\\left(\\frac{1}{2}\\int _{t_{n-1}}^{t_{n}} \\phi _{s}^{2} +\\int _{t_{n-1}}^{t_{n}} -\\phi _{s}( \\phi _{s} +\\lambda _{n-1}) ds\\right) \\ \\exp\\left(\\frac{1}{2}\\int _{t_{n-1}}^{t_{n}}( \\phi _{s} +\\lambda _{n-1})^{2} ds\\right)\\right]\\\\\n& \\left\\{\\ \\int XdW_{s}^{\\mathbb{P}} \\ \\text{ is a }\\mathcal{N}^{\\mathbb{P}}\\left( 0,\\int \\mathbb{E}\\left[ X^{2}\\right] ds\\right) \\ \\text{gaussian random variable.}\\right\\} \\ \\\\\n& =\\mathbb{E}^{\\mathbb{P}}\\left[\\sum _{j=0}^{n-2} \\lambda _{j} (W_{t_{j+1}}^{\\mathbb{Q}} -W_{t_{j}}^{\\mathbb{Q}} )\\exp\\left(\\int _{t_{n-1}}^{t_{n}}\\left( -\\frac{1}{2} \\phi _{s}^{2} -\\lambda _{n-1} \\phi _{s} +\\frac{1}{2} \\phi _{s}^{2} +\\lambda _{n-1} \\phi _{s} +\\lambda _{n-1}^{2}\\right) ds\\right)\\right]\\\\\n& =\\mathbb{E}^{\\mathbb{P}}\\left[\\sum _{j=0}^{n-2} \\lambda _{j} (W_{t_{j+1}}^{\\mathbb{Q}} -W_{t_{j}}^{\\mathbb{Q}} )\\exp\\left( \\lambda _{n-1}\\int _{t_{n-1}}^{t_{n}} ds\\right)\\right]\\\\\n& =\\exp( \\lambda _{n-1}( t_{n} -t_{n-1}) \\cdot \\mathbb{E}^{\\mathbb{P}}\\left[\\sum _{j=0}^{n-2} \\lambda _{j} (W_{t_{j+1}}^{\\mathbb{Q}} -W_{t_{j}}^{\\mathbb{Q}} )\\right]\n\\end{aligned}\n\\]\nHere, I used the fact that \\(L_{t_{n-1}}\\) is \\(\\mathcal{F}_{t_{n-1}}\\) measurable. I can now condition on \\(\\mathcal{F}_{t_{n-2}}\\) down to \\(\\mathcal{F}_{t_1}\\) and proceed as above to obtain the desired result.\nThe process \\(\\phi_t\\) is called the Girsanov kernel."
  },
  {
    "objectID": "posts/fun-with-numeraires/index.html#what-is-a-numeraire",
    "href": "posts/fun-with-numeraires/index.html#what-is-a-numeraire",
    "title": "Fun with numeraires!",
    "section": "What is a numeraire?",
    "text": "What is a numeraire?\nAs Shreve puts it, a numeraire is the unit of account in which other assets are denominated. In practice, we tend to choose numeraires that simply the payoff expression.\nAny strictly positive (non-dividend paying) price process can be chosen as a numeraire. A numeraire must be a tradable asset.\nConsider a unit of stock worth \\(S_t\\). It can be used as numeraire, because the price process \\(e^{-rt}S_t\\) (assume a constant short rate) is a martingale under risk-neutral measure \\(\\mathbb{Q}^M\\). Powers of the stock price \\(S_t^\\alpha\\) cannot be used as numeraires, because their discounted values are not martingales under the risk-neutral measure. Clearly, set the short rate \\(r = 0\\), then \\(\\mathbb{E}^{\\mathbb{Q}^M}[S_T^2] \\geq (\\mathbb{E}^{\\mathbb{Q}^M}[S_T])^2 =S_0^2\\) by the Jensen’s inequality.\nThe price-process \\(V_t\\) of a derivative contract that pays \\(V_T=S_T^2\\) is a martingale under \\(\\mathbb{Q}\\) and can be used as a numeraire.\nConsider the price of a contract that pays a unit sum \\(1\\) at maturity \\(T\\). This instrument is the zero-coupon bond. Its an observable and tradable asset. Its price process \\(P(t,T) = \\mathbb{E}^{\\mathbb{Q}^M}[1/M_T]\\) can be used as a numeraire. \\(\\mathbb{Q}^T\\) is called the \\(T\\)-forward measure."
  },
  {
    "objectID": "posts/fun-with-numeraires/index.html#abstract-bayes-formula",
    "href": "posts/fun-with-numeraires/index.html#abstract-bayes-formula",
    "title": "Fun with numeraires!",
    "section": "Abstract Bayes Formula",
    "text": "Abstract Bayes Formula\n\nTheorem 2 (Abstract Bayes Formula) Let \\((\\Omega,\\mathcal{F},\\mathbb{P})\\) be a probability space and let \\(\\mathbb{Q}\\) be any other probability measure on it. By the Radon-Nikodym theorem, \\(\\exists L = \\frac{d\\mathbb{Q}}{d\\mathbb{P}}\\), \\(L \\geq 0\\) with \\(\\mathbb{E}^{\\mathbb{P}}[L]=1\\). Then we have:\n\\[\n\\begin{align*}\n\\mathbb{E}^{\\mathbb{Q}}[X|\\mathcal{G}] = \\frac{\\mathbb{E}^{\\mathbb{P}}[LX|\\mathcal{G}]}{\\mathbb{E}^{\\mathbb{P}}[L|\\mathcal{G}]}\n\\end{align*}\n\\tag{8}\\]\n\nProof.\nBy the definition of conditional expectations, recall that if \\(W\\) is any \\(\\mathcal{G}\\)-measurable random variable, then the conditional expectation must satisfy the relationship:\n\\[\n\\mathbb{E}[WX] = \\mathbb{E}[W\\mathbb{E}[X|\\mathcal{G}]]\n\\]\nIt is sufficient to prove that:\n\\[\n\\mathbb{E}^{\\mathbb{P}}[X|\\mathcal{G}]\\mathbb{E}^{\\mathbb{Q}}[L|\\mathcal{G}] = \\mathbb{E}^{\\mathbb{P}}[LX|\\mathcal{G}]\n\\]\nLet \\(G\\) be an arbitrary set in \\(\\mathcal{G}\\). We have:\n\\[\n\\begin{align*}\n& \\int_G \\mathbb{E}^{\\mathbb{Q}}[X|\\mathcal{G}]\\mathbb{E}^{\\mathbb{P}}[L|\\mathcal{G}] d\\mathbb{P} \\\\\n&= \\int_G \\mathbb{E}^{\\mathbb{P}}[L\\cdot \\mathbb{E}^{\\mathbb{Q}}[X|\\mathcal{G}]|\\mathcal{G}] d\\mathbb{P} \\\\\n& \\quad \\{ \\mathbb{E}^{\\mathbb{Q}}[X|\\mathcal{G}] \\text{ is }\\mathcal{G}\\text{-measurable } \\}\\\\\n&= \\int_G  L\\cdot \\mathbb{E}^{\\mathbb{Q}}[X|\\mathcal{G}] d\\mathbb{P}\\\\\n&= \\int_G  \\frac{d\\mathbb{Q}}{d\\mathbb{P}}\\cdot \\mathbb{E}^{\\mathbb{Q}}[X|\\mathcal{G}] d\\mathbb{P}\\\\\n&= \\int_G \\mathbb{E}^{\\mathbb{Q}}[X|\\mathcal{G}] d\\mathbb{Q}\\\\\n&= \\int_G X d\\mathbb{Q}\n\\end{align*}\n\\]\nAlso, we have:\n\\[\n\\begin{align*}\n\\int_{G} \\mathbb{E}^{\\mathbb{P}}[LX|\\mathcal{G}]d\\mathbb{P} &= \\int_G LX d\\mathbb{P}\\\\\n&= \\int_G \\frac{d\\mathbb{Q}}{d\\mathbb{P}} X d\\mathbb{P}\\\\\n&= \\int_G X d\\mathbb{Q}\n\\end{align*}\n\\]\nHence, proved.\nNote that, the filtration \\(\\mathcal{G}\\) is the same irrespective of what probability measure we construct on \\(\\Omega\\)."
  },
  {
    "objectID": "posts/fun-with-numeraires/index.html#martingale-property",
    "href": "posts/fun-with-numeraires/index.html#martingale-property",
    "title": "Fun with numeraires!",
    "section": "Martingale property",
    "text": "Martingale property\n\nProposition 1 Assume that there exists a numeraire \\(M\\) and a probability measure \\(\\mathbb{Q}^M\\), such that the price of any traded asset \\(X\\) (without intermediate payments) relative to \\(M\\) is a martingale under \\(\\mathbb{Q}^M\\).That is:\n\\[\n\\frac{X_t}{M_t} = \\mathbb{E}^{\\mathbb{Q}^M} \\left\\{\\frac{X_T}{M_T}|\\mathcal{F}_t\\right\\}\n\\]\nLet \\(N_t\\) be an arbitrary numeraire. Then, there exists a probability measure \\(\\mathbb{Q}^N\\) such that the price of \\(X\\) normalized by \\(N\\) is a martingale under \\(\\mathbb{Q}^N\\).\n\\[\n\\frac{X_t}{N_t} = \\mathbb{E}^{\\mathbb{Q}^N} \\left\\{\\frac{X_T}{N_T}|\\mathcal{F}_t\\right\\}\n\\]\nMoreover, the Radon-Nikodym derivative defining the measure \\(\\mathbb{Q}^N\\) is given by:\n\\[\n\\frac{d\\mathbb{Q}^N}{d\\mathbb{Q}^M} = \\frac{N_T/N_0}{M_T/M_0}\n\\]\n\nProof.\nWe have:\n\\[\nX_0 = M_0 \\mathbb{E}^{\\mathbb{Q}^M}\\left[\\frac{X_T}{M_T}\\right]\n\\]\nImposing the simple fact that, the price of the derivative contract should be the same, even if we switch numeraires from \\(M\\) to \\(N\\), we should have:\n\\[\nX_0 = N_0 \\mathbb{E}^{\\mathbb{Q}^N}\\left[\\frac{X_T}{N_T}\\right]\n\\]\nThus,\n\\[\n\\begin{aligned}\nN_{0}\\mathbb{E}^{\\mathbb{Q}^{N}}\\left[\\frac{X_{T}}{N_{T}}\\right] & =M_{0}\\mathbb{E}^{\\mathbb{Q}^{M}}\\left[\\frac{X_{T}}{M_{T}}\\right]\\\\\n\\frac{N_{T}}{N_{0}} \\times N_{0}\\mathbb{E}^{\\mathbb{Q}^{N}}\\left[\\frac{X_{T}}{N_{T}}\\right] & =\\frac{N_{T}}{N_{0}} \\times M_{0} \\ \\mathbb{E}^{\\mathbb{Q}^{M}}\\left[\\frac{X_{T}}{M_{T}}\\right] \\quad \\left\\{\\text{Multiplying both sides by }\\frac{N_{T}}{N_{0}}\\right\\}\\\\\n\\Longrightarrow \\mathbb{E}^{\\mathbb{Q}^{N}}[ X_{T}] & =\\mathbb{E}^{\\mathbb{Q}^{M}}\\left[\\frac{N_{T} /N_{0}}{M_{T} /M_{0}} X_{T}\\right]\n\\end{aligned}\n\\]\nBut, we know that:\n\\[\n\\mathbb{E}^{\\mathbb{Q}^N}[X_T] = \\mathbb{E}^{\\mathbb{Q}^M}\\left[\\frac{d\\mathbb{Q}^N}{d\\mathbb{Q}^M}X_T\\right]\n\\]\nConsequently, our candidate for the Radon-Nikodym derivative should be:\n\\[\nL_T = \\frac{d\\mathbb{Q}^N}{d\\mathbb{Q}^M} = \\frac{N_T/N_0}{M_T/M_0}\n\\]\nFurther \\((X_t/N_t)\\) is a martingale under \\(\\mathbb{Q}^N\\). Its easy to see that:\n\\[\n\\begin{aligned}\n\\mathbb{E}^{\\mathbb{Q}^{N}}\\left[\\frac{X_{T}}{N_{T}} |\\mathcal{F}_{t}\\right] & =\\frac{\\mathbb{E}^{\\mathbb{Q}^{M}}\\left[ L_{T} \\cdot \\frac{X_{T}}{N_{T}} |\\mathcal{F}_{t}\\right]}{\\mathbb{E}^{\\mathbb{Q}^{M}}[ L_{T} |\\mathcal{F}_{t}]} \\quad \\left\\{\\text{ Abstract bayes formula }\\right\\}\\\\\n& =\\frac{\\mathbb{E}^{\\mathbb{Q}^{M}}\\left[ L_{T} \\cdot \\frac{X_{T}}{N_{T}} |\\mathcal{F}_{t}\\right]}{L_{t}}\\\\\n& =\\frac{\\mathbb{E}^{\\mathbb{Q}^{M}}\\left[\\frac{N_{T}}{N_{0}} \\cdot \\frac{M_{0}}{M_{T}} \\cdot \\frac{X_{T}}{N_{T}} |\\mathcal{F}_{t}\\right]}{\\frac{N_{t}}{N_{0}} \\cdot \\frac{M_{0}}{M_{t}}}\\\\\n& =\\frac{\\mathbb{E}^{\\mathbb{Q}^{M}}\\left[\\frac{N_{T}}{N_{0}} \\cdot \\frac{M_{0}}{M_{T}} \\cdot \\frac{X_{T}}{N_{T}} |\\mathcal{F}_{t}\\right]}{\\frac{N_{t}}{N_{0}} \\cdot \\frac{M_{0}}{M_{t}}}\\\\\n& =\\frac{M_{t}}{N_{t}} \\cdot \\mathbb{E}^{\\mathbb{Q}^{M}}\\left[\\frac{X_{T}}{M_{T}}\\right]\\\\\n& =\\frac{M_{t}}{N_{t}} \\cdot \\frac{X_{t}}{M_{t}}\\\\\n& =\\frac{X_{t}}{N_{t}}\n\\end{aligned}\n\\]\nSince we determined the relevant likelihood process, it is easy to find the Girsanov Kernel."
  },
  {
    "objectID": "posts/fun-with-numeraires/index.html#drift-transformation-under-change-of-numeraire",
    "href": "posts/fun-with-numeraires/index.html#drift-transformation-under-change-of-numeraire",
    "title": "Fun with numeraires!",
    "section": "Drift transformation under change of numeraire",
    "text": "Drift transformation under change of numeraire\nSuppose we are interested in the dynamics of the stochastic process \\((X_t,t\\geq 0)\\). Under \\(\\mathbb{Q}^M\\) measure, its dynamics reads:\n\\[\n\\begin{aligned}\ndX(t) = \\mu_X^{\\mathbb{Q}^M}(t) dt + c_X(t)dW^{\\mathbb{Q}^M}_t\n\\end{aligned}\n\\tag{9}\\]\nI supressed \\(\\mu_X^{\\mathbb{Q}^M}(t,X_t)\\) as \\(\\mu_X^{\\mathbb{Q}^M}(t)\\) for brevity.\nUnder the \\(\\mathbb{Q}^N\\) measure, its dynamics reads:\n\\[\n\\begin{aligned}\ndX(t) = \\mu_X^{\\mathbb{Q}^N}(t) dt + c_X(t)dW^{\\mathbb{Q}^N}_t\n\\end{aligned}\n\\tag{10}\\]\nRemember that the diffusion coefficients in these equations are unaffected by the change of measure! We assume that \\(\\mathbb{Q}^M\\) is associated with the numeraire \\(M(t)\\) whose dynamics is given by:\n\\[\ndM(t) = \\mu_M(t)dt + c_M(t)dW^{\\mathbb{Q}^M}\n\\]\nand that the numeraire \\(N\\) has \\(\\mathbb{Q}^M\\) dynamics:\n\\[\ndN(t) = \\mu_N(t)dt + c_N(t)dW^{\\mathbb{Q}^N}\n\\]\nAccording to the Girsanov theorem, the likelihood process \\(L(t)\\) accompanying this change of measure is a martingale under the measure \\(\\mathbb{Q}^M\\) measure and satisfies the stochastic differential equation:\n\\[\ndL_t = L(t)\\theta(t)dW^{\\mathbb{Q}^M}_t\n\\]\nExplicitly, the likelihood process \\(L(t)\\) is given by the stochastic exponential of the martingale \\(\\int_0^t \\theta_s dW^{\\mathbb{Q}^M}_s\\):\n\\[\nL(t) = \\exp\\left(\\int_0^t \\theta_s dW^{\\mathbb{Q}^M}_s - \\frac{1}{2}\\int_0^t \\theta^2_s ds \\right)\n\\]\nOn the other hand, from Proposition 1, we have:\n\\[\nL_t = \\frac{N_t / N_0}{M_t / M_0}\n\\]\nDifferentiating using Ito’s lemma, we have:\n\\[\n\\begin{aligned}\ndL_{t} & =\\frac{M_{0}}{N_{0}} d\\left(\\frac{N_{t}}{M_{t}}\\right)\\\\\n& =\\frac{M_{0}}{N_{0}}\\left( -\\frac{N_{t}}{M_{t}^{2}} dM_{t} +\\frac{1}{M_{t}} dN_{t} +\\frac{1}{2} \\cdot \\frac{2N_{t}}{M_{t}^{3}}( dM_{t})^{2} -\\frac{1}{M_{t}^{2}}( dM_{t} \\cdot dN_{t})\\right)\\\\\n&  \\begin{array}{l}\n=\\frac{M_{0}}{N_{0}}( -\\frac{N_{t}}{M_{t}^{2}}\\left( \\mu _{M}( t) dt+c_{M}( t) dW_{t}^{\\mathbb{Q}^{M}}\\right) +\\frac{1}{M_{t}}\\left( \\mu _{N}( t) dt+c_{N}( t) dW_{t}^{\\mathbb{Q}^{M}}\\right)\\\\\n+\\frac{N_{t}}{M_{t}^{3}} c_{M}^{2}( t) dt-\\frac{1}{M_{t}^{2}} c_{M}( t) c_{N}( t) dt\n\\end{array}\n\\end{aligned}\n\\]\nBut since \\(L_t\\) is driftless, we can ignore the \\(dt\\) terms (whatever they are, they are bound to cancel out) and only look at the diffusion coefficient. So, we can write:\n\\[\n\\begin{aligned}\ndL_{t} & =\\frac{M_{0}}{N_{0}}\\left( -\\frac{N_{t}}{M_{t}^{2}} c_{M}( t) +\\frac{1}{M_{t}} c_{N}( t)\\right) dW{_{t}^{\\mathbb{Q}}}^{M}\\\\\n& =\\frac{N_{t} /N_{0}}{M_{t} /M_{0}}\\left(\\frac{c_{N}( t)}{N_{t}} -\\frac{c_{M}( t)}{M_{t}}\\right) dW{_{t}^{\\mathbb{Q}}}^{M}\\\\\n& =L_{t}\\left(\\frac{c_{N}( t)}{N_{t}} -\\frac{c_{M}( t)}{M_{t}}\\right) dW{_{t}^{\\mathbb{Q}}}^{M}\n\\end{aligned}\n\\]\nComparing this, we can infer that:\n\\[\n\\theta_t = \\frac{c_N(t)}{N_t} - \\frac{c_M(t)}{M_t}\n\\]\nSince we can write:\n\\[\n\\begin{align*}\ndX_t = \\mu^{\\mathbb{P}}_X(t) dt + c_X(t)dW^{\\mathbb{P}}(t) &= \\mu^{\\mathbb{Q}}_X(t) + c_X(t)dW^{\\mathbb{Q}}(t)\\\\\ndW^{\\mathbb{P}}(t) &= \\frac{\\mu^{\\mathbb{Q}}_X(t) - \\mu^{\\mathbb{P}}_X(t)}{c_X(t)} + dW^{\\mathbb{Q}}(t)\n\\end{align*}\n\\tag{11}\\]\nUsing Equation 11, we conclude that the change of drift accompanying a change of numeraire is given by:\n\\[\n\\begin{align*}\n\\mu_X^{\\mathbb{Q}}(t) - \\mu_X^{\\mathbb{P}}(t) = c_X(t)\\left(\\frac{c_M(t)}{M(t)} - \\frac{c_N(t)}{N(t)}\\right)\n\\end{align*}\n\\tag{12}\\]"
  },
  {
    "objectID": "posts/fun-with-numeraires/index.html#examples-of-numeraires",
    "href": "posts/fun-with-numeraires/index.html#examples-of-numeraires",
    "title": "Fun with numeraires!",
    "section": "Examples of numeraires",
    "text": "Examples of numeraires\nThe basic component of an interest rate model is an instantaneous forward rate process \\(f(t,s)\\). Its value is the future instantaneous interest rate at a future time \\(s\\), that is the rate for the infinitesimally short term \\([s,s+ds]\\) observed at time \\(t \\leq s\\).\nA zero-coupon bond settling at time \\(T_0\\) and maturing at time \\(T &gt; T_0\\) is the process:\n\\[\nP(t,T_0,T) = \\exp\\left(-\\int_{T_0}^Tf(t,s)ds\\right)\n\\]\nfor \\(t \\leq T_0\\). In other words, it is the time \\(T_0\\) value of 1\\(\\$\\) (without the risk of default) at \\(T\\), as observed at time \\(t \\leq T_0\\). Its current value is given by:\n\nBank-account numeraire\nThe bank-account(money-market account) numeraire is simply the value of \\(1\\$\\) deposited in a bank and accruing the (credit-riskless) instantaneous interest rate. In reality, the bank credits interest to the account daily, but this can very well be approximated to a continous process. The associated stochastic price process \\(M(t)\\) is given by:\n\\[\n\\begin{align*}\nM(t) = \\exp(\\int_0^t r(s)ds)\n\\end{align*}\n\\]\nHere, the spot rate \\(r(t)\\) is the instantaneous forward observed at the time it settles. That is,\n\\[\nr(t) = f(t,t)\n\\]\n\n\nForward numeraire\nA zero-coupon bond(ZCB) is a simple contract with unit payoff \\(1\\$\\) at maturity \\(T\\). By the risk-neutral valuation formula:\n\\[\nP(t,t,T) = V(t) = M(t) \\mathbb{E}^{\\mathbb{Q}^M}\\left[\\frac{1}{M(T)}\\right]\n\\]\nSo, a \\(T\\)-maturity ZCB is a tradable asset and its price \\(P(t,T)\\) can be used as a numeraire. The associated measure is called the \\(T\\)-foward measure \\(\\mathbb{Q}^T\\).\nThe term(e.g. 3 months) forward rates for settlement at \\(T_0\\) and maturity at \\(T\\) are defined by the equation:\n\\[\n\\begin{align*}\nP(t,T_0,T) = \\frac{1}{1 + \\delta F(t,T_0,T)}\n\\end{align*}\n\\]\nwhere \\(\\delta\\) is the day-count fraction for the period \\([T_0,T]\\). Re-arranging, we have:\n\\[\n\\begin{align*}\nF(t,T_0,T) &= \\frac{1}{\\delta}\\frac{P(t,T,T) - P(t,T_0, T)}{P(t,T_0,T)}\nF(t,T_0,T)P(t,T_0,T) &= \\frac{1}{\\delta}(P(t,T,T) - P(t,T_0,T))\n\\end{align*}\n\\]\nClearly, it is a multiple of a difference \\(P(t,T,T)\\) and \\(P(t,T_0,T)\\) normalized by \\(T\\)-maturity zero coupon bond price \\(P(t,T_0,T)\\). So, the forward iBOR-rate must be a martingale under the \\(T\\)-forward measure \\(Q^T\\).\n\nProposition 2 (Forward rates are \\(\\mathbb{Q}^T\\) expectations of future spot rates.) Any simply compounded forward rate spanning a time interval ending in \\(T\\) is a martingale under the \\(T\\)-forward measure.\n\\[\n\\mathbb{E}^{\\mathbb{Q}^T}[F(t;S,T)|\\mathcal{F}_u] = F(u;S,T)\n\\]\nfor each \\(0 \\leq u \\leq t \\leq S &lt; T\\). In particular, the forward rate spanning the interval \\([S,T]\\) is the \\(\\mathbb{Q}^T\\) expectation of the future simply-compounded spot rate at time \\(S\\) for the maturity T.\n\\[\n\\mathbb{E}^{\\mathbb{Q}^T}[L(S,T)|\\mathcal{F}_t] = F(t;S,T)\n\\tag{13}\\]\n\n\nThe expected value of any future instantaneous spot interest rate, under the corresponding forward measure, is equal to the related instantaneuous forward rate. That is, \\[\n\\begin{align*}\n\\mathbb{E}^T{r_T|\\mathcal{F}_t} = f(t,T)\n\\end{align*}\n\\]\nfor each \\(0 \\leq t \\leq T\\).\n\nProof.\nWe have:\n\\[\n\\begin{align*}\n\\mathbb{E}^{\\mathbb{Q}^T} [r_T|\\mathcal{F}_t] &= \\frac{1}{P(t,T)}\\mathbb{E}\\left[r_TP(t,T)|\\mathcal{F}_t\\right]\\\\\n&= - \\frac{1}{P(t,T)}\\mathbb{E}\\left[r_Te^{-\\int_t^T r(s)ds}|\\mathcal{F}_t\\right]\\\\\n&= - \\frac{1}{P(t,T)}\\mathbb{E}\\left[\\frac{\\partial}{\\partial T}e^{-\\int_t^T r(s)ds}|\\mathcal{F}_t\\right]\\\\\n&= - \\frac{1}{P(t,T)}\\frac{\\partial}{\\partial T}\\mathbb{E}\\left[e^{-\\int_t^T r(s)ds}|\\mathcal{F}_t\\right]\\\\\n&= - \\frac{1}{P(t,T)}\\frac{\\partial}{\\partial T}P(t,T)\\\\\n&= f(t,T)\n\\end{align*}\n\\]\n\n\nPricing an IRS\nConsider a forward starting interest rate swap(IRS) which settles in \\(T_0\\) and matures in \\(T_N\\) years from now. An IRS is a transaction between two counterparties who exchange interest rate payments on an agreed notional principal.\nOn a vanilla swap, a fixed-coupon interest payments are exchanged for floating rate payments. For the sake of simplicity, we assume that the payment dates on the fixed and floating leg of the swap are the same, and that the floating rate is the same as the discounting rate. The former of these assumptions is a minor simplification, made to lighten up the notation only. The latter is an important simplification, as the basis between the floating rate and the discounting rate may exhibit a complex dynamics.\nLet \\(S\\) be the fixed-rate on the swap. By the risk-neutral valuation formula, the fixed leg value at time \\(t\\) can be expressed as:\n\\[\n\\begin{align*}\nV_{fixed}(t) &=   N \\cdot \\sum_{i=1}^N \\mathbb{E}^{\\mathbb{Q^M}}[e^{-r(T_i-t)}S \\tau(T_{i-1},T_i)|\\mathcal{F}_t]\\\\\n&=S \\cdot N \\cdot \\sum_{i=1}^N \\mathbb{E}^{\\mathbb{Q}}[e^{-r(T_i-t)}\\tau(T_{i-1},T_i)|\\mathcal{F}_t]\\\\\n&=S \\cdot N \\cdot \\left(\\sum_{i=1}^N P(t,T_i)\\tau(T_{i-1},T_i)\\right)\n\\end{align*}\n\\]\nThe floating leg can be written as:\n\\[\n\\begin{align*}\nV_{float}(t) & = N \\cdot \\sum_{i=1}^N P(t,T_i)\\mathbb{E}^{T_i}\\left[L(T,T_{i-1}, T_i)|\\mathcal{F}_t\\right]\\tau(T_{i-1},T_i)\\\\\n&=  N \\cdot \\sum_{i=1}^N P(t,T_i)L(t,T_{i-1}, T_i)\\tau(T_{i-1},T_i)\\\\\n&= N \\cdot \\sum_{i=1}^N P(t,T_i)\\frac{1}{\\tau(T_{i-1},T_i)}\\cdot\\left(\\frac{P(t,T_{i-1})}{P(t,T_{i})}-1\\right)\\tau(T_{i-1},T_i)\\\\\n&= N \\cdot \\sum_{i=1}^N (P(t,T_i) - P(t,T_{i-1}))\\\\\n&= -N P(t,T_0) + NP(t,T_N)\n\\end{align*}\n\\]\nwhere the expectations are under the \\(T_i\\)-forward measure. Note that, I used the fact that the iBOR-rates are martingales under the forward measure.\nThe par-swap rate \\(S\\) is the fixed-rate which renders the value of the swap zero at the contract start date \\(t\\).\n\\[\n\\begin{align*}\n-V_{fix} + V_{floating} &= 0\\\\\nS \\cdot N \\cdot \\left(\\sum_{i=1}^N P(t,T_i)\\tau(T_{i-1},T_i)\\right) &= -N P(t,T_0) + NP(t,T_N) \\\\\nS(t,T_{0:N}) &= \\frac{- P(t,T_0) + P(t,T_N)}{\\left(\\sum_{i=1}^N P(t,T_i)\\tau(T_{i-1},T_i)\\right)}\n\\end{align*}\n\\]\n\n\nThe Annuity Measure\nThe annuity is an asset that pays \\(1\\$\\) on each coupon payment day of the swap, accrued according to the swap’s day count convention.\n\\[\nA(t,T_{0:N}) = \\left( \\sum_{i=1}^N P(t,T_i)\\tau(T_{i-1},T_i) \\right)\n\\]\nSince, it is a portfolio of zero coupon bonds, it is a tradable asset and its price \\(A(t,T_{0:N})\\) can be used as numeraire. This is called the Annuity numeraire and the measure \\(\\mathbb{Q}^{T_{0:N}}\\) associated with this numeraire is called the (forward) swap measure. The annuity numeraire arises as the natural numeraire when valuing swaptions. It is the mechanism that allows us to link the swaption as an option on a swap to the option on the corresponding swap rate.\nThe forward swap rate \\(S(t,T_{0:N})\\) is a martingale in the annuity measure \\(\\mathbb{Q}^{T_{0:N}}\\)."
  },
  {
    "objectID": "posts/fun-with-numeraires/index.html#pricing-the-payoff-vt-s_ts_t---k",
    "href": "posts/fun-with-numeraires/index.html#pricing-the-payoff-vt-s_ts_t---k",
    "title": "Fun with numeraires!",
    "section": "Pricing the payoff \\(V(T) = [S_T(S_T - K)]^{+}\\)",
    "text": "Pricing the payoff \\(V(T) = [S_T(S_T - K)]^{+}\\)\nSell-side quant interviews are known to ask puzzles to price tricky payoffs like the power option \\(V_T=(S_T^2 - K)1_{S_T &gt; K}\\), exchange options \\(V_T = (S_2(T) - S_1(T))^{+}\\) and quantos.\nChange of numeraire and measure transformation provide an elegant way to price these payoffs quickly.\nSuppose, we want to price the following payoff:\n\\[\nV(T) = \\max( S(T)(S(T) - K), 0 )\n\\]\nBy the risk-neutral pricing formula,\n\\[\nV(t) = M(t) \\mathbf{E}^{Q}\\left[\\frac{S(T)}{M(T)}(S(T) - K)1_{S_T &gt; K}|\\mathcal{F}_t\\right]\n\\]\nThe Radon-Nikodym derivative \\(\\frac{dQ}{dQ^S}\\) is given by:\n\\[\nL(t) = \\frac{dQ}{dQ^S} = \\frac{M(T)/M(t)}{S(T)/S(t)} = \\frac{M(T)}{S(T)}\\cdot \\frac{S(t)}{M(t)}\n\\]\nConsequently, we can write:\n\\[\n\\begin{align*}\nV(t) &= M(t) \\mathbf{E}^{Q^S}\\left[\\frac{dQ}{dQ^S}\\cdot\\frac{S(T)}{M(T)}(S(T) - K)1_{S_T &gt; K}|\\mathcal{F}_t\\right]\\\\\n&= M(t) \\mathbf{E}^{Q^S}\\left[\\frac{M(T)}{S(T)}\\cdot \\frac{S(t)}{M(t)}\\cdot\\frac{S(T)}{M(T)}(S(T) - K)1_{S_T &gt; K}|\\mathcal{F}_t\\right]\\\\\n&= \\mathbf{E}^{Q^S}\\left[S(t)(S(T) - K)1_{S_T &gt; K}|\\mathcal{F}_t\\right]\\\\\n&= S(t)\\mathbf{E}^{Q^S}\\left[(S(T) - K)1_{S_T &gt; K}|\\mathcal{F}_t\\right]\n\\end{align*}\n\\tag{14}\\]\nThis looks much like the familiar European vanilla call option payoff, except that, the conditional expectation needs to be taken under the probability measure induced by the stock numeraire \\((S,Q^S)\\).\nTo find the dynamics of the stock price \\(S(t)\\) under the probability measure \\(Q^S\\), we use the intuitive fact, that, all normalized asset prices - the asset price \\(X(t)\\) deflated by the numeraire price \\(S(t)\\), \\(\\frac{X(t)}{S(t)}\\) must be martingales under \\(Q^S\\). Thus, the price process \\(M(t)/S(t)\\) must be a martingale.\nLet’s find the dynamics of the process \\(\\left(\\frac{M(t)}{S(t)}\\right)\\).\nConsider \\(f(x,y) = \\frac{x}{y}\\). We have:\n\\[\n\\begin{align*}\nf_x = \\frac{1}{y}, \\quad f_y = -\\frac{x}{y^2}\\\\\nf_{xx} = 0, \\quad f_{xy} = -\\frac{1}{y^2}, f_{yy} = \\frac{2x}{y^3}\n\\end{align*}\n\\]\nWe have:\n\\[\n\\begin{aligned}\nd\\left(\\frac{M_{t}}{S_{t}}\\right) & =\\frac{1}{S_{t}} dM( t) -\\frac{M_{t}}{S_{t}^{2}} dS( t)\\\\\n& -\\frac{1}{S_{t}^{2}} dM( t) \\cdotp dS( t) +\\frac{1}{2} \\cdot \\frac{2M_{t}}{S_{t}^{3}}( dS_{t})^{2}\\\\\n& =\\frac{1}{S_{t}} rM( t) dt-\\frac{M_{t}}{S_{t}^{2}}\\left( rdt+\\sigma dW^{\\boxed{Q}}( t)\\right)\\\\\n& +\\frac{M_{t}}{S_{t}^{3}} \\sigma ^{2} S_{t}^{2} dt\\\\\n& =\\left(\\frac{M_{t}}{S_{t}}\\right)\\left( rdt-rdt-\\sigma dW^{\\boxed{Q}}( t) +\\sigma ^{2} dt\\right)\\\\\n& =-\\sigma \\left(\\frac{M_{t}}{S_{t}}\\right)\\left( -\\sigma dt+dW^{\\boxed{Q}}( t)\\right)\n\\end{aligned}\n\\]\nBut, we know that the process \\((M_t/S_t)\\) is a \\(Q^S\\)-martingale and should be driftless. Thus, we should have:\n\\[\nd\\left(\\frac{M_t}{S_t}\\right) = -\\sigma \\left(\\frac{M_{t}}{S_{t}}\\right)(0 \\cdot dt + dW^{\\boxed{Q^S}}( t))\n\\]\nSo, we perform the measure transformation:\n\\[\ndW^{\\boxed{Q^S}}(t) = -\\sigma dt+dW^{\\boxed{Q}}(t)\n\\tag{15}\\]\nConsequently, \\(Q^S\\)-dynamics of the asset \\(S(t)\\) can be expressed as:\n\\[\n\\begin{align*}\ndS(t) &= rSdt + \\sigma S dW^{\\boxed{Q}}(t)\\\\\n&=rSdt + \\sigma S (dW^{\\boxed{Q^S}}(t) + \\sigma dt)\\\\\n&=(r+\\sigma^2)Sdt + \\sigma S dW^{\\boxed{Q^S}}(t)\n\\end{align*}\n\\]\nSo, \\(S(t)\\) is still a lognormal random variable and evolves according to:\n\\[\nS(T) = S(t)\\exp\\left[\\left(r+\\frac{\\sigma^2}{2}\\right)(T-t) + \\sigma (W^{\\boxed{Q^S}}(T) - W^{\\boxed{Q^S}}(t))\\right]\n\\tag{16}\\]\nThe price of the option would be given by:\n\\[\nV(t) = S(t)[S(t)\\Phi(d_{+}) - K\\Phi(d_{-})]\n\\]\nwhere\n\\[\n\\begin{align*}\nd_{+} &= \\frac{\\ln\\left(\\frac{S(t)}{K}\\right) + (r + \\frac{3\\sigma^2}{2})(T-t)}{\\sigma\\sqrt{T - t}}\\\\\nd_{-} &= \\frac{\\ln\\left(\\frac{S(t)}{K}\\right) + (r + \\frac{\\sigma^2}{2})(T-t)}{\\sigma\\sqrt{T - t}}\n\\end{align*}\n\\]"
  },
  {
    "objectID": "posts/fun-with-numeraires/index.html#pricing-the-payoff-vt-s_1t1_s_2t-k",
    "href": "posts/fun-with-numeraires/index.html#pricing-the-payoff-vt-s_1t1_s_2t-k",
    "title": "Fun with numeraires!",
    "section": "Pricing the payoff \\(V(T) = S_1(T)1_{S_2(T) > K}\\)",
    "text": "Pricing the payoff \\(V(T) = S_1(T)1_{S_2(T) &gt; K}\\)\nSuppose the dynamics of two assets \\(S_1(t)\\) and \\(S_2(t)\\) are given by:\n\\[\n\\begin{align*}\ndS_1(t) &= rS_1(t)dt + \\sigma_1 S_1 W_1^{Q}(t) \\\\\ndS_2(t) &= rS_2(t)dt + \\sigma_2 S_2 W_2^{Q}(t)\n\\end{align*}\n\\]\nAssume that the two driving brownian motions are correlated and their instantaneous correlation is given by:\n\\[\ndW_1^{Q}(t) dW_2^{Q}(t) = \\rho dt\n\\]\nBy the risk-neutral pricing formula, we have:\n\\[\nV(t) = M(t)\\mathbb{E}^{\\boxed{Q}}\\left[\\frac{S_1(T)}{M(T)}1_{S_2(T) &gt; K}\\right]\n\\]\nBy change of numeraire, we have:\n\\[\n\\begin{align*}\nV(t) &= M(t)\\mathbb{E}^{\\boxed{Q}}\\left[\\frac{S_1(T)}{M(T)}1_{S_2(T) &gt; K}\\right]\\\\\n&= M(t) \\mathbb{E}^{\\boxed{Q^{S_1}}}\\left[\\frac{dQ}{dQ^{S_1}}\\cdot \\frac{S_1(T)}{M(T)}1_{S_2(T) &gt; K}\\right]\\\\\n&= M(t) \\mathbb{E}^{\\boxed{Q^{S_1}}}\\left[\\frac{M(T)}{S_1(T)}\\cdot \\frac{S_1(t)}{M(t)}\\cdot \\frac{S_1(T)}{M(T)}1_{S_2(T) &gt; K}\\right]\\\\\n&= M(t) \\mathbb{E}^{\\boxed{Q^{S_1}}}\\left[\\frac{M(T)}{S_1(T)}\\cdot \\frac{S_1(t)}{M(t)}\\cdot \\frac{S_1(T)}{M(T)}1_{S_2(T) &gt; K}\\right]\\\\\n&=S_1(t)\\mathbb{E}^{\\boxed{Q^{S_1}}}[1_{S_2(T) &gt; K}]\\\\\n&=S_1(t)Q^{S_1}(S_2(T) &gt; K)\n\\end{align*}\n\\]\nThus, we need to derive the \\(Q^{S_1}\\)-dynamics of the asset \\(S_2\\). Under the \\(Q^{S_1}\\)-measure, \\(\\left(\\frac{S_2(t)}{S_1(t)}\\right)\\) must be a martingale.\nLet \\(f(x,y) = \\frac{y}{x}\\). We have:\n\\[\n\\begin{align*}\nf_x = -\\frac{y}{x^2}, \\quad f_y = \\frac{1}{x} \\\\\nf_{xx} = \\frac{2y}{x^3}, \\quad f_{xy} = -\\frac{1}{x^2}, \\quad f_{yy} = 0\n\\end{align*}\n\\]\nWe have:\n\\[\n\\begin{aligned}\nd\\left(\\frac{S_{2}( t)}{S_{1}( t)}\\right) & =-\\frac{S_{2}}{S_{1}^{2}} dS_{1}( t) +\\frac{1}{S_{1}} dS_{2}( t) +\\frac{1}{2}\\left(\\frac{2S_{2}}{S_{1}^{3}}\\right)( dS_{1}( t))^{2} -\\frac{1}{S_{1}^{2}} dS_{1}( t) \\cdot dS_{2}( t)\\\\\n& =-\\frac{S_{2}}{S_{1}^{2}}\\left( rS_{1}( t) dt+\\sigma _{1} S_{1} dW_{1}^{\\boxed{Q}}( t)\\right) +\\frac{1}{S_{1}}\\left( rS_{2}( t) dt+\\sigma _{2} S_{2} dW_{2}^{\\boxed{Q}}( t)\\right)\\\\\n& +\\frac{S_{2}}{S_{1}^{3}} \\sigma _{1}^{2} S_{1}^{2} dt-\\frac{1}{S_{1}^{2}} S_{1} S_{2} \\sigma _{1} \\sigma _{2} \\rho dt\\\\\n& =\\left(\\frac{S_{2}}{S_{1}}\\right)\\left( -rdt-\\sigma _{1} dW_{1}^{\\boxed{Q}}( t) +rdt+\\sigma _{2} dW_{2}^{\\boxed{Q}}( t) +\\sigma _{1}^{2} dt-\\rho \\sigma _{1} \\sigma _{2} dt\\right)\\\\\n& =\\left(\\frac{S_{2}}{S_{1}}\\right)\\left( \\sigma _{1}^{2} dt-\\rho \\sigma _{1} \\sigma _{2} dt-\\sigma _{1} dW_{1}^{\\boxed{Q}}( t) +\\sigma _{2} dW_{2}^{\\boxed{Q}}( t)\\right)\\\\\n& \\quad \\left\\{\\text{ Applying the measure transformation } dW_{1}^{\\boxed{Q}}( t) =dW_{1}^{\\boxed{Q^{S_{1}}}}( t) +\\sigma _{1} dt\\right\\}\\\\\n& =\\left(\\frac{S_{2}}{S_{1}}\\right)\\left( \\sigma _{1}^{2} dt-\\rho \\sigma _{1} \\sigma _{2} dt-\\sigma _{1}\\left( dW_{1}^{\\boxed{Q^{S_{1}}}}( t) +\\sigma _{1} dt\\right) +\\sigma _{2} dW_{2}^{\\boxed{Q}}( t)\\right)\\\\\n& =\\left(\\frac{S_{2}}{S_{1}}\\right)\\left( -\\rho \\sigma _{1} \\sigma _{2} dt-\\sigma _{1} dW_{1}^{\\boxed{Q^{S_{1}}}}( t) +\\sigma _{2} dW_{2}^{\\boxed{Q}}( t)\\right)\\\\\n& =\\left(\\frac{S_{2}}{S_{1}}\\right)\\left[\\left( -\\rho \\sigma _{1} \\sigma _{2} dt+\\sigma _{2} dW_{2}^{\\boxed{Q}}( t)\\right) -\\sigma _{1} dW_{1}^{\\boxed{Q^{S_{1}}}}( t)\\right]\\\\\n& =\\sigma _{2}\\left(\\frac{S_{2}}{S_{1}}\\right)\\left[\\left( -\\rho \\sigma _{1} dt+dW_{2}^{\\boxed{Q}}( t)\\right) -\\frac{\\sigma _{1}}{\\sigma _{2}} dW_{1}^{\\boxed{Q^{S_{1}}}}( t)\\right]\n\\end{aligned}\n\\]\nBut, we must have:\n\\[\nd\\left(\\frac{S_2}{S_1}\\right) = \\sigma_2 \\left(\\frac{S_2}{S_1}\\right) \\left[0 \\cdot dt  + dW_{2}^{\\boxed{Q^{S_1}}}(t) -\\frac{\\sigma_{1}}{\\sigma _{2}} dW_{1}^{\\boxed{Q^{S_{1}}}}( t)\\right]\n\\]\nThis suggests the measure transformation:\n\\[\ndW_2^{\\boxed{Q^{S_1}}}(t) =  -\\rho \\sigma _{1} dt + dW_{2}^{\\boxed{Q}}( t)\n\\]\nSo, finally, the model under the stock measure \\(Q^{S_1}\\) is given by:\n\\[\n\\begin{aligned}\ndS_1(t) &= (r + \\sigma_1^2) S_1 dt + \\sigma_1 S_1 dW_1^{\\boxed{Q^{S_1}}}(t)\\\\\ndS_2(t) &= (r +\\rho \\sigma_1) S_2 dt + \\sigma_2 S_2 dW_2^{\\boxed{Q^{S_1}}}(t)\\\\\ndM(t) &= r M(t) dt\n\\end{aligned}\n\\]\nThe evolution of the second asset can be expressed as:\n\\[\n\\begin{aligned}\nS_2(T) &= S_2(t) \\exp\\left[\\left(r + \\rho \\sigma_1 - \\frac{\\sigma_2^2}{2}\\right)(T-t) + \\sigma_2 (W_2^{\\boxed{Q^{S_1}}}(T) - W_2^{\\boxed{Q^{S_1}}}(t))\\right]\n\\end{aligned}\n\\]\nThe option payoff can be simplified as:\n\\[\n\\begin{aligned}\nV( t) & =S_{1}( t) Q^{\\boxed{S_{1}}}[ S_{2}( T)  &gt;K]\\\\\n& =S_{1}( t) Q^{\\boxed{S_{1}}}\\left[ S_{2}( t)\\exp\\left\\{\\left( r+\\rho \\sigma _{1} -\\frac{\\sigma _{2}^{2}}{2}\\right)( T-t) +\\sigma _{2}( W_{2}( T) -W_{2}( t))\\right\\}  &gt;K\\right]\\\\\n& =S_{1}( t) Q^{\\boxed{S_{1}}}\\left[ S_{2}( t)\\exp\\left\\{\\left( r+\\rho \\sigma _{1} -\\frac{\\sigma _{2}^{2}}{2}\\right)( T-t) -\\sigma _{2}\\sqrt{T-t} \\cdot Z\\right\\}  &gt;K\\right]\\\\\n& =S_{1}( t) Q^{\\boxed{S_{1}}}\\left[\\ln\\frac{S_{2}( t)}{K} +\\left( r+\\rho \\sigma _{1} -\\frac{\\sigma _{2}^{2}}{2}\\right)( T-t)  &gt;\\sigma _{2}\\sqrt{T-t} \\cdot Z\\right]\\\\\n& =S_{1}( t) Q^{\\boxed{S_{1}}}\\left[ Z&lt; \\frac{\\ln\\frac{S_{2}( t)}{K} +\\left( r+\\rho \\sigma _{1} -\\frac{\\sigma _{2}^{2}}{2}\\right)( T-t)}{\\sigma _{2}\\sqrt{T-t}}\\right]\\\\\n& =S_{1}( t) \\Phi \\left[\\frac{\\ln\\frac{S_{2}( t)}{K} +\\left( r+\\rho \\sigma _{1} -\\frac{\\sigma _{2}^{2}}{2}\\right)( T-t)}{\\sigma _{2}\\sqrt{T-t}}\\right]\n\\end{aligned}\n\\]"
  },
  {
    "objectID": "posts/fun-with-numeraires/index.html#pricing-an-assymetric-power-option-v_t-frac1k2k3---s_t3",
    "href": "posts/fun-with-numeraires/index.html#pricing-an-assymetric-power-option-v_t-frac1k2k3---s_t3",
    "title": "Fun with numeraires!",
    "section": "Pricing an assymetric power option \\(V_T = \\frac{1}{K^2}(K^3 - S_T^3)^{+}\\)",
    "text": "Pricing an assymetric power option \\(V_T = \\frac{1}{K^2}(K^3 - S_T^3)^{+}\\)"
  },
  {
    "objectID": "posts/fun-with-numeraires/index.html#references",
    "href": "posts/fun-with-numeraires/index.html#references",
    "title": "Fun with numeraires!",
    "section": "References",
    "text": "References\n\n\nGirsanov, Numeraires and all that, Andrew Lesniewski.\nInterest-rate Models - Theory and Practice, Damiano Brigo and Fabio Mercurio."
  },
  {
    "objectID": "posts/gaussian-discriminant-analysis/index.html",
    "href": "posts/gaussian-discriminant-analysis/index.html",
    "title": "Classification Algorithms",
    "section": "",
    "text": "Let’s say that you have input data \\(\\mathcal{D}=\\{(\\mathbf{x}_i,y_i): i=1,2,\\ldots,N\\}\\), and suppose that \\(y_i \\in \\{0,1\\}\\). Each input has \\(D\\)-features, so \\(\\mathbf{x}_i \\in \\mathbf{R}^D\\). You want to classify an arbitrary feature vector \\(\\mathbf{x}\\) into \\(y=0\\) or \\(y=1\\).\nOne way to build a classifier is to learn the joint probability distribution \\(p(\\mathbf{x},y)\\) and then to condition on \\(\\mathbf{x}\\), thereby deriving \\(p(y=c|\\mathbf{x})\\). This is called the generative approach. An alternative approach is to fit a model of the form \\(p(y|\\mathbf{x})\\) directly. This is called the discriminative approach."
  },
  {
    "objectID": "posts/gaussian-discriminant-analysis/index.html#discriminative-versus-generative-models",
    "href": "posts/gaussian-discriminant-analysis/index.html#discriminative-versus-generative-models",
    "title": "Classification Algorithms",
    "section": "",
    "text": "Let’s say that you have input data \\(\\mathcal{D}=\\{(\\mathbf{x}_i,y_i): i=1,2,\\ldots,N\\}\\), and suppose that \\(y_i \\in \\{0,1\\}\\). Each input has \\(D\\)-features, so \\(\\mathbf{x}_i \\in \\mathbf{R}^D\\). You want to classify an arbitrary feature vector \\(\\mathbf{x}\\) into \\(y=0\\) or \\(y=1\\).\nOne way to build a classifier is to learn the joint probability distribution \\(p(\\mathbf{x},y)\\) and then to condition on \\(\\mathbf{x}\\), thereby deriving \\(p(y=c|\\mathbf{x})\\). This is called the generative approach. An alternative approach is to fit a model of the form \\(p(y|\\mathbf{x})\\) directly. This is called the discriminative approach."
  },
  {
    "objectID": "posts/gaussian-discriminant-analysis/index.html#logistic-regression",
    "href": "posts/gaussian-discriminant-analysis/index.html#logistic-regression",
    "title": "Classification Algorithms",
    "section": "Logistic Regression",
    "text": "Logistic Regression\nThe sigmoid function \\(sigm(x)\\) is defined as:\n\\[\\begin{align*}\nsigm(x) = \\frac{e^x}{1+e^x} \\tag{1}\n\\end{align*}\\]\nThe logistic regression models the class posterior probability as:\n\\[\\begin{align*}\np(y=1|\\mathbf{x}) =sigm(\\mathbf{w}^T \\mathbf{x}) = \\frac{e^{\\mathbf{w}^T \\mathbf{x}}}{1 + e^{\\mathbf{w}^T \\mathbf{x}}} \\tag{2}\n\\end{align*}\\]\nRe-arranging, we can write:\n\\[\\begin{align*}\n\\frac{p(y=1|\\mathbf{x})}{1 - p(y=1|\\mathbf{x})} &= e^{\\mathbf{w}^T \\mathbf{x}}\\\\\n\\log \\left(\\frac{p(y=1|\\mathbf{x})}{1 - p(y=1|\\mathbf{x})}\\right) &= \\mathbf{w}^T \\mathbf{x} \\tag{3}\n\\end{align*}\\]\nThe quantity \\(\\frac{p(y=1|\\mathbf{x})}{1 - p(y=1|\\mathbf{x})}\\) is called the odds and can take on any value between \\(0\\) and \\(\\infty\\). Odds are traditionally used instead of probabilities to express chances of winning in horse-racing and casino games such as roulette.\nThe left-hand side is called log odds or logit. In the simplest case of \\(D=1\\) predictor, the equation (3) becomes:\n\\[\\begin{align*}\n\\log \\left(\\frac{p(y_i = 1|x_i,\\mathbf{w})}{1 - p(y_i = 1|x_i,\\mathbf{w})}\\right) &= w_0 + w_1 x_i \\tag{4}\n\\end{align*}\\]\n\nLikelihood\nThe likelihood of all the data is:\n\\[\\begin{align*}\nL(w_0,w_1) &= \\prod_{i=1}^{N} p(y_i|\\mathbf{x}_i) \\\\\n&= \\prod_{i=1}^{N} p(y_i=1|\\mathbf{x}_i)^{I(y_i=1)} p(y_i=0|\\mathbf{x}_i)^{I(y_i=0)} \\\\\n&= \\prod_{i=1}^{N} p(y_i=1|\\mathbf{x}_i)^{I(y_i=1)} \\cdot [1 - p(y_i=1|\\mathbf{x}_i)]^{I(y_i=0)} \\tag{5}\n\\end{align*}\\]\nWe seek estimates for \\(w_0\\) and \\(w_1\\), such that the predicted class probabilities \\(\\hat{p}(y_i = 1|x_i)\\) and \\(\\hat{p}(y_i = 0|x_i)\\) are as close as possible to the observed class labels. So, we try to maximize the likelihood function \\(L\\)."
  },
  {
    "objectID": "posts/gaussian-discriminant-analysis/index.html#linear-discriminant-analysis",
    "href": "posts/gaussian-discriminant-analysis/index.html#linear-discriminant-analysis",
    "title": "Classification Algorithms",
    "section": "Linear Discriminant Analysis",
    "text": "Linear Discriminant Analysis\nLet \\(c\\) be an arbitrary class label. By the Bayes formula,\n\\[\\begin{align*}\np(y=c|\\mathbf{x}) &= \\frac{p(\\mathbf{x},y=c)}{p(\\mathbf{x})} \\\\\n&= \\frac{p(\\mathbf{x}|y=c) \\cdot p(y=c)}{\\sum_{c=1}^{C} p(\\mathbf{x}|y=c) \\cdot p(y=c)} \\tag{6}\n\\end{align*}\\]\nThe LDA is a generative classifier that models the class conditional distribution \\(p(\\mathbf{x}|y=c)\\) and the class prior \\(p(y=c)\\) and applies the Bayes rule to derive \\(p(y=c|\\mathbf{x})\\).\nLDA makes the following assumptions:\n\nThe prior follows a Bernoulli distribution.\n\n\\[\\begin{align*}\np(y=y_i) = \\phi^{y_i} (1 - \\phi)^{(1-y_i)}\n\\end{align*}\\]\n\nThe data from class \\(c\\) is a \\(D\\)-dimensional multivariate gaussian distribution. We have:\n\n\\[\\begin{align*}\np(\\mathbf{x}|y=c) = \\mathcal{N}(\\mathbf{\\mu}_c,\\mathbf{\\Sigma}) \\tag{8}\n\\end{align*}\\]\nThus,\n\\[\\begin{align*}\np(\\mathbf{x}|y=c) &= \\frac{1}{(2\\pi)^{D/2} |\\det \\mathbf{\\Sigma}|^{1/2}} \\exp \\left[-\\frac{1}{2}(\\mathbf{x} - \\mathbf{\\mu}_c)^T \\mathbf{\\Sigma}^{-1}(\\mathbf{x} - \\mathbf{\\mu}_c) \\right] \\tag{9}\n\\end{align*}\\]\n\nLikelihood\nThe likelihood of all the data is:\n\\[\\begin{align*}\nL(\\phi,\\mathbf{\\mu}_1,\\ldots,\\mathbf{\\mu}_C,\\mathbf{\\Sigma}) &= \\prod_{i=1}^{N} p(\\mathbf{x}_i,y_i)\\\\\n&=\\prod_{i=1}^{N} p(\\mathbf{x}_i|y_i)\\cdot p(y=y_i) \\tag{10}\n\\end{align*}\\]\n\n\nLog-Likelihood\nThe log-likelihood function \\(l\\) is:\n\\[\\begin{align*}\nl(\\phi,\\mathbf{\\mu}_1,\\ldots,\\mathbf{\\mu}_C,\\mathbf{\\Sigma}) = \\log L &= \\sum_{i=1}^{N} \\log p(\\mathbf{x}_i|y_i) + \\sum_{i=1}^{N} \\log p(y=y_i) \\tag{11}\n\\end{align*}\\]\nFor simplicity let’s assume we have \\(C=2\\) classes. Then, the above sum can be written as:\n\\[\\begin{align*}\nl(\\phi,\\mathbf{\\mu}_0,\\mathbf{\\mu}_1,\\mathbf{\\Sigma}) &= \\sum_{i=1}^{N} I(y_i=1)\\log p(\\mathbf{x}_i|y=1) + \\sum_{i=1}^{N} I(y_i = 0)\\log p(\\mathbf{x}_i|y=0) \\\\ &+ \\sum_{i=1}^{N} I(y_i=1) \\log p(y=y_i) + \\sum_{i=1}^{N} I(y_i=0) \\log p(y=y_i) \\tag{12}\n\\end{align*}\\]\n\n\nMLE Estimate for \\(\\phi\\)\nThe first two terms of the log-likelihood function \\(l\\) are not a function of \\(\\phi\\). Taking the partial derivative of \\(l\\) with respect to \\(\\phi\\) on both sides, we are left with:\n\\[\\begin{align*}\n\\frac{\\partial l}{\\partial \\phi} &= \\frac{\\partial}{\\partial \\phi}\\left[\\sum_{i=1}^{N}I(y_i = 1) y_i\\log \\phi + \\sum_{i=1}^{N} I(y_i=0)(1-y_i)\\log(1-\\phi)\\right]\\\\\n&= \\sum_{i=1}^{N} I(y_i = 1) \\frac{y_i}{\\phi} + \\sum_{i=1}^{N} I(y_i=0) (1-y_i)\\frac{-1}{1-\\phi}\\\\\n&= \\sum_{i=1}^{N} I(y_i = 1) \\frac{1}{\\phi} - \\sum_{i=1}^{N} I(y_i=0) \\frac{1}{1-\\phi} \\tag{13}\n\\end{align*}\\]\nEquating \\(\\frac{\\partial l}{\\partial \\phi}\\) to zero:\n\\[\\begin{align*}\n\\sum_{i=1}^{N} I(y_i = 1) \\frac{1}{\\phi} &= \\sum_{i=1}^{N} I(y_i=0) \\frac{1}{1-\\phi}\\\\\n(1-\\phi)\\sum_{i=1}^{N} I(y_i = 1) &= \\phi\\sum_{i=1}^{N} I(y_i=0)\\\\\n\\sum_{i=1}^{N} I(y_i = 1) &= \\phi\\sum_{i=1}^{N} I(y_i=0) + \\phi\\sum_{i=1}^{N} I(y_i=1)\\\\\n\\sum_{i=1}^{N} I(y_i = 1) &= \\phi \\cdot N \\\\\n\\hat{\\phi} &= \\frac{\\sum_{i=1}^{N} I(y_i = 1)}{N} \\tag{14}\n\\end{align*}\\]\n\n\nMLE Estimate for \\(\\mu_c\\)\nFirst, note that:\n\\[\\begin{align*}\n\\log p(\\mathbf{x}_i|y=1) = -\\frac{D}{2}\\log(2\\pi) - \\frac{1}{2} \\log(|\\det \\mathbf{\\Sigma}|) - \\frac{1}{2}(\\mathbf{x}_i - \\mathbf{\\mu}_1)^T \\mathbf{\\Sigma}^{-1}(\\mathbf{x}_i - \\mathbf{\\mu}_1) \\tag{15}\n\\end{align*}\\]\nThus,\n\\[\\begin{align*}\n\\frac{\\partial l}{\\partial \\mu_1} &= -\\frac{1}{2}\\sum_{i=1}^{N} I(y_i = 1)\\frac{\\partial}{\\partial \\mu_1}[(\\mathbf{x}_i - \\mu_1)^T \\mathbf{\\Sigma}^{-1} (\\mathbf{x}_i - \\mu_1)] \\tag{16}\n\\end{align*}\\]\nWe know that, \\(\\frac{\\partial}{\\partial \\mathbf{x}}(\\mathbf{x}^T A \\mathbf{x}) = 2A \\mathbf{x}\\).\nConsequently,\n\\[\\begin{align*}\n\\frac{\\partial l}{\\partial \\mu_1} &= -\\mathbf{\\Sigma}^{-1}\\sum_{i=1}^{N} I(y_i = 1) (\\mathbf{x}_i - \\mu_1) \\tag{17}\n\\end{align*}\\]\nEquating \\(\\frac{\\partial l}{\\partial \\mu_1} = 0\\), we have:\n\\[\\begin{align*}\n\\hat{\\mu}_1 &= \\frac{\\sum_{i=1}^{N}I(y_i = 1) \\mathbf{x}_i}{\\sum_{i=1}^{N}I(y_i = 1)} \\tag{18}\n\\end{align*}\\]\nIn general, for a class \\(c\\), we have:\n\\[\\begin{align*}\n\\hat{\\mu}_c &= \\frac{\\sum_{i=1}^{N}I(y_i = c) \\mathbf{x}_i}{\\sum_{i=1}^{N}I(y_i = c)} \\tag{19}\n\\end{align*}\\]\n\n\nTraces and Determinants\nDefinition. The trace of a square matrix \\(A\\) is defined to the sum of the diagonal elements \\(a_{ii}\\) of \\(A\\)\n\\[\\begin{align*}\ntr(A) = \\sum_i a_{ii} \\tag{20}\n\\end{align*}\\]\nClaim. (Cyclic property) Let \\(A,B,C\\) be arbitrary matrices whose dimensions are conformal and are such that the product \\(ABC\\) (and therefore the other two products) is a square matrix. Then, the trace is invariant under cyclic permutations of matrix products:\n\\[\\begin{align*}\ntr(ABC) = tr(BCA) = tr(CAB) \\tag{21}\n\\end{align*}\\]\nProof.\nWe have:\n\\[\\begin{align*}\ntr(ABC) &= \\sum_{i} (ABC)_{ii} \\tag{22}\n\\end{align*}\\]\nThe \\((i,i)\\) element of \\(ABC\\) must be the inner product of the \\(i\\)-th row of \\(A\\) and the \\(i\\)-th column of \\(BC\\). So:\n\\[\\begin{align*}\ntr(ABC) &= \\sum_{i} \\sum_j A_{ij} (BC)_{ji} \\tag{23}\n\\end{align*}\\]\nThe \\((j,i)\\) element of \\(BC\\) must be the inner product of the \\(j\\)-th row of \\(B\\) and the \\(i\\)-th column of \\(C\\). So:\n\\[\\begin{align*}\ntr(ABC) &= \\sum_{i} \\sum_j A_{ij} \\sum_{k} B_{jk} C_{ki} \\\\\n&= \\sum_{i} \\sum_j \\sum_{k} A_{ij}  B_{jk} C_{ki} \\tag{24}\n\\end{align*}\\]\nBut, this can be re-written as\n\\[\\begin{align*}\ntr(ABC) &= \\sum_{i} \\sum_j \\sum_{k} A_{ij}  B_{jk} C_{ki} \\\\\n&= \\sum_j \\sum_k B_{jk} \\sum_i C_{ki} A_{ij} \\\\\n&= \\sum_j \\sum_k B_{jk} (CA)_{kj} \\\\\n&= \\sum_j (BCA)_{jj} \\\\\n&= tr(BCA) \\tag{25}\n\\end{align*}\\]\nSimilarly, it can be shown that \\(tr(BCA) = tr(CAB)\\). This closes the proof.\nClaim. Let \\(A\\) and \\(B\\) be matrices. Then,\n\\[\\begin{align*}\n\\frac{\\partial}{\\partial A} tr(BA) = B^T \\tag{26}\n\\end{align*}\\]\nProof.\nWe have:\n\\[\\begin{align*}\ntr(BA) &= \\sum_i (BA)_{ii} \\\\\n&= \\sum_i \\sum_j B_{ij} A_{ji}\n\\end{align*}\\]\nConsequently,\n\\[\\begin{align*}\n\\left[\\frac{\\partial}{\\partial A} tr(BA)\\right]_{(i,j)} = \\frac{\\partial}{\\partial a_{ij}} tr(BA) = B_{ji}\n\\end{align*}\\]\nThis closes the proof.\nClaim. Let \\(A\\) be a square matrix. Then:\n\\[\\begin{align*}\n\\frac{\\partial}{\\partial A} \\log (\\det A) = (A^{-1})^T \\tag{27}\n\\end{align*}\\]\nProof.\nRecall that:\n\\[\\begin{align*}\n\\det A = \\sum_{j} a_{ij} C_{ij}\n\\end{align*}\\]\nwhere \\(C_{ij}\\) is the cofactor obtained after removing the \\(i\\)-th row and \\(j\\)-th column of \\(A\\). Thus,\n\\[\\begin{align*}\n\\frac{\\partial}{\\partial a_{ij}}\\det A = C_{ij}\n\\end{align*}\\]\nConsequently,\n\\[\\begin{align*}\n\\frac{\\partial}{\\partial A}\\det A = C\n\\end{align*}\\]\nwhere \\(C\\) is the cofactor matrix of \\(A\\). We know that \\(C = (adj A)^T\\), where \\(adj A\\) is the adjugate of \\(A\\). Moreover, \\(A^{-1} = \\frac{1}{|\\det A|} adj (A)\\). Therefore,\n\\[\\begin{align*}\n\\frac{\\partial}{\\partial A} \\log (\\det A) &= \\frac{1}{|\\det A|} \\frac{\\partial}{\\partial A}\\det A \\\\\n&= \\frac{1}{|\\det A|} C \\\\\n&= \\frac{1}{|\\det A|} (adj A)^T \\\\\n&= \\left(\\frac{1}{|\\det A|} adj A\\right)^T \\\\\n&= (A^{-1})^T\n\\end{align*}\\]\n\n\nMLE Estimate for the covariance matrix \\(\\mathbf{\\Sigma}\\)\nSince \\(\\mathbf{x}^T A \\mathbf{x}\\) is a scalar, \\(\\mathbf{x}^T A \\mathbf{x} = tr(\\mathbf{x}^T A \\mathbf{x})\\). We have:\n\\[\\begin{align*}\n\\mathbf{x}^T A \\mathbf{x} &= tr(\\mathbf{x}^T A \\mathbf{x}) = tr(A \\mathbf{x} \\mathbf{x}^T) = tr(\\mathbf{x} \\mathbf{x}^T A)\n\\end{align*}\\]\nWe have:\n\\[\\begin{align*}\nl(\\phi,\\mu_c,\\mathbf{\\Sigma}) &= \\sum_{i=1}^{N} \\log p(\\mathbf{x}_i|y_i) + \\sum_{i=1}^{N} \\log p(y=y_i) \\\\\n&= -\\frac{ND}{2} \\log(2\\pi) - \\frac{N}{2} \\log(|\\det \\mathbf{\\Sigma}|) \\\\\n&- \\frac{1}{2}\\sum_{i=1}^{N} (\\mathbf{x}_i - \\mu_{y_i})^T \\mathbf{\\Sigma}^{-1} (\\mathbf{x}_i - \\mu_{y_i}) \\\\\n&+ \\sum_{i=1}^{N} \\log p(y=y_i)\\\\\n&= -\\frac{ND}{2} \\log(2\\pi) + \\frac{N}{2} \\log(|\\det \\mathbf{\\Sigma}^{-1}|) \\\\\n&- \\frac{1}{2}\\sum_{i=1}^{N} tr[(\\mathbf{x}_i - \\mu_{y_i}) (\\mathbf{x}_i - \\mu_{y_i})^T \\mathbf{\\Sigma}^{-1}]  \\\\\n&+ \\sum_{i=1}^{N} \\log p(y=y_i)\n\\end{align*}\\]\nDifferentiating both sides with respect to \\(\\mathbf{\\Sigma}^{-1}\\), get:\n\\[\\begin{align*}\n\\frac{\\partial l}{\\partial \\mathbf{\\Sigma}^{-1}} &= \\frac{N}{2} \\mathbf{\\Sigma} - \\frac{1}{2}\\sum_{i=1}^{N} (\\mathbf{x}_i - \\mu_{y_i}) (\\mathbf{x}_i - \\mu_{y_i})^T\n\\end{align*}\\]\nConsequently, we have:\n\\[\\begin{align*}\n\\hat{\\mathbf{\\Sigma}}_{mle} &= \\frac{1}{N} \\sum_{i=1}^{N} (\\mathbf{x}_i - \\mu_{y_i}) (\\mathbf{x}_i - \\mu_{y_i})^T \\tag{28}\n\\end{align*}\\]\n\n\nDecision boundary\nLet’s again consider the binary classification problem with \\(C=2\\) classes. The decision boundary is the line or the hyperplane that separates the part of the space where the probability that the point belongs to class \\(1\\) is larger than \\(50\\) percent from the part where the probability that the point belongs to class \\(2\\) is larger than \\(50\\) percent.\nThe decision boundary is given by \\(p(y=1|\\mathbf{x}) = p(y=0|\\mathbf{x})\\). Since these probabilities involve an exponent, it’s convenient to take logarithms on both sides. This results in:\n\\[\\begin{align*}\n\\cancel{-\\frac{D}{2}\\log(2\\pi)} - \\cancel{\\frac{1}{2} \\log(|\\det \\mathbf{\\Sigma}|)} - \\frac{1}{2}(\\mathbf{x} - \\mathbf{\\mu}_1)^T \\mathbf{\\Sigma}^{-1}(\\mathbf{x} - \\mathbf{\\mu}_1) = \\\\\n\\cancel{-\\frac{D}{2}\\log(2\\pi)} - \\cancel{\\frac{1}{2} \\log(|\\det \\mathbf{\\Sigma}|)} - \\frac{1}{2}(\\mathbf{x} - \\mathbf{\\mu}_0)^T \\mathbf{\\Sigma}^{-1}(\\mathbf{x} - \\mathbf{\\mu}_0) \\tag{29}\n\\end{align*}\\]\nSimplifying, we have:\n\\[\\begin{align*}\n(\\mathbf{x} - \\mathbf{\\mu}_1)^T \\mathbf{\\Sigma}^{-1}(\\mathbf{x} - \\mathbf{\\mu}_1) &= (\\mathbf{x} - \\mathbf{\\mu}_0)^T \\mathbf{\\Sigma}^{-1}(\\mathbf{x} - \\mathbf{\\mu}_0) \\tag{30}\n\\end{align*}\\]\n\\[\\begin{align*}\n(\\mathbf{x}^T - \\mathbf{\\mu}_1^T) \\mathbf{\\Sigma}^{-1}(\\mathbf{x} - \\mathbf{\\mu}_1) &= (\\mathbf{x}^T - \\mathbf{\\mu}_0^T) \\mathbf{\\Sigma}^{-1}(\\mathbf{x} - \\mathbf{\\mu}_0)\\\\\n\\cancel{\\mathbf{x}^T \\mathbf{\\Sigma}^{-1} \\mathbf{x}} - \\mathbf{x}^T \\mathbf{\\Sigma}^{-1}\\mathbf{\\mu}_1 - \\mathbf{\\mu}_1^T \\mathbf{\\Sigma}^{-1} \\mathbf{x} + \\mathbf{\\mu}_1^T \\mathbf{\\Sigma}^{-1} \\mathbf{\\mu}_1 &= \\cancel{\\mathbf{x}^T \\mathbf{\\Sigma}^{-1} \\mathbf{x}} - \\mathbf{x}^T \\mathbf{\\Sigma}^{-1}\\mathbf{\\mu}_0 - \\mathbf{\\mu}_0^T \\mathbf{\\Sigma}^{-1} \\mathbf{x} + \\mathbf{\\mu}_0^T \\mathbf{\\Sigma}^{-1} \\mathbf{\\mu}_0\n\\end{align*}\\]\nNote that, \\(\\mathbf{x}^T \\mathbf{\\Sigma}^{-1} (\\mu_1 - \\mu_0)\\) is a scalar, so \\(\\mathbf{x}^T \\mathbf{\\Sigma}^{-1} (\\mu_1 - \\mu_0) = (\\mathbf{x}^T \\mathbf{\\Sigma}^{-1} (\\mu_1 - \\mu_0))^T\\). So, we get:\n\\[\\begin{align*}\n2\\mathbf{x}^T \\mathbf{\\Sigma}^{-1} (\\mu_1 - \\mu_0) = \\underbrace{\\mu_1^T \\mathbf{\\Sigma}^{-1} \\mu_1 - \\mu_0^T \\mathbf{\\Sigma}^{-1} \\mu_0}_{\\text{constant}} \\tag{31}\n\\end{align*}\\]\nThis is the equation of the decision boundary. This is a linear projection of the vector \\(\\mathbf{x}\\) onto the \\(\\mathbf{\\Sigma}^{-1} (\\mu_1 - \\mu_0)\\) direction. Whenever this projection equals to this constant, we are on the decision boundary; when it’s larger than this threshold, it’s class \\(1\\) and when it’s smaller it’s class \\(2\\). So, the decision boundary is just a line perpendicular to this vector and crossing it in the point that corresponds to this threshold.\nTo make it clear, the fact that the decision boundary is linear follows from our assumption that the covariances are the same."
  },
  {
    "objectID": "posts/gaussian-discriminant-analysis/index.html#quadratic-discriminant-analysis-qda",
    "href": "posts/gaussian-discriminant-analysis/index.html#quadratic-discriminant-analysis-qda",
    "title": "Classification Algorithms",
    "section": "Quadratic Discriminant Analysis (QDA)",
    "text": "Quadratic Discriminant Analysis (QDA)\nLDA assumes that the data within each class \\(c\\) are drawn from a multivariate Gaussian distribution with a class-specific mean vector \\(\\mathbf{\\mu}_c\\) and a covariance matrix that common to all \\(C\\) classes. Quadratic Discriminant Analysis (QDA) classifier assumes that the observations from each class are drawn from a Gaussian distribution and each class has its own mean vector \\(\\mathbf{\\mu}_c\\) and covariance matrix \\(\\mathbf{\\Sigma}_c\\).\n\\[\\begin{align*}\np(y=c|\\mathbf{x}) = \\frac{1}{(2\\pi)^{D/2} |\\det \\mathbf{\\Sigma_c}|^{1/2}}\\exp\\left[-\\frac{1}{2}(\\mathbf{x} - \\mu_c)^T \\mathbf{\\Sigma}_c^{-1}(\\mathbf{x} - \\mu_c)\\right]\n\\end{align*}\\]"
  },
  {
    "objectID": "posts/implementing-vanna-volga/index.html",
    "href": "posts/implementing-vanna-volga/index.html",
    "title": "Implementing Vanna Volga",
    "section": "",
    "text": "It is possible to calculate analytically the values of vanillas or barrier options using the Black-Scholes model, however, they are far from quoted prices. This is because the BS-model is based on the assumption that the volatility \\(\\sigma\\) of the stock price process remains constant throughout the lifetime of the option.\nThe vanna-volga method also known as the trader’s rule of thumb is based on adding an analytical correction to the Black-Scholes price of the instrument. In this note, I derive and implement the original paper The vanna-volga method for implied volatilities, by Castagna and Mercurio."
  },
  {
    "objectID": "posts/implementing-vanna-volga/index.html#background.",
    "href": "posts/implementing-vanna-volga/index.html#background.",
    "title": "Implementing Vanna Volga",
    "section": "",
    "text": "It is possible to calculate analytically the values of vanillas or barrier options using the Black-Scholes model, however, they are far from quoted prices. This is because the BS-model is based on the assumption that the volatility \\(\\sigma\\) of the stock price process remains constant throughout the lifetime of the option.\nThe vanna-volga method also known as the trader’s rule of thumb is based on adding an analytical correction to the Black-Scholes price of the instrument. In this note, I derive and implement the original paper The vanna-volga method for implied volatilities, by Castagna and Mercurio."
  },
  {
    "objectID": "posts/implementing-vanna-volga/index.html#replicating-portfolio.",
    "href": "posts/implementing-vanna-volga/index.html#replicating-portfolio.",
    "title": "Implementing Vanna Volga",
    "section": "Replicating Portfolio.",
    "text": "Replicating Portfolio.\nConsider a Black-Scholes world with two assets : a locally risk free domestic bank account \\(B(t)\\) and a stock \\(S(t)\\). We assume that the volatility of the stock is stochastic, but strike-independent(flat). We have the asset dynamics:\n\\[\n\\begin{align*}\ndB_t &= r_{DOM}B_t dt \\\\\\\\\ndS_t &= \\mu S_t dt + \\sigma_t S_t dW_t\n\\end{align*}\n\\]\nOur aim is to value an arbitrary option contract \\(O=f(t,S_t,\\sigma_t;K)\\) with a strike \\(K\\). We price \\(O\\) using a standard hedging argument. We build a hedge aka replicating portfolio such that it zeroes out the greeks of our net position upto the second order.\nConsider a self-financing portfolio \\(\\Pi_t\\) consisting of:\n\nA long position in \\(1\\) unit of the option \\(O(t;K)\\).\nA short position in \\(\\Delta_t\\) units of the stock \\(S_t\\).\nShort positions in three European vanilla pivot options \\(C_i\\), \\(i \\in \\{1,2,3\\}\\). We short \\(x_i\\) units of \\(C_i\\). It is standard practice, to take \\(C_1,C_2,C_3\\) as a 25-delta put, an ATM call and a 25-delta call option respectively.\n\nThe pivot options have strikes \\(K_1 = K_{25P}\\), \\(K_2 = K_{ATM}\\) and \\(K_3 = K_{25C}\\) and implied volatility quotes (market prices) \\(\\sigma_1\\), \\(\\sigma_2\\) and \\(\\sigma_3\\) which are known to us.\nThe value of the portfolio at time \\(t\\) is:\n\\[\\Pi_t = O_t - \\Delta_t S_t - \\sum_{i=1}^{3} x_i C_t^i \\tag{1}\\]\nBy self-financing, I mean, there is no exogenous infusion or withdrawal of cash, once the portfolio has been setup at time zero. Therefore, the changes in the portfolio are solely due to gains/losses on the constituents. The self-financing condition is:\n\\[d\\Pi_t = dO_t - \\Delta_t dS_t - \\sum_{i=1}^{3} x_i dC_t^i \\tag{2}\\]\nBy Ito’s lemma, the differential of the option price \\(O_t\\) can be written as:\n\\[\n\\begin{align*}\ndO_t &= \\frac{\\partial O}{\\partial t} dt + \\frac{\\partial O}{\\partial S_t} dS_t + \\frac{\\partial O}{\\partial \\sigma_t} d\\sigma_t \\\\\\\\\n&+ \\frac{1}{2}\\frac{\\partial^2 O}{\\partial t^2} (dt)^2 \\\\\\\\\n&+ \\frac{1}{2}\\frac{\\partial^2 O}{\\partial S_t^2} (dS_t)^2 \\\\\\\\\n&+ \\frac{1}{2}\\frac{\\partial^2 O}{\\partial \\sigma_t^2} (d\\sigma_t)^2 \\\\\\\\\n&+ \\frac{\\partial^2 O}{\\partial t \\partial S_t} dt \\cdot dS_t \\\\\\\\\n&+ \\frac{\\partial^2 O}{\\partial S_t \\partial \\sigma_t} dS_t \\cdot d\\sigma_t \\\\\\\\\n&+ \\frac{\\partial^2 O}{\\partial t \\partial \\sigma_t} dt \\cdot d\\sigma_t \\tag{3}\n\\end{align*}\n\\]\nSince \\((dt)^2\\), \\(dt \\cdot dS_t\\), \\(dt \\cdot d\\sigma_t\\) are equal to zero, we can write:\n\\[\n\\begin{align*}\ndO_t &= \\frac{\\partial O}{\\partial t} dt + \\frac{\\partial O}{\\partial S_t} dS_t + \\frac{\\partial O}{\\partial \\sigma_t} d\\sigma_t \\\\\\\\\n&+ \\frac{1}{2}\\frac{\\partial^2 O}{\\partial S_t^2} (dS_t)^2 \\\\\\\\\n&+ \\frac{1}{2}\\frac{\\partial^2 O}{\\partial \\sigma_t^2} (d\\sigma_t)^2 \\\\\\\\\n&+ \\frac{\\partial^2 O}{\\partial S_t \\partial \\sigma_t} dS_t \\cdot d\\sigma_t  \\tag{4}\n\\end{align*}\n\\]\nSimilarly, we can apply Ito’s lemma to the European vanilla pivot options to find the differential \\(dC^i_t\\). Putting it together we have:\n\\[\n\\begin{align*}\nd\\Pi_t &= \\left(\\frac{\\partial O(t;K)}{\\partial t} - \\sum_{i=1}^{3}x_i\\frac{\\partial C^i(t;K_i)}{\\partial t} \\right) dt  \\\\\\\\\n&+ \\left(\\frac{\\partial O(t;K)}{\\partial S_t}  - \\Delta_t - \\sum_{i=1}^{3}x_i\\frac{\\partial C^i(t;K_i)}{\\partial S_t}\\right) dS_t \\\\\\\\\n&+ \\left(\\frac{\\partial O(t;K)}{\\partial \\sigma_t} - \\sum_{i=1}^{3}x_i\\frac{\\partial C^i(t;K_i)}{\\partial \\sigma_t} \\right)d\\sigma_t\\\\\\\\\n&+ \\frac{1}{2}\\left(\\frac{\\partial^2 O(t;K)}{\\partial S_t^2} - \\sum_{i=1}^{3}x_i\\frac{\\partial^2 C^i(t;K_i)}{\\partial S_t^2}\\right)(dS_t)^2 \\\\\\\\\n&+ \\frac{1}{2}\\left(\\frac{\\partial^2 O(t;K)}{\\partial \\sigma_t^2}  - \\sum_{i=1}^{3}x_i\\frac{\\partial^2 C^i(t;K_i)}{\\partial \\sigma_t^2} \\right)(d\\sigma_t)^2 \\\\\\\\\n&+ \\left(\\frac{\\partial^2 O(t;K)}{\\partial S_t \\partial \\sigma_t} - \\sum_{i=1}^{3}x_i\\frac{\\partial^2 C^i(t;K_i)}{\\partial S_t \\partial \\sigma_t}\\right)  dS_t \\cdot d\\sigma_t  \\tag{5}\n\\end{align*}\n\\]\nWe claim that we can choose the weights \\(\\Delta_t\\) and \\(\\mathbf{x}=(x_1,x_2,x_3)\\) of the replicating portfolio, such that the coefficient of the terms \\(dS_t\\), \\(d\\sigma_t\\), \\((d\\sigma_t)^2\\) and \\(dS_t \\cdot d\\sigma_t\\) are zeroed out.\nWe are therefore left with:\n\\[\n\\begin{align*}\nd\\Pi_t &= \\left(\\frac{\\partial O}{\\partial t} - \\sum_{i=1}^{3}x_i\\frac{\\partial C^i_t}{\\partial t} \\right) dt \\\\\\\\\n&+ \\frac{1}{2}\\left(\\frac{\\partial^2 O}{\\partial S_t^2} - \\sum_{i=1}^{3}x_i\\frac{\\partial^2 C^i_t}{\\partial S_t^2}\\right)\\sigma_t^2 S_t^2 dt \\tag{6}\n\\end{align*}\n\\]\nThe portfolio value process has no driving Brownian motion \\(dW_t\\) term, and hence the source of randomness has been eliminated. Therefore, \\(\\Pi_t\\) must be a locally risk-free portfolio. That is, it satisfies:\n\\[d\\Pi_t = r_{DOM}\\Pi_t dt \\tag{7}\\]"
  },
  {
    "objectID": "posts/implementing-vanna-volga/index.html#calculating-the-vv-weights",
    "href": "posts/implementing-vanna-volga/index.html#calculating-the-vv-weights",
    "title": "Implementing Vanna Volga",
    "section": "Calculating the VV weights",
    "text": "Calculating the VV weights\nWe assume hereafter, that the constant BS volatility is the at-the-money one; \\(\\sigma = \\sigma_2 = \\sigma_{ATM}\\). We assume \\(t=0\\), so we can drop the argument \\(t\\) in the call prices \\(C_i(t;K)\\) in equation (5). The weights \\(\\mathbf{x}=(x_1,x_2,x_3)\\) are determined by solving the system of equations \\(A\\mathbf{x}=\\mathbf{b}\\) where:\n\\[\nA = \\begin{bmatrix}\n\\frac{\\partial C_1(K_1)}{\\partial \\sigma_t} & \\frac{\\partial C_1(K_2)}{\\partial \\sigma_t} &  \\frac{\\partial C_3(K_3)}{\\partial \\sigma_t} \\\\\\\\\n\\frac{\\partial^2 C_1(K_1)}{\\partial S_t \\partial \\sigma_t} & \\frac{\\partial^2 C_2(K_2)}{\\partial S_t \\partial \\sigma_t} & \\frac{\\partial^2 C_3(K_3)}{\\partial S_t \\partial \\sigma_t}\\\\\\\\\n\\frac{\\partial^2 C_1(K_1)}{\\partial \\sigma_t^2} & \\frac{\\partial^2 C_2(K_2)}{\\partial \\sigma_t^2} & \\frac{\\partial^2 C_3(K_3)}{\\partial \\sigma_t^2}\n\\end{bmatrix}, \\quad\n\\mathbf{b} = \\begin{bmatrix}\n\\frac{\\partial O(K)}{\\partial \\sigma_t} \\\\\\\\\n\\frac{\\partial^2 O(K)}{\\partial S_t \\partial \\sigma_t} \\\\\\\\\n\\frac{\\partial^2 O(K)}{\\partial \\sigma_t^2}\n\\end{bmatrix}\n\\]\nThe entries in the first, second and third rows of \\(A\\) and \\(\\mathbf{b}\\) are the option vega, the option vanna and the option volga.\nI derived the expressions for option vega, vanna and volga here. They are:\n\\[\n\\begin{align*}\n\\text{Vega} &= S_0 e^{-r_{FOR}T} \\phi(d_{+}) \\sqrt{T} \\\\\\\\\n\\text{Vanna} &= -e^{-r_{FOR}T} \\phi(d_{+})\\frac{d_{-}}{\\sigma}\\\\\\\\\n\\text{Volga} &= S_0 e^{-r_{FOR}T}\\sqrt{T}\\phi(d_{+}) \\frac{d_{+}d_{-}}{\\sigma}\n\\end{align*}\n\\]\nWe can re-phrase the other greeks in terms of vega \\(\\mathcal{V}\\). Recall, that \\(d_{+}\\) varies with the option strike \\(K\\), so all other things equal, we can write \\(\\mathcal{V} = \\mathcal{V}(K)\\).\n\\[\n\\begin{align*}\n\\text{Vanna} &= -\\frac{d_{-}}{\\sigma S_0 \\sqrt{T}} \\mathcal{V}(K)\\\\\\\\\n\\text{Volga} &= \\frac{d_{+}d_{-}}{\\sigma} \\mathcal{V}(K)\n\\end{align*}\n\\]\nThe augmented matrix \\([A | b]\\), therefore is:\n\\[\n\\begin{bmatrix}\n\\mathcal{V}(K_1) & \\mathcal{V}(K_2) &  \\mathcal{V}(K_3) & | & \\mathcal{V}(K)\\\\\\\\\n-\\frac{d_{-}(K_1)}{\\sigma S_0 \\sqrt{T}}\\mathcal{V}(K_1) & -\\frac{d_{-}(K_2)}{\\sigma S_0 \\sqrt{T}}\\mathcal{V}(K_2) & -\\frac{d_{-}(K_3)}{\\sigma S_0 \\sqrt{T}}\\mathcal{V}(K_3) & | &\\frac{d_{-}(K)}{\\sigma S_0 \\sqrt{T}}\\mathcal{V}(K)\\\\\\\\\n\\frac{d_{+}(K_1) d_{-}(K_1)}{\\sigma}\\mathcal{V}(K_1) & \\frac{d_{+}(K_2) d_{-}(K_2)}{\\sigma}\\mathcal{V}(K_2) & \\frac{d_{+}(K_3) d_{-}(K_3)}{\\sigma}\\mathcal{V}(K_3) & | & \\frac{d_{+}(K) d_{-}(K)}{\\sigma}\\mathcal{V}(K)\n\\end{bmatrix}\n\\]\nCancelling out the constant terms, we get:\n\\[\n\\begin{bmatrix}\n\\mathcal{V}(K_1) & \\mathcal{V}(K_2) &  \\mathcal{V}(K_3) & | & \\mathcal{V}(K)\\\\\\\\\nd_{-}(K_1)\\mathcal{V}(K_1) & d_{-}(K_2)\\mathcal{V}(K_2) & d_{-}(K_3)\\mathcal{V}(K_3) & | & d_{-}(K)\\mathcal{V}(K)\\\\\\\\\nd_{+}(K_1) d_{-}(K_1)\\mathcal{V}(K_1) & d_{+}(K_2) d_{-}(K_2)\\mathcal{V}(K_2) & d_{+}(K_3) d_{-}(K_3)\\mathcal{V}(K_3) & | & d_{+}(K) d_{-}(K)\\mathcal{V}(K)\n\\end{bmatrix}\n\\]\nPerforming the elementary row operation \\(R_3 \\leftarrow R_3 - d_{+}(K_1) R_2\\), we get:\n\\[\n\\begin{bmatrix}\n\\mathcal{V}(K_1) & \\mathcal{V}(K_2) &  \\mathcal{V}(K_3) & | & \\mathcal{V}(K)\\\\\\\\\nd_{-}(K_1)\\mathcal{V}(K_1) & d_{-}(K_2)\\mathcal{V}(K_2) & d_{-}(K_3)\\mathcal{V}(K_3) & | & d_{-}(K)\\mathcal{V}(K)\\\\\\\\\n0 & \\log\\frac{K_2}{K_1} d_{-}(K_2)\\mathcal{V}(K_2) & \\log \\frac{K_3}{K_1} d_{-}(K_3)\\mathcal{V}(K_3) & | & \\log \\frac{K}{K_1} d_{-}(K)\\mathcal{V}(K)\n\\end{bmatrix}\n\\]\nPerforming the elementary row operation \\(R_2 \\leftarrow R_2 - d_{-}(K_1)R_1\\), we get:\n\\[\n\\begin{bmatrix}\n\\mathcal{V}(K_1) & \\mathcal{V}(K_2) &  \\mathcal{V}(K_3) & | & \\mathcal{V}(K)\\\\\\\\\n0 & \\log\\frac{K_2}{K_1}\\mathcal{V}(K_2) & \\log \\frac{K_3}{K_1}\\mathcal{V}(K_3) & | & \\log \\frac{K}{K_1}\\mathcal{V}(K)\\\\\\\\\n0 & \\log\\frac{K_2}{K_1} d_{-}(K_2)\\mathcal{V}(K_2) & \\log \\frac{K_3}{K_1} d_{-}(K_3)\\mathcal{V}(K_3) & | & \\log \\frac{K}{K_1} d_{-}(K)\\mathcal{V}(K)\n\\end{bmatrix}\n\\]\nPerforming the elementary row operation \\(R_3 \\leftarrow R_3 - d_{-}(K_2) R_2\\), we get:\n\\[\n\\begin{bmatrix}\n\\mathcal{V}(K_1) & \\mathcal{V}(K_2) &  \\mathcal{V}(K_3) & | & \\mathcal{V}(K)\\\\\\\\\n0 & \\log\\frac{K_2}{K_1}\\mathcal{V}(K_2) & \\log \\frac{K_3}{K_1}\\mathcal{V}(K_3) & | & \\log \\frac{K}{K_1}\\mathcal{V}(K)\\\\\\\\\n0 & 0 & \\log \\frac{K_3}{K_1} \\frac{K_3}{K_2}\\mathcal{V}(K_3) & | & \\log \\frac{K}{K_1} \\log \\frac{K}{K_2}\\mathcal{V}(K)\n\\end{bmatrix}\n\\]\nPerforming the elementary row operation \\(R_1 \\leftarrow \\log(K_2/K_1) R_1 - R_2\\), we get:\n\\[\n\\begin{bmatrix}\n\\log \\frac{K_2}{K_1}\\mathcal{V}(K_1) & 0 & - \\log \\frac{K_3}{K_2}\\mathcal{V}(K_3) & | & -\\log \\frac{K}{K_2}\\mathcal{V}(K)\\\\\\\\\n0 & \\log\\frac{K_2}{K_1}\\mathcal{V}(K_2) & \\log \\frac{K_3}{K_1}\\mathcal{V}(K_3) & | & \\log \\frac{K}{K_1}\\mathcal{V}(K)\\\\\\\\\n0 & 0 & \\log \\frac{K_3}{K_1} \\log \\frac{K_3}{K_2}\\mathcal{V}(K_3) & | & \\log \\frac{K}{K_1} \\log \\frac{K}{K_2}\\mathcal{V}(K)\n\\end{bmatrix}\n\\]\nPerforming the elementary row operation \\(R_1 \\leftarrow \\log(K_3/K_1)R_1 + R_3\\), we get:\n\\[\n\\begin{bmatrix}\n\\log \\frac{K_3}{K_1}\\log \\frac{K_2}{K_1}\\mathcal{V}(K_1) & 0 & 0 & | & \\log \\frac{K}{K_3}\\log \\frac{K}{K_2}\\mathcal{V}(K)\\\\\\\\\n0 & \\log\\frac{K_2}{K_1}\\mathcal{V}(K_2) & \\log \\frac{K_3}{K_1}\\mathcal{V}(K_3) & | & \\log \\frac{K}{K_1}\\mathcal{V}(K)\\\\\\\\\n0 & 0 & \\log \\frac{K_3}{K_1} \\log \\frac{K_3}{K_2}\\mathcal{V}(K_3) & | & \\log \\frac{K}{K_1} \\log \\frac{K}{K_2}\\mathcal{V}(K)\n\\end{bmatrix}\n\\]\nPerforming the elementary row operation \\(R_2 \\leftarrow \\log(K_3/K_2) R_2 - R_3\\), we get:\n\\[\n\\begin{bmatrix}\n\\log \\frac{K_3}{K_1}\\log \\frac{K_2}{K_1}\\mathcal{V}(K_1) & 0 & 0 & | & \\log \\frac{K}{K_3}\\log \\frac{K}{K_2}\\mathcal{V}(K)\\\\\\\\\n0 & \\log\\frac{K_2}{K_1} \\log \\frac{K_3}{K_2}\\mathcal{V}(K_2) & 0 & | & \\log \\frac{K}{K_1} \\log \\frac{K_3}{K}\\mathcal{V}(K)\\\\\\\\\n0 & 0 & \\log \\frac{K_3}{K_1} \\log \\frac{K_3}{K_2}\\mathcal{V}(K_3) & | & \\log \\frac{K}{K_1} \\log \\frac{K}{K_2}\\mathcal{V}(K)\n\\end{bmatrix}\n\\]\nThus, the solution vector \\(\\mathbf{x}\\) is:\n\\[\n\\begin{align*}\nx_1(K) &= \\frac{\\log \\frac{K_3}{K}\\log \\frac{K_2}{K}\\mathcal{V}(K)}{\\log \\frac{K_3}{K_1}\\log \\frac{K_2}{K_1}\\mathcal{V}(K_1)}\\\\\\\\\nx_2(K) &= \\frac{\\log \\frac{K}{K_1} \\log \\frac{K_3}{K}\\mathcal{V}(K)}{\\log\\frac{K_2}{K_1} \\log \\frac{K_3}{K_2}\\mathcal{V}(K_2)}\\\\\\\\\nx_3(K) &= \\frac{\\log \\frac{K}{K_1} \\log \\frac{K}{K_2}\\mathcal{V}(K)}{\\log \\frac{K_3}{K_1} \\log \\frac{K_3}{K_2}\\mathcal{V}(K_3)} \\tag{9}\n\\end{align*}\n\\]"
  },
  {
    "objectID": "posts/implementing-vanna-volga/index.html#the-vv-option-price.",
    "href": "posts/implementing-vanna-volga/index.html#the-vv-option-price.",
    "title": "Implementing Vanna Volga",
    "section": "The VV Option price.",
    "text": "The VV Option price.\nWe can now proceed to the definition of an option price that is consistent with the market prices of the basic options. The above replication argument shows that a portfolio comprising of \\(x_i(K)\\) units of the option with strike \\(K_i\\) and \\(\\Delta_0\\) units of the underlying gives a local perfect hedge in a Black-Scholes world. The hedging strategy has to be implemented at prevailing market prices, which generates an extra cost with respect to the Black-Scholes value of the options portfolio. Such a cost has to be added to the Black-Scholes price \\(O^{BS}(K)\\), with \\(t=0\\), to produce an arbitrage free price which is consistent with the quoted option prices \\(C_1^{MKT}(K_1)\\), \\(C_2^{MKT}(K_2)\\) and \\(C_3^{MKT}(K_3)\\).\nIn fact, in the case of a short-maturity \\(T\\), the equation (7) can be written as:\n\\[\n\\begin{align*}\n&((S\\_T - K)^{+} - O^{BS}(K)) - \\Delta\\_0(S\\_T - S\\_0)\\\\\\\\\n-& \\sum_{i=1}^{3} x_i(K) (C_i^{MKT}(K_i) - C_i^{BS}(K_i))\\\\\\\\\n&= r_{DOM} (O^{BS}(K) - \\Delta_0 S_0 - \\sum_{i=1}^{3} x_i(K_i)C_i^{BS}(K_i))T \\tag{10}\n\\end{align*}\\]\nTherefore, setting\n\\[O_{VV}^{MKT}(K) = O^{BS}(K) + \\sum_{i=1}^{3}x_i(K)(C_i^{MKT}(K_i) - C_i^{BS}(K_i))\\tag{11}\\]\nWe get:\n\\[\n\\begin{align*}\n(S_T - K)^{+} &= O^{MKT}_{VV}(K) + \\Delta_0(S_T - S_0) \\\\\\\\\n&+ r_{DOM} (O^{BS}(K) - \\Delta_0 S_0 - \\sum_{i=1}^{3} x_i(K)C_i^{BS}(K_i))T \\tag{12}\n\\end{align*}\\]\nThus, when actual market prices are considered, the option payout \\((S_T-K)^{+}\\) can still be replicated by starting with an initial capital of \\(O_{VV}^{MKT}(K)\\), buying \\(\\Delta_0\\) units of the stock and \\(x_i(K)\\) units of the pivot options with strike \\(K_i\\), and investing the rest at the cash rate \\(r_{DOM}\\).\nHence, implicitly ignoring the replication error over longer maturities, the price of the option must the initial capital required to setup the hedge portfolio \\(O_{VV}^{MKT}(K)\\).\nThe option premium \\(O_{VV}^{MKT}(K)\\) equals the Black-Scholes price of the option \\(O^{BS}(K)\\) plus a vanna-volga correction term, or overhedge \\(O_{VV}\\), which is the difference between the market quoted prices of the pivot options and the Black-Scholes prices of the pivot options under the constant BS volatility \\(\\sigma = \\sigma_{ATM}\\)."
  },
  {
    "objectID": "posts/implementing-vanna-volga/index.html#deriving-the-implied-volatility-smile.",
    "href": "posts/implementing-vanna-volga/index.html#deriving-the-implied-volatility-smile.",
    "title": "Implementing Vanna Volga",
    "section": "Deriving the implied volatility smile.",
    "text": "Deriving the implied volatility smile.\nWe can now derive an easy approximation for the vanna-volga implied volatility smile curve \\(\\xi(K)\\).\nIn formula (11), we Taylor expand the market quotes \\(C_1^{MKT}(K_1)\\), \\(C_2^{MKT}(K_2)\\), \\(C_3^{MKT}(K_3)\\) and \\(O^{MKT}_{VV}(K)\\), about \\(\\sigma = \\sigma_{2}\\). We have:\n\\[\n\\begin{align*}\nC_i^{MKT}(\\sigma_i,K_i) &= C_i^{BS}(\\sigma,K_i)+ \\frac{\\partial C_i^{BS}(\\sigma,K_i)}{\\partial \\sigma}(\\sigma_i - \\sigma)\\\\\\\\\nO_{VV}^{MKT}(\\xi(K),K) &= O^{BS}(\\sigma,K)+ \\frac{\\partial O^{BS}(\\sigma,K)}{\\partial \\sigma}(\\xi(K) - \\sigma) \\tag{13}\n\\end{align*}\n\\]\nEquivalently,\n\\[\n\\begin{align*}\nC_i^{MKT}(\\sigma_i,K_i) - C_i^{BS}(\\sigma,K_i) &= \\mathcal{V}(K_i)(\\sigma_i - \\sigma)\\\\\\\\\nO_{VV}^{MKT}(\\xi(K),K) - O^{BS}(\\sigma,K) &= \\mathcal{V}(K)(\\xi(K) - \\sigma) \\tag{14}\n\\end{align*}\n\\]\nSubstituting (13) and (14) in formula (11), we get:\n\\[\n\\begin{align*}\n\\mathcal{V}(K)(\\xi(K) - \\sigma) &= \\sum_{i=1}^{3} x_i(K) \\mathcal{V}(K_i)(\\sigma_i - \\sigma)\n\\end{align*}\n\\]\nSince \\(\\sigma_2 = \\sigma\\), the second term in the summation vanishes. Simplifying, we have:\n\\[\n\\begin{align*}\n\\mathcal{V}(K)(\\xi(K) - \\sigma_2) &= x_1(K)\\mathcal{V}(K_1)(\\sigma_1 - \\sigma_2) + x_3(K)\\mathcal{V}(K_3)(\\sigma_3 - \\sigma_2)\\\\\\\\\n\\xi(K) - \\sigma_2 &=  x_1(K)\\frac{\\mathcal{V}(K_1)}{\\mathcal{V}(K)}(\\sigma_1 - \\sigma_2) +  x_3(K)\\frac{\\mathcal{V}(K_3)}{\\mathcal{V}(K)}(\\sigma_3 - \\sigma_2)\\\\\\\\\n\\xi(K) &= \\frac{\\log \\frac{K_3}{K}\\log \\frac{K_2}{K}}{\\log \\frac{K_3}{K_1}\\log \\frac{K_2}{K_1}} \\sigma_1 + \\frac{\\log \\frac{K}{K_1} \\log \\frac{K}{K_2}}{\\log \\frac{K_3}{K_1} \\log \\frac{K_3}{K_2}}\\sigma_3 \\\\\\\\\n&+ \\left(1 - x_1(K)\\frac{\\mathcal{V}(K_1)}{\\mathcal{V}(K)} - x_3(K)\\frac{\\mathcal{V}(K_3)}{\\mathcal{V}(K)} \\right)\\sigma_2 \\tag{15}\n\\end{align*}\n\\]\nBut, we know from the matrix system \\(A\\mathbf{x}=b\\), that the weights \\(\\mathbf{x}=(x_1,x_2,x_3)\\) satisfy:\n\\[x_1(K) \\mathcal{V}(K_1) + x_2(K) \\mathcal{V}(K_2) + x_3(K) \\mathcal{V}(K_3) = \\mathcal{V}(K) \\tag{16}\\]\nSo,\n\\[\n\\begin{align*}\n\\left(1 - x_1(K)\\frac{\\mathcal{V}(K_1)}{\\mathcal{V}(K)} - x_3(K)\\frac{\\mathcal{V}(K_3)}{\\mathcal{V}(K)} \\right) &= x_2(K) \\frac{\\mathcal{V}(K_2)}{\\mathcal{V}(K)}\\\\\\\\\n&=\\frac{\\log \\frac{K}{K_1} \\log \\frac{K_3}{K}}{\\log\\frac{K_2}{K_1} \\log \\frac{K_3}{K_2}} \\tag{17}\n\\end{align*}\n\\]\nSubstituting (17) in the expression (15), we have the result:\n\\[\n\\xi^{1}(K) := \\xi(K) = \\frac{\\log \\frac{K_3}{K}\\log \\frac{K_2}{K}}{\\log \\frac{K_3}{K_1}\\log \\frac{K_2}{K_1}} \\sigma_1 + \\frac{\\log \\frac{K}{K_1} \\log \\frac{K}{K_2}}{\\log \\frac{K_3}{K_1} \\log \\frac{K_3}{K_2}}\\sigma_3 + \\frac{\\log \\frac{K}{K_1} \\log \\frac{K_2}{K_1}}{\\log \\frac{K_2}{K_1} \\log \\frac{K_3}{K_2}} \\tag{18}\n\\]\nThe VV-implied volatility smile \\(\\xi(K)\\) is thus approximated by a linear combination of the implied vol quotes \\(\\sigma_1\\), \\(\\sigma_2\\) and \\(\\sigma_3\\) of the vanilla pivot options with coefficients that add up to \\(1\\). This approximation is extremely accurate in the interval \\(\\[K_1,K_3\\]\\). The wings, however, tend to be overvalued."
  },
  {
    "objectID": "posts/implementing-vanna-volga/index.html#a-second-order-approximation-for-vv-smile.",
    "href": "posts/implementing-vanna-volga/index.html#a-second-order-approximation-for-vv-smile.",
    "title": "Implementing Vanna Volga",
    "section": "A second order approximation for VV-smile.",
    "text": "A second order approximation for VV-smile.\nLet’s Taylor expand the market quotes \\(C_i^{MKT}(\\sigma_i,K_i)\\) and \\(O_{VV}^{MKT}(\\xi(K),K)\\) upto the second order.\n\\[\n\\begin{align*}\nC_i^{MKT}(\\sigma_i,K_i) - C_i^{BS}(\\sigma,K_i) &= \\frac{\\partial C_i^{BS}(\\sigma,K_i)}{\\partial \\sigma}(\\sigma_i - \\sigma) + \\frac{1}{2}\\frac{\\partial^2 C_i^{BS}(\\sigma,K_i)}{\\partial \\sigma^2}(\\sigma_i - \\sigma)^2 \\\\\\\\\nO^{MKT}_{VV}(\\xi(K),K) - O^{BS}(\\sigma,K) &= \\frac{\\partial O^{BS}(\\sigma,K)}{\\partial \\sigma}(\\xi(K) - \\sigma) + \\frac{1}{2}\\frac{\\partial^2 O^{BS}(\\sigma,K)}{\\partial \\sigma^2}(\\xi(K) - \\sigma)^2 \\tag{19}\n\\end{align*}\n\\]\nEquivalently,\n\\[\n\\begin{align*}\nC_i^{MKT}(\\sigma_i,K_i) - C_i^{BS}(\\sigma,K_i) &= \\mathcal{V}(K_i)(\\sigma_i - \\sigma) + \\frac{1}{2}\\frac{d_{+}(K_i)d_{-}(K_i)}{\\sigma}\\mathcal{V}(K_i)(\\sigma_i - \\sigma)^2 \\\\\\\\\nO^{MKT}_{VV}(\\xi(K),K) - O^{BS}(\\sigma,K) &= \\mathcal{V}(K)(\\xi(K) - \\sigma) + \\frac{1}{2}\\frac{d\\_{+}(K) d\\_{-}(K)}{\\sigma}\\mathcal{V}(K)(\\xi(K) - \\sigma)^2 \\tag{20}\n\\end{align*}\n\\]\nSubstituting (20) in formula (11):\n\\[\n\\mathcal{V}(K)(\\xi(K) - \\sigma) + \\frac{1}{2}\\frac{d\\_{+}(K)d\\_{-}(K)}{\\sigma}\\mathcal{V}(K)(\\xi(K) - \\sigma)^2 \\\\\\\\\n= x\\_1\\mathcal{V}(K\\_1)(\\sigma\\_1 - \\sigma) + \\frac{1}{2}x\\_1\\frac{d\\_{+}(K\\_1)d\\_{-}(K\\_1)}{\\sigma}\\mathcal{V}(K\\_1)(\\sigma\\_1 - \\sigma)^2\\\\\\\\\n+(\\sigma\\_3 - \\sigma) + \\frac{1}{2}x\\_3\\frac{d\\_{+}(K\\_3)d\\_{-}(K\\_3)}{\\sigma}\\mathcal{V}(K\\_3)(\\sigma\\_3 - \\sigma)^2 \\tag{21}\n\\]\nSimplifying we have:\n\\[\n\\begin{align*}\n&(\\xi(K) - \\sigma_2) + \\frac{1}{2}\\frac{d_{+}(K)d_{-}(K)}{\\sigma}(\\xi(K) - \\sigma_2)^2 \\\\\\\\\n=& \\frac{\\log \\frac{K_3}{K}\\log \\frac{K_2}{K}}{\\log \\frac{K_3}{K_1}\\log \\frac{K_2}{K_1}}(\\sigma_1 - \\sigma_2) + \\frac{1}{2}\\frac{d_{+}(K_1)d_{-}(K_1)}{\\sigma}\\frac{\\log \\frac{K_3}{K}\\log \\frac{K_2}{K}}{\\log \\frac{K_3}{K_1}\\log \\frac{K_2}{K_1}}(\\sigma_1 - \\sigma_2)^2\\\\\\\\\n+& \\frac{\\log \\frac{K}{K_1} \\log \\frac{K}{K_2}}{\\log \\frac{K_3}{K_1} \\log \\frac{K_3}{K_2}}(\\sigma_3 - \\sigma_2) + \\frac{1}{2}\\frac{d_{+}(K_3)d_{-}(K_3)}{\\sigma}\\frac{\\log \\frac{K}{K_1} \\log \\frac{K}{K_2}}{\\log \\frac{K_3}{K_1} \\log \\frac{K_3}{K_2}}(\\sigma_3 - \\sigma_2)^2\n\\end{align*}\\tag{22}\n\\]\nLet\n\\[\n\\begin{align*}\nD_1(K) &:= \\frac{\\log \\frac{K_3}{K}\\log \\frac{K_2}{K}}{\\log \\frac{K_3}{K_1}\\log \\frac{K_2}{K_1}}(\\sigma_1 - \\sigma_2) + \\frac{\\log \\frac{K}{K_1} \\log \\frac{K}{K_2}}{\\log \\frac{K_3}{K_1} \\log \\frac{K_3}{K_2}}(\\sigma_3 - \\sigma_2)\\\\\\\\\n&= \\xi^1(K) - \\sigma_2 \\tag{23}\n\\end{align*}\n\\]\nand\n\\[\n\\begin{align*}\nD_2(K) &:= d_{+}(K_1)d_{-}(K_1)\\frac{\\log \\frac{K_3}{K}\\log \\frac{K_2}{K}}{\\log \\frac{K_3}{K_1}\\log \\frac{K_2}{K_1}}(\\sigma_1 - \\sigma_2)^2 \\\\\\\\\n&+ d_{+}(K_3)d_{-}(K_3)\\frac{\\log \\frac{K}{K_1} \\log \\frac{K}{K_2}}{\\log \\frac{K_3}{K_1} \\log \\frac{K_3}{K_2}}(\\sigma_3 - \\sigma_2)^2 \\tag{24}\n\\end{align*}\n\\]\nSubstituting (23) and (24) in equation (22), we get:\n\\[(\\xi(K) - \\sigma_2) + \\frac{d_{+}(K)d_{-}(K)}{2\\sigma_2}(\\xi(K) - \\sigma_2)^2 = D_1(K) + \\frac{D_2(K)}{2\\sigma_2}\\tag{25}\\]\nMultiplying throughout by \\(2\\sigma_2\\), we get:\n\\[2\\sigma_2(\\xi(K) - \\sigma_2) + d_{+}(K)d_{-}(K)(\\xi(K) - \\sigma_2)^2 = 2\\sigma_2 D_1(K) + D_2(K)\\tag{26}\\]\nSolving for \\(\\xi(K) - \\sigma_2\\), we have:\n\\[\n\\begin{align*}\n\\xi(K) - \\sigma_2 &= \\frac{-2\\sigma_2 \\pm \\sqrt{4\\sigma_2^2-4d_{+}(K)d_{-}(K)(2\\sigma_2 D_1(K) + D_2(K))}}{2d_{+}(K)d_{-}(K)}\\\\\\\\\n\\xi^2(K) := \\xi(K) &=\\sigma_2 + \\frac{-\\sigma_2 \\pm \\sqrt{\\sigma_2^2-d_{+}(K)d_{-}(K)(2\\sigma_2 D_1(K) + D_2(K))}}{d_{+}(K)d_{-}(K)} \\tag{27}\n\\end{align*}\n\\]"
  },
  {
    "objectID": "posts/irs_caps_floors_and_swaptions/index.html",
    "href": "posts/irs_caps_floors_and_swaptions/index.html",
    "title": "IRS, Caps, Floors and Swaptions",
    "section": "",
    "text": "I review here a few basic definitions relevant to the interest-rate world.\n\nDefinition 1 (Zero-coupon bond.) A \\(T\\)-maturity zero-coupon bond (pure discount bond) is a contract that guarantees its holder the payment of \\(1\\$\\) at time \\(T\\), with no intermediate payments. The contract value at time \\(t &lt; T\\) is denoted by \\(P(t,T)\\). Clearly, \\(P(T,T) = 1\\) \\(\\forall T\\in[0,\\infty)\\).\n\n\nDefinition 2 (Continuously-compounded spot interest rate.) The continuously-compounded spot interest rate prevailing at time \\(t\\) for the maturity \\(T\\) is denoted by \\(R(t,T)\\) and is the constant rate at which an investment of \\(P(t,T)\\) units of currency at time \\(t\\) accrues continuously to yield a unit amount of currency at maturity \\(T\\).\n\\[\n\\begin{align*}\nR(t,T) := - \\frac{\\ln P(t,T)}{\\tau(t,T)}\n\\end{align*}\n\\tag{1}\\]\nThe continuously-compounded interest rate is therefore a constant rate that is consistent with the zero-coupon-bond prices such that:\n\\[\n\\begin{align*}\ne^{R(t,T)\\tau(t,T)}P(t,T) = 1\n\\end{align*}\n\\tag{2}\\]\nfrom which we can express the bond price in terms of the continuously compounded rate \\(R\\):\n\\[\n\\begin{align*}\nP(t,T) = e^{-R(t,T)\\tau(t,T)}\n\\end{align*}\n\\tag{3}\\]\n\n\nDefinition 3 (Simply-compounded spot interest rate.) The simply-compounded spot interest rate prevailing at time \\(t\\) for the maturity \\(T\\) is denoted \\(L(t,T)\\) and is the constant rate at which an investment has to be made to produce an amount of one unit of currency at maturity, starting from \\(P(t,T)\\) units of currency at time \\(t\\), when accruing occurs proportionally to the investment time.\n\\[\n\\begin{align*}\nP(t,T)(1 + L(t,T)\\tau(t,T)) = 1\n\\end{align*}\n\\tag{4}\\]\nSo, the bond price can be expressed in terms of \\(L\\) as:\n\\[\n\\begin{align*}\nP(t,T) = \\frac{1}{1 + L(t,T)\\tau(t,T)}\n\\end{align*}\n\\tag{5}\\]\n\n\nDefinition 4 (Annually-compounded spot interest rate.) The annually-compounded spot interest rate prevailing at time \\(t\\) for the maturity \\(T\\) is denoted by \\(Y(t,T)\\) and is the constant (annualized) rate at which an investment has to be made to produce an amount of one unit of currency at maturity, starting from \\(P(t,T)\\) units of currency at time \\(t\\), reinvesting the obtained amounts once a year. We have:\n\\[\nP(t,T)(1+Y(t,T))^{\\tau(t,T)} = 1\n\\tag{6}\\]\n\nEquivalently,\n\\[\nY(t,T) = \\left[\\frac{1}{P(t,T)}\\right]^{\\frac{1}{\\tau(t,T)}} - 1\n\\tag{7}\\]\n\nDefinition 5 (Zero-coupon curve.) The zero-coupon curve(sometimes also referred to as the yield curve) at time \\(t\\) is the graph of the function\n\\[\nT \\mapsto \\begin{cases}\nL(t,T) & t &lt; T \\leq t + 1 \\text{ years }\\\\\nY(t,T) & T \\geq t + 1\\text{ years }\n\\end{cases}\n\\tag{8}\\]\n\n\nDefinition 6 (Discounting Curve.) The discounting curve at time \\(t\\) is the plot of the function:\n\\[\nT \\mapsto P(t,T), \\quad T &gt; t\n\\tag{9}\\]\nSuch a curve is also referred to as the term structure of discount factors.\n\n\nDefinition 7 (Simply-compounded forward interest rate.) The simply compounded forward interest rate prevailing at time \\(t\\) for the expiry \\(T &gt; t\\), maturity \\(S &gt; T\\) and is defined by:\n\\[\n\\begin{align*}\nF(t;T,S) := \\frac{1}{\\tau(T,S)}\\left(\\frac{P(t,T)}{P(t,S)} - 1\\right)\n\\end{align*}\n\\tag{10}\\]\n\n\nDefinition 8 (Instantaneous forward rate.) The instantaneous forward interest rate prevailing at time \\(t\\) for the maturity \\(T &gt; t\\) is denoted by \\(f(t,T)\\) and is defined by:\n\\[\n\\begin{align*}\nf(t,T) &= \\lim_{S \\to T^+} F(t;T,S) \\\\\n&= \\lim_{S \\to T^+} \\frac{1}{\\tau(T,S)}\\frac{P(t,T) - P(t,S)}{P(t,T)} \\\\\n&= -\\frac{1}{P(t,T)}\\lim_{S \\to T^+} \\frac{P(t,S) - P(t,T)}{\\tau(T,S)}\\\\\n&= -\\frac{1}{P(t,T)}\\lim_{h\\to 0} \\frac{P(t,T+h) - P(t,T)}{h}\\\\\n&= -\\frac{1}{P(t,T)} \\frac{\\partial}{T}(P(t,T))\\\\\n&= - \\frac{\\partial}{\\partial T}(\\ln P(t,T))\n\\end{align*}\n\\tag{11}\\]\nso we also have:\n\\[\nP(t,T) = \\exp\\left(-\\int_{t}^T f(t,u)du\\right)\n\\tag{12}\\]\n\n\n\n\nLet’s start with the classical LIBOR rate model. Suppose that bank B enters into a contract at time \\(t\\) with bank A, to borrow 1 EUR at time \\(T_0\\) and return 1 EUR plus the interest cost at time \\(T_1\\). What’s the fair interest rate, that bank A and bank B can agree on? The MTM value to bank A is:\n\\[\n\\begin{align*}\nV(t) &= P(t,T_0) \\mathbb{E}^{T_0}[-1|\\mathcal{F}_t] + P(t,T_1)\\mathbb{E}^{T_1}[1+\\tau K|\\mathcal{F}_t]\\\\\n0 &= -P(t,T_0) + P(t,T_1)(1+\\tau K)\n\\end{align*}\n\\]\nwhere \\(\\tau=\\tau(T_0,T_1)\\) is the day-count fraction between \\([T_0,T_1]\\)\n\n\n\nThe fair rate for an interbank lending deal with trade date \\(t\\), starting date \\(T_0\\) (typically 0d or 2d after \\(T\\)) and maturity date \\(T_1\\) is:\n\\[\n\\begin{align*}\nL(t;T_0,T_1) = \\frac{1}{\\tau}\\left[\\frac{P(t,T_0)}{P(t,T_1) - 1}\\right]\n\\end{align*}\n\\]\nPanel banks submit daily estimates for interbank lending rates to the calculation agent. The relevant periods \\([T_0,T_1]\\) considered are \\(1m\\), \\(3m\\), \\(6m\\) and \\(12m\\). LIBOR rate fixings used to be the most important reference rates for interest rate derivatives. Nowadays, overnight rates have become the key reference rates."
  },
  {
    "objectID": "posts/irs_caps_floors_and_swaptions/index.html#fundamentals",
    "href": "posts/irs_caps_floors_and_swaptions/index.html#fundamentals",
    "title": "IRS, Caps, Floors and Swaptions",
    "section": "",
    "text": "I review here a few basic definitions relevant to the interest-rate world.\n\nDefinition 1 (Zero-coupon bond.) A \\(T\\)-maturity zero-coupon bond (pure discount bond) is a contract that guarantees its holder the payment of \\(1\\$\\) at time \\(T\\), with no intermediate payments. The contract value at time \\(t &lt; T\\) is denoted by \\(P(t,T)\\). Clearly, \\(P(T,T) = 1\\) \\(\\forall T\\in[0,\\infty)\\).\n\n\nDefinition 2 (Continuously-compounded spot interest rate.) The continuously-compounded spot interest rate prevailing at time \\(t\\) for the maturity \\(T\\) is denoted by \\(R(t,T)\\) and is the constant rate at which an investment of \\(P(t,T)\\) units of currency at time \\(t\\) accrues continuously to yield a unit amount of currency at maturity \\(T\\).\n\\[\n\\begin{align*}\nR(t,T) := - \\frac{\\ln P(t,T)}{\\tau(t,T)}\n\\end{align*}\n\\tag{1}\\]\nThe continuously-compounded interest rate is therefore a constant rate that is consistent with the zero-coupon-bond prices such that:\n\\[\n\\begin{align*}\ne^{R(t,T)\\tau(t,T)}P(t,T) = 1\n\\end{align*}\n\\tag{2}\\]\nfrom which we can express the bond price in terms of the continuously compounded rate \\(R\\):\n\\[\n\\begin{align*}\nP(t,T) = e^{-R(t,T)\\tau(t,T)}\n\\end{align*}\n\\tag{3}\\]\n\n\nDefinition 3 (Simply-compounded spot interest rate.) The simply-compounded spot interest rate prevailing at time \\(t\\) for the maturity \\(T\\) is denoted \\(L(t,T)\\) and is the constant rate at which an investment has to be made to produce an amount of one unit of currency at maturity, starting from \\(P(t,T)\\) units of currency at time \\(t\\), when accruing occurs proportionally to the investment time.\n\\[\n\\begin{align*}\nP(t,T)(1 + L(t,T)\\tau(t,T)) = 1\n\\end{align*}\n\\tag{4}\\]\nSo, the bond price can be expressed in terms of \\(L\\) as:\n\\[\n\\begin{align*}\nP(t,T) = \\frac{1}{1 + L(t,T)\\tau(t,T)}\n\\end{align*}\n\\tag{5}\\]\n\n\nDefinition 4 (Annually-compounded spot interest rate.) The annually-compounded spot interest rate prevailing at time \\(t\\) for the maturity \\(T\\) is denoted by \\(Y(t,T)\\) and is the constant (annualized) rate at which an investment has to be made to produce an amount of one unit of currency at maturity, starting from \\(P(t,T)\\) units of currency at time \\(t\\), reinvesting the obtained amounts once a year. We have:\n\\[\nP(t,T)(1+Y(t,T))^{\\tau(t,T)} = 1\n\\tag{6}\\]\n\nEquivalently,\n\\[\nY(t,T) = \\left[\\frac{1}{P(t,T)}\\right]^{\\frac{1}{\\tau(t,T)}} - 1\n\\tag{7}\\]\n\nDefinition 5 (Zero-coupon curve.) The zero-coupon curve(sometimes also referred to as the yield curve) at time \\(t\\) is the graph of the function\n\\[\nT \\mapsto \\begin{cases}\nL(t,T) & t &lt; T \\leq t + 1 \\text{ years }\\\\\nY(t,T) & T \\geq t + 1\\text{ years }\n\\end{cases}\n\\tag{8}\\]\n\n\nDefinition 6 (Discounting Curve.) The discounting curve at time \\(t\\) is the plot of the function:\n\\[\nT \\mapsto P(t,T), \\quad T &gt; t\n\\tag{9}\\]\nSuch a curve is also referred to as the term structure of discount factors.\n\n\nDefinition 7 (Simply-compounded forward interest rate.) The simply compounded forward interest rate prevailing at time \\(t\\) for the expiry \\(T &gt; t\\), maturity \\(S &gt; T\\) and is defined by:\n\\[\n\\begin{align*}\nF(t;T,S) := \\frac{1}{\\tau(T,S)}\\left(\\frac{P(t,T)}{P(t,S)} - 1\\right)\n\\end{align*}\n\\tag{10}\\]\n\n\nDefinition 8 (Instantaneous forward rate.) The instantaneous forward interest rate prevailing at time \\(t\\) for the maturity \\(T &gt; t\\) is denoted by \\(f(t,T)\\) and is defined by:\n\\[\n\\begin{align*}\nf(t,T) &= \\lim_{S \\to T^+} F(t;T,S) \\\\\n&= \\lim_{S \\to T^+} \\frac{1}{\\tau(T,S)}\\frac{P(t,T) - P(t,S)}{P(t,T)} \\\\\n&= -\\frac{1}{P(t,T)}\\lim_{S \\to T^+} \\frac{P(t,S) - P(t,T)}{\\tau(T,S)}\\\\\n&= -\\frac{1}{P(t,T)}\\lim_{h\\to 0} \\frac{P(t,T+h) - P(t,T)}{h}\\\\\n&= -\\frac{1}{P(t,T)} \\frac{\\partial}{T}(P(t,T))\\\\\n&= - \\frac{\\partial}{\\partial T}(\\ln P(t,T))\n\\end{align*}\n\\tag{11}\\]\nso we also have:\n\\[\nP(t,T) = \\exp\\left(-\\int_{t}^T f(t,u)du\\right)\n\\tag{12}\\]"
  },
  {
    "objectID": "posts/irs_caps_floors_and_swaptions/index.html#classical-libor-rate-model",
    "href": "posts/irs_caps_floors_and_swaptions/index.html#classical-libor-rate-model",
    "title": "IRS, Caps, Floors and Swaptions",
    "section": "",
    "text": "Let’s start with the classical LIBOR rate model. Suppose that bank B enters into a contract at time \\(t\\) with bank A, to borrow 1 EUR at time \\(T_0\\) and return 1 EUR plus the interest cost at time \\(T_1\\). What’s the fair interest rate, that bank A and bank B can agree on? The MTM value to bank A is:\n\\[\n\\begin{align*}\nV(t) &= P(t,T_0) \\mathbb{E}^{T_0}[-1|\\mathcal{F}_t] + P(t,T_1)\\mathbb{E}^{T_1}[1+\\tau K|\\mathcal{F}_t]\\\\\n0 &= -P(t,T_0) + P(t,T_1)(1+\\tau K)\n\\end{align*}\n\\]\nwhere \\(\\tau=\\tau(T_0,T_1)\\) is the day-count fraction between \\([T_0,T_1]\\)"
  },
  {
    "objectID": "posts/irs_caps_floors_and_swaptions/index.html#spot-libor-rate",
    "href": "posts/irs_caps_floors_and_swaptions/index.html#spot-libor-rate",
    "title": "IRS, Caps, Floors and Swaptions",
    "section": "",
    "text": "The fair rate for an interbank lending deal with trade date \\(t\\), starting date \\(T_0\\) (typically 0d or 2d after \\(T\\)) and maturity date \\(T_1\\) is:\n\\[\n\\begin{align*}\nL(t;T_0,T_1) = \\frac{1}{\\tau}\\left[\\frac{P(t,T_0)}{P(t,T_1) - 1}\\right]\n\\end{align*}\n\\]\nPanel banks submit daily estimates for interbank lending rates to the calculation agent. The relevant periods \\([T_0,T_1]\\) considered are \\(1m\\), \\(3m\\), \\(6m\\) and \\(12m\\). LIBOR rate fixings used to be the most important reference rates for interest rate derivatives. Nowadays, overnight rates have become the key reference rates."
  },
  {
    "objectID": "posts/ito_calculus/index.html",
    "href": "posts/ito_calculus/index.html",
    "title": "Ito Calculus",
    "section": "",
    "text": "Exercise 1 (A strange martingale) Let \\((B_t,t\\geq 0)\\) be a standard Brownian motion. Consider the process:\n\\[\nM_t = \\frac{1}{\\sqrt{1-t}}\\exp\\left(\\frac{-B_t^2}{2(1-t)}\\right), \\quad \\text{ for }0 \\leq t &lt; 1\n\\]\n\nShow that \\(M_t\\) can be represented by:\n\n\\[\nM_t = 1 + \\int_0^t \\frac{-B_s M_s}{1-s}dB_s, \\quad \\text{ for } 0 \\leq t \\leq 1\n\\]\n\nDeduce from the previous question that \\((M_s,s \\leq t)\\) is a martingale for \\(t &lt; 1\\) and for the Brownian filtration.\nShow that \\(\\mathbb{E}[M_t] = 1\\) for all \\(t &lt; 1\\).\nProve that \\(\\lim_{t \\to 1^-} M_t = 0\\) almost surely.\n\n\nSolution.\nLet \\(f(t,x) = \\frac{1}{\\sqrt{1-t}}e^{-\\frac{x^2}{2(1-t)}}\\). We have:\n\\[\n\\begin{align*}\n\\frac{\\partial f}{\\partial t} &= \\frac{\\sqrt{1-t}\\cdot e^{-\\frac{x^2}{2(1-t)}}\\cdot \\frac{x^2}{2(1-t)^2}\\cdot (-1) - e^{-\\frac{x^2}{2(1-t)}}\\cdot \\frac{1}{2\\sqrt{1-t}}\\cdot(-1)}{(1-t)}\\\\\n&=\\frac{e^{-\\frac{x^2}{2(1-t)}}}{(1-t)}\\left( -\\frac{x^2}{2(1-t)^{3/2}}+\\frac{1-t}{2(1-t)^{3/2}}\\right)\\\\\n&= \\frac{e^{-\\frac{x^2}{2(1-t)}}((1-t) - x^2)}{2(1-t)^{5/2}}\n\\end{align*}\n\\]\nAlso, the first and second derivatives with respect to the space variable \\(x\\) are:\n\\[\n\\begin{align*}\n\\frac{\\partial f}{\\partial x} &= \\frac{1}{\\sqrt{1-t}}\\exp\\left(-\\frac{x^2}{2(1-t)}\\right)\\left(-\\frac{x}{(1-t)}\\right)\\\\\n&= -\\frac{x}{(1-t)^{3/2}} \\exp\\left(-\\frac{x^2}{2(1-t)}\\right)\n\\end{align*}\n\\]\n\\[\n\\begin{align*}\n\\frac{\\partial^2 f}{\\partial x^2} &= - \\frac{1}{(1-t)^{3/2}}\\left\\{\\exp\\left(-\\frac{x^2}{2(1-t)}\\right) + x\\exp\\left(-\\frac{x^2}{2(1-t)}\\right)\\left(-\\frac{x}{(1-t)}\\right)\\right\\}\\\\\n&= - \\frac{1}{(1-t)^{3/2}}\\exp\\left(-\\frac{x^2}{2(1-t)}\\right) \\left\\{1 - \\frac{x^2}{(1-t)}\\right\\}\\\\\n&= \\frac{(x^2 - (1-t))}{(1-t)^{5/2}}\\exp\\left(-\\frac{x^2}{2(1-t)}\\right)\n\\end{align*}\n\\]\nBy Ito’s formula:\n\\[\n\\begin{align*}\ndf(t,B_t) &= (f_t + \\frac{1}{2}f_{xx})dt + f_x dB_t\\\\\ndM_t &= -\\frac{B_t}{(1-t)} \\frac{e^{-\\frac{B_t^2}{2(1-t)}}}{\\sqrt{1-t}}\\\\\n&= -\\frac{B_t M_t}{(1-t)}\n\\end{align*}\n\\]\nwhere in the second step, we used the fact that \\(f_t + \\frac{1}{2}f_{xx} = 0\\), so the \\(dt\\) term is zero.\nIn the integral form:\n\\[\n\\begin{align*}\nM_t - M_0 &= \\int \\frac{- B_s M_s}{1 - s}dB_s\\\\\nM_t &= 1 + \\int \\frac{- B_s M_s}{1 - s}dB_s\n\\end{align*}\n\\]\n\nThe Ito integral \\(\\int_0^t \\frac{-B_s M_s}{1-s}dB_s\\) is a continuous martingale with respect to the brownian filtration. Hence \\((M_t,t \\geq 0)\\) is a martingale.\nThe expectation of an Ito integral is zero. Hence, \\(\\mathbb{E}[M_t] = 1\\) for all \\(t &lt; 1\\).\nUsing Markov’s inequality followed by (concave) Jensen’s inequality, because we know that \\(\\mathbb{E}[B_t^2]=t\\), \\(\\mathbb{E}[B_t^4]=3t^2\\) and \\(Var(B_t^2) = 2t^2\\) for any \\(\\epsilon &gt; 0\\):"
  },
  {
    "objectID": "posts/ito_calculus/index.html#exercises",
    "href": "posts/ito_calculus/index.html#exercises",
    "title": "Ito Calculus",
    "section": "",
    "text": "Exercise 1 (A strange martingale) Let \\((B_t,t\\geq 0)\\) be a standard Brownian motion. Consider the process:\n\\[\nM_t = \\frac{1}{\\sqrt{1-t}}\\exp\\left(\\frac{-B_t^2}{2(1-t)}\\right), \\quad \\text{ for }0 \\leq t &lt; 1\n\\]\n\nShow that \\(M_t\\) can be represented by:\n\n\\[\nM_t = 1 + \\int_0^t \\frac{-B_s M_s}{1-s}dB_s, \\quad \\text{ for } 0 \\leq t \\leq 1\n\\]\n\nDeduce from the previous question that \\((M_s,s \\leq t)\\) is a martingale for \\(t &lt; 1\\) and for the Brownian filtration.\nShow that \\(\\mathbb{E}[M_t] = 1\\) for all \\(t &lt; 1\\).\nProve that \\(\\lim_{t \\to 1^-} M_t = 0\\) almost surely.\n\n\nSolution.\nLet \\(f(t,x) = \\frac{1}{\\sqrt{1-t}}e^{-\\frac{x^2}{2(1-t)}}\\). We have:\n\\[\n\\begin{align*}\n\\frac{\\partial f}{\\partial t} &= \\frac{\\sqrt{1-t}\\cdot e^{-\\frac{x^2}{2(1-t)}}\\cdot \\frac{x^2}{2(1-t)^2}\\cdot (-1) - e^{-\\frac{x^2}{2(1-t)}}\\cdot \\frac{1}{2\\sqrt{1-t}}\\cdot(-1)}{(1-t)}\\\\\n&=\\frac{e^{-\\frac{x^2}{2(1-t)}}}{(1-t)}\\left( -\\frac{x^2}{2(1-t)^{3/2}}+\\frac{1-t}{2(1-t)^{3/2}}\\right)\\\\\n&= \\frac{e^{-\\frac{x^2}{2(1-t)}}((1-t) - x^2)}{2(1-t)^{5/2}}\n\\end{align*}\n\\]\nAlso, the first and second derivatives with respect to the space variable \\(x\\) are:\n\\[\n\\begin{align*}\n\\frac{\\partial f}{\\partial x} &= \\frac{1}{\\sqrt{1-t}}\\exp\\left(-\\frac{x^2}{2(1-t)}\\right)\\left(-\\frac{x}{(1-t)}\\right)\\\\\n&= -\\frac{x}{(1-t)^{3/2}} \\exp\\left(-\\frac{x^2}{2(1-t)}\\right)\n\\end{align*}\n\\]\n\\[\n\\begin{align*}\n\\frac{\\partial^2 f}{\\partial x^2} &= - \\frac{1}{(1-t)^{3/2}}\\left\\{\\exp\\left(-\\frac{x^2}{2(1-t)}\\right) + x\\exp\\left(-\\frac{x^2}{2(1-t)}\\right)\\left(-\\frac{x}{(1-t)}\\right)\\right\\}\\\\\n&= - \\frac{1}{(1-t)^{3/2}}\\exp\\left(-\\frac{x^2}{2(1-t)}\\right) \\left\\{1 - \\frac{x^2}{(1-t)}\\right\\}\\\\\n&= \\frac{(x^2 - (1-t))}{(1-t)^{5/2}}\\exp\\left(-\\frac{x^2}{2(1-t)}\\right)\n\\end{align*}\n\\]\nBy Ito’s formula:\n\\[\n\\begin{align*}\ndf(t,B_t) &= (f_t + \\frac{1}{2}f_{xx})dt + f_x dB_t\\\\\ndM_t &= -\\frac{B_t}{(1-t)} \\frac{e^{-\\frac{B_t^2}{2(1-t)}}}{\\sqrt{1-t}}\\\\\n&= -\\frac{B_t M_t}{(1-t)}\n\\end{align*}\n\\]\nwhere in the second step, we used the fact that \\(f_t + \\frac{1}{2}f_{xx} = 0\\), so the \\(dt\\) term is zero.\nIn the integral form:\n\\[\n\\begin{align*}\nM_t - M_0 &= \\int \\frac{- B_s M_s}{1 - s}dB_s\\\\\nM_t &= 1 + \\int \\frac{- B_s M_s}{1 - s}dB_s\n\\end{align*}\n\\]\n\nThe Ito integral \\(\\int_0^t \\frac{-B_s M_s}{1-s}dB_s\\) is a continuous martingale with respect to the brownian filtration. Hence \\((M_t,t \\geq 0)\\) is a martingale.\nThe expectation of an Ito integral is zero. Hence, \\(\\mathbb{E}[M_t] = 1\\) for all \\(t &lt; 1\\).\nUsing Markov’s inequality followed by (concave) Jensen’s inequality, because we know that \\(\\mathbb{E}[B_t^2]=t\\), \\(\\mathbb{E}[B_t^4]=3t^2\\) and \\(Var(B_t^2) = 2t^2\\) for any \\(\\epsilon &gt; 0\\):"
  },
  {
    "objectID": "posts/levenberg-marquardt/index.html",
    "href": "posts/levenberg-marquardt/index.html",
    "title": "Levenberg-Marquardt Algorithm",
    "section": "",
    "text": "The Levenberg-Marquardt(LM) method consists of an iterative least-squares minimization of a function based on a modification of the Newton method. It’s a super-intuitive algorithm and a generic implementation can be very quickly coded up. I state the problem formally before defining the algorithm. We’ll use finite differences to approximate the first and second-order derivatives of the function.\nLet \\(\\mathbf{x}\\in\\mathbf{R}^n\\) be the parameter vector to be optimized. We want to find the optimal \\(\\mathbf{x}^*\\) that minimizes the scalar error function:\n\\[\n\\begin{align*}\nF(\\mathbf{x}) = \\frac{1}{2}||\\mathbf{r}(\\mathbf{x})||^2 = \\frac{1}{2}\\mathbf{r}(\\mathbf{x})^T \\mathbf{r}(\\mathbf{x})\n\\end{align*}\n\\]\nThe residual error function \\(\\mathbf{r}:\\mathbf{R}^n \\to \\mathbf{R}^m\\) may sometimes include a comparison to reference or observed data. A very simple linear example would \\(\\mathbf{r}(\\mathbf{x}) = \\mathbf{b} - \\mathbf{Ax}\\). However, in the following, I assume that \\(\\mathbf{r}(\\cdot)\\) is any vector-valued function:\n\\[\n\\begin{align*}\n\\mathbf{r}(\\mathbf{x}) = (r_1(\\mathbf{x}),f_2(\\mathbf{x}),\\ldots,r_m(\\mathbf{x}))\n\\end{align*}\n\\]\nWe can define the Jacobian of the residual error functions as \\(m \\times n\\) matrix with entries :\n\\[\n\\mathbf{J}_{ij}(\\mathbf{x}) = \\frac{\\partial r_i}{\\partial x_j}(\\mathbf{x})\n\\]\nWe can also define the Hessian of the residual error functions as the \\(n \\times n\\) matrix with entries :\n\\[\n\\begin{align*}\n\\mathbf{H}_{ij}(\\mathbf{x}) = \\frac{\\partial^2 r_i}{\\partial x_i \\partial x_j} (\\mathbf{x})\n\\end{align*}\n\\]\nThe gradient of the scalar-valued function \\(F\\), by the \\(uv\\) product rule is:\n\\[\n\\begin{align*}\n\\nabla F(\\mathbf{x}) = D\\mathbf{r}(\\mathbf{x}) \\mathbf{r}(\\mathbf{x}) = \\mathbf{J}(\\mathbf{x})\\cdot \\mathbf{r}(\\mathbf{x})\n\\end{align*}\n\\]\nThe Hessian of the function \\(F\\) is:\n\\[\n\\begin{align*}\n\\nabla^2 F(\\mathbf{x}) &= D\\left\\{\\sum_{j=1}^{m} \\nabla r_j(\\mathbf{x}) \\cdot r_j(\\mathbf{x})\\right\\}\\\\\n&= \\sum_{j=1}^m \\nabla^2 r_j(\\mathbf{x}) r_j(\\mathbf{x}) + (\\nabla r_j(\\mathbf{x}))^2\n\\end{align*}\n\\]\nIf the derivatives \\(\\nabla^2 r_j(\\mathbf{x})\\) are small, they can be dropped and the Hessian in this case simply becomes:\n\\[\n\\nabla^2 F(\\mathbf{x}) = \\nabla r(\\mathbf{x})^T \\nabla(r(\\mathbf{x})) = \\mathbf{J}(\\mathbf{x})^T \\cdot \\mathbf{J}(\\mathbf{x})\n\\]\nThen, the LM method minimizes the following \\(2\\)nd-order Taylor’s expansion of the actual error function:\n\\[\nF(\\mathbf{x}^{(k)} + \\mathbf{h}) - F(\\mathbf{x}^{(k)}) = \\mathbf{h} \\nabla F(\\mathbf{x}^{(k)}) + \\frac{1}{2}\\mathbf{h}^T \\nabla^2 F(\\mathbf{x}^{(k)}) \\mathbf{h}\n\\tag{1}\\]\nDescent methods like gradient descent can place too much trust in their first- or second- order information, which can result in excessively large steps or premature convergence.\nSo, in LM, we add a penalty term\n\\[ \\frac{1}{2} \\lambda^{(k)} \\mathbf{h}^T \\mathbf{h} = \\frac{1}{2} \\lambda^{(k)} ||\\mathbf{x} - \\mathbf{x}^{(k)}||^2 \\tag{2}\\]\nto the above Equation 1, that we want to minimize. That’s because, we don’t want to go too far away from \\(\\mathbf{x}^{(k)}\\). It’s not because, we think the solution is not too far away. The actual solution could be far away. But, that’s a question of trust. And \\(\\lambda^{(k)}\\) essentially gives you your level of distrust. If \\(\\lambda^{(k)}\\) is super-big, it means that you don’t trust the model very much, or you trust it, but only if you are very close to \\(\\mathbf{x}^{(k)}\\). When \\(\\lambda^{(k)}\\) gets really small, it means you really trust your model. And you’re gonna find that \\(\\mathbf{x}\\) is going to very far from \\(\\mathbf{x}^{(k)}\\). So, that’s the gist. Putting together,\n\\[\nE(\\mathbf{h}) = \\mathbf{h} \\nabla F(\\mathbf{x}^{(k)}) + \\frac{1}{2}\\mathbf{h}^T \\nabla^2 ( F(\\mathbf{x}^{(k)}) + \\lambda^{(k)} I )\\mathbf{h}\n\\tag{3}\\]\nWe can just solve for the optimal step-size \\(\\mathbf{h}_{lm}\\) analytically. Taking the first derivative with respect to the step-size \\(\\mathbf{h}\\) and setting it equal to zero:\n\\[\n\\nabla E(\\mathbf{h}) = \\nabla F(\\mathbf{x}^{(k)}) + \\mathbf{h}_{lm}( \\nabla^2 F(\\mathbf{x}^{(k)}) + \\lambda^{(k)}I) = 0\n\\tag{4}\\]\nConsequently,\n\\[\n\\begin{align*}\n\\mathbf{h}_{lm} &= -(\\nabla^2 F(\\mathbf{x}^{(k)}) + \\lambda^{(k)}I)^{-1} \\nabla F(\\mathbf{x}^{(k)})\\\\\n&=-(\\mathbf{J}(\\mathbf{x}^{(k)})^T \\mathbf{J}(\\mathbf{x})^{(k)} + \\lambda^{(k)}I)^{-1} \\mathbf{J}(\\mathbf{x}^{(k)}) \\mathbf{r}(\\mathbf{x}^{(k)})\n\\end{align*}\n\\tag{5}\\]\nOur best estimate of the minima, is consequently:\n\\[\n\\begin{align*}\n\\mathbf{x}^{(k+1)} &= \\mathbf{x}^{(k)} + \\mathbf{h}_{lm}\\\\\n&= \\mathbf{x}^{(k)} -(\\mathbf{J}(\\mathbf{x}^{(k)})^T \\mathbf{J}(\\mathbf{x})^{(k)} + \\lambda^{(k)}I)^{-1} \\mathbf{J}(\\mathbf{x}^{(k)}) \\mathbf{r}(\\mathbf{x}^{(k)})\n\\end{align*}\n\\tag{6}\\]\n\n\n\nA trust-region method, or restricted step method maintains a local model of the trust region. It depends on the success of the previous step. If the step \\(\\mathbf{h}_{lm}\\) results in a decrease in \\(||F(\\mathbf{x})||^2\\), then we reduce \\(\\lambda^{(k)}\\), otherwise we increase the value of this parameter.\nSo, we can use the following update mechanism:\n\nIf \\(||F(\\mathbf{x}^{(k+1)})||^2\\) &lt; \\(||F(\\mathbf{x}^{(k)})||^2\\), accept the new \\(x\\) and reduce \\(\\lambda\\)\n\n\\[ \\lambda^{(k+1)} = 0.8 \\lambda^{(k)}\\]\n\notherwise, we increase the \\(\\lambda\\) and do not update \\(\\mathbf{x}\\):\n\n\\[ \\lambda^{(k+1)} = 2 \\lambda^{k}, \\quad \\mathbf{x}^{(k+1)} = \\mathbf{x}^{(k)}\\]\n\n\n\n\nusing Pkg"
  },
  {
    "objectID": "posts/levenberg-marquardt/index.html#algorithm-description",
    "href": "posts/levenberg-marquardt/index.html#algorithm-description",
    "title": "Levenberg-Marquardt Algorithm",
    "section": "",
    "text": "The Levenberg-Marquardt(LM) method consists of an iterative least-squares minimization of a function based on a modification of the Newton method. It’s a super-intuitive algorithm and a generic implementation can be very quickly coded up. I state the problem formally before defining the algorithm. We’ll use finite differences to approximate the first and second-order derivatives of the function.\nLet \\(\\mathbf{x}\\in\\mathbf{R}^n\\) be the parameter vector to be optimized. We want to find the optimal \\(\\mathbf{x}^*\\) that minimizes the scalar error function:\n\\[\n\\begin{align*}\nF(\\mathbf{x}) = \\frac{1}{2}||\\mathbf{r}(\\mathbf{x})||^2 = \\frac{1}{2}\\mathbf{r}(\\mathbf{x})^T \\mathbf{r}(\\mathbf{x})\n\\end{align*}\n\\]\nThe residual error function \\(\\mathbf{r}:\\mathbf{R}^n \\to \\mathbf{R}^m\\) may sometimes include a comparison to reference or observed data. A very simple linear example would \\(\\mathbf{r}(\\mathbf{x}) = \\mathbf{b} - \\mathbf{Ax}\\). However, in the following, I assume that \\(\\mathbf{r}(\\cdot)\\) is any vector-valued function:\n\\[\n\\begin{align*}\n\\mathbf{r}(\\mathbf{x}) = (r_1(\\mathbf{x}),f_2(\\mathbf{x}),\\ldots,r_m(\\mathbf{x}))\n\\end{align*}\n\\]\nWe can define the Jacobian of the residual error functions as \\(m \\times n\\) matrix with entries :\n\\[\n\\mathbf{J}_{ij}(\\mathbf{x}) = \\frac{\\partial r_i}{\\partial x_j}(\\mathbf{x})\n\\]\nWe can also define the Hessian of the residual error functions as the \\(n \\times n\\) matrix with entries :\n\\[\n\\begin{align*}\n\\mathbf{H}_{ij}(\\mathbf{x}) = \\frac{\\partial^2 r_i}{\\partial x_i \\partial x_j} (\\mathbf{x})\n\\end{align*}\n\\]\nThe gradient of the scalar-valued function \\(F\\), by the \\(uv\\) product rule is:\n\\[\n\\begin{align*}\n\\nabla F(\\mathbf{x}) = D\\mathbf{r}(\\mathbf{x}) \\mathbf{r}(\\mathbf{x}) = \\mathbf{J}(\\mathbf{x})\\cdot \\mathbf{r}(\\mathbf{x})\n\\end{align*}\n\\]\nThe Hessian of the function \\(F\\) is:\n\\[\n\\begin{align*}\n\\nabla^2 F(\\mathbf{x}) &= D\\left\\{\\sum_{j=1}^{m} \\nabla r_j(\\mathbf{x}) \\cdot r_j(\\mathbf{x})\\right\\}\\\\\n&= \\sum_{j=1}^m \\nabla^2 r_j(\\mathbf{x}) r_j(\\mathbf{x}) + (\\nabla r_j(\\mathbf{x}))^2\n\\end{align*}\n\\]\nIf the derivatives \\(\\nabla^2 r_j(\\mathbf{x})\\) are small, they can be dropped and the Hessian in this case simply becomes:\n\\[\n\\nabla^2 F(\\mathbf{x}) = \\nabla r(\\mathbf{x})^T \\nabla(r(\\mathbf{x})) = \\mathbf{J}(\\mathbf{x})^T \\cdot \\mathbf{J}(\\mathbf{x})\n\\]\nThen, the LM method minimizes the following \\(2\\)nd-order Taylor’s expansion of the actual error function:\n\\[\nF(\\mathbf{x}^{(k)} + \\mathbf{h}) - F(\\mathbf{x}^{(k)}) = \\mathbf{h} \\nabla F(\\mathbf{x}^{(k)}) + \\frac{1}{2}\\mathbf{h}^T \\nabla^2 F(\\mathbf{x}^{(k)}) \\mathbf{h}\n\\tag{1}\\]\nDescent methods like gradient descent can place too much trust in their first- or second- order information, which can result in excessively large steps or premature convergence.\nSo, in LM, we add a penalty term\n\\[ \\frac{1}{2} \\lambda^{(k)} \\mathbf{h}^T \\mathbf{h} = \\frac{1}{2} \\lambda^{(k)} ||\\mathbf{x} - \\mathbf{x}^{(k)}||^2 \\tag{2}\\]\nto the above Equation 1, that we want to minimize. That’s because, we don’t want to go too far away from \\(\\mathbf{x}^{(k)}\\). It’s not because, we think the solution is not too far away. The actual solution could be far away. But, that’s a question of trust. And \\(\\lambda^{(k)}\\) essentially gives you your level of distrust. If \\(\\lambda^{(k)}\\) is super-big, it means that you don’t trust the model very much, or you trust it, but only if you are very close to \\(\\mathbf{x}^{(k)}\\). When \\(\\lambda^{(k)}\\) gets really small, it means you really trust your model. And you’re gonna find that \\(\\mathbf{x}\\) is going to very far from \\(\\mathbf{x}^{(k)}\\). So, that’s the gist. Putting together,\n\\[\nE(\\mathbf{h}) = \\mathbf{h} \\nabla F(\\mathbf{x}^{(k)}) + \\frac{1}{2}\\mathbf{h}^T \\nabla^2 ( F(\\mathbf{x}^{(k)}) + \\lambda^{(k)} I )\\mathbf{h}\n\\tag{3}\\]\nWe can just solve for the optimal step-size \\(\\mathbf{h}_{lm}\\) analytically. Taking the first derivative with respect to the step-size \\(\\mathbf{h}\\) and setting it equal to zero:\n\\[\n\\nabla E(\\mathbf{h}) = \\nabla F(\\mathbf{x}^{(k)}) + \\mathbf{h}_{lm}( \\nabla^2 F(\\mathbf{x}^{(k)}) + \\lambda^{(k)}I) = 0\n\\tag{4}\\]\nConsequently,\n\\[\n\\begin{align*}\n\\mathbf{h}_{lm} &= -(\\nabla^2 F(\\mathbf{x}^{(k)}) + \\lambda^{(k)}I)^{-1} \\nabla F(\\mathbf{x}^{(k)})\\\\\n&=-(\\mathbf{J}(\\mathbf{x}^{(k)})^T \\mathbf{J}(\\mathbf{x})^{(k)} + \\lambda^{(k)}I)^{-1} \\mathbf{J}(\\mathbf{x}^{(k)}) \\mathbf{r}(\\mathbf{x}^{(k)})\n\\end{align*}\n\\tag{5}\\]\nOur best estimate of the minima, is consequently:\n\\[\n\\begin{align*}\n\\mathbf{x}^{(k+1)} &= \\mathbf{x}^{(k)} + \\mathbf{h}_{lm}\\\\\n&= \\mathbf{x}^{(k)} -(\\mathbf{J}(\\mathbf{x}^{(k)})^T \\mathbf{J}(\\mathbf{x})^{(k)} + \\lambda^{(k)}I)^{-1} \\mathbf{J}(\\mathbf{x}^{(k)}) \\mathbf{r}(\\mathbf{x}^{(k)})\n\\end{align*}\n\\tag{6}\\]"
  },
  {
    "objectID": "posts/levenberg-marquardt/index.html#updating-lambdak",
    "href": "posts/levenberg-marquardt/index.html#updating-lambdak",
    "title": "Levenberg-Marquardt Algorithm",
    "section": "",
    "text": "A trust-region method, or restricted step method maintains a local model of the trust region. It depends on the success of the previous step. If the step \\(\\mathbf{h}_{lm}\\) results in a decrease in \\(||F(\\mathbf{x})||^2\\), then we reduce \\(\\lambda^{(k)}\\), otherwise we increase the value of this parameter.\nSo, we can use the following update mechanism:\n\nIf \\(||F(\\mathbf{x}^{(k+1)})||^2\\) &lt; \\(||F(\\mathbf{x}^{(k)})||^2\\), accept the new \\(x\\) and reduce \\(\\lambda\\)\n\n\\[ \\lambda^{(k+1)} = 0.8 \\lambda^{(k)}\\]\n\notherwise, we increase the \\(\\lambda\\) and do not update \\(\\mathbf{x}\\):\n\n\\[ \\lambda^{(k+1)} = 2 \\lambda^{k}, \\quad \\mathbf{x}^{(k+1)} = \\mathbf{x}^{(k)}\\]"
  },
  {
    "objectID": "posts/levenberg-marquardt/index.html#generic-implementation-in-julia",
    "href": "posts/levenberg-marquardt/index.html#generic-implementation-in-julia",
    "title": "Levenberg-Marquardt Algorithm",
    "section": "",
    "text": "using Pkg"
  },
  {
    "objectID": "posts/move-semantics/index.html",
    "href": "posts/move-semantics/index.html",
    "title": "Move semantics and perfect forwarding",
    "section": "",
    "text": "C++ defines the following value categories:\n\nlvalues: expressions for locations of long-living objects or functions. These objects have identity, persist in memory and are addressable.\nprvalues: expressions for short-living values for initializations. prvalues themselves do not exist somewhere in memory, they do not denote objects. They are unmaterialized entities meant for initialization.\nxvalue: A special location, representing a (long-living) object, whose resources/values are no longer needed and can be reused. The guts of this object can be stolen.\n\nThe moment a prvalue (conceptual temporary) becomes an xvalue(temporary object), it is called materialization. The temporary materialization conversion is usually an implicit prvalue-to-xvalue conversion.\nAnytime a prvalue is used where a lvalue or xvalue is expected, a temporary object is created and initialized with the prvalue."
  },
  {
    "objectID": "posts/move-semantics/index.html#motivation-for-move-semantics",
    "href": "posts/move-semantics/index.html#motivation-for-move-semantics",
    "title": "A hitchhiker’s guide to move semantics and perfect forwarding",
    "section": "",
    "text": "To understand the basic principles of move semantics, let’s look at the execution of a small piece of code. I’ve written a toy Vector class. I choose to manage the memory myself, so I will follow the rule of three. I will supply a copy-constructor, copy-assignment operator and a destructor. I have also overloaded operator+() to support element-wise addition of two vectors.\n\n\nAssume that we have the following program:\n//basics/copy_semantics.cpp\n#include &lt;iostream&gt;\n#include &lt;stdexcept&gt;\n#include &lt;initializer_list&gt;\n\n\ntemplate &lt;typename T&gt;\nclass Vector {\nprivate:\n    int capacity_;\n    int size_;\n    T* ptr_;\n\npublic:\n    Vector() :capacity_{ 0 }, size_{ 0 }, ptr_{ nullptr } {}\n    Vector(int size) : capacity_{ size }, ptr_{ new T[size] }, size_{ size } {}\n    Vector(int size, T data) : Vector(size) {\n        for (int i{ 0 }; i &lt; size; ++i)\n            ptr_[i] = data;\n    }\n\n    Vector(std::initializer_list&lt;T&gt; list) {\n        clear();\n        for (const T& elem : list)\n            push_back(elem);\n    }\n\n    //Destructor\n    ~Vector()\n    {\n        clear();\n    }\n\n    //Copy constructor\n    Vector(const Vector& v)\n    {\n        if (this == &v)\n            return;\n\n        capacity_ = v.capacity_;\n        size_ = v.size_;\n        ptr_ = new T[v.size_];\n\n        for (int i{ 0 }; i &lt; v.size_; ++i)\n            ptr_[i] = v.ptr_[i];\n    }\n\n    //Copy assignment operator\n    Vector&lt;T&gt;& operator=(const Vector&lt;T&gt;& v)\n    {\n        if (this != &v)\n        {\n            delete[] ptr_;\n            ptr_ = nullptr;\n\n            capacity_ = v.capacity_;\n            size_ = v.size_;\n            ptr_ = new T[capacity_];\n\n            for (int i{ 0 }; i &lt; v.size_; ++i)\n                ptr_[i] = v.ptr_[i];\n        }\n\n        return *this;\n    }\n\n    T& operator[](int i)\n    {\n        if (i &gt;= 0 && i &lt; size_)\n            return ptr_[i];\n        else\n            throw std::out_of_range(\"Index out of bounds.\");\n    }\n\n    T& operator[](int i) const\n    {\n        if (i &gt;= 0 && i &lt; size_)\n            return ptr_[i];\n        else\n            throw std::out_of_range(\"Index out of bounds.\");\n    }\n\n    void reserve(int size)\n    {\n        if (size_ &lt; capacity_) return;\n\n        if (ptr_ == nullptr)\n        {\n            size_ = 0;\n            capacity_ = 0;\n        }\n\n        T* bufferNew = new T[size];\n        unsigned int l_size = std::min(capacity_, size);\n        for (int i{ 0 }; i &lt; l_size; ++i)\n        {\n            bufferNew[i] = ptr_[i];\n        }\n\n        if (ptr_ != nullptr)\n            delete[] ptr_;\n\n        ptr_ = bufferNew;\n        capacity_ = size;\n    }\n\n    void clear()\n    {\n        if (ptr_ != nullptr)\n            delete[] ptr_;\n        ptr_ = nullptr;\n        size_ = 0;\n        capacity_ = 0;\n    }\n\n    int size() const\n    {\n        return size_;\n    }\n\n    int capacity()\n    {\n        return capacity_;\n    }\n\n    void push_back(const T& elem)\n    {\n        if (size_ &gt;= capacity_) {\n            reserve(capacity_ + 5); // Double the capacity\n        }\n\n        ptr_[size_++] = elem;\n    }\n\n    void pop_back()\n    {\n        --size_;\n    }\n\n    T front()\n    {\n        if (size_ &gt; 0)\n            return ptr_[0];\n        else\n            throw std::out_of_range(\"Index out of bounds.\");\n    }\n\n    T back()\n    {\n        if (size_ &gt; 0)\n            return ptr_[size_ - 1];\n        else\n            throw std::out_of_range(\"Index out of bounds.\");\n    }\n\n    T* getRawPointer()\n    {\n        return ptr_;\n    }\n};\n\ntemplate &lt;typename T&gt;\nVector&lt;T&gt; operator+(const Vector&lt;T&gt;& v1, const Vector&lt;T&gt;& v2)\n{\n    if (v1.size() != v2.size())\n        throw std::logic_error(\"Vector lengths must be equal.\");\n    Vector&lt;T&gt; result;\n    for (int i{ 0 }; i &lt; v1.size(); ++i)\n        result.push_back(v1[i] + v2[i]);\n\n    return result;\n}\n\nVector&lt;Vector&lt;double&gt;&gt; createAndInsert()\n{\n    Vector&lt;Vector&lt;double&gt;&gt; pts;\n    pts.reserve(3);\n    Vector&lt;double&gt; x{ 1.0, 1.0 };\n    pts.push_back(x);\n    pts.push_back(x + x);\n    pts.push_back(x);\n    return pts;\n}\n\nint main()\n{\n    Vector&lt;Vector&lt;double&gt;&gt; result = createAndInsert();\n    return 0;\n}\nCompiler Explorer\nLet us look at the individual steps of the program (inspecting both stack and the heap) when we compile this program with a C++ compiler.\nFirst in main, we create the empty vector pts which will be used to store points in the euclidean space \\(\\mathbf{R}^2\\):\nVector&lt;Vector&lt;double&gt;&gt; pts;\nwhich is placed on the stack as an object that has size_ = 0, capacity_ = 0 and no memory allocated for elements.\nThen, we call\npts.reserve(3);\nThis allocates memory for 3 elements on the heap. The member pts_-&gt;capacity_ equals 3, pts-&gt;size_ equals 0 and pts_-&gt;ptr_ contains the address to heap block. The allocated memory is not initialized, because the number of elements is still 0.\nThen, we create a \\(2\\)-tuple to hold the cartesian coordinates of a point \\((1.0,1.0)\\). We create a Vector&lt;double&gt; initialized to {1.0,1.0}. Essentially, we create an object x on the stack with its members x-&gt;size_ = 2, x-&gt;capacity_ = 5 and a pointer x-&gt;ptr_ containing the address of newly allocated memory on the heap for 5 elements. Further, x-&gt;ptr_[0]=1.0, x-&gt;ptr_[1]=1.0.\nVector&lt;double&gt; x{1.0, 1.0};\nAfter this statement, the program has the following state: we have two objects on the stack : pts and x. Both of them have memory allocated on the heap.\n\n\n\nCheckpoint #1\n\n\nThe next step is the command to insert x into the pts vector.\npts.push_back(x);\nMy toy Vector class is said to have value semantics, which means it creates copies of the values passed to it. As a result, we get a first element in the vector, which is a full(deep) copy of the passed value/object x:\n\n\n\nCheckpoint #2\n\n\nThe current state is that we have a vector pts and two copies of x={1.0,1.0}, one of which is the first element in pts.\nLet’s now look at the next statement, which creates a new temporary vector and again inserts it into the pts vector:\npts.push_back(x + x);\nThis statement is performed in three steps:\nStep 1. We create a temporary Vector&lt;double&gt; object x + x.\n\n\n\nStep #1\n\n\nStep 2. x+x is a temporary. The Vector&lt;T&gt;::push_back(const T&) function accepts a reference-to-const as an argument. Since x+x is a temporary, it cannot be modified and binds to a reference-to-const. Moreover, being a temporary object, it is likely to die soon. Referencing it extends the lifetime of the temporary x + x={2.0,2.0}.\nNow, the statement pts_[size++] = elem will invoke the copy-assignment operator on the yet uninitialized second element pts[1] which is of type Vector&lt;double&gt;. This will force a full (deep) copy of x + x={2.0,2.0}. At this time, two copies of {2.0,2.0} exist on the heap. One of these is assigned to pts[1].\n\n\n\nStep #2\n\n\nStep 3. When push_back(const T&) returns, the temporary x + x will die and its destructor is called and the memory allocated on the heap is freed. You can see this on cppinsights.\nOur code is clearly not performing well: we create a copy of the temporary x + x and destroy the source of the copy immediately afterwards, which means we unnecessarily allocate and free memory that we could have just moved from source to the copy.\n\n\n\nStep #3\n\n\nWith the next statement, again we insert x into pts:\npts.push_back(x)\nAgain, pts copies x.\n\n\n\nCheckpoint #3\n\n\nThis is also something to improve. Because the value of x is no longer needed, some optimization could use the memory of x as the memory for the new element instead.\nAt the end of createAndInsert() we come to the return statement:\nreturn pts;\nHere, the behaviour of the program is a bit more complicated. We return by value (the return type is not a reference), which should be a copy of the value in the return statement. Creating a copy of pts means that we have create a deep copy of the whole vector with all of its elements. Thus, we have to allocate heap memory for the array of elements in the pts and heap memory for the value of each 2-tuple. Here, we would have to allocate memory 4 times.\nHowever, since at the same time pts is destroyed because we leave the scope where it is declared, the compiler is allowed to perform named return value optimization (NRVO). This means that the compiler can generate code so that pts is used as the return value.\nLet us assume that we have the named return value optimization. In that case, at the end of the return statement, pts simply becomes the return value and the destructor of x is called, which frees the memory allocated when it was declared.\n\n\n\nReturn statement\n\n\nFinally, we come to the assignment of the return value to result:\nresult = createAndInsert()\nHere, we really get behavior that can be improved: the usual assignment operator has the goal of giving result the same value as the source value that is assigned. In general, any source(assigned) value should not be modified and should independent from the object that the value was assigned to. So, the assignment operator will create a deep-copy of the whole return value:\n\n\n\nReturn statement\n\n\nHowever, right after that we no longer need the temporary return value and we destroy it:\nAgain, we create a copy of a temporary object and destroy the source of the copy immediately afterwards, which means that we again unnecessarily allocate and free memory. This time it applies to four allocations\nFor the state of the program after this assignment in main(), we allocated memory numerous times and released it. Unnecessary memory allocations were caused by:\n\nInserting a temporary object into pts.\nInserting an object into pts where we no longer need the value.\nAssigning a temporary vector with all its elements.\n\nWe can more or less avoid these performance pennalties."
  },
  {
    "objectID": "posts/move-semantics/index.html#copy-elison",
    "href": "posts/move-semantics/index.html#copy-elison",
    "title": "Move semantics and perfect forwarding",
    "section": "Copy elison",
    "text": "Copy elison\nCopy elison omits copy and move constructors, resulting in zero-copy pass-by-value semantics.\n\nMechanics\nThe basic mechanics of Return Value Optimization(RVO) is as follows:\n\nThe caller allocates space on the stack for the return value, passes the address to the callee.\nThe callee constructs the result directly in that space.\n\nIn the below code snip,\n#include &lt;print&gt;\n#include &lt;iostream&gt;\n\nstruct X{\n    X(double val) : m_val{val} { std::cout &lt;&lt; \"\\n\" &lt;&lt; \"constructed at \" &lt;&lt; this; }\n    X(const X&){ std::println(\"X(const X&)\"); }\n    X(X&&){ std::println(\"X(X&&)\"); }\n    ~X(){ std::cout &lt;&lt; \"\\n\" &lt;&lt; \"destructed at \" &lt;&lt; this; }\n    double m_val;\n};\n\nvoid f(X arg){\n    std::cout &lt;&lt; \"\\n\" &lt;&lt; \"&arg = \" &lt;&lt; &arg;\n}\n\nX g(){\n    X obj = X(10);  // copy elison initializing obj\n                    // from temporary\n    return obj;     // NRVO\n}\n\nX h(){\n    return X(15);   // URVO\n}\n\nint main(){\n    f(X(42));\n    X v1{g()};  // Copy elison initializing v1 from the result of g()\n    std::cout &lt;&lt; \"\\n\" &lt;&lt; \"&v1 = \" &lt;&lt; &v1;\n    X v2{h()};  // Copy elison initializing v2 from the result of h()\n    std::cout &lt;&lt; \"\\n\" &lt;&lt; \"&v2 = \" &lt;&lt; &v2;\n    return 0;\n}\nCompiler Explorer\nIt is important to note that:\n\nWhen a temporary(prvalue) is used to initialize an object, or function parameter, a copy is elided.\nInside a function, when a prvalue is returned by value, URVO(unnamed return value optimization) is performed.\nInside a function, when a lvalue is returned by value, NRVO(named return value optimization) is performed."
  },
  {
    "objectID": "posts/move-semantics/index.html#value-categories",
    "href": "posts/move-semantics/index.html#value-categories",
    "title": "Move semantics and perfect forwarding",
    "section": "",
    "text": "In C++, every expression is either an lvalue or an rvalue.\nAn lvalue denotes an object whose resources cannot be reused. The object is an lvalue, if you can’t take the guts(resources) out of this object and donate it to someone else. lvalues include expressions that designate objects by their name. For example, in the expression double y = f(x), y is an lvalue. Moreover, lvalues have persistent storage and an identifiable memory address. For instance, if I declare std::vector&lt;double&gt; v{1.0,2.0,3.0,4.0,5.0};, then v[0] is an lvalue.\nAn rvalue denotes an object whose resources can be reused. The object is an rvalue, if you can take the guts(resources) out of it and donate it to another object. rvalues typically include temporary objects as they can’t manipulated at the place they are created and are likely to be destroyed soon. For instance, if declare int x = 5;, 5 is an rvalue. Moreover, in the statement double y = f(x);, the expression f(x) is an rvalue.\nC++ defines the following value categories:\n\nlvalues: expressions for locations of long-living objects or functions. These objects have identity, persist in memory and are addressable.\nprvalues: expressions for short-living values for initializations. prvalues themselves do not exist somewhere in memory, they do not denote objects. They are an abstract recipee for initializing an object of type T.\nxvalue: A special location, representing a (long-living) object, whose resources/values are no longer needed. The guts of this object can be stolen."
  },
  {
    "objectID": "posts/move-semantics/index.html#moving-data",
    "href": "posts/move-semantics/index.html#moving-data",
    "title": "Move semantics and perfect forwarding",
    "section": "Moving data",
    "text": "Moving data\nAs seen earlier, C++ sometimes performs unnecessary copying.\nVector&lt;double&gt; x;\nx = Vector&lt;double&gt;({\n        1.0, 2.0, 3.0, 4.0, 5.0, \n        6.0, 7.0, 8.0, 9.0, 10.0\n    });\ncppinsights produces the following annotations:\nVector&lt;double&gt; x = Vector&lt;double&gt;();\nconst double __temporary179_5[10] = {\n    1.0, 2.0, 3.0, 4.0, 5.0, \n    6.0, 7.0, 8.0, 9.0, 10.0\n};\nconst Vector&lt;double&gt; __temporary179_6 = Vector&lt;double&gt;(Vector&lt;double&gt;(std::initializer_list&lt;double&gt;{__temporary179_5, 10}));\nx.operator=(__temporary179_6);\n__temporary179_6.~Vector();\n/* __temporary179_5 // lifetime ends here */\nIn the above code snippet, the temporary vector of reals \\(\\{1.0,2.0,3.0,\\ldots,10.0\\}\\) is copied element-wise to x and then destroyed immediately after. We’ve wasted a lot of energy in deep-copying.\nSimilarly, appending to a full vector causes much copying before the append. That is not what we want to do.\nWhat we really want to do is, transfer the contents of __temporary19_6 vector to x in a very simple way. Firstly, we copy the pointers; we cannot stop there, because at this point there are two Vector&lt;T&gt; objects owning the same memory resource.\n\n\n\nStep 1. Copy the pointers\n\n\nThe second step is, of course to set the pointers of the temporary vector to nullptr.\n\n\n\nStep 2. Zero out the members of __temp\n\n\nThat looks great and this is cheap! We are doing the minimum amount of work to transfer the contents of the temporary into x.\nAt the end of the assignment operation, the temporary goes out of scope and the vector \\(\\{1,2,3,\\ldots,10\\}\\) is in x. How do we implement this logic programmatically?\nIn addition to the copy-constructor, we write a move constructor. A move constuctor simply moves the data by taking ownership of the pointer that refers to the data, leaving the data itself where it resides.\n// move constructor\nVector(Vector&& src) noexcept\n{\n    // Just swap the memory pointers\n    std::swap(src, *this);\n}\n\nrvalue references in detail\nThe constructor takes an argument of the type rvalue reference. rvalue references are declared two ampersands. lvalues bind to lvalue references. When taking a reference to a temporary object, an rvalue, you have two choices. rvalues can bind to:\n\nA const lvalue reference.\nA mutable rvalue reference.\n\nconst std::string& r1 {\"hello\"};    \nstd::string& r2 {\"world\"};\n\nconst Vector&lt;int&gt;& r3 {1,2,3,4,5};\nVector&lt;int&gt;&& r4{6,7,8,9,10};\nAll these references have the semantics of - we can steal/modify the resources of the object we refer to, provided the state of the object remains a valid state. Technically, these semantics are not checked by compilers, so we can modify an rvalue reference as we can do with any non-const object of the type. We might also decide not to modify the value.\nstd::string&& r1 = \"hello\";    \nr1 += \"world\"; \n\nVector&lt;int&gt;&& r2 {1,2,3,4,5};\nr2.push_back(6);\nAnd it’s a logic error to take a mutable lvalue reference to a temporary, so this is disallowed in the language:\n// std::string& r1 = \"hello\";    //error: this is not possible\n// r1 += \"world\"; \n// Vector&lt;int&gt;& r2 {1,2,3,4,5};\n// r2.push_back(6);\nAssigning a temporary to a reference extends the lifetime of the temporary so that it matches the lifetime of the reference. So, this is legal:\nint main()\n{\n    {\n        const std::string& s = foo();\n        std::cout &lt;&lt; s &lt;&lt; std::endl;    //the temporary to which s refers is still alive\n    }\n    //but now it's destroyed\n    return 0;    \n}\nAnd so is this:\nstd::string foo(){ return \"foo\";};      //function that returns a string\n\nvoid bar(std::string&& s){              // extends the lifetime as before\n    std::cout &lt;&lt; s; \n}    \n\nint main()\n{\n    bar(foo());     \n    return 0;\n}\n\n\nrvalue references as parameters\nWhen we declare a parameter to be an rvalue reference, it has exactly the behavior and semantics as introduced above:\n\nThe parameter can only bind to a temporary object or an rvalue.\nAccording to the semantics of rvalue references:\n\nThe caller claims that it is no longer interested in the object. Therefore, you can steal the guts of object, take ownership of its resources.\nHowever, the caller might still be interested in using the object. Therefore, any modification should keep the referenced object in a valid state."
  },
  {
    "objectID": "posts/move-semantics/index.html#stdmove",
    "href": "posts/move-semantics/index.html#stdmove",
    "title": "Move semantics and perfect forwarding",
    "section": "std::move()",
    "text": "std::move()\nHey, this is cool! Why don’t we apply these ideas to the below example?\nVector&lt;int&gt; v1 {1, 2, 3, 4, 5};\nVector&lt;int&gt; v2 {v1};\nWell, in this case, we would have a problem. v1 has a name, it has a persistent storage location and a memory address, it is an lvalue. You can’t steal the contents of v1.\nBut, we can do something about this. If indeed you are interested to transfer the contents of v1 into v2, then all we need to do is use std::move.\nVector&lt;int&gt; v1 {1, 2, 3, 4, 5};\nVector&lt;int&gt; v2 {std::move(v1)};\nstd::move() is a function that you can think of as performing an unconditional cast of its argument to an rvalue reference. std::move(v1) marks v1 to be movable. It does not physically move anything. It signals, that the object v1 may be moved from.\nIf you have an lvalue, an object for which the lifetime does not end when you use it, you can mark it with std::move() to express I no longer need this object here. std::move does not move; it only sets a temporary marker in the context where the expression is used:\nvoid foo1(const std::string& lr);    //binds to the passed object without modifying it\nvoid foo1(std::string&& rv);         //binds to the passed object and might steal/modify its contents\n\nstd::string s{\"hello\"};\n\nfoo1(s);                             //calls the first foo(), s keeps its value\nfoo1(std::move(s));                  //calls the second foo(), s might lose its value\n                                     //semantically s no longer legal to access\nObjects marked with std::move() can still be passed to a function that takes an ordinary const lvalue reference. Consider another code snippet:\nvoid foo2(const std::string& lr);   //binds to the passed object without modifying it\n                                    //no other overload of foo2()\nfoo2(s);                            // calls foo2(), s keeps its value\nfoos(std::move(s))                  // calls foo2(), s keeps its value because we know that\n                                    // foo2() can't modify or take ownership of the contents of s.\nSemantically, s is still legal to access after the execution of the last line. Because there’s overload of foo2(const std::string&&), there is no ways its contents can be modified or transferred.\nNote that, an object marked with std::move() cannot be passed to a non-const lvalue reference.\n\nHeader file for std::move()\nstd::move() is defined as a function in the C++ standard library. To use it, you have to include the header file &lt;utility&gt; where it is defined:\n\n\nImplementation of std::move()\nstd::move() is nothing but a static_cast to an rvalue reference. You can achieve the same effect by calling static_cast manually as follows:\nfoo(static_cast&lt;decltype(obj)&&&gt;(obj));     //same effect foo(std::move(obj))\nTherefore, we could also write:\nstd::string s{\"hello\"};\nfoo(static_cast&lt;std::string&&&gt;(s));"
  },
  {
    "objectID": "posts/move-semantics/index.html#moved-from-objects",
    "href": "posts/move-semantics/index.html#moved-from-objects",
    "title": "Move semantics and perfect forwarding",
    "section": "Moved-from objects",
    "text": "Moved-from objects\nAfter a std::move(), moved-from objects are not (partially) destroyed. They are still valid objects for which at least the destructor will be called. However, they should also be valid in the sense that they have a consistent state and all operations work as expected. The only thing you do not know is their contents.\n\nValid but unspecified state\nThe C++ standard library guarantees that moved-from objects are in a valid but unspecified state. Consider the following code:\nstd::string s{\"hello\"};\nstd::vector&lt;std::string&gt; coll{};\ncoll.push_back(std::move(s));\nAfter passing s with std::move() you can ask for the number of characters, print out the value, or even assign a new value. However, you cannot print the first character or any other character without checking the number of characters first:\n#include &lt;iostream&gt;\n#include &lt;vector&gt;\n#include &lt;string&gt;\n#include &lt;utility&gt;\n\nint main()\n{\n    std::string s{\"hello\"};\n    std::vector&lt;std::string&gt; coll{};\n    coll.push_back(std::move(s));   //keeps in a valid but unclear state\n    std::cout &lt;&lt; \"Contents of s : \" &lt;&lt; s &lt;&lt; \"\\n\";     //ok (don't know which value is written)\n    std::cout &lt;&lt; \"size : \" &lt;&lt; s.size() &lt;&lt; \"\\n\"; //ok (rites the number of characters)\n    // std::cout &lt;&lt; \"[0] = \" &lt;&lt; s[0] &lt;&lt; \"\\n\"; //error (potentially undefined behavior)\n    s = \"new value\";    // ok\n    return 0;\n}\nCompiler Explorer\nstdout\nContents of s : \nsize : 0\n\n\nReusing moved-from objects\nWe might wonder why moved-from objects are still valid objects and are not (partially) destroyed. The reason is that there are useful applications of move semantics, where it makes sense to use moved-from objects again.\nFor example, consider code where we read chunks of data from a network socket or read strings line-by-line from a file stream and move them into a vector:\nstd::vector&lt;std::string&gt; allRows;\nstd::string row;\n\nwhile(std::getline(myStream, row)){ //read next line into row\n    allRows.push_back(std::move(row));  //and move it to somewhere\n}\nEach time after we read a line into row, we use std::move() to move the value of row into the vector of all rows. Then, std::getline() uses the moved-from object row again to read the next line into it.\nAs a second example, consider a generic function that swaps two values:\ntemplate &lt;typename T&gt;\nvoid swap(T& a, T& b)\n{\n    T tmp{std::move(a)};\n    a = std::move(b);       //assign new value to moved-from a\n    b = std::move(temp);    //assign new value to moved-from b\n}\nHere, we move the value of a into a temporary object to be able t move-assign the value of b afterwards. The moved-from object b then receives the value of tmp, which is the former value of a.\nCode like this is used in sorting algorithms for example, sorting a vector of buy/sell orders in the order book by the bid/ask prices.\n\n\nMove assignments of objects to themselves\nThe rule that moved-from objects are in a valid but unspecified state usually also applies to objects after a direct or indirect self-move.\nFor example, after the following statement, the object x is usually valid without its value being known:\nx = std::move(x);   //afterwards x is valid but has an unclear value"
  },
  {
    "objectID": "posts/move-semantics/index.html#the-canonical-move-constructor-and-move-assignment-operator",
    "href": "posts/move-semantics/index.html#the-canonical-move-constructor-and-move-assignment-operator",
    "title": "Move semantics and perfect forwarding",
    "section": "The canonical move constructor and move assignment operator",
    "text": "The canonical move constructor and move assignment operator\nConsider the below Widget class as an example. The canonical move constructor and move assignment operators are written as follows:\nclass Widget{\n    private:\n        int i;\n        std::string s{};\n        int* resource;            // Owning pointer\n\n    public:\n    // Move constructor\n    Widget(Widget&& rhs) noexcept //Phase 1: member-wise swap\n        : i {std::move(rhs.i)}\n        , s {std::move(rhs.s)}\n        , resource{std::move(rhs.resource)}\n    {\n        rhs.resource = nullptr; // Phase 2: reset the move-from object\n    }\n\n    // Move assignment operator\n    Widget& operator=(Widget&& src)\n    {\n        delete resource;            //Phase 1: Cleanup\n        std::swap(src, *this);      //Phase 2: Member-wise move\n        src-&gt;resource = nullptr;    //Phase 3: Reset\n        return *this;\n    }\n\n    Widget::Widget& operator=(Widget src);\n}\nAn owning-pointer such int* is special, and it has to be dealt with separately.\nRaw pointers are bad (especially owning raw pointers). In this case, the declaration doesn’t indicate whether it points to an element or an array.\nIf instead, we have a smart-pointer, then what I can do is omit is phase 2.\nclass Widget{\n    private:\n        int i;\n        std::string s{};\n        int* resource;      \n\n    public:\n    // Move constructor\n    Widget(Widget&& rhs) noexcept //Phase 1: member-wise swap\n        : i {std::move(rhs.i)}\n        , s {std::move(rhs.s)}\n        , resource{std::move(rhs.resource)}\n    {}\n\n    // Move assignment operator\n    Widget& operator=(Widget&& src)\n    {\n        std::swap(src, *this); \n        return *this;\n    }\n\n    Widget::Widget& operator=(Widget src);\n}\nI would like to show you one more thing. The canonical copy assignment operator also doubles up as a move-assignment operator.\n// Copy/Move assignment operator\nWidget::Widget& operator=(Widget src)  //Copy/move constructor called \n{\n    std::swap(src, *this); \n    return *this;\n}\n\nint main()\n{\n    Widget w1(5,\"hello\", new int(10)),\n    Widget w2 = w1;     //copy/move assignment operator called\n    Widget w3 = std::move(w1);  //copy/move assignment operator called\n}\nIn the assignment statement Widget w2 = w1;, first the copy constructor is called and the contents of w1 are copied to src, before the control enters the body of operator=(Widget). Whereas the assignment statement Widget w3 = std::move(w1) results in the invocation of the move constructor and the contents of w1 are transferred to w3 before we execute the body of the assignment operator."
  },
  {
    "objectID": "posts/move-semantics/index.html#avoiding-unnecessary-stdmove",
    "href": "posts/move-semantics/index.html#avoiding-unnecessary-stdmove",
    "title": "Move semantics and perfect forwarding",
    "section": "Avoiding unnecessary std::move()",
    "text": "Avoiding unnecessary std::move()\nAs we saw, returning a local object by value automatically uses move semantics if supported. However, to be safe, programmers might try to force this with an explicit std::move():\nstd::string foo()\n{\n    std::string s;\n    // do something\n    // ...\n    return std::move(s);    //Bad, don't do this\n}\nRemember that std::move() is just a static_cast to an rvalue reference. Therefore, std::move is an expression that yields the type std::string&&. However, this no longer matches the return type and therefore disables return value optimization, which usually allows the returned object to be used as a return value. For types where move semantics is not implemented, this might even force the copying of the return value instead of just using the returned object as the return value."
  },
  {
    "objectID": "posts/move-semantics/index.html#value-categories-in-detail",
    "href": "posts/move-semantics/index.html#value-categories-in-detail",
    "title": "Move semantics and perfect forwarding",
    "section": "Value categories in detail",
    "text": "Value categories in detail\nTo compile an expression or statement it does not only matter whether the involved types fit. For example, you cannot assign an int to an int, when on the left hand side of the assignment, an int literal is used.\nint i{};\ni = 88;     //Ok\n//88 = i;   //Error\nFor this reason, each expression in C++ has a value category. Besides the type, the value category is essential to decide what you can do with an expression.\n\nValue categories since C++11\n\n\n\nValue Categories\n\n\nWe have the following primary categories:\n\nlvalue (Locator Value)\nprvalue (Pure Readable Value)\nxvalue (Expiring Value)\n\nThe composite categories are: - glvalue (generalized lvalue) as a common term for lvalue or xvalue - rvalue as a common term for xvalue or prvalue\nIntuitively, it’s easy to understand the primary value categories, if you look at the following diagram:\n\n\n\nValue Categories\n\n\nFor example,\nclass X{\n};\n\nX v;\nconst X c;\n\nf(v);   //passes a modifiable lvalue\nf(c);   //passes a non-modifiable lvalue\nf(X()); //passes a prvalue (old syntax of creating a temporary)\nf(X{}); //passes a prvalue (new syntax of creating a temporary)\nf(std::move(v));  //passes an xvalue\nRoughly speaking, as a rule of thumb:\n\nAll names used as expressions are lvalues.\nAll string literals used as expressions are lvalues.\nAll non-string literals used as expressions are prvalues.\nAll temporaries without a name (especially objects returned by value) are prvalues.\nAll objects marked with a std::move are xvalues.\n\n\n\nCopy Elison since C++17\nC++17 added mandates to the standard, formally known as :\n\nGuaranteed copy elison\nGuraranteed return value optimization\nCopy evasion\n\nIf, in an initialization of an object, when the initializer expression is prvalue of the same class type as the variable type, copy elison is guaranteed.\n#include &lt;iostream&gt;\n\nclass T{\n    public:\n    T(){ std::cout &lt;&lt; \"c'tor T()\\n\";}\n    T(const T& t){ std::cout &lt;&lt; \"c'tor T(const T& t)\\n\";}\n    T(T&& t){ std::cout &lt;&lt; \"c'tor T(T&& t)\\n\";}\n};\nT x{T{}};\nIn C++17, this is equivalent to T x{};. The default constructor is invoked only once.\nSimilarly, if, in a return statement the operand is a prvalue of the same class type as the function return type, copy elison is guaranteed.\nT func()\n{\n    return T{};\n}\n\nT x{func()}; //Only one default construction of T allowed here\nUnder the rules of C++17, under the hood, a prvalue will be used only as unmaterialized recipe of an object, until actual materialization is required.\nA prvalue is an expression whose evaluation initializes/materializes an object. This is called as temporary materialization conversion.\nclass  T{\n    public:\n    T(){\n        std::cout &lt;&lt; \"c'tor T()\\n\";\n    }\n    //delete move and copy constructors\n    T(const T& other) = delete;\n    T(T&& other) = delete;\n}\n\nT make(){\n    //Creates the first temporary (pre C++17)\n    return T{};\n}\n\nint main(){\n    // Construct the second temporary (pre C++17)\n    // Copy/move temporary into N using the = operator (pre C++17)\n    T t = make();\n    return 0;\n}\nPre C++17, the function make() would construct a temporary within its scope. This temporary would then be copied/moved into another temporary within the main scope. Finally, the operator= would build t via copy/move construction. All of this temporary business would be elided by (RVO) by any decent compiler resulting in make() constructing a single object within t. However, this elison is somewhat optional, so the compiler must also demand that copy and move constructors exist, just in case. The above code does not compile with any pre C++17 compiler.\nPost C++17, make() creates an object of type T within t. Avoiding excessive use of temporary objects is now a language feature and the reliance on compiler optimization is removed. The above code does compiler with a post C++17 compiler.\n\n\nValue Categories since C++17\nC++17 has the same value categories but clarified the semantic meaning of the value categories as described in the figure above.\nThe key approach for explaining value categories now is that in general, we have two major kinds of expressions:"
  },
  {
    "objectID": "posts/move-semantics/index.html#perfect-forwarding",
    "href": "posts/move-semantics/index.html#perfect-forwarding",
    "title": "Move semantics and perfect forwarding",
    "section": "Perfect Forwarding",
    "text": "Perfect Forwarding\n\nMotivation for perfect forwarding\nConsider a function that declares the parameter as rvalue reference:\nvoid f(std::string&& s)\n{\n    // Do something\n    std::cout &lt;&lt; \"string s : \" &lt;&lt; s &lt;&lt; \"\\n\";\n}\nAs we’ve learned, we can only pass rvalues to this function:\nstd::string s{\"hello\"};\n// f(s);                // Error : passing an lvalue to an rvalue ref\nf(std::move(s));        // okay, passing an xvalue\nf(std::string(\"world\"));// okay, passing a prvalue\nHowever, when we use the parameter s inside the function f(std::string&&), we are dealing with an object that has a name. This means that we use s as an lvalue. We can do only what we are allowed to do with an lvalue. This means that we cannot call our function recursively.\nvoid f(std::string&& s)\n{\n    // Do something\n    std::cout &lt;&lt; \"string s : \" &lt;&lt; s &lt;&lt; \"\\n\";\n    // f(s);    // Error: passing an lvalue to an rvalue reference\n}\nWe have to mark s with std::move() again:\nvoid f(std::string&& s)\n{\n    // Do something\n    std::cout &lt;&lt; \"string s : \" &lt;&lt; s &lt;&lt; \"\\n\";\n    f(std::move(s));    // Ok, passing an xvalue\n}\nThis is the formal specification of the rule that move semantics is not passed through.\nTo forward an object that is passed with move semantics to a function, it not only has to be bound to an rvalue reference; you have to use std::move() again to forward its move semantics to another function.\nFor example:\nclass X{\n    // ...\n};\n\n//forward declarations\nvoid foo(const X&);     //for constant values (read-only access)\nvoid foo(X&);           //for variable values (out parameters)\nvoid foo(X&&);          //for values that are no longer used(move semantics)\nWe have the following rules when calling these functions:\nX v;\nconst X c;\n\nfoo(v);     //calls foo(X&)\nfoo(c);     //calls foo(const X&)\nfoo(X{});   //calls foo(X&&)\nfoo(std::move(v))   //calls foo(X&&)\nfoo(std::move(c))   //calls foo(const X&)\nNow, assume that we want to call foo() for the same arguments indirectly via a helper function callFoo(). That helper function would also need the three overloads.\nvoid callFoo(const X& arg){     //arg binds to all const objects\n    foo(arg);                   //calls foo(const X&)\n}\n\nvoid callFoo(X& arg)            //arg binds to lvalues\n{\n    foo(arg);                   //calls foo(&)\n}\n\nvoid callFoo(X&& arg){          //arg binds to rvalues\n    foo(std::move(arg));        //needs std::move() to call foo(X&&)\n}\nIn all cases, arg is used as an lvalue (being an object with a name). The first version forwards it as a const object, but the other two cases implement two different ways to forward the non-const argument.\n\nArguments declared as lvalue references (that bind to objects that do not have move semantics) are passed as they are.\nArguments declared as rvalue references (that bind to objects that have move semantics) are passed with std::move.\n\nThis allows us to forward move semantics perfectly: for any argument that is passed with move semantics, we keep the move semantics; but we do not add move semantics when we get an argument that does not have it.\nOnly with this implementation is the use of callFoo to call foo transparent.\nX v;\nconst X c;\n\ncallFoo(v);     //calls foo(X&)\ncallFoo(c);     //calls foo(const X&)\ncallFoo(X{});   //calls foo(X&&)\ncallFoo(std::move(v))   //calls foo(X&&)\ncallFoo(std::move(c))   //calls foo(const X&)\nRemember that an rvalue passed to an rvalue reference becomes an lvalue when used, which means that we need std::move() to pass it as an rvalue again. However, we cannot use std::move() everywhere. For the other overloads, using std::move() would call the overload of foo() for rvalue references when an lvalue is passed.\nFor perfect forwarding in generic code, we would always need all these overloads for each parameter. To support all combinations, this means having \\(3^2 = 9\\) overloads for \\(2\\) generic arguments and \\(3^3 = 27\\) overloads for \\(3\\) generic arguments.\nTherefore, C++11 introduced a special way to perfectly forward without any overloads but still keeping the type and the value category.\n\n\nImplementing perfect forwarding\nTo avoid overloading functions for parameters with different value categories, C++ introduced the mechanism of perfect forwarding. You need three things:\n\nTake the call parameter as a pure rvalue reference (delcared with && but without const or volatile)\nThe type of the parameter has to be a template parameter of the function.\nWhen forwarding the parameter to another function, use a helper function called std::forward&lt;&gt;() which is declared in &lt;utility&gt;.\n\nYou have to implement a function that perfectly forwards an argument as follows:\ntemplate&lt;typename T&gt;\nvoid callFoo(T&& arg)\n{\n    foo(std::forward&lt;T&gt;(arg));\n}\nstd::forward&lt;&gt;() is defined as a conditional std::move(), so that we get the same behavior as the three (or four) overloads of callFoo() above:\n\nIf we pass an rvalue to arg, we have the same effect as calling foo(std::move(arg)).\nIf we pass an lvalue to arg, we have the same effect as calling foo(arg).\n\nWhat exactly is happening here, is pretty tricky and needs a careful explanation.\n\n\nUniversal and Forwarding references\nFirst note that we declare arg as an rvalue reference parameter:\ntemplate&lt;typename T&gt;\nvoid callFoo(T&& arg)\nThis might give the impression that the rules of rvalue references apply. However, that is not the case. An rvalue reference (not qualified with const or volatile) of a function template parameter does not follow the rules of ordinary rvalue references. It is a different thing.\n\nTwo terms : Universal and Forwarding Reference\nSuch a reference is called a universal reference. Unfortunately, there is also another term for it that is mainly used in the C++ standard: forwarding reference. There is no difference between these two terms, it is just that we have a historical mess here with two established terms that mean the same thing. Both terms describe basic aspects of universal/forwarding references:\n\nThey can universally bind to objects of all types(const and non-const) and value categories.\nThey are usually used to forward arguments; but note that this is not the only use (one reason for me to prefer the term universal reference)\n\n\n\nUniversal references bind to all value categories\nThe important feature of universal references is that they can bind to objects and expressions of any value category:\ntemplate&lt;typename T&gt;\nvoid callFoo(T&& arg);  //arg is universal/forwarding reference\n\nX v;\nconst X c;\ncallFoo(v);             //ok\ncallFoo(c);             //ok\ncallFoo(X{});           //ok\ncallFoo(std::move(v));  //ok\ncallFoo(std::move(c));  //ok\nIn addition, they preserve the const-ness and value category (whether we have an rvalue or an lvalue) of the object they are bound to:\n#include &lt;iostream&gt;\n#include &lt;type_traits&gt;\nclass Widget{};\n\ntemplate &lt;typename T&gt;\nvoid f(T&& arg){\n    std::cout &lt;&lt; std::boolalpha;\n\n    if (std::is_same&lt;T&&, Widget&&gt;::value)\n    {\n        std::cout &lt;&lt; \"T&& = Widget&\\n\";\n    }\n    else if (std::is_same&lt;T&&, const Widget&&gt;::value)\n    {\n        std::cout &lt;&lt; \"T&& = const Widget&\\n\";\n    }\n    else if(std::is_same&lt;T&&, Widget&&&gt;::value)\n    {\n        std::cout &lt;&lt; \"T&& = Widget&&\\n\";\n    }\n    else if(std::is_same&lt;T&&,const Widget&&&gt;::value)\n    {\n        std::cout &lt;&lt; \"T&& = const Widget&&\\n\";\n    }\n}\n\nint main()\n{\n    Widget w;\n    const Widget cw;\n\n    std::cout &lt;&lt; \"Calling f(w)\\n\"; \n    f(w);\n    std::cout &lt;&lt; \"Calling f(cw)\\n\"; \n    f(cw);\n    std::cout &lt;&lt; \"Calling f(std::move(w))\\n\"; \n    f(std::move(w));\n    std::cout &lt;&lt; \"Calling f(std::move(cw))\\n\"; \n    f(std::move(cw));\n    return 0;\n}\nCompiler Explorer\nstdout:\nCalling f(w)\nT&& = Widget&\nCalling f(cw)\nT&& = const Widget&\nCalling f(std::move(w))\nT&& = Widget&&\nCalling f(std::move(cw))\nT&& = const Widget&&\nBy rule, the template parameter type T, is deduced to be:\n\nAn lvalue reference if we pass an lvalue.\nAn rvalue reference if we pass to an rvalue.\n\nNote that, a generic rvalue reference that is qualified with const (or volatile) is not a universal reference.\nThe rules of reference collapsing are now applied:\n\nWidget& && becomes Widget&\nWidget&& & becomes Widget&\nWidget& && becomes Widget &\nWidget&& && becomes Widget&&\n\nIn the function call f( w ), we are passing an lvalue, so the template parameter T is deduced to be an lvalue reference, Widget&. Therefore, T&& is Widget& && and by the rules of reference collapsing, this collapses to Widget&.\nSimilarly, in the function call f( Widget{} ), we are passing an rvalue, so the template parameter T is deduced to be an rvalue reference, Widget&&. Therefore, T&& is Widget&& && which collapses to Widget&&.\n\n\nstd::forward&lt;&gt;()\nstd::forward&lt;&gt;() conditionally casts its input into an rvalue reference.\n\nIf the given input expression is an lvalue, it is cast to an lvalue reference.\nIf the given input expression is an rvalue, it is cast to an rvalue reference.\n\nstd::forward does not forward anything.\nA really cool use-case of perfect forwarding is the std::make_unique() function. std::make_unique&lt;T&gt;() must invoke the underlying constructor. However, whilst doing so, it must preserve the const-ness and the value category of the arguments passed to the constructor.\nHere is a quick code snippet:\n// Let's say that we would like to implement the make_unique()\n// function that invokes the underlying constructor - either move\n// or copy based on the arguments\n#include &lt;memory&gt;\n#include &lt;iostream&gt;\n\nclass X{\n    public:\n        X(){}\n        X(const X& x){ std::cout &lt;&lt; \"copy c'tor\\n\";}\n        X(X&& x) { std::cout &lt;&lt; \"move c'tor\\n\"; }\n};\n\n\ntemplate&lt;typename T, typename... Args&gt;\nstd::unique_ptr&lt;T&gt; make_unique(Args&&... args){\n    T* ptr_t = new T(std::forward&lt;Args&gt;(args)...);\n    return std::unique_ptr&lt;T&gt;(ptr_t);\n}\n\nint main()\n{\n    X x1{};\n    std::unique_ptr&lt;X&gt; x2{make_unique&lt;X&gt;(x1)};  //calls X(const X&)\n    std::unique_ptr&lt;X&gt; x3{make_unique&lt;X&gt;(X{})}; //calls X(X&&)\n    return 0;\n}"
  },
  {
    "objectID": "posts/norms/index.html",
    "href": "posts/norms/index.html",
    "title": "Norms",
    "section": "",
    "text": "Consider geometric vectors \\(\\mathbf{x}, \\mathbf{y} \\in \\mathbf{R}^2\\). The scalar product(dot-product) of these two vectors is defined by:\n\\[\n\\mathbf{x} \\cdot \\mathbf{y} = x_1 y_1 + x_2 y_2\n\\]\nAn inner-product is a mathematical generalization of the dot-product.\n\n\\[\n\\newcommand{\\norm}[1]{\\left\\lVert#1\\right\\rVert}\n\\newcommand{\\normp}[2]{\\left\\lVert\\mathbf{#1}\\right\\rVert_{#2}}\n\\newcommand\\inner[2]{\\left\\langle #1, #2 \\right\\rangle}\n\\newcommand{\\bf}[1]{\\mathbf{#1}}\n\\newcommand{\\R}{\\mathbf{R}}\n\\newcommand{\\RR}[1]{\\mathbf{R}^2}\n\\newcommand{\\RRR}[1]{\\mathbf{R}^3}\n\\newcommand{\\C}{\\mathbf{C}}\n\\newcommand{\\CC}[1]{\\mathbf{C}^2}\n\\newcommand{\\CCC}[1]{\\mathbf{C}^3}\n\\]\n\n\nDefinition 1 (Inner product) Let \\(V\\) be a vector space and \\(F\\) be a scalar field, which is either \\(\\bf{R}\\) or \\(\\bf{C}\\). Let \\(\\inner{\\cdot}{\\cdot}\\) be a map from \\(V\\times V \\to F\\). Then, \\(\\inner{\\cdot}{\\cdot}\\) is an inner product if for all \\(\\bf{u},\\bf{v}, \\bf{w} \\in V\\), it satisfies:\n\n\n\\[\n\\inner{\\bf{v}}{\\bf{v}} \\geq 0 \\quad \\text { and } \\quad  \\inner{\\bf{v}}{\\bf{v}} = 0 \\Longleftrightarrow \\bf{v} = \\bf{0}\n\\]\n\n\n\n\\[\n\\inner{\\bf{u} + \\bf{v}}{\\bf{w}} = \\inner{\\bf{u}}{\\bf{w}} + \\inner{\\bf{v}}{\\bf{w}}\n\\]\n\n\n\n\\[\n\\begin{align*}\n\\inner{\\alpha \\bf{v}}{\\bf{w}} &= \\overline{\\alpha} \\inner{\\bf{v}}{\\bf{w}}\\\\\n\\inner{\\bf{v}}{\\alpha \\bf{w}} &= \\alpha \\inner{\\bf{v}}{\\bf{w}}\n\\end{align*}\n\\]\n\n\n\n\\[\n\\inner{\\bf{v}}{\\bf{w}} = \\overline{\\inner{\\bf{w}}{\\bf{v}}}\n\\]\n\n\nThe most important example of inner-product is the Euclidean inner product on \\(\\C^n\\). Let \\(\\bf{w},\\bf{z}\\) be (column) vectors in \\(\\C^n\\).\n\\[\n\\inner{\\bf{w}}{\\bf{z}} = (\\bf{w}^H \\bf{z}) =  \\overline{w_1}z_1 + \\overline{w_2}z_2 + \\ldots + \\overline{w_n} z_n\n\\]\nFirstly,\n\\[\n\\begin{align*}\n\\inner{\\bf{v} + \\bf{w}}{\\bf{z}} &= (\\bf{v} + \\bf{w})^H \\bf{z} & \\{ \\text{ Definition }\\}\\\\\n&= (\\bf{v}^H + \\bf{w}^H)\\bf{z} & \\{ \\overline{z_1 + z_2} = \\overline{z_1} + \\overline{z_2}; z_1,z_2\\in \\C \\}\\\\\n&= \\bf{v}^H \\bf{z} + \\bf{w}^H \\bf{z}\\\\\n&= \\inner{\\bf{v}}{\\bf{z}} + \\inner{\\bf{w}}{\\bf{z}}\n\\end{align*}\n\\]\nSo, it is additive in the first slot.\nNext, let \\(\\alpha \\in \\C\\).\n\\[\n\\begin{align*}\n\\inner{\\alpha\\bf{u}}{\\bf{v}} &= (\\alpha \\bf{u})^H \\bf{v}  & \\{ \\text{ Definition }\\}\\\\\n&= \\overline{\\alpha} \\bf{u}^H \\bf{v} = \\overline{\\alpha} \\inner{\\bf{u}}{\\bf{v}}\n\\end{align*}\n\\]\nand\n\\[\n\\begin{align*}\n\\inner{\\bf{u}}{\\alpha\\bf{v}} &= (\\bf{u})^H \\bf{ \\alpha v}  & \\{ \\text{ Definition }\\}\\\\\n&= \\alpha \\bf{u}^H \\bf{v} = \\alpha \\inner{\\bf{u}}{\\bf{v}}\n\\end{align*}\n\\]\nIt is homogenous.\nFinally,\n\\[\n\\begin{align*}\n\\inner{\\bf{v}}{\\bf{w}} &= \\sum_{i=1}^n \\overline{v_i}w_i\\\\\n&= \\sum_{i=1}^n \\overline{v_i \\overline{w_i}}\\\\\n&= \\overline{\\left(\\sum_{i=1}^n \\overline{w_i} v_i\\right)}\\\\\n&= \\overline{\\inner{\\bf{w}}{\\bf{v}}}\n\\end{align*}\n\\]"
  },
  {
    "objectID": "posts/norms/index.html#inner-product",
    "href": "posts/norms/index.html#inner-product",
    "title": "Norms",
    "section": "",
    "text": "Consider geometric vectors \\(\\mathbf{x}, \\mathbf{y} \\in \\mathbf{R}^2\\). The scalar product(dot-product) of these two vectors is defined by:\n\\[\n\\mathbf{x} \\cdot \\mathbf{y} = x_1 y_1 + x_2 y_2\n\\]\nAn inner-product is a mathematical generalization of the dot-product.\n\n\\[\n\\newcommand{\\norm}[1]{\\left\\lVert#1\\right\\rVert}\n\\newcommand{\\normp}[2]{\\left\\lVert\\mathbf{#1}\\right\\rVert_{#2}}\n\\newcommand\\inner[2]{\\left\\langle #1, #2 \\right\\rangle}\n\\newcommand{\\bf}[1]{\\mathbf{#1}}\n\\newcommand{\\R}{\\mathbf{R}}\n\\newcommand{\\RR}[1]{\\mathbf{R}^2}\n\\newcommand{\\RRR}[1]{\\mathbf{R}^3}\n\\newcommand{\\C}{\\mathbf{C}}\n\\newcommand{\\CC}[1]{\\mathbf{C}^2}\n\\newcommand{\\CCC}[1]{\\mathbf{C}^3}\n\\]\n\n\nDefinition 1 (Inner product) Let \\(V\\) be a vector space and \\(F\\) be a scalar field, which is either \\(\\bf{R}\\) or \\(\\bf{C}\\). Let \\(\\inner{\\cdot}{\\cdot}\\) be a map from \\(V\\times V \\to F\\). Then, \\(\\inner{\\cdot}{\\cdot}\\) is an inner product if for all \\(\\bf{u},\\bf{v}, \\bf{w} \\in V\\), it satisfies:\n\n\n\\[\n\\inner{\\bf{v}}{\\bf{v}} \\geq 0 \\quad \\text { and } \\quad  \\inner{\\bf{v}}{\\bf{v}} = 0 \\Longleftrightarrow \\bf{v} = \\bf{0}\n\\]\n\n\n\n\\[\n\\inner{\\bf{u} + \\bf{v}}{\\bf{w}} = \\inner{\\bf{u}}{\\bf{w}} + \\inner{\\bf{v}}{\\bf{w}}\n\\]\n\n\n\n\\[\n\\begin{align*}\n\\inner{\\alpha \\bf{v}}{\\bf{w}} &= \\overline{\\alpha} \\inner{\\bf{v}}{\\bf{w}}\\\\\n\\inner{\\bf{v}}{\\alpha \\bf{w}} &= \\alpha \\inner{\\bf{v}}{\\bf{w}}\n\\end{align*}\n\\]\n\n\n\n\\[\n\\inner{\\bf{v}}{\\bf{w}} = \\overline{\\inner{\\bf{w}}{\\bf{v}}}\n\\]\n\n\nThe most important example of inner-product is the Euclidean inner product on \\(\\C^n\\). Let \\(\\bf{w},\\bf{z}\\) be (column) vectors in \\(\\C^n\\).\n\\[\n\\inner{\\bf{w}}{\\bf{z}} = (\\bf{w}^H \\bf{z}) =  \\overline{w_1}z_1 + \\overline{w_2}z_2 + \\ldots + \\overline{w_n} z_n\n\\]\nFirstly,\n\\[\n\\begin{align*}\n\\inner{\\bf{v} + \\bf{w}}{\\bf{z}} &= (\\bf{v} + \\bf{w})^H \\bf{z} & \\{ \\text{ Definition }\\}\\\\\n&= (\\bf{v}^H + \\bf{w}^H)\\bf{z} & \\{ \\overline{z_1 + z_2} = \\overline{z_1} + \\overline{z_2}; z_1,z_2\\in \\C \\}\\\\\n&= \\bf{v}^H \\bf{z} + \\bf{w}^H \\bf{z}\\\\\n&= \\inner{\\bf{v}}{\\bf{z}} + \\inner{\\bf{w}}{\\bf{z}}\n\\end{align*}\n\\]\nSo, it is additive in the first slot.\nNext, let \\(\\alpha \\in \\C\\).\n\\[\n\\begin{align*}\n\\inner{\\alpha\\bf{u}}{\\bf{v}} &= (\\alpha \\bf{u})^H \\bf{v}  & \\{ \\text{ Definition }\\}\\\\\n&= \\overline{\\alpha} \\bf{u}^H \\bf{v} = \\overline{\\alpha} \\inner{\\bf{u}}{\\bf{v}}\n\\end{align*}\n\\]\nand\n\\[\n\\begin{align*}\n\\inner{\\bf{u}}{\\alpha\\bf{v}} &= (\\bf{u})^H \\bf{ \\alpha v}  & \\{ \\text{ Definition }\\}\\\\\n&= \\alpha \\bf{u}^H \\bf{v} = \\alpha \\inner{\\bf{u}}{\\bf{v}}\n\\end{align*}\n\\]\nIt is homogenous.\nFinally,\n\\[\n\\begin{align*}\n\\inner{\\bf{v}}{\\bf{w}} &= \\sum_{i=1}^n \\overline{v_i}w_i\\\\\n&= \\sum_{i=1}^n \\overline{v_i \\overline{w_i}}\\\\\n&= \\overline{\\left(\\sum_{i=1}^n \\overline{w_i} v_i\\right)}\\\\\n&= \\overline{\\inner{\\bf{w}}{\\bf{v}}}\n\\end{align*}\n\\]"
  },
  {
    "objectID": "posts/norms/index.html#norms",
    "href": "posts/norms/index.html#norms",
    "title": "Norms",
    "section": "Norms",
    "text": "Norms\nVery often, to quantify errors or measure distances one needs to compute the magnitude(length) of a vector or a matrix. Norms are a mathematical generalization(abstraction) for length.\n\nDefinition 2 (Vector norm) Let \\(\\nu:V \\to \\mathbf{R}\\). Then, \\(\\nu\\) is a (vector) norm if for all \\(\\mathbf{x},\\mathbf{y}\\in V\\) and for all \\(\\alpha \\in \\mathbf{C}\\), \\(\\nu(\\cdot)\\) satisfies:\n\nPositive Semi-Definiteness\n\\[\\nu(\\mathbf{x}) \\geq 0, \\quad \\forall \\bf{x}\\in V\\]\nand\n\\[\\nu(\\mathbf{x})=0 \\Longleftrightarrow \\mathbf{x}=\\mathbf{0}\\]\n\n\nHomogeneity\n\\[\\nu(\\alpha \\mathbf{x}) = |\\alpha|\\nu(\\mathbf{x})\\]\n\n\nTriangle inequality\n\\[\\nu(\\mathbf{x} + \\mathbf{y}) \\leq \\nu(\\mathbf{x}) + \\nu(\\mathbf{y})\\]\n\n\n\nThe vector \\(2-\\)norm\nThe length of a vector is most commonly measured by the square root of the sum of the squares of the components of the vector, also known as the euclidean norm.\n\nDefinition 3 (Vector \\(2-\\)norm) The vector \\(2-\\) norm, \\(||\\cdot||:\\mathbf{C}^n \\to \\mathbf{R}\\) is defined for \\(\\mathbf{x}\\in\\mathbf{C}^n\\) by:\n\\[\n\\norm{\\bf{x}}_2 = \\sqrt{|\\chi_1|^2 + |\\chi_2|^2 + |\\chi_n|^2} = \\sqrt{\\sum_{i=1}^n |\\chi_i^2|}\n\\]\nEquivalently, it can be defined as:\n\\[\n\\norm{\\bf{x}}_2 = \\sqrt{\\inner{\\bf{x}}{\\bf{x}}} =  (\\bf{x}^H \\bf{x})^{1/2} = \\sqrt{\\overline{\\chi_1}\\chi_1 +\\overline{\\chi_2}\\chi_2+\\ldots+\\overline{\\chi_n}\\chi_n}\n\\]\n\nTo prove that the vector \\(2-\\)norm is indeed a valid norm(just calling it a norm, doesn’t mean it is, after all), we need a result known as the Cauchy-Schwarz inequality. This inequality relates the magnitude of the dot-product(inner-product) of two vectors to the product of their two norms : if \\(\\bf{x},\\bf{y} \\in \\R^n\\), then \\(|\\bf{x}^T \\bf{y}|\\leq \\norm{\\bf{x}}_2\\cdot\\norm{\\bf{y}}_2\\).\nBefore we rigorously prove this result, let’s review the idea of orthogonality.\n\nDefinition 4 (Orthogonal vectors) Two vectors \\(\\bf{u},\\bf{v} \\in V\\) are said to be orthogonal to each other if and only if their inner product equals zero:\n\\[\n\\inner{\\bf{u}}{\\bf{v}} = 0\n\\]\n\n\nTheorem 1 (Pythagorean Theorem) If \\(\\bf{u}\\) and \\(\\bf{v}\\) are orthogonal vectors, then\n\\[\n\\inner{\\bf{u} + \\bf{v}}{\\bf{u} + \\bf{v}} = \\inner{\\bf{u}}{\\bf{u}} + \\inner{\\bf{v}}{\\bf{v}}\n\\]\n\nProof.\nWe have:\n\\[\n\\begin{align*}\n\\inner{\\bf{u} + \\bf{v}}{\\bf{u}+\\bf{v}} &= \\inner{\\bf{u}}{\\bf{u} + \\bf{v}} + \\inner{\\bf{v}}{\\bf{u} + \\bf{v}} & \\{ \\text{ Additivity in the first slot }\\}\\\\\n&= \\overline{\\inner{\\bf{u} + \\bf{v}}{\\bf{u}}} + \\overline{\\inner{\\bf{u} + \\bf{v}}{\\bf{v}}} & \\{ \\text{ Conjugate symmetry }\\}\\\\\n&= \\overline{\\inner{\\bf{u}}{\\bf{u}}} + \\overline{\\inner{\\bf{v}}{\\bf{u}}} + \\overline{\\inner{\\bf{u}}{\\bf{v}}} + \\overline{\\inner{\\bf{v}}{\\bf{v}}} \\\\\n&= \\inner{\\bf{u}}{\\bf{u}} + \\inner{\\bf{u}}{\\bf{v}} + \\inner{\\bf{v}}{\\bf{u}} + \\inner{\\bf{v}}{\\bf{v}} \\\\\n&= \\inner{\\bf{u}}{\\bf{u}} + 0 + 0 + \\inner{\\bf{v}}{\\bf{v}} & \\{ \\bf{u} \\perp \\bf{v}\\}\\\\\n&= \\inner{\\bf{u}}{\\bf{u}} + \\inner{\\bf{v}}{\\bf{v}}\n\\end{align*}\n\\]\nThis closes the proof. \\(\\blacksquare\\)\nIn the special case that \\(V=\\C^n\\) or \\(V=\\R^n\\), the pythagorean theorem reduces to:\n\\[\n\\norm{\\bf{u} + \\bf{v}}_2^2 = \\norm{\\bf{u}}_2^2 + \\norm{\\bf{v}}_2^2\n\\]"
  },
  {
    "objectID": "posts/norms/index.html#cauchy-schwarz-inequality",
    "href": "posts/norms/index.html#cauchy-schwarz-inequality",
    "title": "Norms",
    "section": "Cauchy-Schwarz Inequality",
    "text": "Cauchy-Schwarz Inequality\nSuppose \\(\\bf{u},\\bf{v}\\in V\\). We would like to write \\(\\bf{u}\\) as a scalar multiple of \\(\\bf{v}\\) plus a vector \\(\\bf{w}\\) orthogonal to \\(\\bf{v}\\), as suggested in the picture below. Intuitively, we would like to write an orthogonal decomposition of \\(\\bf{u}\\).\n\n%load_ext itikz\n\n\n\nShow the code\n%%itikz --temp-dir --tex-packages=tikz --tikz-libraries=arrows,arrows.meta --implicit-standalone\n\\begin{tikzpicture}[scale=2.0]\n    \\draw [-{Stealth[length=5mm]}](0.0,0.0) -- (7,0);\n    \\draw [-{Stealth[length=5mm]}] (0.0,0.0) -- (7,4);\n    \\node []  at (3.5,2.25) {\\large $\\mathbf{u}$};\n    \\draw [dashed] (7,0) -- (7,4);\n    \\node [circle,fill,minimum size = 0.5mm] at (5,0) {};\n    \\node []  at (5,-0.40) {\\large $\\mathbf{v}$};\n    \\node []  at (7,-0.40) {\\large $\\alpha\\mathbf{v}$};\n    \\node []  at (7.4,2.0) {\\large $\\mathbf{w}$};\n\\end{tikzpicture}\n\n\n\n\n\nTo discover how to write \\(\\bf{u}\\) as a scalar multiple of \\(\\bf{v}\\) plus a vector orthogonal to \\(\\bf{v}\\), let \\(\\alpha\\) denote a scalar. Then,\n\\[\n\\bf{u} = \\alpha \\bf{v} + (\\bf{u} - \\alpha \\bf{v})\n\\]\nThus, we need to choose \\(\\alpha\\) so that \\(\\bf{v}\\) and \\(\\bf{w} = \\bf{u} - \\alpha{v}\\) are mutually orthogonal. Thus, we must set:\n\\[\n\\inner{\\bf{u} - \\alpha\\bf{v}}{\\bf{v}} = \\inner{\\bf{u}}{\\bf{v}} - \\alpha \\inner{\\bf{v}}{\\bf{v}} = 0\n\\]\nThe equation above shows that we choose \\(\\alpha\\) to be \\(\\inner{\\bf{u}}{\\bf{v}}/\\inner{\\bf{v}}{\\bf{v}}\\) (assume that \\(\\bf{v} \\neq \\bf{0}\\) to avoid division by 0). Making this choice of \\(\\alpha\\), we can write:\n\\[\n\\bf{u} = \\frac{\\inner{\\bf{u}}{\\bf{v}}}{\\inner{\\bf{v}}{\\bf{v}}}\\bf{v} + \\left(\\bf{u} - \\frac{\\inner{\\bf{u}}{\\bf{v}}}{\\inner{\\bf{v}}{\\bf{v}}}\\bf{v}\\right)\n\\tag{1}\\]\nThe equation above will be used in the proof the Cauchy-Schwarz inequality, one of the most important inequalities in mathematics\n\nTheorem 2 (Cauchy-Schwarz Inequality) Let \\(\\bf{x},\\bf{y}\\in V\\). Then\n\\[\n|\\inner{\\bf{u}}{\\bf{v}}|^2 \\leq \\inner{\\bf{u}}{\\bf{u}}\\inner{\\bf{v}}{\\bf{v}}\n\\tag{2}\\]\n\nProof.\nLet \\(\\bf{u},\\bf{v} \\in V\\). If \\(\\bf{v} = \\bf{0}\\), then both sides of Equation 2 equal \\(0\\) and the inequality holds. Thus, we assume that \\(\\bf{v}\\neq \\bf{0}\\). Consider the orthogonal decomposition:\n\\[\n\\bf{u} = \\frac{\\inner{\\bf{u}}{\\bf{v}}}{\\inner{\\bf{v}}{\\bf{v}}} \\bf{v} + \\bf{w}\n\\]\nwhere \\(\\bf{w}\\) is orthogonal to \\(\\bf{v}\\) (\\(\\bf{w}\\) is taken to be the second term on the right hand side of Equation 1). By the Pythagorean theorem:\n\\[\n\\begin{align*}\n\\inner{\\bf{u}}{\\bf{u}} &= \\inner{\\frac{\\inner{\\bf{u}}{\\bf{v}}}{\\inner{\\bf{v}}{\\bf{v}}} \\bf{v}}{\\frac{\\inner{\\bf{u}}{\\bf{v}}}{\\inner{\\bf{v}}{\\bf{v}}} \\bf{v}}+\\inner{\\bf{w}}{\\bf{w}}\\\\\n&= \\overline{\\left(\\frac{\\inner{\\bf{u}}{\\bf{v}}}{\\inner{\\bf{v}}{\\bf{v}}}\\right)}\\left(\\frac{\\inner{\\bf{u}}{\\bf{v}}}{\\inner{\\bf{v}}{\\bf{v}}}\\right)\\inner{\\bf{v}}{\\bf{v}} + \\inner{\\bf{w}}{\\bf{w}}\\\\\n&= \\frac{\\overline{\\inner{\\bf{u}}{\\bf{v}}}\\inner{\\bf{u}}{\\bf{v}}}{\\overline{\\inner{\\bf{v}}{\\bf{v}}}} + \\inner{\\bf{w}}{\\bf{w}}\\\\\n&= \\frac{|\\inner{\\bf{u}}{\\bf{v}}|^2}{\\inner{\\bf{v}}{\\bf{v}}} + \\inner{\\bf{w}}{\\bf{w}}\n\\end{align*}\n\\]\nSince \\(\\inner{\\bf{w}}{\\bf{w}} \\geq 0\\), it follows that:\n\\[\n\\inner{\\bf{u}}{\\bf{u}} \\geq \\frac{|\\inner{\\bf{u}}{\\bf{v}}|^2}{\\inner{\\bf{v}}{\\bf{v}}}\n\\]\nConsequently, we have:\n\\[\n|\\inner{\\bf{u}}{\\bf{v}}|^2 \\leq \\inner{\\bf{u}}{\\bf{u}}\\inner{\\bf{v}}{\\bf{v}}\n\\]\nThis closes the proof. \\(\\blacksquare\\)\nIn the special case, that \\(V=\\R^n\\) or \\(V=\\C^n\\), we have:\n\\[\n|\\inner{\\bf{u}}{\\bf{v}}| \\leq \\norm{\\bf{u}}_2 \\norm{\\bf{v}}_2\n\\]"
  },
  {
    "objectID": "posts/norms/index.html#euclidean-norm",
    "href": "posts/norms/index.html#euclidean-norm",
    "title": "Norms",
    "section": "Euclidean Norm",
    "text": "Euclidean Norm\n\nProposition 1 (Well-definedness of the Euclidean norm) Let \\(\\norm{\\cdot}:\\mathbf{C}^n \\to \\mathbf{C}\\) be the euclidean norm. Our claim is, it is well-defined.\n\nProof.\nLet \\(\\bf{z} = (z_1,z_2,\\ldots,z_n) \\in \\C^n\\). Clearly, it is positive semi-definite.\n\\[\n\\begin{align*}\n\\norm{\\bf{z}}_2 = \\bf{z}^H \\bf{z} &= \\overline{z_1} z_1 +\\overline{z_2}z_2 + \\ldots + \\overline{z_n} z_n\\\\\n&= \\sum_{i=1}^n |z_i|^2 \\geq 0\n\\end{align*}\n\\]\nIt is also homogenous. Let \\(\\alpha \\in \\C\\).\n\\[\n\\begin{align*}\n\\norm{\\alpha \\bf{z}}_2 &= \\norm{(\\alpha z_1, \\alpha z_2,\\ldots,\\alpha z_n)}_2\\\\\n&=\\sqrt{\\sum_{i=1}^n |\\alpha z_i|^2}\\\\\n&=|\\alpha|\\sqrt{\\sum_{i=1}^n |z_i|^2} \\\\\n&= |\\alpha|\\norm{\\bf{z}}_2\n\\end{align*}\n\\]\nLet’s verify, if the triangle inequality is satisfied. Let \\(\\bf{x}, \\bf{y}\\in\\C^n\\) be arbitrary vectors.\n\\[\n\\begin{align*}\n\\norm{\\bf{x} + \\bf{y}}_2^2 &= |(\\bf{x} + \\bf{y})^H(\\bf{x} + \\bf{y})|\\\\\n&= |(\\bf{x}^H + \\bf{y}^H)(\\bf{x} + \\bf{y})|\\\\\n&= |\\bf{x}^H \\bf{x} + \\bf{y}^H \\bf{y} + \\bf{y}^H \\bf{x} + \\bf{x}^H \\bf{y}|\\\\\n&\\leq \\norm{\\bf{x}}_2^2 + \\norm{\\bf{y}}_2^2 + |\\inner{\\bf{y}}{\\bf{x}}| + |\\inner{\\bf{x}}{\\bf{y}}|\\\\\n&\\leq \\norm{\\bf{x}}_2^2 + \\norm{\\bf{y}}_2^2 + \\norm{\\bf{y}}_2 \\norm{\\bf{x}}_2  + \\norm{\\bf{x}}_2 \\norm{\\bf{y}}_2 & \\{ \\text{ Cauchy-Schwarz } \\}\\\\\n&\\leq \\norm{\\bf{x}}_2^2 + \\norm{\\bf{y}}_2^2 +  2\\norm{\\bf{x}}_2 \\norm{\\bf{y}}_2\\\\\n&= (\\norm{\\bf{x}}_2 + \\norm{\\bf{y}}_2)^2\n\\end{align*}\n\\]\nConsequently, \\(\\norm{\\bf{x} + \\bf{y}}_2 \\leq \\norm{\\bf{x}}_2 + \\norm{\\bf{y}}_2\\)."
  },
  {
    "objectID": "posts/norms/index.html#the-vector-1-norm",
    "href": "posts/norms/index.html#the-vector-1-norm",
    "title": "Norms",
    "section": "The vector \\(1-\\)norm",
    "text": "The vector \\(1-\\)norm\n\nDefinition 5 (The vector \\(1-\\)norm) The vector \\(1\\)-norm, \\(\\norm{\\cdot}_1 : \\C^n \\to \\R\\) is defined for all \\(\\bf{x}\\in\\C^n\\) by:\n\\[\n\\norm{\\bf{x}}_1 = |\\chi_1| + |\\chi_2| + \\ldots + |\\chi_n| =\\sum_{i=1}^n |\\chi_i|\n\\]\n\n\nTheorem 3 The vector \\(1\\)-norm is well-defined.\n\nProof.\nPositive semi-definitess.\nThe absolute value of complex numbers is non-negative.\n\\[\n\\norm{\\bf{x}}_1 = |\\chi_1| + |\\chi_2| + \\ldots + |\\chi_n| \\geq |\\chi_i| \\geq 0\n\\]\nHomogeneity.\n\\[\n\\norm{\\alpha\\bf{x}}_1 = \\sum_{i=1}^{n}|\\alpha \\chi_i| = |\\alpha| \\sum_{i=1}^{n}|\\chi_i| = |\\alpha| \\norm{\\bf{x}}_1\n\\]\nTriangle Inequality.\n\\[\n\\begin{align*}\n\\norm{\\bf{x} + \\bf{y}} &= \\norm{(\\chi_1 + \\psi_1, \\ldots,\\chi_n + \\psi_n)}_1\\\\\n&= \\sum_{i=1}^n |\\chi_i + \\psi_i|\\\\\n&\\leq \\sum_{i=1}^n |\\chi_i| + |\\psi_i| & \\{ \\text{ Triangle inequality for complex numbers }\\}\\\\\n&= \\sum_{i=1}^n |\\chi_i| + \\sum_{i=1}^{n} |\\psi_i| & \\{ \\text{ Commutativity }\\}\\\\\n&= \\norm{\\bf{x}}_1 + \\norm{\\bf{y}}_1\n\\end{align*}\n\\]\nHence, the three axioms are satisfied. \\(\\blacksquare\\)"
  },
  {
    "objectID": "posts/norms/index.html#jensens-inequality",
    "href": "posts/norms/index.html#jensens-inequality",
    "title": "Norms",
    "section": "Jensen’s inequality",
    "text": "Jensen’s inequality\n\nConvex functions and combinations\nA function \\(f\\) is said to be convex on over an interval \\(I\\), if for all \\(x_1,x_2 \\in I\\), and every \\(p \\in [0,1]\\), we have:\n\\[\nf(px_1 + (1-p)x_2) \\leq pf(x_1) + (1-p)f(x_2)\n\\]\nIn other words, all chords(secants) joining any two points on \\(f\\), lie above the graph of \\(f\\). Note that, if \\(0 \\leq p \\leq 1\\), then \\(\\min(x_1,x_2) \\leq px_1 + (1-p)x_2 \\leq \\max(x_1,x_2)\\). More generally, for non-negative real numbers \\(p_1, p_2, \\ldots, p_n\\) summing to one, that is, satisfying \\(\\sum_{i=1}^n p_i = 1\\), and for any points \\(x_1,\\ldots,x_n \\in I\\), the point \\(\\sum_{i=1}^n \\lambda_i x_i\\) is called a convex combination of \\(x_1,\\ldots,x_n\\). Since:\n\\[ \\min(x_1,\\ldots,x_n) \\leq \\sum_{i=1}^n p_i x_i \\leq \\max(x_1,\\ldots,x_n)\\]\nevery convex combination of any finite number of points in \\(I\\) is again a point of \\(I\\).\nIntuitively, \\(\\sum_{i=1}^{n}p_i x_i\\) simply represents the center of mass of the points \\(x_1,\\ldots,x_n\\) with weights \\(p_1,\\ldots,p_n\\).\n\n\nProving Jensen’s inequality\nJensen’s inequality named after the Danish engineer Johan Jensen (1859-1925) can be stated as follows:\n\nTheorem 4 Let \\(n \\in \\bf{Z}_+\\) be a positive integer and let \\(f:I \\to \\R\\) be a convex function over the interval \\(I \\subseteq \\R\\). For any (not necessarily distinct) points \\(x_1,\\ldots,x_n \\in I\\), and non-negative real numbers \\(p_1,\\ldots,p_n \\in \\R\\) summing to one,\n\\[\nf(\\sum_{i=1}^n p_i x_i) \\leq \\sum_{i=1}^n p_i f(x_i)\n\\]\n\nProof.\nWe proceed by induction. Since \\(f\\) is convex, by definition, \\(\\forall x_1,x_2 \\in I\\), and any \\(p_1,p_2\\in \\R\\), such that \\(p_1 + p_2 = 1\\), we have \\(f(p_1 x_1 + p_2 x_2) \\leq p_1 f(x_1) + p_2 f(x_2)\\). So, the claim is true for \\(n=2\\).\nInductive hypothesis. Assume that \\(\\forall x_1,\\ldots,x_{k} \\in I\\) and any \\(p_1,\\ldots,p_k \\in \\R\\), such that \\(\\sum_{i=1}^k p_i = 1\\), we have \\(f(\\sum_{i=1}^k p_i x_i) \\leq \\sum_{i=1}^k p_i f(x_i)\\).\nClaim. The Jensen’s inequality holds for \\(k+1\\) points in \\(I\\).\nProof.\nLet \\(x_1,\\ldots,x_k, x_{k+1}\\) be arbitrary points in \\(I\\) and consider any convex combination of these points \\(\\sum_{i=1}^{k+1}p_i x_i\\), \\(p_i \\in [0,1], i \\in \\{1,2,3,\\ldots,k+1\\}, \\sum_{i=1}^{k+1}p_i = 1\\).\nDefine:\n\\[\nz := \\frac{p_1 x_1 + p_2 x_2 + \\ldots + p_k x_k}{\\sum_{i=1}^k p_i}\n\\]\nSince, \\(z\\) is a convex combination of \\(\\{x_1,\\ldots,x_k\\}\\), \\(z \\in I\\). Moreover, by the inductive hypothesis, since \\(f\\) is convex,\n\\[\n\\begin{align*}\nf(z) &= f\\left(\\frac{p_1 x_1 + p_2 x_2 + \\ldots + p_k x_k}{\\sum_{i=1}^k p_i}\\right)\\\\\n&\\leq \\frac{p_1}{\\sum_{i=1}^k p_i}f(x_1) + \\frac{p_2}{\\sum_{i=1}^k p_i}f(x_2) + \\ldots + \\frac{p_k}{\\sum_{i=1}^k p_i}f(x_k) \\\\\n&= \\frac{p_1}{1-p_{k+1}}f(x_1) + \\frac{p_2}{1-p_{k+1}}f(x_2) + \\ldots + \\frac{p_k}{1-p_{k+1}}f(x_k) \\\\\n\\end{align*}\n\\]\nSince \\(0 \\leq 1 - p_{k+1} \\leq 1\\), we deduce that:\n\\[\n(1 - p_{k+1})f(z) \\leq p_1 f(x_1) + \\ldots + p_k f(x_k)\n\\]\nWe have: \\[\n\\begin{align*}\nf(p_1 x_1 + \\ldots + p_k x_k + p_{k+1} x_{k+1}) &= f((1-p_{k+1})z + p_{k+1}x_{k+1})\\\\\n&\\leq (1-p_{k+1})f(z) + p_{k+1}f(x_{k+1}) & \\{ \\text{ Jensen's inequality for }n=2\\}\\\\\n&\\leq p_1 f(x_1) + \\ldots + p_k f(x_k) + p_{k+1}f(x_{k+1}) & \\{ \\text{ Deduction from the inductive hypothesis }\\}\n\\end{align*}\n\\]\nThis closes the proof. \\(\\blacksquare\\)"
  },
  {
    "objectID": "posts/norms/index.html#youngs-inequality",
    "href": "posts/norms/index.html#youngs-inequality",
    "title": "Norms",
    "section": "Young’s Inequality",
    "text": "Young’s Inequality\nYoung’s inequality is named after the English mathematician William Henry Young and can be stated as follows:\n\nTheorem 5 (Young’s inequality) For any non-negative real numbers \\(a\\) and \\(b\\) and any positive real numbers \\(p,q\\) satisfying \\(\\frac{1}{p} + \\frac{1}{q}=1\\), we have:\n\\[\nab \\leq \\frac{a^p}{p} + \\frac{b^q}{q}\n\\]\n\nProof.\nLet \\(f(x) = \\log x\\). Since \\(f\\) is concave, we can reverse the Jensen’s inequality. Consequently:\n\\[\n\\begin{align*}\n\\log(\\frac{a^p}{p} + \\frac{b^q}{q}) &\\geq \\frac{1}{p}\\log a^p + \\frac{1}{q}\\log b^q\\\\\n&= \\frac{1}{p}\\cdot p \\log a + \\frac{1}{q}\\cdot q \\log b\\\\\n&= \\log (ab)\n\\end{align*}\n\\]\nSince \\(\\log x\\) is monotonic increasing,\n\\[\n\\frac{a^p}{p} + \\frac{b^q}{q} \\geq ab\n\\]\nThis closes the proof. \\(\\blacksquare\\)"
  },
  {
    "objectID": "posts/norms/index.html#holders-inequality",
    "href": "posts/norms/index.html#holders-inequality",
    "title": "Norms",
    "section": "Holder’s inequality",
    "text": "Holder’s inequality\nWe can use Young’s inequality to prove the Holder’s inequality, named after the German mathematician Otto Ludwig Holder (1859-1937).\n\nTheorem 6 (Holder’s inequality) For any pair of vectors \\(\\bf{x},\\bf{y}\\in \\C^n\\), and for any positive real numbers satisfying \\(p\\) and \\(q\\), we have \\(\\frac{1}{p} + \\frac{1}{q} = 1\\) we have:\n\\[\n\\sum_{i=1}^{n}|x_i y_i| \\leq \\left(\\sum_{i=1}^n |x_i|^p\\right)^{1/p} \\left(\\sum_{i=1}^n |y_i|^q\\right)^{1/q}\n\\]\n\nProof.\nApply Young’s inequality to \\(a = \\frac{|x_i|}{\\left(\\sum_{i=1}^n |x_i|^p\\right)^{1/p}}\\) and \\(b = \\frac{|y_i|}{\\left(\\sum_{i=1}^n |y_i|^q\\right)^{1/q}}\\). We get:\n\\[\n\\begin{align*}\n\\frac{|x_i||y_i|}{\\left(\\sum_{i=1}^n |x_i|^p\\right)^{1/p}\\left(\\sum_{i=1}^n |y_i|^q\\right)^{1/q}} &\\leq \\frac{1}{p} \\frac{|x_i|^p}{\\sum_{i=1}^n |x_i|^p} + \\frac{1}{q}\\frac{|y_i|^q}{\\sum_{i=1}^n |y_i|^q}\n\\end{align*}\n\\]\nSumming on both sides, we get:\n\\[\n\\begin{align*}\n\\frac{\\sum_{i=1}^n|x_i y_i|}{\\left(\\sum_{i=1}^n |x_i|^p\\right)^{1/p}\\left(\\sum_{i=1}^n |y_i|^q\\right)^{1/q}} &\\leq \\frac{1}{p} \\frac{\\sum_{i=1}^n |x_i|^p}{\\sum_{i=1}^n |x_i|^p} + \\frac{1}{q}\\frac{\\sum_{i=1}^n|y_i|^q}{\\sum_{i=1}^n |y_i|^q}\\\\\n&= \\frac{1}{p} + \\frac{1}{q}\\\\\n&= 1\\\\\n\\sum_{i=1}^n |x_i y_i| &\\leq \\left(\\sum_{i=1}^n |x_i|^p\\right)^{1/p}\\left(\\sum_{i=1}^n |y_i|^q\\right)^{1/q}\n\\end{align*}\n\\]\nThis closes the proof. \\(\\blacksquare\\)"
  },
  {
    "objectID": "posts/norms/index.html#the-vector-p-norm",
    "href": "posts/norms/index.html#the-vector-p-norm",
    "title": "Norms",
    "section": "The vector \\(p\\)-norm",
    "text": "The vector \\(p\\)-norm\nThe vector \\(1\\)-norm and \\(2\\)-norm are special cases of the \\(p\\)-norm.\n\nDefinition 6 (\\(p\\)-norm) Given \\(p \\geq 1\\), the vector \\(p\\)-norm \\(\\norm{\\cdot}_p : \\C^n \\to \\R\\) is defined by :\n\\[\n\\norm{\\bf{x}}_p = \\left(\\sum_{i=1}^n |\\chi_i|^p\\right)^{1/p}\n\\]\n\n\nTheorem 7 The vector \\(p\\)-norm is a well-defined norm.\n\nProof.\nPositive semi-definite\nWe have:\n\\[\n\\begin{align*}\n\\norm{\\bf{x}}_p &= \\left(\\sum_{i=1}^n |\\chi_i|^p \\right)^{1/p}\\\\\n&\\geq \\left(|\\chi_i|^p \\right)^{1/p}\\\\\n&= |\\chi_i| \\geq 0\n\\end{align*}\n\\]\nHomogeneity\nWe have:\n\\[\n\\begin{align*}\n\\norm{\\alpha \\bf{x}}_p &= \\left(\\sum_{i=1}^n |\\alpha \\chi_i|^p \\right)^{1/p}\\\\\n&= \\left(\\sum_{i=1}^n |\\alpha|^p |\\chi_i|^p \\right)^{1/p}\\\\\n&= |\\alpha|\\left(\\sum_{i=1}^n |\\chi_i|^p \\right)^{1/p} &= |\\alpha|\\norm{\\bf{x}}_p\n\\end{align*}\n\\]\nTriangle Inequality\nDefine \\(\\frac{1}{q} := 1 - \\frac{1}{p}\\). \\(\\Longrightarrow (p-1)q = p\\).\nBy the Holder’s inequality: \\[\n\\begin{align*}\n\\sum_{i=1}^n |x_i||x_i + y_i|^{p-1} &\\leq \\left(\\sum_{i=1}^n |x_i|^p\\right)^{1/p} \\left(\\sum_{i=1}^n |x_i + y_i|^{(p-1)q}\\right)^{1/q}\\\\\n\\sum_{i=1}^n |y_i||x_i + y_i|^{p-1} &\\leq \\left(\\sum_{i=1}^n |y_i|^p\\right)^{1/p} \\left(\\sum_{i=1}^n |x_i + y_i|^{(p-1)q}\\right)^{1/q}\n\\end{align*}\n\\]\nSumming, we get:\n\\[\n\\begin{align*}\n\\sum_{i=1}^n |x_i + y_i|^{p} &\\leq \\left\\{\\left(\\sum_{i=1}^n |x_i|^p\\right)^{1/p}+ \\left(\\sum_{i=1}^n |y_i|^p\\right)^{1/p}\\right\\} \\left(\\sum_{i=1}^n |x_i + y_i|^{(p-1)q}\\right)^{1/q}\\\\\n&= \\left\\{\\left(\\sum_{i=1}^n |x_i|^p\\right)^{1/p}+ \\left(\\sum_{i=1}^n |y_i|^p\\right)^{1/p}\\right\\}\\left(\\sum_{i=1}^n |x_i + y_i|^{p}\\right)^{1-\\frac{1}{p}}\\\\\n\\Longrightarrow \\left(\\sum_{i=1}^n |x_i + y_i|^{p}\\right)^{1/p} &\\leq \\left\\{\\left(\\sum_{i=1}^n |x_i|^p\\right)^{1/p}+ \\left(\\sum_{i=1}^n |y_i|^p\\right)^{1/p}\\right\\}\n\\end{align*}\n\\]\nThis closes the proof. \\(\\blacksquare\\)"
  },
  {
    "objectID": "posts/norms/index.html#the-vector-infty-norm",
    "href": "posts/norms/index.html#the-vector-infty-norm",
    "title": "Norms",
    "section": "The vector \\(\\infty\\)-norm",
    "text": "The vector \\(\\infty\\)-norm\n\nDefinition 7 (\\(\\infty\\)-norm) The vector \\(\\infty\\)-norm, \\(\\norm{\\cdot}:\\C^n \\to \\R\\) is defined for \\(\\bf{x} \\in \\C^n\\) by:\n\\[\n\\norm{\\bf{x}}_\\infty = \\max\\{|\\chi_1|,|\\chi_2|,\\ldots,|\\chi_n|\\}\n\\]\nThe \\(\\infty\\)-norm simply measures how long the vector is by the magnitude of its largest entry.\n\n\nTheorem 8 The vector \\(\\infty\\)-norm is well-defined.\n\nProof.\nPositive semi-definiteness\nWe have:\n\\[\n\\norm{\\bf{x}}_{\\infty} = \\max_{1\\leq i \\leq n} |\\chi_i| \\geq |\\xi_i| \\geq 0\n\\]\nHomogeneity\nWe have:\n\\[\n\\norm{\\alpha \\bf{x}}_{\\infty} = \\max_{1\\leq i \\leq n}|\\alpha \\chi_i| =\\max_{1\\leq i \\leq n}|\\alpha|| \\chi_i| = |\\alpha| \\max_{1\\leq i \\leq n}|\\chi_i| = |\\alpha|\\norm{\\bf{x}}_{\\infty}\n\\]\nTriangle Inequality\n\\[\n\\begin{align*}\n\\norm{\\bf{x} + \\bf{y}}_\\infty &= \\max_{i=1}^m |\\chi_i + \\xi_i|\\\\\n&\\leq \\max_{i=1}^m (|\\chi_i| + |\\xi_i|)\\\\\n&\\leq \\max_{i=1}^m |\\chi_i| + \\max_{i=1}^m |\\xi_i|\\\\\n&= \\norm{\\bf{x}}_\\infty + \\norm{\\bf{y}}_\\infty\n\\end{align*}\n\\]"
  },
  {
    "objectID": "posts/norms/index.html#equivalence-of-vector-norms",
    "href": "posts/norms/index.html#equivalence-of-vector-norms",
    "title": "Norms",
    "section": "Equivalence of vector norms",
    "text": "Equivalence of vector norms\nAs I was saying earlier, we often measure if a vector is small or large or the distance between two vectors by computing norms. It would be unfortunate, if a vector were small in one norm, yet large in another. Fortunately, the next theorem excludes this possibility.\n\nTheorem 9 (Equivalence of vector norms) Let \\(\\norm{\\cdot}_a:\\C^n \\to \\R\\) and \\(\\norm{\\cdot}_b:\\C^n\\to \\R\\) both be vector norms. Then there exist positive scalars \\(C_1\\) and \\(C_2\\) such that for \\(\\bf{x}\\in \\C^n\\),\n\\[\nC_1 \\norm{\\bf{x}}_b \\leq \\norm{\\bf{x}}_a \\leq C_2 \\norm{\\bf{x}}_b\n\\]\n\nProof.\nWe can prove equivalence of norms in four steps, the last which uses the extreme value theorem from Real Analysis.\n\nStep 1: It is sufficient to consider \\(\\norm{\\cdot}_b = \\norm{\\cdot}_1\\) (transitivity).\nWe will show that it is sufficient to prove that \\(\\norm{\\cdot}_a\\) is equivalent to \\(\\norm{\\cdot}_1\\) because norm equivalence is transitive: if two norms are equivalent to \\(\\norm{\\cdot}_1\\), then they are equivalent to each other. In particular, suppose both \\(\\norm{\\cdot}_a\\) and \\(\\norm{\\cdot}_{a'}\\) are equivalent to \\(\\norm{\\cdot}_1\\) for constants \\(0 \\leq C_1 \\leq C_2\\) and \\(0 \\leq C_1' \\leq C_2'\\) respectively:\n\\[\nC_1 \\norm{\\bf{x}}_1 \\leq \\norm{\\bf{x}}_a \\leq C_2 \\norm{\\bf{x}}_1\n\\]\nand\n\\[\nC_1' \\norm{\\bf{x}}_1 \\leq \\norm{\\bf{x}}_{a'} \\leq C_2' \\norm{\\bf{x}}_1\n\\]\nThen, it immediately follows that:\n\\[\n\\norm{\\bf{x}}_{a'} \\leq C_2' \\norm{\\bf{x}}_1 \\leq \\frac{C_2'}{C_1} \\norm{\\bf{x}}_a\n\\]\nand\n\\[\n\\norm{\\bf{x}}_{a'} \\geq C_1' \\norm{\\bf{x}}_1 \\geq \\frac{C_1'}{C_2} \\norm{\\bf{x}}_a\n\\]\nand hence \\(\\norm{\\cdot}_a\\) and \\(\\norm{\\cdot}_{a'}\\) are equivalent. \\(\\blacksquare\\)\n\n\nStep 2: It is sufficient to consider only \\(\\bf{x}\\) with \\(\\norm{\\bf{x}}_1 = 1\\).\nWe wish to show that\n\\[\nC_1 \\norm{\\bf{x}}_1 \\leq \\norm{\\bf{x}}_a \\leq C_2 \\norm{\\bf{x}}_1\n\\]\nis true for all \\(\\bf{x} \\in V\\) for some \\(C_1\\), \\(C_2\\). It is trivially true for \\(\\bf{x}=\\bf{0}\\), so we only need to consider \\(\\bf{x}\\neq\\bf{0}\\), in which case, we can divide by \\(\\norm{\\bf{x}}_1\\), to obtain the condition:\n\\[\nC_1 \\leq \\norm{\\frac{\\bf{x}}{\\norm{\\bf{x}}_1 }}_a \\leq C_2\n\\]\nThe vector \\(\\bf{u} = \\frac{\\bf{x}}{\\norm{\\bf{x}}_1}\\) is a unit vector in the \\(1\\)-norm, \\(\\norm{\\bf{u}}_1 = 1\\). So, we can write:\n\\[\nC_1 \\leq \\norm{\\bf{u}}_a \\leq C_2\n\\]\nWe have the desired result. \\(\\blacksquare\\)\n\n\nStep 3: Any norm \\(\\norm{\\cdot}_a\\) is continuous under \\(\\norm{\\cdot}_1\\).\nWe wish to show that any norm \\(\\norm{\\cdot}_a\\) is a continuous function on \\(V\\) under the topology induced by \\(\\norm{\\cdot}_1\\). That is, we wish to show that for any \\(\\epsilon &gt; 0\\), there exists \\(\\delta &gt; 0\\), such that for all \\(\\norm{\\bf{x} - \\bf{c}}_1 &lt; \\delta\\), we have \\(\\norm{\\norm{\\bf{x}}_a - \\norm{\\bf{c}}_a}_1 &lt; \\epsilon\\).\nWe prove this into two steps. First, by the triangle inequality on \\(\\norm{\\cdot}_a\\), it follows that:\n\\[\n\\begin{align*}\n\\norm{\\bf{x}}_a - \\norm{\\bf{c}}_a &= \\norm{\\bf{c} + (\\bf{x} - \\bf{c})}_a - \\norm{\\bf{c}}_a \\\\\n&\\leq \\norm{\\bf{c}}_a + \\norm{(\\bf{x} - \\bf{c})}_a - \\norm{\\bf{c}}_a\\\\\n&= \\norm{(\\bf{x} - \\bf{c})}_a\n\\end{align*}\n\\]\nAnd\n\\[\n\\begin{align*}\n\\norm{\\bf{c}}_a - \\norm{\\bf{x}}_a &\\leq \\norm{(\\bf{x} - \\bf{c})}_a\n\\end{align*}\n\\]\nand hence:\n\\[\n|\\norm{\\bf{x}}_a - \\norm{\\bf{c}}_a| \\leq \\norm{(\\bf{x} - \\bf{c})}_a\n\\]\nSecond applying the triangle inequality again, and writing \\(\\bf{x} = \\sum_{i=1}^n \\alpha_i \\bf{e}_i\\) and \\(\\bf{c} = \\sum_{i=1}^n \\alpha_i' \\bf{e}_i\\) in our basis, we obtain:\n\\[\n\\begin{align*}\n\\norm{\\bf{x}-\\bf{c}}_a &= \\norm{\\sum_{i=1}^n (\\alpha_i - \\alpha_i')\\bf{e}_i}_a\\\\\n&\\leq \\sum_{i=1}^n \\norm{(\\alpha_i - \\alpha_i')\\bf{e}_i}_a & \\{ \\text{ Triangle Inequality }\\}\\\\\n&= \\sum_{i=1}^n |(\\alpha_i - \\alpha_i')|\\norm{\\bf{e}_i}_a \\\\\n&= \\norm{\\bf{x} - \\bf{c}}_1 \\left(\\max_i \\norm{\\bf{e}_i}_a \\right)\n\\end{align*}\n\\]\nTherefore, if we choose:\n\\[\n\\delta = \\frac{\\epsilon}{\\left(\\max_i \\norm{\\bf{e}_i}_a \\right)}\n\\]\nit immediate follows that:\n\\[\\begin{align*}\n\\norm{\\bf{x} - \\bf{c}}_1 &&lt; \\delta \\\\\n\\Longrightarrow |\\norm{\\bf{x}}_a - \\norm{\\bf{c}}_a| &\\leq \\norm{\\bf{x} - \\bf{c}}_a \\\\ &\\leq \\norm{\\bf{x} - \\bf{c}}_1 \\left(\\max_i \\norm{\\bf{e}_i}_a \\right) \\\\\n& \\leq \\frac{\\epsilon}{\\left(\\max_i \\norm{\\bf{e}_i}_a \\right)} \\left(\\max_i \\norm{\\bf{e}_i}_a \\right) = \\epsilon\n\\end{align*}\n\\]\nThis proves (uniform) continuity. \\(\\blacksquare\\)\n\n\nStep 4: The maximum and minimum of \\(\\norm{\\cdot}_a\\) on the unit ball\nLet \\(K:=\\{\\bf{u}:\\norm{\\bf{u}}_1 = 1\\}\\). Then, \\(K\\) is a compact set. Since \\(\\norm{\\cdot}_a\\) is continuous on \\(K\\), by the extreme value theorem, \\(\\norm{\\cdot}_a\\) must achieve a supremum and infimum on the set. So, for all \\(\\bf{u}\\) with \\(\\norm{\\bf{u}}_1 = 1\\), there exists \\(C_1,C_2 &gt; 0\\), such that:\n\\[ C_1 \\leq \\norm{\\bf{u}}_a \\leq C_2\\]\nas required by step 2. And we are done! \\(\\blacksquare\\)\n\n\nDeriving the constants \\(C_{1,\\infty}\\), \\(C_{\\infty,1}\\)\nLet’s write a python implementation of the various norms.\n\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport itertools\nimport seaborn as sns\n\nsns.set_style(\"whitegrid\")\n\ndef one_norm(x):\n    return np.sum(np.abs(x))\n\ndef two_norm(x):\n    return np.sqrt(np.sum(x**2))\n\ndef p_norm(x,p):\n    return np.pow(np.sum(np.abs(x)**p),1.0/p)\n\ndef infty_norm(x):\n    return np.max(np.abs(x))\n\ndef get_vectors_eq_norm_val(func, val, lower_bound, upper_bound):\n    x_1 = np.linspace(lower_bound, upper_bound, \n    int((upper_bound - lower_bound)*100 + 1))\n    x_2 = np.linspace(lower_bound, upper_bound, \n    int((upper_bound - lower_bound)*100 + 1))\n\n    pts = np.array(list(itertools.product(x_1, x_2)))\n    norm_arr = np.array(list(map(func, pts)))\n\n    pts_norm_list = list(zip(pts,norm_arr))\n\n    pts_with_norm_eq_val = []\n    for pt in pts_norm_list:\n        if pt[1] == val:\n            pts_with_norm_eq_val.append(pt[0])\n\n    return np.array(pts_with_norm_eq_val)\n\nNow, we can glean useful information by visualizing the set of points(vectors) with a given norm.\n\n\nShow the code\npts1 = get_vectors_eq_norm_val(\n    func=infty_norm, val=1.0, lower_bound=-1.0, upper_bound=1.0\n)\n\npts2 = get_vectors_eq_norm_val(\n    func=one_norm, val=2.0, lower_bound=-2.0, upper_bound=2.0\n)\n\nplt.grid(True)\nplt.xlabel(r\"$x_1$\")\nplt.ylabel(r\"$x_2$\")\na = plt.scatter(pts1[:, 0], pts1[:, 1], s=2)\nb = plt.scatter(pts2[:, 0], pts2[:, 1], s=2)\n# c = plt.scatter(pts_with_unit_infty_norm[:,0],pts_with_unit_infty_norm[:,1],s=2)\n\nplt.legend(\n    (a, b), (r\"$||\\mathbf{x}||_\\infty = 1$\", r\"$||\\mathbf{x}||_1=2$\"), loc=\"lower left\"\n)\nplt.show()\n\n\n\n\n\nThe blue rectangle represents all vectors \\(\\bf{x}\\in\\R^2\\) with unit \\(\\infty\\)-norm, \\(\\norm{\\bf{x}}_\\infty = 1\\). The orange rhombus represents all vectors \\(\\bf{x}\\) with \\(\\norm{\\bf{x}}_1 = 2\\). All points on or outside the blue square represent vectors \\(\\bf{y}\\), such that \\(\\norm{\\bf{y}}_\\infty \\geq 1\\). Hence, if \\(\\norm{\\bf{y}}_1 = 2\\), \\(\\norm{\\bf{y}}_\\infty \\geq 1\\).\nNow, pick any \\(\\bf{z}\\neq \\bf{0}\\). Then, \\(2\\norm{\\frac{\\bf{z}}{\\norm{\\bf{z}}_1}}_1 =2\\). Thus, \\(\\norm{\\frac{2\\bf{z}}{\\norm{\\bf{z}}_1}}_\\infty \\geq 1\\). So, it follows that if \\(\\bf{z}\\in\\R^2\\) is any arbitrary vector, \\(\\norm{\\bf{z}}_1 \\leq 2 \\norm{\\bf{z}}_\\infty\\).\nIn general, if \\(\\bf{x}\\in\\C^n\\), then:\n\\[\n\\begin{align*}\n\\norm{\\bf{x}}_1 &= \\sum_{i=1}^n |x_i|\\\\\n&\\leq \\sum_{i=1}^n \\max\\{|x_i|:i=1,2,\\ldots,n\\}\\\\\n&= n \\norm{\\bf{x}}_\\infty\n\\end{align*}\n\\]\nNext, in the below plot, the orange rhombus represents vectors \\(\\bf{x}\\in\\R^2\\), such that \\(\\normp{x}{1} = 1\\) and all points on or outside the orange rhombus are such that \\(\\normp{y}{1} \\geq 1\\). The blue square represents vectors \\(\\normp{y}{\\infty} = 1\\). Consequently, if \\(\\normp{y}{1} = 1\\), then \\(\\normp{y}{\\infty} \\leq \\normp{y}{1}\\). In general, if \\(\\bf{x}\\in C^n\\), we have:\n\\[\n\\begin{align*}\n\\normp{x}{\\infty} &= \\max\\{|x_1|,\\ldots,|x_n|\\}\\\\\n&\\leq \\sum_{i=1}^n |x_i|=\\normp{x}{1}\n\\end{align*}\n\\]\nPutting together, we have:\n\\[\n\\begin{align*}\n\\normp{x}{\\infty} \\leq C_{\\infty,1} \\normp{x}{1} \\\\\n\\normp{x}{1} \\leq C_{1,\\infty} \\normp{x}{\\infty}\n\\end{align*}\n\\]\nwhere \\(C_{\\infty,1} = 1\\) and \\(C_{1,\\infty}=n\\).\n\n\nShow the code\npts1 = get_vectors_eq_norm_val(\n    func=infty_norm, val=1.0, lower_bound=-1.0, upper_bound=1.0\n)\n\npts2 = get_vectors_eq_norm_val(\n    func=one_norm, val=1.0, lower_bound=-2.0, upper_bound=2.0\n)\n\nplt.grid(True)\nplt.xlabel(r\"$x_1$\")\nplt.ylabel(r\"$x_2$\")\na = plt.scatter(pts1[:, 0], pts1[:, 1], s=2)\nb = plt.scatter(pts2[:, 0], pts2[:, 1], s=2)\n# c = plt.scatter(pts_with_unit_infty_norm[:,0],pts_with_unit_infty_norm[:,1],s=2)\n\nplt.legend(\n    (a, b), (r\"$||\\mathbf{x}||_\\infty = 1$\", r\"$||\\mathbf{x}||_1=1$\"), loc=\"lower left\"\n)\nplt.show()\n\n\n\n\n\n\n\nDeriving the constants \\(C_{1,2}\\), \\(C_{2,1}\\)\nWe can also derive the constants \\(C_{1,2}\\) and \\(C_{2,1}\\). We have:\nLet \\(\\bf{x}\\in\\C^n\\) be an arbitrary vector. And let \\(\\bf{y}=(1+0i,\\ldots,1+0i)\\). By the Cauchy-Schwarz inequality,\n\\[\n\\begin{align*}\n\\sum_{i=1}^n |x_i| \\leq \\left(\\sum_{i=1}^n |x_i|^2\\right)^{1/2}\\sqrt{n}\n\\end{align*}\n\\]\nSo, our claim is \\(\\normp{x}{1} \\leq \\sqrt{n}\\normp{x}{2}\\).\nAlso, consider the vector \\(\\bf{v}=\\left(\\frac{1}{\\sqrt{n}},\\ldots,\\frac{1}{\\sqrt{n}}\\right)\\). \\(\\norm{\\bf{v}}_1 = \\sqrt{n}\\norm{\\bf{v}}_2\\). So, the bound is tight.\nMoreover:\n\\[\n\\begin{align*}\n\\normp{x}{2}^2 &= \\sum_{i=1}^n |x_i|^2 \\\\\n&\\leq \\sum_{i=1}^n |x_i|^2 + \\sum_{i \\neq j}|x_i||x_j|\\\\\n&= \\sum_{i=1}^n |x_i|^2 + \\sum_{i &lt; j}2|x_i||x_j|\\\\\n&= \\left(\\sum_{i=1}^n |x_i|\\right)^2\n\\end{align*}\n\\]\nSo, \\(\\normp{x}{2} \\leq \\normp{x}{1}\\). Consider the standard basis vector \\(\\bf{e}_1 = (1,0,0,\\ldots,0)\\). \\(\\norm{\\bf{e}_1}_2 = \\norm{\\bf{e}_1}_1\\). Hence, the bound is tight. We conclude that:\n\\[\n\\begin{align*}\n\\normp{x}{1} \\leq C_{1,2} \\normp{x}{2}\\\\\n\\normp{x}{2} \\leq C_{2,1} \\normp{x}{1}\n\\end{align*}\n\\]\nwhere \\(C_{1,2} = \\sqrt{n}\\) and \\(C_{2,1} = 1\\).\n\n\nDeriving the constants \\(C_{2,\\infty}\\) and \\(C_{\\infty,2}\\)\nLet \\(x \\in \\C^n\\). We have:\n\\[\n\\begin{align}\n\\norm{x}_2^2 & = \\sum_{i=0}^{n-1}|\\chi_i|^2\\\\\n&\\leq\\sum_{i=0}^{n-1} (\\max_{i=0}^{n-1}|\\chi_i|)^2\\\\\n&= n \\norm{x}_\\infty\n\\end{align}\n\\]\nSo, \\(\\norm{x}_2 \\leq \\sqrt{n} \\norm{x}_\\infty\\).\nMoreover, let \\(x = (1, 1, \\ldots, 1)^T\\). Then, \\(\\norm{x}_2 = \\sqrt{n}\\) and \\(\\norm{x}_\\infty = 1\\), so \\(\\norm{x}_2 = \\sqrt{n}\\norm{x}_\\infty\\). Hence, it is a tight inequality.\nAlso, we have:\n\\[\n\\begin{align*}\n\\norm{x}_\\infty^2 &= \\max \\{|\\chi_0|^2,|\\chi_1|^2,\\ldots,|\\chi_{n-1}^2|\\}\\\\\n&\\leq \\max \\{\\sum_{i=0}^{n-1}|\\chi_i|^2,\\sum_{i=0}^{n-1}|\\chi_i|^2,\\ldots,\\sum_{i=0}^{n-1}|\\chi_i|^2|\\}\\\\\n&= \\norm{x}_2^2\n\\end{align*}\n\\]\nMoreover, let \\(x = (1, 0)\\). Then, \\(\\norm{x}_2 = 1\\) and \\(\\norm{x}_\\infty = 1\\). So, \\(\\norm{x}_\\infty = \\norm{x}_2\\). Hence, the inequality is tight."
  },
  {
    "objectID": "posts/norms/index.html#matrix-norms",
    "href": "posts/norms/index.html#matrix-norms",
    "title": "Norms",
    "section": "Matrix Norms",
    "text": "Matrix Norms\nThe analysis of matrix algorithms requires the use of matrix norms. For example, the quality of a linear system solution may be poor, if the matrix of coefficients is nearly singular. To quantify the notion of singularity, we need a measure of the distance on the space of matrices. Matrix norms can be used to provide that measure.\n\nDefinitions\nSince \\(\\R^{m \\times n}\\) is isomorphic \\(\\R^{mn}\\), the definition of a matrix norm is equivalent to the definition of a vector norm. In particular, \\(f:\\R^{m \\times n} \\to \\R\\) is a matrix norm, if the following three properties holds:\n\\[\n\\begin{align*}\nf(A) \\geq 0, & & A \\in \\R^{m \\times n}\\\\\nf(A + B) \\leq f(A) + f(B), & & A,B \\in \\R^{m \\times n}\\\\\nf(\\alpha A) = |\\alpha|f(A), & & \\alpha \\in \\R, A \\in \\R^{m \\times n}\n\\end{align*}\n\\]\nThe most frequently used matrix norms in numerical linear algebra are the Frobenius norm and the \\(p\\)-norms.\n\nDefinition 8 (Frobenius Norm) The Frobenius norm \\(\\norm{\\cdot}_F : \\C^{m \\times n} \\to \\R\\) is defined for \\(A \\in \\C^{m \\times n}\\) by:\n\\[\n\\norm{A}_F = \\left(\\sum_{i=1}^m \\sum_{j=1}^n |a_{ij}|^2\\right)^{1/2}\n\\]\n\n\nTheorem 10 The Frobenius norm is a well-defined norm.\n\nProof.\nPositive Semi-definite\nWe have:\n\\[\n\\begin{align*}\n\\norm{A}_F &= \\left(\\sum_{i=1}^m \\sum_{j=1}^n |a_{ij}|^2\\right)^{1/2}\\\\\n&\\geq \\left( |a_{ij}|^2\\right)^{1/2} = |a_{ij}|\\\\\n&\\geq 0\n\\end{align*}\n\\]\nTriangle Inequality\nWe have:\n\\[\n\\begin{align*}\n\\norm{A + B}_F^2 &= \\sum_{i=1}^m \\sum_{j=1}^n |a_{ij} + b_{ij}|^2 \\\\\n&\\leq \\sum_{i=1}^m \\sum_{j=1}^n \\left(|a_{ij}|^2 + |b_{ij}|^2 + 2|a_{ij}||b_{ij}|\\right)\\\\\n&= \\sum_{i=1}^m \\sum_{j=1}^n |a_{ij}|^2 + \\sum_{i=1}^m \\sum_{j=1}^n |b_{ij}|^2 + 2\\sum_{i=1}^m \\sum_{j=1}^n|a_{ij}||b_{ij}|\\\\\n&\\leq \\sum_{i=1}^m \\sum_{j=1}^n |a_{ij}|^2 + \\sum_{i=1}^m \\sum_{j=1}^n |b_{ij}|^2 + 2\\left(\\sum_{i=1}^m \\sum_{j=1}^n|a_{ij}|^2\\right)^{1/2}\\left(\\sum_{i=1}^m \\sum_{j=1}^n|b_{ij}|^2\\right)^{1/2} & \\{\\text{ Cauchy-Schwarz }\\}\\\\\n&= \\norm{A}_F^2 + \\norm{B}_F^2 + 2\\norm{A}_F \\norm{B}_F\\\\\n&= (\\norm{A}_F + \\norm{B}_F)^2\\\\\\\\\n\\Longrightarrow \\norm{A + B}_F &\\leq \\norm{A}_F + \\norm{B}_F\n\\end{align*}\n\\]\nHomogeneity\nWe have:\n\\[\n\\begin{align*}\n\\norm{\\alpha A}_F &= \\left(\\sum_{i=1}^m \\sum_{j=1}^n |\\alpha a_{ij}|^2\\right)^{1/2}\\\\\n&=\\left(\\sum_{i=1}^m \\sum_{j=1}^n |\\alpha|^2 |a_{ij}|^2\\right)^{1/2}\\\\\n&= |\\alpha| \\norm{A}_F\n\\end{align*}\n\\]\nThis closes the proof. \\(\\blacksquare\\)\n\nDefinition 9 (Induced matrix norm) Let \\(\\norm{\\cdot}_\\mu : \\C^m \\to \\R\\) and \\(\\norm{\\cdot}_\\nu : \\C^n \\to R\\) be vector norms. Define \\(\\norm{\\cdot}_{\\mu,\\nu} : \\C^{m \\times n} \\to R\\) by:\n\\[\n\\norm{A}_{\\mu,\\nu} = \\sup_{\\bf{x}\\neq\\bf{0}} \\frac{\\norm{A\\bf{x}}_\\mu}{\\norm{\\bf{x}}_\\nu}\n\\]\nMatrix norms that are defined in this way are called induced matrix norms.\n\nLet us start by interpreting this. How large \\(A\\) is, as measured by \\(\\norm{A}_{\\mu,\\nu}\\) is defined as the most that \\(A\\) magnifies the length of non-zero vectors, where the length of the \\(\\bf{x}\\) is measured with the norm \\(\\norm{\\cdot}_\\nu\\) and the length of the transformed vector \\(A\\bf{x}\\) is measured with the norm \\(\\norm{\\cdot}_\\mu\\).\nTwo comments are in order. First,\n\\[\n\\begin{align*}\n\\sup_{\\bf{x}\\neq\\bf{0}} \\frac{\\norm{A\\bf{x}}_\\mu}{\\norm{\\bf{x}}_\\nu} = \\sup_{\\bf{x} \\neq \\bf{0}} \\norm{A\\frac{\\bf{x}}{\\norm{\\bf{x}}_\\nu}}_\\mu = \\sup_{\\norm{\\bf{u}}_\\nu = 1} \\norm{A\\bf{u}}_\\mu\n\\end{align*}\n\\]\nSecond, it is not immediately obvious, that there is a vector \\(\\bf{x}\\) for which a supremum is attained. The fact is there is always such a vector \\(\\bf{x}\\). The \\(K=\\{\\bf{u}:\\norm{\\bf{u}}_\\nu = 1\\}\\) is a compact set, and \\(\\norm{\\cdot}_\\mu : \\C^m \\to \\R\\) is a continuous function. Continuous functions preserve compact sets. So, the supremum exists and further it belongs to \\(\\{A\\bf{x}:\\norm{\\bf{x}}_\\nu = 1\\}\\).\n\nTheorem 11 The induced matrix norm \\(\\norm{\\cdot}_{\\mu,\\nu} : \\C^{m \\times n} \\to \\R\\) is a well-defined norm.\n\nProof\nTo prove this, we merely check if the three conditions are met:\nLet \\(A,B \\in \\C^{m \\times n}\\) and \\(\\alpha \\in \\C\\) be arbitrarily chosen. Then:\nPositive definite\nLet \\(A \\neq 0\\). That means, at least one of the columns of \\(A\\) is not a zero-vector. Partition \\(A\\) by columns:\n\\[\n\\left[\n    \\begin{array}{c|c|c|c}\n        a_{1} & a_2 & \\ldots & a_{n}\n    \\end{array}\n\\right]\n\\]\nLet us assume that, it is the \\(j\\)-th column \\(a_j\\), that is non-zero. Let \\(\\bf{e}_j\\) be the column of \\(I\\)(the identity matrix) indexed with \\(j\\). Then:\n\\[\n\\begin{align*}\n\\norm{A}_{\\mu,\\nu} &= \\sup \\frac{\\norm{A\\bf{x}}_\\mu}{\\norm{\\bf{x}}_\\nu} & \\{ \\text{ Definition }\\}\\\\\n&\\geq \\frac{\\norm{A\\bf{e}_j}_\\mu}{\\norm{\\bf{e}_j}_\\nu}\\\\\n&= \\frac{\\norm{a_j}_\\mu}{\\norm{\\bf{e}_j}_\\nu} & \\{ A\\bf{e}_j = a_j \\}\\\\\n&&gt; 0 & \\{ \\text{ we assumed } a_j \\neq \\bf{0}\\}\n\\end{align*}\n\\]\nHomogeneity\nWe have:\n\\[\n\\begin{align*}\n\\norm{\\alpha A}_{\\mu,\\nu} &= \\sup_{\\bf{x}\\neq \\bf{0}} \\frac{\\norm{\\alpha A \\bf{x}}_\\mu}{\\norm{\\bf{x}}_\\nu} & \\{ \\text{ Definition }\\}\\\\\n&= \\sup_{\\bf{x}\\neq \\bf{0}} \\frac{|\\alpha|\\norm{A\\bf{x}}_\\mu}{\\norm{\\bf{x}}_\\nu} & \\{ \\text{ Homogeneity of vector norm }\\norm{\\cdot}_\\mu\\}\\\\\n&= |\\alpha|\\sup_{\\bf{x}\\neq \\bf{0}} \\frac{\\norm{A\\bf{x}}_\\mu}{\\norm{\\bf{x}}_\\nu} & \\{ \\text{ Algebra }\\}\\\\\n&= |\\alpha|\\norm{A}_{\\mu,\\nu}\n\\end{align*}\n\\]\nTriangle Inequality\nWe have:\n\\[\n\\begin{align*}\n\\norm{A + B}_{\\mu,\\nu} &= \\max_{\\bf{x}\\neq \\bf{0}} \\frac{\\norm{(A + B) \\bf{x}}_\\mu}{\\norm{\\bf{x}}_\\nu} & \\{ \\text{ Definition }\\}\\\\\n&= \\max_{\\bf{x}\\neq \\bf{0}} \\frac{\\norm{(A\\bf{x} + B\\bf{x})}_\\mu}{\\norm{\\bf{x}}_\\nu} & \\{ \\text{ Distribute }\\}\\\\\n&\\leq \\max_{\\bf{x}\\neq \\bf{0}} \\frac{\\norm{(A\\bf{x}}_\\mu + \\norm{B\\bf{x}}_\\mu}{\\norm{\\bf{x}}_\\nu} & \\{ \\text{ Triangle inequality for vector norms }\\}\\\\\n&= \\max_{\\bf{x}\\neq \\bf{0}} \\left(\\frac{\\norm{(A\\bf{x}}_\\mu}{\\norm{\\bf{x}}_\\nu} + \\frac{\\norm{(A\\bf{x}}_\\mu}{\\norm{\\bf{x}}_\\nu} \\right) & \\{ \\text{ Algebra }\\}\\\\\n&= \\max_{\\bf{x}\\neq \\bf{0}} \\frac{\\norm{(A\\bf{x}}_\\mu}{\\norm{\\bf{x}}_\\nu} + \\max_{\\bf{x}\\neq \\bf{0}} \\frac{\\norm{(A\\bf{x}}_\\mu}{\\norm{\\bf{x}}_\\nu} \\\\\n&= \\norm{A}_{\\mu,\\nu} + \\norm{B}_{\\mu,\\nu} & \\{ \\text{ Definition }\\}\n\\end{align*}\n\\]\nThis closes the proof. \\(\\blacksquare\\)\nWhen \\(\\norm{\\cdot}_\\mu\\) and \\(\\norm{\\cdot}_\\nu\\) are the same norm, the induced norm becomes:\n\\[\n\\norm{A}_\\mu = \\max_{\\bf{x}\\neq\\bf{0}} \\frac{\\norm{A\\bf{x}}_\\mu}{\\norm{\\bf{x}}_\\mu}\n\\]\nor equivalently:\n\\[\n\\norm{A}_\\mu = \\max_{\\norm{\\bf{u}}_\\mu = 1} \\norm{A\\bf{u}}_\\mu\n\\]\n\nExample 1 Consider the vector \\(p\\)-norm \\(\\norm{\\cdot}_p:\\C^n \\to \\R\\) and let us denote the induced matrix norm \\(|||\\cdot|||:\\C^{m \\times n} \\to \\R\\) by \\(|||A||| = \\max_{\\bf{x}\\neq\\bf{0}}\\frac{\\norm{A\\bf{x}}_p}{\\norm{\\bf{x}}_p}\\). Prove that \\(|||\\bf{y}||| = \\norm{\\bf{y}}_p\\) for all \\(\\bf{y}\\in\\C^m\\).\n\nProof.\nWe have:\n\\[\n\\begin{align*}\n|||\\bf{y}||| &= \\frac{\\norm{\\bf{y}x}_p}{\\norm{x}_p} & \\{ \\text{ Definition }\\}\\\\\n&= \\frac{|x_1| \\norm{\\bf{y}}_p}{|x_1|} & \\{ x \\text{ has to be } 1 \\times 1, \\text{ a scalar }\\}\\\\\n&= \\norm{\\bf{y}}_p\n\\end{align*}\n\\]\nThe last example is important. One can view a vector \\(\\bf{y}\\in \\C^m\\) as an \\(m \\times 1\\) matrix. What this last exercise tells us is that regardless of whether we view \\(\\bf{y}\\) as a matrix or a vector, \\(\\norm{y}_p\\) is the same.\nWe already encountered the vector \\(p\\)-norms as an important class of vector norms. The matrix \\(p\\)-norm is induced by the corresponding vector norm.\n\nDefinition 10 (The matrix \\(p\\)-norm) For any vector \\(p\\)-norm, define the corresponding matrix \\(p\\)-norm \\(\\norm{\\cdot}_p : \\C^{m \\times n} \\to \\R\\) by:\n\\[\n\\norm{A}_p = \\max_{\\bf{x}\\neq\\bf{0}} \\frac{\\norm{A\\bf{x}}_p}{\\norm{\\bf{x}}_p} \\quad \\text{ or equivalently } \\quad \\norm{A}_p = \\max_{\\norm{\\bf{x}}_p = 1} \\norm{A\\bf{x}}_p\n\\]\n\nIn practice, the matrix \\(2\\)-norm is of great theoretical importance, but difficult to evaluate, except for special matrices. The \\(1\\)-norm, the \\(\\infty\\)-norm and Frobenius norms are straightforward and relatively cheap to compute.\nLet us instantiate the definition of the vector \\(p\\)-norm where \\(p=2\\), giving us a matrix norm induced by the vector \\(2\\)-norm or the Euclidean norm:\n\nDefinition 11 (The matrix \\(2\\)-norm) Define the matrix \\(2\\)-norm \\(\\norm{\\cdot}_2:\\C^{m \\times n} \\to \\R\\) by :\n\\[\n\\norm{A}_2 = \\max_{\\bf{x}\\neq\\bf{0}} \\frac{\\norm{A\\bf{x}}_2}{\\norm{\\bf{x}}_2} = \\max_{\\norm{\\bf{x}}_2 = 1} \\norm{A\\bf{x}}_2\n\\]\n\n\n\n\n\n\n\nNote\n\n\n\nThe problem with the matrix \\(2\\)-norm is that it is hard to compute. In future posts, we shall find out that if \\(A\\) is a Hermitian matrix (\\(A = A^H\\)), then \\(\\norm{A}_2 = |\\lambda_1|\\) where \\(\\lambda_1\\) is the eigenvalue of \\(A\\) that is largest in magnitude.\nRecall from basic linear algebra, that computing eigenvalues involves computing the roots of polynomials, and for polynomials of degree three or greater, this is a non-trivial task. We shall see that the matrix \\(2\\)-norm plays an important part in theory, but less so in practical computation.\n\n\n\nExample 2 Show that:\n\\[\n\\norm{\\begin{bmatrix}\nd_1 & 0 \\\\\n0 & d_2\n\\end{bmatrix}}_2 = \\max(|d_1|,|d_2|)\n\\]\n\nSolution\nWe have:\n\\[\n\\begin{align*}\n\\norm{\\begin{bmatrix}\nd_1 & 0 \\\\\n0 & d_2\n\\end{bmatrix}}_2^2 &= \\max_{\\norm{\\bf{x}}_2 = 1} \\norm{\\begin{bmatrix}\nd_1 & 0 \\\\\n0 & d_2\n\\end{bmatrix}\\begin{bmatrix}x_1 \\\\ x_2\\end{bmatrix}}_2^2 & \\{ \\text{ Definition }\\}\\\\\n&= \\max_{\\norm{\\bf{x}}_2 = 1}|d_1x_1|^2 + |d_2 x_2|^2\\\\\n&\\leq \\max_{\\norm{\\bf{x}}_2 = 1} [\\max(|d_1|,|d_2|)^2 |x_1|^2 + \\max(|d_1|,|d_2|)^2 |x_2|^2]\\\\\n&= \\max(|d_1|,|d_2|)^2 \\max_{\\norm{\\bf{x}}_2 = 1} (|x_1|^2 + |x_2|^2)\\\\\n&= \\max(|d_1|,|d_2|)^2\n\\end{align*}\n\\]\nMoreover, if we take \\(\\bf{x} = \\bf{e}_1\\) and \\(\\bf{x}=\\bf{e}_2\\), we get:\n\\[\n\\begin{align*}\n\\norm{\\begin{bmatrix}\nd_1 & 0 \\\\\n0 & d_2\n\\end{bmatrix}}_2^2  &= \\max_{\\norm{\\bf{x}}_2 = 1} \\norm{\\begin{bmatrix}\nd_1 & 0 \\\\\n0 & d_2\n\\end{bmatrix}\\begin{bmatrix}x_1 \\\\ x_2\\end{bmatrix}}_2 & \\{ \\text{ Definition }\\}\\\\\n&\\geq  \\norm{\\begin{bmatrix}\nd_1 & 0 \\\\\n0 & d_2\n\\end{bmatrix}\\begin{bmatrix}1 \\\\ 0\\end{bmatrix}}_2^2 \\\\\n&= |d_1|^2\n\\end{align*}\n\\]\nand\n\\[\n\\begin{align*}\n\\norm{\\begin{bmatrix}\nd_1 & 0 \\\\\n0 & d_2\n\\end{bmatrix}}_2^2  &= \\max_{\\norm{\\bf{x}}_2 = 1} \\norm{\\begin{bmatrix}\nd_1 & 0 \\\\\n0 & d_2\n\\end{bmatrix}\\begin{bmatrix}x_1 \\\\ x_2\\end{bmatrix}}_2 & \\{ \\text{ Definition }\\}\\\\\n&\\geq  \\norm{\\begin{bmatrix}\nd_1 & 0 \\\\\n0 & d_2\n\\end{bmatrix}\\begin{bmatrix}0 \\\\ 1\\end{bmatrix}}_2 \\\\\n&= |d_2|^2\n\\end{align*}\n\\]\nConsequently,\n\\[\n\\norm{\\begin{bmatrix}\nd_1 & 0 \\\\\n0 & d_2\n\\end{bmatrix}}_2^2 \\geq \\max(|d_1|,|d_2|)^2\n\\]\nWe conclude that\n\\[\n\\norm{\\begin{bmatrix}\nd_1 & 0 \\\\\n0 & d_2\n\\end{bmatrix}}_2 = \\max(|d_1|,|d_2|)\n\\]\n\n\n\n\n\n\nTip\n\n\n\nThe proof of the last example builds on a general principle: Showing that \\(\\max_{x \\in D} f(x) = \\alpha\\) for some function \\(f:D \\to \\R\\) can be broken down into showing that both:\n\\[\n\\max_{x \\in D} f(x) \\leq \\alpha\n\\]\nand\n\\[\n\\max_{x \\in D} f(x) \\geq \\alpha\n\\]\nIn turn, showing that \\(\\max_{x \\in D}f(x) \\geq \\alpha\\) can often be accomplished by showing that there exists a vector \\(y \\in D\\) such that \\(f(y) = \\alpha\\) since then\n\\[\n\\max_{x \\in D}f(x) \\geq f(y) = \\alpha\n\\]\nWe will use this technique in future proofs involving matrix norms.\n\n\n\nExercise 1 Let \\(D \\in C^{m \\times m}\\) be a diagonal matrix \\(diag(d_1,d_2,\\ldots,d_m)\\). Show that:\n\\[\n\\norm{D}_2 = \\max_{j=1}^{m} |d_j|\n\\]\n\nSolution.\nWe have:\n\\[\n\\begin{align*}\n\\norm{D}_2^2 &= \\max_{\\norm{\\bf{x}}_2 = 1} \\norm{\n    \\begin{bmatrix}\n    d_1 \\\\\n    & d_2 \\\\\n    & & \\ddots\\\\\n    & & & d_m\n    \\end{bmatrix}\n    \\begin{bmatrix}\n    x_1\\\\\n    x_2\\\\\n    \\vdots\\\\\n    x_m\n    \\end{bmatrix}\n}_2^2 \\{ \\text{ Definition }\\}\\\\\n&=\\max_{\\norm{\\bf{x}}_2 = 1} \\norm{\n    \\begin{bmatrix}\n    d_1 x_1\\\\\n    d_2 x_2\\\\\n    \\vdots\\\\\n    d_m x_m\n    \\end{bmatrix}\n}_2^2\\\\\n&= \\max_{\\norm{\\bf{x}}_2 = 1} \\sum_{j=1}^m |d_j x_j|^2\\\\\n&\\leq \\max_{\\norm{\\bf{x}}_2 = 1} \\sum_{j=1}^m \\max(|d_1|,\\ldots,|d_m|)^2 |x_j|^2\\\\\n&= \\max(|d_1|,\\ldots,|d_m|)^2 \\max_{\\norm{\\bf{x}}_2 = 1} \\sum_{j=1}^m |x_j|^2 \\\\\n&= \\max(|d_1|,\\ldots,|d_m|)^2\n\\end{align*}\n\\]\nMoreover, if we take take \\(\\bf{x} = \\bf{e}_j\\), the standard basis vector with its \\(j\\)-th coordinate equal to one, we find that\n\\[\n\\norm{D}_2^2 \\geq |d_j|^2\n\\]\nConsequently, \\(\\norm{D}_2^2 \\geq \\max(|d_1|,\\ldots,|d_m|)^2\\).\nThis closes the proof. \\(\\blacksquare\\)\n\nExercise 2 Let \\(\\bf{y}\\in\\C^m\\) and \\(\\bf{x} \\in \\C^n\\). Show that:\n\\[\n\\norm{\\bf{y}\\bf{x}^H}_2 = \\norm{\\bf{y}}_2 \\norm{\\bf{x}}_2\n\\]\n\nProof.\nFrom the Cauchy-Schwarz inequality, we know that:\n\\[\n|x^H z| \\leq \\norm{\\bf{x}^H}_2 \\norm{\\bf{z}}_2\n\\]\nNow, \\(\\bf{x}^H \\in \\C^{1 \\times n}\\) and \\(\\bf{z} \\in \\C^{n \\times 1}\\). So, \\(\\bf{x}^H \\bf{z} \\in \\C^{1 \\times 1}\\), and it is a scalar.\n\\[\n\\begin{align*}\n\\norm{\\bf{y}\\bf{x}^H}_2 &= \\max_{\\norm{\\bf{z}}_2 = 1} \\norm{\\bf{y}\\bf{x}^H \\bf{z}}_2 \\\\\n&= \\max_{\\norm{\\bf{z}}_2 = 1} |\\bf{x}^H \\bf{z}| \\norm{\\bf{y}}_2 \\{ \\bf{x}^H\\bf{z}\\text{ is scalar }\\}\\\\\n&\\leq \\max_{\\norm{\\bf{z}}_2 = 1} \\norm{\\bf{x}^H}_2 \\norm{\\bf{z}}_2 \\norm{\\bf{y}}_2 \\\\\n&= \\norm{\\bf{x}}_2 \\norm{\\bf{y}}_2\n\\end{align*}\n\\]\nOn the other hand,\n\\[\n\\begin{align*}\n\\norm{\\bf{y}\\bf{x}^H}_2 &= \\max_{\\bf{z}\\neq \\bf{0}} \\frac{\\norm{\\bf{y}\\bf{x}^H \\bf{z}}_2}{\\norm{\\bf{z}}_2}\\\\\n&\\geq \\frac{\\norm{\\bf{y}\\bf{x}^H \\bf{x}}_2}{\\norm{\\bf{x}}_2} & \\{ \\text{ Specific }\\bf{z} \\}\\\\\n&= \\frac{\\norm{\\bf{y}\\norm{\\bf{x}}_2^2}_2}{\\norm{\\bf{x}}_2} & \\{ \\bf{x}^H \\bf{x} = \\norm{\\bf{x}}_2^2\\}\\\\\n&= \\norm{\\bf{y}}_2 \\norm{\\bf{x}}_2\n\\end{align*}\n\\]\nThis closes the proof. \\(\\blacksquare\\)\n\nExercise 3 Let \\(A \\in \\C^{m \\times n}\\) and \\(a_j\\) be its column indexed with \\(j\\). Prove that:\n\\[\n\\norm{a_j}_2 \\leq \\norm{A}_2\n\\]\n\nProof.\nWe have:\n\\[\n\\begin{align*}\n\\norm{A}_2 &= \\max_{\\norm{\\bf{z}}_2 = 1} \\norm{A\\bf{z}}_2 \\\\\n&\\geq  \\norm{A\\bf{e}_j}_2\\\\\n&= \\norm{a_j}_2\n\\end{align*}\n\\]\nThis closes the proof. \\(\\blacksquare\\)\n\nExercise 4 Let \\(A \\in \\C^{m \\times n}\\). Prove that:\n\n\\[\n\\norm{A}_2 = \\max_{\\norm{\\bf{x}}_2 = \\norm{\\bf{y}}_2 = 1} |\\bf{y}^H A \\bf{x}|\n\\]\n\\[\n\\norm{A^H}_2 = \\norm{A}_2\n\\]\n\\[\n\\norm{A^H A}_2 = \\norm{A}_2^2\n\\]\n\n\nClaim.\n\\[\n\\norm{A}_2 = \\max_{\\norm{\\bf{x}}_2 = \\norm{\\bf{y}}_2 = 1} |\\bf{y}^H A \\bf{x}|\n\\]\nProof.\nWe have:\n\\[\n\\begin{align*}\n\\max_{\\norm{\\bf{x}}_2 = \\norm{\\bf{y}}_2 = 1} |\\bf{y}^H A \\bf{x}| &\\leq \\max_{\\norm{\\bf{x}}_2 = \\norm{\\bf{y}}_2 = 1} \\norm{\\bf{y}^H}_2 \\norm{A\\bf{x}}_2 & \\{ \\text{ Cauchy-Schwarz }\\} \\\\\n&= \\max_{\\norm{\\bf{x}}_2 } \\norm{A\\bf{x}}_2\\\\\n&= \\norm{A}_2\n\\end{align*}\n\\]\nOn the other hand:\n\\[\n\\begin{align*}\n\\max_{\\norm{\\bf{x}}_2 = \\norm{\\bf{y}}_2 = 1} |\\bf{y}^H A \\bf{x}| &\\geq \\max_{\\norm{\\bf{x}}_2 = 1} |\\left(\\frac{A\\bf{x}}{\\norm{A\\bf{x}}_2}\\right)^H A \\bf{x}| & \\{\\text{ Specific vector }\\}\\\\\n&= \\max_{\\norm{\\bf{x}}_2 = 1} \\frac{\\norm{A\\bf{x}}_2^2}{\\norm{A\\bf{x}}_2}\\\\\n&=\\max_{\\norm{\\bf{x}}_2 = 1} \\norm{A\\bf{x}}_2\\\\\n&= \\norm{A}_2\n\\end{align*}\n\\]\nWe have the desired result.\nClaim.\n\\[\n\\norm{A^H}_2 = \\norm{A}_2\n\\]\nProof.\nWe have:\n\\[\n\\begin{align*}\n\\norm{A^H}_2^2 &= \\max_{\\norm{\\bf{x}}_2 = 1} \\norm{A^H\\bf{x}}_2^2 \\\\\n&= \\max_{\\norm{\\bf{x}}_2 = 1} |(A^H \\bf{x})^H (A^H \\bf{x})|\n\\end{align*}\n\\]\nClaim.\n\\[\n\\norm{A^H}_2 = \\norm{A}_2\n\\]\nProof.\nWe have:\n\\[\n\\begin{align*}\n\\norm{A^H}_2 &= \\max_{\\norm{\\bf{x}}_2 = \\norm{\\bf{y}}_2 = 1} |\\bf{y}^H A^H \\bf{x}| \\\\\n&= \\max_{\\norm{\\bf{x}}_2 = \\norm{\\bf{y}}_2 = 1} |\\bf{x}^H A \\bf{y}| & \\{ |\\overline \\alpha| = |\\alpha| \\}\\\\\n&= \\max_{\\norm{\\bf{y}}_2 = 1} \\norm{A \\bf{y}}_2 \\\\\n&= \\norm{A}_2\n\\end{align*}\n\\]\nClaim\n\\[\n\\norm{A^H A}_2 = \\norm{A}_2^2\n\\]\nProof.\nWe have:\n\\[\n\\begin{align*}\n\\norm{A^H A}_2 &= \\max_{\\norm{\\bf{x}}_2 = \\norm{\\bf{y}}_2 = 1} |\\bf{y}^H A^H A \\bf{x}|\\\\\n&\\leq \\max_{\\norm{\\bf{x}}_2 = \\norm{\\bf{y}}_2 = 1} \\norm{\\bf{y}^H A^H}_2 \\norm{A\\bf{x}}_2 & \\{ \\text{ Cauchy-Schwarz }\\}\\\\\n&= \\max_{\\norm{\\bf{y}}_2 = 1} \\norm{A\\bf{y}}_2 \\max_{\\norm{\\bf{x}}_2 = 1} \\norm{A\\bf{x}}_2  & \\{ \\norm{A^H}_2 = \\norm{A}_2 \\}\\\\\n&= \\norm{A}_2^2\n\\end{align*}\n\\]\nMoreover:\n\\[\n\\begin{align*}\n\\norm{A^H A}_2 &= \\max_{\\norm{\\bf{x}}_2 = \\norm{\\bf{y}}_2 = 1} |\\bf{y}^H A^H A \\bf{x}|\\\\\n&\\geq \\max_{\\norm{\\bf{x}}_2 = 1}  |\\bf{x}^H A^H A \\bf{x}| \\{ \\text{ Restrict the choices of }\\bf{y}\\}\\\\\n&=  \\max_{\\norm{\\bf{x}}_2 = 1}  |(A\\bf{x})^H (A \\bf{x})| \\\\\n&=  \\max_{\\norm{\\bf{x}}_2 = 1}  \\norm{A\\bf{x}}_2^2\\\\\n&= \\norm{A}_2^2\n\\end{align*}\n\\]\n\nExercise 5 Partition\n\\[\nA = \\left[\n    \\begin{array}{c|c|c}\n        A_{1,1} & \\ldots & A_{1,N}\\\\\n        \\hline\n        \\vdots & & \\vdots\\\\\n        \\hline\n        A_{M,1} & \\ldots & A_{M,N}\n    \\end{array}\n\\right]\n\\]\nProve that \\(\\norm{A_{i,j}}_2 \\leq \\norm{A}_2\\).\n\nProof.\nBy definition,\n\\[\n\\begin{align*}\n\\norm{A_{i,j}}_2 = \\max_{\\norm{\\bf{x}}_2 = \\norm{\\bf{y}}_2 = 1} |\\bf{y}^H A_{i,j} \\bf{x}|\n\\end{align*}\n\\]\nSince \\(\\norm{\\bf{x}}_2 = \\norm{\\bf{y}}_2 = 1\\) is a compact set, the above maximum exists. There exists \\(\\bf{w}_i\\) and \\(\\bf{v}_j\\), satisfying \\(\\norm{\\bf{w}_i}_2 = \\norm{\\bf{v}_j}_2 = 1\\) such that:\n\\[\n\\begin{align*}\n\\norm{A_{i,j}}_2 = |\\bf{w}_i^H A_{i,j} \\bf{v}_j|\n\\end{align*}\n\\]\nNext, we choose\n\\[\n\\bf{w} = \\left[\n    \\begin{array}{c}\n    0 \\\\\n    \\hline\n    0 \\\\\n    \\hline\n    \\vdots \\\\\n    \\hline\n    \\bf{w}_i\\\\\n    \\hline\n    0 \\\\\n    \\hline\n    \\vdots\\\\\n    0\n    \\end{array}\n\\right] \\quad\n\\bf{v} = \\left[\n    \\begin{array}{c}\n    0 \\\\\n    \\hline\n    0 \\\\\n    \\hline\n    \\vdots \\\\\n    \\hline\n    \\bf{v}_j\\\\\n    \\hline\n    0 \\\\\n    \\hline\n    \\vdots\\\\\n    0\n    \\end{array}\n\\right]\n\\]\nConsider:\n\\[\n\\begin{align*}\n\\norm{A}_2 &= \\max_{\\norm{\\bf{x}}_2 = \\norm{\\bf{y}}_2 = 1} |\\bf{y}^H A \\bf{x}|\\\\\n& \\geq |\\bf{w}^H A \\bf{v}|\\\\\n&= |\\bf{w}_j^H A_{i,j} \\bf{v}_i|\\\\\n&= \\norm{A_{i,j}}_2\n\\end{align*}\n\\]\nThis closes the proof. \\(\\blacksquare\\)\n\n\nComputing the matrix \\(1\\)-norm and \\(\\infty\\)-norm\nThe matrix \\(1\\)-norm and the matrix \\(\\infty\\)-norm are of great importance, because, unlike the matrix \\(2\\)-norm, they are easy and relatively cheap to compute. The following exercises show how to practically compute the matrix \\(1\\)-norm and \\(\\infty\\)-norm.\n\nExercise 6 Let \\(A = \\C^{m \\times n}\\) and partition \\(A = [a_1 | a_2 | \\ldots | a_n]\\). Prove that\n\\[\n\\norm{A}_1 = \\max_{1 \\leq j \\leq n}\\norm{a_j}_1\n\\]\n\nProof\nWe have:\n\\[\n\\begin{align*}\n\\norm{A}_1 &= \\max_{\\norm{\\bf{x}}_1 = 1} \\norm{A\\bf{x}}_1 & \\{ \\text{ Definition }\\}\\\\\n&= \\max_{\\norm{\\bf{x}}_1 = 1} \\norm{a_1 x_1 + a_2 x_2 + \\ldots + a_n x_n}_1 & \\{ \\text{ Algebra }\\}\\\\\n&\\leq \\max_{\\norm{\\bf{x}}_1 = 1} \\norm{a_1 x_1}_1 + \\norm{a_2 x_2}_1 + \\ldots + \\norm{a_n x_n}_1 & \\{ \\text{ Triangle Inequality }\\}\\\\\n&= \\max_{\\norm{\\bf{x}}_1 = 1} |x_1| \\norm{a_1}_1 + |x_2| \\norm{a_2}_1 + \\ldots + |x_n| \\norm{a_n}_1  & \\{ \\text{ Homogeneity }\\}\\\\\n&= \\max_{\\norm{\\bf{x}}_1 = 1}  |x_1| (\\max_{1 \\leq j \\leq n} \\norm{a_j}_1) + |x_2| (\\max_{1 \\leq j \\leq n} \\norm{a_j}_1)+ \\ldots + |x_n| (\\max_{1 \\leq j \\leq n} \\norm{a_j}_1)\\\\\n&= \\max_{1 \\leq j \\leq n} \\norm{a_j}_1 \\max_{\\norm{\\bf{x}}_1 = 1} \\sum_{j=1}^n |x_j|\\\\\n&= \\max_{1 \\leq j \\leq n} \\norm{a_j}_1\n\\end{align*}\n\\]\nOn the other hand,\n\\[\n\\begin{align*}\n\\norm{A}_1  &= \\max_{\\norm{\\bf{x}}_1 = 1} \\norm{A\\bf{x}}_1 & \\{ \\text{ Definition }\\}\\\\\n&\\geq \\norm{A\\bf{e}_j}_1 & \\{ \\text{ Specific vector }\\}\\\\\n&= \\norm{a_j}_1\n\\end{align*}\n\\]\nThis concludes the proof. \\(\\blacksquare\\)\n\nExercise 7 Let \\(A = \\C^{m \\times n}\\) and partition\n\\[\nA = \\left[\n    \\begin{array}{c}\n        \\tilde{a}_0^T\\\\\n        \\hline\n        \\tilde{a}_1^T\\\\\n        \\hline\n        \\vdots\\\\\n        \\hline\n        \\tilde{a}_{m-1}^T\\\\\n    \\end{array}\n\\right]\n\\]\nProve that\n\\[\n\\norm{A}_\\infty = \\max_{0\\leq i &lt; m} \\norm{\\tilde{a}_i}_1 = \\max_{0 \\leq i &lt; m} (|\\alpha_{i,0}| + |\\alpha_{i,1}| + \\ldots + |\\alpha_{i,n-1}|)\n\\]\n\n*Notice that in this exercise, \\(\\tilde{a}_i\\) is really \\((\\tilde{a}_i^T)^T\\), since \\(\\tilde{a}_i^T\\) is the label for the \\(i\\)-th row of the matrix.\nProof.\nWe have:\n\\[\n\\begin{align*}\n\\norm{A}_\\infty &= \\max_{\\norm{\\bf{x}}_\\infty = 1} \\norm{A\\bf{x}}_\\infty & \\{ \\text{ Definition }\\} \\\\\n&= \\max_{\\norm{\\bf{x}}_\\infty = 1} \\norm{\\left[\n    \\begin{array}{c}\n        \\tilde{a}_0^T \\bf{x}\\\\\n        \\hline\n        \\tilde{a}_1^T \\bf{x}\\\\\n        \\hline\n        \\vdots\\\\\n        \\hline\n        \\tilde{a}_{m-1}^T \\bf{x}\\\\\n    \\end{array}\n\\right]}_\\infty & \\{ \\text{ Algebra }\\}\\\\\n&=  \\max_{\\norm{\\bf{x}}_\\infty = 1} \\max_{0 \\leq i &lt; m} |\\tilde{a}_i^T \\bf{x}|\\\\\n&=  \\max_{\\norm{\\bf{x}}_\\infty = 1} \\max_{0 \\leq i &lt; m} |\\alpha_{i,0}x_0 + \\ldots + \\alpha_{i,n-1}x_{n-1}|\\\\\n&\\leq  \\max_{\\norm{\\bf{x}}_\\infty = 1} \\max_{0 \\leq i &lt; m} \\left( |\\alpha_{i,0}x_0 | + \\ldots + |\\alpha_{i,n-1}x_{n-1}| \\right) & \\{ \\text{ Triangle Inequality }\\}\\\\\n&=  \\max_{\\norm{\\bf{x}}_\\infty = 1} \\max_{0 \\leq i &lt; m} \\left( |\\alpha_{i,0}||x_0 | + \\ldots + |\\alpha_{i,n-1}||x_{n-1}| \\right) & \\{ \\text{ Algebra }\\}\\\\\n&\\leq \\max_{\\norm{\\bf{x}}_\\infty = 1} \\max_{0 \\leq i &lt; m}\\left( |\\alpha_{i,0}|\\norm{\\bf{x}}_\\infty + \\ldots + |\\alpha_{i,n-1}|\\norm{\\bf{x}}_\\infty \\right) & \\{ |x_i| \\leq \\norm{\\bf{x}}_\\infty \\}\\\\\n&= \\max_{0 \\leq i &lt; m} ( |\\alpha_{i,0}| + \\ldots + |\\alpha_{i,n-1}|) \\max_{\\norm{\\bf{x}}_\\infty = 1} \\norm{\\bf{x}}_\\infty\\\\\n&= \\max_{0 \\leq i &lt; m} ( |\\alpha_{i,0}| + \\ldots + |\\alpha_{i,n-1}|)\\\\\n&= \\max_{0 \\leq i &lt; m}\n\\norm{\\tilde{a}_i}_1\n\\end{align*}\n\\]\nWe also want to show that \\(\\norm{A}_\\infty \\geq \\max_{0 \\leq i &lt; m} \\norm{\\tilde{a}_i}_1\\). Let \\(k\\) be such that \\(\\max_{0 \\leq i &lt; m}\\norm{\\tilde{a}_i}_1 = \\norm{\\tilde{a}_k}_1\\) and pick \\(\\bf{y} = \\left(\\begin{array}{c}\\psi_0\\\\ \\vdots\\\\ \\psi_{n-1}\\end{array}\\right)\\) so that \\(\\tilde{a}_k^T \\bf{y} = |\\alpha_{k,0}| + |\\alpha_{k,1}| + \\ldots + |\\alpha_{k,n-1}|=\\norm{\\tilde{a}_k}_1\\). This is a matter of picking \\(\\psi_j = |\\alpha_{k,j}|/\\alpha_{k,j}\\). Then, \\(|\\psi_j| = 1\\) and hence, \\(\\norm{\\bf{y}}_\\infty = 1\\) and \\(\\psi_j \\alpha_{k,j} = |\\alpha_{k,j}|\\). Then:\n\\[\n\\begin{align*}\n\\norm{A}_\\infty &= \\max_{\\norm{\\bf{x}}_\\infty = 1} \\norm{A\\bf{x}}_\\infty & \\{ \\text{ Definition }\\} \\\\\n&= \\max_{\\norm{\\bf{x}}_\\infty = 1} \\norm{\\left[\n    \\begin{array}{c}\n        \\tilde{a}_0^T \\bf{x}\\\\\n        \\hline\n        \\tilde{a}_1^T \\bf{x}\\\\\n        \\hline\n        \\vdots\\\\\n        \\hline\n        \\tilde{a}_{m-1}^T \\bf{x}\\\\\n    \\end{array}\n\\right]}_\\infty & \\{ \\text{ Expose rows }\\}\\\\\n&\\geq  \\norm{\\left[\n    \\begin{array}{c}\n        \\tilde{a}_0^T \\bf{y}\\\\\n        \\hline\n        \\tilde{a}_1^T \\bf{y}\\\\\n        \\hline\n        \\vdots\\\\\n        \\hline\n        \\tilde{a}_{m-1}^T \\bf{y}\\\\\n    \\end{array}\n\\right]}_\\infty & \\{ \\text{ Specific vector }\\}\\\\\n&\\geq |\\tilde{a}_k^T \\bf{y}|\\\\\n&= \\norm{\\tilde{a}_k}_1 \\\\\n&= \\max_{0 \\leq i &lt; m} \\norm{\\tilde{a}_i}_1\n\\end{align*}\n\\]\nThis closes the proof. \\(\\blacksquare\\)\n\nExercise 8 Fill out the following table:\n\\[\n\\begin{array}{|c|c|c|c|}\n\\hline\nA & \\norm{A}_1 & \\norm{A}_\\infty & \\norm{A}_F & \\norm{A}_2\\\\\n\\hline\n\\begin{bmatrix}\n1 & 0 & 0 \\\\\n0 & 1 & 0 \\\\\n0 & 0 & 1\n\\end{bmatrix}\\\\\n\\hline\n\\begin{bmatrix}\n1 & 1 & 1\\\\\n1 & 1 & 1\\\\\n1 & 1 & 1\\\\\n1 & 1 & 1\n\\end{bmatrix}\\\\\n\\hline\n\\begin{bmatrix}\n0 & 1 & 0\\\\\n0 & 1 & 0\\\\\n0 & 1 & 0\n\\end{bmatrix}\\\\\n\\hline\n\\end{array}\n\\]\n\nSolution.\nLet\n\\[\nA = \\begin{bmatrix}\n1 & 0 & 0 \\\\\n0 & 1 & 0 \\\\\n0 & 0 & 1\n\\end{bmatrix}\n\\]\nWe have, \\(\\norm{A}_1 = 1\\), \\(\\norm{A}_\\infty = 1\\), \\(\\norm{A}_F = \\sqrt{3}\\). Since this is a diagonal matrix, \\(\\norm{A}_2 = \\max_{0 \\leq i \\leq 2} |d_{i}|\\) = 1.\nNext, consider:\n\\[\n\\begin{bmatrix}\n1 & 1 & 1\\\\\n1 & 1 & 1\\\\\n1 & 1 & 1\\\\\n1 & 1 & 1\n\\end{bmatrix}\n\\]\nWe have, \\(\\norm{A}_1 = 4\\), \\(\\norm{A}_\\infty = 3\\), \\(\\norm{A}_F = \\sqrt{12}\\).\nNote that, we can write\n\\[\nA = \\begin{bmatrix}\n1 \\\\\n1 \\\\\n1 \\\\\n1 \\\\\n\\end{bmatrix} [1, 1, 1, 1] = \\bf{x}\\bf{y}^H\n\\]\nwhere \\(\\bf{x} = \\bf{y} = \\begin{bmatrix} 1 \\\\ 1 \\\\ 1 \\\\ 1 \\\\ \\end{bmatrix}\\). Using the property that, \\(\\norm{\\bf{x}\\bf{y}^H}_2 = \\norm{\\bf{x}}_2 \\norm{\\bf{y}}_2\\), we have that, \\(\\norm{A}_2 = 4\\).\nFinally, if\n\\[\nA = \\begin{bmatrix}\n0 & 1 & 0\\\\\n0 & 1 & 0\\\\\n0 & 1 & 0\n\\end{bmatrix}\n\\]\nwe find that \\(\\norm{A}_1 = 3\\), \\(\\norm{A}_\\infty = 1\\), \\(\\norm{A}_F = \\sqrt{3}\\). Finally, let \\(\\bf{x} = \\begin{bmatrix}1 \\\\ 1 \\\\ 1\\end{bmatrix}\\) and \\(\\bf{y} = \\begin{bmatrix}0 \\\\ 1 \\\\ 0\\end{bmatrix}\\). Then, \\(A = \\bf{x}\\bf{y}^H\\). So, \\(\\norm{A}_2 = \\norm{\\bf{x}}_2 \\norm{\\bf{y}}_2 = \\sqrt{3}\\).\n\n\nEquivalence of matrix norms\nWe saw that vector norms are equivalent in the sense that if a vector is small in one norm, it is small in all other norms and if it is large in one norm, it is large in all other norms. The same is true for matrix norms.\n\nTheorem 12 (Equivalence of matrix norms) Let \\(\\norm{\\cdot} : \\C^{m \\times n} \\to \\R\\) and \\(|||\\cdot|||:\\C^{m \\times n} \\to \\R\\) both be matrix norms. Then, there exist positive scalars \\(\\sigma\\) and \\(\\tau\\) such that for all \\(A \\in \\C^{m \\times n}\\)\n\\[\n\\sigma \\norm{A} \\leq |||A||| \\leq \\tau \\norm{A}\n\\]\n\nProof.\nThe proof again builds on the fact that the supremum over a compact set is achieved and can be replaced by the maximum. We will prove that there exists \\(\\tau\\) such that for all \\(A \\in \\C^{m \\times n}\\)\n\\[\n|||A||| \\leq \\tau \\norm{A}\n\\]\nLet \\(A \\in \\C^{m \\times n}\\) be an arbitrary matrix. Assume that \\(A \\neq 0\\) (the zero matrix). Then:\n\\[\n\\begin{align*}\n|||A||| &= \\frac{|||A|||}{\\norm{A}} \\cdot \\norm{A} & \\{\\text{Algebra}\\}\\\\\n&\\leq \\sup_{Z \\neq 0} \\left(\\frac{|||Z|||}{\\norm{Z}}\\right) \\norm{A} & \\{\\text{Definition of supremum}\\}\\\\\n&= \\sup_{Z \\neq 0} \\left(\\Biggl|\\Biggl|\\Biggl|\\frac{Z}{\\norm{Z}}\\Biggr|\\Biggr|\\Biggr|\\right) \\norm{A} & \\{\\text{Homogeneity}\\}\\\\\n&= \\left(\\sup_{\\norm{B} = 1} |||B||| \\right) \\norm{A} &\\{ \\text{change of variables }B=Z/\\norm{Z}\\}\\\\\n&= \\left(\\max_{\\norm{B}=1}|||B|||\\right) \\norm{A} & \\{\\text{the set }\\norm{B} = 1\\text{ is compact}\\}\n\\end{align*}\n\\]\nSo, we can choose \\(\\tau = \\max_{\\norm{B}=1} |||B|||\\).\nAlso, from the above proof, we deduce that, there exists \\(\\sigma\\) given by:\n\\[\n\\sigma = \\frac{1}{\\max_{|||B|||=1}||B||}\n\\]\nsuch that:\n\\[\n\\sigma \\norm{A} \\leq |||A|||\n\\]\nThis closes the proof. \\(\\blacksquare\\)\n\nExercise 9 Given \\(A \\in \\C^{m \\times n}\\), show that \\(\\norm{A}_2 \\leq \\norm{A}_F\\). For what matrix, is the equality attained?\n\nSolution.\nWe have:\n\\[\n\\begin{align*}\n\\norm{A}_2^2 &= \\max_{\\norm{x}_2 = 1} \\norm{Ax}_2^2  & \\{\\text{Definition}\\}\\\\\n&= \\max_{\\norm{x}_2 = 1} \\norm{\\begin{bmatrix}\n\\sum_{j=0}^{n-1} a_{0,j} x_j \\\\\n\\sum_{j=0}^{n-1} a_{1,j} x_j \\\\\n\\vdots\\\\\n\\sum_{j=0}^{n-1} a_{m-1,j} x_j\n\\end{bmatrix}\n}_2^2\\\\\n&= \\max_{\\norm{x}_2 = 1} \\sum_{i=0}^{m-1} \\Biggl|\\sum_{j=0}^{n-1} a_{i,j} x_j\\Biggr|^2\\\\\n&\\leq \\max_{\\norm{x}_2 = 1} \\sum_{i=0}^{m-1} \\left(\\sum_{j=0}^{n-1} |a_{i,j} x_j|\\right)^2 & \\{\\text{Triangle Inequality}\\}\\\\\n&\\leq \\max_{\\norm{x}_2 = 1} \\sum_{i=0}^{m-1} \\left\\{\\left(\\sum_{j=0}^{n-1} |a_{i,j}|^2\\right)^{1/2} \\left(\\sum_{j=0}^{n-1}|x_j|^2\\right)^{1/2}\\right\\}^2 & \\{\\text{Cauchy-Schwarz}\\}\\\\\n&=\\max_{\\norm{x}_2 = 1} \\sum_{i=0}^{m-1} \\left(\\sum_{j=0}^{n-1} |a_{i,j}|^2\\right) \\left(\\sum_{j=0}^{n-1}|x_j|^2\\right) & \\{\\text{Simplify}\\}\\\\\n&=\\sum_{i=0}^{m-1} \\left(\\sum_{j=0}^{n-1} |a_{i,j}|^2\\right) & \\{\\norm{x}_2 = 1\\}\\\\\n&= \\norm{A}_F\n\\end{align*}\n\\]\nAlso, consider\n\\[A = \\begin{bmatrix}1 & 0 \\\\ 0 & 0\\end{bmatrix}\\]\nThen, \\(\\norm{A}_2 = \\norm{A}_F = 1\\). So, the inequality \\(\\norm{A}_2 \\leq \\norm{A}_F\\) is tight. This closes the proof. \\(\\blacksquare\\)\n\nExercise 10 Let \\(A \\in \\C^{m \\times n}\\). The following table summarizes the equivalences of various matrix norms:\n\\[\n\\begin{array}{c|c|c|c}\n& \\norm{A}_1 \\leq \\sqrt{m}\\norm{A}_2 & \\norm{A}_1 \\leq m \\norm{A}_\\infty & \\norm{A}_1 \\leq \\sqrt{m}\\norm{A}_F \\\\\n\\hline\n\\norm{A}_2 \\leq \\sqrt{n}\\norm{A}_1 & & \\norm{A}_2 \\leq \\sqrt{m}\\norm{A}_\\infty & \\norm{A}_2 \\leq \\norm{A}_F \\\\\n\\hline\n\\norm{A}_\\infty \\leq n \\norm{A}_1 & \\norm{A}_\\infty \\leq \\sqrt{n} \\norm{A}_2 & & \\norm{A}_\\infty \\leq \\sqrt{n}\\norm{A}_F\\\\\n\\hline\n\\norm{A}_F \\leq \\sqrt{n} \\norm{A}_1 & \\norm{A}_F \\leq \\tau \\norm{A}_2 & \\norm{A}_F \\leq \\sqrt{m}\\norm{A}_\\infty\n\\end{array}\n\\]\nFor each, prove the inequality, including that it is a tight inequality for some nonzero \\(A\\). (Skip \\(\\norm{A}_F \\leq \\tau \\norm{A}_2\\), we revisit it in a later post)\n\nSolution.\nClaim. Our claim is that \\(\\norm{A}_1 \\leq \\sqrt{m} \\norm{A}_2\\).\nPartition \\(A = [a_0 | a_1 | \\ldots | a_{n-1}]\\).\nWe have:\n\\[\n\\begin{align*}\n\\norm{A}_1 &= \\max_{0 \\leq j &lt; n} \\norm{a_j}_1 & \\{\\text{Definition}\\}\\\\\n&= \\max_{0 \\leq j &lt; n} \\norm{\n    \\begin{bmatrix}\n    \\alpha_{0,j}\\\\\n    \\alpha_{1,j}\\\\\n    \\vdots\\\\\n    \\alpha_{m-1,j}\n    \\end{bmatrix}\n}_1\\\\\n&= \\max_{0 \\leq j &lt; n} \\sum_{i=0}^{m-1}|\\alpha_{i,j}| \\cdot |1|\\\\\n&= \\max_{0 \\leq j &lt; n} \\left(\\sum_{i=0}^{m-1}|\\alpha_{i,j}|^2\\right)^{1/2} \\left(\\sum_{i=0}^{m-1}|1|^2\\right)^{1/2} & \\{\\text{Cauchy-Schwarz}\\}\\\\\n&= \\max_{0 \\leq j &lt; n} \\norm{a_j}_2 \\sqrt{m}\\\\\n&= \\max_{0 \\leq j &lt; n} \\norm{A}_2 \\sqrt{m} & \\{\\norm{A_{i,j}}_2 \\leq \\norm{A}_2\\}\\\\\n&= \\sqrt{m} \\norm{A}_2\n\\end{align*}\n\\]\nMoreover, consider the matrix\n\\[\nA = \\begin{bmatrix}\n1 & 0 \\\\\n1 & 0\n\\end{bmatrix} =\n\\begin{bmatrix}\n1 \\\\\n1\n\\end{bmatrix}\n\\begin{bmatrix}\n1 & 0\n\\end{bmatrix}\n\\]\nWe have, \\(\\norm{A}_2 = \\sqrt{2}\\) and \\(\\norm{A}_1 = 2\\), so \\(\\norm{A}_1 = \\sqrt{2}\\norm{A}_2\\). Thus, the inequality is tight. This closes the proof.\nClaim. Our claim is that \\(\\norm{A}_1 \\leq m \\norm{A}_\\infty\\).\nSolution.\nWe have:\n\\[\n\\begin{align}\n\\norm{A}_1 &= \\max_{0 \\leq j &lt; n} \\norm{a_j}_1 & \\{\\text{Definition}\\}\\\\\n&= \\max_{0 \\leq j &lt; n} \\sum_{i=0}^{m-1}|\\alpha_{i,j}|\\\\\n&\\leq \\sum_{j=0}^{n-1} \\sum_{i=0}^{m-1} |\\alpha_{i,j}| = \\sum_{i=0}^{m-1} \\sum_{j=0}^{n-1} |\\alpha_{i,j}| \\\\\n&=\\sum_{i=0}^{m-1} \\norm{\\tilde{a}_i^T}_1\\\\\n&= m \\max_{0 \\leq i &lt; m} \\norm{\\tilde{a}_i^T}_1\\\\\n&= m \\norm{A}_\\infty\n\\end{align}\n\\]\nAgain, consider the matrix\n\\[\nA = \\begin{bmatrix}\n1 & 0\\\\\n1 & 0\n\\end{bmatrix}\n\\]\n\\(\\norm{A}_1 = 2\\) and \\(\\norm{A}_\\infty = 1\\), so \\(\\norm{A}_1 = 2 \\norm{A}_\\infty\\). Hence, the inequality is tight. This closes the proof.\nClaim. Our claim is that \\(\\norm{A}_1 \\leq \\sqrt{m}\\norm{A}_F\\).\nSolution.\nWe have shown that:\n\\[\n\\begin{align}\n\\norm{A}_1 &\\leq \\sqrt{m}\\norm{A}_2 \\\\\n\\norm{A}_2 &\\leq \\norm{A}_F\n\\end{align}\n\\]\nSo, we deduce that \\(\\norm{A}_1 \\leq \\sqrt{m}\\norm{A}_F\\). Moreover, consider\n\\[\nA = \\sqrt{2}I\n\\]\nThen, \\(\\norm{A}_1 = \\sqrt{2}\\) and \\(\\norm{A}_F = 2\\), so \\(\\norm{A}_1 = \\sqrt{2}\\norm{A}_F\\). Hence, the inequality is tight.\nClaim. Our claim is that \\(\\norm{A}_2 \\leq \\sqrt{n}\\norm{A}_1\\).\nSolution.\nWe have:\n\\[\n\\begin{align}\n\\norm{A}_2 &= \\max_{x \\neq 0} \\frac{\\norm{Ax}_2}{\\norm{x}_2} & \\{\\text{Definition}\\}\\\\\n&= \\max_{x \\neq 0} \\frac{\\norm{Ax}_1}{\\norm{x}_2}  & \\{\\norm{z}_2 \\leq \\norm{z}_1\\} \\\\\n&= \\max_{x \\neq 0} \\frac{\\norm{Ax}_1}{\\frac{1}{\\sqrt{n}}\\norm{x}_1}  & \\{\\norm{z}_1 \\leq \\sqrt{n}\\norm{z}_2\\} \\\\\n&= \\sqrt{n}\\norm{A}_1\n\\end{align}\n\\]\nAgain, consider the matrix \\(A = [1 | 1| \\ldots | 1]\\). Then, \\(\\norm{A}_2 = \\sqrt{n}\\) and \\(\\norm{A}_1 = 1\\). So, \\(\\norm{A}_2 = \\sqrt{n}\\norm{A}_1\\).\nClaim. Our claim is that \\(\\norm{A}_2 \\leq \\sqrt{m} \\norm{A}_\\infty\\).\nSolution.\n\\[\n\\begin{align*}\n\\norm{A}_2 &= \\max_{x \\neq 0} \\frac{\\norm{Ax}_2}{\\norm{x}_2} &\\{\\text{Definition}\\}\\\\\n&=\\max_{x \\neq 0} \\frac{\\norm{\\begin{bmatrix}\\tilde{a}_0^T \\\\ \\tilde{a}_1^T \\\\ \\vdots \\\\ \\tilde{a}_{m-1}^T\\end{bmatrix}x}_2}{\\norm{x}_2} &\\{\\text{Expose rows}\\}\\\\\n&=\\max_{x \\neq 0} \\frac{\\norm{\\begin{bmatrix}\\tilde{a}_0^T x \\\\ \\tilde{a}_1^T x\\\\ \\vdots \\\\ \\tilde{a}_{m-1}^T x\\end{bmatrix}}_2}{\\norm{x}_2} &\\{\\text{Algebra}\\}\\\\\n&\\leq \\max_{x \\neq 0} \\frac{\\sqrt{m}\\norm{Ax}_\\infty}{\\norm{x}_2} &\\{\\norm{z}_2 \\leq \\sqrt{n}\\norm{z}_\\infty\\}\\\\\n& \\leq \\max_{x \\neq 0} \\frac{\\sqrt{m}\\norm{Ax}_\\infty}{\\norm{x}_\\infty} &\\{\\norm{z}_\\infty \\leq \\norm{z}_2\\}\\\\\n&= \\sqrt{m} \\norm{A}_\\infty\n\\end{align*}\n\\]\nMoreover, consider the matrix\n\\[\nA = \\begin{bmatrix}\n1 \\\\\n1 \\\\\n\\vdots \\\\\n1\n\\end{bmatrix}\n\\]\nWe have \\(\\norm{A}_2 = \\sqrt{m}\\), \\(\\norm{A}_\\infty = 1\\), so \\(\\norm{A}_2 = \\sqrt{m}\\norm{A}_\\infty\\). Hence, the inequality is tight.\nClaim. Our claim is that \\(\\norm{A}_\\infty \\leq n \\norm{A}_1\\).\nSolution.\nWe have:\n\\[\n\\begin{align*}\n\\norm{A}_\\infty &= \\max_{x \\neq 0} \\frac{\\norm{Ax}_\\infty}{\\norm{x}_\\infty} & \\{\\text{Definition}\\}\\\\\n&\\leq  \\max_{x \\neq 0} \\frac{\\norm{Ax}_1}{\\norm{x}_\\infty} & \\{\\norm{x}_\\infty \\leq \\norm{x}_1\\}\\\\\n&\\leq  \\max_{x \\neq 0} \\frac{\\norm{Ax}_1}{\\frac{1}{n}\\norm{x}_1} & \\{\\norm{x}_1 \\leq n \\norm{x}_\\infty\\}\\\\\n&= n \\norm{A}_1\n\\end{align*}\n\\]\nMoreover, let \\(A = [1 | 1 | \\ldots | 1]\\). Then, \\(\\norm{A}_\\infty = n\\) and \\(\\norm{A}_1 = 1\\), so \\(\\norm{A}_\\infty = n \\norm{A}_1\\). Hence, the inequality is tight.\nClaim. Our claim is that \\(\\norm{A}_\\infty \\leq \\sqrt{n} \\norm{A}_2\\).\nSolution.\nWe have:\n\\[\n\\begin{align*}\n\\norm{A}_\\infty &= \\max_{x \\neq 0} \\frac{\\norm{Ax}_\\infty}{\\norm{x}_\\infty} & \\{\\text{Definition}\\}\\\\\n&\\leq  \\max_{x \\neq 0} \\frac{\\norm{Ax}_2}{\\norm{x}_\\infty} & \\{\\norm{x}_\\infty \\leq \\norm{x}_2\\}\\\\\n&\\leq  \\max_{x \\neq 0} \\frac{\\norm{Ax}_2}{\\frac{1}{\\sqrt{n}}\\norm{x}_2} & \\{\\norm{x}_2 \\leq \\sqrt{n} \\norm{x}_\\infty\\}\\\\\n&= \\sqrt{n} \\norm{A}_2\n\\end{align*}\n\\]\nMoreover, let \\(A = [1|1|\\ldots|1]\\)\nThen, \\(\\norm{A}_\\infty = n\\), \\(\\norm{A}_2 = \\sqrt{n}\\) and \\(\\norm{A}_\\infty = \\sqrt{n} \\norm{A}_2\\). So, the bound is tight.\nClaim. Our claim is that \\(\\norm{A}_\\infty \\leq \\sqrt{n}\\norm{A}_F\\).\nSolution. This is true since \\(\\norm{A}_\\infty \\leq \\sqrt{n}\\norm{A}_2\\) and \\(\\norm{A}_2 \\leq \\norm{A}_F\\).\nLet \\(A = [1 | 1 | \\ldots | 1]\\). Then, \\(\\norm{A}_\\infty = n\\) and \\(\\norm{A}_F = \\sqrt{n}\\). So, \\(\\norm{A}_\\infty = \\sqrt{n}\\norm{A}_F\\). The bound is tight.\nClaim. Our claim is that \\(\\norm{A}_F \\leq \\sqrt{n} \\norm{A}_1\\).\nSolution.\nWe have:\n\\[\n\\begin{align}\n\\norm{A}_F^2 &= \\sum_{i=0}^{m-1} \\sum_{j=0}^{n-1} |\\alpha_{i,j}|^2 & \\{\\text{Definition}\\}\\\\\n&= \\sum_{j=0}^{n-1} \\sum_{i=0}^{m-1} |\\alpha_{i,j}|^2 \\\\\n&\\leq \\sum_{j=0}^{n-1} \\left(\\sum_{i=0}^{m-1} |\\alpha_{i,j}| \\right)^2 \\\\\n&= \\sum_{j=0}^{n-1} \\norm{a_j}_1^2 \\\\\n&\\leq \\sum_{j=0}^{n-1} \\max_{j=0}^{n-1} \\norm{a_j}_1^2 \\\\\n&= n \\norm{A}_1^2\n\\end{align}\n\\]\nConsequently, \\(\\norm{A}_F \\leq \\sqrt{n}\\norm{A}_1\\). Let \\(A = [1 |1 | \\ldots| 1]\\). Then, \\(\\norm{A}_F = \\sqrt{n}\\) and \\(\\norm{A}_1 = 1\\), so \\(\\norm{A}_F = \\sqrt{n}\\norm{A}_1\\). Hence, the bound is tight.\nClaim. Our claim is that \\(\\norm{A}_F \\leq \\sqrt{m} \\norm{A}_\\infty\\).\nSolution.\nWe have:\n\\[\n\\begin{align}\n\\norm{A}_F^2 &= \\sum_{i=0}^{m-1} \\sum_{j=0}^{n-1} |\\alpha_{i,j}|^2 & \\{\\text{Definition}\\}\\\\\n&\\leq \\sum_{i=0}^{m-1} \\left(\\sum_{j=0}^{n-1} |\\alpha_{i,j}| \\right)^2 \\\\\n&= \\sum_{i=0}^{m-1} \\norm{\\tilde{a}_i^T}_1^2 \\\\\n&\\leq \\sum_{j=0}^{n-1} \\max_{i=0}^{m-1} \\norm{\\tilde{a}_i^T}_1^2 \\\\\n&= m \\norm{A}_\\infty^2\n\\end{align}\n\\]\nConsequently, \\(\\norm{A}_F \\leq \\sqrt{m}\\norm{A}_\\infty\\). Let \\(A = [1, 1, \\ldots, 1]^T\\). Then, \\(\\norm{A}_F = \\sqrt{m}\\) and \\(\\norm{A}_\\infty = 1\\), so \\(\\norm{A}_F = \\sqrt{m}\\norm{A}_1\\). Hence, the bound is tight.\n\n\nSub-multiplicative norms\nThere are a number of properties that we would like a matrix norm to have(but not all matrix norms do). Given a matrix norm \\(\\norm{\\cdot} : \\C^{m \\times n} \\to \\R\\), we may ask the following question. Do there exist vector norms \\(\\norm{\\cdot}_\\mu : C^m \\to \\R\\) and \\(\\norm{\\cdot}:\\C^n \\to R\\), such that the matrix norm is an upper bound on how much the non-zero vector \\(x\\) is stretched? That is, the following inequality is satisfied:\n\\[\n\\frac{\\norm{Ax}_\\mu}{\\norm{x}_\\nu} \\leq \\norm{A}\n\\]\nor equivalently\n\\[\n\\norm{Ax}_\\mu \\leq \\norm{A} \\norm{x}_\\nu\n\\]\nwhere this second formulation has the benefit that it also holds if \\(x = 0\\).\n\nDefinition 12 (Subordinate matrix norm) A matrix norm \\(\\norm{\\cdot}:\\C^{m \\times n} \\to \\R\\) is said to be subordinate to vector norms \\(\\norm{\\cdot}_\\mu :\\C^m \\to \\R\\) and \\(\\norm{\\cdot}_\\nu : \\C^n \\to \\R\\), if for all, \\(x \\in \\C^n\\),\n\\[\n\\norm{Ax}_\\mu \\leq \\norm{A} \\norm{x}_\\nu\n\\]\nIf \\(\\norm{\\cdot}_\\mu\\) and \\(\\norm{\\cdot}_\\nu\\) are the same norm (but perhaps for different \\(m\\) and \\(n\\)), then \\(\\norm{\\cdot}\\) is said to be subordinate to the given vector norm.\n\n\nExercise 11 Prove that the matrix \\(2\\)-norm is subordinate to the vector \\(2\\)-norm.\n\nProof.\nLet \\(A \\in C^{m \\times n}\\) and let \\(x \\in \\C^n\\). Assume that \\(x \\neq 0\\), for if \\(x = 0\\), then the inequality \\(\\norm{Ax}_2 \\leq \\norm{A}_2 \\norm{x}_2\\) is vacuously true.\nWe have:\n\\[\n\\begin{align}\n\\norm{Ax}_2&= \\left(\\frac{\\norm{Ax}_2}{\\norm{x}_2}\\right) \\norm{x}_2 & \\{x \\neq 0\\} \\\\\n&\\leq \\left(\\max_{y \\neq 0} \\frac{\\norm{Ay}_2}{\\norm{y}_2}\\right)\\norm{x}_2\\\\\n&= \\norm{A}_2 \\norm{x}_2\n\\end{align}\n\\]\nThis closes the proof. \\(\\blacksquare\\)\n\nExercise 12 Prove that the Frobenius norm is subordinate to the vector \\(2\\)-norm.\n\nProof.\nWe are interested to prove the claim that, \\((\\forall A \\in \\C^{m\\times n})(\\forall x \\in \\C^n)\\):\n\\[ \\norm{Ax}_2 \\leq \\norm{A}_F \\norm{x}_2 \\]\nAgain, without loss of generality, we have:\n\\[\n\\begin{align}\n\\norm{Ax}_2^2 &= \\norm{\n    \\begin{bmatrix}\n        \\sum_{j=0}^{n-1}\\alpha_{0,j} x_j \\\\\n        \\sum_{j=0}^{n-1}\\alpha_{1,j} x_j \\\\\n        \\vdots\n        \\sum_{j=0}^{n-1}\\alpha_{m-1,j} x_j\n    \\end{bmatrix}\n}_2^2 & \\{\\text{Definition}\\}\\\\\n&= \\sum_{i=0}^{m-1} \\Biggl| \\sum_{j=0}^{n-1}\\alpha_{i,j} x_j \\Biggr|^2\\\\\n&= \\sum_{i=0}^{m-1} \\left(\\sum_{j=0}^{n-1}|\\alpha_{i,j} x_j| \\right)^2 & \\{\\text{Triangle Inequality}\\}\\\\\n&\\leq \\sum_{i=0}^{m-1} \\left[\\left(\\sum_{j=0}^{n-1}|\\alpha_{i,j}|^2 \\right)  \\left(\\sum_{j=0}^{n-1} |x_j|^2\\right)\\right] & \\{\\text{Cauchy-Schwarz}\\}\\\\\n&= \\left(\\sum_{j=0}^{n-1} |x_j|^2\\right) \\left(\\sum_{i=0}^{m-1} \\sum_{j=0}^{n-1}|\\alpha_{i,j}|^2 \\right)   & \\{\\text{Algebra}\\}\\\\\n&= \\norm{A}_F^2 \\norm{x}_2^2\n\\end{align}\n\\]\nThis closes the proof. \\(\\blacksquare\\)\n\nTheorem 13 Induced matrix norms, \\(\\norm{\\cdot}_{\\mu,\\nu} : \\C^{m \\times n} \\to \\R\\) are subordinate to the norms, \\(\\norm{\\cdot}_\\mu\\) and \\(\\norm{\\cdot}_\\nu\\) that induce them.\n\nProof.\nWithout loss of generality, assume that \\(x \\neq 0\\), otherwise the proposition is vacuously true.\nWe have:\n\\[\n\\begin{align}\n\\norm{Ax}_\\mu &= \\frac{\\norm{Ax}_\\mu}{\\norm{x}_\\nu} \\norm{x}_\\nu \\\\\n&\\leq \\left(\\max_{x \\neq 0} \\frac{\\norm{Ax}_\\mu}{\\norm{x}_\\nu} \\right) \\norm{x}_\\nu \\\\\n&= \\left(\\max_{y \\neq 0} \\frac{\\norm{Ay}_\\mu}{\\norm{y}_\\nu} \\right) \\norm{x}_\\nu \\\\\n&= \\norm{A} \\norm{x}_\\nu\n\\end{align}\n\\]\nThis closes the proof. \\(\\blacksquare\\)\n\nCorollary 1 Any matrix \\(p\\)-norm is subordinate to the corresponding vector norm.\n\nProof.\nWithout the loss of generality, assume that \\(x \\neq 0\\). If \\(x = 0\\), the proposition is vacuously true.\nWe have:\n\\[\n\\begin{align}\n\\norm{Ax}_p &= \\left(\\frac{\\norm{Ax}_p}{\\norm{x}_p} \\right) \\norm{x}_p & \\{ x \\neq 0\\}\\\\\n&\\leq  \\left(\\max_{x \\neq 0} \\frac{\\norm{Ax}_p}{\\norm{x}_p} \\right) \\norm{x}_p\\\\\n&=  \\left(\\max_{y \\neq 0}\\frac{\\norm{Ay}_p}{\\norm{y}_p} \\right) \\norm{x}_p\\\\\n&= \\norm{A}_p \\norm{x}_p\n\\end{align}\n\\]\nThis closes the proof. \\(\\blacksquare\\)\nAnother desirable property that not all norms have is that:\n\\[\n\\norm{AB} \\leq \\norm{A} \\norm{B}\n\\]\nThis requires the given norm to be defined for all matrix sizes.\n\nDefinition 13 (Consistent matrix norm) A matrix norm \\(\\norm{\\cdot} : \\C^{m \\times n} \\to \\R\\) is said to be consistent matrix norm if it is defined for all \\(m\\) and \\(n\\), using the same formula for all \\(m\\) and \\(n\\).\n\n\nDefinition 14 (Submultiplicative matrix norm) A consistent matrix norm \\(\\norm{\\cdot} : \\C^{m \\times n} \\to \\R\\) is said to be submultiplicative if it satisfies:\n\\[\n\\norm{AB} \\leq \\norm{A} \\norm{B}\n\\]\n\n\nTheorem 14 Let \\(\\norm{\\cdot} : \\C^n \\to \\R\\) be a vector norm defined for all \\(n\\). Define the corresponding induced matrix norm as:\n\\[\n\\norm{A} = \\max_{x \\neq 0} \\frac{\\norm{Ax}}{\\norm{x}} = \\max_{\\norm{x} = 1} \\norm{Ax}\n\\]\nThen, for any \\(A \\in \\C^{m \\times k}\\) and \\(B^{k \\times n}\\), the inequality \\(\\norm{AB} \\leq \\norm{A} \\norm{B}\\) holds.\n\nIn other words, induced matrix norms are submultiplicative.\nProof.\nWe have:\n\\[\n\\begin{align}\n\\norm{AB} &= \\max_{\\norm{x}=1} \\norm{ABx} & \\{\\text{Definition}\\}\\\\\n&= \\max_{\\norm{x}=1} \\norm{A(Bx)} & \\{\\text{Associativity}\\}\\\\\n&\\leq \\max_{\\norm{x}=1} \\norm{A} \\norm{Bx} & \\{\\text{Subordinate property}\\}\\\\\n&\\leq \\max_{\\norm{x}=1} \\norm{A} \\norm{B} \\norm{x} & \\{\\text{Subordinate property}\\}\\\\\n&= \\norm{A} \\norm{B} & \\{\\norm{x}=1\\}\n\\end{align}\n\\]"
  },
  {
    "objectID": "posts/numpy-and-pandas-cheatsheet/index.html",
    "href": "posts/numpy-and-pandas-cheatsheet/index.html",
    "title": "numpy and pandas CheatSheet",
    "section": "",
    "text": "np.arange(start, stop, step) returns evenly spaced values in a given interval.\n\nimport numpy as np\n\nnp.arange(0.0, 1.1, 0.1)\n\narray([0. , 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1. ])"
  },
  {
    "objectID": "posts/numpy-and-pandas-cheatsheet/index.html#np.arangestartstopstep",
    "href": "posts/numpy-and-pandas-cheatsheet/index.html#np.arangestartstopstep",
    "title": "numpy and pandas CheatSheet",
    "section": "",
    "text": "np.arange(start, stop, step) returns evenly spaced values in a given interval.\n\nimport numpy as np\n\nnp.arange(0.0, 1.1, 0.1)\n\narray([0. , 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1. ])"
  },
  {
    "objectID": "posts/numpy-and-pandas-cheatsheet/index.html#np.zerosshape",
    "href": "posts/numpy-and-pandas-cheatsheet/index.html#np.zerosshape",
    "title": "numpy and pandas CheatSheet",
    "section": "np.zeros(shape)",
    "text": "np.zeros(shape)\n\nnp.zeros(shape=(3,3))\n\narray([[0., 0., 0.],\n       [0., 0., 0.],\n       [0., 0., 0.]])"
  },
  {
    "objectID": "posts/numpy-and-pandas-cheatsheet/index.html#np.zeros_like",
    "href": "posts/numpy-and-pandas-cheatsheet/index.html#np.zeros_like",
    "title": "numpy and pandas CheatSheet",
    "section": "np.zeros_like",
    "text": "np.zeros_like\n\nx = np.array([\n    [1, 2, 3, 4],\n    [5, 6, 7, 8],\n    [9,10,11,12]\n])\n\nnp.zeros_like(x)\n\narray([[0, 0, 0, 0],\n       [0, 0, 0, 0],\n       [0, 0, 0, 0]])"
  },
  {
    "objectID": "posts/numpy-and-pandas-cheatsheet/index.html#np.onesshape",
    "href": "posts/numpy-and-pandas-cheatsheet/index.html#np.onesshape",
    "title": "numpy and pandas CheatSheet",
    "section": "np.ones(shape)",
    "text": "np.ones(shape)\n\nimport numpy as np\n\n# The matrix of all ones of size 3 x 3\nnp.ones(shape=(3,3))\n\narray([[1., 1., 1.],\n       [1., 1., 1.],\n       [1., 1., 1.]])"
  },
  {
    "objectID": "posts/numpy-and-pandas-cheatsheet/index.html#np.eyen_rowsm_cols",
    "href": "posts/numpy-and-pandas-cheatsheet/index.html#np.eyen_rowsm_cols",
    "title": "numpy and pandas CheatSheet",
    "section": "np.eye(N_rows,M_cols)",
    "text": "np.eye(N_rows,M_cols)\n\nimport numpy as np\n\n# Identity matrix of size 3 x 3\nnp.eye(3,3)\n\narray([[1., 0., 0.],\n       [0., 1., 0.],\n       [0., 0., 1.]])"
  },
  {
    "objectID": "posts/numpy-and-pandas-cheatsheet/index.html#np.anyarray_like-axis-keepdims",
    "href": "posts/numpy-and-pandas-cheatsheet/index.html#np.anyarray_like-axis-keepdims",
    "title": "numpy and pandas CheatSheet",
    "section": "np.any(array_like, axis, keepdims)",
    "text": "np.any(array_like, axis, keepdims)\nTests whether any array element along a given axis evaluates to True.\n\nimport numpy as np\n\nnp.any([[True, False], [True, True]])\n\nnp.True_\n\n\n\nnp.any([[True, False], [True, True]], axis=0)\n\narray([ True,  True])\n\n\n\nnp.any([[True, False], [True, False]], axis=0)\n\narray([ True, False])\n\n\n\nnp.any([[True, False], [True, False]], axis=1)\n\narray([ True,  True])\n\n\n\nnp.any([[True, False], [True, False]], axis=1, keepdims=True)\n\narray([[ True],\n       [ True]])"
  },
  {
    "objectID": "posts/numpy-and-pandas-cheatsheet/index.html#np.allarray_like-axis-keepdims",
    "href": "posts/numpy-and-pandas-cheatsheet/index.html#np.allarray_like-axis-keepdims",
    "title": "numpy and pandas CheatSheet",
    "section": "np.all(array_like, axis, keepdims)",
    "text": "np.all(array_like, axis, keepdims)\n\nimport numpy as np\n\nnp.all([[True, False], [True, True]])\n\nnp.False_\n\n\n\nnp.all([[True, False], [True, True]], axis=0)\n\narray([ True, False])\n\n\n\nnp.all([[True, False], [True, False]], axis=1)\n\narray([False, False])"
  },
  {
    "objectID": "posts/numpy-and-pandas-cheatsheet/index.html#np.tilearray-reps",
    "href": "posts/numpy-and-pandas-cheatsheet/index.html#np.tilearray-reps",
    "title": "numpy and pandas CheatSheet",
    "section": "np.tile(array, reps)",
    "text": "np.tile(array, reps)\nConstructs an array by repeating the array reps number of times.\n\nimport numpy as np\n\na = np.array([0, 1, 2])\nnp.tile(a, 2)\n\narray([0, 1, 2, 0, 1, 2])\n\n\n\nimport numpy as np\n\na = np.array([0, 1, 2])\nnp.tile(a, (2, 2))\n\narray([[0, 1, 2, 0, 1, 2],\n       [0, 1, 2, 0, 1, 2]])"
  },
  {
    "objectID": "posts/numpy-and-pandas-cheatsheet/index.html#np.repeatarray-repeats-axis",
    "href": "posts/numpy-and-pandas-cheatsheet/index.html#np.repeatarray-repeats-axis",
    "title": "numpy and pandas CheatSheet",
    "section": "np.repeat(array, repeats, axis)",
    "text": "np.repeat(array, repeats, axis)\nRepeats each element of an array after themselves.\n\nnp.repeat(3,4)\n\narray([3, 3, 3, 3])\n\n\n\nx = np.array([\n    [1, 2],\n    [3, 4],\n    [5, 6]\n])\n\nnp.repeat(x, repeats=2,axis=0)\n\narray([[1, 2],\n       [1, 2],\n       [3, 4],\n       [3, 4],\n       [5, 6],\n       [5, 6]])\n\n\n\nnp.repeat(x, repeats = 2, axis=1)\n\narray([[1, 1, 2, 2],\n       [3, 3, 4, 4],\n       [5, 5, 6, 6]])"
  },
  {
    "objectID": "posts/numpy-and-pandas-cheatsheet/index.html#broadcasting",
    "href": "posts/numpy-and-pandas-cheatsheet/index.html#broadcasting",
    "title": "numpy and pandas CheatSheet",
    "section": "Broadcasting",
    "text": "Broadcasting\nThe term broadcasting describes how NumPy treats arrays with different shapes during arithmetic operations. Subject to certain constraints, the smaller array is broadcast across the larger array, so that they have compatible shapes. Broadcasting provides a means of vectorizing array operations so that looping occurs in C, instead of Python.\nFor example, let \\(\\mathbf{x}=[x_0, x_1, \\ldots, x_{n-1}]\\) be a column vector and let \\(k\\) be a scalar.\nThe scalar multiplication \\(\\mathbf{y} = k \\mathbf{x}\\) multiplies each element \\(x_0, x_1, x_2, \\ldots, x_{n-1}\\) by \\(k\\).\nWe can think of the scalar \\(k\\) as being stretched during the arithmetic operation into a vector with the same length as \\(\\mathbf{x}\\). The stretching analogy is only conceptual. NumPy is smart enough to use the original scalar value without actually making copies."
  },
  {
    "objectID": "posts/numpy-and-pandas-cheatsheet/index.html#np.wherecondition-x-y",
    "href": "posts/numpy-and-pandas-cheatsheet/index.html#np.wherecondition-x-y",
    "title": "numpy and pandas CheatSheet",
    "section": "np.where(condition, x, y)",
    "text": "np.where(condition, x, y)\nFor each element \\(x\\) in the array, if the array-element satisfies the condition, then x values are returned, else y values are returned.\n\nimport numpy as np\n\nx = np.arange(10)\nx &gt; 5   # this returns a filter mask - an array of booleans\n\narray([False, False, False, False, False, False,  True,  True,  True,\n        True])\n\n\n\nx[x &gt; 5]\n\narray([6, 7, 8, 9])\n\n\n\nnp.where(x &gt; 5, x**2, x)\n\narray([ 0,  1,  2,  3,  4,  5, 36, 49, 64, 81])"
  },
  {
    "objectID": "posts/numpy-and-pandas-cheatsheet/index.html#pandas.dataframedatacolumns",
    "href": "posts/numpy-and-pandas-cheatsheet/index.html#pandas.dataframedatacolumns",
    "title": "numpy and pandas CheatSheet",
    "section": "pandas.DataFrame(data,columns)",
    "text": "pandas.DataFrame(data,columns)\nA pandas.DataFrame represents a two dimensional, size-mutable, potentially heterogenous collection of data.\ndata can be any iterable, dict or another dataframe.\n\nimport pandas as pd\nfrom datetime import date\ndata = {\n    'Date' : [ date(2025,1,31), date(2025,2,1)],\n    'Close price' : [ 101.25, 103.00 ]\n}\n\ndf = pd.DataFrame(data)\ndf\n\n\n\n\n\n\n\n\nDate\nClose price\n\n\n\n\n0\n2025-01-31\n101.25\n\n\n1\n2025-02-01\n103.00"
  },
  {
    "objectID": "posts/numpy-and-pandas-cheatsheet/index.html#indexing-a-dataframe",
    "href": "posts/numpy-and-pandas-cheatsheet/index.html#indexing-a-dataframe",
    "title": "numpy and pandas CheatSheet",
    "section": "Indexing a DataFrame",
    "text": "Indexing a DataFrame\n\n# Access a single value for a row/column label pair\ndf.at[1, 'Close price']\n\nnp.float64(103.0)\n\n\n\ndf.at[1, 'Close price'] = 102.50\n\n\n# Accessing a group of rows and columns by label(s) or boolean array\ndf.loc[0]\n\nDate           2025-01-31\nClose price        101.25\nName: 0, dtype: object\n\n\n\ndf = pd.DataFrame({\n    'A' : [1, 2, 3, 4, 5, 6],\n    'B' : [7, 8, 9, 10, 11, 12],\n    'C' : [13, 14, 15, 16, 17, 18]\n})\ndf\n\n\n\n\n\n\n\n\nA\nB\nC\n\n\n\n\n0\n1\n7\n13\n\n\n1\n2\n8\n14\n\n\n2\n3\n9\n15\n\n\n3\n4\n10\n16\n\n\n4\n5\n11\n17\n\n\n5\n6\n12\n18\n\n\n\n\n\n\n\n\n# Accessing a group of rows and columns by label(s) or boolean array\ndf.loc[0]\n\nA     1\nB     7\nC    13\nName: 0, dtype: int64\n\n\n\n# Integer location based indexing\ndf.iloc[1:3,1]\n\n1    8\n2    9\nName: B, dtype: int64"
  },
  {
    "objectID": "posts/numpy-and-pandas-cheatsheet/index.html#filtering-data",
    "href": "posts/numpy-and-pandas-cheatsheet/index.html#filtering-data",
    "title": "numpy and pandas CheatSheet",
    "section": "Filtering data",
    "text": "Filtering data\n\n# This produces a filter mask\ndf['B'] &gt;= 10\n\n0    False\n1    False\n2    False\n3     True\n4     True\n5     True\nName: B, dtype: bool\n\n\n\ndf[df['B'] &gt;= 10]\n\n\n\n\n\n\n\n\nA\nB\nC\n\n\n\n\n3\n4\n10\n16\n\n\n4\n5\n11\n17\n\n\n5\n6\n12\n18"
  },
  {
    "objectID": "posts/numpy-and-pandas-cheatsheet/index.html#data-transformation",
    "href": "posts/numpy-and-pandas-cheatsheet/index.html#data-transformation",
    "title": "numpy and pandas CheatSheet",
    "section": "Data transformation",
    "text": "Data transformation\n\ndf['B'] = df.apply(lambda row: row['B'] ** 2 , axis=1)\ndf\n\n\n\n\n\n\n\n\nA\nB\nC\n\n\n\n\n0\n1\n49\n13\n\n\n1\n2\n64\n14\n\n\n2\n3\n81\n15\n\n\n3\n4\n100\n16\n\n\n4\n5\n121\n17\n\n\n5\n6\n144\n18"
  },
  {
    "objectID": "posts/positive_definiteness/index.html",
    "href": "posts/positive_definiteness/index.html",
    "title": "Positive Definiteness",
    "section": "",
    "text": "Definition 1. A real-valued symmetric matrix \\(A\\) is positive-definite (written as \\(A \\succ 0\\)), if for every real valued vector \\(\\mathbf{x} \\in \\mathbf{R}^n \\setminus \\{\\mathbf{0}\\}\\), the quadratic form\n\\[\\begin{align*}\nq(\\mathbf{x}) = \\mathbf{x}^T A \\mathbf{x} &gt; 0\n\\end{align*}\\]\nThe real-value symmetric matrix \\(A\\) is positive semi-definite (written as \\(A \\succeq 0\\)) if :\n\\[\\begin{align*}\nq(\\mathbf{x}) = \\mathbf{x}^T A \\mathbf{x} \\geq 0\n\\end{align*}\\]\n\\(\\forall \\mathbf{x} \\in \\mathbf{R}^n \\setminus \\{\\mathbf{0}\\}\\).\nIntuitively, positive definite matrices are like strictly positive real numbers. Consider a scalar \\(a &gt; 0\\). The sign of \\(ax\\) will depend on the sign of \\(x\\). And \\(x\\cdot ax &gt; 0\\). However, if \\(a &lt; 0\\), multiplying it with \\(x\\) will flip the sign, so \\(x\\) and \\(ax\\) have opposite signs and \\(x \\cdot ax &lt; 0\\).\nIf \\(A \\succ 0\\), then by definition \\(\\mathbf{x}^T A \\mathbf{x} &gt; 0\\) for all \\(\\mathbf{x} \\in \\mathbf{R}^n\\). Thus, the vector \\(\\mathbf{x}\\) and it’s transformed self \\(A\\mathbf{x}\\) should make an angle \\(\\theta \\in \\left[-\\frac{\\pi}{2},\\frac{\\pi}{2}\\right]\\). Both \\(\\mathbf{x}\\) and \\(A\\mathbf{x}\\) lie on the same side of the hyperplane \\(\\mathbf{x}^{\\perp}\\).\n\n%load_ext itikz\n\n\n\nShow the code\n%%itikz --temp-dir --tex-packages=tikz --tikz-libraries=arrows --implicit-standalone\n\\begin{tikzpicture}[scale=1.5]\n\\draw [-&gt;] (-2,0) -- (6,0) node [below] {\\huge $x_1$};\n\\draw [-&gt;] (0,-2) -- (0,6) node [above] {\\huge $x_2$};\n\\draw [-&gt;] (0,0) -- (3,1) node [above] {\\huge $\\mathbf{x}$};\n\\draw [-&gt;] (0,0) -- (2,5) node [above] {\\huge $A\\mathbf{x}$};\n\\draw [dashed] (-2,6) -- (1,-3) node [] {\\huge $\\mathbf{x}^{\\perp}$};\n\\draw[draw=green!50!black,thick] (1,1/3) arc (18.43:68.19:1) node [midway,above] {\\huge $\\theta$};\n\\end{tikzpicture}"
  },
  {
    "objectID": "posts/positive_definiteness/index.html#positive-definite-matrices",
    "href": "posts/positive_definiteness/index.html#positive-definite-matrices",
    "title": "Positive Definiteness",
    "section": "",
    "text": "Definition 1. A real-valued symmetric matrix \\(A\\) is positive-definite (written as \\(A \\succ 0\\)), if for every real valued vector \\(\\mathbf{x} \\in \\mathbf{R}^n \\setminus \\{\\mathbf{0}\\}\\), the quadratic form\n\\[\\begin{align*}\nq(\\mathbf{x}) = \\mathbf{x}^T A \\mathbf{x} &gt; 0\n\\end{align*}\\]\nThe real-value symmetric matrix \\(A\\) is positive semi-definite (written as \\(A \\succeq 0\\)) if :\n\\[\\begin{align*}\nq(\\mathbf{x}) = \\mathbf{x}^T A \\mathbf{x} \\geq 0\n\\end{align*}\\]\n\\(\\forall \\mathbf{x} \\in \\mathbf{R}^n \\setminus \\{\\mathbf{0}\\}\\).\nIntuitively, positive definite matrices are like strictly positive real numbers. Consider a scalar \\(a &gt; 0\\). The sign of \\(ax\\) will depend on the sign of \\(x\\). And \\(x\\cdot ax &gt; 0\\). However, if \\(a &lt; 0\\), multiplying it with \\(x\\) will flip the sign, so \\(x\\) and \\(ax\\) have opposite signs and \\(x \\cdot ax &lt; 0\\).\nIf \\(A \\succ 0\\), then by definition \\(\\mathbf{x}^T A \\mathbf{x} &gt; 0\\) for all \\(\\mathbf{x} \\in \\mathbf{R}^n\\). Thus, the vector \\(\\mathbf{x}\\) and it’s transformed self \\(A\\mathbf{x}\\) should make an angle \\(\\theta \\in \\left[-\\frac{\\pi}{2},\\frac{\\pi}{2}\\right]\\). Both \\(\\mathbf{x}\\) and \\(A\\mathbf{x}\\) lie on the same side of the hyperplane \\(\\mathbf{x}^{\\perp}\\).\n\n%load_ext itikz\n\n\n\nShow the code\n%%itikz --temp-dir --tex-packages=tikz --tikz-libraries=arrows --implicit-standalone\n\\begin{tikzpicture}[scale=1.5]\n\\draw [-&gt;] (-2,0) -- (6,0) node [below] {\\huge $x_1$};\n\\draw [-&gt;] (0,-2) -- (0,6) node [above] {\\huge $x_2$};\n\\draw [-&gt;] (0,0) -- (3,1) node [above] {\\huge $\\mathbf{x}$};\n\\draw [-&gt;] (0,0) -- (2,5) node [above] {\\huge $A\\mathbf{x}$};\n\\draw [dashed] (-2,6) -- (1,-3) node [] {\\huge $\\mathbf{x}^{\\perp}$};\n\\draw[draw=green!50!black,thick] (1,1/3) arc (18.43:68.19:1) node [midway,above] {\\huge $\\theta$};\n\\end{tikzpicture}"
  },
  {
    "objectID": "posts/positive_definiteness/index.html#convex-functions",
    "href": "posts/positive_definiteness/index.html#convex-functions",
    "title": "Positive Definiteness",
    "section": "Convex functions",
    "text": "Convex functions\nThere is a second geometric way to think about positive definite matrices : a quadratic form is convex when the matrix is symmetric and positive definite.\nDefinition 2. (Convex function) A function \\(f:\\mathbf{R}^n \\to \\mathbf{R}\\) is convex, if for all \\(\\mathbf{x},\\mathbf{y}\\in \\mathbf{R}^n\\) and \\(0 \\leq \\lambda \\leq 1\\), we have:\n\\[\\begin{align*}\nf(\\lambda \\mathbf{x} + (1-\\lambda)\\mathbf{y}) \\leq \\lambda f(\\mathbf{x}) + (1-\\lambda) f(\\mathbf{y}) \\tag{1}\n\\end{align*}\\]\nProposition 3. Assume that the function \\(f:\\mathbf{R}^n \\to \\mathbf{R}\\) is differentiable. Then, \\(f\\) is convex, if and only if, for all \\(\\mathbf{x},\\mathbf{y} \\in \\mathbf{R}^n\\), the inequality\n\\[\\begin{align*}\nf(\\mathbf{y}) \\geq f(\\mathbf{x}) + \\nabla f(\\mathbf{y})^T (\\mathbf{y} - \\mathbf{x}) \\tag{2}\n\\end{align*}\\]\nis satisfied.\nProof.\n\\(\\Longrightarrow\\) direction.\nAssume that \\(f\\) is convex and let \\(\\mathbf{x} \\neq \\mathbf{y} \\in \\mathbf{R}^n\\). The convexity of \\(f\\) implies that:\n\\[\\begin{align*}\nf((\\mathbf{x} + \\mathbf{y})/2) \\leq \\frac{1}{2}f(\\mathbf{x}) + \\frac{1}{2}f(\\mathbf{y})\n\\end{align*}\\]\nDenote now \\(\\mathbf{h} = \\mathbf{y}-\\mathbf{x}\\). Then this inequality reads:\n\\[\\begin{align*}\nf(\\mathbf{x} + \\mathbf{h}/2) \\leq \\frac{1}{2} f(\\mathbf{x}) + \\frac{1}{2}f(\\mathbf{x} + \\mathbf{h})\n\\end{align*}\\]\nUsing elementary transformations, we have:\n\\[\\begin{align*}\n\\frac{f(\\mathbf{x} + \\mathbf{h}/2)}{1/2} &\\leq f(\\mathbf{x}) + f(\\mathbf{x} + \\mathbf{h}) \\\\\nf(\\mathbf{x} + \\mathbf{h}) - f(\\mathbf{x}) &\\geq \\frac{f(\\mathbf{x} + \\mathbf{h}/2) - f(\\mathbf{x})}{1/2}\n\\end{align*}\\]\nRepeating this line of argumentation:\n\\[\\begin{align*}\nf(\\mathbf{x} + \\mathbf{h}) - f(\\mathbf{x}) \\geq \\frac{f(\\mathbf{x} + \\mathbf{h}/2) - f(\\mathbf{x})}{1/2} \\geq \\frac{f(\\mathbf{x} + \\mathbf{h}/4) - f(\\mathbf{x})}{1/4}\n\\end{align*}\\]\nConsequently,\n\\[\\begin{align*}\nf(\\mathbf{x} + \\mathbf{h}) - f(\\mathbf{x}) \\geq \\frac{f(\\mathbf{x} + 2^{-k}\\mathbf{h}) - f(\\mathbf{x})}{2^{-k}} \\tag{2}\n\\end{align*}\\]\nBy the order limit theorem,\n\\[\\begin{align*}\nf(\\mathbf{x} + \\mathbf{h}) - f(\\mathbf{x}) \\geq \\lim_{k \\to \\infty}\\frac{f(\\mathbf{x} + 2^{-k}\\mathbf{h}) - f(\\mathbf{x})}{2^{-k}} = D_{\\mathbf{h}}f(\\mathbf{x}) = \\nabla f(\\mathbf{x}) \\cdot (\\mathbf{y} - \\mathbf{x})\n\\end{align*}\\]\nReplacing \\(\\mathbf{y}-\\mathbf{x}\\) by \\(\\mathbf{h}\\), we have:\n\\[\\begin{align*}\nf(\\mathbf{y}) \\geq f(\\mathbf{x}) + \\nabla f(\\mathbf{x})^T (\\mathbf{y} - \\mathbf{x})\n\\end{align*}\\]\n\\(\\Longleftarrow\\) direction.\nLet \\(\\mathbf{w}, \\mathbf{z} \\in \\mathbf{R}^n\\). Moreover, denote:\n\\[\\begin{align*}\n\\mathbf{x} := \\lambda \\mathbf{w} + (1-\\lambda)\\mathbf{z}\n\\end{align*}\\]\nThen, the inequality in (1) implies that:\n\\[\\begin{align*}\nf(\\mathbf{w}) &\\geq f(\\mathbf{x}) + \\nabla f(\\mathbf{x})^T (\\mathbf{w} - \\mathbf{x})\\\\\nf(\\mathbf{z}) &\\geq f(\\mathbf{x}) + \\nabla f(\\mathbf{x})^T (\\mathbf{z} - \\mathbf{x}) \\tag{3}\n\\end{align*}\\]\nNote moreover that:\n\\[\\begin{align*}\n\\mathbf{w} - \\mathbf{x} &= (1-\\lambda)(\\mathbf{w}-\\mathbf{z})\\\\\n\\mathbf{z} - \\mathbf{x} &= \\lambda(\\mathbf{z}-\\mathbf{w})\n\\end{align*}\\]\nThus, if we multiply the first line in (3) with \\(\\lambda\\) and the second line with \\((1-\\lambda)\\) and then add the two inequalities, we obtain:\n\\[\\begin{align*}\n\\lambda f(\\mathbf{w}) + (1-\\lambda)f(\\mathbf{z}) &\\geq f(\\mathbf{x}) + \\nabla f(\\mathbf{x})[\\lambda(1-\\lambda)(\\mathbf{w} - \\mathbf{z} + \\mathbf{z} - \\mathbf{w})\\\\\n&=f(\\lambda \\mathbf{w} + (1-\\lambda)\\mathbf{z})\n\\end{align*}\\]\nSince \\(\\mathbf{w}\\) and \\(\\mathbf{z}\\) were arbitrary, this proves the convexity of \\(f\\).\nThe convexity of a differentiable function can either be characterized by the fact that all secants lie above the graph or that all tangents lie below the graph.\nWe state the next corollary without proof.\nCorollary 4. Assume that \\(f:\\mathbf{R}^n \\to \\mathbf{R}\\) is convex and differentiable. Then \\(\\mathbf{x}^*\\) is a global minimizer of \\(f\\), if and only if \\(\\nabla f(\\mathbf{x}^{*}) = 0\\).\n\nHessians of convex functions.\nProposition 5. (Second derivative test) Let \\(f:X\\subseteq\\mathbf{R}^n \\to \\mathbf{R}\\) be a \\(C^2\\) function and suppose that \\(\\mathbf{a}\\in X\\) is a critical point of \\(f\\). If the hessian \\(\\nabla^2 f(\\mathbf{a})\\) is positive definite, then \\(f\\) has a local minimum at \\(\\mathbf{a}\\).\nProof.\nLet \\(q(\\mathbf{x}) = \\mathbf{x}^T A \\mathbf{x}\\) be a quadratic form. We have:\n\\[\\begin{align*}\nq(\\lambda \\mathbf{h}) &= (\\lambda \\mathbf{x}^T) A (\\lambda \\mathbf{x})\\\\\n&= \\lambda^2 \\mathbf{x}^T A \\mathbf{x}\\\\\n&= \\lambda^2 q(\\mathbf{x}) \\tag{4}\n\\end{align*}\\]\nWe show that if \\(A\\) is the symmetric matrix associated with a positive definite quadratic form \\(q(\\mathbf{x})\\), then there exists \\(M &gt; 0\\) such that:\n\\[\\begin{align*}\nq(\\mathbf{h}) \\geq M ||\\mathbf{h}||^2 \\tag{5}\n\\end{align*}\\]\nfor all \\(\\mathbf{h} \\in \\mathbf{R}^n\\).\nFirst note that when \\(\\mathbf{h} = \\mathbf{0}\\), then \\(q(\\mathbf{h})=q(\\mathbf{0})=0\\), so the conclusion holds trivially in this case.\nNext, suppose that when \\(\\mathbf{h}\\) is a unit vector, that is \\(||\\mathbf{h}||=1\\). The set of all unit vectors in \\(\\mathbf{R}^n\\) is an \\((n-1)\\)-dimensional hypersphere, which is a compact set. By the extreme-value theorem, the restriction of \\(q\\) to \\(S\\) must achieve a global minimum value \\(M\\) somewhere on \\(S\\). Thus, \\(q(\\mathbf{h}) \\geq M\\) for all \\(\\mathbf{h} \\in S\\).\nFinally, let \\(\\mathbf{h}\\) be any nonzero vector in \\(\\mathbf{R}^n\\). Then, its normalization \\(\\mathbf{h}/||\\mathbf{h}||\\) is a unit vector and also lies in \\(S\\). Therefore, by the result of step 1, we have:\n\\[\\begin{align*}\nq(\\mathbf{h}) &= q\\left(||\\mathbf{h}|| \\cdot \\frac{\\mathbf{h}}{||\\mathbf{h}||} \\right)\\\\\n&= ||\\mathbf{h}||^2 q\\left(\\frac{\\mathbf{h}}{||\\mathbf{h}||}\\right)\\\\\n&\\geq M ||\\mathbf{h}||^2\n\\end{align*}\\]\nWe can now prove the theorem.\nBy the second order Taylor’s formula, we have that, for the critical point \\(\\mathbf{a}\\) of \\(f\\),\n\\[\\begin{align*}\nf(\\mathbf{x}) = f(\\mathbf{a}) + \\nabla f(\\mathbf{x})\\cdot(\\mathbf{x} - \\mathbf{a}) + \\frac{1}{2}(\\mathbf{x} - \\mathbf{a})^T \\nabla^2 f(\\mathbf{a}) (\\mathbf{x} - \\mathbf{a}) + R_2(\\mathbf{x},\\mathbf{a}) \\tag{6}\n\\end{align*}\\]\nwhere \\(R_2(\\mathbf{x},\\mathbf{a})/||\\mathbf{x}-\\mathbf{a}||^2 \\to 0\\) as \\(\\mathbf{x} \\to \\mathbf{a}\\).\nIf \\(\\nabla^2 f(\\mathbf{a}) \\succ 0\\), then\n\\[\\begin{align*}\n\\frac{1}{2}(\\mathbf{x} - \\mathbf{a})^T \\nabla^2 f(\\mathbf{a}) (\\mathbf{x} - \\mathbf{a}) \\geq M||\\mathbf{x} - \\mathbf{a}||^2 \\tag{7}\n\\end{align*}\\]\nPick \\(\\epsilon = M\\). By the definition of limits, since \\(R_2(\\mathbf{x},\\mathbf{a})/||\\mathbf{x} - \\mathbf{a}||^2 \\to 0\\) as \\(\\mathbf{x} \\to \\mathbf{a}\\), there exists \\(\\delta &gt; 0\\), such that for all \\(||\\mathbf{x} - \\mathbf{a}||&lt;\\delta\\), \\(|R_2(\\mathbf{x},\\mathbf{a})|/||\\mathbf{x} - \\mathbf{a}||^2 &lt; M\\). Or equivalently,\n\\[\\begin{align*}\n|R_2(\\mathbf{x},\\mathbf{a})| &lt; M||\\mathbf{x}-\\mathbf{a}||^2\n\\end{align*}\\]\nthat is:\n\\[\\begin{align*}\n-M||\\mathbf{x}-\\mathbf{a}||^2 &lt; R_2(\\mathbf{x},\\mathbf{a}) &lt; M||\\mathbf{x}-\\mathbf{a}||^2 \\tag{8}\n\\end{align*}\\]\nPutting together (6), (7) and (8),\n\\[\\begin{align*}\nf(\\mathbf{x}) - f(\\mathbf{a}) &gt; 0\n\\end{align*}\\]\nso that \\(f\\) has a minimum at \\(\\mathbf{a}\\).\nProposition 6. A twice differentiable function \\(f:\\mathbf{R}^n \\to \\mathbf{R}\\) is convex, if and only if, the hessian \\(\\nabla^2 f(\\mathbf{x})\\) is positive semi-definite for all \\(\\mathbf{x}\\in\\mathbf{R}^n\\).\nProof.\nAssume first that \\(f\\) is convex and let \\(\\mathbf{x}\\in\\mathbf{R}^n\\). Define the \\(g:\\mathbf{R}^n \\to \\mathbf{R}\\) as a function of the vector \\(\\mathbf{y}\\) setting:\n\\[\\begin{align*}\ng(\\mathbf{y}) := f(\\mathbf{y}) - \\nabla f(\\mathbf{x})^T (\\mathbf{y} - \\mathbf{x})\n\\end{align*}\\]\nConsider the mapping \\(T(\\mathbf{y}) = -\\nabla f(\\mathbf{x})^T (\\mathbf{y} - \\mathbf{x})\\). We have:\n\\[\\begin{align*}\nT(\\lambda \\mathbf{y}_1 + (1-\\lambda)\\mathbf{y}_2) &= -\\nabla f(\\mathbf{x})^T (\\lambda \\mathbf{y}_1 + (1-\\lambda)\\mathbf{y}_2 - \\mathbf{x}) \\\\\n&= \\lambda [-\\nabla f(\\mathbf{x})^T (\\mathbf{y}_1 - \\mathbf{x})] + (1-\\lambda)[-\\nabla f(\\mathbf{x})^T (\\mathbf{y}_2 - \\mathbf{x})]\\\\\n&=\\lambda T(\\mathbf{y}_1) + (1-\\lambda)T(\\mathbf{y}_2)\n\\end{align*}\\]\nThus, \\(T\\) is an affine transformation.\nSince an affine transformation is convex and \\(f\\) is convex, their sum \\(g\\) is also convex. Moreover \\(g\\) is a function of \\(\\mathbf{y}\\), treating \\(\\mathbf{x}\\) as a constant, we have:\n\\[\\begin{align*}\n\\nabla g(\\mathbf{y}) = \\nabla f(\\mathbf{y}) - \\nabla f(\\mathbf{x})\n\\end{align*}\\]\nand\n\\[\\begin{align*}\n\\nabla^2 g(\\mathbf{y}) = \\nabla^2 f(\\mathbf{y})\n\\end{align*}\\]\nfor all \\(\\mathbf{y} \\in \\mathbf{R}^n\\). In particular, \\(\\nabla g(\\mathbf{x}) = 0\\). Thus, corollary (4) implies that \\(\\mathbf{x}\\) is a global minimizer of \\(g\\). Now, the second order necessary condition for a minimizer implies that \\(\\nabla^2 g(\\mathbf{x})\\) is positive semi-definite. Since \\(\\nabla^2 g(\\mathbf{x}) = \\nabla^2 f(\\mathbf{x})\\), this proves that the Hessian of \\(f\\) is positive semi-definite for all \\(\\mathbf{x} \\in \\mathbf{R}^n\\).\nThus, a function \\(f\\) is convex, if its Hessian is everywhere positive semi-definite. This allows us to test whether a given function is convex."
  },
  {
    "objectID": "posts/positive_definiteness/index.html#tests-for-positive-definiteness",
    "href": "posts/positive_definiteness/index.html#tests-for-positive-definiteness",
    "title": "Positive Definiteness",
    "section": "Tests for positive definiteness",
    "text": "Tests for positive definiteness\nOne of the most important theorems of finite dimensional vector spaces is the spectral theorem. Every real symmetric matrix \\(A\\) is orthogonally diagonalizable. It admits \\(A = Q\\Lambda Q^T\\) factorization, where \\(Q\\) is an orthogonal matrix and \\(\\Lambda = diag(\\lambda_1,\\ldots,\\lambda_n)\\).\nFrom basic algebra, we know that, if \\(A\\) is a non-singular matrix, with all it’s pivot elements \\(a_{kk}^{(k)}\\) non-zero in the Gaussian elimination process, then \\(A=LDU\\) where \\(L\\) and \\(U\\) are lower and upper unitriangular matrices and \\(D\\) is a diagonal matrix consisting of the pivots of \\(A\\). If \\(A\\) is symmetric, then it admits the unique factorization \\(A = LDL^T\\).\nConsider the quadratic form \\(q(\\mathbf{x}) = \\mathbf{x}^T A \\mathbf{x}\\). Substituting \\(A = Q \\Lambda Q^T\\), we have:\n\\[\\begin{align*}\nq(\\mathbf{x}) &= \\mathbf{x}^T A \\mathbf{x} \\\\\n&= \\mathbf{x}^T Q \\Lambda Q^T \\mathbf{x} \\\\\n&= (Q^T \\mathbf{x})^T \\Lambda (Q^T \\mathbf{x}) \\tag{9}\n\\end{align*}\\]\nBut, the matrix \\(Q = [\\mathbf{q}_1,\\mathbf{q}_2,\\ldots,\\mathbf{q}_n]\\). Moreover, \\(A=Q\\Lambda Q^T\\) implies that \\(AQ^{-1} = AQ^T = \\Lambda Q^T\\). Therefore:\n\\[\\begin{align*}\nA\\begin{bmatrix}\n\\mathbf{q}_1\\\\\n\\mathbf{q}_2\\\\\n\\vdots\\\\\n\\mathbf{q}_n\n\\end{bmatrix}=\\begin{bmatrix}\n\\lambda_1 \\\\\n& \\lambda_2 \\\\\n& & \\ddots \\\\\n& & & \\lambda_n\n\\end{bmatrix}\\begin{bmatrix}\n\\mathbf{q}_1\\\\\n\\mathbf{q}_2\\\\\n\\vdots\\\\\n\\mathbf{q}_n\n\\end{bmatrix}\n\\end{align*}\\]\nSo, \\(\\mathbf{q}_1,\\ldots,\\mathbf{q}_n\\) are the eigenvectors of \\(A\\). Now,\n\\[\\begin{align*}\n\\mathbf{q}_1 &= [q_{11}, q_{21}, \\ldots,q_{n1}]^T = q_{11} \\mathbf{e}_1 + q_{21} \\mathbf{e}_2 + \\ldots + q_{n1} \\mathbf{e}_n\\\\\n\\mathbf{q}_2 &= [q_{12}, q_{22}, \\ldots,q_{n2}]^T = q_{12} \\mathbf{e}_1 + q_{22} \\mathbf{e}_2 + \\ldots + q_{n2} \\mathbf{e}_n\\\\\n\\vdots \\\\\n\\mathbf{q}_n &= [q_{1n}, q_{2n}, \\ldots,q_{nn}]^T = q_{1n} \\mathbf{e}_1 + q_{2n} \\mathbf{e}_2 + \\ldots + q_{nn} \\mathbf{e}_n\n\\end{align*}\\]\nSo,\n\\[\\begin{align*}\nQ = \\begin{bmatrix}\nq_{11} & \\ldots & q_{1n}\\\\\n\\vdots & & \\vdots \\\\\nq_{n1} & \\ldots & q_{nn}\n\\end{bmatrix}\n\\end{align*}\\]\nis the change of basis matrix from the standard basis \\(\\mathcal{B}_{old}=\\{\\mathbf{e}_1,\\ldots,\\mathbf{e}_n\\}\\) to the eigenvector basis \\(\\mathcal{B}_{new}=\\{\\mathbf{q}_1,\\ldots,\\mathbf{q}_n\\}\\).\nIf \\(\\mathbf{x}\\) are the coordinates of a vector in the standard basis and \\(\\mathbf{y}\\) are its coordinates in the eigenvector basis, then \\(\\mathbf{x}=Q\\mathbf{y}\\).\nHence, substituting \\(\\mathbf{y}=Q^{-1}\\mathbf{x}=Q^T \\mathbf{x}\\) in equation (9), the quadratic form becomes:\n\\[\\begin{align*}\nq(\\mathbf{x}) &= \\mathbf{x}^T A \\mathbf{x} = \\mathbf{y}^T \\Lambda \\mathbf{y}\\\\\n&=\\lambda_1 y_1^2 + \\lambda_2 y_2^2 + \\ldots + \\lambda_n y_n^2\n\\end{align*}\\]\nwhere we have changed the axes to be aligned across the eigenvectors of \\(A\\).\nThe coefficients \\(\\lambda_i\\) are the diagonal entries of \\(\\Lambda\\) and are the pivots of \\(A\\). The quadratic form is strictly positive for all \\(\\mathbf{y}\\), if and only if the eigenvalues \\(\\lambda_1 &gt; 0\\), \\(\\lambda_2 &gt;0\\), \\(\\ldots\\), \\(\\lambda_n &gt; 0\\).\nTheorem 7. (Positive definiteness) Let \\(A \\in \\mathbf{R}^{n \\times n}\\) be a real symmetric positive definite(SPD) matrix. Then, the following statements are equivalent:\n\n\\(A\\) is non-singular and has positive pivot elements when performing Gaussian elimination (without row exchanges).\n\\(A\\) admits a factorization \\(A = Q \\Lambda Q^T\\), where \\(\\Lambda = diag(\\lambda_1,\\ldots,\\lambda_n)\\) such that \\(\\lambda_i &gt; 0\\) for all \\(i=1,2,3,\\ldots,n\\)."
  },
  {
    "objectID": "posts/positive_definiteness/index.html#cholesky-factorization",
    "href": "posts/positive_definiteness/index.html#cholesky-factorization",
    "title": "Positive Definiteness",
    "section": "Cholesky Factorization",
    "text": "Cholesky Factorization\nWe can push the result above slightly further in the positive definite case. Since, each eigen value \\(\\lambda_i\\) is positive, the quadratic form can be written as a sum of squares:\n\\[\\begin{align*}\n\\lambda_1 y_1^2 + \\lambda_2 y_2^2 + \\ldots + \\lambda_n y_n^2 &= (\\sqrt{\\lambda_1} y_1)^2 + \\ldots + (\\sqrt{\\lambda_n} y_n)^2\\\\\n&= z_1^2 + z^2 + \\ldots + z_n^2\n\\end{align*}\\]\nwhere \\(z_i =\\sqrt{\\lambda_i}y_i\\). In the matrix form, we are writing:\n\\[\\begin{align*}\n\\hat{q}(\\mathbf{y}) &= \\mathbf{y}^T \\Lambda \\mathbf{y}\\\\\n&= \\mathbf{z}^T \\mathbf{z}\\\\\n&= ||\\mathbf{z}||^2\n\\end{align*}\\]\nwhere \\(\\mathbf{z} = S\\mathbf{y}\\) with \\(S=diag(\\sqrt{\\lambda_1},\\ldots,\\sqrt{\\lambda_n})\\). Since \\(\\Lambda = S^2=SS^T\\), \\(S\\) can be thought as the square root of the original matrix \\(\\Lambda\\). Substituting back into the equation \\(A=Q\\Lambda Q^T\\), we deduce the Cholesky factorization:\n\\[\\begin{align*}\nA &= Q\\Lambda Q^T\\\\\n&= QS S^T Q^T\\\\\n&= MM^T\n\\end{align*}\\]"
  },
  {
    "objectID": "posts/positive_definiteness/index.html#level-plots-of-a-positive-definite-quadratic-form-are-ellipsoids",
    "href": "posts/positive_definiteness/index.html#level-plots-of-a-positive-definite-quadratic-form-are-ellipsoids",
    "title": "Positive Definiteness",
    "section": "Level plots of a positive definite quadratic form are ellipsoids",
    "text": "Level plots of a positive definite quadratic form are ellipsoids\nConsider the level plot of a positive definite quadratic form \\(q(\\mathbf{x})\\):\n\\[\\begin{align*}\nq(\\mathbf{x}) = \\hat{q}(\\mathbf{y}) &= 1 \\\\\n\\lambda_1 y_1^2 + \\ldots + \\lambda_n y_n^2 &= 1\\\\\n\\frac{y_1^2}{\\left(\\frac{1}{\\sqrt{\\lambda_1}}\\right)^2}+\\frac{y_2^2}{\\left(\\frac{1}{\\sqrt{\\lambda_2}}\\right)^2} + \\ldots + \\frac{y_n^2}{\\left(\\frac{1}{\\sqrt{\\lambda_n}}\\right)^2} &= 1\n\\end{align*}\\]\nThus, the level plot of a positive definite quadratic form is an ellipse (if \\(n=2\\)) or an ellipsoid (if \\(n &gt; 2\\)) with axes aligned along the eigenvectors and lengths \\(\\frac{1}{\\sqrt{\\lambda_i}}\\), \\(i=1,2,3,\\ldots,n\\).\n\nimport numpy as np\nimport matplotlib.pyplot as plt\n\nA = np.array([[4, 3], [3, 4]])\n\neigenvalues, eigenvectors = np.linalg.eig(A)\n\n# The parameteric equation of an ellipse is\n# (x(theta),y(theta))=(a cos theta, b sin theta)\n# where a and b are semi-major and semi-minor axes\ntheta = np.linspace(0, 2 * np.pi, 10000)\ny1 = np.sqrt(1 / eigenvalues[0]) * np.cos(theta)\ny2 = np.sqrt(1 / eigenvalues[1]) * np.sin(theta)\n\nY = np.array([y1,y2])\n\n# The change of basis matrix from the standard basis to the eigen vector basis\n# is Q. So, x = Q y, where Q = [q_1,q_2]; q_1, q_2 are the eigenvectors of A.\n\nQ = eigenvectors.T\nX = np.dot(Q, Y)\nx1 = X[0,:]\nx2 = X[1,:]\n\nplt.xlim([-1, 1])\nplt.grid(True)\nplt.title(r'$q(\\mathbf{x})=\\mathbf{x}^T A \\mathbf{x} = 1$')\nplt.xlabel(r'$x_1$')\nplt.ylabel(r'$x_2$')\nplt.plot(x1, x2)\nplt.show()"
  },
  {
    "objectID": "posts/properties-of-brownian-motion/index.html",
    "href": "posts/properties-of-brownian-motion/index.html",
    "title": "Properties of Brownian Motion",
    "section": "",
    "text": "Let \\(B(t)\\) be a fixed Brownian motion. We give below some simple properties that follow directly from the definition of the Brownian Motion.\n\nFor any \\(t\\geq0\\), \\(B(t)\\) is normally distributed with mean \\(0\\) and variance \\(t\\). For any \\(s,t\\geq0\\) we have \\(\\mathbb{E}(B_{s}B_{t})=\\min\\{s,t\\}\\).\n\nProof. From condition (1), we have that \\(B_{0}=0\\). From condition (2), \\(B_{t}-B_{0}=B_{t}\\) is normally distributed with mean \\(0\\) and variance \\(t\\).\nAssume that \\(s&lt;t\\).\nWe have:\n\\[\\begin{aligned}\n\\mathbb{E}(B_{s}B_{t}) & =\\mathbb{E}\\left[B_{s}(B_{t}-B_{s}+B_{s})\\right] & \\{\\text{Write }B_{t}=B_{t}-B_{s}+B_{s}\\}\\\\\n& =\\mathbb{E}[B_{s}(B_{t}-B_{s})]+\\mathbb{E}[B_{s}^{2}] & \\{\\text{Linearity of expectations}\\}\\\\\n& =\\mathbb{E}[B_{s}]\\mathbb{E}(B_{t}-B_{s})+s & \\{B_{s},(B_{t}-B_{s})\\text{ are independent}\\}\\\\\n& =0\\cdot0+s\\\\\n& =s\n\\end{aligned}\\]\nThis closes the proof. ◻ :::\n\n(Translation Invariance) For fixed \\(t_{0}\\geq0\\), the stochastic process \\(\\tilde{B}(t)=B(t+t_{0})-B(t_{0})\\) is also a Brownian motion.\n\n\nProof. Proof. Firstly, the stochastic process \\(\\tilde{B}(t)\\) is such that:\n(1) \\(\\tilde{B}(0)=B(t_{0})-B(t_{0})=0\\). Hence, it satisfies condition (1).\n(2) Let \\(s&lt;t\\). We have: \\(\\tilde{B}(t)-\\tilde{B}(s)=B(t+t_{0})-B(s+t_{0})\\) which a Gaussian random variable with mean 0 and variance \\(t-s\\). Hence, for \\(a\\leq b\\),\n\\[\\begin{aligned}\n\\mathbb{P}\\{a\\leq & \\tilde{B}(t)\\leq b\\}=\\frac{1}{\\sqrt{2\\pi(t-s)}}\\int_{a}^{b}e^{-\\frac{x^{2}}{2(t-s)}}dx\n\\end{aligned}\\]\nHence, it satisfies condition (2).\n(3) To check condition (3) for \\(\\tilde{B}(t)\\), we may assume \\(t_{0}&gt;0\\). Then, for any \\(0\\leq t_{1}\\leq t_{2}\\leq\\ldots\\leq t_{n}\\), we have:\n\\[0&lt;t_{0}\\leq t_{0}+t_{1}\\leq t_{0}+t_{2}\\leq\\ldots\\leq t_{0}+t_{n}\\]\nSo, \\(B(t_{1}+t_{0})-B(t_{0})\\), \\(B(t_{2}+t_{0})-B(t_{1}+t_{0})\\), \\(\\ldots\\), \\(B(t_{k}+t_{0})-B(t_{k-1}+t_{0})\\), \\(\\ldots\\), \\(B(t_{n}+t_{0})-B(t_{n-1}+t_{0})\\) are independent random variables. Consequently, \\(\\tilde{B}(t)\\) satisfies condition (3).\nThis closes the proof. ◻\n\nThe above translation invariance property says that a Brownian motion starts afresh at any moment as a new Brownian motion.\n\n(Scaling Invariance) For any real number \\(\\lambda&gt;0\\), the stochastic process \\(\\tilde{B}(t)=B(\\lambda t)/\\sqrt{\\lambda}\\) is also a Brownian motion.\n\n\nProof. Proof. The scaled stochastic process \\(\\tilde{B}(t)\\) is such that:\n(1) \\(\\tilde{B}(0)=0\\). Hence it satisfies condition (1).\n(2) Let \\(s&lt;t\\). Then, \\(\\lambda s&lt;\\lambda t\\). We have:\n\\[\\begin{aligned}\n\\tilde{B}(t)-\\tilde{B}(s) & =\\frac{1}{\\sqrt{\\lambda}}(B(\\lambda t)-B(\\lambda s))\n\\end{aligned}\\]\nNow, \\(B(\\lambda t)-B(\\lambda s)\\) is a Gaussian random variable with mean \\(0\\) and variance \\(\\lambda(t-s)\\). We know that, if \\(X\\) is a random variable with mean \\(\\mu\\) and variance \\(\\sigma^{2}\\), \\(Z=\\left(\\frac{X-\\mu}{\\sigma}\\right)\\) has mean \\(0\\) and variance \\(1\\). Consequently, \\(\\frac{B(\\lambda t)-B(\\lambda s)}{\\sqrt{\\lambda}}\\) is a Gaussian random variable with mean \\(0\\) and variance \\((t-s)\\).\nHence, \\(\\tilde{B}(t)-\\tilde{B}(s)\\) is normal distributed with mean \\(0\\) and variance \\(t-s\\) and it satisfies condition (2).\n(3) To check condition (3) for \\(\\tilde{B}(t)\\), we may assume \\(t_{0}&gt;0\\). Then, for any \\(0\\leq t_{1}\\leq t_{2}\\leq\\ldots\\leq t_{n}\\), we have:\n\\[0\\leq\\lambda t_{1}\\leq\\lambda t_{2}\\leq\\ldots\\leq\\lambda t_{n}\\]\nConsequently, the random variables \\(B(\\lambda t_{k})-B(\\lambda t_{k-1})\\), \\(k=1,2,3,\\ldots,n\\) are independent. Hence it follows that \\(\\frac{1}{\\sqrt{\\lambda}}[B(\\lambda t_{k})-B(\\lambda t_{k-1})]\\) for \\(k=1,2,\\ldots,n\\) are also independent random variables.\nThis closes the proof. ◻\n\nIt follows from the scaling invariance property that for any \\(\\lambda&gt;0\\) and \\(0\\leq t_{1}\\leq t_{2}\\leq\\ldots\\leq t_{n}\\), the random vectors:\n\\[(B(\\lambda t_{1}),B(\\lambda t_{2}),\\ldots,B(\\lambda t_{n}))\\quad(\\sqrt{\\lambda}B(t_{1}),\\sqrt{\\lambda}B(t_{1}),\\ldots,\\sqrt{\\lambda}B(t_{n}))\\]\nhave the same distribution.\nThe scaling property shows that Brownian motion is self-similar, much like a fractal. To see this, suppose we zoom into a Brownian motion path very close to zero, say on the interval \\([0,10^{-6}]\\). If the Brownian motion path were smooth and differentiable, the closer we zoom in around the origin, the flatter the function will look. In the limit, we would essentially see a straight line given by the derivative at \\(0\\). However, what we see with the Brownian motion is very different. The scaling property means that for \\(a=10^{-6}\\),\n\\[\n\\begin{aligned}\n(B_{10^{-6}t,}t\\in[0,1]) & \\stackrel{\\text{distrib.}}{=}(10^{-3}B_{t},t\\in[0,1])\n\\end{aligned}\n\\]\nwhere \\(\\stackrel{\\text{distrib.}}{=}\\) means equality of the distribution of the two processes. In other words, Brownian motion on \\([0,10^{-6}]\\) looks like a Browian motion on \\([0,1]\\), but with its amplitude multiplied by a factor of \\(10^{-3}\\). In particular, it will remain rugged as we zoom in, unlike a smooth function.\n\n(Reflection at time \\(s\\)) The process \\((-B_{t},t\\geq0)\\) is a Brownian motion. More generally, for any \\(s\\geq0\\), the process \\((\\tilde{B}(t),t\\geq0)\\) defined by:\n\\[\\begin{aligned}\n\\tilde{B}(t) & =\\begin{cases}\nB_{t} & \\text{if }t\\leq s\\\\\nB_{s}-(B_{t}-B_{s}) & \\text{if }t&gt;s\n\\end{cases}\\label{eq:reflection-property}\n\\end{aligned}\\]\nis a Brownian motion.\n\n\nProof. Proof. (a) Consider the process \\(\\tilde{B}(t)=(-B_{t},t\\geq0)\\).\n(1) \\(\\tilde{B}(0)=0\\).\n(2) If \\(X\\) is a Gaussian random variable with mean \\(0\\) and variance \\(t-s\\), \\(-X\\) is also Gaussian with mean \\(0\\) and variance \\(t-s\\). Thus, \\(\\tilde{B}(t)-\\tilde{B}(s)=-(B(t)-B(s))\\) is also Gaussian with mean \\(0\\) and variance \\((t-s)\\). Hence condition (2) is satisfied.\n(3) Assume that \\(0\\leq t_{0}\\leq t_{1}\\leq\\ldots\\leq t_{n}\\). Then, the random variables \\(-(B(t_{k})-B(t_{k-1}))\\) are independent for \\(k=1,2,3,\\ldots,n\\). Hence, condition (3) is satisfied.\n(b) Consider the process \\(\\tilde{B}(t)\\) as defined in ([eq:reflection-property]).\nFix an \\(s\\geq0\\).\n(1) Let \\(t=0\\). Then, \\(t\\leq s\\). \\(\\tilde{B}(t)=\\tilde{B}(0)=B(0)=0\\).\n(2) Let \\(t_{1}&lt;t_{2}\\leq s\\). Then, \\(\\tilde{B}(t_{2})-\\tilde{B}(t_{1})=B(t_{2})-B(t_{1})\\). This is a Gaussian random variable with mean \\(0\\) and variance \\(t_{2}-t_{1}\\).\nLet \\(t_{1}&lt;s&lt;t_{2}\\). Then, \\(\\tilde{B}(t_{2})-\\tilde{B}(t_{1})=B(s)-(B(t_{2})-B(s))-B(t_{1})=(B(s)-B(t_{1}))-(B(t_{2})-B(s))\\). Since, \\(B(s)-B(t_{1})\\) and \\(B(t_{2})-B(s)\\) are independent Gaussian random variables, any linear combination of these is Gaussian. Moreover, its mean is zero. The variance is given by:\n\\[\\begin{aligned}\nVar[\\tilde{B}(t_{2})-\\tilde{B}(t_{1})] & =Var[B(s)-B(t_{1})]+Var[B(t_{2})-B(s)]\\\\\n& =(s-t_{1})+(t_{2}-s)\\\\\n& =t_{2}-t_{1}\n\\end{aligned}\\]\nLet \\(s&lt;t_{1}&lt;t_{2}\\). Then, \\[\\begin{aligned}\n\\tilde{B}(t_{2})-\\tilde{B}(t_{1}) & =B_{s}-(B_{t_{2}}-B_{s})-(B_{s}-(B_{t_{1}}-B_{s}))\\\\\n& =\\cancel{B_{s}}-(B_{t_{2}}-\\cancel{B_{s}})-(\\cancel{B_{s}}-(B_{t_{1}}-\\cancel{B_{s}}))\\\\\n& =-(B_{t_{2}}-B_{t_{1}})\n\\end{aligned}\\]\nHence, \\(\\tilde{B}(t_{2})-\\tilde{B}(t_{1})\\) is again a Gaussian random variable with mean \\(0\\) and variance \\(t_{2}-t_{1}\\). Hence, condition (3) is satisfied.\n(3) Assume that \\(0\\leq t_{1}\\leq\\ldots\\leq t_{k-1}\\leq s\\leq t_{k}\\leq\\ldots\\leq t_{n}\\). From the above discussion, the increments \\(\\tilde{B}(t_{2})-\\tilde{B}(t_{1})\\), \\(\\ldots\\), \\(\\tilde{B}(s)-\\tilde{B}(t_{k-1})\\), \\(\\tilde{B}(t_{k})-\\tilde{B}(s)\\), \\(\\ldots\\), \\(\\tilde{B}(t_{n})-\\tilde{B}(t_{n-1})\\) are independent increments. The increment \\(\\tilde{B}(t_{k})-\\tilde{B}(t_{k-1})\\) only depends on the random variables \\(\\tilde{B}(s)-\\tilde{B}(t_{k-1})\\) and \\(\\tilde{B}(t_{k})-\\tilde{B}(s)\\). Thus, \\(\\tilde{B}(t_{2})-\\tilde{B}(t_{1})\\), \\(\\ldots\\), \\(\\tilde{B}(t_{k})-\\tilde{B}(t_{k-1})\\), \\(\\ldots\\), \\(\\tilde{B}(t_{n})-\\tilde{B}(t_{n-1})\\) are independent. ◻\n\n\n(Time Reversal). Let \\((B_{t},t\\geq0)\\) be a Brownian motion. Show that the process \\((B_{1}-B_{1-t},t\\in[0,1])\\) has the distribution of a standard brownian motion on \\([0,1]\\).\n\n\nProof. Proof. (1) At \\(t=0\\), \\(B(1)-B(1-t)=B(1)-B(1)=0\\).\n(2) Let \\(s&lt;t\\). Then, \\(1-t&lt;1-s\\). So, the increment :\n\\[\\begin{aligned}\n(B(1)-B(1-t))-(B(1)-B(1-s)) & =B(1-s)-B(1-t)\n\\end{aligned}\\]\nhas a Gaussian distribution. It’s mean is \\(0\\) and variance is \\((1-s)-(1-t)=t-s\\).\n(3) Let \\(0\\leq t_{1}\\leq t_{2}\\leq\\ldots\\leq t_{n}\\). Then:\n\\[1-t_{n}\\leq\\ldots\\leq1-t_{k}\\leq1-t_{k-1}\\leq\\ldots\\leq1-t_{2}\\leq1-t_{1}\\]\nConsider the increments of the process for \\(k=1,2,\\ldots,n\\):\n\\[\\begin{aligned}\n(B(1)-B(1-t_{k}))-(B(1)-B(1-t_{k-1})) & =B(1-t_{k-1})-B(1-t_{k})\n\\end{aligned}\\]\nThey are independent random variables. Hence, condition (3) is satisfied. ◻\n\n\n(Evaluating Brownian Probabilities). Let’s compute the probability that \\(B_{1}&gt;0\\) and \\(B_{2}&gt;0\\). We know from the definition that \\((B_{1},B_{2})\\) is a Gaussian vector with mean \\(0\\) and covariance matrix:\n\\[\\begin{aligned}\nC & =\\left[\\begin{array}{cc}\n1 & 1\\\\\n1 & 2\n\\end{array}\\right]\n\\end{aligned}\\]\nThe determinant of \\(C\\) is \\(1\\). By performing row operations on the augmented matrix \\([C|I]\\) we find that:\n\\[\\begin{aligned}\nC^{-1} & =\\left[\\begin{array}{cc}\n2 & -1\\\\\n-1 & 1\n\\end{array}\\right]\n\\end{aligned}\\]\nThus, the probability \\(\\mathbb{P}(B_{1}&gt;0,B_{2}&gt;0)\\) can be expressed as:\n\\[\\begin{aligned}\n\\mathbb{P}(B_{1}&gt;0,B_{2}&gt;0) & =\\frac{1}{\\sqrt{(2\\pi)^{2}}}\\int_{0}^{\\infty}\\int_{0}^{\\infty}\\exp\\left[-\\frac{1}{2}(2x_{1}^{2}-2x_{1}x_{2}+x_{2}^{2}\\right]dx_{2}dx_{1}\n\\end{aligned}\\]\nThis integral can be evaluated using a calculator or software and is equal to \\(3/8\\). The probability can also be computed using the independence of increments. The increments \\((B_{1},B_{2}-B_{1})\\) are IID standard Gaussians. We know their joint PDF. It remains to integrate over the correct region of \\(\\mathbf{R}^{2}\\) which in this case will be:\n\\[\\begin{aligned}\nD^{*} & =\\{(z_{1},z_{2}):(z_{1}&gt;0,z_{1}+z_{2}&gt;0)\\}\n\\end{aligned}\\]\nWe have:\n\\[\\begin{aligned}\n\\mathbb{P}(B_{1}&gt;0,B_{2}&gt;0) & =\\frac{1}{2\\pi}\\int_{0}^{\\infty}\\int_{z_{2}=-z_{1}}^{z_{2}=\\infty}e^{-(z_{1}^{2}+z_{2}^{2})/2}dz_{2}dz_{1}\n\\end{aligned}\\]\nIt turns out that this integral can be evaluated exactly. Indeed by writing \\(B_{1}=Z_{1}\\) and \\(Z_{2}=B_{2}-B_{1}\\) and splitting the probability on the event \\(\\{Z_{2}\\geq0\\}\\) and its complement, we have that \\(\\mathbb{P}(B_{1}\\geq0,B_{2}\\geq0)\\) equals:\n\\[\\begin{aligned}\n\\mathbb{P}(B_{1}\\geq0,B_{2}\\geq0) & =\\mathbb{P}(Z_{1}\\geq0,Z_{1}+Z_{2}&gt;0,Z_{2}\\geq0)+\\mathbb{P}(Z_{1}\\geq0,Z_{1}+Z_{2}&gt;0,Z_{2}&lt;0)\\\\\n& =\\mathbb{P}(Z_{1}\\geq0,Z_{2}\\geq0)+\\mathbb{P}(Z_{1}\\geq0,Z_{1}&gt;-Z_{2},-Z_{2}&gt;0)\\\\\n& =\\mathbb{P}(Z_{1}\\geq0,Z_{2}\\geq0)+\\mathbb{P}(Z_{1}\\geq0,Z_{1}&gt;Z_{2},Z_{2}&gt;0)\\\\\n& =\\frac{1}{4}+\\frac{1}{8}\\\\\n& =\\frac{3}{8}\n\\end{aligned}\\]\nNote that, by symmetry, \\(\\mathbb{P}(Z_{1}\\geq0,Z_{1}&gt;Z_{2},Z_{2}&gt;0)=\\mathbb{P}(Z_{1}\\geq0,Z_{1}\\leq Z_{2},Z_{2}&gt;0)=\\frac{1}{8}\\).\n\n\n(Another look at Ornstein Uhlenbeck process.) Consider the process \\((X_{t},t\\in\\mathbf{R})\\) defined by :\n\\[\\begin{aligned}\nX_{t} & =\\frac{e^{-2t}}{\\sqrt{2}}B(e^{4t}),\\quad t\\in\\mathbf{R}\n\\end{aligned}\\]\nHere the process \\((B_{e^{4t}},t\\ge0)\\) is called a time change of Brownian motion, since the time is now quantitfied by an increasing function of \\(t\\) namely \\(e^{4t}\\). The example \\((B(\\lambda t),t\\geq0)\\) in the scaling property is another example of time change.\n\nIt turns out that \\((X_{t},t\\in\\mathbf{R})\\) is a stationary Ornstein-Uhlenbeck process. (Here the index of time is \\(\\mathbf{R}\\) instead of \\([0,\\infty)\\), but the definition also applies as the process is stationary. Since the original brownian motion \\(B(t)\\) is a Gaussian process, any finite dimensional vector \\((B(t_{1}),\\ldots,B(t_{n}))\\) is Gaussian. It follows that:\n\\[(B(T_{1}),\\ldots,B(T_{n}))=\\frac{1}{\\sqrt{2}}(e^{-2t_{1}}B(e^{4t_{1}}),\\ldots,e^{-2t_{n}}B(e^{4t_{n}}))\\]\nis also a Gaussian vector. (Note, once we fix \\(t_{1},t_{2},\\ldots,t_{n}\\), \\(e^{-4t_{1}},\\ldots,e^{-4t_{n}}\\) are constants.) Hence, \\((X_{t},t\\in\\mathbf{R})\\) is a Gaussian process.\nThe mean of \\((X_{t},t\\in\\mathbf{R})\\) is:\n\\[\\begin{aligned}\n\\mathbb{E}[X_{t}] & =\\frac{e^{-2t}}{\\sqrt{2}}\\mathbb{E}[B(e^{4t})]=0\n\\end{aligned}\\]\nAnd if \\(s&lt;t\\),\n\\[\\begin{aligned}\n\\mathbb{E}[X_{s}X_{t}] & =\\frac{e^{-2(s+t)}}{2}\\mathbb{E}[B(e^{4s})B(e^{4t})]\\\\\n& =\\frac{e^{-2(s+t)}}{2}e^{4s}\\\\\n& =\\frac{e^{-2(t-s)}}{2}\n\\end{aligned}\\]\nTwo Gaussian processes having the same mean and covariance have the same distribution. Hence, it proves the claim that \\((X_{t})\\) is a stationary OU process.\n\n\n\nFirst we review the definitions of the Riemann integral and the Riemann-Stieljtes integral in Calculus.\n\nA partition \\(P\\) of \\([a,b]\\) is a finite set of points from \\([a,b]\\) that includes both \\([a,b].\\)The notational convention is to always list the points of a partition \\(P=\\{a=x_{0},x_{1},x_{2},\\ldots,x_{n}=b\\}\\) in increasing order. Thus:\n\\[a=x_{0}&lt;x_{1}&lt;\\ldots&lt;x_{k-1}&lt;x_{k}&lt;\\ldots&lt;x_{n}=b\\]\n\nFor each subinterval \\([x_{k-1},x_{k}]\\) of \\(P\\), let\n\\[\\begin{aligned}\nm_{k} & =\\inf\\{f(x):x\\in[x_{k-1},x_{k}]\\}\\\\\nM_{k} & =\\sup\\{f(x):x\\in[x_{k-1},x_{k}]\\}\n\\end{aligned}\\]\nThe lower sum of \\(f\\) with respect to \\(P\\) is given by :\n\\[\\begin{aligned}\nL(f,P) & =\\sum_{k=1}^{n}m_{k}(x_{k}-x_{k-1})\n\\end{aligned}\\]\nThe upper sum of \\(f\\) with respect to \\(P\\) is given by:\n\\[\\begin{aligned}\nU(f,P) & =\\sum_{k=1}^{n}M_{k}(x_{k}-x_{k-1})\n\\end{aligned}\\]\nFor a particular partition \\(P\\), it is clear that \\(U(f,P)\\geq L(f,P)\\) because \\(M_{k}\\geq m_{k}\\) for all \\(k=0,1,2,\\ldots,n\\).\n\nA partition \\(Q\\) is called a refinement of \\(P\\) if \\(Q\\) contains all of the points of \\(P\\); that is \\(Q\\subseteq P\\).\n\n\nIf \\(P\\subseteq Q\\), then \\(L(f,P)\\leq L(f,Q)\\) and \\(U(f,Q)\\leq U(f,P)\\).\n\n\nProof. Proof. Consider what happens when we refine \\(P\\) by adding a single point \\(z\\) to some subinterval \\([x_{k-1},x_{k}]\\) of \\(P\\). We have:\n\\[\\begin{aligned}\nm_{k}(x_{k}-x_{k-1}) & =m_{k}(x_{k}-z)+m_{k}(z-x_{k-1})\\\\\n& \\leq m_{k}'(x_{k}-z)+m_{k}''(z-x_{k-1})\n\\end{aligned}\\]\nwhere\n\\[\\begin{aligned}\nm_{k}' & =\\inf\\{f(x):x\\in[z,x_{k}]\\}\\\\\nm_{k}'' & =\\inf\\{f(x):x\\in[x_{k-1},z]\\}\n\\end{aligned}\\]\nBy induction we have:\n\\[\\begin{aligned}\nL(f,P) & \\leq L(f,Q)\\\\\nU(f,Q) & \\leq U(f,P)\n\\end{aligned}\\] ◻\n\n\nIf \\(P_{1}\\) and \\(P_{2}\\) are any two partitions of \\([a,b]\\), then \\(L(f,P_{1})\\leq U(f,P_{2})\\).\n\n\nProof. Proof. Let \\(Q=P_{1}\\cup P_{2}\\). Then, \\(P_{1}\\subseteq Q\\) and \\(P_{2}\\subseteq Q\\). Thus, \\(L(f,P_{1})\\leq L(f,Q)\\leq U(f,Q)\\leq L(f,P_{2})\\). ◻\n\n\nLet \\(\\mathcal{P}\\) be the collection of all possible partitions of the interval \\([a,b]\\). The upper integral of \\(f\\) is defined to be:\n\\[\\begin{aligned}\nU(f) & =\\inf\\{U(f,P):P\\in\\mathcal{P}\\}\n\\end{aligned}\\]\nThe lower integral of \\(f\\) is defined by:\n\\[\\begin{aligned}\nL(f) & =\\sup\\{L(f,P):P\\in\\mathcal{P}\\}\n\\end{aligned}\\]\n\nConsider the set of all upper sums of \\(f\\) - \\(\\{U(f,P):P\\in\\mathcal{P}\\}\\). Take an arbitrary partition \\(P'\\in\\mathcal{P}\\). Since \\(L(f,P')\\leq U(f,P)\\) for all \\(P\\in\\mathcal{P}\\), by the Axiom of Completeness(AoC), \\(\\inf\\{U(f,P):P\\in\\mathcal{P}\\}\\) exists.We can similarly argue for the supremum of all lower Riemann sums.\n\nFor any bounded function \\(f\\) on \\([a,b]\\), it is always the case that \\(U(f)\\geq L(f)\\).\n\n\nProof. Proof. By the properties of the infimum of a set, \\((\\forall\\epsilon&gt;0)\\), \\(\\exists P(\\epsilon)\\) such that \\(U(f)&lt;U(f,P(\\epsilon))&lt;U(f)+\\epsilon\\). Pick \\(\\epsilon=1,\\frac{1}{2},\\frac{1}{3}\\ldots,\\frac{1}{n},\\ldots\\). Thus, we can produce a sequence of partitions \\(P_{n}\\) such that :\n\\[U(f)&lt;\\ldots&lt;U(f,P_{n})&lt;U(f)+\\frac{1}{n}\\]\nConsequently, \\(\\lim U(f,P_{n})=U(f)\\). Similarly, we can produce a sequence of partitions \\((Q_{m})\\) such that :\n\\[L(f)-\\frac{1}{m}&lt;\\ldots&lt;L(f,Q_{m})&lt;L(f)\\]\nWe know that:\n\\[\\begin{aligned}\nL(f,Q_{m}) & \\leq U(f,P_{n})\n\\end{aligned}\\]\nKeeping \\(m\\) fixed and passing to the limit, as \\(n\\to\\infty\\) on both sides, we have:\n\\[\\begin{aligned}\n\\lim_{n\\to\\infty}L(f,Q_{m}) & \\leq\\lim_{n\\to\\infty}U(f,P_{n})\\quad\\left\\{ \\text{Order Limit Theorem}\\right\\} \\\\\nL(f,Q_{m}) & \\leq U(f)\n\\end{aligned}\\]\nNow, passing to the limit, as \\(m\\to\\infty\\) on both sides, we have:\n\\[\\begin{aligned}\n\\lim_{m\\to\\infty}L(f,Q_{m}) & \\leq\\lim_{m\\to\\infty}U(f)\\quad\\left\\{ \\text{Order Limit Theorem}\\right\\} \\\\\nL(f) & \\leq U(f)\n\\end{aligned}\\] ◻\n\n\n(Riemann Integrability). A bounded function \\(f\\) on the interval \\([a,b]\\) is said to be Riemann integrable if \\(U(f)=L(f)\\). In this case, we define \\(\\int_{a}^{b}f\\) or \\(\\int_{a}^{b}f(x)dx\\) to be the common value:\n\\[\\begin{aligned}\n\\int_{a}^{b}f(x)dx & =U(f)=L(f)\n\\end{aligned}\\]\n\n\n(Integrability Criterion) A bounded function \\(f\\) is integrable on \\([a,b]\\) if and only if, for every \\(\\epsilon&gt;0\\), there exists a partition \\(P_{\\epsilon}\\) of \\([a,b]\\) such that:\n\\[\\begin{aligned}\nU(f,P_{\\epsilon})-L(f,P_{\\epsilon}) & &lt;\\epsilon\n\\end{aligned}\\]\n\n\nProof. Proof. (\\(\\Longleftarrow\\) direction.) Let \\(\\epsilon&gt;0\\). If such a partition \\(P_{\\epsilon}\\) exists, then:\n\\[U(f)-L(f)\\leq U(f,P_{\\epsilon})-L(f,P_{\\epsilon})&lt;\\epsilon\\]\nBecause \\(\\epsilon\\) is arbitrary, it follows that \\(U(f)=L(f)\\) and hence \\(f\\) is Riemann integrable.\n(\\(\\Longrightarrow\\) direction.) Let \\(f\\) be a bounded function on \\([a,b]\\) such that \\(f\\) is Riemann integrable.\nPick an arbitrary \\(\\epsilon&gt;0\\).\nThen, since \\(U(f)=\\inf\\{U(f,P):P\\in\\mathcal{P}\\}\\), there exists \\(P_{\\epsilon}\\in\\mathcal{P}\\), such that \\(U(f)&lt;U(f,P_{\\epsilon})&lt;U(f)+\\frac{\\epsilon}{2}\\). Since \\(L(f)=\\sup\\{L(f,P):P\\in\\mathcal{P}\\}\\), there exists \\(P_{\\epsilon}\\in\\mathcal{P}\\), such that \\(L(f)-\\frac{\\epsilon}{2}&lt;L(f,P_{\\epsilon})&lt;L(f)\\). Consequently,\n\\[\\begin{aligned}\nU(f,P_{\\epsilon})-L(f,P_{\\epsilon}) & &lt;U(f)+\\frac{\\epsilon}{2}-\\left(L(f)-\\frac{\\epsilon}{2}\\right)\\\\\n& =U(f)-L(f)+\\epsilon\\\\\n& =\\epsilon\n\\end{aligned}\\] ◻\n\n\n\n\nA point \\(c\\) is called a discontinuity of the first kind or jump point if both limits \\(g(c+)=\\lim_{t\\uparrow c}g(t)\\) and \\(g(c-)=\\lim_{t\\downarrow c}g(t)\\) exist and are not equal. The jump at \\(c\\) is defined as \\(\\Delta g(c)=g(c+)-g(c-)\\). Any other discontinuity is said to be of the second kind.\n\n\nConsider the function\n\\[\\begin{aligned}\nf(x) & =\\sin\\left(\\frac{1}{x}\\right)\n\\end{aligned}\\]\nLet \\(x_{n}=\\frac{1}{2n\\pi}\\). Then, \\(f(x_{n})=(0,0,0,\\ldots)\\). Next, consider \\(y_{n}=\\frac{1}{\\pi/2+2n\\pi}\\). Then, \\(f(y_{n})=(1,1,1,\\ldots)\\). Consequently, \\(f\\) is not continuous at \\(0\\). Hence, limits from the left or right don’t exist. Consequently, this is a discontinuity of the second kind.\n\nFunctions in stochastic calculus are functions without discontinuities of the second kind, that is functions have both left and right hand limits at any point of the domain and have one-sided limits at the boundary. These functions are called regular functions. It is often agreed to identify functions if they have the same right and left limits at any point.\nThe class \\(D=D[0,T]\\) of right-continuous functions on \\([0,T]\\) with left limits has a special name, cadlag functions (which is the abbreviation of right continuous with left limits in French). Sometimes these processes are called R.R.C. for regular right continuous. Notice that this class of processes includes \\(C\\), the class of continuous functions.\nLet \\(g\\in D\\) be a cadlag function, then, by definition, all the discontinuities of \\(g\\) are jumps. An important result in analysis is that, a function can have no more than a countable number of discontinuities.\n\n\n\nIf \\(g\\) is a function of a real variable, its variation over the interval \\([a,b]\\) is defined as:\n\\[\\begin{aligned}\nV_{g}([a,b]) & =\\sup\\left\\{ \\sum_{i=1}^{n}\\left|g(t_{i})-g(t_{i-1})\\right|\\right\\} \\label{eq:total-variation-of-a-function}\n\\end{aligned}\\]\nwhere the supremum is taken over all partitions \\(P\\in\\mathcal{P}\\).\nClearly, by the Triangle Inequality, the sums in ([eq:total-variation-of-a-function]) increase as new points are added to the partitions. Therefore, the variation of \\(g\\) is:\n\\[\\begin{aligned}\nV_{g}([a,b]) & =\\lim_{||\\Delta_{n}||\\to0}\\sum_{i=1}^{n}\\left|g(t_{i})-g(t_{i-1})\\right|\n\\end{aligned}\\]\nwhere \\(||\\Delta_{n}||=\\max_{1\\leq i\\leq n}(t_{i}-t_{i-1})\\). If \\(V_{g}([a,b])\\) is finite, then \\(g\\) is said to be a function of finite variation on \\([a,b]\\). If \\(g\\) is a function of \\(t\\geq0\\), then the variation of \\(g\\) as a function of \\(t\\) is defined by:\n\\[\\begin{aligned}\nV_{g}(t) & =V_{g}([0,t])\n\\end{aligned}\\]\nClearly, \\(V_{g}(t)\\) is an increasing function of \\(t\\).\n\n\\(g\\) is a function of finite variation if \\(V_{g}(t)&lt;\\infty\\) for all \\(t\\in[0,\\infty)\\). \\(g\\) is of bounded variation if \\(\\sup_{t}V_{g}(t)&lt;\\infty\\), in other words there exists \\(C\\), for all \\(t\\), such that \\(V_{g}(t)&lt;C\\). Here \\(C\\) is independent of \\(t\\).\n\n\n(1) If \\(g(t)\\) is increasing then for any \\(i\\), \\(g(t_{i})\\geq g(t_{i-1})\\), resulting in a telescopic sum, where all terms excluding the first and the last cancel out, leaving\n\\[\\begin{aligned}\nV_{g}(t) & =g(t)-g(0)\n\\end{aligned}\\]\n(2) If \\(g(t)\\) is decreasing, then similarly,\n\\[\\begin{aligned}\nV_{g}(t) & =g(0)-g(t)\n\\end{aligned}\\]\n\n\nIf \\(g(t)\\) is differentiable with continuous derivative \\(g'(t)\\), \\(g(t)=\\int_{0}^{t}g'(s)ds\\) then\n\\[\\begin{aligned}\nV_{g}(t) & =\\int_{0}^{t}|g'(s)|ds\n\\end{aligned}\\]\n\n\nProof. Proof. By definition,\n\\[\\begin{aligned}\nV_{g}(t) & =\\lim_{||\\Delta_{n}\\to0||}\\sum_{i=1}^{n}|g(t_{i})-g(t_{i-1})|\n\\end{aligned}\\]\nSince \\(g\\) is continuous and differentiable on \\([t_{i-1},t_{i}]\\), there exists \\(z_{i}\\in(t_{i-1},t_{i})\\) such, that \\(g(t_{i})-g(t_{i-1})=g'(z_{i})(t_{i}-t_{i-1})\\). Therefore, we can write:\n\\[\\begin{aligned}\n{1}\nV_{g}(t) & =\\lim_{||\\Delta_{n}\\to0||}\\sum_{i=1}^{n}|g'(z_{i})|(t_{i}-t_{i-1})\\\\\n& =\\int_{0}^{t}|g'(s)|ds\n\\end{aligned}\\] ◻\n\n\nIf \\(g\\) is continuous, \\(g'\\) exists and \\(\\int_{0}^{t}|g'(s)|ds\\) is finite, then \\(g\\) is of finite variation.\n\n\nThe function \\(g(t)=t\\sin(1/t)\\) for \\(t&gt;0\\) and \\(g(0)=0\\) is continuous on \\([0,1]\\) and differentiable at all points except zero, but is not of bounded variation on any interval that includes \\(0\\). Consider the partition \\(\\{x_{n}\\}=\\left\\{ \\frac{1}{\\pi/2+n\\pi}\\right\\}\\). Thus,\n\\[\\begin{aligned}\n\\sin(\\frac{1}{x_{n}}) & =\\begin{cases}\n1 & \\text{if }n\\text{ is even}\\\\\n-1 & \\text{if }n\\text{ is odd}\n\\end{cases}\n\\end{aligned}\\]\nThus,\n\\[\\begin{aligned}\nf(x_{n}) & =\\begin{cases}\nx_{n} & n\\text{ is even}\\\\\n-x_{n} & n\\text{ is odd}\n\\end{cases}\n\\end{aligned}\\]\nTherefore,\n\\[\\begin{aligned}\n\\sum_{n=1}^{m}|f(x_{n})-f(x_{n-1})| & =\\sum_{n=1}^{m}(x_{n}+x_{n-1})\\\\\n& =x_{0}+x_{n}+2\\sum_{n=1}^{m-1}x_{n}\\\\\n& \\geq\\sum_{n=1}^{m-1}x_{n}\n\\end{aligned}\\]\nThis is the lower bound on the variation of \\(g\\) on the partition \\(\\{0,x_{m},\\ldots,x_{1},x_{0},1\\}\\). Now, passing to the limit as \\(m\\) approaches infinity, \\(\\sum\\frac{1}{\\pi/2+n\\pi}\\) is a divergent series. Consequently, \\(V_{g}([0,1])\\) has unbounded variation.\n\n\n\n\n\nAny function \\(g:[0,\\infty)\\to\\mathbf{R}\\) is of bounded variation if and only if it can be expressed as the difference of two increasing functions:\n\\[\\begin{aligned}\ng(t) & =a(t)-b(t)\n\\end{aligned}\\]\n\n\nProof. Proof. (\\(\\Longrightarrow\\)direction). If \\(g\\) is of finite variation, \\(V_{g}(t)&lt;\\infty\\) for all \\(t\\), and we can write:\n\\[\\begin{aligned}\ng(t) & =V_{g}(t)-(V_{g}(t)-g(t))\n\\end{aligned}\\]\nLet \\(a(t)=V_{g}(t)\\) and \\(b(t)=V_{g}(t)-g(t)\\). Clearly, both \\(a(t)\\) and \\(b(t)\\) are increasing functions.\n(\\(\\Longleftarrow\\)direction). Suppose a function \\(g\\) can be expressed as a difference of two bounded increasing functions. Then,\n\\[\\begin{aligned}\nV_{g}(t) & =\\lim_{||\\Delta_{n}||\\to0}\\sum_{i=1}^{n}|(a(t_{i})-b(t_{i}))-(a(t_{i-1})-b(t_{i-1})|\\\\\n& \\quad\\{\\text{ Telescoping sum }\\}\\\\\n& =a(t)-b(t)-(a(0)-b(0))\n\\end{aligned}\\]\nSince both \\(a(t)\\) and \\(b(t)\\) are bounded, \\(g\\) has bounded variation. ◻\n\n\n\n\nLet \\(g\\) be a montonically increasing function on a finite closed interval \\([a,b]\\). A bounded function \\(f\\) defined on \\([a,b]\\) is said to Riemann-Stieltjes integrable with respect to \\(g\\) if the following limit exists:\n\\[\\begin{aligned}\n\\int_{a}^{b}f(t)dg(t) & =\\lim_{||\\Delta_{n}||\\to0}\\sum_{i=1}^{n}f(\\tau_{i})(g(t_{i})-g(t_{i-1}))\\label{eq:riemann-stieltjes-integral}\n\\end{aligned}\\]\nwhere \\(\\tau_{i}\\) is an evaluation point in the interval \\([t_{i-1},t_{i}]\\). It is a well-known fact that continuous functions are Riemann integrable and Riemann-Stieltjes integrable with respect to any monotonically increasing function on \\([a,b]\\).\nWe ask the following question. For any continuous functions \\(f\\) and \\(g\\) on \\([a,b]\\), can we define the integral \\(\\int_{a}^{b}f(t)dg(t)\\) by Equation ([eq:riemann-stieltjes-integral])?\nConsider the special case \\(f=g\\), namely, the integral:\n\\[\\int_{a}^{b}f(t)df(t)\\]\nLet \\(\\Delta_{n}=\\{a=t_{0},t_{1},\\ldots,t_{n}=b\\}\\) be a partition of \\([a,b]\\). Let \\(L_{n}\\) and \\(R_{n}\\) denote the corresponding Riemann sums with the evaluation points \\(\\tau_{i}=t_{i-1}\\) and \\(\\tau_{i}=t_{i}\\), respectively, namely,\n\\[\\begin{aligned}\nL_{n} & =\\sum_{i=1}^{n}f(t_{i-1})(f(t_{i})-f(t_{i-1}))\\label{eq:left-riemann-sum}\\\\\nR_{n} & =\\sum_{i=1}^{n}f(t_{i})(f(t_{i})-f(t_{i-1}))\\label{eq:right-riemann-sum}\n\\end{aligned}\\]\nIs it true that, \\(\\lim L_{n}=\\lim R_{n}\\) as \\(||\\Delta_{n}||\\to0\\)? Observe that:\n\\[R_{n}-L_{n}=\\sum_{i=1}^{n}(f(t_{i})-f(t_{i-1}))^{2}\\label{eq:quadratic-variation}\\]\n\\[R_{n}+L_{n}=\\sum_{i=1}^{n}(f(t_{i})^{2}-f(t_{i-1})^{2})=f(b)^{2}-f(a)^{2}\\label{eq:sum-of-left-and-right-riemann-sums}\\]\nTherefore, \\(R_{n}\\) and \\(L_{n}\\) are given by:\n\\[R_{n}=\\frac{1}{2}\\left(f(b)^{2}-f(a)^{2}+\\sum_{i=1}^{n}(f(t_{i})-f(t_{i-1}))^{2}\\right)\\]\n\\[L_{n}=\\frac{1}{2}\\left(f(b)^{2}-f(a)^{2}-\\sum_{i=1}^{n}(f(t_{i})-f(t_{i-1}))^{2}\\right)\\]\nThe limit of the right-hand side of equation ([eq:quadratic-variation]) is called the quadratic variation of the function \\(f\\) on \\([a,b]\\). Obviously, \\(\\lim_{||\\Delta_{n}||\\to0}R_{n}\\neq\\lim_{||\\Delta_{n}||\\to0}L_{n}\\) if and only the quadratic variation of the function \\(f\\) is non-zero.\n\nLet \\(f\\) be a \\(C^{1}\\)-function that is \\(f'(t)\\) is a continuous function. Then, by the mean value theorem:\n\\[\\begin{aligned}\n|R_{n}-L_{n}| & =\\sum_{i=1}^{n}(f(t_{i})-f(t_{i-1}))^{2}\\\\\n& =\\sum_{i=1}^{n}(f'(t_{i}^{*})(t_{i}-t_{i-1}))^{2}\\\\\n& \\quad\\{\\text{Mean Value Theorem}\\}\\\\\n& \\leq\\sum_{i=1}^{n}\\left\\Vert f'\\right\\Vert _{\\infty}^{2}(t_{i}-t_{i-1})^{2}\\\\\n& \\quad\\{\\text{ Interior Extremum Theorem }\\}\\\\\n& \\leq\\left\\Vert f'\\right\\Vert _{\\infty}^{2}\\left\\Vert \\Delta_{n}\\right\\Vert \\sum_{i=1}^{n}(t_{i}-t_{i-1})\\\\\n& =\\left\\Vert f'\\right\\Vert _{\\infty}^{2}\\left\\Vert \\Delta_{n}\\right\\Vert (b-a)\n\\end{aligned}\\]\nwhere \\(\\left\\Vert f'\\right\\Vert _{\\infty}=\\sup_{x\\in[a,b]}f(x)\\). Thus, the limit as \\(\\left\\Vert \\Delta_{n}\\right\\Vert \\to0\\) of the distance \\(|R_{n}-L_{n}|\\) also approaches zero. Thus, \\(\\lim L_{n}=\\lim R_{n}\\) as \\(\\left\\Vert \\Delta_{n}\\right\\Vert \\to0\\) and the Riemann-Stieltjes integral exists. By equation ([eq:sum-of-left-and-right-riemann-sums]), we have:\n\\[\\lim_{\\left\\Vert \\Delta_{n}\\right\\Vert \\to0}L_{n}=\\lim_{\\left\\Vert \\Delta_{n}\\right\\Vert \\to0}R_{n}=\\frac{1}{2}(f(b)^{2}-f(a)^{2})\\]\nOn the other hand, for such a \\(C^{1}\\)-function \\(f\\), we may simply define the integral \\(\\int_{a}^{b}f(t)df(t)\\) by:\n\\[\\begin{aligned}\n\\int_{a}^{b}f(t)df(t) & =\\int_{a}^{b}f(t)f'(t)dt\n\\end{aligned}\\]\nThen, by the fundamental theorem of Calculus:\n\\[\\int_{a}^{b}f(t)df(t)=\\int_{a}^{b}f(t)f'(t)dt=\\frac{1}{2}f(t)^{2}|_{a}^{b}=\\frac{1}{2}(f(b)^{2}-f(a)^{2})\\]\n\n\nThere is a very close relationship between functions with bounded variation and functions for which the classical integral makes sense. For the Ito integral, the quadratic variation plays a similar role. The quadratic variation of a smooth fuction \\(f\\in C^{1}([0,t])\\) is zero.\n\n\nSuppose \\(f\\) is a continuous function satisfying the condition\n\\[\\begin{aligned}\n|f(t)-f(s)| & \\leq C|t-s|^{1/2}\n\\end{aligned}\\]\nwhere \\(0&lt;C&lt;1\\).\nIn this case we have:\n\\[0\\leq|R_{n}-L_{n}|\\leq C^{2}\\sum_{i=1}^{n}(t_{i}-t_{i-1})=C^{2}(b-a)\\]\nHence, \\(\\lim R_{n}\\neq\\lim L_{n}\\) as \\(\\left\\Vert \\Delta_{n}\\right\\Vert \\to0\\) when \\(a\\neq b\\). Consequently, the integral \\(\\int_{a}^{b}f(t)df(t)\\) cannot be defined for such a function \\(f\\). Observe that the quandratic variation of the function is \\(b-a\\) (non-zero).\n\nWe see from the above examples, that definining the integral \\(\\int_{a}^{b}f(t)dg(t)\\) even when \\(f=g\\) is a non-trivial problem. Consider the question posed earlier - if \\(f\\) and \\(g\\) are continuous functions on \\([a,b]\\), can we define the integral \\(\\int_{a}^{b}f(t)dg(t)\\)? There is no simple answer to this question. But then in view of example ([ex:non-zero-quadratic-variation-example]), we can ask another question:\nQuestion. Are there continuous functions \\(f\\) satisfying the condition\n\\[\\begin{aligned}\n|f(t)-f(s)| & \\leq C|t-s|^{1/2}\n\\end{aligned}\\]\n\n\n\nConsider a random walk starting at \\(0\\) with jumps \\(h\\) and \\(-h\\) equally at times \\(\\delta\\), \\(2\\delta\\), \\(\\ldots\\) where \\(h\\) and \\(\\delta\\) are positive numbers. More precisely, let \\(\\{X_{n}\\}_{n=1}^{\\infty}\\) be a sequence of independent and identically distributed random variables with :\n\\[\\begin{aligned}\n\\mathbb{P}\\{X_{j}=h\\} & =\\mathbb{P}\\{X_{j}=-h\\}=\\frac{1}{2}\n\\end{aligned}\\]\nLet \\(Y_{\\delta,h}(0)=0\\) and put:\n\\[\\begin{aligned}\nY_{\\delta,h}(n\\delta) & =X_{1}+X_{2}+\\ldots+X_{n}\n\\end{aligned}\\]\nFor \\(t&gt;0\\), define \\(Y_{\\delta,h}(t)\\) by linearization that is, for \\(n\\delta&lt;t&lt;(n+1)\\delta\\), define:\n\\[\\begin{aligned}\nY_{\\delta,h}(t) & =\\frac{(n+1)\\delta-t}{\\delta}Y_{\\delta,h}(n\\delta)+\\frac{t-n\\delta}{\\delta}Y_{\\delta,h}((n+1)\\delta)\n\\end{aligned}\\]\nWe can think of \\(Y_{\\delta,h}(t)\\) as the position of the random walk at time \\(t\\). In particular, \\(X_{1}+X_{2}+\\ldots+X_{n}\\) is the position of this random walk at time \\(n\\delta\\).\nQuestion. What is the limit of the random walk \\(Y_{\\delta,h}\\) as \\(\\delta,h\\to0\\)?\nRecall that the characteristic function of a random variable \\(X\\) is \\(\\phi_{X}(\\lambda)=\\mathbb{E}\\exp[i\\lambda X]\\). In order to find out the answer, let us compute the following limit of the characteristic function of \\(Y_{\\delta,h}(t)\\):\n\\[\\lim_{\\delta,h\\to0}\\mathbb{E}\\exp\\left[i\\lambda Y_{\\delta,h}(t)\\right]\\]\nwhere \\(\\lambda\\in\\mathbf{R}\\)is fixed. For heuristic derivation, let \\(t=n\\delta\\) and so \\(n=t/\\delta\\). Then we have:\n\\[\\begin{aligned}\n\\mathbb{E}\\exp\\left[i\\lambda Y_{\\delta,h}(t)\\right] & =\\prod_{j=1}^{n}\\mathbb{E}e^{i\\lambda X_{j}}\\\\\n& =\\prod_{j=1}^{n}\\left(\\frac{1}{2}e^{i\\lambda h}+\\frac{1}{2}e^{-i\\lambda h}\\right)\\\\\n& =\\left(\\frac{1}{2}e^{i\\lambda h}+\\frac{1}{2}e^{-i\\lambda h}\\right)^{n}\\\\\n& =\\left(\\cos\\lambda h\\right)^{n}\\\\\n& =\\left(\\cos\\lambda h\\right)^{t/\\delta}\n\\end{aligned}\\]\nFor fixed \\(t\\) and \\(\\lambda\\), when \\(\\delta\\) and \\(h\\) independently approach \\(0\\), the limit of \\(\\mathbb{E}\\exp\\left[i\\lambda Y_{\\delta,h}(t)\\right]\\) may not exist. For example, holding \\(h\\) constant, letting \\(\\delta\\to0\\), since \\(-1\\leq\\cos\\theta\\leq1\\), the function \\(\\left(\\cos\\lambda h\\right)^{t/\\delta}\\to0\\). Holding \\(\\delta\\) constant, letting \\(h\\to0\\), the function \\(\\left(\\cos\\lambda h\\right)^{t/\\delta}\\to1\\). In order for the limit to exist, we impose a certain relationship between \\(\\delta\\) and \\(h\\). However, depending on the relationship, we may obtain different limits.\nLet \\(u=\\cos(\\lambda h)^{1/\\delta}\\). Then \\(\\ln u=\\frac{1}{\\delta}\\ln\\cos(\\lambda h)\\). Note that:\n\\[\\begin{aligned}\n\\cos(\\lambda h) & \\approx1-\\frac{1}{2}\\lambda^{2}h^{2}\n\\end{aligned}\\]\nAnd \\(\\ln(1+x)\\approx x\\). Hence,\n\\[\\ln\\cos(\\lambda h)\\approx\\ln\\left(1-\\frac{1}{2}\\lambda^{2}h^{2}\\right)\\approx-\\frac{1}{2}\\lambda^{2}h^{2}\\]\nTherefore for small \\(\\lambda\\) and \\(h\\), we have \\(\\ln u\\approx-\\frac{1}{2\\delta}\\lambda^{2}h^{2}\\) and so:\n\\[\\begin{aligned}\nu & \\approx\\exp\\left[-\\frac{1}{2\\delta}\\lambda^{2}h^{2}\\right]\n\\end{aligned}\\]\nIn particular, if \\(\\delta\\) and \\(h\\) are related by \\(h^{2}=\\delta\\), then\n\\[\\begin{aligned}\n\\lim_{\\delta\\to0}\\mathbb{E}\\exp\\left[i\\lambda Y_{\\delta,h}(t)\\right] & =e^{-\\frac{1}{2}\\lambda^{2}t}\n\\end{aligned}\\]\nBut, \\(e^{-\\frac{1}{2}\\lambda^{2}t}\\) is the characteristic function of a Gaussian random variable with mean \\(0\\) and variance \\(t\\). Thus, we have derived the following theorem about the limit of the random walk \\(Y_{\\delta,h}\\) as \\(\\delta,h\\to0\\) in such a way that \\(h^{2}=\\delta\\).\n\nLet \\(Y_{\\delta,h}(t)\\) be the random walk starting at \\(0\\) with jumps \\(h\\) and \\(-h\\) equally likely at times \\(\\delta\\), \\(2\\delta\\), \\(3\\delta\\), \\(\\ldots\\). Assume that \\(h^{2}=\\delta\\). Then, for each \\(t\\geq0\\), the limit:\n\\[\\begin{aligned}\n\\lim_{\\delta\\to0}Y_{\\delta,h}(t) & =B(t)\n\\end{aligned}\\] exists in distribution. Moreover, we have:\n\\[\\begin{aligned}\n\\mathbb{E}e^{i\\lambda B(t)} & =e^{-\\frac{1}{2}\\lambda^{2}t}\n\\end{aligned}\\]\n\n\n(Quadratic Variation of a Brownian motion). Let \\((B_{t},t\\ge0)\\) be a standard brownian motion. Then, for any sequence of partitions \\((t_{j},j\\leq n)\\) of \\([0,t]\\) we have:\n\\[\\begin{aligned}\n\\left\\langle B\\right\\rangle _{t} & =\\sum_{j=1}^{n}(B_{t_{j+1}}-B_{t_{j}})^{2}\\stackrel{L^{2}}{\\to}t\n\\end{aligned}\\]\nwhere the convergence is in the \\(L^{2}\\) sense.\n\n\nIt is reasonable to have some sort of convergence as we are dealing with a sum of independent random variables. However, the conclusion would not hold if the increments were not squared. So there is something more at play here.\n\n\nProof. Proof. We have:\n\\[\\begin{aligned}\n\\mathbb{E}\\left[\\left(\\sum_{j=0}^{n-1}(B(t_{j+1})-B(t_{j}))^{2}-t\\right)^{2}\\right] & =\\mathbb{E}\\left[\\left(\\sum_{j=0}^{n-1}(B(t_{j+1})-B(t_{j}))^{2}-\\sum_{j=0}^{n-1}(t_{j+1}-t_{j})\\right)^{2}\\right]\\\\\n& =\\mathbb{E}\\left[\\left(\\sum_{j=0}^{n-1}\\left\\{ (B(t_{j+1})-B(t_{j}))^{2}-(t_{j+1}-t_{j})\\right\\} \\right)^{2}\\right]\n\\end{aligned}\\]\nFor simplicity, we define the variables \\(X_{j}=(B(t_{j+1})-B(t_{j}))^{2}-(t_{j+1}-t_{j})\\). Then, we may write:\n\\[\\begin{aligned}\n\\mathbb{E}\\left[\\left(\\sum_{j=0}^{n-1}(B(t_{j+1})-B(t_{j}))^{2}-t\\right)^{2}\\right] & =\\mathbb{E}\\left[\\left(\\sum_{j=0}^{n-1}X_{j}\\right)^{2}\\right]\\\\\n& =\\mathbb{E}\\left[\\sum_{i=0}^{n-1}\\sum_{j=0}^{n-1}X_{i}X_{j}\\right]\\\\\n& =\\sum_{i=0}^{n-1}\\sum_{j=0}^{n-1}\\mathbb{E}[X_{i}X_{j}]\n\\end{aligned}\\]\nNow, the random variables \\(X_{j}\\) are independent.\nThe expectation of \\(X_{j}\\) is \\(\\mathbb{E}[X_{j}]=\\mathbb{E}(B(t_{j+1})-B(t_{j}))^{2}-(t_{j+1}-t_{j})=0\\).\nSince, \\(X_{i}\\) and \\(X_{j}\\) are independent, for \\(i\\neq j\\), \\(\\mathbb{E}[X_{i}X_{j}]=\\mathbb{E}X_{i}\\cdot\\mathbb{E}X_{j}=0\\).\nHence, we have:\n\\[\\begin{aligned}\n\\mathbb{E}\\left[\\left(\\sum_{j=0}^{n-1}(B(t_{j+1})-B(t_{j}))^{2}-t\\right)^{2}\\right] & =\\sum_{i=0}^{n-1}\\mathbb{E}[X_{i}^{2}]\n\\end{aligned}\\]\nWe now develop the expectation of the square of \\(X_{i}\\). We have:\n\\[\\begin{aligned}\n\\mathbb{E}[X_{i}^{2}] & =\\mathbb{E}\\left[\\left((B(t_{i+1})-B(t_{i}))^{2}-(t_{i+1}-t_{i})\\right)^{2}\\right]\\\\\n& =\\mathbb{E}\\left[((B(t_{i+1})-B(t_{i}))^{4}-2(B(t_{i+1})-B(t_{i}))^{2}(t_{i+1}-t_{i})+(t_{i+1}-t_{i})^{2}\\right]\n\\end{aligned}\\]\nThe MGF of the random variable \\(B(t_{i+1})-B(t_{i})\\) is :\n\\[\\begin{aligned}\n\\phi(\\lambda) & =\\exp\\left[\\frac{\\lambda^{2}(t_{i+1}-t_{i})}{2}\\right]\\\\\n\\phi'(\\lambda) & =\\lambda(t_{i+1}-t_{i})\\exp\\left[\\frac{\\lambda^{2}(t_{i+1}-t_{i})}{2}\\right]\\\\\n\\phi''(\\lambda) & =\\left[(t_{i+1}-t_{i})+\\lambda^{2}(t_{i+1}-t_{i})^{2}\\right]\\exp\\left[\\frac{\\lambda^{2}(t_{i+1}-t_{i})}{2}\\right]\\\\\n\\phi^{(3)}(\\lambda) & =\\left[3\\lambda(t_{i+1}-t_{i})^{2}+\\lambda^{3}(t_{i+1}-t_{i})^{3}\\right]\\exp\\left[\\frac{\\lambda^{2}(t_{i+1}-t_{i})}{2}\\right]\\\\\n\\phi^{(4)}(\\lambda) & =\\left[3(t_{i+1}-t_{i})^{2}+6\\lambda^{2}(t_{i+1}-t_{i})^{3}+\\lambda^{4}(t_{i+1}-t_{i})^{4}\\right]\\exp\\left[\\frac{\\lambda^{2}(t_{i+1}-t_{i})}{2}\\right]\n\\end{aligned}\\]\nThus, \\(\\mathbb{E}[(B(t_{i+1})-B(t_{i}))^{4}]=3(t_{i+1}-t_{i})^{2}\\). Consequently,\n\\[\\begin{aligned}\n\\mathbb{E}[X_{i}^{2}] & =\\mathbb{E}[(B(t_{i+1})-B(t_{i}))^{4}]-2(t_{i+1}-t_{i})\\mathbb{E}[(B(t_{i+1})-B(t_{i}))^{2}]+(t_{i+1}-t_{i})^{2}\\\\\n& =3(t_{i+1}-t_{i})^{2}-2(t_{i+1}-t_{i})^{2}+(t_{i+1}-t_{i})^{2}\\\\\n& =2(t_{i+1}-t_{i})^{2}\n\\end{aligned}\\]\nPutting all this together, we finally have that:\n\\[\\begin{aligned}\n\\mathbb{E}\\left[\\left(\\sum_{j=0}^{n-1}(B(t_{j+1})-B(t_{j}))^{2}-t\\right)^{2}\\right] & =2\\sum_{i=0}^{n-1}(t_{i+1}-t_{i})^{2}\\label{eq:second-moment-of-qv}\\\\\n& \\leq2\\left\\Vert \\Delta_{n}\\right\\Vert \\sum_{i=0}^{n-1}(t_{i+1}-t_{i})\\nonumber \\\\\n& =2\\left\\Vert \\Delta_{n}\\right\\Vert \\cdot t\\nonumber\n\\end{aligned}\\]\nAs \\(n\\to\\infty\\), \\(\\left\\Vert \\Delta_{n}\\right\\Vert \\to0\\). Hence,\n\\[\\begin{aligned}\n\\lim_{n\\to\\infty}\\mathbb{E}\\left[\\left(\\sum_{j=0}^{n-1}(B(t_{j+1})-B(t_{j}))^{2}-t\\right)^{2}\\right] & =0\n\\end{aligned}\\]\nHence, the sequence of random variables\n\\[\\begin{aligned}\n\\sum_{j=0}^{n-1}(B(t_{j+1})-B(t_{j}))^{2} & \\stackrel{L^{2}}{\\to}t\n\\end{aligned}\\] ◻\n\n\n(Quadratic Variation of a Brownian Motion Path). Let \\((B_{s},s\\geq0)\\) be a Brownian motion. For every \\(n\\in\\mathbf{N}\\), consider the dyadic partition \\((t_{j},j\\leq2^{n})\\) of \\([0,t]\\) where \\(t_{j}=\\frac{j}{2^{n}}t\\). Then we have that:\n\\[\\begin{aligned}\n\\left\\langle B\\right\\rangle _{t} & =\\sum_{j=1}^{2^{n}-1}(B_{t_{j+1}}-B_{t_{j}})^{2}\\stackrel{a.s.}{\\to}t\n\\end{aligned}\\]\n\n\nProof. Proof. We have \\((t_{i+1}-t_{i})=\\frac{t}{2^{n}}.\\) Borrowing equation ([eq:second-moment-of-qv]) from the proof of theorem ([th:quadratic-variation-of-bm-approaches-t-in-mean-square]), we have that:\n\\[\\begin{aligned}\n\\mathbb{E}\\left[\\left(\\sum_{j=0}^{2^{n}-1}(B(t_{j+1})-B(t_{j}))^{2}-t\\right)^{2}\\right] & =2\\sum_{i=0}^{2^{n}-1}\\left(\\frac{t}{2^{n}}\\right)^{2}\\\\\n& =2\\cdot(2^{n})\\cdot\\frac{t^{2}}{2^{2n}}\\\\\n& =\\frac{2t^{2}}{2^{n}}\n\\end{aligned}\\]\nBy Chebyshev’s inequality,\n\\[\\begin{aligned}\n\\mathbb{P}\\left(\\left|\\sum_{j=0}^{2^{n}-1}(B(t_{j+1})-B(t_{j}))^{2}-t\\right|&gt;\\epsilon\\right) & \\leq\\frac{1}{\\epsilon^{2}}\\mathbb{E}\\left[\\left(\\sum_{j=0}^{2^{n}-1}(B(t_{j+1})-B(t_{j}))^{2}-t\\right)^{2}\\right]\\\\\n& \\leq\\frac{1}{\\epsilon^{2}}\\cdot\\frac{2t^{2}}{2^{n}}\n\\end{aligned}\\]\nDefine \\(A_{n}:=\\left\\{ \\left|\\sum_{j=0}^{2^{n}-1}(B(t_{j+1})-B(t_{j}))^{2}-t\\right|&gt;\\epsilon\\right\\}\\). Since, \\(\\sum\\frac{1}{2^{n}}\\) is a convergent series, any multiple of it, \\((2t^{2}/\\epsilon^{2})\\sum\\frac{1}{2^{n}}\\) also converges. Now, \\(0\\leq\\mathbb{P}(A_{n})\\leq\\frac{(2t^{2}/\\epsilon^{2})}{2^{n}}\\). By the comparison test, \\(\\sum\\mathbb{P}(A_{n})\\) converges to a finite value. By Theorem ([th:sufficient-condition-for-almost-sure-convergence]),\n\\[\\begin{aligned}\n\\sum_{j=0}^{2^{n}-1}(B(t_{j+1})-B(t_{j}))^{2} & \\stackrel{a.s.}{\\to}t\n\\end{aligned}\\] ◻\n\nWe are now ready to show that every Brownian motion path has infinite variation.\nIf \\(g\\) is a \\(C^{1}\\) function,\n\\[\\begin{aligned}\n\\int_{0}^{t}|g'(t)|dt & =\\int_{0}^{t}\\sqrt{g'(t)^{2}}dt\\\\\n& \\leq\\int_{0}^{t}\\sqrt{1+g'(t)^{2}}dt\\\\\n& =l_{g}(t)\n\\end{aligned}\\]\nwhere \\(l_{g}(t)\\) is the arclength of the function \\(g\\) between \\([0,t]\\). So, \\(V_{g}(t)\\leq l_{g}(t)\\) and further:\n\\[\\begin{aligned}\nl_{g}(t) & =\\int_{0}^{t}\\sqrt{1+g'(t)^{2}}dt\\\\\n& \\leq\\int_{0}^{t}\\left(1+\\sqrt{g'(t)^{2}}\\right)dt\\\\\n& \\leq t+V_{g}(t)\n\\end{aligned}\\]\nConsequently,\n\\[\\begin{aligned}\nV_{g}(t) & \\leq l_{g}(t)\\leq t+V_{g}(t)\n\\end{aligned}\\]\nThe total variation of the function is finite if and only if it’s arclength is.\nHence, intuitively, our claim is that a Brownian motion path on \\([0,T]\\) has infinite arc-length. Since \\(g\\in C^{1}([a,b])\\Longrightarrow(V_{g}(t)&lt;\\infty)\\), it follows that \\((V_{g}(t)\\to\\infty)\\Longrightarrow g\\notin C^{1}\\).\n\n(Brownian Motion paths have unbounded total variation.)  Let \\((B_{s},s\\geq0)\\) be a Brownian motion. Then, the random functions \\(B(s,\\omega)\\) on the interval \\([0,t]\\) have unbounded variation almost surely.\n\n\nProof. Proof. Take the sequence of dyadic partitions of \\([0,t]\\): \\(t_{j}=\\frac{j}{2^{n}}t\\), \\(n\\in\\mathbf{N}\\), \\(j\\leq2^{n}\\). By pulling out the worst increment, we have the trivial bound for every \\(\\omega\\):\n\\[\\begin{aligned}\n\\sum_{j=0}^{2^{n}-1}(B_{t_{j+1}}(\\omega)-B_{t_{j}}(\\omega))^{2} & \\leq\\max_{0\\leq j\\leq2^{n}}\\left|B_{t_{j+1}}(\\omega)-B_{t_{j}}(\\omega)\\right|\\cdot\\sum_{j=0}^{2^{n}-1}(B_{t_{j+1}}(\\omega)-B_{t_{j}}(\\omega))\\label{eq:trivial-upper-bound-on-quadratic-variation}\n\\end{aligned}\\]\nWe proceed by contradiction. Let \\(A'\\) be the set of all \\(\\omega\\), for which the Brownian motion paths have bounded total variation. Let \\(A\\) be event that the Brownian motion paths have unbounded variation.\nBy the definition of total variation, that would imply, \\(\\exists M\\in\\mathbf{N}\\) :\n\\[\\begin{aligned}\n(\\forall\\omega\\in A')\\quad\\lim_{n\\to\\infty}\\sum_{j=0}^{2^{n}-1}\\left|(B_{t_{j+1}}(\\omega)-B_{t_{j}}(\\omega))\\right| & &lt;M\n\\end{aligned}\\]\nSince Brownian Motion paths are continuous on the compact set \\([\\frac{j}{2^{n}}t,\\frac{j+1}{2^{n}}t]\\), they are uniformly continuous. So, as \\(n\\to\\infty\\), \\(|t_{j+1}-t_{j}|\\to0\\) and therefore \\(|B_{t_{j+1}}(\\omega)-B_{t_{j}}(\\omega)|\\to0\\). And consequently, \\(\\max_{0\\leq j\\leq2^{n}}\\left|B_{t_{j+1}}(\\omega)-B_{t_{j}}(\\omega)\\right|\\to0\\).\nThus, for every \\(\\omega\\in A'\\), the right hand side of the inequality ([eq:trivial-upper-bound-on-quadratic-variation]), converges to \\(0\\) and therefore the left hand side converges to \\(0\\). But, this contradicts the fact that \\(\\left\\langle B\\right\\rangle _{t}\\stackrel{a.s.}{\\to}t\\). So, \\(A'\\) is a null set, and \\(\\mathbb{P}(A')=0\\) and \\(\\mathbb{P}(A)=1\\). This closes the proof. ◻\n\n\n\n\n\nIf we make the simplifying assumption that the process paths are continuous, we obtain the set of all continuous functions on \\([0,T]\\), denoted by \\(C[0,T]\\). This is a very rich space. In a more general model, it is assumed that the process paths are right continuous with left limits (regular right-continuous RRC, cadlag) functions.\nLet the sample space \\(\\Omega=D[0,T]\\) be the set of all RRC functions on \\([0,T]\\). An element of this set is a RRC function from \\([0,T]\\) into \\(\\mathbf{R}\\). First we must decide what kind of sets of these functions are measurable? The simplest set for which we would like to calculate the probabilities are sets of the form \\(\\{a\\leq S(t_{1})\\leq b\\}\\) for some \\(t_{1}\\). If \\(S(t)\\) represents the price of a stock at time \\(t\\), then the probability of such a set gives the probability that the stock price at time \\(t_{1}\\) is between \\(a\\) and \\(b\\). We are also interested in how the price of the stock at time \\(t_{1}\\) affects the price at another time \\(t_{2}\\). Thus, we need to talk about the joint distribution of stock prices \\(S(t_{1})\\) and \\(S(t_{2})\\). This means that we need to define probability on the sets of the form \\(\\{S(t_{1})\\in B_{1},S(t_{2})\\in B_{2}\\}\\) where \\(B_{1}\\) and \\(B_{2}\\) are intervals on the line. More generally, we would like to have all the finite-dimensional distributions of the process \\(S(t)\\), that is, the probabilities of the sets: \\(\\{S(t_{1})\\in B_{1},S(t_{2})\\in B_{2},\\ldots,S(t_{n})\\in B_{n}\\}\\) for any choice of \\(0\\leq t_{1}\\leq\\ldots\\leq t_{n}\\leq T\\).\nThe sets of the form \\(A=\\{\\omega(\\cdot)\\in D[0,T]:\\omega(t_{1})\\in B_{1},\\ldots,\\omega(t_{n})\\in B_{n}\\}\\), where \\(B_{i}\\)’s are borel subsets of \\(\\mathbf{R}\\), are called cylinder sets or finite-dimensional rectangles.\nThe stochastic process \\(S(t)\\) is just a (function-valued) random variable on this sample space, which takes some value \\(\\omega(t)\\) - the value of the function \\(\\omega\\) at \\(t\\).\nLet \\(\\mathcal{R}\\) be the colllection of all cylindrical subsets of \\(D[0,1]\\). Obviously \\(\\mathcal{R}\\) is not a \\(\\sigma\\)-field.\nProbability is first defined by on the elements of \\(\\mathcal{R}\\). Let \\(A\\subseteq\\mathcal{R}\\).\n\\[\\begin{aligned}\n\\mathbb{P}(A) & =\\int_{B_{1}}\\cdots\\int_{B_{n}}\\prod_{i=1}^{n}\\frac{1}{\\sqrt{(2\\pi)(t_{i}-t_{i-1})}}\\exp\\left[-\\frac{(u_{i}-u_{i-1})^{2}}{2(t_{i}-t_{i-1})}\\right]du_{1}\\cdots du_{n}\n\\end{aligned}\\]\nand then extended to the \\(\\sigma\\)-field generated by taking unions, complements and intersections of cylinders. We take the smallest \\(\\sigma\\)-algebra containing all the cylindrical subsets of \\(D[0,1]\\). Thus, \\(\\mathcal{F}=\\mathcal{B}(D[0,1])\\).\nHence, \\((\\Omega,\\mathcal{F},\\mathbb{P})=(D[0,1],\\mathcal{B}(D[0,1]),\\mathbb{P})\\) is a probability space. It is called the Wiener space and \\(\\mathbb{P}\\) here is called the Wiener measure.\n\n\n\nAs discussed in the previous section, a stochastic process is determined by its finite-dimensional distribution. In studying stochastic processes, it is often natural to think of them as function-valued random variables in \\(t\\). Let \\(S(t)\\) be defined for \\(0\\leq t\\leq T\\), then for a fixed \\(\\omega\\), it is a function in \\(t\\), called the sample path or a realization of \\(S\\). Finite-dimensional distributions do not determine the continuity property of sample paths. The following example illustrates this.\n\nLet \\(X(t)=0\\) for all \\(t\\), \\(0\\leq t\\leq1\\) and \\(\\tau\\) be a uniformly distributed random variable on \\([0,1]\\). Let \\(Y(t)=0\\) for \\(t\\neq\\tau\\) and \\(Y(t)=1\\) if \\(t=\\tau.\\) Then, for any fixed \\(t\\), \\(\\mathbb{P}(Y(t)\\neq0)=\\mathbb{P}(\\tau=t)=0\\), and hence \\(\\mathbb{P}(Y(t)=0)=1\\). So, that all one-dimensional distributions of \\(X(t)\\) and \\(Y(t)\\) are the same. Similarly, all finite-dimensional distributions of \\(X\\) and \\(Y\\) are the same. However, the sample paths of the process \\(X\\), that is, the functions \\(X(t)_{0\\leq t\\leq1}\\) are continuous in \\(t\\), whereas every sample path \\(Y(t)_{0\\leq t\\leq1}\\) has a jump at the (random) point \\(\\tau\\). Notice that, \\(\\mathbb{P}(X(t)=Y(t))=1\\) for all \\(t\\), \\(0\\leq t\\leq1\\).\n\n\nTwo stochastic processes are called versions (modifications) of one another if\n\\[\\mathbb{P}(X(t)=Y(t))=1\\quad\\text{for all }0\\leq t\\leq T\\]\n\nThus, the two processes in the example ([ex:modifications-of-a-stochastic-process]) are versions of one another, one has continuous sample paths, the other does not. If we agree to pick any version of the process we want, then we can pick the continous version when it exists. In general, we choose the smoothest possible version of the process.\nFor two processes, \\(X\\) and \\(Y\\), denote by \\(N_{t}=\\{X(t)\\neq Y(t)\\}\\), \\(0\\leq t\\leq T\\). In the above example, \\(\\mathbb{P}(N_{t})=\\mathbb{P}(\\tau=t)=0\\) for any \\(t\\), \\(0\\leq t\\leq1\\). However, \\(\\mathbb{P}(\\bigcup_{0\\leq t\\leq1}N_{t})=\\mathbb{P}(\\tau=t\\:\\text{for some }t\\:\\text{in }[0,1])=1\\). Although, each of \\(N_{t}\\) is a \\(\\mathbb{P}\\)-null set, the union \\(N=\\bigcup_{0\\leq t\\leq1}N_{t}\\) contains uncountably many null sets, and in this particular case it is a set of of probability one.\nIf it happens that \\(\\mathbb{P}(N)=0\\), then \\(N\\) is called an evanescent set, and the processes \\(X\\) and \\(Y\\) are called indistinguishable. Note that in this case, \\(\\mathbb{P}(\\{\\omega:\\exists t:X(t)\\neq Y(t)\\})=\\mathbb{P}(\\bigcup_{0\\leq t\\leq1}\\{X(t)\\neq Y(t))=0\\) and \\(\\mathbb{P}(\\bigcap_{0\\leq t\\leq1}\\{X(t)=Y(t)\\})=1\\). It is clear, that if the time is discrete, then any two versions of the process are indistinguishable. It is also not hard to see, that if \\(X(t)\\) and \\(Y(t)\\) are versions of one another and they are both right-continuous, they are indistinguishable.\n\n(Paul Levy’s construction of Brownian Motion). Standard Brownian motion exists.\n\n\nProof. Proof. I reproduce the standard proof as present in Brownian Motion by Morters and Peres. I added some remarks for greater clarity.\nLet\n\\[\\begin{aligned}\n\\mathcal{D}_{n} & =\\left\\{ \\frac{k}{2^{n}}:k=0,1,2,\\ldots,2^{n}\\right\\}\n\\end{aligned}\\]\nbe a finite set of dyadic points.\nLet\n\\[\\begin{aligned}\n\\mathcal{D} & =\\bigcup_{n=0}^{\\infty}\\mathcal{D}_{n}\n\\end{aligned}\\]\nLet \\(\\{Z_{t}:t\\in\\mathcal{D}\\}\\) be a collection of independent, standard normally distributed random variables. This is a countable set of random variables.\nLet \\(B(0):=0\\) and \\(B(1):=Z_{1}\\).\nFor each \\(n\\in\\mathbf{N}\\), we define the random variables \\(B(d)\\), \\(d\\in\\mathcal{D}_{n}\\) such that, the following invariant holds:\n(1) for all \\(r&lt;s&lt;t\\) in \\(\\mathcal{D}_{n}\\) the random variable \\(B(t)-B(s)\\) is normally distributed with mean zero and variance \\(t-s\\) and is independent of \\(B(s)-B(r)\\).\n(2) the vectors \\((B(d):d\\in\\mathcal{D}_{n})\\) and \\((Z_{t}:t\\in\\mathcal{D}\\setminus\\mathcal{D}_{n})\\) are independent.\nNote that we have already done this for \\(\\mathcal{D}_{0}=\\{0,1\\}\\). Proceeding inductively, let’s assume that the above holds for some \\(n-1\\). We are interested to prove that the invariant also holds for \\(n\\).\nWe define \\(B(d)\\) for \\(d\\in\\mathcal{D}_{n}\\backslash\\mathcal{D}_{n-1}\\) by:\n\\[\\begin{aligned}\nB(d) & =\\frac{B(d-2^{-n})+B(d+2^{-n})}{2}+\\frac{Z_{d}}{2^{(n+1)/2}}\n\\end{aligned}\\]\nNote that, the points \\(0,\\frac{1}{2^{n-1}},\\ldots,\\frac{k}{2^{n-1}},\\frac{k+1}{2^{n-1}},\\ldots,1\\) belong to \\(\\mathcal{D}_{n-1}\\). The first summand is the linear interpolation of the values of \\(B\\) at the neighbouring points of \\(d\\) in \\(\\mathcal{D}_{n-1}\\). That is,\n\\[\\begin{aligned}\nB\\left(\\frac{2k+1}{2^{n}}\\right) & =\\frac{B\\left(\\frac{k}{2^{n-1}}\\right)+B\\left(\\frac{k+1}{2^{n-1}}\\right)}{2}+\\frac{Z_{d}}{2^{(n+1)/2}}\n\\end{aligned}\\]\nSince \\(P(n-1)\\) holds, \\(B(d-2^{-n})\\) and \\(B(d+2^{-n})\\) are have no dependence on \\((Z_{t}:t\\in\\mathcal{D}\\setminus\\mathcal{D}_{n-1})\\). Consequently, \\(B(d)\\) has no dependence on \\((Z_{t}:t\\in\\mathcal{D}\\setminus\\mathcal{D}_{n})\\) and the second property is fulfilled.\nMoreover, as \\(\\frac{1}{2}[B(d+2^{-n})-B(d-2^{-n})]\\) depends only on \\((Z_{t}:t\\in\\mathcal{D}_{n-1})\\), it is independent of \\(\\frac{Z_{d}}{2^{(n+1)/2}}\\). By our induction assumptions, they are both nromally distributed with mean \\(0\\) and variance \\(\\frac{1}{2^{(n+1)}}\\).\nSo, their sum and difference random variables\n\\[\\begin{aligned}\nB(d)-B(d-2^{-n}) & =\\frac{B(d+2^{-n})-B(d-2^{-n})}{2}+\\frac{Z_{d}}{2^{(n+1)/2}}\\\\\nB(d+2^{-n})-B(d) & =\\frac{B(d+2^{-n})-B(d-2^{-n})}{2}-\\frac{Z_{d}}{2^{(n+1)/2}}\n\\end{aligned}\\]\nare also independent, with mean \\(0\\) and variance \\(\\frac{1}{2^{n}}\\) (the variance of independent random variables is the sum of the variances).\nIndeed all increments \\(B(d)-B(d-2^{-n})\\) for \\(d\\in\\mathcal{D}_{n}\\setminus\\{0\\}\\) are independent. To see this, it suffices to show that they are pairwise independent. We have seen in the previous paragraph that the pairs \\(B(d)-B(d-2^{-n})\\) and \\(B(d+2^{-n})-B(d)\\) with \\(d\\in\\mathcal{D}_{n}\\setminus\\mathcal{D}_{n-1}\\) are independent. The other possibility is that the increments are over the intervals separated by some \\(d\\in\\mathcal{D}_{n-1}\\). For concreteness, if \\(n\\) were \\(3\\), then the increments, \\(B_{7/8}-B_{6/8}\\) and \\(B_{5/8}-B_{4/8}\\) are seperated by \\(d=\\frac{3}{4}\\in\\mathcal{D}_{2}\\). Choose \\(d\\in\\mathcal{D}_{j}\\) with this property and minimal \\(j\\), so, the two intervals are contained in \\([d-2^{-j},d]\\) and \\([d,d+2^{-j}]\\) respectively. By induction, the increments over these two intervals of length \\(2^{-j}\\) are independent and the increments over the intervals of length \\(2^{-n}\\) are constructed from the independent increments \\(B(d)-B(d-2^{-j})\\) and \\(B(d+2^{-j})-B(d)\\) using a disjoint set of variables \\((Z_{t}:t\\in\\mathcal{D}_{n})\\). Hence, they are independent and this implies pairwise independence. This implies the first property. Consequently, the vector of increments \\((B(d)-B(d-2^{-n})\\) for all \\(d\\in\\mathcal{D}_{n}\\) is Gaussian.\nHaving thus chosen the value of the process on all the dyadic points, we interpolate between them. Formally, we define:\n\\[\\begin{aligned}\nF_{0}(t) & =\\begin{cases}\nZ_{1} & \\text{for }t=1\\\\\n0 & \\text{for }t=0\\\\\n\\text{\\text{linear in between}}\n\\end{cases}\n\\end{aligned}\\]\nand for each \\(n\\geq1\\),\n\\[\\begin{aligned}\nF_{n}(t) & =\\begin{cases}\n\\frac{Z_{t}}{2^{(n+1)/2}} & \\text{for }t\\in\\mathcal{D}\\setminus\\mathcal{D}_{n-1}\\\\\n0 & \\text{for }t\\in\\mathcal{D}_{n-1}\\\\\n\\text{\\text{linear between consecutive points in }\\ensuremath{\\mathcal{D}_{n}}}\n\\end{cases}\n\\end{aligned}\\]\nThese functions are continuous on \\([0,1]\\) and for all \\(n\\) and \\(d\\in\\mathcal{D}_{n}\\), we have:\n\\[\\begin{aligned}\nB(d) & =\\sum_{i=0}^{n}F_{i}(d)=\\sum_{i=0}^{\\infty}F_{i}(d)\\label{eq:claim-of-induction-for-bd}\n\\end{aligned}\\]\nTo see this, assume that above equation holds for all \\(d\\in\\mathcal{D}_{n-1}\\).\nLet’s consider the point \\(d\\in\\mathcal{D}_{n}\\setminus\\mathcal{D}_{n-1}\\).\n\\[\\begin{aligned}\nB(d) & =\\frac{B(d-2^{-n})+B(d+2^{-n})}{2}+\\frac{Z_{d}}{2^{(n+1)/2}}\\nonumber \\\\\n& =\\sum_{i=0}^{n-1}\\frac{F_{i}(d-2^{-n})+F_{i}(d+2^{-n})}{2}+\\frac{Z_{d}}{2^{(n+1)/2}}\\label{eq:expression-for-bd}\n\\end{aligned}\\]\nNow, \\(d-2^{-n}\\) and \\(d+2^{-n}\\) belong to \\(\\mathcal{D}_{n-1}\\) and are not in \\(\\bigcup_{i&lt;n-1}\\mathcal{D}_{i}\\). Therefore, for \\(i=0,1,\\ldots,n-2\\), the points \\((d-2^{-n},F_{i}(d-2^{-n}))\\) and \\((d+2^{-n},F_{i}(d+2^{-n})\\) lie on some straight line and have \\((d,F_{i}(d))\\) as their midpoint. Moreover, \\(d-2^{-n}\\) and \\(d+2^{-n}\\) are vertices in \\(\\mathcal{D}_{n-1}\\). So, by definition of \\(F_{n-1}(d)\\), we have \\(F_{n-1}(d)=[F_{n-1}(d-2^{-n})+F_{n-1}(d+2^{-n})]/2\\).\nTo summarize, the first term on the right hand side of expression ([eq:expression-for-bd]) is equal to \\(\\sum_{i=0}^{n-1}F_{i}(d)\\). By mathematical induction, it follows that the claim ([eq:claim-of-induction-for-bd]) is true for all \\(n\\in\\mathbf{N}\\).\nIt’s extremely easy to find an upper bound on the probability contained in the Gaussian tails. Suppose \\(X\\sim N(0,1)\\) and let \\(x&gt;0\\). We are interested in the tail probability \\(\\mathbb{P}(X&gt;x)\\). We have:\n\\[\\begin{aligned}\n\\mathbb{P}(X&gt;x) & =\\int_{x}^{\\infty}e^{-x^{2}/2}dx=\\int_{x}^{\\infty}\\frac{xe^{-x^{2}/2}dx}{x}\n\\end{aligned}\\]\nLet \\(u=\\frac{1}{x}\\) and \\(dv=xe^{-x^{2}/2}dx\\). We have:\n\n\n\n\\(u=\\frac{1}{x}\\)\n\\(dv=xe^{-x^{2}/2}dx\\)\n\n\n\n\n\\(du=-\\frac{1}{x^{2}}dx\\)\n\\(v=-e^{-x^{2}/2}\\)\n\n\n\nThus,\n\\[\\begin{aligned}\n\\mathbb{P}(X&gt;x) & =-\\left.\\frac{1}{x}e^{-x^{2}/2}\\right|_{x}^{\\infty}-\\int_{x}^{\\infty}\\frac{e^{-x^{2}/2}}{x^{2}}dx\\\\\n& =\\frac{e^{-x^{2}/2}}{x}-\\int_{x}^{\\infty}\\frac{e^{-x^{2}/2}}{x^{2}}dx\\\\\n& \\quad\\left\\{ I(x)=\\int_{x}^{\\infty}\\frac{e^{-x^{2}/2}}{x^{2}}\\geq0\\right\\} \\\\\n& \\leq\\frac{e^{-x^{2}/2}}{x}\n\\end{aligned}\\]\nThus, for \\(c&gt;1\\) and large \\(n\\), we have:\n\\[\\begin{aligned}\n\\mathbb{P}(|Z_{d}|\\geq c\\sqrt{n}) & \\leq\\frac{1}{c\\sqrt{n}}e^{-c^{2}n/2}\\leq\\exp\\left(-\\frac{c^{2}n}{2}\\right)\n\\end{aligned}\\]\nSo, the series:\n\\[\\begin{aligned}\n\\sum_{n=0}^{\\infty}\\mathbb{P}\\left\\{ \\text{There exists atleast one }d\\in\\mathcal{D}_{n}\\text{ with }|Z_{d}|\\geq c\\sqrt{n}\\right\\}  & \\leq\\sum_{n=0}^{\\infty}\\sum_{d\\in\\mathcal{D}_{n}}\\mathbb{P}\\left\\{ |Z_{d}|\\geq c\\sqrt{n}\\right\\} \\\\\n& \\leq\\sum_{n=0}^{\\infty}(2^{n}+1)\\exp\\left(-\\frac{c^{2}n}{2}\\right)\n\\end{aligned}\\]\nNow, the series \\((a_{n})\\) given by, \\(a_{n}:=(2^{n}+1)e^{-c^{2}n/2}\\) has the ratio between successive terms:\n\\[\\begin{aligned}\n\\lim\\left|\\frac{a_{n+1}}{a_{n}}\\right| & =\\lim_{n\\to\\infty}\\frac{2^{n+1}+1}{2^{n}+1}\\cdot\\frac{e^{(c^{2}n)/2}}{e^{c^{2}(n+1)/2}}\\\\\n& =\\lim_{n\\to\\infty}\\frac{\\frac{1}{2}+\\frac{1}{2^{n}}}{1+\\frac{1}{2^{n}}}\\cdot\\frac{1}{e^{c^{2}/2}}\\\\\n& =\\frac{1}{2e^{c^{2}/2}}\n\\end{aligned}\\]\nIf this ratio is less than unity, that is \\(c&gt;\\sqrt{2\\log2}\\), than by the ratio test, \\(\\sum(2^{n}+1)e^{-c^{2}n/2}\\) converges to a finite value. Fix such a \\(c\\).\nBy BCL1(Borel-Cantelli Lemma), if \\(A_{n}:=\\left\\{ \\text{There exists atleast one }d\\in\\mathcal{D}_{n}\\text{ with }|Z_{d}|\\geq c\\sqrt{n}\\right\\}\\) and \\(\\sum_{n=0}^{\\infty}\\mathbb{P}(A_{n})\\) converges to a finite value, then the event \\(A_{n}\\) occurs finitely many times with probability \\(1\\). There exists \\(N\\in\\mathbf{N}\\), such that for all \\(n\\geq N\\), \\(A_{n}\\) fails to occur with probability \\(1\\). Thus, for all \\(n\\geq N\\), \\(\\{Z_{d}\\leq c\\sqrt{n}\\}\\) occurs with probability \\(1\\). It follows that:\n\\[\\begin{aligned}\n\\sup_{t\\in[0,1]}F_{n}(t) & \\leq\\frac{c\\sqrt{n}}{2^{(n+1)/2}}\n\\end{aligned}\\]\nDefine\n\\[\\begin{aligned}\nM_{n} & =\\frac{c\\sqrt{n}}{2^{(n+1)/2}}\n\\end{aligned}\\]\nSince \\(\\sum M_{n}\\) converges, by the Weierstrass \\(M\\)-test, the infinite series of functions \\(\\sum_{n=0}^{\\infty}F_{n}(t)\\) converges uniformly on \\([0,1].\\) Since, each \\(F_{n}(t)\\) is piecewise linear and continuous, by the Term-by-Term continuity theorem, \\(\\sum_{n=0}^{\\infty}F_{n}(t)\\) is continuous on \\([0,1]\\). ◻\n\n\n\n\nLike the Brownian motion, the Poisson process is defined as a process with stationary and independent increments.\n\n A process \\((N_{t},t\\geq0)\\) defined on \\((\\Omega,\\mathcal{F},\\mathbb{P})\\) has the distribution of the Poisson process with rate \\(\\lambda&gt;0\\), if and only if the following hold:\n(1) \\(N_{0}=0\\).\n(2) For any \\(s&lt;t\\), the increment \\(N_{t}-N_{s}\\) is a Poisson random variable with parameter \\(\\lambda(t-s).\\)\n(3) For any \\(n\\in\\mathbf{N}\\) and any choice \\(0&lt;t_{1}&lt;t_{2}&lt;\\ldots&lt;t_{n}&lt;\\infty\\), the increments \\(N_{t_{2}}-N_{t_{1}},N_{t_{3}}-N_{t_{2}},\\ldots,N_{t_{n}}-N_{t_{n-1}}\\) are independent.\n\nPoisson paths can be sampled using this definition. By construction, it is not hard to see that the paths of Poisson processes are piecewise, constant, integer-valued and non-decreasing. In particular, the paths of Poisson processes have finite variation. Poisson paths are much simpler than the ones of Brownian motion in many ways!\n\n(Simulating the Poisson Process.) Use the definition ([def:poisson-process]) to generate \\(10\\) paths of the Poisson process with rate \\(1\\) on the interval \\([0,10]\\) with step-size \\(0.01\\).\n\ndef generatePoissonProcess(lam,T,stepSize):\n    N = int(T/stepSize)\n    x = np.random.poisson(lam=lam,size=N)\n    y = np.cumsum(x)\n    y = np.concatenate([[0.0],y])\n    return y\nWe can construct a Poisson process as follows. Consider \\((\\tau_{j},j\\in\\mathbf{N})\\) IID exponential random variables with parameter \\(1/\\lambda\\). One should think of \\(\\tau_{j}\\) as the waiting time from the \\((j-1)\\)st to the \\(j\\)th jump. Then, one defines :\n\\[\\begin{aligned}\nN_{t} & =\\#\\{k:\\tau_{1}+\\tau_{2}+\\ldots+\\tau_{k}\\leq t\\}\\\\\n& =\\text{Number of jumps upto and including time }t\n\\end{aligned}\\]\nNow, here is an idea! What about defining a new process with stationary and independent increments using a given distribution other than Poisson and Gaussian? Is this even possible? The answer is yes, but only if the distribution satisfies the property of being infinitely divisible. To see this, consider the value of the process at time \\(1\\), \\(N_{1}\\). Then, no matter how many subintervals we chop the interval \\([0,1]\\) into, we must have the increments add up to \\(N_{1}\\). In other words, we must be able to write \\(N_{1}\\) as a sum of \\(n\\) IID random variables for every possible \\(n\\). This is certainly true for Poisson random variables and Gaussian random variables. Another example is the Cauchy distribution. In general, processes that can be constructed using independent, stationary increments are called Levy processes.\n\nTime Inversion. Let \\((B_{t},t\\geq0)\\) be a standard brownian motion. We consider the process:\n\\[\\begin{aligned}\nX_{t} & =tB_{1/t}\\quad\\text{for }t&gt;0\n\\end{aligned}\\]\nThis property relates the behavior of \\(t\\) large to the behavior of \\(t\\) small.\n\n(a) Show that \\((X_{t},t&gt;0)\\) has the distribution of Brownian motion on \\(t&gt;0\\).\nProof.\nLike \\(B(t)\\), it is an easy exercise to prove that \\(X(t)\\) is also a Gaussian process.\nWe have, \\(\\mathbb{E}[X_{s}]=0\\).\nLet \\(s&lt;t\\). We have:\n\\[\\begin{aligned}\nCov(X_{s},X_{t}) & =\\mathbb{E}[sB(1/s)\\cdot tB(1/t)]\\\\\n& =st\\mathbb{E}[B(1/s)\\cdot B(1/t)]\\\\\n& =st\\cdot\\frac{1}{t}\\\\\n& \\quad\\left\\{ \\because\\frac{1}{t}&lt;\\frac{1}{s}\\right\\} \\\\\n& =s\n\\end{aligned}\\]\nConsequently, \\(X(t)\\) has the distribution of a Brownian motion.\n(b) Argue that \\(X(t)\\) converges to \\(0\\) as \\(t\\to0\\) in the sense of \\(L^{2}\\)-convergence. It is possible to show convergence almost surely so that \\((X_{t},t\\geq0)\\) is really a Brownian motion for \\(t\\geq0\\).\nSolution.\nLet \\((t_{n})\\) be any arbitrary sequence of positive real numbers approaching \\(0\\) and consider the sequence of random variables \\((X(t_{n}))_{n=1}^{\\infty}\\). We have:\n\\[\\begin{aligned}\n\\mathbb{E}\\left[X(t_{n})^{2}\\right] & =\\mathbb{E}\\left[t_{n}^{2}B(1/t_{n})^{2}\\right]\\\\\n& =t_{n}^{2}\\mathbb{E}\\left[B(1/t_{n})^{2}\\right]\\\\\n& =t_{n}^{2}\\cdot\\frac{1}{t_{n}}\\\\\n& =t_{n}\n\\end{aligned}\\]\nHence,\n\\[\\begin{aligned}\n\\lim\\mathbb{E}\\left[X(t_{n})^{2}\\right] & =\\lim t_{n}=0\n\\end{aligned}\\]\nSince \\((t_{n})\\) was an arbitrary sequence, it follows that \\(\\lim_{t\\to0}\\mathbb{E}[(X(t))^{2}]=0\\).\n(c) Use this property of Brownian motion to show the law of large numbers for Brownian motion:\n\\[\\begin{aligned}\n\\lim_{t\\to\\infty}\\frac{X(t)}{t} & =0\\quad\\text{almost surely}\n\\end{aligned}\\]\nSolution.\nWhat we need to do is to show that \\(X(t)\\to0\\) as \\(t\\to0\\) almost surely. That would show that \\(\\frac{B(1/t)}{1/t}\\to0\\) as \\(t\\to0\\) almost surely, which is the same as showing \\(\\frac{B(t)}{t}\\to0\\) as \\(t\\to\\infty\\), which is the law of large numbers for Brownian motion.\nWhat we have done in part (b), is to prove the claim that \\(\\mathbb{E}[X(t)^{2}]\\to0\\) as \\(t\\to0\\), which shows convergence in the \\(L^{2}\\) sense and hence convergence in probability. This is infact the weak law of large numbers. \\(\\frac{B(t)}{t}\\stackrel{\\mathbb{\\mathbf{P}}}{\\to}0\\) as \\(t\\to\\infty\\).\nFor \\(t&gt;0\\), continuity is clear. However, it is the proof that as \\(t\\to0\\), \\(X(t)\\to0\\) almost surely which we have not done.\nNote that, the limit \\(X(t)\\to0\\) as \\(t\\to0\\) if and only if \\((\\forall n\\geq1)\\), \\((\\exists m\\geq1)\\), such that \\(\\forall r\\in\\mathbb{Q}\\cap(0,\\frac{1}{m}]\\), we have \\(|X(r)|=\\left|rB\\left(\\frac{1}{r}\\right)\\right|\\leq\\frac{1}{n}\\).\nTo understand the above, we just recall the \\(\\epsilon-\\delta\\) definition of continuity. Note that \\(\\frac{1}{n}\\) plays the role of \\(\\epsilon\\) and \\(\\frac{1}{m}\\) works as \\(\\delta\\).\nThat is,\n\\[\\begin{aligned}\n\\Omega^{X}:=\\left\\{ \\lim_{t\\to0}X(t)=0\\right\\}  & =\\bigcap_{n\\geq1}\\bigcup_{m\\geq1}\\bigcap_{r\\in\\mathbb{Q}\\cap(0,\\frac{1}{m}]}\\left\\{ \\left|X(r)\\right|\\leq\\frac{1}{n}\\right\\}\n\\end{aligned}\\]\nAlso, note that \\(X(t)\\) is continuous on all \\([a,1]\\) for all \\(a&gt;0\\), thus, uniformly continuous on \\([a,1]\\), and hence uniformly continuous on \\(\\mathbb{Q}\\cap(0,1]\\). So, there exists a continuous extension of \\(X(t)\\) on \\([0,1]\\). We already know from part (a), that \\((X(t))_{t&gt;0}\\) and \\((B(t))_{t&gt;0}\\) have the same finite dimensional distributions. Therefore, the RHS event has the same probability as \\(\\Omega^{B}:=\\bigcap_{n\\geq1}\\bigcup_{m\\geq1}\\bigcap_{r\\in\\mathbb{Q}\\cap(0,\\frac{1}{m}]}\\left\\{ \\left|B(r)\\right|\\leq\\frac{1}{n}\\right\\}\\). Since \\(B(t)\\to0\\) as \\(t\\to0\\) almost surely, the event \\(\\Omega^{B}\\) has probability \\(1\\). Thus, \\(\\mathbb{P}\\left\\{ \\lim_{t\\to0}X(t)=0\\right\\} =1\\).\nThis actually shows that \\(X(t)\\) is a bonafide standard brownian motion, as we have established continuity as well."
  },
  {
    "objectID": "posts/properties-of-brownian-motion/index.html#properties-of-brownian-motion.-1",
    "href": "posts/properties-of-brownian-motion/index.html#properties-of-brownian-motion.-1",
    "title": "Properties of Brownian Motion",
    "section": "",
    "text": "Let \\(B(t)\\) be a fixed Brownian motion. We give below some simple properties that follow directly from the definition of the Brownian Motion.\n\nFor any \\(t\\geq0\\), \\(B(t)\\) is normally distributed with mean \\(0\\) and variance \\(t\\). For any \\(s,t\\geq0\\) we have \\(\\mathbb{E}(B_{s}B_{t})=\\min\\{s,t\\}\\).\n\nProof. From condition (1), we have that \\(B_{0}=0\\). From condition (2), \\(B_{t}-B_{0}=B_{t}\\) is normally distributed with mean \\(0\\) and variance \\(t\\).\nAssume that \\(s&lt;t\\).\nWe have:\n\\[\\begin{aligned}\n\\mathbb{E}(B_{s}B_{t}) & =\\mathbb{E}\\left[B_{s}(B_{t}-B_{s}+B_{s})\\right] & \\{\\text{Write }B_{t}=B_{t}-B_{s}+B_{s}\\}\\\\\n& =\\mathbb{E}[B_{s}(B_{t}-B_{s})]+\\mathbb{E}[B_{s}^{2}] & \\{\\text{Linearity of expectations}\\}\\\\\n& =\\mathbb{E}[B_{s}]\\mathbb{E}(B_{t}-B_{s})+s & \\{B_{s},(B_{t}-B_{s})\\text{ are independent}\\}\\\\\n& =0\\cdot0+s\\\\\n& =s\n\\end{aligned}\\]\nThis closes the proof. ◻ :::\n\n(Translation Invariance) For fixed \\(t_{0}\\geq0\\), the stochastic process \\(\\tilde{B}(t)=B(t+t_{0})-B(t_{0})\\) is also a Brownian motion.\n\n\nProof. Proof. Firstly, the stochastic process \\(\\tilde{B}(t)\\) is such that:\n(1) \\(\\tilde{B}(0)=B(t_{0})-B(t_{0})=0\\). Hence, it satisfies condition (1).\n(2) Let \\(s&lt;t\\). We have: \\(\\tilde{B}(t)-\\tilde{B}(s)=B(t+t_{0})-B(s+t_{0})\\) which a Gaussian random variable with mean 0 and variance \\(t-s\\). Hence, for \\(a\\leq b\\),\n\\[\\begin{aligned}\n\\mathbb{P}\\{a\\leq & \\tilde{B}(t)\\leq b\\}=\\frac{1}{\\sqrt{2\\pi(t-s)}}\\int_{a}^{b}e^{-\\frac{x^{2}}{2(t-s)}}dx\n\\end{aligned}\\]\nHence, it satisfies condition (2).\n(3) To check condition (3) for \\(\\tilde{B}(t)\\), we may assume \\(t_{0}&gt;0\\). Then, for any \\(0\\leq t_{1}\\leq t_{2}\\leq\\ldots\\leq t_{n}\\), we have:\n\\[0&lt;t_{0}\\leq t_{0}+t_{1}\\leq t_{0}+t_{2}\\leq\\ldots\\leq t_{0}+t_{n}\\]\nSo, \\(B(t_{1}+t_{0})-B(t_{0})\\), \\(B(t_{2}+t_{0})-B(t_{1}+t_{0})\\), \\(\\ldots\\), \\(B(t_{k}+t_{0})-B(t_{k-1}+t_{0})\\), \\(\\ldots\\), \\(B(t_{n}+t_{0})-B(t_{n-1}+t_{0})\\) are independent random variables. Consequently, \\(\\tilde{B}(t)\\) satisfies condition (3).\nThis closes the proof. ◻\n\nThe above translation invariance property says that a Brownian motion starts afresh at any moment as a new Brownian motion.\n\n(Scaling Invariance) For any real number \\(\\lambda&gt;0\\), the stochastic process \\(\\tilde{B}(t)=B(\\lambda t)/\\sqrt{\\lambda}\\) is also a Brownian motion.\n\n\nProof. Proof. The scaled stochastic process \\(\\tilde{B}(t)\\) is such that:\n(1) \\(\\tilde{B}(0)=0\\). Hence it satisfies condition (1).\n(2) Let \\(s&lt;t\\). Then, \\(\\lambda s&lt;\\lambda t\\). We have:\n\\[\\begin{aligned}\n\\tilde{B}(t)-\\tilde{B}(s) & =\\frac{1}{\\sqrt{\\lambda}}(B(\\lambda t)-B(\\lambda s))\n\\end{aligned}\\]\nNow, \\(B(\\lambda t)-B(\\lambda s)\\) is a Gaussian random variable with mean \\(0\\) and variance \\(\\lambda(t-s)\\). We know that, if \\(X\\) is a random variable with mean \\(\\mu\\) and variance \\(\\sigma^{2}\\), \\(Z=\\left(\\frac{X-\\mu}{\\sigma}\\right)\\) has mean \\(0\\) and variance \\(1\\). Consequently, \\(\\frac{B(\\lambda t)-B(\\lambda s)}{\\sqrt{\\lambda}}\\) is a Gaussian random variable with mean \\(0\\) and variance \\((t-s)\\).\nHence, \\(\\tilde{B}(t)-\\tilde{B}(s)\\) is normal distributed with mean \\(0\\) and variance \\(t-s\\) and it satisfies condition (2).\n(3) To check condition (3) for \\(\\tilde{B}(t)\\), we may assume \\(t_{0}&gt;0\\). Then, for any \\(0\\leq t_{1}\\leq t_{2}\\leq\\ldots\\leq t_{n}\\), we have:\n\\[0\\leq\\lambda t_{1}\\leq\\lambda t_{2}\\leq\\ldots\\leq\\lambda t_{n}\\]\nConsequently, the random variables \\(B(\\lambda t_{k})-B(\\lambda t_{k-1})\\), \\(k=1,2,3,\\ldots,n\\) are independent. Hence it follows that \\(\\frac{1}{\\sqrt{\\lambda}}[B(\\lambda t_{k})-B(\\lambda t_{k-1})]\\) for \\(k=1,2,\\ldots,n\\) are also independent random variables.\nThis closes the proof. ◻\n\nIt follows from the scaling invariance property that for any \\(\\lambda&gt;0\\) and \\(0\\leq t_{1}\\leq t_{2}\\leq\\ldots\\leq t_{n}\\), the random vectors:\n\\[(B(\\lambda t_{1}),B(\\lambda t_{2}),\\ldots,B(\\lambda t_{n}))\\quad(\\sqrt{\\lambda}B(t_{1}),\\sqrt{\\lambda}B(t_{1}),\\ldots,\\sqrt{\\lambda}B(t_{n}))\\]\nhave the same distribution.\nThe scaling property shows that Brownian motion is self-similar, much like a fractal. To see this, suppose we zoom into a Brownian motion path very close to zero, say on the interval \\([0,10^{-6}]\\). If the Brownian motion path were smooth and differentiable, the closer we zoom in around the origin, the flatter the function will look. In the limit, we would essentially see a straight line given by the derivative at \\(0\\). However, what we see with the Brownian motion is very different. The scaling property means that for \\(a=10^{-6}\\),\n\\[\n\\begin{aligned}\n(B_{10^{-6}t,}t\\in[0,1]) & \\stackrel{\\text{distrib.}}{=}(10^{-3}B_{t},t\\in[0,1])\n\\end{aligned}\n\\]\nwhere \\(\\stackrel{\\text{distrib.}}{=}\\) means equality of the distribution of the two processes. In other words, Brownian motion on \\([0,10^{-6}]\\) looks like a Browian motion on \\([0,1]\\), but with its amplitude multiplied by a factor of \\(10^{-3}\\). In particular, it will remain rugged as we zoom in, unlike a smooth function.\n\n(Reflection at time \\(s\\)) The process \\((-B_{t},t\\geq0)\\) is a Brownian motion. More generally, for any \\(s\\geq0\\), the process \\((\\tilde{B}(t),t\\geq0)\\) defined by:\n\\[\\begin{aligned}\n\\tilde{B}(t) & =\\begin{cases}\nB_{t} & \\text{if }t\\leq s\\\\\nB_{s}-(B_{t}-B_{s}) & \\text{if }t&gt;s\n\\end{cases}\\label{eq:reflection-property}\n\\end{aligned}\\]\nis a Brownian motion.\n\n\nProof. Proof. (a) Consider the process \\(\\tilde{B}(t)=(-B_{t},t\\geq0)\\).\n(1) \\(\\tilde{B}(0)=0\\).\n(2) If \\(X\\) is a Gaussian random variable with mean \\(0\\) and variance \\(t-s\\), \\(-X\\) is also Gaussian with mean \\(0\\) and variance \\(t-s\\). Thus, \\(\\tilde{B}(t)-\\tilde{B}(s)=-(B(t)-B(s))\\) is also Gaussian with mean \\(0\\) and variance \\((t-s)\\). Hence condition (2) is satisfied.\n(3) Assume that \\(0\\leq t_{0}\\leq t_{1}\\leq\\ldots\\leq t_{n}\\). Then, the random variables \\(-(B(t_{k})-B(t_{k-1}))\\) are independent for \\(k=1,2,3,\\ldots,n\\). Hence, condition (3) is satisfied.\n(b) Consider the process \\(\\tilde{B}(t)\\) as defined in ([eq:reflection-property]).\nFix an \\(s\\geq0\\).\n(1) Let \\(t=0\\). Then, \\(t\\leq s\\). \\(\\tilde{B}(t)=\\tilde{B}(0)=B(0)=0\\).\n(2) Let \\(t_{1}&lt;t_{2}\\leq s\\). Then, \\(\\tilde{B}(t_{2})-\\tilde{B}(t_{1})=B(t_{2})-B(t_{1})\\). This is a Gaussian random variable with mean \\(0\\) and variance \\(t_{2}-t_{1}\\).\nLet \\(t_{1}&lt;s&lt;t_{2}\\). Then, \\(\\tilde{B}(t_{2})-\\tilde{B}(t_{1})=B(s)-(B(t_{2})-B(s))-B(t_{1})=(B(s)-B(t_{1}))-(B(t_{2})-B(s))\\). Since, \\(B(s)-B(t_{1})\\) and \\(B(t_{2})-B(s)\\) are independent Gaussian random variables, any linear combination of these is Gaussian. Moreover, its mean is zero. The variance is given by:\n\\[\\begin{aligned}\nVar[\\tilde{B}(t_{2})-\\tilde{B}(t_{1})] & =Var[B(s)-B(t_{1})]+Var[B(t_{2})-B(s)]\\\\\n& =(s-t_{1})+(t_{2}-s)\\\\\n& =t_{2}-t_{1}\n\\end{aligned}\\]\nLet \\(s&lt;t_{1}&lt;t_{2}\\). Then, \\[\\begin{aligned}\n\\tilde{B}(t_{2})-\\tilde{B}(t_{1}) & =B_{s}-(B_{t_{2}}-B_{s})-(B_{s}-(B_{t_{1}}-B_{s}))\\\\\n& =\\cancel{B_{s}}-(B_{t_{2}}-\\cancel{B_{s}})-(\\cancel{B_{s}}-(B_{t_{1}}-\\cancel{B_{s}}))\\\\\n& =-(B_{t_{2}}-B_{t_{1}})\n\\end{aligned}\\]\nHence, \\(\\tilde{B}(t_{2})-\\tilde{B}(t_{1})\\) is again a Gaussian random variable with mean \\(0\\) and variance \\(t_{2}-t_{1}\\). Hence, condition (3) is satisfied.\n(3) Assume that \\(0\\leq t_{1}\\leq\\ldots\\leq t_{k-1}\\leq s\\leq t_{k}\\leq\\ldots\\leq t_{n}\\). From the above discussion, the increments \\(\\tilde{B}(t_{2})-\\tilde{B}(t_{1})\\), \\(\\ldots\\), \\(\\tilde{B}(s)-\\tilde{B}(t_{k-1})\\), \\(\\tilde{B}(t_{k})-\\tilde{B}(s)\\), \\(\\ldots\\), \\(\\tilde{B}(t_{n})-\\tilde{B}(t_{n-1})\\) are independent increments. The increment \\(\\tilde{B}(t_{k})-\\tilde{B}(t_{k-1})\\) only depends on the random variables \\(\\tilde{B}(s)-\\tilde{B}(t_{k-1})\\) and \\(\\tilde{B}(t_{k})-\\tilde{B}(s)\\). Thus, \\(\\tilde{B}(t_{2})-\\tilde{B}(t_{1})\\), \\(\\ldots\\), \\(\\tilde{B}(t_{k})-\\tilde{B}(t_{k-1})\\), \\(\\ldots\\), \\(\\tilde{B}(t_{n})-\\tilde{B}(t_{n-1})\\) are independent. ◻\n\n\n(Time Reversal). Let \\((B_{t},t\\geq0)\\) be a Brownian motion. Show that the process \\((B_{1}-B_{1-t},t\\in[0,1])\\) has the distribution of a standard brownian motion on \\([0,1]\\).\n\n\nProof. Proof. (1) At \\(t=0\\), \\(B(1)-B(1-t)=B(1)-B(1)=0\\).\n(2) Let \\(s&lt;t\\). Then, \\(1-t&lt;1-s\\). So, the increment :\n\\[\\begin{aligned}\n(B(1)-B(1-t))-(B(1)-B(1-s)) & =B(1-s)-B(1-t)\n\\end{aligned}\\]\nhas a Gaussian distribution. It’s mean is \\(0\\) and variance is \\((1-s)-(1-t)=t-s\\).\n(3) Let \\(0\\leq t_{1}\\leq t_{2}\\leq\\ldots\\leq t_{n}\\). Then:\n\\[1-t_{n}\\leq\\ldots\\leq1-t_{k}\\leq1-t_{k-1}\\leq\\ldots\\leq1-t_{2}\\leq1-t_{1}\\]\nConsider the increments of the process for \\(k=1,2,\\ldots,n\\):\n\\[\\begin{aligned}\n(B(1)-B(1-t_{k}))-(B(1)-B(1-t_{k-1})) & =B(1-t_{k-1})-B(1-t_{k})\n\\end{aligned}\\]\nThey are independent random variables. Hence, condition (3) is satisfied. ◻\n\n\n(Evaluating Brownian Probabilities). Let’s compute the probability that \\(B_{1}&gt;0\\) and \\(B_{2}&gt;0\\). We know from the definition that \\((B_{1},B_{2})\\) is a Gaussian vector with mean \\(0\\) and covariance matrix:\n\\[\\begin{aligned}\nC & =\\left[\\begin{array}{cc}\n1 & 1\\\\\n1 & 2\n\\end{array}\\right]\n\\end{aligned}\\]\nThe determinant of \\(C\\) is \\(1\\). By performing row operations on the augmented matrix \\([C|I]\\) we find that:\n\\[\\begin{aligned}\nC^{-1} & =\\left[\\begin{array}{cc}\n2 & -1\\\\\n-1 & 1\n\\end{array}\\right]\n\\end{aligned}\\]\nThus, the probability \\(\\mathbb{P}(B_{1}&gt;0,B_{2}&gt;0)\\) can be expressed as:\n\\[\\begin{aligned}\n\\mathbb{P}(B_{1}&gt;0,B_{2}&gt;0) & =\\frac{1}{\\sqrt{(2\\pi)^{2}}}\\int_{0}^{\\infty}\\int_{0}^{\\infty}\\exp\\left[-\\frac{1}{2}(2x_{1}^{2}-2x_{1}x_{2}+x_{2}^{2}\\right]dx_{2}dx_{1}\n\\end{aligned}\\]\nThis integral can be evaluated using a calculator or software and is equal to \\(3/8\\). The probability can also be computed using the independence of increments. The increments \\((B_{1},B_{2}-B_{1})\\) are IID standard Gaussians. We know their joint PDF. It remains to integrate over the correct region of \\(\\mathbf{R}^{2}\\) which in this case will be:\n\\[\\begin{aligned}\nD^{*} & =\\{(z_{1},z_{2}):(z_{1}&gt;0,z_{1}+z_{2}&gt;0)\\}\n\\end{aligned}\\]\nWe have:\n\\[\\begin{aligned}\n\\mathbb{P}(B_{1}&gt;0,B_{2}&gt;0) & =\\frac{1}{2\\pi}\\int_{0}^{\\infty}\\int_{z_{2}=-z_{1}}^{z_{2}=\\infty}e^{-(z_{1}^{2}+z_{2}^{2})/2}dz_{2}dz_{1}\n\\end{aligned}\\]\nIt turns out that this integral can be evaluated exactly. Indeed by writing \\(B_{1}=Z_{1}\\) and \\(Z_{2}=B_{2}-B_{1}\\) and splitting the probability on the event \\(\\{Z_{2}\\geq0\\}\\) and its complement, we have that \\(\\mathbb{P}(B_{1}\\geq0,B_{2}\\geq0)\\) equals:\n\\[\\begin{aligned}\n\\mathbb{P}(B_{1}\\geq0,B_{2}\\geq0) & =\\mathbb{P}(Z_{1}\\geq0,Z_{1}+Z_{2}&gt;0,Z_{2}\\geq0)+\\mathbb{P}(Z_{1}\\geq0,Z_{1}+Z_{2}&gt;0,Z_{2}&lt;0)\\\\\n& =\\mathbb{P}(Z_{1}\\geq0,Z_{2}\\geq0)+\\mathbb{P}(Z_{1}\\geq0,Z_{1}&gt;-Z_{2},-Z_{2}&gt;0)\\\\\n& =\\mathbb{P}(Z_{1}\\geq0,Z_{2}\\geq0)+\\mathbb{P}(Z_{1}\\geq0,Z_{1}&gt;Z_{2},Z_{2}&gt;0)\\\\\n& =\\frac{1}{4}+\\frac{1}{8}\\\\\n& =\\frac{3}{8}\n\\end{aligned}\\]\nNote that, by symmetry, \\(\\mathbb{P}(Z_{1}\\geq0,Z_{1}&gt;Z_{2},Z_{2}&gt;0)=\\mathbb{P}(Z_{1}\\geq0,Z_{1}\\leq Z_{2},Z_{2}&gt;0)=\\frac{1}{8}\\).\n\n\n(Another look at Ornstein Uhlenbeck process.) Consider the process \\((X_{t},t\\in\\mathbf{R})\\) defined by :\n\\[\\begin{aligned}\nX_{t} & =\\frac{e^{-2t}}{\\sqrt{2}}B(e^{4t}),\\quad t\\in\\mathbf{R}\n\\end{aligned}\\]\nHere the process \\((B_{e^{4t}},t\\ge0)\\) is called a time change of Brownian motion, since the time is now quantitfied by an increasing function of \\(t\\) namely \\(e^{4t}\\). The example \\((B(\\lambda t),t\\geq0)\\) in the scaling property is another example of time change.\n\nIt turns out that \\((X_{t},t\\in\\mathbf{R})\\) is a stationary Ornstein-Uhlenbeck process. (Here the index of time is \\(\\mathbf{R}\\) instead of \\([0,\\infty)\\), but the definition also applies as the process is stationary. Since the original brownian motion \\(B(t)\\) is a Gaussian process, any finite dimensional vector \\((B(t_{1}),\\ldots,B(t_{n}))\\) is Gaussian. It follows that:\n\\[(B(T_{1}),\\ldots,B(T_{n}))=\\frac{1}{\\sqrt{2}}(e^{-2t_{1}}B(e^{4t_{1}}),\\ldots,e^{-2t_{n}}B(e^{4t_{n}}))\\]\nis also a Gaussian vector. (Note, once we fix \\(t_{1},t_{2},\\ldots,t_{n}\\), \\(e^{-4t_{1}},\\ldots,e^{-4t_{n}}\\) are constants.) Hence, \\((X_{t},t\\in\\mathbf{R})\\) is a Gaussian process.\nThe mean of \\((X_{t},t\\in\\mathbf{R})\\) is:\n\\[\\begin{aligned}\n\\mathbb{E}[X_{t}] & =\\frac{e^{-2t}}{\\sqrt{2}}\\mathbb{E}[B(e^{4t})]=0\n\\end{aligned}\\]\nAnd if \\(s&lt;t\\),\n\\[\\begin{aligned}\n\\mathbb{E}[X_{s}X_{t}] & =\\frac{e^{-2(s+t)}}{2}\\mathbb{E}[B(e^{4s})B(e^{4t})]\\\\\n& =\\frac{e^{-2(s+t)}}{2}e^{4s}\\\\\n& =\\frac{e^{-2(t-s)}}{2}\n\\end{aligned}\\]\nTwo Gaussian processes having the same mean and covariance have the same distribution. Hence, it proves the claim that \\((X_{t})\\) is a stationary OU process."
  },
  {
    "objectID": "posts/properties-of-brownian-motion/index.html#properties-of-the-paths.",
    "href": "posts/properties-of-brownian-motion/index.html#properties-of-the-paths.",
    "title": "Properties of Brownian Motion",
    "section": "",
    "text": "First we review the definitions of the Riemann integral and the Riemann-Stieljtes integral in Calculus.\n\nA partition \\(P\\) of \\([a,b]\\) is a finite set of points from \\([a,b]\\) that includes both \\([a,b].\\)The notational convention is to always list the points of a partition \\(P=\\{a=x_{0},x_{1},x_{2},\\ldots,x_{n}=b\\}\\) in increasing order. Thus:\n\\[a=x_{0}&lt;x_{1}&lt;\\ldots&lt;x_{k-1}&lt;x_{k}&lt;\\ldots&lt;x_{n}=b\\]\n\nFor each subinterval \\([x_{k-1},x_{k}]\\) of \\(P\\), let\n\\[\\begin{aligned}\nm_{k} & =\\inf\\{f(x):x\\in[x_{k-1},x_{k}]\\}\\\\\nM_{k} & =\\sup\\{f(x):x\\in[x_{k-1},x_{k}]\\}\n\\end{aligned}\\]\nThe lower sum of \\(f\\) with respect to \\(P\\) is given by :\n\\[\\begin{aligned}\nL(f,P) & =\\sum_{k=1}^{n}m_{k}(x_{k}-x_{k-1})\n\\end{aligned}\\]\nThe upper sum of \\(f\\) with respect to \\(P\\) is given by:\n\\[\\begin{aligned}\nU(f,P) & =\\sum_{k=1}^{n}M_{k}(x_{k}-x_{k-1})\n\\end{aligned}\\]\nFor a particular partition \\(P\\), it is clear that \\(U(f,P)\\geq L(f,P)\\) because \\(M_{k}\\geq m_{k}\\) for all \\(k=0,1,2,\\ldots,n\\).\n\nA partition \\(Q\\) is called a refinement of \\(P\\) if \\(Q\\) contains all of the points of \\(P\\); that is \\(Q\\subseteq P\\).\n\n\nIf \\(P\\subseteq Q\\), then \\(L(f,P)\\leq L(f,Q)\\) and \\(U(f,Q)\\leq U(f,P)\\).\n\n\nProof. Proof. Consider what happens when we refine \\(P\\) by adding a single point \\(z\\) to some subinterval \\([x_{k-1},x_{k}]\\) of \\(P\\). We have:\n\\[\\begin{aligned}\nm_{k}(x_{k}-x_{k-1}) & =m_{k}(x_{k}-z)+m_{k}(z-x_{k-1})\\\\\n& \\leq m_{k}'(x_{k}-z)+m_{k}''(z-x_{k-1})\n\\end{aligned}\\]\nwhere\n\\[\\begin{aligned}\nm_{k}' & =\\inf\\{f(x):x\\in[z,x_{k}]\\}\\\\\nm_{k}'' & =\\inf\\{f(x):x\\in[x_{k-1},z]\\}\n\\end{aligned}\\]\nBy induction we have:\n\\[\\begin{aligned}\nL(f,P) & \\leq L(f,Q)\\\\\nU(f,Q) & \\leq U(f,P)\n\\end{aligned}\\] ◻\n\n\nIf \\(P_{1}\\) and \\(P_{2}\\) are any two partitions of \\([a,b]\\), then \\(L(f,P_{1})\\leq U(f,P_{2})\\).\n\n\nProof. Proof. Let \\(Q=P_{1}\\cup P_{2}\\). Then, \\(P_{1}\\subseteq Q\\) and \\(P_{2}\\subseteq Q\\). Thus, \\(L(f,P_{1})\\leq L(f,Q)\\leq U(f,Q)\\leq L(f,P_{2})\\). ◻\n\n\nLet \\(\\mathcal{P}\\) be the collection of all possible partitions of the interval \\([a,b]\\). The upper integral of \\(f\\) is defined to be:\n\\[\\begin{aligned}\nU(f) & =\\inf\\{U(f,P):P\\in\\mathcal{P}\\}\n\\end{aligned}\\]\nThe lower integral of \\(f\\) is defined by:\n\\[\\begin{aligned}\nL(f) & =\\sup\\{L(f,P):P\\in\\mathcal{P}\\}\n\\end{aligned}\\]\n\nConsider the set of all upper sums of \\(f\\) - \\(\\{U(f,P):P\\in\\mathcal{P}\\}\\). Take an arbitrary partition \\(P'\\in\\mathcal{P}\\). Since \\(L(f,P')\\leq U(f,P)\\) for all \\(P\\in\\mathcal{P}\\), by the Axiom of Completeness(AoC), \\(\\inf\\{U(f,P):P\\in\\mathcal{P}\\}\\) exists.We can similarly argue for the supremum of all lower Riemann sums.\n\nFor any bounded function \\(f\\) on \\([a,b]\\), it is always the case that \\(U(f)\\geq L(f)\\).\n\n\nProof. Proof. By the properties of the infimum of a set, \\((\\forall\\epsilon&gt;0)\\), \\(\\exists P(\\epsilon)\\) such that \\(U(f)&lt;U(f,P(\\epsilon))&lt;U(f)+\\epsilon\\). Pick \\(\\epsilon=1,\\frac{1}{2},\\frac{1}{3}\\ldots,\\frac{1}{n},\\ldots\\). Thus, we can produce a sequence of partitions \\(P_{n}\\) such that :\n\\[U(f)&lt;\\ldots&lt;U(f,P_{n})&lt;U(f)+\\frac{1}{n}\\]\nConsequently, \\(\\lim U(f,P_{n})=U(f)\\). Similarly, we can produce a sequence of partitions \\((Q_{m})\\) such that :\n\\[L(f)-\\frac{1}{m}&lt;\\ldots&lt;L(f,Q_{m})&lt;L(f)\\]\nWe know that:\n\\[\\begin{aligned}\nL(f,Q_{m}) & \\leq U(f,P_{n})\n\\end{aligned}\\]\nKeeping \\(m\\) fixed and passing to the limit, as \\(n\\to\\infty\\) on both sides, we have:\n\\[\\begin{aligned}\n\\lim_{n\\to\\infty}L(f,Q_{m}) & \\leq\\lim_{n\\to\\infty}U(f,P_{n})\\quad\\left\\{ \\text{Order Limit Theorem}\\right\\} \\\\\nL(f,Q_{m}) & \\leq U(f)\n\\end{aligned}\\]\nNow, passing to the limit, as \\(m\\to\\infty\\) on both sides, we have:\n\\[\\begin{aligned}\n\\lim_{m\\to\\infty}L(f,Q_{m}) & \\leq\\lim_{m\\to\\infty}U(f)\\quad\\left\\{ \\text{Order Limit Theorem}\\right\\} \\\\\nL(f) & \\leq U(f)\n\\end{aligned}\\] ◻\n\n\n(Riemann Integrability). A bounded function \\(f\\) on the interval \\([a,b]\\) is said to be Riemann integrable if \\(U(f)=L(f)\\). In this case, we define \\(\\int_{a}^{b}f\\) or \\(\\int_{a}^{b}f(x)dx\\) to be the common value:\n\\[\\begin{aligned}\n\\int_{a}^{b}f(x)dx & =U(f)=L(f)\n\\end{aligned}\\]\n\n\n(Integrability Criterion) A bounded function \\(f\\) is integrable on \\([a,b]\\) if and only if, for every \\(\\epsilon&gt;0\\), there exists a partition \\(P_{\\epsilon}\\) of \\([a,b]\\) such that:\n\\[\\begin{aligned}\nU(f,P_{\\epsilon})-L(f,P_{\\epsilon}) & &lt;\\epsilon\n\\end{aligned}\\]\n\n\nProof. Proof. (\\(\\Longleftarrow\\) direction.) Let \\(\\epsilon&gt;0\\). If such a partition \\(P_{\\epsilon}\\) exists, then:\n\\[U(f)-L(f)\\leq U(f,P_{\\epsilon})-L(f,P_{\\epsilon})&lt;\\epsilon\\]\nBecause \\(\\epsilon\\) is arbitrary, it follows that \\(U(f)=L(f)\\) and hence \\(f\\) is Riemann integrable.\n(\\(\\Longrightarrow\\) direction.) Let \\(f\\) be a bounded function on \\([a,b]\\) such that \\(f\\) is Riemann integrable.\nPick an arbitrary \\(\\epsilon&gt;0\\).\nThen, since \\(U(f)=\\inf\\{U(f,P):P\\in\\mathcal{P}\\}\\), there exists \\(P_{\\epsilon}\\in\\mathcal{P}\\), such that \\(U(f)&lt;U(f,P_{\\epsilon})&lt;U(f)+\\frac{\\epsilon}{2}\\). Since \\(L(f)=\\sup\\{L(f,P):P\\in\\mathcal{P}\\}\\), there exists \\(P_{\\epsilon}\\in\\mathcal{P}\\), such that \\(L(f)-\\frac{\\epsilon}{2}&lt;L(f,P_{\\epsilon})&lt;L(f)\\). Consequently,\n\\[\\begin{aligned}\nU(f,P_{\\epsilon})-L(f,P_{\\epsilon}) & &lt;U(f)+\\frac{\\epsilon}{2}-\\left(L(f)-\\frac{\\epsilon}{2}\\right)\\\\\n& =U(f)-L(f)+\\epsilon\\\\\n& =\\epsilon\n\\end{aligned}\\] ◻\n\n\n\n\nA point \\(c\\) is called a discontinuity of the first kind or jump point if both limits \\(g(c+)=\\lim_{t\\uparrow c}g(t)\\) and \\(g(c-)=\\lim_{t\\downarrow c}g(t)\\) exist and are not equal. The jump at \\(c\\) is defined as \\(\\Delta g(c)=g(c+)-g(c-)\\). Any other discontinuity is said to be of the second kind.\n\n\nConsider the function\n\\[\\begin{aligned}\nf(x) & =\\sin\\left(\\frac{1}{x}\\right)\n\\end{aligned}\\]\nLet \\(x_{n}=\\frac{1}{2n\\pi}\\). Then, \\(f(x_{n})=(0,0,0,\\ldots)\\). Next, consider \\(y_{n}=\\frac{1}{\\pi/2+2n\\pi}\\). Then, \\(f(y_{n})=(1,1,1,\\ldots)\\). Consequently, \\(f\\) is not continuous at \\(0\\). Hence, limits from the left or right don’t exist. Consequently, this is a discontinuity of the second kind.\n\nFunctions in stochastic calculus are functions without discontinuities of the second kind, that is functions have both left and right hand limits at any point of the domain and have one-sided limits at the boundary. These functions are called regular functions. It is often agreed to identify functions if they have the same right and left limits at any point.\nThe class \\(D=D[0,T]\\) of right-continuous functions on \\([0,T]\\) with left limits has a special name, cadlag functions (which is the abbreviation of right continuous with left limits in French). Sometimes these processes are called R.R.C. for regular right continuous. Notice that this class of processes includes \\(C\\), the class of continuous functions.\nLet \\(g\\in D\\) be a cadlag function, then, by definition, all the discontinuities of \\(g\\) are jumps. An important result in analysis is that, a function can have no more than a countable number of discontinuities.\n\n\n\nIf \\(g\\) is a function of a real variable, its variation over the interval \\([a,b]\\) is defined as:\n\\[\\begin{aligned}\nV_{g}([a,b]) & =\\sup\\left\\{ \\sum_{i=1}^{n}\\left|g(t_{i})-g(t_{i-1})\\right|\\right\\} \\label{eq:total-variation-of-a-function}\n\\end{aligned}\\]\nwhere the supremum is taken over all partitions \\(P\\in\\mathcal{P}\\).\nClearly, by the Triangle Inequality, the sums in ([eq:total-variation-of-a-function]) increase as new points are added to the partitions. Therefore, the variation of \\(g\\) is:\n\\[\\begin{aligned}\nV_{g}([a,b]) & =\\lim_{||\\Delta_{n}||\\to0}\\sum_{i=1}^{n}\\left|g(t_{i})-g(t_{i-1})\\right|\n\\end{aligned}\\]\nwhere \\(||\\Delta_{n}||=\\max_{1\\leq i\\leq n}(t_{i}-t_{i-1})\\). If \\(V_{g}([a,b])\\) is finite, then \\(g\\) is said to be a function of finite variation on \\([a,b]\\). If \\(g\\) is a function of \\(t\\geq0\\), then the variation of \\(g\\) as a function of \\(t\\) is defined by:\n\\[\\begin{aligned}\nV_{g}(t) & =V_{g}([0,t])\n\\end{aligned}\\]\nClearly, \\(V_{g}(t)\\) is an increasing function of \\(t\\).\n\n\\(g\\) is a function of finite variation if \\(V_{g}(t)&lt;\\infty\\) for all \\(t\\in[0,\\infty)\\). \\(g\\) is of bounded variation if \\(\\sup_{t}V_{g}(t)&lt;\\infty\\), in other words there exists \\(C\\), for all \\(t\\), such that \\(V_{g}(t)&lt;C\\). Here \\(C\\) is independent of \\(t\\).\n\n\n(1) If \\(g(t)\\) is increasing then for any \\(i\\), \\(g(t_{i})\\geq g(t_{i-1})\\), resulting in a telescopic sum, where all terms excluding the first and the last cancel out, leaving\n\\[\\begin{aligned}\nV_{g}(t) & =g(t)-g(0)\n\\end{aligned}\\]\n(2) If \\(g(t)\\) is decreasing, then similarly,\n\\[\\begin{aligned}\nV_{g}(t) & =g(0)-g(t)\n\\end{aligned}\\]\n\n\nIf \\(g(t)\\) is differentiable with continuous derivative \\(g'(t)\\), \\(g(t)=\\int_{0}^{t}g'(s)ds\\) then\n\\[\\begin{aligned}\nV_{g}(t) & =\\int_{0}^{t}|g'(s)|ds\n\\end{aligned}\\]\n\n\nProof. Proof. By definition,\n\\[\\begin{aligned}\nV_{g}(t) & =\\lim_{||\\Delta_{n}\\to0||}\\sum_{i=1}^{n}|g(t_{i})-g(t_{i-1})|\n\\end{aligned}\\]\nSince \\(g\\) is continuous and differentiable on \\([t_{i-1},t_{i}]\\), there exists \\(z_{i}\\in(t_{i-1},t_{i})\\) such, that \\(g(t_{i})-g(t_{i-1})=g'(z_{i})(t_{i}-t_{i-1})\\). Therefore, we can write:\n\\[\\begin{aligned}\n{1}\nV_{g}(t) & =\\lim_{||\\Delta_{n}\\to0||}\\sum_{i=1}^{n}|g'(z_{i})|(t_{i}-t_{i-1})\\\\\n& =\\int_{0}^{t}|g'(s)|ds\n\\end{aligned}\\] ◻\n\n\nIf \\(g\\) is continuous, \\(g'\\) exists and \\(\\int_{0}^{t}|g'(s)|ds\\) is finite, then \\(g\\) is of finite variation.\n\n\nThe function \\(g(t)=t\\sin(1/t)\\) for \\(t&gt;0\\) and \\(g(0)=0\\) is continuous on \\([0,1]\\) and differentiable at all points except zero, but is not of bounded variation on any interval that includes \\(0\\). Consider the partition \\(\\{x_{n}\\}=\\left\\{ \\frac{1}{\\pi/2+n\\pi}\\right\\}\\). Thus,\n\\[\\begin{aligned}\n\\sin(\\frac{1}{x_{n}}) & =\\begin{cases}\n1 & \\text{if }n\\text{ is even}\\\\\n-1 & \\text{if }n\\text{ is odd}\n\\end{cases}\n\\end{aligned}\\]\nThus,\n\\[\\begin{aligned}\nf(x_{n}) & =\\begin{cases}\nx_{n} & n\\text{ is even}\\\\\n-x_{n} & n\\text{ is odd}\n\\end{cases}\n\\end{aligned}\\]\nTherefore,\n\\[\\begin{aligned}\n\\sum_{n=1}^{m}|f(x_{n})-f(x_{n-1})| & =\\sum_{n=1}^{m}(x_{n}+x_{n-1})\\\\\n& =x_{0}+x_{n}+2\\sum_{n=1}^{m-1}x_{n}\\\\\n& \\geq\\sum_{n=1}^{m-1}x_{n}\n\\end{aligned}\\]\nThis is the lower bound on the variation of \\(g\\) on the partition \\(\\{0,x_{m},\\ldots,x_{1},x_{0},1\\}\\). Now, passing to the limit as \\(m\\) approaches infinity, \\(\\sum\\frac{1}{\\pi/2+n\\pi}\\) is a divergent series. Consequently, \\(V_{g}([0,1])\\) has unbounded variation.\n\n\n\n\n\nAny function \\(g:[0,\\infty)\\to\\mathbf{R}\\) is of bounded variation if and only if it can be expressed as the difference of two increasing functions:\n\\[\\begin{aligned}\ng(t) & =a(t)-b(t)\n\\end{aligned}\\]\n\n\nProof. Proof. (\\(\\Longrightarrow\\)direction). If \\(g\\) is of finite variation, \\(V_{g}(t)&lt;\\infty\\) for all \\(t\\), and we can write:\n\\[\\begin{aligned}\ng(t) & =V_{g}(t)-(V_{g}(t)-g(t))\n\\end{aligned}\\]\nLet \\(a(t)=V_{g}(t)\\) and \\(b(t)=V_{g}(t)-g(t)\\). Clearly, both \\(a(t)\\) and \\(b(t)\\) are increasing functions.\n(\\(\\Longleftarrow\\)direction). Suppose a function \\(g\\) can be expressed as a difference of two bounded increasing functions. Then,\n\\[\\begin{aligned}\nV_{g}(t) & =\\lim_{||\\Delta_{n}||\\to0}\\sum_{i=1}^{n}|(a(t_{i})-b(t_{i}))-(a(t_{i-1})-b(t_{i-1})|\\\\\n& \\quad\\{\\text{ Telescoping sum }\\}\\\\\n& =a(t)-b(t)-(a(0)-b(0))\n\\end{aligned}\\]\nSince both \\(a(t)\\) and \\(b(t)\\) are bounded, \\(g\\) has bounded variation. ◻\n\n\n\n\nLet \\(g\\) be a montonically increasing function on a finite closed interval \\([a,b]\\). A bounded function \\(f\\) defined on \\([a,b]\\) is said to Riemann-Stieltjes integrable with respect to \\(g\\) if the following limit exists:\n\\[\\begin{aligned}\n\\int_{a}^{b}f(t)dg(t) & =\\lim_{||\\Delta_{n}||\\to0}\\sum_{i=1}^{n}f(\\tau_{i})(g(t_{i})-g(t_{i-1}))\\label{eq:riemann-stieltjes-integral}\n\\end{aligned}\\]\nwhere \\(\\tau_{i}\\) is an evaluation point in the interval \\([t_{i-1},t_{i}]\\). It is a well-known fact that continuous functions are Riemann integrable and Riemann-Stieltjes integrable with respect to any monotonically increasing function on \\([a,b]\\).\nWe ask the following question. For any continuous functions \\(f\\) and \\(g\\) on \\([a,b]\\), can we define the integral \\(\\int_{a}^{b}f(t)dg(t)\\) by Equation ([eq:riemann-stieltjes-integral])?\nConsider the special case \\(f=g\\), namely, the integral:\n\\[\\int_{a}^{b}f(t)df(t)\\]\nLet \\(\\Delta_{n}=\\{a=t_{0},t_{1},\\ldots,t_{n}=b\\}\\) be a partition of \\([a,b]\\). Let \\(L_{n}\\) and \\(R_{n}\\) denote the corresponding Riemann sums with the evaluation points \\(\\tau_{i}=t_{i-1}\\) and \\(\\tau_{i}=t_{i}\\), respectively, namely,\n\\[\\begin{aligned}\nL_{n} & =\\sum_{i=1}^{n}f(t_{i-1})(f(t_{i})-f(t_{i-1}))\\label{eq:left-riemann-sum}\\\\\nR_{n} & =\\sum_{i=1}^{n}f(t_{i})(f(t_{i})-f(t_{i-1}))\\label{eq:right-riemann-sum}\n\\end{aligned}\\]\nIs it true that, \\(\\lim L_{n}=\\lim R_{n}\\) as \\(||\\Delta_{n}||\\to0\\)? Observe that:\n\\[R_{n}-L_{n}=\\sum_{i=1}^{n}(f(t_{i})-f(t_{i-1}))^{2}\\label{eq:quadratic-variation}\\]\n\\[R_{n}+L_{n}=\\sum_{i=1}^{n}(f(t_{i})^{2}-f(t_{i-1})^{2})=f(b)^{2}-f(a)^{2}\\label{eq:sum-of-left-and-right-riemann-sums}\\]\nTherefore, \\(R_{n}\\) and \\(L_{n}\\) are given by:\n\\[R_{n}=\\frac{1}{2}\\left(f(b)^{2}-f(a)^{2}+\\sum_{i=1}^{n}(f(t_{i})-f(t_{i-1}))^{2}\\right)\\]\n\\[L_{n}=\\frac{1}{2}\\left(f(b)^{2}-f(a)^{2}-\\sum_{i=1}^{n}(f(t_{i})-f(t_{i-1}))^{2}\\right)\\]\nThe limit of the right-hand side of equation ([eq:quadratic-variation]) is called the quadratic variation of the function \\(f\\) on \\([a,b]\\). Obviously, \\(\\lim_{||\\Delta_{n}||\\to0}R_{n}\\neq\\lim_{||\\Delta_{n}||\\to0}L_{n}\\) if and only the quadratic variation of the function \\(f\\) is non-zero.\n\nLet \\(f\\) be a \\(C^{1}\\)-function that is \\(f'(t)\\) is a continuous function. Then, by the mean value theorem:\n\\[\\begin{aligned}\n|R_{n}-L_{n}| & =\\sum_{i=1}^{n}(f(t_{i})-f(t_{i-1}))^{2}\\\\\n& =\\sum_{i=1}^{n}(f'(t_{i}^{*})(t_{i}-t_{i-1}))^{2}\\\\\n& \\quad\\{\\text{Mean Value Theorem}\\}\\\\\n& \\leq\\sum_{i=1}^{n}\\left\\Vert f'\\right\\Vert _{\\infty}^{2}(t_{i}-t_{i-1})^{2}\\\\\n& \\quad\\{\\text{ Interior Extremum Theorem }\\}\\\\\n& \\leq\\left\\Vert f'\\right\\Vert _{\\infty}^{2}\\left\\Vert \\Delta_{n}\\right\\Vert \\sum_{i=1}^{n}(t_{i}-t_{i-1})\\\\\n& =\\left\\Vert f'\\right\\Vert _{\\infty}^{2}\\left\\Vert \\Delta_{n}\\right\\Vert (b-a)\n\\end{aligned}\\]\nwhere \\(\\left\\Vert f'\\right\\Vert _{\\infty}=\\sup_{x\\in[a,b]}f(x)\\). Thus, the limit as \\(\\left\\Vert \\Delta_{n}\\right\\Vert \\to0\\) of the distance \\(|R_{n}-L_{n}|\\) also approaches zero. Thus, \\(\\lim L_{n}=\\lim R_{n}\\) as \\(\\left\\Vert \\Delta_{n}\\right\\Vert \\to0\\) and the Riemann-Stieltjes integral exists. By equation ([eq:sum-of-left-and-right-riemann-sums]), we have:\n\\[\\lim_{\\left\\Vert \\Delta_{n}\\right\\Vert \\to0}L_{n}=\\lim_{\\left\\Vert \\Delta_{n}\\right\\Vert \\to0}R_{n}=\\frac{1}{2}(f(b)^{2}-f(a)^{2})\\]\nOn the other hand, for such a \\(C^{1}\\)-function \\(f\\), we may simply define the integral \\(\\int_{a}^{b}f(t)df(t)\\) by:\n\\[\\begin{aligned}\n\\int_{a}^{b}f(t)df(t) & =\\int_{a}^{b}f(t)f'(t)dt\n\\end{aligned}\\]\nThen, by the fundamental theorem of Calculus:\n\\[\\int_{a}^{b}f(t)df(t)=\\int_{a}^{b}f(t)f'(t)dt=\\frac{1}{2}f(t)^{2}|_{a}^{b}=\\frac{1}{2}(f(b)^{2}-f(a)^{2})\\]\n\n\nThere is a very close relationship between functions with bounded variation and functions for which the classical integral makes sense. For the Ito integral, the quadratic variation plays a similar role. The quadratic variation of a smooth fuction \\(f\\in C^{1}([0,t])\\) is zero.\n\n\nSuppose \\(f\\) is a continuous function satisfying the condition\n\\[\\begin{aligned}\n|f(t)-f(s)| & \\leq C|t-s|^{1/2}\n\\end{aligned}\\]\nwhere \\(0&lt;C&lt;1\\).\nIn this case we have:\n\\[0\\leq|R_{n}-L_{n}|\\leq C^{2}\\sum_{i=1}^{n}(t_{i}-t_{i-1})=C^{2}(b-a)\\]\nHence, \\(\\lim R_{n}\\neq\\lim L_{n}\\) as \\(\\left\\Vert \\Delta_{n}\\right\\Vert \\to0\\) when \\(a\\neq b\\). Consequently, the integral \\(\\int_{a}^{b}f(t)df(t)\\) cannot be defined for such a function \\(f\\). Observe that the quandratic variation of the function is \\(b-a\\) (non-zero).\n\nWe see from the above examples, that definining the integral \\(\\int_{a}^{b}f(t)dg(t)\\) even when \\(f=g\\) is a non-trivial problem. Consider the question posed earlier - if \\(f\\) and \\(g\\) are continuous functions on \\([a,b]\\), can we define the integral \\(\\int_{a}^{b}f(t)dg(t)\\)? There is no simple answer to this question. But then in view of example ([ex:non-zero-quadratic-variation-example]), we can ask another question:\nQuestion. Are there continuous functions \\(f\\) satisfying the condition\n\\[\\begin{aligned}\n|f(t)-f(s)| & \\leq C|t-s|^{1/2}\n\\end{aligned}\\]\n\n\n\nConsider a random walk starting at \\(0\\) with jumps \\(h\\) and \\(-h\\) equally at times \\(\\delta\\), \\(2\\delta\\), \\(\\ldots\\) where \\(h\\) and \\(\\delta\\) are positive numbers. More precisely, let \\(\\{X_{n}\\}_{n=1}^{\\infty}\\) be a sequence of independent and identically distributed random variables with :\n\\[\\begin{aligned}\n\\mathbb{P}\\{X_{j}=h\\} & =\\mathbb{P}\\{X_{j}=-h\\}=\\frac{1}{2}\n\\end{aligned}\\]\nLet \\(Y_{\\delta,h}(0)=0\\) and put:\n\\[\\begin{aligned}\nY_{\\delta,h}(n\\delta) & =X_{1}+X_{2}+\\ldots+X_{n}\n\\end{aligned}\\]\nFor \\(t&gt;0\\), define \\(Y_{\\delta,h}(t)\\) by linearization that is, for \\(n\\delta&lt;t&lt;(n+1)\\delta\\), define:\n\\[\\begin{aligned}\nY_{\\delta,h}(t) & =\\frac{(n+1)\\delta-t}{\\delta}Y_{\\delta,h}(n\\delta)+\\frac{t-n\\delta}{\\delta}Y_{\\delta,h}((n+1)\\delta)\n\\end{aligned}\\]\nWe can think of \\(Y_{\\delta,h}(t)\\) as the position of the random walk at time \\(t\\). In particular, \\(X_{1}+X_{2}+\\ldots+X_{n}\\) is the position of this random walk at time \\(n\\delta\\).\nQuestion. What is the limit of the random walk \\(Y_{\\delta,h}\\) as \\(\\delta,h\\to0\\)?\nRecall that the characteristic function of a random variable \\(X\\) is \\(\\phi_{X}(\\lambda)=\\mathbb{E}\\exp[i\\lambda X]\\). In order to find out the answer, let us compute the following limit of the characteristic function of \\(Y_{\\delta,h}(t)\\):\n\\[\\lim_{\\delta,h\\to0}\\mathbb{E}\\exp\\left[i\\lambda Y_{\\delta,h}(t)\\right]\\]\nwhere \\(\\lambda\\in\\mathbf{R}\\)is fixed. For heuristic derivation, let \\(t=n\\delta\\) and so \\(n=t/\\delta\\). Then we have:\n\\[\\begin{aligned}\n\\mathbb{E}\\exp\\left[i\\lambda Y_{\\delta,h}(t)\\right] & =\\prod_{j=1}^{n}\\mathbb{E}e^{i\\lambda X_{j}}\\\\\n& =\\prod_{j=1}^{n}\\left(\\frac{1}{2}e^{i\\lambda h}+\\frac{1}{2}e^{-i\\lambda h}\\right)\\\\\n& =\\left(\\frac{1}{2}e^{i\\lambda h}+\\frac{1}{2}e^{-i\\lambda h}\\right)^{n}\\\\\n& =\\left(\\cos\\lambda h\\right)^{n}\\\\\n& =\\left(\\cos\\lambda h\\right)^{t/\\delta}\n\\end{aligned}\\]\nFor fixed \\(t\\) and \\(\\lambda\\), when \\(\\delta\\) and \\(h\\) independently approach \\(0\\), the limit of \\(\\mathbb{E}\\exp\\left[i\\lambda Y_{\\delta,h}(t)\\right]\\) may not exist. For example, holding \\(h\\) constant, letting \\(\\delta\\to0\\), since \\(-1\\leq\\cos\\theta\\leq1\\), the function \\(\\left(\\cos\\lambda h\\right)^{t/\\delta}\\to0\\). Holding \\(\\delta\\) constant, letting \\(h\\to0\\), the function \\(\\left(\\cos\\lambda h\\right)^{t/\\delta}\\to1\\). In order for the limit to exist, we impose a certain relationship between \\(\\delta\\) and \\(h\\). However, depending on the relationship, we may obtain different limits.\nLet \\(u=\\cos(\\lambda h)^{1/\\delta}\\). Then \\(\\ln u=\\frac{1}{\\delta}\\ln\\cos(\\lambda h)\\). Note that:\n\\[\\begin{aligned}\n\\cos(\\lambda h) & \\approx1-\\frac{1}{2}\\lambda^{2}h^{2}\n\\end{aligned}\\]\nAnd \\(\\ln(1+x)\\approx x\\). Hence,\n\\[\\ln\\cos(\\lambda h)\\approx\\ln\\left(1-\\frac{1}{2}\\lambda^{2}h^{2}\\right)\\approx-\\frac{1}{2}\\lambda^{2}h^{2}\\]\nTherefore for small \\(\\lambda\\) and \\(h\\), we have \\(\\ln u\\approx-\\frac{1}{2\\delta}\\lambda^{2}h^{2}\\) and so:\n\\[\\begin{aligned}\nu & \\approx\\exp\\left[-\\frac{1}{2\\delta}\\lambda^{2}h^{2}\\right]\n\\end{aligned}\\]\nIn particular, if \\(\\delta\\) and \\(h\\) are related by \\(h^{2}=\\delta\\), then\n\\[\\begin{aligned}\n\\lim_{\\delta\\to0}\\mathbb{E}\\exp\\left[i\\lambda Y_{\\delta,h}(t)\\right] & =e^{-\\frac{1}{2}\\lambda^{2}t}\n\\end{aligned}\\]\nBut, \\(e^{-\\frac{1}{2}\\lambda^{2}t}\\) is the characteristic function of a Gaussian random variable with mean \\(0\\) and variance \\(t\\). Thus, we have derived the following theorem about the limit of the random walk \\(Y_{\\delta,h}\\) as \\(\\delta,h\\to0\\) in such a way that \\(h^{2}=\\delta\\).\n\nLet \\(Y_{\\delta,h}(t)\\) be the random walk starting at \\(0\\) with jumps \\(h\\) and \\(-h\\) equally likely at times \\(\\delta\\), \\(2\\delta\\), \\(3\\delta\\), \\(\\ldots\\). Assume that \\(h^{2}=\\delta\\). Then, for each \\(t\\geq0\\), the limit:\n\\[\\begin{aligned}\n\\lim_{\\delta\\to0}Y_{\\delta,h}(t) & =B(t)\n\\end{aligned}\\] exists in distribution. Moreover, we have:\n\\[\\begin{aligned}\n\\mathbb{E}e^{i\\lambda B(t)} & =e^{-\\frac{1}{2}\\lambda^{2}t}\n\\end{aligned}\\]\n\n\n(Quadratic Variation of a Brownian motion). Let \\((B_{t},t\\ge0)\\) be a standard brownian motion. Then, for any sequence of partitions \\((t_{j},j\\leq n)\\) of \\([0,t]\\) we have:\n\\[\\begin{aligned}\n\\left\\langle B\\right\\rangle _{t} & =\\sum_{j=1}^{n}(B_{t_{j+1}}-B_{t_{j}})^{2}\\stackrel{L^{2}}{\\to}t\n\\end{aligned}\\]\nwhere the convergence is in the \\(L^{2}\\) sense.\n\n\nIt is reasonable to have some sort of convergence as we are dealing with a sum of independent random variables. However, the conclusion would not hold if the increments were not squared. So there is something more at play here.\n\n\nProof. Proof. We have:\n\\[\\begin{aligned}\n\\mathbb{E}\\left[\\left(\\sum_{j=0}^{n-1}(B(t_{j+1})-B(t_{j}))^{2}-t\\right)^{2}\\right] & =\\mathbb{E}\\left[\\left(\\sum_{j=0}^{n-1}(B(t_{j+1})-B(t_{j}))^{2}-\\sum_{j=0}^{n-1}(t_{j+1}-t_{j})\\right)^{2}\\right]\\\\\n& =\\mathbb{E}\\left[\\left(\\sum_{j=0}^{n-1}\\left\\{ (B(t_{j+1})-B(t_{j}))^{2}-(t_{j+1}-t_{j})\\right\\} \\right)^{2}\\right]\n\\end{aligned}\\]\nFor simplicity, we define the variables \\(X_{j}=(B(t_{j+1})-B(t_{j}))^{2}-(t_{j+1}-t_{j})\\). Then, we may write:\n\\[\\begin{aligned}\n\\mathbb{E}\\left[\\left(\\sum_{j=0}^{n-1}(B(t_{j+1})-B(t_{j}))^{2}-t\\right)^{2}\\right] & =\\mathbb{E}\\left[\\left(\\sum_{j=0}^{n-1}X_{j}\\right)^{2}\\right]\\\\\n& =\\mathbb{E}\\left[\\sum_{i=0}^{n-1}\\sum_{j=0}^{n-1}X_{i}X_{j}\\right]\\\\\n& =\\sum_{i=0}^{n-1}\\sum_{j=0}^{n-1}\\mathbb{E}[X_{i}X_{j}]\n\\end{aligned}\\]\nNow, the random variables \\(X_{j}\\) are independent.\nThe expectation of \\(X_{j}\\) is \\(\\mathbb{E}[X_{j}]=\\mathbb{E}(B(t_{j+1})-B(t_{j}))^{2}-(t_{j+1}-t_{j})=0\\).\nSince, \\(X_{i}\\) and \\(X_{j}\\) are independent, for \\(i\\neq j\\), \\(\\mathbb{E}[X_{i}X_{j}]=\\mathbb{E}X_{i}\\cdot\\mathbb{E}X_{j}=0\\).\nHence, we have:\n\\[\\begin{aligned}\n\\mathbb{E}\\left[\\left(\\sum_{j=0}^{n-1}(B(t_{j+1})-B(t_{j}))^{2}-t\\right)^{2}\\right] & =\\sum_{i=0}^{n-1}\\mathbb{E}[X_{i}^{2}]\n\\end{aligned}\\]\nWe now develop the expectation of the square of \\(X_{i}\\). We have:\n\\[\\begin{aligned}\n\\mathbb{E}[X_{i}^{2}] & =\\mathbb{E}\\left[\\left((B(t_{i+1})-B(t_{i}))^{2}-(t_{i+1}-t_{i})\\right)^{2}\\right]\\\\\n& =\\mathbb{E}\\left[((B(t_{i+1})-B(t_{i}))^{4}-2(B(t_{i+1})-B(t_{i}))^{2}(t_{i+1}-t_{i})+(t_{i+1}-t_{i})^{2}\\right]\n\\end{aligned}\\]\nThe MGF of the random variable \\(B(t_{i+1})-B(t_{i})\\) is :\n\\[\\begin{aligned}\n\\phi(\\lambda) & =\\exp\\left[\\frac{\\lambda^{2}(t_{i+1}-t_{i})}{2}\\right]\\\\\n\\phi'(\\lambda) & =\\lambda(t_{i+1}-t_{i})\\exp\\left[\\frac{\\lambda^{2}(t_{i+1}-t_{i})}{2}\\right]\\\\\n\\phi''(\\lambda) & =\\left[(t_{i+1}-t_{i})+\\lambda^{2}(t_{i+1}-t_{i})^{2}\\right]\\exp\\left[\\frac{\\lambda^{2}(t_{i+1}-t_{i})}{2}\\right]\\\\\n\\phi^{(3)}(\\lambda) & =\\left[3\\lambda(t_{i+1}-t_{i})^{2}+\\lambda^{3}(t_{i+1}-t_{i})^{3}\\right]\\exp\\left[\\frac{\\lambda^{2}(t_{i+1}-t_{i})}{2}\\right]\\\\\n\\phi^{(4)}(\\lambda) & =\\left[3(t_{i+1}-t_{i})^{2}+6\\lambda^{2}(t_{i+1}-t_{i})^{3}+\\lambda^{4}(t_{i+1}-t_{i})^{4}\\right]\\exp\\left[\\frac{\\lambda^{2}(t_{i+1}-t_{i})}{2}\\right]\n\\end{aligned}\\]\nThus, \\(\\mathbb{E}[(B(t_{i+1})-B(t_{i}))^{4}]=3(t_{i+1}-t_{i})^{2}\\). Consequently,\n\\[\\begin{aligned}\n\\mathbb{E}[X_{i}^{2}] & =\\mathbb{E}[(B(t_{i+1})-B(t_{i}))^{4}]-2(t_{i+1}-t_{i})\\mathbb{E}[(B(t_{i+1})-B(t_{i}))^{2}]+(t_{i+1}-t_{i})^{2}\\\\\n& =3(t_{i+1}-t_{i})^{2}-2(t_{i+1}-t_{i})^{2}+(t_{i+1}-t_{i})^{2}\\\\\n& =2(t_{i+1}-t_{i})^{2}\n\\end{aligned}\\]\nPutting all this together, we finally have that:\n\\[\\begin{aligned}\n\\mathbb{E}\\left[\\left(\\sum_{j=0}^{n-1}(B(t_{j+1})-B(t_{j}))^{2}-t\\right)^{2}\\right] & =2\\sum_{i=0}^{n-1}(t_{i+1}-t_{i})^{2}\\label{eq:second-moment-of-qv}\\\\\n& \\leq2\\left\\Vert \\Delta_{n}\\right\\Vert \\sum_{i=0}^{n-1}(t_{i+1}-t_{i})\\nonumber \\\\\n& =2\\left\\Vert \\Delta_{n}\\right\\Vert \\cdot t\\nonumber\n\\end{aligned}\\]\nAs \\(n\\to\\infty\\), \\(\\left\\Vert \\Delta_{n}\\right\\Vert \\to0\\). Hence,\n\\[\\begin{aligned}\n\\lim_{n\\to\\infty}\\mathbb{E}\\left[\\left(\\sum_{j=0}^{n-1}(B(t_{j+1})-B(t_{j}))^{2}-t\\right)^{2}\\right] & =0\n\\end{aligned}\\]\nHence, the sequence of random variables\n\\[\\begin{aligned}\n\\sum_{j=0}^{n-1}(B(t_{j+1})-B(t_{j}))^{2} & \\stackrel{L^{2}}{\\to}t\n\\end{aligned}\\] ◻\n\n\n(Quadratic Variation of a Brownian Motion Path). Let \\((B_{s},s\\geq0)\\) be a Brownian motion. For every \\(n\\in\\mathbf{N}\\), consider the dyadic partition \\((t_{j},j\\leq2^{n})\\) of \\([0,t]\\) where \\(t_{j}=\\frac{j}{2^{n}}t\\). Then we have that:\n\\[\\begin{aligned}\n\\left\\langle B\\right\\rangle _{t} & =\\sum_{j=1}^{2^{n}-1}(B_{t_{j+1}}-B_{t_{j}})^{2}\\stackrel{a.s.}{\\to}t\n\\end{aligned}\\]\n\n\nProof. Proof. We have \\((t_{i+1}-t_{i})=\\frac{t}{2^{n}}.\\) Borrowing equation ([eq:second-moment-of-qv]) from the proof of theorem ([th:quadratic-variation-of-bm-approaches-t-in-mean-square]), we have that:\n\\[\\begin{aligned}\n\\mathbb{E}\\left[\\left(\\sum_{j=0}^{2^{n}-1}(B(t_{j+1})-B(t_{j}))^{2}-t\\right)^{2}\\right] & =2\\sum_{i=0}^{2^{n}-1}\\left(\\frac{t}{2^{n}}\\right)^{2}\\\\\n& =2\\cdot(2^{n})\\cdot\\frac{t^{2}}{2^{2n}}\\\\\n& =\\frac{2t^{2}}{2^{n}}\n\\end{aligned}\\]\nBy Chebyshev’s inequality,\n\\[\\begin{aligned}\n\\mathbb{P}\\left(\\left|\\sum_{j=0}^{2^{n}-1}(B(t_{j+1})-B(t_{j}))^{2}-t\\right|&gt;\\epsilon\\right) & \\leq\\frac{1}{\\epsilon^{2}}\\mathbb{E}\\left[\\left(\\sum_{j=0}^{2^{n}-1}(B(t_{j+1})-B(t_{j}))^{2}-t\\right)^{2}\\right]\\\\\n& \\leq\\frac{1}{\\epsilon^{2}}\\cdot\\frac{2t^{2}}{2^{n}}\n\\end{aligned}\\]\nDefine \\(A_{n}:=\\left\\{ \\left|\\sum_{j=0}^{2^{n}-1}(B(t_{j+1})-B(t_{j}))^{2}-t\\right|&gt;\\epsilon\\right\\}\\). Since, \\(\\sum\\frac{1}{2^{n}}\\) is a convergent series, any multiple of it, \\((2t^{2}/\\epsilon^{2})\\sum\\frac{1}{2^{n}}\\) also converges. Now, \\(0\\leq\\mathbb{P}(A_{n})\\leq\\frac{(2t^{2}/\\epsilon^{2})}{2^{n}}\\). By the comparison test, \\(\\sum\\mathbb{P}(A_{n})\\) converges to a finite value. By Theorem ([th:sufficient-condition-for-almost-sure-convergence]),\n\\[\\begin{aligned}\n\\sum_{j=0}^{2^{n}-1}(B(t_{j+1})-B(t_{j}))^{2} & \\stackrel{a.s.}{\\to}t\n\\end{aligned}\\] ◻\n\nWe are now ready to show that every Brownian motion path has infinite variation.\nIf \\(g\\) is a \\(C^{1}\\) function,\n\\[\\begin{aligned}\n\\int_{0}^{t}|g'(t)|dt & =\\int_{0}^{t}\\sqrt{g'(t)^{2}}dt\\\\\n& \\leq\\int_{0}^{t}\\sqrt{1+g'(t)^{2}}dt\\\\\n& =l_{g}(t)\n\\end{aligned}\\]\nwhere \\(l_{g}(t)\\) is the arclength of the function \\(g\\) between \\([0,t]\\). So, \\(V_{g}(t)\\leq l_{g}(t)\\) and further:\n\\[\\begin{aligned}\nl_{g}(t) & =\\int_{0}^{t}\\sqrt{1+g'(t)^{2}}dt\\\\\n& \\leq\\int_{0}^{t}\\left(1+\\sqrt{g'(t)^{2}}\\right)dt\\\\\n& \\leq t+V_{g}(t)\n\\end{aligned}\\]\nConsequently,\n\\[\\begin{aligned}\nV_{g}(t) & \\leq l_{g}(t)\\leq t+V_{g}(t)\n\\end{aligned}\\]\nThe total variation of the function is finite if and only if it’s arclength is.\nHence, intuitively, our claim is that a Brownian motion path on \\([0,T]\\) has infinite arc-length. Since \\(g\\in C^{1}([a,b])\\Longrightarrow(V_{g}(t)&lt;\\infty)\\), it follows that \\((V_{g}(t)\\to\\infty)\\Longrightarrow g\\notin C^{1}\\).\n\n(Brownian Motion paths have unbounded total variation.)  Let \\((B_{s},s\\geq0)\\) be a Brownian motion. Then, the random functions \\(B(s,\\omega)\\) on the interval \\([0,t]\\) have unbounded variation almost surely.\n\n\nProof. Proof. Take the sequence of dyadic partitions of \\([0,t]\\): \\(t_{j}=\\frac{j}{2^{n}}t\\), \\(n\\in\\mathbf{N}\\), \\(j\\leq2^{n}\\). By pulling out the worst increment, we have the trivial bound for every \\(\\omega\\):\n\\[\\begin{aligned}\n\\sum_{j=0}^{2^{n}-1}(B_{t_{j+1}}(\\omega)-B_{t_{j}}(\\omega))^{2} & \\leq\\max_{0\\leq j\\leq2^{n}}\\left|B_{t_{j+1}}(\\omega)-B_{t_{j}}(\\omega)\\right|\\cdot\\sum_{j=0}^{2^{n}-1}(B_{t_{j+1}}(\\omega)-B_{t_{j}}(\\omega))\\label{eq:trivial-upper-bound-on-quadratic-variation}\n\\end{aligned}\\]\nWe proceed by contradiction. Let \\(A'\\) be the set of all \\(\\omega\\), for which the Brownian motion paths have bounded total variation. Let \\(A\\) be event that the Brownian motion paths have unbounded variation.\nBy the definition of total variation, that would imply, \\(\\exists M\\in\\mathbf{N}\\) :\n\\[\\begin{aligned}\n(\\forall\\omega\\in A')\\quad\\lim_{n\\to\\infty}\\sum_{j=0}^{2^{n}-1}\\left|(B_{t_{j+1}}(\\omega)-B_{t_{j}}(\\omega))\\right| & &lt;M\n\\end{aligned}\\]\nSince Brownian Motion paths are continuous on the compact set \\([\\frac{j}{2^{n}}t,\\frac{j+1}{2^{n}}t]\\), they are uniformly continuous. So, as \\(n\\to\\infty\\), \\(|t_{j+1}-t_{j}|\\to0\\) and therefore \\(|B_{t_{j+1}}(\\omega)-B_{t_{j}}(\\omega)|\\to0\\). And consequently, \\(\\max_{0\\leq j\\leq2^{n}}\\left|B_{t_{j+1}}(\\omega)-B_{t_{j}}(\\omega)\\right|\\to0\\).\nThus, for every \\(\\omega\\in A'\\), the right hand side of the inequality ([eq:trivial-upper-bound-on-quadratic-variation]), converges to \\(0\\) and therefore the left hand side converges to \\(0\\). But, this contradicts the fact that \\(\\left\\langle B\\right\\rangle _{t}\\stackrel{a.s.}{\\to}t\\). So, \\(A'\\) is a null set, and \\(\\mathbb{P}(A')=0\\) and \\(\\mathbb{P}(A)=1\\). This closes the proof. ◻"
  },
  {
    "objectID": "posts/properties-of-brownian-motion/index.html#what-exactly-is-omegamathcalfmathbbp-in-mathematical-finance",
    "href": "posts/properties-of-brownian-motion/index.html#what-exactly-is-omegamathcalfmathbbp-in-mathematical-finance",
    "title": "Properties of Brownian Motion",
    "section": "",
    "text": "If we make the simplifying assumption that the process paths are continuous, we obtain the set of all continuous functions on \\([0,T]\\), denoted by \\(C[0,T]\\). This is a very rich space. In a more general model, it is assumed that the process paths are right continuous with left limits (regular right-continuous RRC, cadlag) functions.\nLet the sample space \\(\\Omega=D[0,T]\\) be the set of all RRC functions on \\([0,T]\\). An element of this set is a RRC function from \\([0,T]\\) into \\(\\mathbf{R}\\). First we must decide what kind of sets of these functions are measurable? The simplest set for which we would like to calculate the probabilities are sets of the form \\(\\{a\\leq S(t_{1})\\leq b\\}\\) for some \\(t_{1}\\). If \\(S(t)\\) represents the price of a stock at time \\(t\\), then the probability of such a set gives the probability that the stock price at time \\(t_{1}\\) is between \\(a\\) and \\(b\\). We are also interested in how the price of the stock at time \\(t_{1}\\) affects the price at another time \\(t_{2}\\). Thus, we need to talk about the joint distribution of stock prices \\(S(t_{1})\\) and \\(S(t_{2})\\). This means that we need to define probability on the sets of the form \\(\\{S(t_{1})\\in B_{1},S(t_{2})\\in B_{2}\\}\\) where \\(B_{1}\\) and \\(B_{2}\\) are intervals on the line. More generally, we would like to have all the finite-dimensional distributions of the process \\(S(t)\\), that is, the probabilities of the sets: \\(\\{S(t_{1})\\in B_{1},S(t_{2})\\in B_{2},\\ldots,S(t_{n})\\in B_{n}\\}\\) for any choice of \\(0\\leq t_{1}\\leq\\ldots\\leq t_{n}\\leq T\\).\nThe sets of the form \\(A=\\{\\omega(\\cdot)\\in D[0,T]:\\omega(t_{1})\\in B_{1},\\ldots,\\omega(t_{n})\\in B_{n}\\}\\), where \\(B_{i}\\)’s are borel subsets of \\(\\mathbf{R}\\), are called cylinder sets or finite-dimensional rectangles.\nThe stochastic process \\(S(t)\\) is just a (function-valued) random variable on this sample space, which takes some value \\(\\omega(t)\\) - the value of the function \\(\\omega\\) at \\(t\\).\nLet \\(\\mathcal{R}\\) be the colllection of all cylindrical subsets of \\(D[0,1]\\). Obviously \\(\\mathcal{R}\\) is not a \\(\\sigma\\)-field.\nProbability is first defined by on the elements of \\(\\mathcal{R}\\). Let \\(A\\subseteq\\mathcal{R}\\).\n\\[\\begin{aligned}\n\\mathbb{P}(A) & =\\int_{B_{1}}\\cdots\\int_{B_{n}}\\prod_{i=1}^{n}\\frac{1}{\\sqrt{(2\\pi)(t_{i}-t_{i-1})}}\\exp\\left[-\\frac{(u_{i}-u_{i-1})^{2}}{2(t_{i}-t_{i-1})}\\right]du_{1}\\cdots du_{n}\n\\end{aligned}\\]\nand then extended to the \\(\\sigma\\)-field generated by taking unions, complements and intersections of cylinders. We take the smallest \\(\\sigma\\)-algebra containing all the cylindrical subsets of \\(D[0,1]\\). Thus, \\(\\mathcal{F}=\\mathcal{B}(D[0,1])\\).\nHence, \\((\\Omega,\\mathcal{F},\\mathbb{P})=(D[0,1],\\mathcal{B}(D[0,1]),\\mathbb{P})\\) is a probability space. It is called the Wiener space and \\(\\mathbb{P}\\) here is called the Wiener measure."
  },
  {
    "objectID": "posts/properties-of-brownian-motion/index.html#continuity-and-regularity-of-paths.",
    "href": "posts/properties-of-brownian-motion/index.html#continuity-and-regularity-of-paths.",
    "title": "Properties of Brownian Motion",
    "section": "",
    "text": "As discussed in the previous section, a stochastic process is determined by its finite-dimensional distribution. In studying stochastic processes, it is often natural to think of them as function-valued random variables in \\(t\\). Let \\(S(t)\\) be defined for \\(0\\leq t\\leq T\\), then for a fixed \\(\\omega\\), it is a function in \\(t\\), called the sample path or a realization of \\(S\\). Finite-dimensional distributions do not determine the continuity property of sample paths. The following example illustrates this.\n\nLet \\(X(t)=0\\) for all \\(t\\), \\(0\\leq t\\leq1\\) and \\(\\tau\\) be a uniformly distributed random variable on \\([0,1]\\). Let \\(Y(t)=0\\) for \\(t\\neq\\tau\\) and \\(Y(t)=1\\) if \\(t=\\tau.\\) Then, for any fixed \\(t\\), \\(\\mathbb{P}(Y(t)\\neq0)=\\mathbb{P}(\\tau=t)=0\\), and hence \\(\\mathbb{P}(Y(t)=0)=1\\). So, that all one-dimensional distributions of \\(X(t)\\) and \\(Y(t)\\) are the same. Similarly, all finite-dimensional distributions of \\(X\\) and \\(Y\\) are the same. However, the sample paths of the process \\(X\\), that is, the functions \\(X(t)_{0\\leq t\\leq1}\\) are continuous in \\(t\\), whereas every sample path \\(Y(t)_{0\\leq t\\leq1}\\) has a jump at the (random) point \\(\\tau\\). Notice that, \\(\\mathbb{P}(X(t)=Y(t))=1\\) for all \\(t\\), \\(0\\leq t\\leq1\\).\n\n\nTwo stochastic processes are called versions (modifications) of one another if\n\\[\\mathbb{P}(X(t)=Y(t))=1\\quad\\text{for all }0\\leq t\\leq T\\]\n\nThus, the two processes in the example ([ex:modifications-of-a-stochastic-process]) are versions of one another, one has continuous sample paths, the other does not. If we agree to pick any version of the process we want, then we can pick the continous version when it exists. In general, we choose the smoothest possible version of the process.\nFor two processes, \\(X\\) and \\(Y\\), denote by \\(N_{t}=\\{X(t)\\neq Y(t)\\}\\), \\(0\\leq t\\leq T\\). In the above example, \\(\\mathbb{P}(N_{t})=\\mathbb{P}(\\tau=t)=0\\) for any \\(t\\), \\(0\\leq t\\leq1\\). However, \\(\\mathbb{P}(\\bigcup_{0\\leq t\\leq1}N_{t})=\\mathbb{P}(\\tau=t\\:\\text{for some }t\\:\\text{in }[0,1])=1\\). Although, each of \\(N_{t}\\) is a \\(\\mathbb{P}\\)-null set, the union \\(N=\\bigcup_{0\\leq t\\leq1}N_{t}\\) contains uncountably many null sets, and in this particular case it is a set of of probability one.\nIf it happens that \\(\\mathbb{P}(N)=0\\), then \\(N\\) is called an evanescent set, and the processes \\(X\\) and \\(Y\\) are called indistinguishable. Note that in this case, \\(\\mathbb{P}(\\{\\omega:\\exists t:X(t)\\neq Y(t)\\})=\\mathbb{P}(\\bigcup_{0\\leq t\\leq1}\\{X(t)\\neq Y(t))=0\\) and \\(\\mathbb{P}(\\bigcap_{0\\leq t\\leq1}\\{X(t)=Y(t)\\})=1\\). It is clear, that if the time is discrete, then any two versions of the process are indistinguishable. It is also not hard to see, that if \\(X(t)\\) and \\(Y(t)\\) are versions of one another and they are both right-continuous, they are indistinguishable.\n\n(Paul Levy’s construction of Brownian Motion). Standard Brownian motion exists.\n\n\nProof. Proof. I reproduce the standard proof as present in Brownian Motion by Morters and Peres. I added some remarks for greater clarity.\nLet\n\\[\\begin{aligned}\n\\mathcal{D}_{n} & =\\left\\{ \\frac{k}{2^{n}}:k=0,1,2,\\ldots,2^{n}\\right\\}\n\\end{aligned}\\]\nbe a finite set of dyadic points.\nLet\n\\[\\begin{aligned}\n\\mathcal{D} & =\\bigcup_{n=0}^{\\infty}\\mathcal{D}_{n}\n\\end{aligned}\\]\nLet \\(\\{Z_{t}:t\\in\\mathcal{D}\\}\\) be a collection of independent, standard normally distributed random variables. This is a countable set of random variables.\nLet \\(B(0):=0\\) and \\(B(1):=Z_{1}\\).\nFor each \\(n\\in\\mathbf{N}\\), we define the random variables \\(B(d)\\), \\(d\\in\\mathcal{D}_{n}\\) such that, the following invariant holds:\n(1) for all \\(r&lt;s&lt;t\\) in \\(\\mathcal{D}_{n}\\) the random variable \\(B(t)-B(s)\\) is normally distributed with mean zero and variance \\(t-s\\) and is independent of \\(B(s)-B(r)\\).\n(2) the vectors \\((B(d):d\\in\\mathcal{D}_{n})\\) and \\((Z_{t}:t\\in\\mathcal{D}\\setminus\\mathcal{D}_{n})\\) are independent.\nNote that we have already done this for \\(\\mathcal{D}_{0}=\\{0,1\\}\\). Proceeding inductively, let’s assume that the above holds for some \\(n-1\\). We are interested to prove that the invariant also holds for \\(n\\).\nWe define \\(B(d)\\) for \\(d\\in\\mathcal{D}_{n}\\backslash\\mathcal{D}_{n-1}\\) by:\n\\[\\begin{aligned}\nB(d) & =\\frac{B(d-2^{-n})+B(d+2^{-n})}{2}+\\frac{Z_{d}}{2^{(n+1)/2}}\n\\end{aligned}\\]\nNote that, the points \\(0,\\frac{1}{2^{n-1}},\\ldots,\\frac{k}{2^{n-1}},\\frac{k+1}{2^{n-1}},\\ldots,1\\) belong to \\(\\mathcal{D}_{n-1}\\). The first summand is the linear interpolation of the values of \\(B\\) at the neighbouring points of \\(d\\) in \\(\\mathcal{D}_{n-1}\\). That is,\n\\[\\begin{aligned}\nB\\left(\\frac{2k+1}{2^{n}}\\right) & =\\frac{B\\left(\\frac{k}{2^{n-1}}\\right)+B\\left(\\frac{k+1}{2^{n-1}}\\right)}{2}+\\frac{Z_{d}}{2^{(n+1)/2}}\n\\end{aligned}\\]\nSince \\(P(n-1)\\) holds, \\(B(d-2^{-n})\\) and \\(B(d+2^{-n})\\) are have no dependence on \\((Z_{t}:t\\in\\mathcal{D}\\setminus\\mathcal{D}_{n-1})\\). Consequently, \\(B(d)\\) has no dependence on \\((Z_{t}:t\\in\\mathcal{D}\\setminus\\mathcal{D}_{n})\\) and the second property is fulfilled.\nMoreover, as \\(\\frac{1}{2}[B(d+2^{-n})-B(d-2^{-n})]\\) depends only on \\((Z_{t}:t\\in\\mathcal{D}_{n-1})\\), it is independent of \\(\\frac{Z_{d}}{2^{(n+1)/2}}\\). By our induction assumptions, they are both nromally distributed with mean \\(0\\) and variance \\(\\frac{1}{2^{(n+1)}}\\).\nSo, their sum and difference random variables\n\\[\\begin{aligned}\nB(d)-B(d-2^{-n}) & =\\frac{B(d+2^{-n})-B(d-2^{-n})}{2}+\\frac{Z_{d}}{2^{(n+1)/2}}\\\\\nB(d+2^{-n})-B(d) & =\\frac{B(d+2^{-n})-B(d-2^{-n})}{2}-\\frac{Z_{d}}{2^{(n+1)/2}}\n\\end{aligned}\\]\nare also independent, with mean \\(0\\) and variance \\(\\frac{1}{2^{n}}\\) (the variance of independent random variables is the sum of the variances).\nIndeed all increments \\(B(d)-B(d-2^{-n})\\) for \\(d\\in\\mathcal{D}_{n}\\setminus\\{0\\}\\) are independent. To see this, it suffices to show that they are pairwise independent. We have seen in the previous paragraph that the pairs \\(B(d)-B(d-2^{-n})\\) and \\(B(d+2^{-n})-B(d)\\) with \\(d\\in\\mathcal{D}_{n}\\setminus\\mathcal{D}_{n-1}\\) are independent. The other possibility is that the increments are over the intervals separated by some \\(d\\in\\mathcal{D}_{n-1}\\). For concreteness, if \\(n\\) were \\(3\\), then the increments, \\(B_{7/8}-B_{6/8}\\) and \\(B_{5/8}-B_{4/8}\\) are seperated by \\(d=\\frac{3}{4}\\in\\mathcal{D}_{2}\\). Choose \\(d\\in\\mathcal{D}_{j}\\) with this property and minimal \\(j\\), so, the two intervals are contained in \\([d-2^{-j},d]\\) and \\([d,d+2^{-j}]\\) respectively. By induction, the increments over these two intervals of length \\(2^{-j}\\) are independent and the increments over the intervals of length \\(2^{-n}\\) are constructed from the independent increments \\(B(d)-B(d-2^{-j})\\) and \\(B(d+2^{-j})-B(d)\\) using a disjoint set of variables \\((Z_{t}:t\\in\\mathcal{D}_{n})\\). Hence, they are independent and this implies pairwise independence. This implies the first property. Consequently, the vector of increments \\((B(d)-B(d-2^{-n})\\) for all \\(d\\in\\mathcal{D}_{n}\\) is Gaussian.\nHaving thus chosen the value of the process on all the dyadic points, we interpolate between them. Formally, we define:\n\\[\\begin{aligned}\nF_{0}(t) & =\\begin{cases}\nZ_{1} & \\text{for }t=1\\\\\n0 & \\text{for }t=0\\\\\n\\text{\\text{linear in between}}\n\\end{cases}\n\\end{aligned}\\]\nand for each \\(n\\geq1\\),\n\\[\\begin{aligned}\nF_{n}(t) & =\\begin{cases}\n\\frac{Z_{t}}{2^{(n+1)/2}} & \\text{for }t\\in\\mathcal{D}\\setminus\\mathcal{D}_{n-1}\\\\\n0 & \\text{for }t\\in\\mathcal{D}_{n-1}\\\\\n\\text{\\text{linear between consecutive points in }\\ensuremath{\\mathcal{D}_{n}}}\n\\end{cases}\n\\end{aligned}\\]\nThese functions are continuous on \\([0,1]\\) and for all \\(n\\) and \\(d\\in\\mathcal{D}_{n}\\), we have:\n\\[\\begin{aligned}\nB(d) & =\\sum_{i=0}^{n}F_{i}(d)=\\sum_{i=0}^{\\infty}F_{i}(d)\\label{eq:claim-of-induction-for-bd}\n\\end{aligned}\\]\nTo see this, assume that above equation holds for all \\(d\\in\\mathcal{D}_{n-1}\\).\nLet’s consider the point \\(d\\in\\mathcal{D}_{n}\\setminus\\mathcal{D}_{n-1}\\).\n\\[\\begin{aligned}\nB(d) & =\\frac{B(d-2^{-n})+B(d+2^{-n})}{2}+\\frac{Z_{d}}{2^{(n+1)/2}}\\nonumber \\\\\n& =\\sum_{i=0}^{n-1}\\frac{F_{i}(d-2^{-n})+F_{i}(d+2^{-n})}{2}+\\frac{Z_{d}}{2^{(n+1)/2}}\\label{eq:expression-for-bd}\n\\end{aligned}\\]\nNow, \\(d-2^{-n}\\) and \\(d+2^{-n}\\) belong to \\(\\mathcal{D}_{n-1}\\) and are not in \\(\\bigcup_{i&lt;n-1}\\mathcal{D}_{i}\\). Therefore, for \\(i=0,1,\\ldots,n-2\\), the points \\((d-2^{-n},F_{i}(d-2^{-n}))\\) and \\((d+2^{-n},F_{i}(d+2^{-n})\\) lie on some straight line and have \\((d,F_{i}(d))\\) as their midpoint. Moreover, \\(d-2^{-n}\\) and \\(d+2^{-n}\\) are vertices in \\(\\mathcal{D}_{n-1}\\). So, by definition of \\(F_{n-1}(d)\\), we have \\(F_{n-1}(d)=[F_{n-1}(d-2^{-n})+F_{n-1}(d+2^{-n})]/2\\).\nTo summarize, the first term on the right hand side of expression ([eq:expression-for-bd]) is equal to \\(\\sum_{i=0}^{n-1}F_{i}(d)\\). By mathematical induction, it follows that the claim ([eq:claim-of-induction-for-bd]) is true for all \\(n\\in\\mathbf{N}\\).\nIt’s extremely easy to find an upper bound on the probability contained in the Gaussian tails. Suppose \\(X\\sim N(0,1)\\) and let \\(x&gt;0\\). We are interested in the tail probability \\(\\mathbb{P}(X&gt;x)\\). We have:\n\\[\\begin{aligned}\n\\mathbb{P}(X&gt;x) & =\\int_{x}^{\\infty}e^{-x^{2}/2}dx=\\int_{x}^{\\infty}\\frac{xe^{-x^{2}/2}dx}{x}\n\\end{aligned}\\]\nLet \\(u=\\frac{1}{x}\\) and \\(dv=xe^{-x^{2}/2}dx\\). We have:\n\n\n\n\\(u=\\frac{1}{x}\\)\n\\(dv=xe^{-x^{2}/2}dx\\)\n\n\n\n\n\\(du=-\\frac{1}{x^{2}}dx\\)\n\\(v=-e^{-x^{2}/2}\\)\n\n\n\nThus,\n\\[\\begin{aligned}\n\\mathbb{P}(X&gt;x) & =-\\left.\\frac{1}{x}e^{-x^{2}/2}\\right|_{x}^{\\infty}-\\int_{x}^{\\infty}\\frac{e^{-x^{2}/2}}{x^{2}}dx\\\\\n& =\\frac{e^{-x^{2}/2}}{x}-\\int_{x}^{\\infty}\\frac{e^{-x^{2}/2}}{x^{2}}dx\\\\\n& \\quad\\left\\{ I(x)=\\int_{x}^{\\infty}\\frac{e^{-x^{2}/2}}{x^{2}}\\geq0\\right\\} \\\\\n& \\leq\\frac{e^{-x^{2}/2}}{x}\n\\end{aligned}\\]\nThus, for \\(c&gt;1\\) and large \\(n\\), we have:\n\\[\\begin{aligned}\n\\mathbb{P}(|Z_{d}|\\geq c\\sqrt{n}) & \\leq\\frac{1}{c\\sqrt{n}}e^{-c^{2}n/2}\\leq\\exp\\left(-\\frac{c^{2}n}{2}\\right)\n\\end{aligned}\\]\nSo, the series:\n\\[\\begin{aligned}\n\\sum_{n=0}^{\\infty}\\mathbb{P}\\left\\{ \\text{There exists atleast one }d\\in\\mathcal{D}_{n}\\text{ with }|Z_{d}|\\geq c\\sqrt{n}\\right\\}  & \\leq\\sum_{n=0}^{\\infty}\\sum_{d\\in\\mathcal{D}_{n}}\\mathbb{P}\\left\\{ |Z_{d}|\\geq c\\sqrt{n}\\right\\} \\\\\n& \\leq\\sum_{n=0}^{\\infty}(2^{n}+1)\\exp\\left(-\\frac{c^{2}n}{2}\\right)\n\\end{aligned}\\]\nNow, the series \\((a_{n})\\) given by, \\(a_{n}:=(2^{n}+1)e^{-c^{2}n/2}\\) has the ratio between successive terms:\n\\[\\begin{aligned}\n\\lim\\left|\\frac{a_{n+1}}{a_{n}}\\right| & =\\lim_{n\\to\\infty}\\frac{2^{n+1}+1}{2^{n}+1}\\cdot\\frac{e^{(c^{2}n)/2}}{e^{c^{2}(n+1)/2}}\\\\\n& =\\lim_{n\\to\\infty}\\frac{\\frac{1}{2}+\\frac{1}{2^{n}}}{1+\\frac{1}{2^{n}}}\\cdot\\frac{1}{e^{c^{2}/2}}\\\\\n& =\\frac{1}{2e^{c^{2}/2}}\n\\end{aligned}\\]\nIf this ratio is less than unity, that is \\(c&gt;\\sqrt{2\\log2}\\), than by the ratio test, \\(\\sum(2^{n}+1)e^{-c^{2}n/2}\\) converges to a finite value. Fix such a \\(c\\).\nBy BCL1(Borel-Cantelli Lemma), if \\(A_{n}:=\\left\\{ \\text{There exists atleast one }d\\in\\mathcal{D}_{n}\\text{ with }|Z_{d}|\\geq c\\sqrt{n}\\right\\}\\) and \\(\\sum_{n=0}^{\\infty}\\mathbb{P}(A_{n})\\) converges to a finite value, then the event \\(A_{n}\\) occurs finitely many times with probability \\(1\\). There exists \\(N\\in\\mathbf{N}\\), such that for all \\(n\\geq N\\), \\(A_{n}\\) fails to occur with probability \\(1\\). Thus, for all \\(n\\geq N\\), \\(\\{Z_{d}\\leq c\\sqrt{n}\\}\\) occurs with probability \\(1\\). It follows that:\n\\[\\begin{aligned}\n\\sup_{t\\in[0,1]}F_{n}(t) & \\leq\\frac{c\\sqrt{n}}{2^{(n+1)/2}}\n\\end{aligned}\\]\nDefine\n\\[\\begin{aligned}\nM_{n} & =\\frac{c\\sqrt{n}}{2^{(n+1)/2}}\n\\end{aligned}\\]\nSince \\(\\sum M_{n}\\) converges, by the Weierstrass \\(M\\)-test, the infinite series of functions \\(\\sum_{n=0}^{\\infty}F_{n}(t)\\) converges uniformly on \\([0,1].\\) Since, each \\(F_{n}(t)\\) is piecewise linear and continuous, by the Term-by-Term continuity theorem, \\(\\sum_{n=0}^{\\infty}F_{n}(t)\\) is continuous on \\([0,1]\\). ◻"
  },
  {
    "objectID": "posts/properties-of-brownian-motion/index.html#a-point-of-comparison-the-poisson-process.",
    "href": "posts/properties-of-brownian-motion/index.html#a-point-of-comparison-the-poisson-process.",
    "title": "Properties of Brownian Motion",
    "section": "",
    "text": "Like the Brownian motion, the Poisson process is defined as a process with stationary and independent increments.\n\n A process \\((N_{t},t\\geq0)\\) defined on \\((\\Omega,\\mathcal{F},\\mathbb{P})\\) has the distribution of the Poisson process with rate \\(\\lambda&gt;0\\), if and only if the following hold:\n(1) \\(N_{0}=0\\).\n(2) For any \\(s&lt;t\\), the increment \\(N_{t}-N_{s}\\) is a Poisson random variable with parameter \\(\\lambda(t-s).\\)\n(3) For any \\(n\\in\\mathbf{N}\\) and any choice \\(0&lt;t_{1}&lt;t_{2}&lt;\\ldots&lt;t_{n}&lt;\\infty\\), the increments \\(N_{t_{2}}-N_{t_{1}},N_{t_{3}}-N_{t_{2}},\\ldots,N_{t_{n}}-N_{t_{n-1}}\\) are independent.\n\nPoisson paths can be sampled using this definition. By construction, it is not hard to see that the paths of Poisson processes are piecewise, constant, integer-valued and non-decreasing. In particular, the paths of Poisson processes have finite variation. Poisson paths are much simpler than the ones of Brownian motion in many ways!\n\n(Simulating the Poisson Process.) Use the definition ([def:poisson-process]) to generate \\(10\\) paths of the Poisson process with rate \\(1\\) on the interval \\([0,10]\\) with step-size \\(0.01\\).\n\ndef generatePoissonProcess(lam,T,stepSize):\n    N = int(T/stepSize)\n    x = np.random.poisson(lam=lam,size=N)\n    y = np.cumsum(x)\n    y = np.concatenate([[0.0],y])\n    return y\nWe can construct a Poisson process as follows. Consider \\((\\tau_{j},j\\in\\mathbf{N})\\) IID exponential random variables with parameter \\(1/\\lambda\\). One should think of \\(\\tau_{j}\\) as the waiting time from the \\((j-1)\\)st to the \\(j\\)th jump. Then, one defines :\n\\[\\begin{aligned}\nN_{t} & =\\#\\{k:\\tau_{1}+\\tau_{2}+\\ldots+\\tau_{k}\\leq t\\}\\\\\n& =\\text{Number of jumps upto and including time }t\n\\end{aligned}\\]\nNow, here is an idea! What about defining a new process with stationary and independent increments using a given distribution other than Poisson and Gaussian? Is this even possible? The answer is yes, but only if the distribution satisfies the property of being infinitely divisible. To see this, consider the value of the process at time \\(1\\), \\(N_{1}\\). Then, no matter how many subintervals we chop the interval \\([0,1]\\) into, we must have the increments add up to \\(N_{1}\\). In other words, we must be able to write \\(N_{1}\\) as a sum of \\(n\\) IID random variables for every possible \\(n\\). This is certainly true for Poisson random variables and Gaussian random variables. Another example is the Cauchy distribution. In general, processes that can be constructed using independent, stationary increments are called Levy processes.\n\nTime Inversion. Let \\((B_{t},t\\geq0)\\) be a standard brownian motion. We consider the process:\n\\[\\begin{aligned}\nX_{t} & =tB_{1/t}\\quad\\text{for }t&gt;0\n\\end{aligned}\\]\nThis property relates the behavior of \\(t\\) large to the behavior of \\(t\\) small.\n\n(a) Show that \\((X_{t},t&gt;0)\\) has the distribution of Brownian motion on \\(t&gt;0\\).\nProof.\nLike \\(B(t)\\), it is an easy exercise to prove that \\(X(t)\\) is also a Gaussian process.\nWe have, \\(\\mathbb{E}[X_{s}]=0\\).\nLet \\(s&lt;t\\). We have:\n\\[\\begin{aligned}\nCov(X_{s},X_{t}) & =\\mathbb{E}[sB(1/s)\\cdot tB(1/t)]\\\\\n& =st\\mathbb{E}[B(1/s)\\cdot B(1/t)]\\\\\n& =st\\cdot\\frac{1}{t}\\\\\n& \\quad\\left\\{ \\because\\frac{1}{t}&lt;\\frac{1}{s}\\right\\} \\\\\n& =s\n\\end{aligned}\\]\nConsequently, \\(X(t)\\) has the distribution of a Brownian motion.\n(b) Argue that \\(X(t)\\) converges to \\(0\\) as \\(t\\to0\\) in the sense of \\(L^{2}\\)-convergence. It is possible to show convergence almost surely so that \\((X_{t},t\\geq0)\\) is really a Brownian motion for \\(t\\geq0\\).\nSolution.\nLet \\((t_{n})\\) be any arbitrary sequence of positive real numbers approaching \\(0\\) and consider the sequence of random variables \\((X(t_{n}))_{n=1}^{\\infty}\\). We have:\n\\[\\begin{aligned}\n\\mathbb{E}\\left[X(t_{n})^{2}\\right] & =\\mathbb{E}\\left[t_{n}^{2}B(1/t_{n})^{2}\\right]\\\\\n& =t_{n}^{2}\\mathbb{E}\\left[B(1/t_{n})^{2}\\right]\\\\\n& =t_{n}^{2}\\cdot\\frac{1}{t_{n}}\\\\\n& =t_{n}\n\\end{aligned}\\]\nHence,\n\\[\\begin{aligned}\n\\lim\\mathbb{E}\\left[X(t_{n})^{2}\\right] & =\\lim t_{n}=0\n\\end{aligned}\\]\nSince \\((t_{n})\\) was an arbitrary sequence, it follows that \\(\\lim_{t\\to0}\\mathbb{E}[(X(t))^{2}]=0\\).\n(c) Use this property of Brownian motion to show the law of large numbers for Brownian motion:\n\\[\\begin{aligned}\n\\lim_{t\\to\\infty}\\frac{X(t)}{t} & =0\\quad\\text{almost surely}\n\\end{aligned}\\]\nSolution.\nWhat we need to do is to show that \\(X(t)\\to0\\) as \\(t\\to0\\) almost surely. That would show that \\(\\frac{B(1/t)}{1/t}\\to0\\) as \\(t\\to0\\) almost surely, which is the same as showing \\(\\frac{B(t)}{t}\\to0\\) as \\(t\\to\\infty\\), which is the law of large numbers for Brownian motion.\nWhat we have done in part (b), is to prove the claim that \\(\\mathbb{E}[X(t)^{2}]\\to0\\) as \\(t\\to0\\), which shows convergence in the \\(L^{2}\\) sense and hence convergence in probability. This is infact the weak law of large numbers. \\(\\frac{B(t)}{t}\\stackrel{\\mathbb{\\mathbf{P}}}{\\to}0\\) as \\(t\\to\\infty\\).\nFor \\(t&gt;0\\), continuity is clear. However, it is the proof that as \\(t\\to0\\), \\(X(t)\\to0\\) almost surely which we have not done.\nNote that, the limit \\(X(t)\\to0\\) as \\(t\\to0\\) if and only if \\((\\forall n\\geq1)\\), \\((\\exists m\\geq1)\\), such that \\(\\forall r\\in\\mathbb{Q}\\cap(0,\\frac{1}{m}]\\), we have \\(|X(r)|=\\left|rB\\left(\\frac{1}{r}\\right)\\right|\\leq\\frac{1}{n}\\).\nTo understand the above, we just recall the \\(\\epsilon-\\delta\\) definition of continuity. Note that \\(\\frac{1}{n}\\) plays the role of \\(\\epsilon\\) and \\(\\frac{1}{m}\\) works as \\(\\delta\\).\nThat is,\n\\[\\begin{aligned}\n\\Omega^{X}:=\\left\\{ \\lim_{t\\to0}X(t)=0\\right\\}  & =\\bigcap_{n\\geq1}\\bigcup_{m\\geq1}\\bigcap_{r\\in\\mathbb{Q}\\cap(0,\\frac{1}{m}]}\\left\\{ \\left|X(r)\\right|\\leq\\frac{1}{n}\\right\\}\n\\end{aligned}\\]\nAlso, note that \\(X(t)\\) is continuous on all \\([a,1]\\) for all \\(a&gt;0\\), thus, uniformly continuous on \\([a,1]\\), and hence uniformly continuous on \\(\\mathbb{Q}\\cap(0,1]\\). So, there exists a continuous extension of \\(X(t)\\) on \\([0,1]\\). We already know from part (a), that \\((X(t))_{t&gt;0}\\) and \\((B(t))_{t&gt;0}\\) have the same finite dimensional distributions. Therefore, the RHS event has the same probability as \\(\\Omega^{B}:=\\bigcap_{n\\geq1}\\bigcup_{m\\geq1}\\bigcap_{r\\in\\mathbb{Q}\\cap(0,\\frac{1}{m}]}\\left\\{ \\left|B(r)\\right|\\leq\\frac{1}{n}\\right\\}\\). Since \\(B(t)\\to0\\) as \\(t\\to0\\) almost surely, the event \\(\\Omega^{B}\\) has probability \\(1\\). Thus, \\(\\mathbb{P}\\left\\{ \\lim_{t\\to0}X(t)=0\\right\\} =1\\).\nThis actually shows that \\(X(t)\\) is a bonafide standard brownian motion, as we have established continuity as well."
  },
  {
    "objectID": "posts/singular-value-decomposition/index.html",
    "href": "posts/singular-value-decomposition/index.html",
    "title": "Singular Value Decomposition(SVD)",
    "section": "",
    "text": "Rectangular matrices do not have eigenvalues. However, we might look at the eigenvalues of the symmetric, positive semidefinite square Gram matrix \\(K=AA^T\\). Perhaps the eigenvalues of \\(K\\) might form an important role for general matrices. They were first studied by the German mathematician Erhard Schmidt in early days of the 20th century.\nSince \\(K=AA^T\\) is necessarily positive semi-definite, its eigenvalues are necessarily non-negative, \\(\\lambda_i \\geq 0\\), which justifies the positivity of the singular values of \\(A\\) - independently of whether \\(A\\) itself has positive, negative or even complex eigenvalues, or is rectangular and has no eigenvalues at all. I will follow the standard convention, and always label the singular values in decreasing order, so that \\(\\sigma_1 \\geq \\sigma_2 \\geq \\ldots \\geq \\sigma_r\\).\nIn the special case of symmetric matrices, there is a direct connection between their singular values and their (necessarily real) eigenvalues.\nProof.\nWhen \\(A\\) is symmetric, \\(K=A^T A = A^2\\). So, if\n\\[\nA \\mathbf{v} = \\lambda \\mathbf{v}\n\\]\nthen\n\\[\nK \\mathbf{v} = A^2 \\mathbf{v} = A(A \\mathbf{v}) = A(\\lambda \\mathbf{v}) = \\lambda A \\mathbf{v} = \\lambda^2 \\mathbf{v}\n\\]\nThus, every eigenvector \\(\\mathbf{v}\\) of \\(A\\) is also an eigenvector of \\(K\\) with eigenvalue \\(\\lambda^2\\). So, the eigenvector basis of \\(A\\) is also an eigenvector basis for \\(K\\), and forms a complete system of singular vectors for \\(A\\). \\(\\blacksquare\\)"
  },
  {
    "objectID": "posts/singular-value-decomposition/index.html#svd-factorization",
    "href": "posts/singular-value-decomposition/index.html#svd-factorization",
    "title": "Singular Value Decomposition(SVD)",
    "section": "SVD Factorization",
    "text": "SVD Factorization\nThe generalization of the spectral theorem to non-symmetric matrices is known as the singular value decomposition, commonly abbreviated SVD. Unlike the former, which applies to only symmetric matrices, every nonzero matrix possesses a SVD factorization.\n\nTheorem 1 (SVD Factorization) Every non-zero real \\(m \\times n\\) matrix \\(A\\) of rank \\(r &gt; 0\\) can be factored:\n\\[ A = U \\Sigma V^T \\]\ninto the product of an \\(m \\times r\\) matrix \\(U\\), the \\(r \\times r\\) diagonal matrix \\(\\Sigma = diag(\\sigma_1,\\ldots,\\sigma_r)\\) and an \\(r \\times n\\) matrix \\(V^T\\), such that \\(U\\) and \\(V\\) are orthonormal matrices.\n\nProof.\nLet’s begin by writing the desired factorization as \\(AQ = P \\Sigma\\). The individual columns"
  },
  {
    "objectID": "posts/template-programming/index.html",
    "href": "posts/template-programming/index.html",
    "title": "Template programming",
    "section": "",
    "text": "C++11 introduced variadic templates which permit functions to accept a variable number of arguments. They also permit template types such as std::tuple that can hold a variable number of elements. The main language mechanism enabling variadic templates is parameter packs, which hold an arbitrary number of values or types. Some things are easier to do with parameter packs - for instance passing the values they comprise to a function. Other tasks are a bit trickier to accomplish, such as iterating over a parameter pack or extracting specific elements. However, these things can generally be accomplished through various idioms, some more unwieldy then others.\nBetween C++11 and C++20, the language gained several improvements to variadic templates. Improvements to other features, such as concepts and lambdas, have also created new options for manipulating parameter packs in C++20. Ideally, cataloging these tricks make it easier for people to do what they need with variadic templates."
  },
  {
    "objectID": "posts/template-programming/index.html#an-overview-of-variadic-templates",
    "href": "posts/template-programming/index.html#an-overview-of-variadic-templates",
    "title": "Template programming",
    "section": "An overview of variadic templates",
    "text": "An overview of variadic templates\nA template parameter pack is a template parameter that accepts zero or more template arguments. A function parameter pack is a function parameter that accepts zero or more function arguments. A variadic template is template that captures a parameter pack in its template arguments or function arguments. A parameter pack is captured by introducing an identifier prefixed by an ellipsis, as in ...X. Once captured, a parameter pack can later be used in a pattern expanded by an ellipsis (...), generally to the right of the pattern, as in X.... Pack expansion is conceptually equivalent to having one copy of the pattern for each element of the parameter pack.\n#include &lt;iostream&gt;\n\ntemplate &lt;typename T&gt;\nT sum(T x){\n    return x;\n}\n\ntemplate &lt;typename T, typename... Args&gt;\nT sum(T x, Args... args){\n    return x + sum&lt;Args...&gt;(args...);\n}\n\nint main()\n{   \n    double result = sum(1.0, 2.0, 3.0, 4.0, 5.0);\n    std::cout &lt;&lt; \"result = \" &lt;&lt;  result;\n    return 0;\n}\nCompiler Explorer\nThe sum() function takes one or more arguments. The first argument is always captured by the parameter x and the rest of the arguments are captured by the pack ...args on line 9."
  },
  {
    "objectID": "posts/template-programming/index.html#expanding-parameter-packs",
    "href": "posts/template-programming/index.html#expanding-parameter-packs",
    "title": "Template programming",
    "section": "Expanding parameter packs",
    "text": "Expanding parameter packs\nWhen using a variadic template, we often use a recursive logic with two overloads : one for the general case and one for ending the recursion. For instance:\n#include &lt;iostream&gt;\n\ntemplate &lt;typename T&gt;\nT min(T a, T b)\n{\n    return a &lt; b ? a : b;\n}\n\ntemplate &lt;typename T, typename... Args&gt;\nT min(T first, Args... rest){\n    return min(first, min(rest...));\n}\n\nint main()\n{\n    int a = 2, b = 3, c = 4, d = 5;\n    int minValue {0};\n    minValue = min(a, b);\n    minValue = min(a, b, c);\n    minValue = min(a, b, c, d);\n    return 0;\n}\nCompiler Explorer\nThe below code snip is a minimalistic example of tuple. The first class is the primary template. The primary template tuple has two member variables : first of type Type and rest of type Types... . This means that a template of N elements will contain the first element, and another tuple; this second tuple in turn contains the second element and yet another tuple; so on and so forth.\nA captured parameter pack must be used in a pattern that is expanded with an ellipsis (...). A pattern is a set of tokens containing the identifiers of one or more parameter packs. On line 11, we capture a parameter pack rest consisting of a sequence of values rest[i] each of type Types[i] for the i-th position in parameter pack Types. On line 13, we expand the pattern rest.\n// Variadic class templates and parameter pack expansion\n#include &lt;functional&gt;\n#include &lt;utility&gt;\n#include &lt;iostream&gt;\n\ntemplate &lt;typename Type, typename... Types&gt;\nstruct tuple{\n    Type first_;\n    tuple&lt;Types...&gt; rest_;\n\n    tuple(Type first, Types... rest) \n        : first_(first)\n        , rest_(rest...)\n        {}\n};\n\ntemplate &lt;typename T&gt;\nstruct tuple&lt;T&gt;{\n    T first_;\n\n    tuple(T first) : first_(first) {}\n};\n\nint main()\n{   \n    tuple&lt;double, double, double&gt; x1(3.0, 4.0, 5.0);\n    return 0;\n}\nCompiler Explorer\nWhen a pattern contains more than one parameter pack, all packs must have the same length. This length determines the number of times the pattern is conceptually replicated in the expansion, once for each position in the expanded pack(s). Consider the following code snippet:\n// An example with two parameter packs\n#include &lt;iostream&gt;\n#include &lt;type_traits&gt;\n#include &lt;tuple&gt;\n\ntemplate &lt;std::same_as&lt;char&gt;... C&gt;\nvoid expand(C... c)\n{\n    std::tuple&lt;C...&gt; tpl(c...);\n\n    const char msg[] = { C(std::toupper(c))..., '\\0' };\n    //Do something\n}\nint main()\n{   \n    expand('t','e','m','p','l','a','t','e','s');\n    return 0;\n}\nOn line 7, tuple&lt;C...&gt; expands the pack C in the template-argument list, while tpl(c...) expands c in an initializer list (which, not to be confused with std::initializer_list is the C++ grammar for comma-separated lists of expressions passed as arguments to function calls and constructors).\nOn line 9, we expand the pattern C(std::toupper(c)) in another initializer list. This is an example of a pattern with two packs, C and c, both of which have the same length and are expanded in lockstep. (std::toupper() returns an int rather than a char so requires a cast).\n\nsizeof...(pack)\nThe number of arguments in a parameter pack can be retrieved at compile-time with the sizeof... operator. This operator returns a constexpr value of the std::size_t type. Let’s see this in action:\n#include &lt;iostream&gt;\n#include &lt;array&gt;\ntemplate &lt;typename... Args&gt;\nconstexpr auto get_type_sizes(Args... args){\n    return std::array&lt;std::size_t, sizeof...(Args)&gt;{sizeof(args)...};\n}\n\nint main()\n{\n    auto sizes = get_type_sizes&lt;char, int, long, double&gt;('a', 2, 3L, 3.14);\n    return 0;\n}\nCompiler Explorer\nIn this snippet, sizeof...(Args) evaluates to \\(4\\) at compile-time, while sizeof(args)... is expanded to the following comma-separated pack of arguments: sizeof(char), sizeof(int), sizeof(long) and sizeof(double).\nIn most cases, an expanded pattern is conceptually equivalent to the number of copies of the pattern equal to the size of the parameter pack. Unless otherwise noted, a pattern is expanded by appending an ellipsis (...). Here is a list of contexts in which a pattern can be expanded:\n\nInside template parameters and function parameters, a pack expansion behaves like a comma separated list of patterns. An example in template parameters is the expansion of T in inner here:\n\ntemplate &lt;typename... T&gt;\nstruct outer{\n    template &lt;T... args&gt;\n    struct inner{};\n};\n\nouter&lt;int, double, char[5]&gt; a{};\nAn example in function parameters is the expansion of Args..., when you call foo:\ntemplate &lt;typename... Args&gt;\nvoid foo(Args... args){}\n\nfoo(42);\nfoo(42, 'a');\n\nIn template argument lists as in std::tuple&lt;C...&gt;, the pack expands to the equivalent of a comma separated list of template arguments.\nIn function argument lists when a captured parameter pack appears inside the parenthesis of a function call. The largest expression to the left of the ellipsis (...) is the pattern that is expanded.\n\ntemplate&lt;typename T&gt;\nT step_it(T value){\n    return value + 1;\n}\nT sum(T x){\n    return x;\n}\n\nT sum(T first, T... args){\n    return (first + sum(args...));\n}\n\ntemplate &lt;typename... T&gt;\nvoid do_sums(T... args)\n{\n    auto s1 = sum(args...); \n    // sum(1, 2, 3, 4)\n\n    auto s2 = sum(42, args...);\n    // sum(42, 1, 2, 3, 4)\n\n    auto s3 = sum(step_it(args)...);\n    // sum(2, 3, 4, 5)\n}\n\ndo_sums(1, 2, 3, 4);\n\nIn base specifier lists, to specify one base class for each member of a type parameter pack e.g.:\n\ntemplate &lt;typename Base...&gt;\nstruct MyStruct : Base...{\n    MyStruct();\n};\n\nWhen initializing base classes in a mem-initializer list in a class constructor, the pack expansion initializes a list of base classes based on a type parameter pack:\n\ntemplate&lt;typename... Base&gt;\nstruct MyStruct: Base...{\n    /* Default c'ctor */\n    MyStruct() : Base...() {}\n\n    MyStruct(const Base&... args) : Base{args}... {}\n};\n\nIn initializer lists, the pack exmpansion is conceptually equivlent to a comma-separated list of instances of the pattern.\n\n#include &lt;iostream&gt;\n#include &lt;array&gt;\n\ntemplate&lt;typename... Args&gt;\nstruct sum_wrapper{\n    sum_wrapper(Args... args){\n        result = (... + args);\n    }\n    std::common_type_t&lt;Args...&gt; result;\n};\n\ntemplate&lt;typename... T&gt;\nvoid parenthesized(T... args){\n    std::array&lt;std::common_type_t&lt;T...&gt;,sizeof...(T)&gt; arr {args...};\n    //std::array&lt;int, 4&gt; {1, 2, 3, 4}\n\n    sum_wrapper sw1(args...);\n    //value = 1 + 2 + 3 + 4\n\n    sum_wrapper sw2(++args...);\n    //value = 2 + 3 + 4 + 5\n}\n\nint main()\n{\n    parenthesized(1, 2, 3, 4);\n    return 0;\n}\nCompiler Explorer\n\nIn the context of deriving from a pack of base classes, it is useful to introduce names from the base classes into the definition of the derived class. Therefore, a pack expansion may also appear in a using declaration.\n\n#include &lt;iostream&gt;\n#include &lt;array&gt;\n\nstruct A{\n    void execute() { std::cout &lt;&lt; \"A::execute()\\n\"; }\n};\n\nstruct B{\n    void execute() { std::cout &lt;&lt; \"B::execute()\\n\"; }\n};\n\nstruct C{\n    void execute() { std::cout &lt;&lt; \"C::execute()\\n\"; }\n};\n\ntemplate&lt;typename... Bases&gt;\nstruct X : public Bases...\n{\n    X(Bases const& ... args) : Bases(args)... {}\n    using Bases::execute...;\n    // Conceptually equivalent to\n    // using A::f;\n    // using B::f;\n    // using C::f;\n};\n\nint main()\n{\n    A a; B b; C c; X x(a, b, c);\n    x.A::execute();\n    x.B::execute();\n    x.C::execute();\n\n    \n    return 0;\n}\nCompiler Explorer\n\nLambda Captures - The capture clause of a lambda expression may contain a pack expansion.\n\n#include &lt;iostream&gt;\n\ntemplate&lt;typename... Args&gt;\nstd::common_type_t&lt;Args...&gt; add(Args... args){\n    return (... + args);\n}\n\ntemplate&lt;typename... T&gt;\nvoid captures(T... args){\n    auto l = [args...]{\n        return add(args...);\n    };\n\n    l();\n}\n\nint main()\n{\n    captures(1, 2, 3, 4);\n    return 0;\n}\n\nFold expressions - These are similar to left fold and right fold in functional programming.\n\ntemplate&lt;typename... T&gt;\nint sum(T... args){\n    return (args + ...);\n}\nA pattern may itself contain an expanded parameter pack, in which case there is no need for the inner and outer packs to contain the same number of elements. The expanded inner pack simply becomes a part of the pattern around the outer pack. For example:\n#include &lt;iostream&gt;\n\ntemplate&lt;typename... Args&gt;\nstd::common_type_t&lt;Args...&gt; sum(Args... il){\n    return (... + il);\n}\n\ntemplate&lt;int... N&gt;\nstruct Nested_sum{\n\n    template&lt;typename... Args&gt;\n    int nested_sum(Args... args){\n        return sum(sum(N...,args)...);\n    }\n};\nint main()\n{\n    Nested_sum&lt;1,2&gt; ns{};\n    int result = ns.nested_sum(100, 200);\n    // Equivalent to : sum(sum(1, 2, 100), sum(1, 2, 200))\n    return 0;\n}\nCompiler Explorer"
  },
  {
    "objectID": "posts/template-programming/index.html#implementing-getn-for-the-tuple",
    "href": "posts/template-programming/index.html#implementing-getn-for-the-tuple",
    "title": "Template programming",
    "section": "Implementing get<N> for the tuple",
    "text": "Implementing get&lt;N&gt; for the tuple\nWe can implement get&lt;N&gt; that takes a tuple as an argument and returns a reference to the element at the index n. Its prototype could look like the following:\ntemplate &lt;int n, typename... Ts&gt;\ntypename nth_type&lt;n, Ts...&gt;::value_type& get(tuple&lt;Ts...&gt;& t);\nThe template arguments are the index and a parameter pack of the tuple types. Its implementation, however, requires some helper types. First, we need to know what the type of the element is at the n-th index. This can be done with the help of the following nth_type variadic class template:\ntemplate&lt;int n, typename T, typename... Ts&gt;\nstruct nth_type : nth_type&lt;n-1,Ts...&gt;{\n};\n\ntemplate&lt;typename T, typename... Ts&gt;\nstruct nth_type&lt;0,T,Ts...&gt;{\n    using value_type = T;\n};\nAgain, we have a primary template that uses recursive inheritance, and the specialization for the index 0 (which is the head of the list of templates). This type is only used as a mechanism for determining the type of a tuple element. We need another variadic class template for retrieving the value.\ntemplate&lt;int n&gt;\nstruct getter{\n    template&lt;typename... Ts&gt;\n    static typename nth_type&lt;n, Ts...&gt;::value_type&\n    get(tuple&lt;Ts...&gt;& t){\n        return getter&lt;n-1&gt;::get(t.rest_);\n    }\n};\n\ntemplate&lt;&gt;\nstruct getter&lt;0&gt;{\n    template&lt;typename T, typename... Ts&gt;\n    static T& get(tuple&lt;T, Ts...&gt;& t){\n        return t.first_;\n    }\n};\nWith all these defined, we can now provide an implementation for the helper variadic function template get. This implementation relies on the getter class template and calls the get variadic function template.\ntemplate&lt;int n, typename... Ts&gt;\ntypename nth_type&lt;n, Ts...&gt;::value_type &\nget(tuple&lt;Ts...&gt;& t){\n    return getter&lt;n&gt;::get(t);\n}\nCompiler Explorer\nAnalysing the example above in cppinsights.io will be very illuminating. Here’s the listing:\n/*************************************************************************************\n * NOTE: This an educational hand-rolled transformation. Things can be incorrect or  *\n * buggy.                                                                            *\n *************************************************************************************/\n#include &lt;iostream&gt;\n\ntemplate&lt;typename T, typename ... Ts&gt;\nstruct tuple\n{\n  T first_;\n  tuple&lt;Ts...&gt; rest_;\n  inline tuple(T first, Ts... rest)\n  : first_{first}\n  , rest_{tuple&lt;Ts...&gt;(rest... )}\n  {\n  }\n  \n};\n\n/* First instantiated from: insights.cpp:6 */\n#ifdef INSIGHTS_USE_TEMPLATE\ntemplate&lt;&gt;\nstruct tuple&lt;int, double&gt;\n{\n  int first_;\n  tuple&lt;double&gt; rest_;\n  inline tuple(int first, double __rest1)\n  : first_{first}\n  , rest_{tuple&lt;double&gt;(__rest1)}\n  {\n  }\n  \n};\n\n#endif\n/* First instantiated from: insights.cpp:6 */\n#ifdef INSIGHTS_USE_TEMPLATE\ntemplate&lt;&gt;\nstruct tuple&lt;double&gt;\n{\n  double first_;\n  inline tuple(double first)\n  : first_{first}\n  {\n  }\n  \n};\n\n#endif\n/* First instantiated from: insights.cpp:53 */\n#ifdef INSIGHTS_USE_TEMPLATE\ntemplate&lt;&gt;\nstruct tuple&lt;char, int, double&gt;\n{\n  char first_;\n  tuple&lt;int, double&gt; rest_;\n  inline tuple(char first, int __rest1, double __rest2)\n  : first_{first}\n  , rest_{tuple&lt;int, double&gt;(__rest1, __rest2)}\n  {\n  }\n  \n};\n\n#endif\n\ntemplate&lt;typename T&gt;\nstruct tuple&lt;T&gt;\n{\n  T first_;\n  inline tuple(T first)\n  : first_(first)\n  {\n  }\n  \n};\nThe tuple&lt;char, int, double&gt; contains an int and a tuple&lt;int, double&gt;, which contains a int and tuple&lt;double&gt;, which in turn contains a double value.\nNext, we have the nth_type class template, for which, again, we have a primary template and several specializations, as follows:\n\ntemplate&lt;int n, typename T, typename ... Ts&gt;\nstruct nth_type : public nth_type&lt;n - 1, Ts...&gt;\n{\n};\n\n/* First instantiated from: insights.cpp:19 */\n#ifdef INSIGHTS_USE_TEMPLATE\ntemplate&lt;&gt;\nstruct nth_type&lt;1, int, double&gt; : public nth_type&lt;0, double&gt;\n{\n};\n\n#endif\n/* First instantiated from: insights.cpp:19 */\n#ifdef INSIGHTS_USE_TEMPLATE\ntemplate&lt;&gt;\nstruct nth_type&lt;0, double&gt;\n{\n  using value_type = double;\n};\n\n#endif\n/* First instantiated from: insights.cpp:45 */\n#ifdef INSIGHTS_USE_TEMPLATE\ntemplate&lt;&gt;\nstruct nth_type&lt;2, char, int, double&gt; : public nth_type&lt;1, int, double&gt;\n{\n};\n\n#endif\n\ntemplate&lt;typename T, typename ... Ts&gt;\nstruct nth_type&lt;0, T, Ts...&gt;\n{\n  using value_type = T;\n};\nThe nth_type&lt;2, char, int, double&gt; specialization is derived from nth_type&lt;1, int, double&gt; which in turn is derived from nth_type&lt;0, double&gt;, which is the last class in the base hierarchy.\nThe nth_type structure is used as the return type in the getter helper class template, which is instantiated as follows:\n/* First instantiated from: insights.cpp:32 */\n#ifdef INSIGHTS_USE_TEMPLATE\ntemplate&lt;&gt;\nstruct getter&lt;1&gt;\n{\n  template&lt;typename ... Ts&gt;\n  static inline typename nth_type&lt;1, Ts...&gt;::value_type & get(tuple&lt;Ts...&gt; & t);\n  \n  /* First instantiated from: insights.cpp:32 */\n  #ifdef INSIGHTS_USE_TEMPLATE\n  template&lt;&gt;\n  static inline typename nth_type&lt;1, int, double&gt;::value_type & get&lt;int, double&gt;(tuple&lt;int, double&gt; & t)\n  {\n    return getter&lt;0&gt;::get(t.rest_);\n  }\n  #endif\n  \n};\n\n#endif\n/* First instantiated from: insights.cpp:47 */\n#ifdef INSIGHTS_USE_TEMPLATE\ntemplate&lt;&gt;\nstruct getter&lt;2&gt;\n{\n  template&lt;typename ... Ts&gt;\n  static inline typename nth_type&lt;2, Ts...&gt;::value_type & get(tuple&lt;Ts...&gt; & t);\n  \n  /* First instantiated from: insights.cpp:47 */\n  #ifdef INSIGHTS_USE_TEMPLATE\n  template&lt;&gt;\n  static inline typename nth_type&lt;2, char, int, double&gt;::value_type & get&lt;char, int, double&gt;(tuple&lt;char, int, double&gt; & t)\n  {\n    return getter&lt;1&gt;::get(t.rest_);\n  }\n  #endif\n  \n};\n\n#endif\n\ntemplate&lt;&gt;\nstruct getter&lt;0&gt;\n{\n  template&lt;typename T, typename ... Ts&gt;\n  static inline T & get(tuple&lt;T, Ts...&gt; & t)\n  {\n    return t.first_;\n  }\n  \n  /* First instantiated from: insights.cpp:32 */\n  #ifdef INSIGHTS_USE_TEMPLATE\n  template&lt;&gt;\n  static inline double & get&lt;double&gt;(tuple&lt;double&gt; & t)\n  {\n    return t.first_;\n  }\n  #endif\n  \n};\nWe see the use of the keyword typename to prefix the nth_type&lt;N, Ts...&gt;::value_type which is a dependent type. In C++ 20, this is however no longer necessary.\nBecause implementing variadic templates is often verbose and can be cumbersome, the C++17 added fold expressions."
  },
  {
    "objectID": "posts/template-programming/index.html#fold-expressions",
    "href": "posts/template-programming/index.html#fold-expressions",
    "title": "Template programming",
    "section": "Fold Expressions",
    "text": "Fold Expressions\nA special form of pack expansions is folds introduced in C++17. Above, we showed a function sum that summed a set of integers. This function can be implemented far more concisely with a fold:\nint sum(auto... i){\n    return (... + i);\n}\nLet \\(p_1,\\ldots,p_n\\) be the instances of the parameter pack \\(p\\). Let \\(\\bigoplus\\) stand for any binary operator in the C++ grammar.\nA binary left fold has the form \\((e \\bigoplus \\ldots \\bigoplus p)\\) and is equivalent to \\((((e \\bigoplus p_1) \\bigoplus p_2)\\ldots ) \\bigoplus p_n\\).\nA unary left fold has the form \\((\\ldots \\bigoplus p)\\) and is equivalent to \\((((p_1 \\bigoplus p_2)\\bigoplus p_3) \\ldots )\\bigoplus p_n\\).\nA binary right fold has the form \\((p \\bigoplus \\ldots \\bigoplus e)\\) and is equivalent to \\(p_1 \\bigoplus (\\ldots (p_{n-1} \\bigoplus (p_n \\bigoplus e)))\\).\nA binary right fold has the form \\((p \\bigoplus \\ldots \\bigoplus p_n)\\) and is equivalent to \\(p_1 \\bigoplus (p_2 \\bigoplus (\\ldots \\bigoplus p_n))\\).\nIn the above expressions, \\(e\\) stands for the initial value."
  },
  {
    "objectID": "posts/template-programming/index.html#idioms",
    "href": "posts/template-programming/index.html#idioms",
    "title": "Template programming",
    "section": "Idioms",
    "text": "Idioms\nBelow is a collection of idioms for working with parameter packs."
  },
  {
    "objectID": "posts/thread-safe-queues/index.html",
    "href": "posts/thread-safe-queues/index.html",
    "title": "A thread-safe queue implementation",
    "section": "",
    "text": "In the producer-consumer problem, we have two classes of threads, producers and consumers and a buffer containing a fixed number of slots. A producer thread attempts to put something into the next empty buffer slot, a consumer thread attempts to take something out of the next occupied buffer slot. The synchronization conditions are that producers cannot proceed unless there are empty slots and consumers cannot proceed unless there are occupied slots. The problem occurs because of the different rates at which producers deposit and consumers exhaust data.\nThis is a classic, but frequently occurring synchronization problem. For example, the heart of the implementation of UNIX pipes is an instance of this problem."
  },
  {
    "objectID": "posts/thread-safe-queues/index.html#producer-consumer-problem",
    "href": "posts/thread-safe-queues/index.html#producer-consumer-problem",
    "title": "A thread-safe queue implementation",
    "section": "",
    "text": "In the producer-consumer problem, we have two classes of threads, producers and consumers and a buffer containing a fixed number of slots. A producer thread attempts to put something into the next empty buffer slot, a consumer thread attempts to take something out of the next occupied buffer slot. The synchronization conditions are that producers cannot proceed unless there are empty slots and consumers cannot proceed unless there are occupied slots. The problem occurs because of the different rates at which producers deposit and consumers exhaust data.\nThis is a classic, but frequently occurring synchronization problem. For example, the heart of the implementation of UNIX pipes is an instance of this problem."
  },
  {
    "objectID": "posts/thread-safe-queues/index.html#ring-buffer",
    "href": "posts/thread-safe-queues/index.html#ring-buffer",
    "title": "A thread-safe queue implementation",
    "section": "Ring buffer",
    "text": "Ring buffer\nConsider a single, fixed-size buffer as if it were connected end-to-end, such that the oldest entry is processed first. This is a circular FIFO queue.\nWhat do we use SPSC FIFO queues for? In the industry, you often have a pipeline of processes. For example, you have one thread reading from sockets, another thread that handles the messages from the sockets and maybe processes them and produces a result and a third thread writes a response to the network. Those can be connected by SPSC FIFO queues. There’s a couple of advantages to this. All these advantages and disadvantages are subject to measurement, so always measure. It may improve the throughput over just a single thread doing all \\(3\\) of these operations, in fact, I’ll be surprised if it didn’t. It also should improve the resiliency of the application to spikes in message traffic. Some of the disadvantages are that you have to manage 3 threads and it probably uses more memory, because each of the FIFO queues needs place to store its messages."
  },
  {
    "objectID": "posts/thread-safe-queues/index.html#basic-functionalities-to-expect-from-a-thread-safe-queue",
    "href": "posts/thread-safe-queues/index.html#basic-functionalities-to-expect-from-a-thread-safe-queue",
    "title": "A thread-safe queue implementation",
    "section": "Basic functionalities to expect from a thread-safe queue",
    "text": "Basic functionalities to expect from a thread-safe queue\n#include &lt;gtest/gtest.h&gt;\n#include &lt;thread&gt;\n#include &lt;vector&gt;\n#include \"threadsafe_queue.h\"\n\n// Test default constructor\nTEST(ThreadSafeQueueTest, DefaultConstructorTest) {\n    dev::threadsafe_queue&lt;int&gt; queue;\n    EXPECT_EQ(queue.empty(), true);\n    EXPECT_EQ(queue.size(), 0);\n}\n\n// Test push and front\nTEST(ThreadSafeQueueTest, PushAndFrontTest) {\n    dev::threadsafe_queue&lt;int&gt; queue;\n    queue.push(42);\n    EXPECT_EQ(queue.front(), 42);\n    EXPECT_EQ(queue.size(), 1);\n    EXPECT_EQ(queue.empty(), false);\n}\n\n// Test push and back\nTEST(ThreadSafeQueueTest, PushAndBackTest) {\n    dev::threadsafe_queue&lt;int&gt; queue;\n    queue.push(10);\n    queue.push(20);\n    EXPECT_EQ(queue.back(), 20);\n    EXPECT_EQ(queue.size(), 2);\n}\n\n// Test try_pop (non-blocking)\nTEST(ThreadSafeQueueTest, TryPopTest) {\n    dev::threadsafe_queue&lt;int&gt; queue;\n    queue.push(42);\n    auto item = queue.try_pop();\n    EXPECT_TRUE(item.has_value());\n    EXPECT_EQ(item.value(), 42);\n    EXPECT_EQ(queue.empty(), true);\n}\n\n// Test pop (blocking)\nTEST(ThreadSafeQueueTest, BlockingPopTest) {\n    dev::threadsafe_queue&lt;int&gt; queue;\n\n    std::thread producer([&queue]() {\n        std::this_thread::sleep_for(std::chrono::milliseconds(100));\n        queue.push(42);\n    });\n\n    auto item = queue.pop();\n    EXPECT_EQ(item, 42);\n    EXPECT_EQ(queue.empty(), true);\n\n    producer.join();\n}\n\n// Test emplace\nTEST(ThreadSafeQueueTest, EmplaceTest) {\n    struct Point {\n        int x, y;\n        Point(int a, int b) : x(a), y(b) {}\n    };\n\n    dev::threadsafe_queue&lt;Point&gt; queue;\n    queue.emplace(1, 2);\n    EXPECT_EQ(queue.front().x, 1);\n    EXPECT_EQ(queue.front().y, 2);\n}\n\n// Test thread safety with multiple producers and consumers\nTEST(ThreadSafeQueueTest, MultiThreadedTest) {\n    dev::threadsafe_queue&lt;int&gt; queue;\n    const int num_items = 100;\n\n    std::thread producer1([&queue]() {\n        for (int i = 0; i &lt; num_items; ++i) {\n            queue.push(i);\n        }\n    });\n\n    std::thread producer2([&queue]() {\n        for (int i = num_items; i &lt; 2 * num_items; ++i) {\n            queue.push(i);\n        }\n    });\n\n    std::vector&lt;int&gt; consumed_items;\n    std::mutex mtx;\n    std::thread consumer1([&queue, &consumed_items, &mtx]() {\n        for (int i = 0; i &lt; num_items; ++i) {\n            {\n                std::unique_lock&lt;std::mutex&gt; unique_lck(mtx);\n                consumed_items.push_back(queue.pop());\n            }\n        }\n    });\n\n    std::thread consumer2([&queue, &consumed_items, &mtx]() {\n        for (int i = 0; i &lt; num_items; ++i) {\n            {\n                std::unique_lock&lt;std::mutex&gt; unique_lck(mtx);\n                consumed_items.push_back(queue.pop());\n            }\n        }\n    });\n\n    producer1.join();\n    producer2.join();\n    consumer1.join();\n    consumer2.join();\n\n    EXPECT_EQ(consumed_items.size(), 2 * num_items);\n    EXPECT_EQ(queue.empty(), true);\n}\n\n// Test empty queue behavior\nTEST(ThreadSafeQueueTest, EmptyQueueTest) {\n    dev::threadsafe_queue&lt;int&gt; queue;\n    EXPECT_EQ(queue.empty(), true);\n    EXPECT_EQ(queue.size(), 0);\n\n    auto item = queue.try_pop();\n    EXPECT_FALSE(item.has_value());\n}\n\n// Test copy constructor\nTEST(ThreadSafeQueueTest, CopyConstructorTest) {\n    dev::threadsafe_queue&lt;int&gt; queue1;\n    queue1.push(42);\n    queue1.push(17);\n\n    dev::threadsafe_queue&lt;int&gt; queue2(queue1);\n    EXPECT_EQ(queue2.size(), 2);\n    EXPECT_EQ(queue2.front(), 42);\n    EXPECT_EQ(queue2.back(), 17);\n}\n\n// Test size\nTEST(ThreadSafeQueueTest, SizeTest) {\n    dev::threadsafe_queue&lt;int&gt; queue;\n    queue.push(1);\n    queue.push(2);\n    queue.push(3);\n    EXPECT_EQ(queue.size(), 3);\n}"
  },
  {
    "objectID": "posts/thread-safe-queues/index.html#basic-threadsafe_queue-implementation",
    "href": "posts/thread-safe-queues/index.html#basic-threadsafe_queue-implementation",
    "title": "A thread-safe queue implementation",
    "section": "Basic threadsafe_queue implementation",
    "text": "Basic threadsafe_queue implementation\n// Ref: Asynchronous Programming with C++\n// Javier Reguara Salgado, Juan Antonio Rufes\n#include &lt;iostream&gt;\n#include &lt;shared_mutex&gt;\n#include &lt;queue&gt;\n#include &lt;condition_variable&gt;\n#include &lt;optional&gt;\n#include &lt;type_traits&gt;\n\nnamespace dev{\n    template&lt;typename T&gt;\n    class threadsafe_queue{\n        private:\n        std::queue&lt;T&gt; m_queue;\n        mutable std::mutex m_mutex;\n        std::condition_variable not_empty_;\n\n        public:\n        using value_type = T;\n        using reference = T&;\n        using const_reference = const T&;\n\n        threadsafe_queue() = default;\n\n        threadsafe_queue(const threadsafe_queue& other){\n            std::unique_lock&lt;std::mutex&gt; unique_lck(other.m_mutex);\n            m_queue = other.m_queue;\n        }\n\n        threadsafe_queue& operator=(const threadsafe_queue&) = delete;\n        \n        value_type front(){\n            std::unique_lock&lt;std::mutex&gt; unique_lck(m_mutex);\n            return m_queue.front();\n        }\n\n        value_type back(){\n            std::unique_lock&lt;std::mutex&gt; unique_lck(m_mutex);\n            return m_queue.back();\n        }\n\n        bool empty(){\n            std::unique_lock&lt;std::mutex&gt; unique_lck(m_mutex);\n            return m_queue.empty();\n        }\n\n        std::size_t size(){\n            std::unique_lock&lt;std::mutex&gt; unique_lck(m_mutex);\n            return m_queue.size();\n        }\n\n        // non-blocking\n        bool try_push(const_reference item){\n            std::unique_lock&lt;std::mutex&gt; unique_lck(m_mutex, std::try_to_lock);\n            if(!unique_lck)\n                return false;\n\n            if constexpr(std::is_nothrow_move_constructible_v&lt;T&gt;){\n                m_queue.push(std::move(item));\n            }else{\n                m_queue.push(item);\n            }\n            unique_lck.unlock();\n            not_empty_.notify_one();\n            return true;\n        }\n\n        // blocking\n        void push(const_reference item){\n            std::unique_lock&lt;std::mutex&gt; unique_lck(m_mutex);\n            m_queue.push(item);\n            unique_lck.unlock();\n            not_empty_.notify_one();\n        }\n\n        // non-blocking\n        std::optional&lt;T&gt; try_pop()\n        {\n            std::unique_lock&lt;std::mutex&gt; unique_lck(m_mutex, std::try_to_lock);\n            if(!unique_lck || m_queue.empty())\n                return std::nullopt;\n\n            value_type item;\n            if constexpr(std::is_nothrow_move_assignable_v&lt;T&gt;){\n                item = std::move(m_queue.front());\n            }\n            else{\n                item = m_queue.front();\n            }\n            m_queue.pop();\n            return item;\n        }\n\n        // blocking\n        value_type pop(){\n            std::unique_lock&lt;std::mutex&gt; unique_lck(m_mutex);\n            not_empty_.wait(unique_lck, [this](){ return !m_queue.empty(); });\n\n            value_type item;\n            if constexpr(std::is_nothrow_move_assignable_v&lt;T&gt;){\n                item = std::move(m_queue.front());\n            }\n            else{\n                item = m_queue.front();\n            }\n            m_queue.pop();\n            return item;\n        }\n\n        // blocking\n        template&lt;typename... Args&gt;\n        void emplace(Args&&... args){\n            std::unique_lock&lt;std::mutex&gt; unique_lck(m_mutex);\n            m_queue.emplace(std::forward&lt;Args&gt;(args)...);\n            unique_lck.unlock();\n            not_empty_.notify_one();\n        }\n    };\n}\nIt would be The use of a mutex to protect the entire stack data-structure limits the concurrency supported by this queue; although multiple threads might be blocked on the queue in various member functions, only one thread can be doing any work at the time. This restriction comes from the use of std::queue&lt;T&gt; in the implementation. If we write a detailed implementation of the data-structure, we can provide more fine-grained locking and allow a higher level of concurrency."
  },
  {
    "objectID": "posts/thread-safe-queues/index.html#semaphores",
    "href": "posts/thread-safe-queues/index.html#semaphores",
    "title": "A thread-safe queue implementation",
    "section": "Semaphores",
    "text": "Semaphores\nC++20 introduces new synchronization primitives to write multi-threaded applications .\nA semaphore is a counter that manages the numberof permits available for accessing a share resource. Semaphores can be classified into two main types:\n\nBinary Semaphore. It has only \\(2\\) states: \\(0\\) and \\(1\\). Event though a binary semaphore is conceptually like a mutex, there are some differences between a binary semaphore and a mutex, that we’ll explore later.\nCounting Semaphore. It can have a value greater than \\(1\\) and is used to control access to a resource that has a limited number of instances.\n\nC++20 implements both binary and counting semaphores.\n\nBinary Semaphores\nA binary semaphore is a synchronization primitive that can be used to control access to a shared resource. It has two states: \\(0\\) and \\(1\\). A semaphore with a value of \\(0\\) indicates that the resource is unavailable, while a semaphore with a value of \\(1\\) indicates that the resource is available.\nThe most significant difference between mutexes and semaphores is that threads that have acquired a mutex have exclusive ownership of it. Only the thread owning the mutex can release it. Semaphores can be signaled by any thread. A mutex is a locking mechanism for a critical section, whereas a semaphore is more like a signaling mechanism. For this reason, semaphores are commonly used for signaling rather than for mutual exlusion.\nIn C++20, std::binary_semaphore is an alias for the specialization of std::counting_semaphore with LeastMaxValue being \\(1\\).\nBinary semaphores must be initialized with either \\(1\\) or \\(0\\) as follows:\nstd::binary_semaphore smphr1{ 0 };\nstd::binary_semaphore smphr2{ 1 };\nIf the initial value is 0, acquiring the semaphore will block the thread trying to acquire it, and before it can be acquired, it must be released by another thread. Acquiring the semaphore decreases the counter, and releasing it increases the counter.\n\n\nCounting semaphores\nA counting semaphore allows access to a shared resource by more than one thread. The counter can be initialized to an arbitrary number, and it will be decreased every time a thread acquires the semaphore.\nWe can design a thread-safe queue using semaphores instead of condition variables to synchronize access to the queue.\nWe code up an unbounded queue implemented as a circular queue with doubling.\n#include &lt;iostream&gt;\n#include &lt;shared_mutex&gt;\n#include &lt;semaphore&gt;\n\nnamespace dev {\n    /* \n    A queue implements a first-in-first-out data-structure allowing \n    enqueuing (adding) items to the rear and dequeuing(removing)\n    them from the front.\n\n    My implementation uses a circular queue with doubling - the simplest\n    and reasonably efficient choice.\n\n    The interface design conforms to the standard library std::queue&lt;T&gt;\n    specification.\n    */\n    template&lt;typename T&gt;\n    class queue {\n    private:\n        enum{min_capacity = 8};\n        T* m_ring_buffer;\n        int m_front;\n        int m_rear;\n        int m_capacity;\n\n    public:\n        using value_type = T;\n        using reference = T&;\n\n        /* Constructors */\n\n        // Default constructor\n        queue() : queue(min_capacity){}\n\n        // Parametrized Constructor\n        queue(int capacity)\n            : m_ring_buffer{ nullptr }\n            , m_front{ 0 }\n            , m_rear{ 0 }\n            , m_capacity{ 0 }\n        {\n            m_ring_buffer = static_cast&lt;T*&gt;(operator new(capacity * sizeof(T)));\n            m_capacity = capacity;\n        }\n\n        /* Destructor */\n        ~queue() {\n            clear();\n            operator delete(m_ring_buffer);\n        }\n\n        /* Copy constructor \n        * Perform a deep-copy of the contents of the queue\n        */\n        queue(const queue& other) \n            : queue(other.m_capacity) // Allocation step\n        {\n            /* Call the copy constructor of T \n            * placing it directly into the pre-allocated\n            * storage at memory address &m_ring_buffer[i]\n            */\n            for (int i{ 0 };i &lt; other.size();++i) {\n                new (&m_ring_buffer[i]) T(other[i]);\n                ++m_rear;\n            }\n        }\n\n        /* Swap the contents of lhs and rhs member-by-member */\n        friend void swap(queue& lhs, queue& rhs) {\n            std::swap(lhs.m_ring_buffer, rhs.m_ring_buffer);\n            std::swap(lhs.m_front, rhs.m_front);\n            std::swap(lhs.m_rear, rhs.m_rear);\n            std::swap(lhs.m_capacity, rhs.m_capacity);\n        }\n\n        /* Copy-assignment */\n        queue& operator=(const queue& other) {\n            queue temp{ other };    // Copy-construct\n            swap(*this, temp);      // and swap idiom\n            return (*this);\n        }\n\n        /* Move constructor */\n        queue(queue&& other)\n            : m_ring_buffer{ std::move(other.m_ring_buffer) }\n            , m_front{ std::move(other.m_front) }\n            , m_rear{ std::move(other.m_rear) }\n            , m_capacity{ std::move(other.m_capacity) }\n        {\n            other.m_ring_buffer = nullptr;\n        }\n\n        /* Move assignment */\n        queue& operator=(queue&& other) {\n            queue temp{ std::move(other) };\n            std::swap(*this, temp);\n            return (*this);\n        }\n\n        /* Capacity*/\n\n        /* Checks whether the queue is empty */\n        bool empty()\n        {\n            return (m_rear == m_front);\n        }\n\n        bool full() {\n            return (m_rear == m_front + m_capacity);\n        }\n\n        /* Returns the number of elements in the queue*/\n        int size() const {\n            return (m_rear - m_front);\n        }\n\n        int capacity() const {\n            return m_capacity;\n        }\n\n        /* Modifiers */\n\n        /* Double the capacity of the queue */\n        void resize()\n        {\n            std::cout &lt;&lt; \"\\n\" &lt;&lt; \"Resizing the queue from \" &lt;&lt; m_capacity \n                &lt;&lt; \" to \" &lt;&lt; 2 * m_capacity &lt;&lt; \" elements.\";\n\n            // 1. Allocation step\n            T* new_array = static_cast&lt;T*&gt;(operator new(2 * m_capacity * sizeof(T)));\n\n            std::cout &lt;&lt; \"\\n\" &lt;&lt; \"Allocation complete.\";\n\n            // 2. Copy over the elements of the queue to the newly\n            // allocated storage.\n            int new_size = size();\n            for (int i{ 0 };i &lt; new_size;++i) {\n                new (&new_array[i]) T(std::move(m_ring_buffer[(i + m_front) % m_capacity]));\n            }\n\n            std::cout &lt;&lt; \"\\n\" &lt;&lt; \"Copy-construction complete\";\n\n            // 3. Destroy the old array\n            clear();\n            operator delete(m_ring_buffer);\n            \n            std::cout &lt;&lt; \"\\n\" &lt;&lt; \"Destruction of old array complete\";\n            \n            // Re-wire m_ring_buffer, set front, rear and capacity\n            m_ring_buffer = new_array;\n            m_front = 0;\n            m_rear = new_size;\n            m_capacity *= 2;\n        }\n\n        /* Push the given value to the end of the queue */\n        void push(const T& value) {\n            std::cout &lt;&lt; \"\\n\" &lt;&lt; \"Pushing \" &lt;&lt; value &lt;&lt; \" to the queue\";\n            if (full())\n                resize();\n            new (&m_ring_buffer[(m_rear % m_capacity)]) T(value);\n            std::cout &lt;&lt; \"\\n\" &lt;&lt; \"Pushed \" &lt;&lt; value &lt;&lt; \" to the queue\";\n            m_rear++;\n        }\n\n        void push(T&& value) {\n            std::cout &lt;&lt; \"\\n\" &lt;&lt; \"Pushing \" &lt;&lt; value &lt;&lt; \" to the queue\";\n            if (full())\n                resize();\n            new(&m_ring_buffer[(m_rear % m_capacity)]) T(std::move(value));\n            m_rear++;\n        }\n\n        /* Removes an element from the front of the queue */\n        void pop() {\n            m_ring_buffer[m_front % m_capacity].~T();\n            m_front++;\n        }\n\n        /* Element access */\n\n        T& operator[](int i) {\n            return m_ring_buffer[(m_front + i) % m_capacity];\n        }\n\n        T& operator[](int i) const {\n            return m_ring_buffer[(m_front + i) % m_capacity];\n        }\n\n        /* Returns a reference to the first element in the queue */\n        T& front() {\n            return m_ring_buffer[m_front % m_capacity];\n        }\n\n        /* Return a reference to the last element in the queue */\n        T& back() {\n            return m_ring_buffer[(m_rear - 1) % m_capacity];\n        }\n\n    private:\n        /* Helper function to clear the queue */\n        void clear() {\n            for (int i{ 0 }; i &lt; size(); ++i) {\n                m_ring_buffer[(m_front + i) % m_capacity].~T();\n            }\n        }\n    };\n}\n\nint main()\n{\n    dev::queue&lt;double&gt; q;\n    std::cout &lt;&lt; \"\\n\" &lt;&lt; \"Queue capacity = \" &lt;&lt; q.capacity();\n    \n    for (double i{ 1.0 };i &lt;= 10.0;i++)\n        q.push(i);\n    \n    std::cout &lt;&lt; \"\\n\" &lt;&lt; \"Queue capacity = \" &lt;&lt; q.capacity();\n}\nPlay on Compiler Explorer\nNext, we code up the semaphore_queue class that uses semaphores instead of condition variables as the synchronization mechanism."
  },
  {
    "objectID": "posts/thread-safe-queues/index.html#spmc-queues-and-coding-up-a-threadpool",
    "href": "posts/thread-safe-queues/index.html#spmc-queues-and-coding-up-a-threadpool",
    "title": "A thread-safe queue implementation",
    "section": "SPMC queues and coding up a ThreadPool",
    "text": "SPMC queues and coding up a ThreadPool\nA thread-pool is a group of pre-instantiated, idle threads which stand ready to be given work. These are preferred over instantiating new threads for each task whenever there are a large number of short tasks to be done rather than a small number of long ones. This prevents having to incur the overhead of creating a thread a large number of times and starvation of threads.\nThe ThreadPool class has a container for the worker threads as one of its member-variables.\nWhen a thread-pool is handed a Task, it is added to a SPMC queue. If a thread from the ThreadPool is idle, it can pop() the next task off the TaskQueue and executes it. Once the execution is complete, the thread hands itself back to the pool to be put into the container for reuse and until the queue_not_empty_cond condition is met, and the cycle repeats."
  },
  {
    "objectID": "posts/tridiagonal-systems/index.html",
    "href": "posts/tridiagonal-systems/index.html",
    "title": "Tridiagonal Systems",
    "section": "",
    "text": "The special case of a system of linear equations that is tridiagonal, that is, has non-zero elements only on the diagonal plus or minus one column, is one that occurs frequently. Also common are systems that are band-diagonal, with non-zero elements only along a few diagonal lines adjacent to the main diagonal (above and below).\nFor triadiagonal sets, the procedures \\(LU\\)-decomposition, forward- and back- substitution each take only \\(O(n)\\) operations and the whole solution can be coded very concisely. In this blog post, I am going to explore solving triadiagonal matrix systems. I closely follow Daniel Duffy’s exposition in Chapter 13 of his excellent book Financial Instrument Pricing using C++.\nLet \\(A\\) be a \\(m \\times n\\) general banded matrix with \\(kl\\) subdiagonals and \\(ku\\) superdiagonals. Then, \\(a_{ij}=0\\), when \\(|i - j| &gt; kl + ku + 1\\). All non-zero elements are positioned on the main diagonal, \\(kl\\) subdiagonals below it and \\(ku\\) superdiagonals above it.\n\nA diagonal matrix is a \\(n \\times n\\) band matrix with \\(kl = ku = 0\\).\nA Toeplitz matrix is a \\(n \\times n\\) band matrix \\(T_n=[t_{k,j};k,j=0,1,\\ldots,n-1]\\) where \\(t_{k,j}=t_{k-j}\\). That is, a matrix of the form: \\[\nT_n = \\begin{bmatrix}\nt_0 & t_{-1} & t_{-2} & \\ldots & t_{-(n-1)}\\\\\nt_1 & t_0 & t_{-1} & \\ldots & t_{-(n-2)}\\\\\nt_2 & t_1 & t_{0} & \\ldots & t_{-(n-3)}\\\\\n\\vdots & & & \\ddots & \\\\\nt_{n-1} & t_{n-2} & t_{n-3} & \\ldots & t_{0}\n\\end{bmatrix}\n\\]\nA tridiagonal (Jacobi) matrix is a \\(n \\times n\\) band matrix of width three \\(kl = ku = 1\\). \\[\n\\begin{bmatrix}\nb_0 & c_0 & 0 & \\ldots \\\\\na_1 & b_1 & c_1 & \\ldots \\\\\n0 & a_2 & b_2 & \\ldots \\\\\n& & & \\ldots \\\\\n& & & \\ldots & a_{n-2} & b_{n-2} & c_{n-2}\\\\\n& & & \\ldots & 0 & a_{n-1} & b_{n-1}\n\\end{bmatrix}\n\\]\n\nConsider a two-point boundary value problem on the interval \\((0,1)\\) with Dirichlet boundary conditions:\n\\[\n\\begin{align*}\n\\frac{d^2 u}{d x^2} &= f(x), \\quad 0 &lt; x &lt; 1\\\\\nu(0) &= \\phi, \\\\\nu(1) &= \\psi\n\\end{align*}\n\\tag{1}\\]\nWe approximate the solution \\(u\\) by creating a discrete mesh of points defined by \\(\\{x_j\\}\\), \\(j=0,\\ldots,N\\) where \\(N\\) is a positive integer. At each interior mesh point the second derivative in the Equation 1 can be approximated by a second-order divided difference. The corresponding discrete scheme is:\n\\[\n\\begin{matrix}\nU_0 &- 2U_1 &+ U_2 & & & & & & & &= h^2 f_1 \\\\\n& U_1 &- 2U_2 &+ U_3  & & & & & & &= h^2 f_2 \\\\\n& & U_2 &- 2U_3 &+ U_4 & & & & & &= h^2 f_3 \\\\\n& &     &       &      & \\ldots & & & & & \\vdots \\\\\n& &     &       &      & \\ldots & U_{N-3} &- 2U_{N-2} &+ U_{N-1} &  &= h^2 f_{N-2}\\\\\n& &     &       &      & \\ldots &  & U_{N-2} &-2 U_{N-1} &+ U_N &= h^2 f_{N-1}\\\\\n\\end{matrix}\n\\]\nSince \\(U_0 = \\phi\\) and \\(U_N = \\psi\\), we have \\(N-1\\) equations in \\({N-1}\\) unknowns. These can be arranged in the matrix form as:\n\\[\n\\begin{bmatrix}\n-2 & 1\\\\\n1  &-2 & 1  &   & \\ldots &   &    &  \\\\\n   & 1 &-2  & 1 & \\ldots &   &    &  \\\\\n   &   &    &   & \\ldots &   &    &  \\\\\n   &   &    &   & \\ldots & 1 & -2 & 1 \\\\\n   &   &    &   & \\ldots &   &  1 & -2\n\\end{bmatrix}\\begin{bmatrix}\nU_1 \\\\\nU_2 \\\\\n\\vdots\\\\\nU_{N-2} \\\\\nU_{N-1}\n\\end{bmatrix} = \\begin{bmatrix}\nh^2 f_1 - \\phi\\\\\nh^2 f_2 \\\\\n\\vdots\\\\\nh^2 f_{N-2} \\\\\nh^2 f_{N-1} - \\psi\n\\end{bmatrix}\n\\]\nor in matrix form \\(AU=F\\)."
  },
  {
    "objectID": "posts/tridiagonal-systems/index.html#introduction",
    "href": "posts/tridiagonal-systems/index.html#introduction",
    "title": "Tridiagonal Systems",
    "section": "",
    "text": "The special case of a system of linear equations that is tridiagonal, that is, has non-zero elements only on the diagonal plus or minus one column, is one that occurs frequently. Also common are systems that are band-diagonal, with non-zero elements only along a few diagonal lines adjacent to the main diagonal (above and below).\nFor triadiagonal sets, the procedures \\(LU\\)-decomposition, forward- and back- substitution each take only \\(O(n)\\) operations and the whole solution can be coded very concisely. In this blog post, I am going to explore solving triadiagonal matrix systems. I closely follow Daniel Duffy’s exposition in Chapter 13 of his excellent book Financial Instrument Pricing using C++.\nLet \\(A\\) be a \\(m \\times n\\) general banded matrix with \\(kl\\) subdiagonals and \\(ku\\) superdiagonals. Then, \\(a_{ij}=0\\), when \\(|i - j| &gt; kl + ku + 1\\). All non-zero elements are positioned on the main diagonal, \\(kl\\) subdiagonals below it and \\(ku\\) superdiagonals above it.\n\nA diagonal matrix is a \\(n \\times n\\) band matrix with \\(kl = ku = 0\\).\nA Toeplitz matrix is a \\(n \\times n\\) band matrix \\(T_n=[t_{k,j};k,j=0,1,\\ldots,n-1]\\) where \\(t_{k,j}=t_{k-j}\\). That is, a matrix of the form: \\[\nT_n = \\begin{bmatrix}\nt_0 & t_{-1} & t_{-2} & \\ldots & t_{-(n-1)}\\\\\nt_1 & t_0 & t_{-1} & \\ldots & t_{-(n-2)}\\\\\nt_2 & t_1 & t_{0} & \\ldots & t_{-(n-3)}\\\\\n\\vdots & & & \\ddots & \\\\\nt_{n-1} & t_{n-2} & t_{n-3} & \\ldots & t_{0}\n\\end{bmatrix}\n\\]\nA tridiagonal (Jacobi) matrix is a \\(n \\times n\\) band matrix of width three \\(kl = ku = 1\\). \\[\n\\begin{bmatrix}\nb_0 & c_0 & 0 & \\ldots \\\\\na_1 & b_1 & c_1 & \\ldots \\\\\n0 & a_2 & b_2 & \\ldots \\\\\n& & & \\ldots \\\\\n& & & \\ldots & a_{n-2} & b_{n-2} & c_{n-2}\\\\\n& & & \\ldots & 0 & a_{n-1} & b_{n-1}\n\\end{bmatrix}\n\\]\n\nConsider a two-point boundary value problem on the interval \\((0,1)\\) with Dirichlet boundary conditions:\n\\[\n\\begin{align*}\n\\frac{d^2 u}{d x^2} &= f(x), \\quad 0 &lt; x &lt; 1\\\\\nu(0) &= \\phi, \\\\\nu(1) &= \\psi\n\\end{align*}\n\\tag{1}\\]\nWe approximate the solution \\(u\\) by creating a discrete mesh of points defined by \\(\\{x_j\\}\\), \\(j=0,\\ldots,N\\) where \\(N\\) is a positive integer. At each interior mesh point the second derivative in the Equation 1 can be approximated by a second-order divided difference. The corresponding discrete scheme is:\n\\[\n\\begin{matrix}\nU_0 &- 2U_1 &+ U_2 & & & & & & & &= h^2 f_1 \\\\\n& U_1 &- 2U_2 &+ U_3  & & & & & & &= h^2 f_2 \\\\\n& & U_2 &- 2U_3 &+ U_4 & & & & & &= h^2 f_3 \\\\\n& &     &       &      & \\ldots & & & & & \\vdots \\\\\n& &     &       &      & \\ldots & U_{N-3} &- 2U_{N-2} &+ U_{N-1} &  &= h^2 f_{N-2}\\\\\n& &     &       &      & \\ldots &  & U_{N-2} &-2 U_{N-1} &+ U_N &= h^2 f_{N-1}\\\\\n\\end{matrix}\n\\]\nSince \\(U_0 = \\phi\\) and \\(U_N = \\psi\\), we have \\(N-1\\) equations in \\({N-1}\\) unknowns. These can be arranged in the matrix form as:\n\\[\n\\begin{bmatrix}\n-2 & 1\\\\\n1  &-2 & 1  &   & \\ldots &   &    &  \\\\\n   & 1 &-2  & 1 & \\ldots &   &    &  \\\\\n   &   &    &   & \\ldots &   &    &  \\\\\n   &   &    &   & \\ldots & 1 & -2 & 1 \\\\\n   &   &    &   & \\ldots &   &  1 & -2\n\\end{bmatrix}\\begin{bmatrix}\nU_1 \\\\\nU_2 \\\\\n\\vdots\\\\\nU_{N-2} \\\\\nU_{N-1}\n\\end{bmatrix} = \\begin{bmatrix}\nh^2 f_1 - \\phi\\\\\nh^2 f_2 \\\\\n\\vdots\\\\\nh^2 f_{N-2} \\\\\nh^2 f_{N-1} - \\psi\n\\end{bmatrix}\n\\]\nor in matrix form \\(AU=F\\)."
  },
  {
    "objectID": "posts/tridiagonal-systems/index.html#thomas-algorithm",
    "href": "posts/tridiagonal-systems/index.html#thomas-algorithm",
    "title": "Tridiagonal Systems",
    "section": "Thomas Algorithm",
    "text": "Thomas Algorithm\nThe Thomas algorithm is an efficient way of solving tridiagonal matrix systems. It is based on \\(LU\\)-decomposition in which the matrix system \\(Ax=r\\) is written as \\(LUx=r\\), where \\(L\\) is a lower-triangular matrix and \\(U\\) is an upper triangular matrix. The system can be efficiently solved by setting \\(Ux=\\rho\\) and then solving first \\(L\\rho=r\\) and then \\(Ux=\\rho\\) for \\(x\\). The Thomas algorithm consists of two steps. In step 1, decomposing the matrix \\(M = LU\\) and solving \\(L\\rho=r\\) are accomplished in a single downwards sweep, taking us straight from \\(Ax=r\\) to \\(Ux=\\rho\\). In step 2, the equation \\(Ux = \\rho\\) is solved for \\(x\\) in an upward sweep.\n\nStage 1\nIn the first stage, the matrix equation \\(Ax=r\\) is converted to the form \\(Ux=\\rho\\). Initially, the matrix equation looks like this:\n\\[\n\\begin{bmatrix}\n{\\color{blue}b_1} & {\\color{blue}c_1} & 0 & 0 & 0 & 0\\\\\n{\\color{blue}a_2} & {\\color{blue}b_2} & {\\color{blue}c_2} & 0 & 0 & 0\\\\\n0 & {\\color{blue}a_3} & {\\color{blue}b_3} & {\\color{blue}c_3} & 0 & 0\\\\\n0 & 0 & {\\color{blue}a_4} & {\\color{blue}b_4} & {\\color{blue}c_4} & 0\\\\\n0 & 0 & 0 & {\\color{blue}a_5} & {\\color{blue}b_5} & {\\color{blue}c_5}\\\\\n0 & 0 & 0 & 0 & a_6 & b_6\n\\end{bmatrix} \\begin{bmatrix}\nx_1 \\\\\nx_2 \\\\\nx_3 \\\\\nx_4 \\\\\nx_5 \\\\\nx_6\n\\end{bmatrix} =\n\\begin{bmatrix}\n{\\color{blue}r_1} \\\\\n{\\color{blue}r_2} \\\\\n{\\color{blue}r_3} \\\\\n{\\color{blue}r_4} \\\\\n{\\color{blue}r_5} \\\\\n{\\color{blue}r_6}\n\\end{bmatrix}\n\\]\nRow \\(1\\):\n\\[\n{\\color{blue}b_1} x_1 + {\\color{blue}c_1} x_2 = {\\color{blue}r_1}\n\\]\nDividing throughout by \\(\\color{blue}b_1\\),\n\\[\nx_1 + {\\color{blue}\\frac{c_1}{b_1}} x_2 = {\\color{blue}\\frac{r_1}{b_1}}\n\\]\nRewrite:\n\\[\nx_1 + {\\color{red}\\gamma_1} x_2 = {\\color{red}\\rho_1}, \\quad {\\color{red}\\gamma_1} = {\\color{blue}\\frac{c_1}{b_1}}, \\quad {\\color{red}\\rho_1} = {\\color{blue}\\frac{r_1}{b_1}}\n\\]\n\\[\n\\begin{bmatrix}\n{\\color{red}1} & {\\color{red}\\gamma_1} & 0 & 0 & 0 & 0\\\\\n{\\color{blue}a_2} & {\\color{blue}b_2} & {\\color{blue}c_2} & 0 & 0 & 0\\\\\n0 & {\\color{blue}a_3} & {\\color{blue}b_3} & {\\color{blue}c_3} & 0 & 0\\\\\n0 & 0 & {\\color{blue}a_4} & {\\color{blue}b_4} & {\\color{blue}c_4} & 0\\\\\n0 & 0 & 0 & {\\color{blue}a_5} & {\\color{blue}b_5} & {\\color{blue}c_5}\\\\\n0 & 0 & 0 & 0 & a_6 & b_6\n\\end{bmatrix} \\begin{bmatrix}\nx_1 \\\\\nx_2 \\\\\nx_3 \\\\\nx_4 \\\\\nx_5 \\\\\nx_6\n\\end{bmatrix} =\n\\begin{bmatrix}\n{\\color{red}\\rho_1} \\\\\n{\\color{blue}r_2} \\\\\n{\\color{blue}r_3} \\\\\n{\\color{blue}r_4} \\\\\n{\\color{blue}r_5} \\\\\n{\\color{blue}r_6}\n\\end{bmatrix}\n\\]\nRow \\(2\\):\n\\[\n{\\color{blue}a_2} x_1 + {\\color{blue}b_2} x_2 + {\\color{blue}c_2} x_3 = {\\color{blue}r_2}\n\\]\nUse \\(a_2\\) times row \\(1\\) of the matrix to eliminate the first term\n\\[\na_2(x_1 + {\\color{red}\\gamma_1}x_2 = {\\color{red}\\rho_1})\n\\]\n\\[\n\\begin{array}{c|cccc}\n\\text{Row 2} & a_2 x_1 &+ b_2 x_2 &+ c_2 x_3 &= r_2\\\\\na_2 \\times \\text{Row 1} & a_2 x_1 &+ a_2 \\gamma_1 x_2 & &= a_2\\rho_1\\\\\n\\hline\n\\text{New Row 2} & & (b_2 - a_2 \\gamma_1) x_2 &+ c_2 x_3  &= r_2 - a_2 \\rho_1\n\\end{array}\n\\]\nDividing throughout by \\((b_2 - a_2 \\gamma_1)\\), we get:\n\\[\nx_2 + \\frac{c_2}{b_2 - a_2 \\gamma_1}x_3 = \\frac{(r_2 - a_2 \\rho_1)}{(b_2 - a_2 \\gamma_1)}\n\\]\nWe can rewrite this as:\n\\[\nx_2 + \\gamma_2 x_3 = \\rho_2, \\quad \\gamma_2 = \\frac{c_2}{b_2 - a_2 \\gamma_1}, \\quad \\rho_2 = \\frac{(r_2 - a_2 \\rho_1)}{(b_2 - a_2 \\gamma_1)}\n\\]\n\\[\n\\begin{bmatrix}\n1 & \\gamma_1 & 0 & 0 & 0 & 0\\\\\n0 & 1 & \\gamma_2 & 0 & 0 & 0\\\\\n0 & a_3 & b_3 & c_3 & 0 & 0\\\\\n0 & 0 & a_4 & b_4 & c_4 & 0\\\\\n0 & 0 & 0 & a_5 & b_5 & c_5\\\\\n0 & 0 & 0 & 0 & a_6 & b_6\n\\end{bmatrix} \\begin{bmatrix}\nx_1 \\\\\nx_2 \\\\\nx_3 \\\\\nx_4 \\\\\nx_5 \\\\\nx_6\n\\end{bmatrix} =\n\\begin{bmatrix}\n\\rho_1 \\\\\n\\rho_2 \\\\\nr_3 \\\\\nr_4 \\\\\nr_5 \\\\\nr_6\n\\end{bmatrix}\n\\]\nRow \\(3\\):\n\\[\na_3 x_2 + b_3 x_3 + c_3 x_4 = r_3\n\\]\nUse \\(a_3\\) times row \\(2\\) of the matrix to eliminate the first term:\n\\[\n\\begin{array}{c|cccc}\n\\text{Row 3} & a_3 x_2 &+ b_3 x_3 &+ c_3 x_4 &= r_3\\\\\na_3 \\times \\text{Row 2} & a_3 x_2 &+ a_3 \\gamma_2 x_3 & &= a_3\\rho_2\\\\\n\\hline\n\\text{New Row 3} & & (b_3 - a_3 \\gamma_2) x_3 &+ c_3 x_4  &= r_3 - a_3 \\rho_2\n\\end{array}\n\\]\nDividing throughout by \\((b_3 - a_3 \\gamma_2)\\), we have:\n\\[\nx_3 + \\frac{c_3}{b_3 - a_3 \\gamma_2} x_4 = \\frac{r_3 - a_3\\rho_2}{b_3 - a_3 \\gamma_2}\n\\]\nWe can rewrite this as:\n\\[\nx_3 + \\gamma_3 x_4 = \\rho_3, \\quad  \\gamma_3 = \\frac{c_3}{b_3 - a_3 \\gamma_2}, \\quad \\rho_3=\\frac{r_3 - a_3 \\rho_2}{b_3 - a_3 \\gamma_2}\n\\]\nContinuing in this fashion, we get:\n\\[\n\\begin{bmatrix}\n1 & \\gamma_1 & 0 & 0 & 0 & 0\\\\\n0 & 1 & \\gamma_2 & 0 & 0 & 0\\\\\n0 & 1 & 1 & \\gamma_3 & 0 & 0\\\\\n0 & 0 & 0 & 1 & \\gamma_4 & 0\\\\\n0 & 0 & 0 & 0 & 1 & \\gamma_5\\\\\n0 & 0 & 0 & 0 & a_6 & b_6\n\\end{bmatrix} \\begin{bmatrix}\nx_1 \\\\\nx_2 \\\\\nx_3 \\\\\nx_4 \\\\\nx_5 \\\\\nx_6\n\\end{bmatrix} =\n\\begin{bmatrix}\n\\rho_1 \\\\\n\\rho_2 \\\\\n\\rho_3 \\\\\n\\rho_4 \\\\\n\\rho_5 \\\\\nr_6\n\\end{bmatrix}\n\\]\nRow \\(6\\):\n\\[\na_6 x_5 + a_6 x_6 = r_6\n\\]\nUse \\(a_6\\) times row 5 of the matrix:\n\\[a_6(x_5 + \\gamma_5 x_6 = \\rho_5)\\]\n\\[\n\\begin{array}{c|cccc}\n\\text{Row 6} & a_6 x_5 &+ b_6 x_6 &= r_6\\\\\na_6 \\times \\text{Row 5} & a_6 x_5 &+ a_6 \\gamma_5 x_6  &= a_6\\rho_5\\\\\n\\hline\n\\text{New Row 3} & & (b_6 - a_6 \\gamma_5) x_6  &= r_6 - a_6 \\rho_5\n\\end{array}\n\\]\nDividing throughout by \\((b_6 - a_6 \\gamma_5)\\), we can rewrite:\n\\[\nx_6 = \\rho_6, \\quad \\rho_6 = \\frac{r_6 - a_6 \\rho_5}{b_6 - a_6 \\gamma_5}\n\\]\n\\[\n\\begin{bmatrix}\n1 & \\gamma_1 & 0 & 0 & 0 & 0\\\\\n0 & 1 & \\gamma_2 & 0 & 0 & 0\\\\\n0 & 1 & 1 & \\gamma_3 & 0 & 0\\\\\n0 & 0 & 0 & 1 & \\gamma_4 & 0\\\\\n0 & 0 & 0 & 0 & 1 & \\gamma_5\\\\\n0 & 0 & 0 & 0 & 0 & 1\n\\end{bmatrix} \\begin{bmatrix}\nx_1 \\\\\nx_2 \\\\\nx_3 \\\\\nx_4 \\\\\nx_5 \\\\\nx_6\n\\end{bmatrix} =\n\\begin{bmatrix}\n\\rho_1 \\\\\n\\rho_2 \\\\\n\\rho_3 \\\\\n\\rho_4 \\\\\n\\rho_5 \\\\\n\\rho_6\n\\end{bmatrix}\n\\]\nThese steps may be summarized as compute the following sequences:\n\\[\n\\gamma_1 = \\frac{c_1}{b_1}, \\quad \\rho_1 = \\frac{r_1}{b_1}\n\\]\nAnd \\[\\gamma_j = \\frac{c_j}{b_j - a_j \\gamma_{j-1}}, \\quad \\rho_j = \\frac{r_j - a_j \\rho_{j-1}}{b_j - a_j \\gamma_{j-1}}\\]\nfor \\(j=2:6\\).\nAt this point, the matrix has been reduced to the upper diagonal form, so our equations are of the form \\(Ux = \\rho\\).\n\n\nStage 2\nThe matrix is now in a form which is trivial to solve for \\(x\\). We start with the last row and work our way up. The final equation is already solved.\n\\[\nx_6 = \\rho_6\n\\]\n\\[\n\\begin{bmatrix}\n1 & \\gamma_1 & 0 & 0 & 0 & 0\\\\\n0 & 1 & \\gamma_2 & 0 & 0 & 0\\\\\n0 & 1 & 1 & \\gamma_3 & 0 & 0\\\\\n0 & 0 & 0 & 1 & \\gamma_4 & 0\\\\\n0 & 0 & 0 & 0 & 1 & \\gamma_5\\\\\n0 & 0 & 0 & 0 & 0 & 1\n\\end{bmatrix} \\begin{bmatrix}\nx_1 \\\\\nx_2 \\\\\nx_3 \\\\\nx_4 \\\\\nx_5 \\\\\nx_6\n\\end{bmatrix} =\n\\begin{bmatrix}\n\\rho_1 \\\\\n\\rho_2 \\\\\n\\rho_3 \\\\\n\\rho_4 \\\\\n\\rho_5 \\\\\n\\rho_6\n\\end{bmatrix}\n\\]\nRow \\(5\\): \\[\nx_5 + \\gamma_5 x_6 = \\rho_5\n\\]\nRearrange to get:\n\\[\nx_5 = \\rho_5 - \\gamma_5 x_6\n\\]\nRow \\(4\\):\n\\[\nx_4 + \\gamma_4 x_5 = \\rho_4\n\\]\nRearrange to get:\n\\[\nx_4 = \\rho_4 - \\gamma_4 x_5\n\\]\nContinuing in this fashion, we find that, \\(x_6 = \\rho_6\\) and\n\\[\nx_j = \\rho_j - \\gamma_j x_{j+1}\n\\]\nfor all \\(j=1:5\\)."
  },
  {
    "objectID": "posts/tridiagonal-systems/index.html#computational-solution",
    "href": "posts/tridiagonal-systems/index.html#computational-solution",
    "title": "Tridiagonal Systems",
    "section": "Computational Solution",
    "text": "Computational Solution\nLet’s quickly code up the algorithm in Julia.\n\nfunction thomasAlgorithm(a, b, c, r)\n    N = size(a)[1]\n\n    # Stage 1\n    γ = Array{Float64,1}(undef,N)\n    ρ = Array{Float64,1}(undef,N)\n    u = Array{Float64,1}(undef,N)\n\n    γ[1] = c[1]/b[1]\n    ρ[1] = r[1]/b[1]\n\n    for j=2:N\n        γ[j] = c[j]/(b[j] - a[j] * γ[j-1])\n        ρ[j] = (r[j] - a[j] * ρ[j-1])/(b[j] - a[j] * γ[j-1])\n    end\n\n    # Stage 2\n    u[N] =  ρ[N]\n\n    for j=reverse(1:N-1)\n        u[j] = ρ[j] - γ[j] * u[j+1]\n    end\n\n    return u\nend\n\n# Test Case\n\na = Array{Float64,1}([0, 2, 2, 2])\nb = Array{Float64,1}([3, 3, 3, 3])\nc = Array{Float64,1}([2, 2, 2, 0])\nr = Array{Float64,1}([12, 17, 14, 7])\nu = thomasAlgorithm(a, b, c, r)\n\nprint(u)\n\n[2.0, 3.0, 1.9999999999999996, 1.0000000000000004]\n\n\nHere is an implementation in modern C++:\n#include &lt;iostream&gt;\n#include &lt;memory&gt;\n#include &lt;functional&gt;\n#include &lt;concepts&gt;\n\ntemplate &lt;typename T&gt;\nconcept Real = std::integral&lt;T&gt; || std::floating_point&lt;T&gt;;\n\ntemplate &lt;typename T&gt;\nrequires Real&lt;T&gt;\nusing Function = std::function&lt;void(std::vector&lt;T&gt;, std::vector&lt;T&gt;, std::vector&lt;T&gt;, std::vector&lt;T&gt;, std::vector&lt;T&gt;&)&gt;;\n\ntemplate &lt;typename T&gt;\nrequires Real&lt;T&gt;\nvoid thomasAlgorithm(\n      std::vector&lt;T&gt; a\n    , std::vector&lt;T&gt; b\n    , std::vector&lt;T&gt; c\n    , std::vector&lt;T&gt; r\n    , std::vector&lt;T&gt;&x \n    ){\n    //Stage-1\n    int N = a.size();\n    std::vector&lt;T&gt; gamma(N);\n    std::vector&lt;T&gt; rho(N);\n    x = std::vector&lt;T&gt;(N);\n\n    gamma[0] = c[0]/b[0]; \n    rho[0] = r[0]/b[0];\n\n    for(int j{1}; j &lt; N; ++j)\n    {\n        gamma[j] = c[j]/(b[j] - a[j] * gamma[j-1]);\n        rho[j] = (r[j] - a[j] * rho[j-1])/(b[j] - a[j] * gamma[j-1]);\n    }\n\n    //Stage-2\n    x[N-1] = rho[N-1];\n    for(int j{N-2}; j &gt;= 0; j--)\n    {\n        x[j] = rho[j] - gamma[j] * x[j+1];\n    }\n}\n\ntemplate &lt;typename T&gt;\nrequires Real&lt;T&gt;\nclass LUTridiagonalSolver{\n    private:\n        std::vector&lt;T&gt; m_a;\n        std::vector&lt;T&gt; m_b;\n        std::vector&lt;T&gt; m_c;\n        std::vector&lt;T&gt; m_r;\n        std::vector&lt;T&gt; m_x;\n        Function&lt;T&gt; m_LUTridiagonalSolverStrategy;\n    \n    public:\n        LUTridiagonalSolver() = default;\n        LUTridiagonalSolver(\n              std::vector&lt;T&gt; a\n            , std::vector&lt;T&gt; b\n            , std::vector&lt;T&gt; c\n            , std::vector&lt;T&gt; r\n            , Function&lt;T&gt; solver) \n            : m_a {std::move(a)}\n            , m_b {std::move(b)}\n            , m_c {std::move(c)}\n            , m_r {std::move(r)}\n            , m_LUTridiagonalSolverStrategy {solver} \n            {}\n\n        std::vector&lt;T&gt; solve(){\n            m_LUTridiagonalSolverStrategy(m_a, m_b, m_c, m_r, m_x);\n            return m_x;\n        }\n\n        LUTridiagonalSolver(const LUTridiagonalSolver& ) = delete;\n        LUTridiagonalSolver operator=(LUTridiagonalSolver& ) = delete;\n        ~LUTridiagonalSolver(){}\n};\n\nint main()\n{\n    std::vector&lt;double&gt; a{0, 2, 2, 2};\n    std::vector&lt;double&gt; b{3, 3, 3, 3};\n    std::vector&lt;double&gt; c{2, 2, 2, 0};\n    std::vector&lt;double&gt; r{12, 17, 14, 7};\n\n    LUTridiagonalSolver&lt;double&gt; solver(a, b, c, r, thomasAlgorithm&lt;double&gt;);\n    std::vector&lt;double&gt; u = solver.solve();\n    return 0;\n}\nCompiler Explorer"
  },
  {
    "objectID": "posts/tridiagonal-systems/index.html#deriving-the-one-dimensional-heat-equation",
    "href": "posts/tridiagonal-systems/index.html#deriving-the-one-dimensional-heat-equation",
    "title": "Tridiagonal Systems",
    "section": "Deriving the one-dimensional Heat equation",
    "text": "Deriving the one-dimensional Heat equation\nConsider a slender homogenous rod, lying along the \\(x\\)-axis and insulated, so that no heat can escape across its longitudinal surface. In addition, we make the simplifying assumption that the temperature in the rod is constant on each cross-section perpendicular to the \\(x\\)-axis, and thus that the flow of heat in the rod takes place only in the \\(x\\)-direction.\nConsider a small segment of the rod at position \\(x\\) of length \\(\\Delta x\\).\nThe thermal energy in this segment at time \\(t\\) is:\n\\[\nE(x,x+\\Delta x, t) \\approx u(x,t) s \\rho \\Delta x\n\\]\nwhere \\(s\\) is the constant of specific heat i.e. amount of heat required to raise one unit of mass by one unit of temperature, \\(\\rho\\) is the mass density.\nFourier’s law of heat conduction quantifies the idea that heat flows from warmer to colder regions and states that the (rightward) heat flux density \\(\\phi(x,t)\\) (the flow of heat energy per unit area per unit time, SI units \\(J/s/m^2\\)) at any point is:\n\\[\n\\phi(x,t) = -K_0 u_x (x, t)\n\\]\nwhere \\(K_0\\) is the thermal conductivity of the rod. The negative sign shows that the heat flows from higher temperature regions to colder temperature regions.\nAppealing to the law of conservation of energy:\n\\[\n\\begin{align*}\n\\underbrace{\\frac{\\partial}{\\partial t}(u(x,t) s \\rho \\Delta x)}_{\\text{Heat flux through segment}} = \\underbrace{(-K_0 u_x(x, t))}_{\\text{Flux in}} - \\underbrace{(- K_0 u_x(x + \\Delta x,t))}_{\\text{Flux out}}\n\\end{align*}\n\\tag{2}\\]\nDividing throughout by \\(\\Delta x\\) we have:\n\\[\n\\begin{align*}\nu_t(x,t) \\approx \\frac{K_0}{s \\rho } \\frac{u_x(x+\\Delta x, t) - u_x(x,t)}{\\Delta x}\n\\end{align*}\n\\]\nLetting \\(\\Delta x \\to 0\\) improves the approximation and leads to the heat equation:\n\\[\nu_t=c^2 u_{xx}\n\\]\nwhere \\(c^2 = \\frac{K_0}{\\rho s}\\) is called the thermal diffusivity."
  },
  {
    "objectID": "posts/tridiagonal-systems/index.html#the-crank-nicolson-and-theta-methods",
    "href": "posts/tridiagonal-systems/index.html#the-crank-nicolson-and-theta-methods",
    "title": "Tridiagonal Systems",
    "section": "The Crank-Nicolson and Theta methods",
    "text": "The Crank-Nicolson and Theta methods\nConsider the initial boundary value problem for the \\(1\\)d-heat equation:\n\\[\n\\begin{align*}\nu_t &= a^2 u_{xx}, \\quad & 0 &lt; x &lt; L, t&gt;0\\\\\nu(x,0) &= f(x), \\quad 0 \\leq x \\leq L \\\\\nu(0,t) &= A, \\\\\nu(L,t) &= B\n\\end{align*}\n\\]\nIn this case, we can assume without the loss of generality that \\(L = 1\\). Here, \\(a\\), \\(A\\) and \\(B\\) are constants.\nWe find a solution to this system in the case when \\(A = B = 0\\) and \\(a = 1\\) by the method of the separation of variables. In this case, the analytical solution is:\n\\[\nu(x,t) = \\frac{8}{\\pi^2}\\sum_{n=1}^{\\infty}\\frac{1}{n^2}\\sin\\left(\\frac{n\\pi}{2}\\right)\\sin(n\\pi x)\\exp(-n^2 \\pi^2 t)\n\\]\nand we are going to use this solution as a benchmark against which the numerical solutions can be compared.\nWe can discretize a parabolic PDE in the space dimension (using centered difference schemes) while keeping the time variable continuous. We examine the following initial boundary value problem for the \\(1\\)d-heat equation on the unit interval with zero Dirichlet boundary conditions.\nThe problem is:\n\\[\n\\begin{align*}\nu_t &= u_{xx}, \\quad & 0 &lt; x &lt; 1, t&gt;0\\\\\nu(x,0) &= f(x), \\quad 0 \\leq x \\leq 1 \\\\\nu(0,t) &= u(1,t) = 0\n\\end{align*}\n\\tag{3}\\]\nWe partition the space interval \\((0,1)\\) into \\(J\\) subintervals and we approximate Equation 3 by the semi-discrete scheme:\n\\[\n\\begin{align*}\n\\frac{dU_j}{dt} &= \\frac{1}{h^2}(U_{j+1} - 2U_j + U_{j-1}), \\quad 1 \\leq j \\leq J-1 \\\\\nU_0(t) &= U_J(t) = 0, \\quad t &gt; 0 \\\\\nU_j(0) &= f(x_j)\n\\end{align*}\n\\]\nwhere \\(h = 1/J\\) is the constant mesh size. The \\(U_j\\)’s are functions of time \\(t\\). So, we define the following vectors:\n\\[\n\\begin{align*}\nU(t) &= (U_1(t),U_2(t),\\ldots,U_J(t))^T \\\\\nU^0 &= (f(x_1),f(x_2),\\ldots,f(x_{J-1}))^T\n\\end{align*}\n\\]\nThen, we can rewrite the system Equation 3 as a system of ordinary differential equations:\n\\[\n\\begin{align*}\n\\frac{dU}{dt} &= AU\\\\\nU(0) &= U^0\n\\end{align*}\n\\tag{4}\\]\nwhere the matrix \\(A\\) is given by:\n\\[\nA = \\frac{1}{h^2}\\begin{bmatrix}\n-2 & 1 & 0 & \\ldots \\\\\n1  &-2 & 1 & \\ldots \\\\\n0  & 1 & -2 & \\ldots \\\\\n   &   &    & \\ldots \\\\\n      &   &    & \\ldots & 1 & -2 & 1\\\\\n      &   &    & \\ldots & 0 & 1  & -2\\\\\n\\end{bmatrix}\n\\]\nThere are many discretization schemes. I plan to explore various finite difference schemes and their application to derivatives pricing in future posts. For now, I will concentrate on the one-step explicit and implicit methods to discretise the system of ODEs(Equation 4) as:\n\\[\n\\begin{align*}\n\\frac{U^{n+1 - U^n}}{\\Delta t} &= \\theta AU^{n+1} + (1-\\theta)AU^{n}, \\quad 0 \\leq n \\leq N-1, 0 \\leq \\theta \\leq 1 \\\\\nU^{0} &= U(0)\n\\end{align*}\n\\tag{5}\\]\nIn this case, \\(\\Delta t\\) is the constant mesh size in time.\nWe can rewrite Equation 5 in the equivalent form:\n\\[\n\\begin{align*}\nU^{n+1} - U^{n} &= \\theta \\Delta t A U^{n+1} + \\Delta t (I- \\theta)AU^{n} \\\\\n[I - \\Delta t A]U^{n+1} &= (\\Delta t (1 - \\theta) + 1)AU^n\n\\end{align*}\n\\tag{6}\\]\nor formally as:\n\\[\n\\begin{align*}\nU^{n+1} = [1-\\Delta t \\theta A]^{-1} (I + \\Delta t(I - \\theta)) A U^n\n\\end{align*}\n\\tag{7}\\]\nwhere \\(I\\) is the identity matrix.\nSome special cases of \\(\\theta\\) are:\n\\[\n\\begin{align*}\n\\theta &= 1, \\quad \\text{Implicit Euler Scheme}\\\\\n\\theta &= 0, \\quad \\text{Explicit Euler Scheme}\\\\\n\\theta &= 1/2,\\quad \\text{Crank-Nicolson Scheme}\n\\end{align*}\n\\tag{8}\\]\nWhen the schemes are implicit, we can solve the system of equations (Equation 5) at each time level \\(n+1\\) using the Thomas algorithm. No matrix inversion is needed in the case of explicit schemes. The formulation (Equation 4) is called the method of lines and it corresponds to semi-discretization of the PDE in the space direction while keeping the time variable continuous (I will explore MOL in future posts).\nWe can write the scheme (Equation 6 - Equation 8) in the component form:\n\\[\n\\begin{align*}\n\\frac{U^{n+1}j - U^{n}j}{\\Delta t} = \\theta(U^{n+1}_{j+1}-2U^{n+1}_j + U^{n+1}_{j-1})/h^2 + (1-\\theta)(U^{n}_{j+1}-2U^{n}_j + U^{n}_{j-1})/h^2\n\\end{align*}\n\\tag{9}\\]\nor equivalently:\n\\[\n\\begin{align*}\n{U^{n+1}j - U^{n}_j} &= \\lambda\\theta(U^{n+1}_{j+1}-2U^{n+1}_j + U^{n+1}_{j-1})/h^2 \\\\&+ (1-\\theta)(U^{n}_{j+1}-2U^{n}_j + U^{n}_{j-1})\n\\end{align*}\n\\]\nwhere \\(\\lambda = \\Delta t/h^2\\).\nFinally:\n\\[\n\\begin{align*}\n-\\lambda \\theta U^{n+1}_{j+1} + (1+2\\lambda \\theta)U_j^{n+1} - \\lambda \\theta U^{n+1}_{j-1} \\\\= \\lambda (1-\\theta)U^{n}_{j+1}+(1-2\\lambda(1-\\theta))U^{n}_j + \\lambda(1-\\theta)U^{n}_{j-1}\n\\end{align*}\n\\tag{10}\\]\nThe system (Equation 10) is tridiagonal and we can apply the Thomas algorithm to solve it. In the case of the explicit Euler scheme \\((\\theta = 0)\\), these algorithms are not needed, because the solution at time level \\(n+1\\) can be explicitly computed:\n\\[\n\\begin{align*}\nU^{n+1}_j = \\lambda U^{n}_{j+1} + (1-2\\lambda)U^{n}_j +\\lambda U^{n}_{j-1}\n\\end{align*}\n\\tag{11}\\]\n\nComputational Solution\nI implemented the algorithm in Equation 10. This is a one-step marching scheme called BTCS(Backward in Time, Centered in Space) that computes the solution at time level \\(n+1\\) in terms of the solution at time \\(n\\). Since there are three unknowns to be computed at each time level \\(n+1\\), we need to use the Thomas algorithm. The main steps in the algorithm are:\n\nChoose input parameters and generate meshes\nDefine the initial solution and the boundary conditions\nCompute the solution at each time upto and including expiration."
  },
  {
    "objectID": "posts/unique_ptr/index.html",
    "href": "posts/unique_ptr/index.html",
    "title": "unique_ptr - A custom implementation",
    "section": "",
    "text": "In this post, I try to write a simple homegrown version of std::unique_ptr&lt;T&gt;. This post is partly inspired by the fantastic book C++ Memory Management by Patrice Roy. Tghe toy examples in this book are very instructive and I highly reckon you order a copy. Our goal is just to build intuition for the kind of code required to write such a type, and not to try and replace the standard library facilities.\nThe std::unique_ptr&lt;T&gt; smart pointer type models unqiue(sole) ownership of the resource semantics.\nstruct X{};\n\nstd::unique_ptr&lt;X&gt; p1 = std::make_unique&lt;X&gt;();  \n//std::unique_ptr&lt;X&gt; p2(p1);      // Error when calling copy constructor, \n                                  // p1 is the exclusive owner\nstd::unique_ptr enforces exclusive ownership using the fact, that it is not copy-constructible or copy-assignable. Note however, that it doesn’t prevent you from writing deliberately hostile code. The below code is compiles perfectly well and is valid C++.\nint* p = new int(10);\n\nstd::unique_ptr&lt;int&gt; p1(p);  \nstd::unique_ptr&lt;int&gt; p2(p);      \nThe copy constructor and the copy assignment operator of std::unique_ptr&lt;T&gt; are marked delete. It is however, move constructible and move-assignable."
  },
  {
    "objectID": "posts/unique_ptr/index.html#references",
    "href": "posts/unique_ptr/index.html#references",
    "title": "unique_ptr - A custom implementation",
    "section": "References",
    "text": "References\n\n\nC++ Memory Management by Patrice Roy."
  },
  {
    "objectID": "posts/make-shared-and-make-unique/index.html",
    "href": "posts/make-shared-and-make-unique/index.html",
    "title": "A note on make_shared<T>(Args&&...) and make_unique<T>(Args&&...)",
    "section": "",
    "text": "A note on make_unique&lt;T&gt;(Args&&...)\nSince C++14, unique_ptr&lt;T&gt; has been accpompanied by the factory function make_unique&lt;T&gt;(Args&&...) that perfectly forwards its arguments to the constructor of T. Why standard library implementors provide a separate factory function make_unique&lt;T&gt;(Args&&...), when the constructor unique_ptr&lt;T&gt;(T*) does the same job?\nstd::unique_ptr&lt;T&gt; models ownership of the resource semantics. Calling unique_ptr&lt;T&gt;(T*) makes the client code responsible for supplying a pre-existing T object whose address is passed as an argument.\nConsider the following code snippet:\n#include&lt;iostream&gt;\n#include&lt;memory&gt;\n\ntemplate&lt;typename T&gt;\nclass pair_allocator{\n    private:\n    std::unique_ptr&lt;T&gt; p1;\n    std::unique_ptr&lt;T&gt; p2;\n\n    public:\n    pair_allocator() = default;\n    pair_allocator(T x, T y)\n    : p1(new T(x))\n    , p2(new T(y))\n    {}\n\n    ~pair_allocator() = default;\n};\nWe know that, the member subobjects of a C++ object are constructed in the order of their declaration. So, p1 is constructed before p2. Also, the allocation and construction operation new T(x) precedes the construction of p1. new T(y) precedes the construction of p2.\nDenoting \\(A:=\\) new T(x), \\(B:=\\) Construction of p1, \\(C:=\\) new T(y), \\(D:=\\) Construction of p2.\nIf we see the rules laid out above, we could have the operations in the following order: \\(A \\rightarrow B \\rightarrow C \\rightarrow D\\), but we could also have \\(A \\rightarrow C \\rightarrow B \\rightarrow D\\) or \\(C \\rightarrow A \\rightarrow B \\rightarrow D\\), in which case the two calls to new T(...) occur prior to the construction of p1 and p2. If this happens, then an exception thrown by the second call to new T(...) would lead to a memory leak, because we fail to release the memory allocated by the first call to new T().\nThe factory function make_unique&lt;T&gt;(Args&&...) is a wrapper over the operations new T() and unique__ptr&lt;T&gt;(), and so if the second call to new T() fails, the object p1 goes out of scope, its destructor ~unique_ptr&lt;T&gt;() in turn calls operator delete T, destroying the T object and releasing the memory held by T.\nIf we modify the above snippet as:\n#include&lt;iostream&gt;\n#include&lt;memory&gt;\n\ntemplate&lt;typename T&gt;\nclass pair_allocator{\n    private:\n    std::unique_ptr&lt;T&gt; p1;\n    std::unique_ptr&lt;T&gt; p2;\n\n    public:\n    pair_allocator() = default;\n    pair_allocator(T x, T y)\n    : p1(make_unique&lt;T&gt;(x))\n    , p2(make_unique&lt;T&gt;(y))\n    {}\n\n    ~pair_allocator() = default;\n};\nIn this instance, the client code will never find itself with floating results from calls to new. make_unique&lt;T&gt; is therefore a security feature that prevents client code being exposed to ownerless resources.\n\n\nA note on make_shared&lt;T&gt;(Args&&...)\nIn modern C++, it is recommended practice to replace this:\nstd::shared_ptr&lt;T&gt; p(\n    new T{ /* ... constructor args ... */ }\n);\nwith\nstd::shared_ptr&lt;T&gt; p = std::make_shared&lt;T&gt;( \n    /* ... constructor args ... */\n)\nOne might wonder, why this is recommended practice? To understand why the factory function make_shared&lt;T&gt;(/* ... ctor args ...*/) is preferred to the constructor shared_ptr&lt;T&gt;( new T( /*... ctor args ...*/) ), we need to realize that with the shared_ptr&lt;T&gt;(T*) constructor, the client code is reponsible for the construction of the T object (pointee), and is then given to shared_ptr&lt;T&gt; under construction, which takes ownership of the pointer and allocates a shared counter separately. So, there are two separate allocations (the T object and the counter), probably on different cache lines.\n\n\n\n\n\n\nNote\n\n\n\nThe cache memory usually keeps 64-byte lines of memory. A cache line is also the smallest fundamental unit of data transfer between the CPU cache and the main memory. On most architectures, a cache line is 64 bytes or 128 bytes.\n\n\nNow, if we go through make_shared&lt;T&gt;(), this factory function is responsible for allocating both the T object and the counter, perfectly forwarding the constructor arguments received by the function to the constructor of T. Since, the same function performs both allocations, it can fuse them into a single allocation of a memory block that contains both the T object and the shared counter, putting them both on the same cache line. This can lead to enhanced performance characteristics, if a single thread tries to read from both the pointers (T* and the counter) in a short span of time.\nIn most libraries, the factory function make_shared&lt;T&gt; is implemented as:\ntemplate&lt;typename T, typename... Args&gt;\nstd::shared_ptr&lt;T&gt; make_shared(Args&&... args){\n    return std::shared_ptr(\n        new T(std::forward&lt;T&gt;(args)...)\n    );\n}"
  },
  {
    "objectID": "posts/storage-duration/index.html",
    "href": "posts/storage-duration/index.html",
    "title": "Storage Durations in C++",
    "section": "",
    "text": "Introduction\nTwo key properties of an object in C++ are storage and linkage.\n\n\n\n\n\n\nNote\n\n\n\nStorage Duration. The storage duration is the property of an object that defines the minimum potential lifetime of the storage containing the object. The storage duration is determined by the construct used to create the object.\n\n\nAn object in C++ has one of the following storage durations:\n\nautomatic : Automatic means that the storage is allocated at the start of the scope. Most local variables have automatic storage duration (except those declared as static, extern or thread_local ).\nstatic : The storage for an object is allocated when the program begins usually before the main() function starts and is deallocated when the program ends. There’s only one instance of such an object in the whole program.\nthread : The storage for an object is tied to a thread: it’s started when a thread begins and is deallocated when the thread ends. Each thread has its own copy of the object.\ndynamic : The storage for an object is allocated and deallocated using explicit dynamic memory allocation functions.\n\nThe definition of the second property linkage from the standard is as follows:\n\n\n\n\n\n\nNote\n\n\n\nLinkage. A name is said to have a linkage when it can denote the same object, reference , function type, template, namespace as a name introduced in another scope.\n\n\nWe can have several linkage types:\n\nexternal linkage : External means that the name can be referred to in scopes within the same translation unit or outside. Non-const global variables have extern storage duration."
  },
  {
    "objectID": "posts/spsc_lockfree_queue/index.html",
    "href": "posts/spsc_lockfree_queue/index.html",
    "title": "Lock-free SPSC Queue",
    "section": "",
    "text": "I would like to present my implementation for an SPSC lock-free queue in this blog-post.\n\n%load_ext itikz\n\n\n\nWhen a programmer says that an operation is atomic, there are atleast two properties to which they might be referring:\n\nNon-preemptible - The operation can’t be pre-empted in the middle (e.g. by another thread).\nSynchronizable - The results of the operation can be made visible to other threads of execution in a controllable fashion.\n\n\n\n\n\nBounded size. The elements are stored in a fixed-length buffer.\nSingle-producer, Single-consumer applications.\nCircular buffer. The head and tail cursors after reaching the maximum index of the buffer wrap around to the start of the buffer.\n\nThe spsc_queue type contains a fixed-length array - a buffer to store the elements of the queue and it also contains two indices into the array:\n\nm_head - The index of the front element, if any.\nm_tail - The index where a new element would be inserted at the back of the queue.\n\nIn an initially empty container, both the m_head and m_tail start at zero:\n\n\n\nShow the code\n%%itikz --temp-dir --tex-packages=tikz --tikz-libraries=arrows.meta --implicit-standalone\n\\begin{tikzpicture}[font=\\small\\ttfamily]\n    \\fill[white] (-2, 0.5) rectangle (8.5, -4.8);\n    % Title\n    \\node[anchor=north] at (4, 0) {\\textbf{SPSC Ring Buffer (Empty)}};\n    \n    % Index labels\n    \\node[anchor=east] at (-0.2, -1.5) {Index:};\n    \\foreach \\i in {0,...,7} {\n        \\node at (\\i, -1.5) {\\i};\n    }\n    \n    % Buffer cells\n    \\node[anchor=east] at (-0.2, -2.5) {Buffer:};\n    \\foreach \\i in {0,...,7} {\n        \\draw (\\i-0.4, -2.2) rectangle (\\i+0.4, -2.8);\n    }\n    \n    % Pointers\n    \\draw[-&gt;, thick] (0, -3.2) -- (0, -2.8);\n    \\node[anchor=north] at (0, -3.2) {m\\_head = 0};\n    \\node[anchor=north] at (0, -3.6) {m\\_tail = 0};\n    \n    % Status\n    \\node[anchor=north] at (4, -4.2) {Status: Empty (m\\_head == m\\_tail)};\n\\end{tikzpicture}\n\n\n\n\n\n\nThen I have a spsc_queue::push_back() function that is used to append a new element to the queue. If the queue is not full, this operation should succeed, and it will go ahead and write a new element to the tail location and move the m_tail index forward.\nFor example, if do push_back(1) the queue looks something like this.\n\n\n\nShow the code\n%%itikz --temp-dir --tex-packages=tikz --tikz-libraries=arrows.meta --implicit-standalone\n\\begin{tikzpicture}[font=\\small\\ttfamily]\n    \\fill[white] (-2, 0.5) rectangle (8.5, -4.8);\n    % Title\n    \\node[anchor=north] at (4, 0) {\\textbf{SPSC Ring Buffer (1 element)}};\n    \n    % m_head pointer (above)\n    \\node[anchor=south] at (0, -0.8) {m\\_head = 0};\n    \\draw[-&gt;, thick] (0, -1.0) -- (0, -1.4);\n    \n    % Index labels\n    \\node[anchor=east] at (-0.2, -1.5) {Index:};\n    \\foreach \\i in {0,...,7} {\n        \\node at (\\i, -1.5) {\\i};\n    }\n    \n    % Buffer cells\n    \\node[anchor=east] at (-0.2, -2.5) {Buffer:};\n    \\foreach \\i in {0,...,7} {\n        \\draw (\\i-0.4, -2.2) rectangle (\\i+0.4, -2.8);\n    }\n    % Fill first cell\n    \\fill[lightgray!30] (-0.4, -2.2) rectangle (0.4, -2.8);\n    \\node at (0, -2.5) {1};\n    \n    % m_tail pointer (below)\n    \\draw[-&gt;, thick] (1, -3.2) -- (1, -2.8);\n    \\node[anchor=north] at (1, -3.2) {m\\_tail = 1};\n    \n    % Status\n    \\node[anchor=north] at (4, -3.8) {Status: 1 element (m\\_tail &gt; m\\_head)};\n\\end{tikzpicture}\n\n\n\n\n\n\nHere’s the queue with a few more elements added:\n\n\n\nShow the code\n%%itikz --temp-dir --tex-packages=tikz --tikz-libraries=arrows.meta --implicit-standalone\n\\begin{tikzpicture}[font=\\small\\ttfamily]\n    \\fill[white] (-2, 0.5) rectangle (8.5, -4.8);\n    % Title\n    \\node[anchor=north] at (4, 0) {\\textbf{SPSC Ring Buffer (4 elements)}};\n    \n    % m_head pointer (above)\n    \\node[anchor=south] at (0, -0.8) {m\\_head = 0};\n    \\draw[-&gt;, thick] (0, -1.0) -- (0, -1.4);\n    \n    % Index labels\n    \\node[anchor=east] at (-0.2, -1.5) {Index:};\n    \\foreach \\i in {0,...,7} {\n        \\node at (\\i, -1.5) {\\i};\n    }\n    \n    % Buffer cells\n    \\node[anchor=east] at (-0.2, -2.5) {Buffer:};\n    \\foreach \\i in {0,...,7} {\n        \\draw (\\i-0.4, -2.2) rectangle (\\i+0.4, -2.8);\n    }\n    % Fill cells 0-3\n    \\fill[lightgray!30] (-0.4, -2.2) rectangle (0.4, -2.8);\n    \\fill[lightgray!30] (0.6, -2.2) rectangle (1.4, -2.8);\n    \\fill[lightgray!30] (1.6, -2.2) rectangle (2.4, -2.8);\n    \\fill[lightgray!30] (2.6, -2.2) rectangle (3.4, -2.8);\n    \\node at (0, -2.5) {1};\n    \\node at (1, -2.5) {2};\n    \\node at (2, -2.5) {3};\n    \\node at (3, -2.5) {5};\n    \n    % m_tail pointer (below)\n    \\draw[-&gt;, thick] (4, -3.2) -- (4, -2.8);\n    \\node[anchor=north] at (4, -3.2) {m\\_tail = 4};\n    \n    % Status\n    \\node[anchor=north] at (4, -3.8) {Status: 4 elements (m\\_tail &gt; m\\_head)};\n\\end{tikzpicture}\n\n\n\n\n\n\nOnce I have got some elements into the queue, I can go ahead and call the pop() function, which is going to try to read and remove the first element from the front of the queue.\nIf the queue isn’t empty, it :\n\nAdvances m_head thereby implicitly discard the element at the front of the queue\n\n\n\n\nShow the code\n%%itikz --temp-dir --tex-packages=tikz --tikz-libraries=arrows.meta --implicit-standalone\n\\begin{tikzpicture}[font=\\small\\ttfamily]\n    \\fill[white] (-2, 0.5) rectangle (8.5, -4.8);\n    % Title\n    \\node[anchor=north] at (4, 0) {\\textbf{SPSC Ring Buffer (3 elements)}};\n    \n    % m_head pointer (above)\n    \\node[anchor=south] at (1, -0.8) {m\\_head = 1};\n    \\draw[-&gt;, thick] (1, -1.0) -- (1, -1.4);\n    \n    % Index labels\n    \\node[anchor=east] at (-0.2, -1.5) {Index:};\n    \\foreach \\i in {0,...,7} {\n        \\node at (\\i, -1.5) {\\i};\n    }\n    \n    % Buffer cells\n    \\node[anchor=east] at (-0.2, -2.5) {Buffer:};\n    \\foreach \\i in {0,...,7} {\n        \\draw (\\i-0.4, -2.2) rectangle (\\i+0.4, -2.8);\n    }\n    % Fill cells 1-3\n    \\fill[lightgray!30] (0.6, -2.2) rectangle (1.4, -2.8);\n    \\fill[lightgray!30] (1.6, -2.2) rectangle (2.4, -2.8);\n    \\fill[lightgray!30] (2.6, -2.2) rectangle (3.4, -2.8);\n    \\node at (1, -2.5) {2};\n    \\node at (2, -2.5) {3};\n    \\node at (3, -2.5) {5};\n    \n    % m_tail pointer (below)\n    \\draw[-&gt;, thick] (4, -3.2) -- (4, -2.8);\n    \\node[anchor=north] at (4, -3.2) {m\\_tail = 4};\n    \n    % Status\n    \\node[anchor=north] at (4, -3.8) {Status: 3 elements (m\\_tail &gt; m\\_head)};\n    \\node[anchor=north] at (4, -4.2) {Note: Index 0 is now \"stale\" (logically removed)};\n\\end{tikzpicture}\n\n\n\n\n\n\nMost of the time, when we advance an index like this, it is a simple increment. But, as I stated earlier, the buffer slots are used in a a circular fashion. If that increment would place that index out of bounds, it wraps around to the zeroeth slot (that’s what makes it a ring) of the queue buffer.\n\n\n\nShow the code\n%%itikz --temp-dir --tex-packages=tikz --tikz-libraries=arrows.meta --implicit-standalone\n\\begin{tikzpicture}[font=\\small\\ttfamily]\n    \\fill[white] (-2, 0.5) rectangle (8.5, -4.8);\n    % Title\n    \\node[anchor=north] at (4, 0) {\\textbf{SPSC Ring Buffer (7 elements)}};\n    \n    % m_head pointer (above)\n    \\node[anchor=south] at (1, -0.8) {m\\_head = 1};\n    \\draw[-&gt;, thick] (1, -1.0) -- (1, -1.4);\n    \n    % Index labels\n    \\node[anchor=east] at (-0.2, -1.5) {Index:};\n    \\foreach \\i in {0,...,7} {\n        \\node at (\\i, -1.5) {\\i};\n    }\n    \n    % Buffer cells\n    \\node[anchor=east] at (-0.2, -2.5) {Buffer:};\n    \\foreach \\i in {0,...,7} {\n        \\draw (\\i-0.4, -2.2) rectangle (\\i+0.4, -2.8);\n    }\n    % Fill cells 1-7\n    \\fill[lightgray!30] (0.6, -2.2) rectangle (1.4, -2.8);\n    \\fill[lightgray!30] (1.6, -2.2) rectangle (2.4, -2.8);\n    \\fill[lightgray!30] (2.6, -2.2) rectangle (3.4, -2.8);\n    \\fill[lightgray!30] (3.6, -2.2) rectangle (4.4, -2.8);\n    \\fill[lightgray!30] (4.6, -2.2) rectangle (5.4, -2.8);\n    \\fill[lightgray!30] (5.6, -2.2) rectangle (6.4, -2.8);\n    \\fill[lightgray!30] (6.6, -2.2) rectangle (7.4, -2.8);\n    \\node at (1, -2.5) {2};\n    \\node at (2, -2.5) {3};\n    \\node at (3, -2.5) {5};\n    \\node at (4, -2.5) {8};\n    \\node at (5, -2.5) {13};\n    \\node at (6, -2.5) {21};\n    \\node at (7, -2.5) {34};\n    \n    % m_tail pointer (below)\n    \\draw[-&gt;, thick] (0, -3.2) -- (0, -2.8);\n    \\node[anchor=north] at (0, -3.2) {m\\_tail = 0};\n\\end{tikzpicture}\n\n\n\n\n\n\nAs we’ll see, it turns out that the indices m_head and m_tail will need to be atomic objects. We’ll understand why this is the case.\nThe storage for a ring buffer consists of a fixed-capacity array of elements and the indices for head and tail. We shall write spsc_queue as a templated class having the capacity as a template parameter.\ntemplate&lt;typename T, size_t capacity&gt;\nclass spsc_queue{\n    private:\n    // The capacity must be a power of two.\n    static_assert((capacity & (capacity - 1)) == 0);    \n    T m_buffer[capacity];\n    size_t m_head;\n    size_t m_tail;\n    public:\n        /* ... */\n};\nWe would like to enforce the capacity to be a power of \\(2\\) for efficiency reasons. Remember, that with this design, there’s always atleast one unused element in the array, because m_head == m_tail + 1 is the queue full condition. So, the effective capacity equals capacity - 1.\n\n\n\nHere is the class interface:\ntemplate&lt;typename T, size_t capacity&gt;\nclass spsc_queue{\n    private:\n    // The capacity must be a power of two.\n    static_assert((capacity & (capacity - 1)) == 0);    \n    T m_buffer[capacity];\n    size_t m_head;\n    size_t m_tail;\n    public:\n        using value_type = T;\n        spsc_queue();\n        bool is_empty() const;\n        bool is_full() const;\n        bool push_back(value_type& item);\n        bool pop_front();\n};"
  },
  {
    "objectID": "posts/spsc_lockfree_queue/index.html#what-makes-an-operation-atomic",
    "href": "posts/spsc_lockfree_queue/index.html#what-makes-an-operation-atomic",
    "title": "Lock-free SPSC Queue",
    "section": "",
    "text": "When a programmer says that an operation is atomic, there are atleast two properties to which they might be referring:\n\nNon-preemptible - The operation can’t be pre-empted in the middle (e.g. by another thread).\nSynchronizable - The results of the operation can be made visible to other threads of execution in a controllable fashion."
  },
  {
    "objectID": "posts/spsc_lockfree_queue/index.html#setup---how-the-queue-works",
    "href": "posts/spsc_lockfree_queue/index.html#setup---how-the-queue-works",
    "title": "Lock-free SPSC Queue",
    "section": "",
    "text": "Bounded size. The elements are stored in a fixed-length buffer.\nSingle-producer, Single-consumer applications.\nCircular buffer. The head and tail cursors after reaching the maximum index of the buffer wrap around to the start of the buffer.\n\nThe spsc_queue type contains a fixed-length array - a buffer to store the elements of the queue and it also contains two indices into the array:\n\nm_head - The index of the front element, if any.\nm_tail - The index where a new element would be inserted at the back of the queue.\n\nIn an initially empty container, both the m_head and m_tail start at zero:\n\n\n\nShow the code\n%%itikz --temp-dir --tex-packages=tikz --tikz-libraries=arrows.meta --implicit-standalone\n\\begin{tikzpicture}[font=\\small\\ttfamily]\n    \\fill[white] (-2, 0.5) rectangle (8.5, -4.8);\n    % Title\n    \\node[anchor=north] at (4, 0) {\\textbf{SPSC Ring Buffer (Empty)}};\n    \n    % Index labels\n    \\node[anchor=east] at (-0.2, -1.5) {Index:};\n    \\foreach \\i in {0,...,7} {\n        \\node at (\\i, -1.5) {\\i};\n    }\n    \n    % Buffer cells\n    \\node[anchor=east] at (-0.2, -2.5) {Buffer:};\n    \\foreach \\i in {0,...,7} {\n        \\draw (\\i-0.4, -2.2) rectangle (\\i+0.4, -2.8);\n    }\n    \n    % Pointers\n    \\draw[-&gt;, thick] (0, -3.2) -- (0, -2.8);\n    \\node[anchor=north] at (0, -3.2) {m\\_head = 0};\n    \\node[anchor=north] at (0, -3.6) {m\\_tail = 0};\n    \n    % Status\n    \\node[anchor=north] at (4, -4.2) {Status: Empty (m\\_head == m\\_tail)};\n\\end{tikzpicture}\n\n\n\n\n\n\nThen I have a spsc_queue::push_back() function that is used to append a new element to the queue. If the queue is not full, this operation should succeed, and it will go ahead and write a new element to the tail location and move the m_tail index forward.\nFor example, if do push_back(1) the queue looks something like this.\n\n\n\nShow the code\n%%itikz --temp-dir --tex-packages=tikz --tikz-libraries=arrows.meta --implicit-standalone\n\\begin{tikzpicture}[font=\\small\\ttfamily]\n    \\fill[white] (-2, 0.5) rectangle (8.5, -4.8);\n    % Title\n    \\node[anchor=north] at (4, 0) {\\textbf{SPSC Ring Buffer (1 element)}};\n    \n    % m_head pointer (above)\n    \\node[anchor=south] at (0, -0.8) {m\\_head = 0};\n    \\draw[-&gt;, thick] (0, -1.0) -- (0, -1.4);\n    \n    % Index labels\n    \\node[anchor=east] at (-0.2, -1.5) {Index:};\n    \\foreach \\i in {0,...,7} {\n        \\node at (\\i, -1.5) {\\i};\n    }\n    \n    % Buffer cells\n    \\node[anchor=east] at (-0.2, -2.5) {Buffer:};\n    \\foreach \\i in {0,...,7} {\n        \\draw (\\i-0.4, -2.2) rectangle (\\i+0.4, -2.8);\n    }\n    % Fill first cell\n    \\fill[lightgray!30] (-0.4, -2.2) rectangle (0.4, -2.8);\n    \\node at (0, -2.5) {1};\n    \n    % m_tail pointer (below)\n    \\draw[-&gt;, thick] (1, -3.2) -- (1, -2.8);\n    \\node[anchor=north] at (1, -3.2) {m\\_tail = 1};\n    \n    % Status\n    \\node[anchor=north] at (4, -3.8) {Status: 1 element (m\\_tail &gt; m\\_head)};\n\\end{tikzpicture}\n\n\n\n\n\n\nHere’s the queue with a few more elements added:\n\n\n\nShow the code\n%%itikz --temp-dir --tex-packages=tikz --tikz-libraries=arrows.meta --implicit-standalone\n\\begin{tikzpicture}[font=\\small\\ttfamily]\n    \\fill[white] (-2, 0.5) rectangle (8.5, -4.8);\n    % Title\n    \\node[anchor=north] at (4, 0) {\\textbf{SPSC Ring Buffer (4 elements)}};\n    \n    % m_head pointer (above)\n    \\node[anchor=south] at (0, -0.8) {m\\_head = 0};\n    \\draw[-&gt;, thick] (0, -1.0) -- (0, -1.4);\n    \n    % Index labels\n    \\node[anchor=east] at (-0.2, -1.5) {Index:};\n    \\foreach \\i in {0,...,7} {\n        \\node at (\\i, -1.5) {\\i};\n    }\n    \n    % Buffer cells\n    \\node[anchor=east] at (-0.2, -2.5) {Buffer:};\n    \\foreach \\i in {0,...,7} {\n        \\draw (\\i-0.4, -2.2) rectangle (\\i+0.4, -2.8);\n    }\n    % Fill cells 0-3\n    \\fill[lightgray!30] (-0.4, -2.2) rectangle (0.4, -2.8);\n    \\fill[lightgray!30] (0.6, -2.2) rectangle (1.4, -2.8);\n    \\fill[lightgray!30] (1.6, -2.2) rectangle (2.4, -2.8);\n    \\fill[lightgray!30] (2.6, -2.2) rectangle (3.4, -2.8);\n    \\node at (0, -2.5) {1};\n    \\node at (1, -2.5) {2};\n    \\node at (2, -2.5) {3};\n    \\node at (3, -2.5) {5};\n    \n    % m_tail pointer (below)\n    \\draw[-&gt;, thick] (4, -3.2) -- (4, -2.8);\n    \\node[anchor=north] at (4, -3.2) {m\\_tail = 4};\n    \n    % Status\n    \\node[anchor=north] at (4, -3.8) {Status: 4 elements (m\\_tail &gt; m\\_head)};\n\\end{tikzpicture}\n\n\n\n\n\n\nOnce I have got some elements into the queue, I can go ahead and call the pop() function, which is going to try to read and remove the first element from the front of the queue.\nIf the queue isn’t empty, it :\n\nAdvances m_head thereby implicitly discard the element at the front of the queue\n\n\n\n\nShow the code\n%%itikz --temp-dir --tex-packages=tikz --tikz-libraries=arrows.meta --implicit-standalone\n\\begin{tikzpicture}[font=\\small\\ttfamily]\n    \\fill[white] (-2, 0.5) rectangle (8.5, -4.8);\n    % Title\n    \\node[anchor=north] at (4, 0) {\\textbf{SPSC Ring Buffer (3 elements)}};\n    \n    % m_head pointer (above)\n    \\node[anchor=south] at (1, -0.8) {m\\_head = 1};\n    \\draw[-&gt;, thick] (1, -1.0) -- (1, -1.4);\n    \n    % Index labels\n    \\node[anchor=east] at (-0.2, -1.5) {Index:};\n    \\foreach \\i in {0,...,7} {\n        \\node at (\\i, -1.5) {\\i};\n    }\n    \n    % Buffer cells\n    \\node[anchor=east] at (-0.2, -2.5) {Buffer:};\n    \\foreach \\i in {0,...,7} {\n        \\draw (\\i-0.4, -2.2) rectangle (\\i+0.4, -2.8);\n    }\n    % Fill cells 1-3\n    \\fill[lightgray!30] (0.6, -2.2) rectangle (1.4, -2.8);\n    \\fill[lightgray!30] (1.6, -2.2) rectangle (2.4, -2.8);\n    \\fill[lightgray!30] (2.6, -2.2) rectangle (3.4, -2.8);\n    \\node at (1, -2.5) {2};\n    \\node at (2, -2.5) {3};\n    \\node at (3, -2.5) {5};\n    \n    % m_tail pointer (below)\n    \\draw[-&gt;, thick] (4, -3.2) -- (4, -2.8);\n    \\node[anchor=north] at (4, -3.2) {m\\_tail = 4};\n    \n    % Status\n    \\node[anchor=north] at (4, -3.8) {Status: 3 elements (m\\_tail &gt; m\\_head)};\n    \\node[anchor=north] at (4, -4.2) {Note: Index 0 is now \"stale\" (logically removed)};\n\\end{tikzpicture}\n\n\n\n\n\n\nMost of the time, when we advance an index like this, it is a simple increment. But, as I stated earlier, the buffer slots are used in a a circular fashion. If that increment would place that index out of bounds, it wraps around to the zeroeth slot (that’s what makes it a ring) of the queue buffer.\n\n\n\nShow the code\n%%itikz --temp-dir --tex-packages=tikz --tikz-libraries=arrows.meta --implicit-standalone\n\\begin{tikzpicture}[font=\\small\\ttfamily]\n    \\fill[white] (-2, 0.5) rectangle (8.5, -4.8);\n    % Title\n    \\node[anchor=north] at (4, 0) {\\textbf{SPSC Ring Buffer (7 elements)}};\n    \n    % m_head pointer (above)\n    \\node[anchor=south] at (1, -0.8) {m\\_head = 1};\n    \\draw[-&gt;, thick] (1, -1.0) -- (1, -1.4);\n    \n    % Index labels\n    \\node[anchor=east] at (-0.2, -1.5) {Index:};\n    \\foreach \\i in {0,...,7} {\n        \\node at (\\i, -1.5) {\\i};\n    }\n    \n    % Buffer cells\n    \\node[anchor=east] at (-0.2, -2.5) {Buffer:};\n    \\foreach \\i in {0,...,7} {\n        \\draw (\\i-0.4, -2.2) rectangle (\\i+0.4, -2.8);\n    }\n    % Fill cells 1-7\n    \\fill[lightgray!30] (0.6, -2.2) rectangle (1.4, -2.8);\n    \\fill[lightgray!30] (1.6, -2.2) rectangle (2.4, -2.8);\n    \\fill[lightgray!30] (2.6, -2.2) rectangle (3.4, -2.8);\n    \\fill[lightgray!30] (3.6, -2.2) rectangle (4.4, -2.8);\n    \\fill[lightgray!30] (4.6, -2.2) rectangle (5.4, -2.8);\n    \\fill[lightgray!30] (5.6, -2.2) rectangle (6.4, -2.8);\n    \\fill[lightgray!30] (6.6, -2.2) rectangle (7.4, -2.8);\n    \\node at (1, -2.5) {2};\n    \\node at (2, -2.5) {3};\n    \\node at (3, -2.5) {5};\n    \\node at (4, -2.5) {8};\n    \\node at (5, -2.5) {13};\n    \\node at (6, -2.5) {21};\n    \\node at (7, -2.5) {34};\n    \n    % m_tail pointer (below)\n    \\draw[-&gt;, thick] (0, -3.2) -- (0, -2.8);\n    \\node[anchor=north] at (0, -3.2) {m\\_tail = 0};\n\\end{tikzpicture}\n\n\n\n\n\n\nAs we’ll see, it turns out that the indices m_head and m_tail will need to be atomic objects. We’ll understand why this is the case.\nThe storage for a ring buffer consists of a fixed-capacity array of elements and the indices for head and tail. We shall write spsc_queue as a templated class having the capacity as a template parameter.\ntemplate&lt;typename T, size_t capacity&gt;\nclass spsc_queue{\n    private:\n    // The capacity must be a power of two.\n    static_assert((capacity & (capacity - 1)) == 0);    \n    T m_buffer[capacity];\n    size_t m_head;\n    size_t m_tail;\n    public:\n        /* ... */\n};\nWe would like to enforce the capacity to be a power of \\(2\\) for efficiency reasons. Remember, that with this design, there’s always atleast one unused element in the array, because m_head == m_tail + 1 is the queue full condition. So, the effective capacity equals capacity - 1."
  },
  {
    "objectID": "posts/spsc_lockfree_queue/index.html#the-class-interface",
    "href": "posts/spsc_lockfree_queue/index.html#the-class-interface",
    "title": "Lock-free SPSC Queue",
    "section": "",
    "text": "Here is the class interface:\ntemplate&lt;typename T, size_t capacity&gt;\nclass spsc_queue{\n    private:\n    // The capacity must be a power of two.\n    static_assert((capacity & (capacity - 1)) == 0);    \n    T m_buffer[capacity];\n    size_t m_head;\n    size_t m_tail;\n    public:\n        using value_type = T;\n        spsc_queue();\n        bool is_empty() const;\n        bool is_full() const;\n        bool push_back(value_type& item);\n        bool pop_front();\n};"
  },
  {
    "objectID": "posts/spsc_lockfree_queue/index.html#using-atomic-indices",
    "href": "posts/spsc_lockfree_queue/index.html#using-atomic-indices",
    "title": "Lock-free SPSC Queue",
    "section": "Using atomic indices",
    "text": "Using atomic indices\nThis is my implementation for SPSC lock-free queue with atomic indices.\n#include &lt;atomic&gt;\n#include &lt;thread&gt;\n\ntemplate&lt;typename T, size_t capacity&gt;\nclass spsc_queue{\n    private:\n    // The capacity must be a power of two.\n    static_assert((capacity & (capacity - 1)) == 0);    \n    T m_buffer[capacity];\n    alignas(std::hardware_destructive_interference_size) std::atomic&lt;size_t&gt; m_head;\n    alignas(std::hardware_destructive_interference_size) std::atomic&lt;size_t&gt; m_tail;\n\n    public:\n        using value_type = T;\n        spsc_queue()\n        : m_buffer{}\n        , m_head{0}\n        , m_tail{0}\n        {}\n\n        [[nodiscard]] bool is_empty() const{\n            return m_head.load()\n                == m_tail.load();\n        }\n\n        [[nodiscard]] bool is_full() const{\n            return m_tail.load() + 1 == m_head.load();\n        }\n\n        [[nodiscard]] size_t get_size(){\n            return m_tail.load() - m_head.load() + 1;\n        }\n\n        [[nodiscard]] size_t get_capacity(){\n            return capacity - 1;\n        }\n\n        [[nodiscard]] size_t next(size_t current_idx)\n        {\n            size_t next_idx = current_idx & (capacity - 1);\n            return next_idx;\n        }\n\n        bool push_back(value_type& item){\n            size_t tail = m_tail.load(std::memory_order_relaxed);\n            size_t next_write_index = next(tail);\n            if(next_write_index == m_head.load(std::memory_order_acquire))\n                return false;\n\n            m_buffer[tail] = item;\n            m_tail.store(next_write_index, std::memory_order_release);\n            return true;\n        }\n\n        bool pop_front(value_type& v){\n            size_t head = m_head.load(std::memory_order_relaxed);\n            if(head == m_tail.load(std::memory_order_acquire))\n                return false;\n\n            v = m_buffer[head];\n            size_t next_read_index = next(m_head);\n            m_head.store(next_read_index, std::memory_order_release);\n            return true;\n        }\n};\n\nWhy do we use a power of \\(2\\) buffer size?\nFor a buffer of fixed capacity \\(N\\), with current index idx, the index to the next element can be calculated as:\nnext_idx = (curr_idx + 1) % N\nThis is because our queue is a ring buffer, so after the last slot, we will go back to the zeroeth one, then the first one and so on.\nWe can use the above method to get the next index for any buffer size \\(N\\). Why do we then only use capacity that are powers of \\(2\\)? The answer is easy: performance. The modulo (%) operator requires a division instruction, which is expensive. When the size \\(N\\) is a power of \\(2\\), we can just do the following:\nsize_t next_index = curr_index & (N - 1);\n\n\nBuffer access synchronization\n\n\n\nSynchronization\n\n\nHere’s what the actual execution order looks like after we make the indices atomic.\nIf we look at the push thread, the incremented value of the tail, next_write_index written to m_tail index is a release operation. Over on the pop thread, when we load the m_tail index (take a snapshot of it), this is an acquire operation. The combination of release and acquire on the same atomic variable implies that m_tail store in the push thread synchronizes with m_tail load on the pop thread.\nThe instruction m_buffer[tail] = item cannot be moved to after the release barrier in actual CPU execution order. The instrusction v=m_buffer[head] cannot be moved to before the acquire barrier in actual CPU exection order. So, we have happens-before relationship between these two instructions.\nThe release of m_head in the pop thread synchronizes with the acquire of m_head in the push thread."
  },
  {
    "objectID": "posts/type-erasure/index.html",
    "href": "posts/type-erasure/index.html",
    "title": "C++ Type erasure",
    "section": "",
    "text": "Once you instantiate a std::function object, how is it, that you are able to stick objects of different actual types e.g. an anonymous lambda, a free-standing function or a function-pointer (with only a common function signature) to it? This is achieved through type erasure.\nType erasure is a programming technique by which the explicit type information is removed from the program. It is a type of abstraction that ensures that the program does not explicitly depend on some of the data-types. You might wonder, how is it, that a program is written in a strongly typed language but does not use the actual types?"
  },
  {
    "objectID": "posts/dupire-pde/index.html",
    "href": "posts/dupire-pde/index.html",
    "title": "A short note on the Dupire PDE",
    "section": "",
    "text": "If the Black-Scholes model were good, the implied volatility \\(\\hat{\\sigma}\\) parameter would be the same for all call option market prices. However, in reality, Black-Scholes implied volatility depends strongly on strike \\(K\\), and maturity \\(T\\).\nIn Dupire’s 1993 paper, he proposes the following dynamics for the spot process:\n\\[\ndS_t = r(t)S_t dt + \\sigma_{LV}(t, S_t) S_t dW_t^{Q}\n\\tag{1}\\]\nwhere \\(\\sigma_{LV}(t,S_t)\\) is a deterministic function of the variables \\((S_t,t)\\).\nThe function \\(\\sigma_{LV}(t,s)\\) such that the call option prices are given by the model in Equation 1 coinicide with the market option prices \\(\\hat{C}(K,T)\\) is called local volatility."
  },
  {
    "objectID": "posts/dupire-pde/index.html#digression---breeden-litzenberger-formula",
    "href": "posts/dupire-pde/index.html#digression---breeden-litzenberger-formula",
    "title": "A short note on the Dupire PDE",
    "section": "Digression - Breeden-Litzenberger Formula",
    "text": "Digression - Breeden-Litzenberger Formula\nAssume that \\((S_t,t\\geq 0)\\) is a markov process with the density \\(p(t,s,T,S_T)\\) conditioned on \\(S_t = s\\). Then:\n\\[\n\\begin{align*}\nC(s,t,T,K) &= e^{-r(T-t)}\\int_0^\\infty p(t,s,T,S_T) (S_T - K)^{+} dS_T \\\\\n&=  e^{-r(T-t)}\\int_K^\\infty p(t,s,T,y) (y - K) dy \\\\\n\\end{align*}\n\\tag{10}\\]\nDifferentiating with respect to \\(K\\), we have:\n\\[\n\\begin{align*}\n\\frac{\\partial C}{\\partial K} &= e^{-r(T-t)}\\left[\\left.p(t,s,T,y) (y - K)\\right\\vert_{y=\\infty} - \\left.p(t,s,T,y) (y - K)\\right\\vert_{y=K} + \\int_{K}^\\infty p(t,s,T,y) \\frac{\\partial}{\\partial K}(y-k)dy\\right] \\\\\n&= -e^{-r(T-t)} \\int_{K}^\\infty p(t,s,T,y) dy\n\\end{align*}\n\\]\nDifferentiating again with respect to \\(K\\) and applying the Leibnitz rule:\n\\[\n\\begin{align*}\n\\frac{\\partial^2 C}{\\partial K^2} &= - e^{-r(T-t)} [ p(t,s,T,y)|_{y=\\infty} -  p(t,s,T,y)|_{y=K}]\\\\\n&= e^{-r(T-t)}p(t,s,T,K)\n\\end{align*}\n\\]\nFinally, we have:\n\\[\n\\boxed{\\frac{\\partial^2 C}{\\partial K^2} = e^{-r(T-t)}p(t,s,T,K)}\n\\tag{11}\\]\nBreeden & Litzenberger(1978), showed that this second-order partial derivative can be used to approximate the option-implied risk-neutral probability that the underlying asset price \\(S\\) will be equal to the strike \\(K\\) at maturity."
  },
  {
    "objectID": "posts/dupire-pde/index.html#no-arbitrage-conditions",
    "href": "posts/dupire-pde/index.html#no-arbitrage-conditions",
    "title": "A short note on the Dupire PDE",
    "section": "No-arbitrage conditions",
    "text": "No-arbitrage conditions\nThe volatility surface, or equivalently the Call prices surface cannot have any arbitrary shape. Peter Carr has shown that static arbitrage is avoided in a set of option prices, if the calendar spread and butterfly spread arbitrages are avoided.\n\nCalendar spread condition\nCalendar spread arbitrage is usually expressed as the monotonicity of the European call option prices \\(C\\) with respect to the maturity \\(T\\). I closely follow the derivation in Fengler(2005).\n\nProposition 1 (Calendar Arbitrage) Define forward-moneyness \\(k \\stackrel{def}{=} K/F(t,T)\\), where the forward price is given by \\(F(t,T) = S_t e^{\\int_t^T r(u)du}\\) and total variance as \\(\\nu^2(k,\\tau) = \\hat{\\sigma}^2(k,\\tau)\\tau\\).\nIf \\(\\nu^2(k,\\tau_i)\\) is a strictly increasing function of \\(\\tau_i = T_i - t\\), \\(i=1,2\\), there is no calendar arbitrage.\n\nProof.\nGiven two expiry dates \\(t &lt; T_1 &lt; T_2\\), construct in \\(t\\), the following calendar spread in two calls with the same forward-moneyness: a long position in a call \\(C_t(K_2, T_2)\\) and a short position in \\(C_t(K_1,T_1)\\) call. The forward-moneyness requirement implies that:\n\\[\n\\begin{align*}\n\\frac{K_1}{F(t,T_1)} &= \\frac{K_2}{F(t,T_2)}\\\\\nK_1 &= e^{-\\int_{T_1}^{T_2}r(u)du} K_2\n\\end{align*}\n\\tag{12}\\]\nIn \\(T_1\\), if \\(S_{T_1} \\leq K_1\\) the short option position struck at \\(K_1\\) expires worthless while \\(C_{T_1}(K_2,T_2)\\geq 0\\), because it still has some time-value of money. Otherwise, the entire portfolio is worth \\(C_{T_1}(K_2,T_2) - (S_{T_1} - K_1)\\). But, Equation 12 implies that the portfolio is worth \\(C_{T_1}(K_2,T_2) - (S_{T_1} - K_2 e^{-\\int_{T_1}^{T_2} r(u) du})\\) which equals \\(P_{T_1}(K_2,T_2)\\) by put-call parity. Thus, the payoff of this portfolio is always non-negative.\nIn order to preclude arbitrage, at time \\(t \\leq T_1 &lt; T_2\\) we must have:\n\\[\n\\begin{align*}\nC_t(K_2,T_2) - C_t(K_1,T_1) &&gt; 0\\\\\nC_t(K_2,T_2) &&gt; C_t(K_1,T_1)\n\\end{align*}\n\\]\nMultiplying by \\(e^{\\int_0^{T_2} r_u du}\\) and dividing by \\(K_2\\) yields:\n\\[\n\\begin{align*}\n\\frac{e^{\\int_0^{T_2} r_u du}C_t(K_2,T_2)}{K_2} &&gt; \\frac{e^{\\int_0^{T_2} r_u du}C_t(K_1,T_1)}{K_2}\\\\\n&= \\frac{e^{\\int_0^{T_2} r_u du}C_t(K_1,T_1)}{K_1 e^{\\int_{T_1}^{T_2}r_u du}}\\\\\n\\end{align*}\n\\]\nSo, we have the condition:\n\\[\n\\begin{align*}\n\\boxed{\\frac{e^{\\int_0^{T_2} r_u du}C_t(K_2,T_2)}{K_2} &gt;  \\frac{e^{\\int_0^{T_1} r_u du}C_t(K_1,T_1)}{K_1}}\n\\end{align*}\n\\tag{13}\\]\nFinally, we observe that the function:\n\\[\n\\begin{align*}\nf(k,\\nu^2) &\\stackrel{def}{=} \\frac{e^{\\int_{0}^T r_u du}C_t^{BS}(K,T)}{K}\\\\\n&= \\frac{F(0,T)\\Phi(d_{+})}{K} - \\Phi(d_{-})\\\\\n&= k^{-1}\\Phi(d_{+}) - \\Phi(d_{-})\n\\end{align*}\n\\]\nis a function in \\(k\\) and \\(\\nu^2\\) only, and, for a fixed \\(k\\), is a strictly monotone increasing function in \\(\\nu^2\\), since\n\\[\n\\begin{align*}\nd_{\\pm} &= \\frac{\\ln(\\frac{1}{k})\\pm \\frac{\\nu^2}{2}}{\\sqrt{\\nu^2}}\\\\\n\\frac{\\partial d_{+}}{\\partial \\nu^2} &=\\frac{\\sqrt{\\nu^2} \\cdot \\frac{1}{2} - \\left(-\\ln k + \\frac{\\nu^2}{2}\\right)\\cdot \\frac{1}{2\\sqrt{\\nu^2}}}{\\nu^2}\\\\\n&= \\frac{\\frac{\\sqrt{\\nu^2}}{2} - \\frac{d_{+}}{2}}{\\nu^2}\\\\\n\\frac{\\partial d_{-}}{\\partial \\nu^2} &= \\frac{-\\frac{\\sqrt{\\nu^2}}{2} - \\frac{d_{-}}{2}}{\\nu^2}\\\\\n\\frac{\\partial d_{+}}{\\partial \\nu^2} - \\frac{\\partial d_{-}}{\\partial \\nu^2} &= \\frac{1}{2\\sqrt{\\nu^2}}\n\\end{align*}\n\\]\nAlso observe that:\n\\[\n\\begin{align*}\n\\frac{\\phi(d_{+})}{\\phi(d_{-})} &= \\exp\\left[-\\frac{1}{2}(d_{+}^2 - d_{-}^2)\\right]\\\\\n&= \\exp\\left[-\\frac{1}{2}(d_{+} + d_{-})(d_{+} - d_{-})\\right]\\\\\n&= \\exp\\left[-\\frac{1}{2}\\left(\\frac{-\\ln k + \\nu^2/2}{\\sqrt{\\nu^2}} + \\frac{-\\ln k - \\nu^2/2}{\\sqrt{\\nu^2}}\\right)\\left(\\frac{-\\ln k + \\nu^2/2}{\\sqrt{\\nu^2}} - \\frac{-\\ln k - \\nu^2/2}{\\sqrt{\\nu^2}}\\right)\\right]\\\\\n&= \\exp\\left[\\left(\\frac{\\ln k}{\\sqrt{\\nu^2}}\\right)\\sqrt{\\nu^2}\\right]\\\\\n&= k\n\\end{align*}\n\\]\nSo, \\(\\phi(d_{+}) = k \\phi(d_{-})\\). Also, recall that \\(d_{+} = d_{-} + \\sqrt{\\nu^2}\\). Putting it all together, we have:\n\\[\n\\begin{align*}\n\\frac{\\partial f}{\\partial \\nu^2} &= k^{-1}\\phi(d_{+}) (\\partial d_{+}/\\partial \\nu^2) - \\phi(d_{-})(\\partial d_{-}/\\partial \\nu^2) \\\\\n&= \\phi(d_{-}) \\cdot \\left(\\frac{\\partial d_{+}}{\\partial \\nu^2} - \\frac{\\partial d_{-}}{\\partial \\nu^2}\\right)\\\\\n&= \\phi(d_{-})\\frac{1}{2\\sqrt{\\nu^2}} &gt; 0, \\quad \\forall \\nu^2 \\in (0,\\infty)\n\\end{align*}\n\\]\nWe conclude that \\(f\\) is strictly monotonically increasing in \\(\\nu^2\\). So, if total variance \\(\\nu^2 = \\sigma^2(k,\\tau)\\) is increasing, \\(f(k,\\nu^2)\\), that is the undiscounted call option price scaled by the strike price \\(K\\) is increasing and from Equation 13, it follows that there is no calendar arbitrage.\nThe equation Equation 13 is the discrete version of the calendar spread no-arbitrage condition. We can also \\(\\blacksquare\\)\n\n\nButterfly spread arbitrage\nWe can write:\n\\[\n\\begin{align*}\n\\frac{\\partial^2 C}{\\partial K^2} = \\lim_{\\epsilon \\to 0} \\frac{C(K-\\epsilon,T) - 2C(K,T) + C(K+\\epsilon, T)}{\\epsilon^2}\n\\end{align*}\n\\]\nConsider the European payoff consisting of \\(\\frac{1}{\\epsilon^2}\\) calls of strike \\(K - \\epsilon\\), \\(1/\\epsilon^2\\) calls of strike \\(K+\\epsilon\\) and \\(-2/\\epsilon^2\\) calls of strike \\(K\\) - this is known as the butterfly spread.\nThe payout at maturity as a function of \\(S_T\\) has a triangular shape whose surface area is unity : it vanishes for \\(S_T \\leq K - \\epsilon\\) and \\(S_T \\geq K + \\epsilon\\) and is equal to \\(1/\\epsilon\\) for \\(S_T = K\\). For \\(\\epsilon \\to 0\\), it becomes a Dirac-Delta function. It either vanishes or is strictly positive dependending on \\(S_T\\). Hence, its price at inception must be positive.\nOptions prices are arbitraged well-enough that butterfly spreads do not have negative prices : the denominator in the Dupire formula is positive.\nBy the Breeden-Litzenberger formula Equation 11, \\(\\frac{d^2 C(K,T)}{dK^2}\\) is related to the probability density of \\(S_T\\), which must be positive. Hence, the condition \\(\\frac{d^2 C(K,T)}{dK^2} &gt; 0\\) is equivalent to requiring that the market implied risk-beutral probabilities are not negative. Violation of the positivity of \\(d^2 C/dK^2\\) is called butterfly-spread arbitrage.\n\n\nCall option price bounds\nFrom Equation 10, we have:\n\\[\n\\frac{\\partial C}{\\partial K} = -e^{-r\\tau} \\int_{K}^{\\infty}p(s,t,y,T)dy\n\\]\nFrom the positivity of the integral \\(\\int_{K}^{\\infty}p(s,t,y,T)dy &gt; 0\\), we must have:\n\\[\n\\frac{\\partial C}{\\partial K} \\leq 0\n\\]\nFurther, using the fact \\(\\int_{-\\infty}^{\\infty}p(s,t,y,T)dy = 1\\), we have:\n\\[\n\\begin{align*}\ne^{-r\\tau}\\int_{K}^{\\infty}p(s,t,y,T)dy &\\leq e^{-r\\tau} \\int_{K}^{\\infty}p(s,t,y,T)dy = e^{-r\\tau} \\\\\n-e^{-r\\tau}\\int_{K}^{\\infty}p(s,t,y,T)dy \\frac{\\partial C}{\\partial K}\\geq -e^{-r\\tau}\n\\end{align*}\n\\]\nPutting it together, we have:\n\\[\n\\boxed{-e^{-r\\tau} \\leq \\frac{\\partial C}{\\partial K} \\leq 0}\n\\tag{14}\\]\nThe option price is a decreasing and convex function of the strike \\(K\\)."
  },
  {
    "objectID": "posts/dupire-pde/index.html#dupire-pde-in-terms-of-forward-moneyness",
    "href": "posts/dupire-pde/index.html#dupire-pde-in-terms-of-forward-moneyness",
    "title": "A short note on the Dupire PDE",
    "section": "Dupire PDE in terms of forward moneyness",
    "text": "Dupire PDE in terms of forward moneyness\nLet the log forward-moneyness be defined as \\(y = \\ln(K/F)\\). We need to transform the derivatives of the Dupire formula in terms of forward-moneyness.\nThe deterministic local volatility function is given by:\n\\[\n\\sigma_{K,T}^2(S_t,t) = \\frac{\\frac{\\partial C^u_{K,T}}{\\partial T} + rK\\frac{\\partial C^u_{K,T}}{\\partial K} - rC^u_{K,T}}{\\frac{1}{2}K^2 \\frac{\\partial^2 C^u_{K,T}}{\\partial K^2}}\n\\]\nThe first derivative with respect to time \\(T\\) is obtained using the total derivative rule. Imagine that the undiscounted call option price is a function of two intermediate variables \\(a,b\\) which are in turn a function of \\(T\\). That is, \\(C^u = C^u(a(T),b(T))\\). Then:\n\\[\n\\begin{align*}\n\\frac{\\partial C^u}{\\partial T}({a(T),b(T)}) &= \\left.\\frac{\\partial C^u}{\\partial a}\\right\\vert_{b} \\cdot \\frac{\\partial a}{\\partial T} + \\left.\\frac{\\partial C^u}{\\partial b}\\right\\vert_{a}  \\cdot \\frac{\\partial b}{\\partial T}  \n\\end{align*}\n\\]\nwhere \\(\\vert_{a}\\) indicates that \\(a\\) is treated as a constant. For the undiscounted call option price \\(C^u = C^u(y(K,T),T)\\), so \\(a(T) = y(K,T)\\) and \\(b(T) = T\\). So, we have:\n\\[\n\\begin{align*}\n\\frac{\\partial C^u}{\\partial T}({y(K,T),T}) &= \\left.\\frac{\\partial C^u}{\\partial y}\\right\\vert_{T} \\cdot \\frac{\\partial y}{\\partial T} + \\left.\\frac{\\partial C^u}{\\partial T}\\right\\vert_{y}  \\cdot \\frac{\\partial T}{\\partial T} \\\\\n&= \\left.\\frac{\\partial C^u}{\\partial y}\\right\\vert_{T} \\cdot \\frac{\\partial y}{\\partial T} + \\left.\\frac{\\partial C^u}{\\partial T}\\right\\vert_{y}  \\\\\n\\end{align*}\n\\]\nNow,\n\\[\n\\begin{align*}\ny(K,T) &= (-rT)+\\ln\\left(\\frac{K}{S_0}\\right)\\\\\n\\frac{\\partial y}{\\partial T} &= (-r)\n\\end{align*}\n\\]\nThus,\n\\[\n\\frac{\\partial C^u}{\\partial T} = -r\\left.\\frac{\\partial C^u}{\\partial y}\\right\\vert_{T}  + \\left.\\frac{\\partial C^u}{\\partial T}\\right\\vert_{y}  \\\\\n\\tag{15}\\]\nUsing the chain rule, the first derivative with respect to \\(K\\) is:\n\\[\n\\begin{align*}\n\\frac{\\partial C^u}{\\partial K} &= \\frac{\\partial C^u}{\\partial y} \\cdot \\frac{\\partial y}{\\partial K} \\\\\n&= \\frac{\\partial C^u}{\\partial y} \\cdot \\frac{\\partial }{\\partial K} \\ln\\left(\\frac{K}{F_t}\\right)\\\\\n&= \\frac{\\partial C^u}{\\partial y} \\cdot \\frac{F}{K} \\cdot \\frac{\\partial}{\\partial K} \\left(\\frac{K}{F_t}\\right)\\\\\n&= \\frac{1}{K} \\frac{\\partial C^u}{\\partial y}\n\\end{align*}\n\\tag{16}\\]\nDifferentiating again with respect to \\(K\\), we have:\n\\[\n\\begin{align*}\n\\frac{\\partial^2 C^u}{\\partial K^2} &= \\frac{\\partial}{\\partial K} \\left(\\frac{1}{K} \\frac{\\partial C^u}{\\partial y}\\right) \\\\\n&= -\\frac{1}{K^2} \\frac{\\partial C^u}{\\partial y} + \\frac{1}{K} \\frac{\\partial}{\\partial K} \\left(\\frac{\\partial C^u}{\\partial y}\\right)\\\\\n&= -\\frac{1}{K^2} \\frac{\\partial C^u}{\\partial y} + \\frac{1}{K} \\frac{\\partial}{\\partial y} \\left(\\frac{\\partial C^u}{\\partial y}\\right)\\frac{\\partial y}{\\partial K}\\\\\n&= -\\frac{1}{K^2} \\frac{\\partial C^u}{\\partial y} + \\frac{1}{K^2}\\frac{\\partial^2 C^u}{\\partial y^2}\\\\\n&=\\frac{1}{K^2}\\left(\\frac{\\partial^2 C^u}{\\partial y^2} - \\frac{\\partial C^u}{\\partial y}\\right)\n\\end{align*}\n\\tag{17}\\]\nSubstituting Equation 15, Equation 16 and Equation 17 in the expression for local volatility, we have:\n\\[\n\\begin{align*}\n\\sigma_{K,T}^2(S_t,t) &= \\frac{-r \\left.\\frac{\\partial C^u_{y,T}}{\\partial y}\\right\\vert_{T} + \\left.\\frac{\\partial C^u_{y,T}}{\\partial T}\\right\\vert_{y} + rK\\frac{\\partial C^u_{y,T}}{\\partial y} \\cdot \\frac{1}{K} - rC^u_{y,T}}{\\frac{1}{2}K^2 \\frac{1}{K^2}\\cdot \\left(\\frac{\\partial^2 C^u}{\\partial y^2} - \\frac{\\partial C^u}{\\partial y}\\right)}\\\\\n&= \\frac{ \\left.\\frac{\\partial C^u_{y,T}}{\\partial T}\\right\\vert_{y} +  - rC^u_{y,T}}{\\frac{1}{2} \\left(\\frac{\\partial^2 C^u}{\\partial y^2} - \\frac{\\partial C^u}{\\partial y}\\right)}\\\\\n\\frac{\\partial C^u_{y,T}}{\\partial T} &= rC^u_{y,T} + \\frac{\\sigma_{y,T}^2}{2}\\left(\\frac{\\partial^2 C^u_{y,T}}{\\partial y^2} - \\frac{\\partial C^u_{y,T}}{\\partial y}\\right)\n\\end{align*}\n\\]"
  },
  {
    "objectID": "posts/dupire-pde/index.html#local-volatility-in-terms-of-implied-volatility",
    "href": "posts/dupire-pde/index.html#local-volatility-in-terms-of-implied-volatility",
    "title": "A short note on the Dupire PDE",
    "section": "Local volatility in terms of implied volatility",
    "text": "Local volatility in terms of implied volatility\nSince options can also be quoted in terms of implied volatility, the local volatility may also be expressed in terms of the total variance \\(w(y,T)\\). Define:\n\\[\nw(y,T) = \\Sigma^2(y,T) T\n\\]\nwhere \\(\\Sigma(y,T)\\) is the Black-Scholes implied volatility as a function of forward-moneyness and time-to-maturity \\(T\\).\nWe know that the Black-Scholes formula for the future value of the call-option price is:\n\\[\nC_{BS}(y,w) = F\\left(\\Phi\\left(-\\frac{y}{\\sqrt{w}}+\\frac{\\sqrt{w}}{2}\\right) - e^y\\Phi\\left(-\\frac{y}{\\sqrt{w}}-\\frac{\\sqrt{w}}{2}\\right)\\right)\n\\]\nDifferentiating with respect to \\(w\\), we have:\n\\[\n\\begin{aligned}\n\\frac{\\partial C_{BS}}{\\partial w} & =F_{T}\\left\\{\\phi \\left( -\\frac{y}{\\sqrt{w}} +\\frac{\\sqrt{w}}{2}\\right)\\frac{\\partial }{\\partial w}\\left( -\\frac{y}{\\sqrt{w}} +\\frac{\\sqrt{w}}{2}\\right) -e^{y} \\phi \\left( -\\frac{y}{\\sqrt{w}} -\\frac{\\sqrt{w}}{2}\\right)\\frac{\\partial }{\\partial w}\\left( -\\frac{y}{\\sqrt{w}} -\\frac{\\sqrt{w}}{2}\\right)\\right\\}\\\\\n& =F_{T}\\left\\{\\phi \\left( -\\frac{y}{\\sqrt{w}} +\\frac{\\sqrt{w}}{2}\\right)\\left(\\frac{y}{2w^{3/2}} +\\frac{1}{4w^{1/2}}\\right) -e^{y} \\phi \\left( -\\frac{y}{\\sqrt{w}} -\\frac{\\sqrt{w}}{2}\\right)\\left(\\frac{y}{2w^{3/2}} -\\frac{1}{4w^{1/2}}\\right)\\right\\}\\\\\n& =F_{T}\\left\\{\\phi \\left( -\\frac{y}{\\sqrt{w}} +\\frac{\\sqrt{w}}{2}\\right)\\left(\\frac{y}{2w^{3/2}} +\\frac{1}{4w^{1/2}}\\right) -\\left(\\frac{y}{2w^{3/2}} -\\frac{1}{4w^{1/2}}\\right)\\right\\}\\\\\n& =F_{T} \\phi \\left( -\\frac{y}{\\sqrt{w}} +\\frac{\\sqrt{w}}{2}\\right) \\cdotp \\frac{1}{2w^{1/2}}\n\\end{aligned}\n\\tag{18}\\]\nDifferentiating again with respect to \\(w\\):\n\\[\n\\begin{aligned}\n\\frac{\\partial ^{2} C_{BS}}{\\partial w^{2}} & =F_{T}\\frac{\\partial }{\\partial w}\\left( \\phi ( d_{+}) \\cdotp \\frac{1}{2w^{1/2}}\\right)\\\\\n& =F_{T}\\left[\\frac{1}{2w^{1/2}}\\frac{\\partial }{\\partial w}( \\phi ( d_{+})) +\\phi ( d_{+})\\frac{\\partial }{\\partial w}\\left(\\frac{1}{2w^{1/2}}\\right)\\right]\\\\\n& =F_{T}\\left[\\frac{1}{2w^{1/2}} \\phi ( d_{+})\\frac{\\partial }{\\partial w}\\left( -\\frac{d_{+}^{2}}{2}\\right) -\\phi ( d_{+})\\frac{1}{4w^{3/2}}\\right]\\\\\n& =F_{T}\\frac{\\phi ( d_{+})}{2w^{1/2}}\\left[\\frac{\\partial }{\\partial w}\\left( -\\frac{d_{+}^{2}}{2}\\right) -\\frac{1}{2w}\\right]\\\\\n& =\\frac{\\partial C_{BS}}{\\partial w}\\left[ -d_{+}\\frac{\\partial d_{+}}{\\partial w} -\\frac{1}{2w}\\right]\\\\\n& =\\frac{\\partial C_{BS}}{\\partial w}\\left[ -\\left( -\\frac{y}{w^{1/2}} +\\frac{w^{1/2}}{2}\\right)\\left(\\frac{y}{2w^{3/2}} +\\frac{1}{4w^{1/2}}\\right) -\\frac{1}{2w}\\right]\\\\\n& =\\frac{\\partial C_{BS}}{\\partial w}\\left[\\frac{y^{2}}{2w^{2}} +\\frac{y}{4w} -\\frac{y}{4w} -\\frac{1}{8} -\\frac{1}{2w}\\right]\\\\\n& =\\frac{\\partial C_{BS}}{\\partial w}\\left(\\frac{y^{2}}{2w^{2}} -\\frac{1}{2w} -\\frac{1}{8}\\right)\n\\end{aligned}\n\\tag{19}\\]\nAlso, the mixed partial \\(\\partial_{wy} C_{BS}\\) is given by:\n\\[\n\\begin{aligned}\n\\frac{\\partial ^{2} C_{BS}}{\\partial w\\partial y} & =\\frac{F_{T}}{2w^{1/2}}\\frac{\\partial }{\\partial y}\\left\\{\\phi \\left( -\\frac{y}{\\sqrt{w}} +\\frac{\\sqrt{w}}{2}\\right)\\right\\}\\\\\n& =\\frac{F_{T}}{2w^{1/2}} \\phi \\left( -\\frac{y}{\\sqrt{w}} +\\frac{\\sqrt{w}}{2}\\right)\\frac{\\partial }{\\partial y}\\left( -\\frac{d_{+}^{2}}{2}\\right)\\\\\n& =\\frac{\\partial C_{BS}}{\\partial w}\\frac{\\partial }{\\partial d_{+}}\\left( -\\frac{d_{+}^{2}}{2}\\right)\\frac{\\partial d_{+}}{\\partial y}\\\\\n& =-\\frac{\\partial C_{BS}}{\\partial w}\\left( -\\frac{y}{w^{1/2}} +\\frac{w^{1/2}}{2}\\right)\\left( -\\frac{1}{\\sqrt{w}}\\right)\\\\\n& =\\frac{\\partial C_{BS}}{\\partial w}\\left(\\frac{1}{2} -\\frac{y}{w}\\right)\n\\end{aligned}\n\\tag{20}\\]\nAdditionally, the partial derivatives of the Black-Scholes formula with respect to \\(y\\) are:\n\\[\n\\begin{aligned}\n\\frac{\\partial C_{BS}}{\\partial y} & =F_{T}\\frac{\\partial }{\\partial y}\\left\\{\\Phi \\left( -\\frac{y}{\\sqrt{w}} +\\frac{\\sqrt{w}}{2}\\right) -e^{y} \\Phi \\left( -\\frac{y}{\\sqrt{w}} -\\frac{\\sqrt{w}}{2}\\right)\\right\\}\\\\\n& =F_{T} \\cdot \\left[ \\phi \\left( -\\frac{y}{\\sqrt{w}} +\\frac{\\sqrt{w}}{2}\\right)\\frac{\\partial d_{+}}{\\partial y} -e^{y} \\Phi \\left( -\\frac{y}{\\sqrt{w}} -\\frac{\\sqrt{w}}{2}\\right)\\right]\\\\\n& -F_{T}\\left[ e^{y} \\phi \\left( -\\frac{y}{\\sqrt{w}} -\\frac{\\sqrt{w}}{2}\\right)\\frac{\\partial d_{-}}{\\partial y}\\right]\\\\\n& =F_{T} \\cdot \\left[ \\phi \\left( -\\frac{y}{\\sqrt{w}} +\\frac{\\sqrt{w}}{2}\\right)\\left( -\\frac{1}{\\sqrt{w}}\\right) -e^{y} \\Phi \\left( -\\frac{y}{\\sqrt{w}} -\\frac{\\sqrt{w}}{2}\\right)\\right]\\\\\n& -F_{T}\\left[ e^{y} \\phi \\left( -\\frac{y}{\\sqrt{w}} -\\frac{\\sqrt{w}}{2}\\right)\\left( -\\frac{1}{\\sqrt{w}}\\right)\\right]\\\\\n& =-\\frac{F_{T}}{\\sqrt{w}} \\cdot \\left[ \\phi ( d_{+}) -e^{y} \\phi ( d_{-})\\right]\\\\\n& -F_{T} e^{y} \\Phi ( d_{-})\\\\\n& =-F_{T} e^{y} \\Phi ( d_{-})\n\\end{aligned}\n\\tag{21}\\]\nAlso:\n\\[\n\\begin{aligned}\n\\frac{\\partial ^{2} C_{BS}}{\\partial y^{2}} & =-F_{T}\\frac{\\partial }{\\partial y}\\left( e^{y} \\Phi ( d_{-})\\right)\\\\\n& =-F_{T}\\left( e^{y} \\Phi ( d_{-}) +e^{y} \\phi ( d_{-})\\frac{\\partial d_{-}}{\\partial y}\\right)\\\\\n& =-F_{T} e^{y} \\Phi ( d_{-}) +\\frac{F_{T} e^{y} \\phi ( d_{-})}{\\sqrt{w}}\\\\\n& =\\frac{\\partial C_{BS}}{\\partial y} +2\\frac{\\partial C_{BS}}{\\partial w}\n\\end{aligned}\n\\tag{22}\\]\nNow, the undiscounted call option price \\(C^u(y,T) = C_{BS}(y(T),w(y,T))\\) is a function of the intermediate variables \\((y,w)\\). So, we may write:\n\\[\n\\begin{aligned}\nC^u(y,T) &= C_{BS}(w(y),y)\\\\\nC^u_y(y,T) &= (C_{BS})_w \\cdot w_y + (C_{BS})_y\n\\end{aligned}\n\\]\n\\[\n\\begin{aligned}\nC_{yy} &= \\frac{\\partial}{\\partial y}\\left((C_{BS})_w \\cdot w_y + (C_{BS})_y\\right)\\\\\n&=\\frac{\\partial}{\\partial y}\\left[(C_{BS})_w \\cdot w_y\\right] + \\frac{\\partial}{\\partial y}((C_{BS})_y)\\\\\n&=\\left[\\frac{\\partial}{\\partial y}\\{(C_{BS})_w\\} \\cdot w_y + (C_{BS})_w \\cdot w_{yy}\\right] + (C_{BS})_{yy} + (C_{BS})_{yw} \\cdot w_y\\\\\n&=\\left[\\{(C_{BS})_{ww} \\cdot w_y + (C_{BS})_{wy}\\} \\cdot w_y + (C_{BS})_w \\cdot w_{yy}\\right] + (C_{BS})_{yy} + (C_{BS})_{yw} \\cdot w_y\\\\\n&= (C_{BS})_{yy} + 2(C_{BS})_{wy} \\cdot w_y + (C_{BS})_{ww} \\cdot (w_y)^2 + (C_{BS})_w \\cdot w_{yy}\n\\end{aligned}\n\\]\n\\[\n\\begin{align*}\n\\left.\\frac{\\partial C_u(y,T)}{\\partial T}\\right|_y &= \\left.\\frac{\\partial C_{BS}(w(y,T),T)}{\\partial T}\\right|_{w} \\cdot \\frac{\\partial T}{\\partial T} + \\frac{\\partial C_{BS}}{\\partial w} \\cdot \\frac{\\partial w}{\\partial T}\\\\\n&= rC_{BS} + \\frac{\\partial C_{BS}}{\\partial w} \\cdot \\frac{\\partial w}{\\partial T}\\\\\n\\end{align*}\n\\]\nwhere the last equality follows from the fact that the only explicit dependence of the option price on \\(T\\) is through the forward price \\(F_T = S_0 \\exp(\\int_0^T r dt)\\).\nSubstituting these results in the Dupire’s formula:\n\\[\n\\begin{align*}\n\\frac{\\partial C^u(y,T)}{\\partial T} &= rC^u(y,T) + \\frac{\\sigma^2(y,T)}{2}\\left(\\frac{\\partial^2 C_u(y,T)}{\\partial y^2} - \\frac{\\partial C_u(y,T)}{\\partial y}\\right)\\\\\nrC_{BS} + (C_{BS})_w \\cdot w_T &= rC_{BS} + \\sigma_{LV}^2/2((C_{BS})_{yy} + 2(C_{BS})_{wy} \\cdot w_y + (C_{BS})_{ww} \\cdot (w_y)^2 + (C_{BS})_w \\cdot w_{yy}- (C_{BS})_y)\\\\\n(C_{BS})_w \\cdot w_T &= \\sigma_{LV}^2/2[((C_{BS})_{yy} - (C_{BS})_y) + 2(C_{BS})_{wy} \\cdot w_y  + (C_{BS})_{ww} \\cdot (w_y)^2 + (C_{BS})_w \\cdot w_{yy}-(C_{BS})_w \\cdot w_y]\\\\\n(C_{BS})_w \\cdot w_T &= \\sigma_{LV}^2/2[2(C_{BS})_w + 2(C_{BS})_w \\left(\\frac{1}{2} - \\frac{y}{w}\\right)\\cdot w_y + \\left(\\frac{y^{2}}{2w^{2}} -\\frac{1}{2w} -\\frac{1}{8}\\right)(C_{BS})_w (w_y)^2 + (C_{BS})_w \\cdot w_{yy}-(C_{BS})_w \\cdot w_y]\\\\\nw_T &= \\sigma_{LV}^2/2[2 + 2 \\left(\\frac{1}{2} - \\frac{y}{w}\\right)\\cdot w_y + \\left(\\frac{y^{2}}{2w^{2}} -\\frac{1}{2w} -\\frac{1}{8}\\right)(w_y)^2 + w_{yy}-  w_y]\\\\\n\\sigma_{LV}^2 &= \\frac{w_T}{1 - \\frac{y}{w}w_y + \\frac{1}{4}\\left(\\frac{y^2}{2w^2} - \\frac{1}{w} - \\frac{1}{4}\\right)(w_y)^2 + \\frac{1}{2} w_{yy}}\n\\end{align*}\n\\]\nThis gives us our final result:\n\\[\n\\boxed{\\sigma_{LV}^2 = \\frac{\\frac{\\partial w}{\\partial T}}{1 - \\frac{y}{w}\\frac{\\partial w}{\\partial y} + \\frac{1}{4}\\left(\\frac{y^2}{2w^2} - \\frac{1}{w} - \\frac{1}{4}\\right)(\\frac{\\partial w}{\\partial y})^2 + \\frac{1}{2} \\frac{\\partial^2 w}{\\partial y^2}}}\n\\tag{23}\\]"
  },
  {
    "objectID": "posts/dupire-pde/index.html#implied-variance-is-the-average-of-local-variance-over-the-life-of-the-option-when-there-is-no-skew",
    "href": "posts/dupire-pde/index.html#implied-variance-is-the-average-of-local-variance-over-the-life-of-the-option-when-there-is-no-skew",
    "title": "A short note on the Dupire PDE",
    "section": "Implied variance is the average of local variance over the life of the option when there is no skew",
    "text": "Implied variance is the average of local variance over the life of the option when there is no skew\nIf the implied volatility \\(\\Sigma\\) is independent of the strike, then the skew \\(\\frac{\\partial w}{\\partial y}\\) is zero.\nSo, the Dupire’s formula becomes:\n\\[\n\\begin{align*}\n\\sigma_{LV}^2(w,T) &= \\frac{\\partial w}{\\partial T}\\\\\n\\Sigma^2(T) T &= \\int_{R} \\sigma_{LV}^2 (w,T) dT\\\\\n\\Sigma^2(T) &= \\frac{1}{T}\\int_{R} \\sigma_{LV}^2 (w,T) dT\\\\\n\\end{align*}\n\\]"
  },
  {
    "objectID": "posts/dupire-pde/index.html#references",
    "href": "posts/dupire-pde/index.html#references",
    "title": "A short note on the Dupire PDE",
    "section": "References",
    "text": "References\n\nA note sufficient conditions for no arbitrage, Peter Carr and Dilip Madan\nThe volatility surface - A practitioner’s guide, Jim Gatheral"
  },
  {
    "objectID": "posts/sampling-uniformly-on-the-unit-disk/index.html",
    "href": "posts/sampling-uniformly-on-the-unit-disk/index.html",
    "title": "Uniformly sampling from the unit disk",
    "section": "",
    "text": "I was asked this puzzle in a recent quant interview and thought it would be interesting to solve this. We are asked to generate points that are uniformly distributed on the unit circle. This is a really elegant question.\nA first approach would be to generate points from the unit square distribution - that is pick \\(U_1 \\sim U[0,1]\\) and \\(U_2 \\sim U[0,1]\\), and apply the transform \\(U_1' = -1 + 2U_1\\), \\(U_2' = -1 + 2U_2\\), so that the transformed random variables are \\(U[-1,1]\\). We then accept all points that satisfy \\(u_1'^2 + u_2'^2 \\leq 1\\) and reject all points that violate this condition. However, this is not computationally efficient as we are wasting \\(\\frac{4 - \\pi}{4} \\approx 20\\%\\) of the points.\nOne thing is, if you divide circle in concentric rings of size \\(\\Delta R\\), note that the further you are away from the origin, the more area the ring contains. However, we would like a distant ring to have the same density as a ring closer to the origin. So, we need to pick more points in the outer ring then in the inner ring. If we pick points with a probability proportional to the square of the distance from the origin, we should end up with a uniform scattering.\nLet \\(u = F(r) = r^2\\). So, \\(r = \\sqrt{u}\\). Thus, \\(R \\stackrel{def}{=} F^{-1}(U) = \\sqrt{U}\\) must have the CDF \\(F_R(r) = r^2\\) and density \\(f_R(r) = 2r\\). We also pick \\(\\Theta \\sim U[0,2\\pi]\\). If we project the point \\(\\left(r, \\theta \\right)\\) onto the \\(x\\)- and \\(y\\)-axis, then we have:\n\\[\n\\begin{align*}\nX &= \\sqrt{U} \\cos \\Theta\\\\\nY &= \\sqrt{U} \\sin \\Theta\\\\\n\\end{align*}\n\\]\nThen, we have:\n\\[\n\\begin{align*}\nf_{X,Y}(x,y) &= f_{R,\\Theta}(r(x,y),\\theta(x,y)) \\frac{\\partial(r,\\theta)}{\\partial(x,y)}\\\\\n&= 2r \\cdot \\frac{1}{2\\pi} \\left|\\begin{matrix}\n\\frac{\\partial}{\\partial x} \\frac{1}{\\sqrt{x^2 + y^2}} & \\frac{\\partial}{\\partial y} \\frac{1}{\\sqrt{x^2 + y^2}} \\\\\n\\frac{\\partial}{\\partial x} \\arctan (y/x) & \\frac{\\partial}{\\partial y} \\arctan (y/x)\n\\end{matrix}\\right|\\\\\n&= 2\\sqrt{x^2 + y^2} \\cdot \\frac{1}{2\\pi} \\left|\\begin{matrix}\n\\frac{x}{\\sqrt{x^2 + y^2}} & \\frac{y}{\\sqrt{x^2 + y^2}} \\\\\n-\\frac{y}{x^2 + y^2} & \\frac{x}{x^2 + y^2}\n\\end{matrix}\\right|.\\\\\n& = \\frac{1}{\\pi}\n\\end{align*}\n\\]\n\n\n\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport matplotlib.patches as patches\n\nu = np.random.uniform(low=0.0, high=1.0, size=10000)\nr = np.sqrt(u)\ntheta = 2*np.pi*np.random.uniform(low=0.0, high=1.0, size=10000)\nx = r * np.cos(theta)\ny = r * np.sin(theta)\n\n# Create fig and axes\nfig, ax = plt.subplots()\n\n# Use patches.Circle() to create the circle. The xy argument is a tuple for the center (x,y) and radius is a float\ncircle = patches.Circle((0.0, 0.0), radius = 1.0, fill=False)\n\n# Add the circle to the axes\nax.add_patch(circle)\n\n# Add the (x,y) samples to the axes using the 'scatter' method\nax.scatter(x, y, color='blue', s=2.5)\n\n# Ensure the aspect ratio is equal so the circle isn't distorted\nax.set_aspect('equal', adjustable='box')\n\n# Set the plot limits\nax.set_xlim(-1,1)\nax.set_ylim(-1,1)\n\nplt.title('Uniform sampling from the unit circle')\nplt.show()"
  },
  {
    "objectID": "posts/sampling-uniformly-on-the-unit-disk/index.html#numerical-simulation",
    "href": "posts/sampling-uniformly-on-the-unit-disk/index.html#numerical-simulation",
    "title": "Uniformly sampling from the unit disk",
    "section": "",
    "text": "import numpy as np\nimport matplotlib.pyplot as plt\nimport matplotlib.patches as patches\n\nu = np.random.uniform(low=0.0, high=1.0, size=10000)\nr = np.sqrt(u)\ntheta = 2*np.pi*np.random.uniform(low=0.0, high=1.0, size=10000)\nx = r * np.cos(theta)\ny = r * np.sin(theta)\n\n# Create fig and axes\nfig, ax = plt.subplots()\n\n# Use patches.Circle() to create the circle. The xy argument is a tuple for the center (x,y) and radius is a float\ncircle = patches.Circle((0.0, 0.0), radius = 1.0, fill=False)\n\n# Add the circle to the axes\nax.add_patch(circle)\n\n# Add the (x,y) samples to the axes using the 'scatter' method\nax.scatter(x, y, color='blue', s=2.5)\n\n# Ensure the aspect ratio is equal so the circle isn't distorted\nax.set_aspect('equal', adjustable='box')\n\n# Set the plot limits\nax.set_xlim(-1,1)\nax.set_ylim(-1,1)\n\nplt.title('Uniform sampling from the unit circle')\nplt.show()"
  },
  {
    "objectID": "posts/aad/index.html",
    "href": "posts/aad/index.html",
    "title": "AAD(Adjoint Algorithmic Differentiation)",
    "section": "",
    "text": "I was skimming through Luca Capriotti and Mike Giles’ paper 15 Years of Adjoint Algorithmic Differentiation in Finance and wanted to write a toy implementation in Julia. Algorithmic differentiation (AD) is a set of techniques to accurately and efficiently compute derivatives of a function in the form of a computer program. Many of my toy examples are borrowed from the excellent Algorithmic Differentiation in Finance Explained, by Marc Henrard.\n\n\nAs a quick example, suppose we have the scalar-valued function \\(f:\\mathbb{R}^{p_a} \\to \\mathbb{R}\\):\n\\[\ny = \\cos(x_1 + e^{x_2})(\\sin x_3 + \\cos x_4) + x_2^{3/2} + x_4\n\\]\nThe function inputs are a vector a[1...p_a] of dimension \\(p_a\\). All intermediate values in the program will be denoted by bs. The output of the function is denoted by the variable z of dimension \\(1\\). So, the algorithm starts with the inputs a, goes to z through a lot of bs. The new variables are denoted by b[j] with j starting with 1 and going upto \\(p_b\\). There are \\(p_b\\) intermediate variables \\(b\\) in the program.\n\n\n\nStandard algorithmic differentiation also called forward algorithmic differentiation or tangent algorithmic differentiation. Our goal is to compute \\(\\partial z/\\partial a_i\\). We achieve this by computing for each \\(j\\)(\\(p_a + 1 \\leq j \\leq p_b\\)) the value:\n\\[\n\\dot{b}[j,i] = \\frac{\\partial b[j]}{\\partial a[i]}\n\\]\nWe first initialize the variables \\(b[j]\\) from \\(1 \\leq j \\leq p_a\\) with the inputs values \\(a[j]\\). Note that the derivative is denoted by dot on the variable and \\(\\dot{b}[j,i]\\) is the derivative of \\(b[j]\\) with respect to some other variable \\(a[i]\\). For \\(j=1:p_a\\), then, the derivative of \\(b[j]\\) with respect to \\(a[i]\\) is simply \\(1\\), if \\(j=i\\) and \\(0\\) if \\(j \\neq i\\). This is the starting point of a recursive algorithm. The starting part is the identity matrix :\n\\[\n\\dot{b}[j,i] = \\delta_{i,j}\n\\]\nwhere \\(\\delta_{i,j}\\) represents Kronecker’s delta.\nThe successive derivatives \\(\\dot{b}[j,i]\\) are given by the chain rule:\n\\[\n\\begin{align*}\n\\dot{b}[j,i] = \\frac{\\partial b[j]}{\\partial a[i]} &= \\sum_{k=p_a + 1}^{k=j-1}\\frac{\\partial b[j]}{\\partial b[k]} \\cdot \\frac{\\partial b[k]}{\\partial a[i]}\\\\\n&= \\sum_{k=p_a + 1}^{j-1} \\frac{\\partial}{\\partial b[k]} (b[j]) \\cdot \\dot{b}[k,i]\\\\\n&= \\sum_{k=p_a + 1}^{j-1} \\frac{\\partial}{\\partial b[k]} g_j(b[p_a + 1 : j - 1]) \\cdot \\dot{b}[k,i]\\\\\n\\end{align*}\n\\]\nThe numbers \\(\\dot{b}[p_b,i]\\) are equal to the derivatives of \\(z=b[p_b]\\) with respect to \\(a_i\\), \\(1 \\leq i \\leq p_a\\). This concludes the algorithm for the computation of \\(\\partial z/\\partial a_i\\).\nThe requirements for such an implementation is that all the intermediary functions \\(g_j\\) have a derivative version. The algorithmic differentiation approach is a bottom-up approach : it can be implemented for an algorithm only if all the components below it, all the components entering into the composition have already been implemented.\n\n\n\nForward AD\n\n\n\n\n\n\nfunction f(a::Array{Real})\n    b = zeros(4)\n    b[1] = a[1] + exp(a[2])\n    b[2] = sin(a[3]) + cos(a[4])\n    b[3] = a[2] ^ (3/2) + a[4]\n    b[4] = cos(b[1]) * b[2] + b[3]\n    b[4]\nend\n\nf (generic function with 1 method)\n\n\nWe create an AD version of the starter function as follows:\n\nfunction f_AD(x::Array{Real})\n    b = zeros(4)\n    b[1] = a[1] + exp(a[2])\n    b[2] = sin(a[3]) + cos(a[4])\n    b[3] = a[2] ^ (3/2) + a[4]\n    b[4] = cos(b[1]) * b[2] + b[3]\n    \n    # Forward sweep - derivatives\n    n = length(x)\n\n    b1dot = zeros(n)\n    b1dot[1] = 1\n    b1dot[2] = exp(b[2])\n\n    b2dot = zeros(n)\n    b2dot[3] = cos(b[3])\n    b2dot[4] = -sin(b[4])\n\n    b3dot = zeros(n)\n    b3dot[2] = (3/2)*(b[2] ^ (1/2))\n    b3dot[4] = 1\n\n    b4dot = b[2] * -sin(b[1]) * b1dot + cos(b[1]) * b2dot + b3dot\n    (b[4],b4dot)\nend\n\nf_AD (generic function with 1 method)\n\n\nNote that, the output of the original function f is the function value - a double, whilst the output f_ad is a 2-tuple : the function value and the value of the jacobian(gradient).\n\n\n\nOur goal is to compute \\(\\frac{\\partial z}{\\partial a_i}\\). We achieve this by computing for each intermediate variable \\(j\\) (\\(p_a + 1 \\leq j \\leq p_b\\)) the value:\n\\[\n\\overline{b}[j] = \\frac{\\partial z}{\\partial b[j]}\n\\]\nNote that, \\(\\overline{b}[j]\\) is the derivative of the output with respect to b[j]. It is important to switch the perception between the forward mode and the reverse mode. What is fixed in the reverse approach is the output, we always compute the derivative of the same variable, the output.\nThe starting point of the algorithm is easy. For \\(j = p_b\\), the derivative of \\(z\\) with respect to \\(b[j]\\) is simply the derivative of \\(z\\) with respect to itself, which is \\(1\\). This is the starting point of a recursive algorithm.\nFrom there, we read the code in reverse order and just apply the chain rule. Each intermediary variable \\(b[j]\\) is used only in the lines of code that follow in the computation. The derivative \\(\\overline{b}[j]\\) is given by:\n\\[\n\\overline{b}[j] = \\frac{\\partial z}{\\partial b_j} = \\sum_{k=j+1}^{p_b} \\frac{\\partial z}{\\partial b_k} \\cdot \\frac{\\partial b_k}{\\partial b_j} = \\sum_{k=j+1}^{p_b} \\overline{b}[k] \\cdot \\frac{\\partial g_k}{\\partial b_j}\n\\]\nI think it’s easy to visualize this in a computational graph:\n\n\n\nReverse AD\n\n\n\nfunction f_AAD(a::Array{Real})\n    b = zeros(4)\n    b[1] = a[1] + exp(a[2])\n    b[2] = sin(a[3]) + cos(a[4])\n    b[3] = a[2] ^ (3/2) + a[4]\n    b[4] = cos(b[1]) * b[2] + b[3]\n\n    # Backward sweep - derivatives\n    n = length(a)\n    abar = zeros(n)\n    b4bar = 1.0\n    b3bar = 1.0 * b4bar\n    b2bar = cos(b[1]) * b4bar\n    b1bar = b[2] * (-sin(b[1])) * b4bar\n\n    abar[4] = -sin(a[4]) * b2bar + 1.0 * b3bar\n    abar[3] = cos(a[3]) * b2bar\n    abar[2] = exp(a[2]) * b1bar + (1.5) * (a[2] ^ (0.5)) * b3bar\n    abar[1] = 1.0 * b1bar\n\n    (b[4], abar)\nend\n\nf_AAD (generic function with 1 method)"
  },
  {
    "objectID": "posts/aad/index.html#setup",
    "href": "posts/aad/index.html#setup",
    "title": "AAD(Adjoint Algorithmic Differentiation)",
    "section": "",
    "text": "As a quick example, suppose we have the scalar-valued function \\(f:\\mathbb{R}^{p_a} \\to \\mathbb{R}\\):\n\\[\ny = \\cos(x_1 + e^{x_2})(\\sin x_3 + \\cos x_4) + x_2^{3/2} + x_4\n\\]\nThe function inputs are a vector a[1...p_a] of dimension \\(p_a\\). All intermediate values in the program will be denoted by bs. The output of the function is denoted by the variable z of dimension \\(1\\). So, the algorithm starts with the inputs a, goes to z through a lot of bs. The new variables are denoted by b[j] with j starting with 1 and going upto \\(p_b\\). There are \\(p_b\\) intermediate variables \\(b\\) in the program."
  },
  {
    "objectID": "posts/aad/index.html#forward-mode-ad",
    "href": "posts/aad/index.html#forward-mode-ad",
    "title": "AAD(Adjoint Algorithmic Differentiation)",
    "section": "",
    "text": "Standard algorithmic differentiation also called forward algorithmic differentiation or tangent algorithmic differentiation. Our goal is to compute \\(\\partial z/\\partial a_i\\). We achieve this by computing for each \\(j\\)(\\(p_a + 1 \\leq j \\leq p_b\\)) the value:\n\\[\n\\dot{b}[j,i] = \\frac{\\partial b[j]}{\\partial a[i]}\n\\]\nWe first initialize the variables \\(b[j]\\) from \\(1 \\leq j \\leq p_a\\) with the inputs values \\(a[j]\\). Note that the derivative is denoted by dot on the variable and \\(\\dot{b}[j,i]\\) is the derivative of \\(b[j]\\) with respect to some other variable \\(a[i]\\). For \\(j=1:p_a\\), then, the derivative of \\(b[j]\\) with respect to \\(a[i]\\) is simply \\(1\\), if \\(j=i\\) and \\(0\\) if \\(j \\neq i\\). This is the starting point of a recursive algorithm. The starting part is the identity matrix :\n\\[\n\\dot{b}[j,i] = \\delta_{i,j}\n\\]\nwhere \\(\\delta_{i,j}\\) represents Kronecker’s delta.\nThe successive derivatives \\(\\dot{b}[j,i]\\) are given by the chain rule:\n\\[\n\\begin{align*}\n\\dot{b}[j,i] = \\frac{\\partial b[j]}{\\partial a[i]} &= \\sum_{k=p_a + 1}^{k=j-1}\\frac{\\partial b[j]}{\\partial b[k]} \\cdot \\frac{\\partial b[k]}{\\partial a[i]}\\\\\n&= \\sum_{k=p_a + 1}^{j-1} \\frac{\\partial}{\\partial b[k]} (b[j]) \\cdot \\dot{b}[k,i]\\\\\n&= \\sum_{k=p_a + 1}^{j-1} \\frac{\\partial}{\\partial b[k]} g_j(b[p_a + 1 : j - 1]) \\cdot \\dot{b}[k,i]\\\\\n\\end{align*}\n\\]\nThe numbers \\(\\dot{b}[p_b,i]\\) are equal to the derivatives of \\(z=b[p_b]\\) with respect to \\(a_i\\), \\(1 \\leq i \\leq p_a\\). This concludes the algorithm for the computation of \\(\\partial z/\\partial a_i\\).\nThe requirements for such an implementation is that all the intermediary functions \\(g_j\\) have a derivative version. The algorithmic differentiation approach is a bottom-up approach : it can be implemented for an algorithm only if all the components below it, all the components entering into the composition have already been implemented.\n\n\n\nForward AD"
  },
  {
    "objectID": "posts/aad/index.html#naive-implementation-of-forward-ad",
    "href": "posts/aad/index.html#naive-implementation-of-forward-ad",
    "title": "AAD(Adjoint Algorithmic Differentiation)",
    "section": "",
    "text": "function f(a::Array{Real})\n    b = zeros(4)\n    b[1] = a[1] + exp(a[2])\n    b[2] = sin(a[3]) + cos(a[4])\n    b[3] = a[2] ^ (3/2) + a[4]\n    b[4] = cos(b[1]) * b[2] + b[3]\n    b[4]\nend\n\nf (generic function with 1 method)\n\n\nWe create an AD version of the starter function as follows:\n\nfunction f_AD(x::Array{Real})\n    b = zeros(4)\n    b[1] = a[1] + exp(a[2])\n    b[2] = sin(a[3]) + cos(a[4])\n    b[3] = a[2] ^ (3/2) + a[4]\n    b[4] = cos(b[1]) * b[2] + b[3]\n    \n    # Forward sweep - derivatives\n    n = length(x)\n\n    b1dot = zeros(n)\n    b1dot[1] = 1\n    b1dot[2] = exp(b[2])\n\n    b2dot = zeros(n)\n    b2dot[3] = cos(b[3])\n    b2dot[4] = -sin(b[4])\n\n    b3dot = zeros(n)\n    b3dot[2] = (3/2)*(b[2] ^ (1/2))\n    b3dot[4] = 1\n\n    b4dot = b[2] * -sin(b[1]) * b1dot + cos(b[1]) * b2dot + b3dot\n    (b[4],b4dot)\nend\n\nf_AD (generic function with 1 method)\n\n\nNote that, the output of the original function f is the function value - a double, whilst the output f_ad is a 2-tuple : the function value and the value of the jacobian(gradient)."
  },
  {
    "objectID": "posts/aad/index.html#adjoint-algorithmic-differentiation",
    "href": "posts/aad/index.html#adjoint-algorithmic-differentiation",
    "title": "AAD(Adjoint Algorithmic Differentiation)",
    "section": "",
    "text": "Our goal is to compute \\(\\frac{\\partial z}{\\partial a_i}\\). We achieve this by computing for each intermediate variable \\(j\\) (\\(p_a + 1 \\leq j \\leq p_b\\)) the value:\n\\[\n\\overline{b}[j] = \\frac{\\partial z}{\\partial b[j]}\n\\]\nNote that, \\(\\overline{b}[j]\\) is the derivative of the output with respect to b[j]. It is important to switch the perception between the forward mode and the reverse mode. What is fixed in the reverse approach is the output, we always compute the derivative of the same variable, the output.\nThe starting point of the algorithm is easy. For \\(j = p_b\\), the derivative of \\(z\\) with respect to \\(b[j]\\) is simply the derivative of \\(z\\) with respect to itself, which is \\(1\\). This is the starting point of a recursive algorithm.\nFrom there, we read the code in reverse order and just apply the chain rule. Each intermediary variable \\(b[j]\\) is used only in the lines of code that follow in the computation. The derivative \\(\\overline{b}[j]\\) is given by:\n\\[\n\\overline{b}[j] = \\frac{\\partial z}{\\partial b_j} = \\sum_{k=j+1}^{p_b} \\frac{\\partial z}{\\partial b_k} \\cdot \\frac{\\partial b_k}{\\partial b_j} = \\sum_{k=j+1}^{p_b} \\overline{b}[k] \\cdot \\frac{\\partial g_k}{\\partial b_j}\n\\]\nI think it’s easy to visualize this in a computational graph:\n\n\n\nReverse AD\n\n\n\nfunction f_AAD(a::Array{Real})\n    b = zeros(4)\n    b[1] = a[1] + exp(a[2])\n    b[2] = sin(a[3]) + cos(a[4])\n    b[3] = a[2] ^ (3/2) + a[4]\n    b[4] = cos(b[1]) * b[2] + b[3]\n\n    # Backward sweep - derivatives\n    n = length(a)\n    abar = zeros(n)\n    b4bar = 1.0\n    b3bar = 1.0 * b4bar\n    b2bar = cos(b[1]) * b4bar\n    b1bar = b[2] * (-sin(b[1])) * b4bar\n\n    abar[4] = -sin(a[4]) * b2bar + 1.0 * b3bar\n    abar[3] = cos(a[3]) * b2bar\n    abar[2] = exp(a[2]) * b1bar + (1.5) * (a[2] ^ (0.5)) * b3bar\n    abar[1] = 1.0 * b1bar\n\n    (b[4], abar)\nend\n\nf_AAD (generic function with 1 method)"
  },
  {
    "objectID": "posts/coroutines/index.html",
    "href": "posts/coroutines/index.html",
    "title": "Coroutines",
    "section": "",
    "text": "You’ve likely heard about this new C++20 feature, coroutines. I think that this is a really important subject and there are several cool use-cases for coroutines. A coroutine in the simplest terms is just a function that you can pause in the middle. Imagine that you are executing a function top-down and then just at some point in between, you’d like to say, I am going to hit the pause button here; going to return the control back to the caller. At a later point the caller will decide to resume the execution of the function right where you left off. Unlike a function therefore, coroutines are always stateful - you atleast need to remember where you left off in the function body. Usually, you also need to remember more than this; you need to remember the values of all of the local variables were at the point where you paused. As a consequence, you can think of the coroutine you are calling not as a function in the classical sense of the term, but more like a factory function that actually returns the coroutine object back to you. And this coroutine object is the one that holds all the state, and which you can resume to continue the computation at a future time.\n\n%load_ext itikz\n\nCoroutines can simplify our code! Coroutines are a great tool, when it comes to implementing parsers.\nCompared to functions, the control flow of coroutines looks as follows:\n\n\n\nShow the code\n%%itikz --temp-dir --tex-packages=tikz --tikz-libraries=arrows.meta --implicit-standalone\n\\begin{tikzpicture}[scale=1.5]\n\\draw[blue, rounded corners] (0,0) rectangle (3,5);\n\\node(A) at (1.5,4.75) {Caller};\n\\node(B) at (1.5,3.50) {};\n\\node(C) at (1.5,3.20) {};\n\\node(call) at (2.20,4.20) {call};\n\\node(D) at (1.5,0.20) {};\n\\node(F) at (5.5,4.75) {Function};\n\\node(Func) at (5.55,4.50) {};\n\\node(Return) at (5.55,0.25) {};\n\\node(return_back) at (6.2,0.50) {\\texttt{return}};\n\\draw[dashed, -{Stealth[length=3mm]}] (A) -- (B);\n\\draw[dashed, -{Stealth[length=3mm]}] (B) -- (Func);\n\\draw[dashed, -{Stealth[length=3mm]}] (Func) -- (Return);\n\\draw[dashed, -{Stealth[length=3mm]}] (Return) -- (C);\n\\draw[dashed, -{Stealth[length=3mm]}] (C) -- (D);\n\\draw[blue, rounded corners] (4,0) rectangle (7,5);\n\\end{tikzpicture}\n\n\n\n\n\nFig. Functions - control flow\n\n\n\n\nShow the code\n%%itikz --temp-dir --tex-packages=tikz --tikz-libraries=arrows.meta --implicit-standalone\n\\begin{tikzpicture}[scale=1.5]\n\\draw[blue, rounded corners] (0,0) rectangle (3,7);\n\\node(F) at (5.5,6.75) {Coroutine};\n\\node(A) at (1.5,6.75) {Caller};\n\\node(B) at (1.5,5.50) {};\n\\node(coro_A) at (5.55,6.50) {};\n\\node(coro_B) at (5.55,5.20) {};\n\\node(suspend_1) at (4.75,5.70) {suspend};\n\\node(coyield_1) at (6.50,5.25) {\\texttt{co\\_yield}};\n\\node(call_1) at (2.20,6.20) {call};\n\\node(C) at (1.5,5.20) {};\n\\node(D) at (1.5,3.70) {};\n\\node(coro_C) at (5.55,3.70) {};\n\\node(resume_1) at (4.75,4.10) {resume};\n\\node(coro_D) at (5.55,2.20) {};\n\\node(suspend_2) at (4.75,2.70) {suspend};\n\\node(coyield_2) at (6.50,2.25) {\\texttt{co\\_yield}};\n\\node(E) at (1.5, 2.20) {};\n\\node(F) at (1.5, 1.25) {};\n\\node(resume_2) at (4.75,1.55) {resume};\n\\node(coro_F) at (5.55, 1.25) {};\n\\node(coro_G) at (5.55, 0.25) {};\n\\node(return_back) at (6.2,0.25) {\\texttt{co\\_return}};\n\\node(H) at (1.5, 0.25) {};\n\\draw[dashed, -{Stealth[length=3mm]}] (A) -- (B);\n\\draw[dashed, -{Stealth[length=3mm]}] (B) -- (coro_A);\n\\draw[dashed, -{Stealth[length=3mm]}] (coro_A) -- (coro_B);\n\\draw[dashed, -{Stealth[length=3mm]}] (coro_B) -- (C);\n\\draw[dashed, -{Stealth[length=3mm]}] (C) -- (D);\n\\draw[dashed, -{Stealth[length=3mm]}] (D) -- (coro_C);\n\\draw[dashed, -{Stealth[length=3mm]}] (coro_C) -- (coro_D);\n\\draw[dashed, -{Stealth[length=3mm]}] (coro_D) -- (E);\n\\draw[dashed, -{Stealth[length=3mm]}] (E) -- (F);\n\\draw[dashed, -{Stealth[length=3mm]}] (F) -- (coro_F);\n\\draw[dashed, -{Stealth[length=3mm]}] (coro_F) -- (coro_G);\n\\draw[dashed, -{Stealth[length=3mm]}] (coro_G) -- (H);\n\\draw[blue, rounded corners] (4,0) rectangle (7,7);\n\\end{tikzpicture}\n\n\n\n\n\nFig. Coroutines - control flow\n\nCoroutine frames (state of all the local variables at the point where you paused) may be stored on the stack or on the dynamic heap. C++ implements the latter approach - stackless coroutines.\nWhen using coroutines, we are talking about cooperative multi-tasking. As a quick 101, in preemptive multitasking, a special hardware timer interrupt is sent to the CPU periodically, the register state of the currently running process is saved to the main memory (in a data-structure called the process context) and the OS kernel acquires control of the CPU. The OS scheduler uses a scheduling policy such as round-robin to schedule another process from the process queue, copies its context from main memory to the CPU registers and transfers control to it. This is called a context switch. In cooperative multitasking, each process/thread, once running decides for how long to keep the CPU, and (crucially) when it is time to give it up so that another thread can use it.\n\n\nLet’s start with a simple example. Let’s say, you want to compute the Fibonacci sequence. First thing, that you’d do, is code up a function fibo(int) that returns a sequence in a vector.\n// Returns a vector containing the \n// first n elements of the Fibonacci \n// series: \n// 1, 1, 2, 3, 5, 8, 13, 21, ...\nstd::vector&lt;int&gt; fibo(int n)\n{\n    std::vector&lt;int&gt; results{};\n    int a_prev{1}, a_curr{1};\n    int a_next{0};\n    results.push_back(a_prev);\n    results.push_back(a_curr);\n    for(int i=2;i&lt;=n;++i)\n    {\n        a_next = a_prev + a_curr;\n        results.push_back(a_next);\n        a_prev = a_curr;\n        a_curr = a_next;\n    }\n\n    return results;\n}\nThis naive implementation has a number of disadvantages. For example, this function will always require \\(O(n)\\) storage. Fibonacci has a simple recursive equation, but if I have a complex computation, and I am only ever processing the numbers sequentially one at a time, then it makes no sense to pay for the entire \\(O(n)\\) storage. Another problem is that, if you are dealing with an infinite range, then it becomes a lot harder to handle.\nA different way of implementing this would be as follows. Instead of our function returning a range in a vector, we are just going to return a generator object; this generator object has then a next() member function and then every call to the next() member function gives us back the next number in the sequence.\nstruct FiboGenerator\n{\n    // Successive calls to next()  \n    // return the numbers from the \n    // Fibonacci series\n    int next();\n}\n\n// Returns a new FiboGenerator object\n// that will start from the first \n// Fibonacci number\nFiboGenerator makeFiboGenerator();\nThe interesting question is: Is makeFiboGenerator() a coroutine? And we really can’t tell - it’s an implementation detail. All we see is an interface. This is actually the most important thing about coroutines. From the outside, they just look and behave like functions. From the outside, there is no way to tell, whether they’ve been implemented using a coroutine or not. The only thing that we need to know as the user of this function is the interface of the object FiboGenerator.\n\n\n\nThe initial call to the coroutine function will produce this return object of a certain ReturnType and hand it back to the caller. The interface of this type is what is going to determine what the coroutine is capable of. Since coroutines are super-flexible, we can do a whole lot with this return object. If you have some coroutine, and you want to understand what it’s doing, the first thing you should look at is the ReturnType, and what it’s interface is. The important thing here is, we design this ReturnType. If you are writing a coroutine, you can decide, what goes into this interface.\n\n\n\nThe compiler looks for one of the three keywords in the implementation: co_yield, co_await and co_return.\n\nCoroutine keywords and their effects\n\n\nKeyword\nAction\nState\n\n\n\n\nco_yield\nOutput\nSuspended\n\n\nco_return\nOutput\nEnded\n\n\nco_await\nInput\nSuspended\n\n\n\nIn the preceding table, we see that after co_yield and co_await, the coroutine suspends itself and after co_return, it is terminated (co_return is the equivalent of the return statement in the C++ function).\nA classical function starts executing when it’s called and normally terminates with a return statement or just when the function’s end is reached. A function runs from the beginning to end. It may call another function (or even itself if it is recursive) and it may throw exceptions or have different return points. But it always runs from the beginning to the end.\nA coroutine is different. A coroutine is a function that can suspend itself. The flow for a coroutine may be like the following pseudo-code:\nReturnType coroutine(){\n    do_something();\n    co_yield;\n    do_something_else();\n    co_yield;\n    do_more_work();\n    co_return;\n}\nYou should think of the coroutine function not as a function in the classical sense, but rather as a factory function that returns a coroutine object and this coroutine object is the one that holds all the state, and one which you can resume to continue the computation later on.\n\n\n\nAsynchronous computation. Suppose we are tasked with designing a simple echo server. We listen for incoming data from a client socket and we simply send it back to the client. At some point in our code for the echo server, we will have a piece of logic like below:\nvoid session(Socket sock){\n    char buffer[1024];\n    int len = sock.read({buffer});\n    sock.write({buffer,len});\n    log(buffer);\n}\nWe create a buffer, then call the read that reads packets from the NIC and stores them in the buffer. The return value len will tell us how many bytes we read. Then, we shrink the buffer - we create a smaller one with len bytes and we write it back. Finally, we perform some logging. If we run it, it will probably work, but we certainly don’t want to write a server like this. Say one of the clients requests communication and we are in a session. They say, they are ready to send the data, so we are blocking on the read, but maybe they send us this data in 2 minutes, or 5 minutes or even more. And other clients keep waiting.\nWhat we could do is start this session and run it in a separate thread. And this would work, because if this thread is blocked, and if there are other threads in this server, they would run in exchange during the wait time. If we have a threadpool, we’ll just grab a thread from the threadpool, tell whatever system manages the pool to run this session(Socket) function there.\nThis solution is still far from ideal. These are operating system emulated threads and the OS will have to manage which threads get CPU time. It will have to preempt one thread, run another. This preemption will occur at random moments, when we least expect it. We could have data-races and likely require protection of a critical section/resource using mutexes.\nOne alternative is to use an asynchronous framework and rewrite our code as follows:\nvoid session(Socket sock){\n    struct State{ Socket sock; char buffer[1024]; };\n    \n    // Heap allocate the state\n    auto state = std::make_shared&lt;State&gt;(sock, buffer);\n\n    auto on_read_finished_callback = /* ... */\n\n    // Perform an asynchronous read \n    state-&gt;socket.async_read( state-&gt;buffer, \n                             on_read_finished_callback );\n}\nThe async_read() call is a request to the framework, which says that we are interested in data being read to our buffer at some point convenient to the client. When this succeeds, call our on_read_finished_callback. So, we are just making this association at this point and the server can move on to doing other stuff.\nThe read operation may fail for a number of reasons, so a good approach would be supply two arguments to the on_read_finished_callback: (i) An error code (ii) The number of bytes received, if there were no errors. We can try to implement it, by checking the error-code.\nvoid session(Socket sock){\n    struct State{ Socket sock; char buffer[1024]; };\n    \n    // Heap allocate the state\n    auto state = std::make_shared&lt;State&gt;(sock, buffer);\n\n    auto on_read_finished_callback = [&state](\n        error_code ec, \n        size_t len\n    )\n    {\n        auto done = /* ... */\n        if(!ec)\n        {\n            // Perform an asynchronous write\n            state-&gt;socket.async_write( \n                state-&gt;buffer, \n                done \n            );    \n        }\n    }\n\n    // Perform an asynchronous read \n    state-&gt;socket.async_read( state-&gt;buffer, \n                             on_read_finished_callback );\n}\nNow, we don’t have exception handling, because we have spread our logic over a number of callbacks. We are only left with if statements. If the reading all went fine, we can write the data back by shrinking the buffer, requesting that the write is performed at some time, not necessarily now - maybe later. When this write is performed, we would like to call another callback done. We don’t wait until this callback is called or write is performed. At this point, we just make an association. It is possible, that at a future time, the write succeeds and then the callback done is called. So, we have to define it.\nvoid session(Socket sock){\n    struct State{ Socket sock; char buffer[1024]; };\n    \n    // Heap allocate the state\n    auto state = std::make_shared&lt;State&gt;(sock, buffer);\n\n    auto on_read_finished_callback = [state](\n        error_code ec, \n        size_t len\n    )\n    {\n        auto done = [state](error_code ec, size_t len)\n        {\n            if(!ec)\n                log();\n        }\n        if(!ec)\n        {\n            // Perform an asynchronous write\n            state-&gt;socket.async_write( \n                state-&gt;buffer, \n                done \n            );    \n        }\n    }\n\n    // Perform an asynchronous read \n    state-&gt;socket.async_read( state-&gt;buffer, \n                             on_read_finished_callback );\n}\ndone has a similar structure. It takes two arguments - the error code that tells if the write went fine and the number of bytes written len. If there were no errors on write and everything went fine, we can do the logging. Implicitly,\nSo, the session makes two associations:\n\\[\n\\begin{align*}\n\\text{On finishing read} &\\mapsto \\texttt{on\\_finished\\_read\\_callback} \\\\\n\\text{On finishing write} &\\mapsto \\texttt{done} \\\\\n\\text{Accepting a new client connection} &\\mapsto \\texttt{session}\n\\end{align*}\n\\]\nAnd implicitly there is a third association even though we cannot see it here - this entire function session is most likely a callback, in response to an event like \\(\\text{On client connection established}\\). So, the server will be many different associations of events to callbacks at different levels.\nPay attention to the state. We said that, we wanted to allocate it on the heap and manage it through a shared_ptr. We pass this shared_ptr&lt;State&gt; by value to every single callback. This way, I make sure that the last one who touches this session turns off the lights and deallocates state.\nWhile this is a toy-example, in real production code, there can be a long sequence of steps and calling lambdas inside lambdas can obfuscate the meaning of the code. We already see a weird inversion of control flow, when reading the code.\nOne thing to note before I go to coroutines is that, even though those things happen asynchronously, there is a sequence to it, that is not violated. We only perform a write when we know that the read has succeeded. We only perform the log after the write has succeeded.\n\\[\n\\texttt{read} \\to \\texttt{write} \\to \\texttt{log}\n\\]\nAs an application programmer we determine, when we yield control to the system other sessions. It’s not that the system pre-empts this task.\nA coroutine implementation of the same echo’ing session would look like this:\nTask&lt;void&gt; session(Socket sock){\n    char buffer[1024];\n    int len = co_await sock.async_read({buffer});\n    co_await sock.async_write({buffer,len});\n    log(buffer);\n}\nThis looks very similar to the sequential code, except that we use this co_await keyword. You have clear indication of the points where the coroutine will be suspended. Also, note that previously the function session returned void. Now, we are returning something - a Task&lt;void&gt;. This will be a handle to the coroutine and it’s how the outside world will be communicating with the coroutine.\nSuspended computation. A second use-case is that coroutines support lazy evaluation. Just as in the fibonacci example, sometimes we want to avoid doing unecessary evaluation. Lazy evaluation doesn’t do any work unless it’s absolutely necessary. This can also potentially make your code more efficient. Lazy evaluation also supports programming with infinite lists."
  },
  {
    "objectID": "posts/coroutines/index.html#coroutines",
    "href": "posts/coroutines/index.html#coroutines",
    "title": "Coroutines",
    "section": "",
    "text": "You’ve likely heard about this new C++20 feature, coroutines. I think that this is a really important subject and there are several cool use-cases for coroutines. A coroutine in the simplest terms is just a function that you can pause in the middle. Imagine that you are executing a function top-down and then just at some point in between, you’d like to say, I am going to hit the pause button here; going to return the control back to the caller. At a later point the caller will decide to resume the execution of the function right where you left off. Unlike a function therefore, coroutines are always stateful - you atleast need to remember where you left off in the function body. Usually, you also need to remember more than this; you need to remember the values of all of the local variables were at the point where you paused. As a consequence, you can think of the coroutine you are calling not as a function in the classical sense of the term, but more like a factory function that actually returns the coroutine object back to you. And this coroutine object is the one that holds all the state, and which you can resume to continue the computation at a future time.\n\n%load_ext itikz\n\nCoroutines can simplify our code! Coroutines are a great tool, when it comes to implementing parsers.\nCompared to functions, the control flow of coroutines looks as follows:\n\n\n\nShow the code\n%%itikz --temp-dir --tex-packages=tikz --tikz-libraries=arrows.meta --implicit-standalone\n\\begin{tikzpicture}[scale=1.5]\n\\draw[blue, rounded corners] (0,0) rectangle (3,5);\n\\node(A) at (1.5,4.75) {Caller};\n\\node(B) at (1.5,3.50) {};\n\\node(C) at (1.5,3.20) {};\n\\node(call) at (2.20,4.20) {call};\n\\node(D) at (1.5,0.20) {};\n\\node(F) at (5.5,4.75) {Function};\n\\node(Func) at (5.55,4.50) {};\n\\node(Return) at (5.55,0.25) {};\n\\node(return_back) at (6.2,0.50) {\\texttt{return}};\n\\draw[dashed, -{Stealth[length=3mm]}] (A) -- (B);\n\\draw[dashed, -{Stealth[length=3mm]}] (B) -- (Func);\n\\draw[dashed, -{Stealth[length=3mm]}] (Func) -- (Return);\n\\draw[dashed, -{Stealth[length=3mm]}] (Return) -- (C);\n\\draw[dashed, -{Stealth[length=3mm]}] (C) -- (D);\n\\draw[blue, rounded corners] (4,0) rectangle (7,5);\n\\end{tikzpicture}\n\n\n\n\n\nFig. Functions - control flow\n\n\n\n\nShow the code\n%%itikz --temp-dir --tex-packages=tikz --tikz-libraries=arrows.meta --implicit-standalone\n\\begin{tikzpicture}[scale=1.5]\n\\draw[blue, rounded corners] (0,0) rectangle (3,7);\n\\node(F) at (5.5,6.75) {Coroutine};\n\\node(A) at (1.5,6.75) {Caller};\n\\node(B) at (1.5,5.50) {};\n\\node(coro_A) at (5.55,6.50) {};\n\\node(coro_B) at (5.55,5.20) {};\n\\node(suspend_1) at (4.75,5.70) {suspend};\n\\node(coyield_1) at (6.50,5.25) {\\texttt{co\\_yield}};\n\\node(call_1) at (2.20,6.20) {call};\n\\node(C) at (1.5,5.20) {};\n\\node(D) at (1.5,3.70) {};\n\\node(coro_C) at (5.55,3.70) {};\n\\node(resume_1) at (4.75,4.10) {resume};\n\\node(coro_D) at (5.55,2.20) {};\n\\node(suspend_2) at (4.75,2.70) {suspend};\n\\node(coyield_2) at (6.50,2.25) {\\texttt{co\\_yield}};\n\\node(E) at (1.5, 2.20) {};\n\\node(F) at (1.5, 1.25) {};\n\\node(resume_2) at (4.75,1.55) {resume};\n\\node(coro_F) at (5.55, 1.25) {};\n\\node(coro_G) at (5.55, 0.25) {};\n\\node(return_back) at (6.2,0.25) {\\texttt{co\\_return}};\n\\node(H) at (1.5, 0.25) {};\n\\draw[dashed, -{Stealth[length=3mm]}] (A) -- (B);\n\\draw[dashed, -{Stealth[length=3mm]}] (B) -- (coro_A);\n\\draw[dashed, -{Stealth[length=3mm]}] (coro_A) -- (coro_B);\n\\draw[dashed, -{Stealth[length=3mm]}] (coro_B) -- (C);\n\\draw[dashed, -{Stealth[length=3mm]}] (C) -- (D);\n\\draw[dashed, -{Stealth[length=3mm]}] (D) -- (coro_C);\n\\draw[dashed, -{Stealth[length=3mm]}] (coro_C) -- (coro_D);\n\\draw[dashed, -{Stealth[length=3mm]}] (coro_D) -- (E);\n\\draw[dashed, -{Stealth[length=3mm]}] (E) -- (F);\n\\draw[dashed, -{Stealth[length=3mm]}] (F) -- (coro_F);\n\\draw[dashed, -{Stealth[length=3mm]}] (coro_F) -- (coro_G);\n\\draw[dashed, -{Stealth[length=3mm]}] (coro_G) -- (H);\n\\draw[blue, rounded corners] (4,0) rectangle (7,7);\n\\end{tikzpicture}\n\n\n\n\n\nFig. Coroutines - control flow\n\nCoroutine frames (state of all the local variables at the point where you paused) may be stored on the stack or on the dynamic heap. C++ implements the latter approach - stackless coroutines.\nWhen using coroutines, we are talking about cooperative multi-tasking. As a quick 101, in preemptive multitasking, a special hardware timer interrupt is sent to the CPU periodically, the register state of the currently running process is saved to the main memory (in a data-structure called the process context) and the OS kernel acquires control of the CPU. The OS scheduler uses a scheduling policy such as round-robin to schedule another process from the process queue, copies its context from main memory to the CPU registers and transfers control to it. This is called a context switch. In cooperative multitasking, each process/thread, once running decides for how long to keep the CPU, and (crucially) when it is time to give it up so that another thread can use it.\n\n\nLet’s start with a simple example. Let’s say, you want to compute the Fibonacci sequence. First thing, that you’d do, is code up a function fibo(int) that returns a sequence in a vector.\n// Returns a vector containing the \n// first n elements of the Fibonacci \n// series: \n// 1, 1, 2, 3, 5, 8, 13, 21, ...\nstd::vector&lt;int&gt; fibo(int n)\n{\n    std::vector&lt;int&gt; results{};\n    int a_prev{1}, a_curr{1};\n    int a_next{0};\n    results.push_back(a_prev);\n    results.push_back(a_curr);\n    for(int i=2;i&lt;=n;++i)\n    {\n        a_next = a_prev + a_curr;\n        results.push_back(a_next);\n        a_prev = a_curr;\n        a_curr = a_next;\n    }\n\n    return results;\n}\nThis naive implementation has a number of disadvantages. For example, this function will always require \\(O(n)\\) storage. Fibonacci has a simple recursive equation, but if I have a complex computation, and I am only ever processing the numbers sequentially one at a time, then it makes no sense to pay for the entire \\(O(n)\\) storage. Another problem is that, if you are dealing with an infinite range, then it becomes a lot harder to handle.\nA different way of implementing this would be as follows. Instead of our function returning a range in a vector, we are just going to return a generator object; this generator object has then a next() member function and then every call to the next() member function gives us back the next number in the sequence.\nstruct FiboGenerator\n{\n    // Successive calls to next()  \n    // return the numbers from the \n    // Fibonacci series\n    int next();\n}\n\n// Returns a new FiboGenerator object\n// that will start from the first \n// Fibonacci number\nFiboGenerator makeFiboGenerator();\nThe interesting question is: Is makeFiboGenerator() a coroutine? And we really can’t tell - it’s an implementation detail. All we see is an interface. This is actually the most important thing about coroutines. From the outside, they just look and behave like functions. From the outside, there is no way to tell, whether they’ve been implemented using a coroutine or not. The only thing that we need to know as the user of this function is the interface of the object FiboGenerator.\n\n\n\nThe initial call to the coroutine function will produce this return object of a certain ReturnType and hand it back to the caller. The interface of this type is what is going to determine what the coroutine is capable of. Since coroutines are super-flexible, we can do a whole lot with this return object. If you have some coroutine, and you want to understand what it’s doing, the first thing you should look at is the ReturnType, and what it’s interface is. The important thing here is, we design this ReturnType. If you are writing a coroutine, you can decide, what goes into this interface.\n\n\n\nThe compiler looks for one of the three keywords in the implementation: co_yield, co_await and co_return.\n\nCoroutine keywords and their effects\n\n\nKeyword\nAction\nState\n\n\n\n\nco_yield\nOutput\nSuspended\n\n\nco_return\nOutput\nEnded\n\n\nco_await\nInput\nSuspended\n\n\n\nIn the preceding table, we see that after co_yield and co_await, the coroutine suspends itself and after co_return, it is terminated (co_return is the equivalent of the return statement in the C++ function).\nA classical function starts executing when it’s called and normally terminates with a return statement or just when the function’s end is reached. A function runs from the beginning to end. It may call another function (or even itself if it is recursive) and it may throw exceptions or have different return points. But it always runs from the beginning to the end.\nA coroutine is different. A coroutine is a function that can suspend itself. The flow for a coroutine may be like the following pseudo-code:\nReturnType coroutine(){\n    do_something();\n    co_yield;\n    do_something_else();\n    co_yield;\n    do_more_work();\n    co_return;\n}\nYou should think of the coroutine function not as a function in the classical sense, but rather as a factory function that returns a coroutine object and this coroutine object is the one that holds all the state, and one which you can resume to continue the computation later on.\n\n\n\nAsynchronous computation. Suppose we are tasked with designing a simple echo server. We listen for incoming data from a client socket and we simply send it back to the client. At some point in our code for the echo server, we will have a piece of logic like below:\nvoid session(Socket sock){\n    char buffer[1024];\n    int len = sock.read({buffer});\n    sock.write({buffer,len});\n    log(buffer);\n}\nWe create a buffer, then call the read that reads packets from the NIC and stores them in the buffer. The return value len will tell us how many bytes we read. Then, we shrink the buffer - we create a smaller one with len bytes and we write it back. Finally, we perform some logging. If we run it, it will probably work, but we certainly don’t want to write a server like this. Say one of the clients requests communication and we are in a session. They say, they are ready to send the data, so we are blocking on the read, but maybe they send us this data in 2 minutes, or 5 minutes or even more. And other clients keep waiting.\nWhat we could do is start this session and run it in a separate thread. And this would work, because if this thread is blocked, and if there are other threads in this server, they would run in exchange during the wait time. If we have a threadpool, we’ll just grab a thread from the threadpool, tell whatever system manages the pool to run this session(Socket) function there.\nThis solution is still far from ideal. These are operating system emulated threads and the OS will have to manage which threads get CPU time. It will have to preempt one thread, run another. This preemption will occur at random moments, when we least expect it. We could have data-races and likely require protection of a critical section/resource using mutexes.\nOne alternative is to use an asynchronous framework and rewrite our code as follows:\nvoid session(Socket sock){\n    struct State{ Socket sock; char buffer[1024]; };\n    \n    // Heap allocate the state\n    auto state = std::make_shared&lt;State&gt;(sock, buffer);\n\n    auto on_read_finished_callback = /* ... */\n\n    // Perform an asynchronous read \n    state-&gt;socket.async_read( state-&gt;buffer, \n                             on_read_finished_callback );\n}\nThe async_read() call is a request to the framework, which says that we are interested in data being read to our buffer at some point convenient to the client. When this succeeds, call our on_read_finished_callback. So, we are just making this association at this point and the server can move on to doing other stuff.\nThe read operation may fail for a number of reasons, so a good approach would be supply two arguments to the on_read_finished_callback: (i) An error code (ii) The number of bytes received, if there were no errors. We can try to implement it, by checking the error-code.\nvoid session(Socket sock){\n    struct State{ Socket sock; char buffer[1024]; };\n    \n    // Heap allocate the state\n    auto state = std::make_shared&lt;State&gt;(sock, buffer);\n\n    auto on_read_finished_callback = [&state](\n        error_code ec, \n        size_t len\n    )\n    {\n        auto done = /* ... */\n        if(!ec)\n        {\n            // Perform an asynchronous write\n            state-&gt;socket.async_write( \n                state-&gt;buffer, \n                done \n            );    \n        }\n    }\n\n    // Perform an asynchronous read \n    state-&gt;socket.async_read( state-&gt;buffer, \n                             on_read_finished_callback );\n}\nNow, we don’t have exception handling, because we have spread our logic over a number of callbacks. We are only left with if statements. If the reading all went fine, we can write the data back by shrinking the buffer, requesting that the write is performed at some time, not necessarily now - maybe later. When this write is performed, we would like to call another callback done. We don’t wait until this callback is called or write is performed. At this point, we just make an association. It is possible, that at a future time, the write succeeds and then the callback done is called. So, we have to define it.\nvoid session(Socket sock){\n    struct State{ Socket sock; char buffer[1024]; };\n    \n    // Heap allocate the state\n    auto state = std::make_shared&lt;State&gt;(sock, buffer);\n\n    auto on_read_finished_callback = [state](\n        error_code ec, \n        size_t len\n    )\n    {\n        auto done = [state](error_code ec, size_t len)\n        {\n            if(!ec)\n                log();\n        }\n        if(!ec)\n        {\n            // Perform an asynchronous write\n            state-&gt;socket.async_write( \n                state-&gt;buffer, \n                done \n            );    \n        }\n    }\n\n    // Perform an asynchronous read \n    state-&gt;socket.async_read( state-&gt;buffer, \n                             on_read_finished_callback );\n}\ndone has a similar structure. It takes two arguments - the error code that tells if the write went fine and the number of bytes written len. If there were no errors on write and everything went fine, we can do the logging. Implicitly,\nSo, the session makes two associations:\n\\[\n\\begin{align*}\n\\text{On finishing read} &\\mapsto \\texttt{on\\_finished\\_read\\_callback} \\\\\n\\text{On finishing write} &\\mapsto \\texttt{done} \\\\\n\\text{Accepting a new client connection} &\\mapsto \\texttt{session}\n\\end{align*}\n\\]\nAnd implicitly there is a third association even though we cannot see it here - this entire function session is most likely a callback, in response to an event like \\(\\text{On client connection established}\\). So, the server will be many different associations of events to callbacks at different levels.\nPay attention to the state. We said that, we wanted to allocate it on the heap and manage it through a shared_ptr. We pass this shared_ptr&lt;State&gt; by value to every single callback. This way, I make sure that the last one who touches this session turns off the lights and deallocates state.\nWhile this is a toy-example, in real production code, there can be a long sequence of steps and calling lambdas inside lambdas can obfuscate the meaning of the code. We already see a weird inversion of control flow, when reading the code.\nOne thing to note before I go to coroutines is that, even though those things happen asynchronously, there is a sequence to it, that is not violated. We only perform a write when we know that the read has succeeded. We only perform the log after the write has succeeded.\n\\[\n\\texttt{read} \\to \\texttt{write} \\to \\texttt{log}\n\\]\nAs an application programmer we determine, when we yield control to the system other sessions. It’s not that the system pre-empts this task.\nA coroutine implementation of the same echo’ing session would look like this:\nTask&lt;void&gt; session(Socket sock){\n    char buffer[1024];\n    int len = co_await sock.async_read({buffer});\n    co_await sock.async_write({buffer,len});\n    log(buffer);\n}\nThis looks very similar to the sequential code, except that we use this co_await keyword. You have clear indication of the points where the coroutine will be suspended. Also, note that previously the function session returned void. Now, we are returning something - a Task&lt;void&gt;. This will be a handle to the coroutine and it’s how the outside world will be communicating with the coroutine.\nSuspended computation. A second use-case is that coroutines support lazy evaluation. Just as in the fibonacci example, sometimes we want to avoid doing unecessary evaluation. Lazy evaluation doesn’t do any work unless it’s absolutely necessary. This can also potentially make your code more efficient. Lazy evaluation also supports programming with infinite lists."
  },
  {
    "objectID": "posts/coroutines/index.html#the-simplest-coroutine",
    "href": "posts/coroutines/index.html#the-simplest-coroutine",
    "title": "Coroutines",
    "section": "The simplest coroutine",
    "text": "The simplest coroutine\nThe following code is the simplest implementation of a coroutine:\n#include &lt;coroutine&gt;\nvoid coro_func(){\n    co_return;\n}\n\nint main(){\n    coro_func();\n}\nCompiler Explorer\nOur first coroutine will just return nothing. It will not do anything else. Sadly, the preceding code is too simple for a functional coroutine and it will not compile. When compiling with gcc 15.2, we get the following error:\n&lt;source&gt;: In function 'void coro_func()':\n&lt;source&gt;:4:5: error: unable to find the promise type for this coroutine\n    4 |     co_return;\n      |     ^~~~~~~~~\nLooking at C++ reference, we see that the return type of a coroutine must define a type named promise_type.\n\nThe promise_type\nWhy do we need a promise? The promise_type is the second important piece in the coroutine mechanism. We can draw an analogy from futures and promises which are essential blocks for achieving asynchronous programming in C++. The future is the thing, that the function that does the asynchronous computation, hands out back to the caller, that the caller can use to retrieve the result by invoking the get() member function. The future has the role of the return object. But, you need something that remains on the producer-side. The asynchronous function holds on to the promise, and that’s where it puts the results that will be given to the caller, when it calls get() on the future. The idea behind the promise_type for coroutines is similar. The promise is where the coroutine’s return value is stored, and it provides functions to control the coroutine’s behavior at startup and completion of t he coroutine. The promise is the interface through which the caller interacts with the coroutine.\nFollowing the reference advice, we can write a new version of our coroutine.\n#include &lt;coroutine&gt;\nstruct Task\n{\n    struct promise_type\n    {\n    };\n};\n\nTask coro_func(){\n    co_return;\n}\n\nint main(){\n    coro_func();\n}\nCompiler Explorer\nNote that the return type of a coroutine can have any name (I call it Task, so that it makes intuitive sense). Compiling the preceding code again gives us errors. All errors are about missing functions in the promise_type:\n&lt;source&gt;: In function 'Task coro_func()':\n&lt;source&gt;:11:5: error: no member named 'return_void' in\n'std::__n4861::__coroutine_traits_impl&lt;Task, void&gt;::promise_type' {aka 'Task::promise_type'}\n   11 |     co_return;\n      |     ^~~~~~~~~\n&lt;source&gt;:10:6: error: no member named 'unhandled_exception' in\n'std::__n4861::__coroutine_traits_impl&lt;Task, void&gt;::promise_type' {aka 'Task::promise_type'}\n   10 | Task coro_func(){\n      |      ^~~~~~~~~\n&lt;source&gt;:10:6: error: no member named 'get_return_object' in\n'std::__n4861::__coroutine_traits_impl&lt;Task, void&gt;::promise_type' {aka 'Task::promise_type'}\nOne of the important functions of the promise_type is that it determines what happens at certain key points in the coroutine’s life. It determines, what happens at the startup and completion of execution of the coroutine.\n\n\nImplementing the promise_type\nThe first thing that the compiler expects from us the get_return_object() function. The return type of this function is the same as the return type of the coroutine.\n#include &lt;coroutine&gt;\n#include &lt;print&gt;\n\nstruct Task{\n    struct promise_type{\n        Task get_return_object(){\n            std::println(\"get_return_object()\");\n            return Task{ *this };\n        }\n\n        void return_void() noexcept {\n            std::println(\"return_void()\");\n        }\n\n        void unhandled_exception() noexcept {\n            std::println(\"unhandled_exception()\");\n        }\n\n        std::suspend_always initial_suspend() noexcept{\n            std::println(\"initial_suspend()\");\n            return {};\n        }\n\n        std::suspend_always final_suspend() noexcept{\n            std::println(\"final_suspend()\");\n            return {};\n        }\n    };\n\n    explicit Task(promise_type&){\n        std::println(\"Task(promise_type&)\");\n    }\n\n    ~Task() noexcept{\n        std::println(\"~Task()\");\n    }\n};\n\nTask coro_func(){\n    co_return;\n}\n\nint main(){\n    coro_func();\n}\nCompiler Explorer\nOutput:\nget_return_object()\nTask(promise_type&)\ninitial_suspend()\n~Task()\nThe get_return_object() method is implicitly called when the coroutine starts executing. Its upto the promise_type to provide an implementation of this method that constructs the return object that will be handed back to the caller. The Task object is stored on the heap. You don’t see this in the source code anywhere. When the coroutine reaches its first suspension point, and control flow is returned back to the caller, then the caller will receive this object.\nThe next thing we need to specify is the return_void() function. This is a customization point for handling what happens when we reach the co_return statement in the function body. There is also a corresponding return_value(), if you don’t have an empty co_return statement, but we’ll look at this at length later ahead.\nThe next one we need is unhandled_exception() and similar to the return_void(), this function is a customization point for handling, what happens when the coroutine throws an exception. We leave it empty for now.\nWe need to implement two more functions initial_suspend() and final_suspend(). These are basically the customization points that allow us to execute some code, both when the coroutine first starts executing and shortly before the coroutine ends execution. Here, we are returning std::suspend_always which basically means that at these points, I want to go into suspension. In a typical implementation, you either return std::suspend_always, which means you pause execution at this point and hand control back to the caller always, or you return std::suspend_never, which basically means you just go on and continue executing the coroutine.\nNote that, final_suspend() is not printed in the output, because the coroutine is paused at initial_suspend() and since I never resumed it, I don’t see the output on the console."
  },
  {
    "objectID": "posts/coroutines/index.html#a-yielding-coroutine",
    "href": "posts/coroutines/index.html#a-yielding-coroutine",
    "title": "Coroutines",
    "section": "A yielding coroutine",
    "text": "A yielding coroutine\nThe do-nothing coroutine was great to get a gut intuitive feel for the basic mechanics of writing low-level coroutines in C++. Let’s implement another coroutine that can send data back to the caller.\nIn this second example, we implement a coroutine that produces a message. It will be the hello world of coroutines. The coroutine will say hello and the caller function will print the message received from the coroutine.\nTo implement this functionality, we need to establish a communication channel from the coroutine to the caller. This channel is the mechanism that allows the coroutine to pass values to the caller and receive information from it. This channel is established through the coroutine’s promise_type and the coroutine handle.\nThe coroutine handle is a type that gives access to the coroutine frame(the coroutine’s internal state) and allows the caller to resume or destroy the coroutine. The handle is what the caller can use to resume the coroutine after it has been suspended (for example after co_await or co_yield). The handle can also be used to check whether the coroutine is done or to clean up its resources.\nThe following code is the new version of both the caller function and the coroutine:\nTask coro_func(){\n    co_yield \"Hello world from the coroutine\";\n    co_return;\n}\n\nint main(){\n    auto task = coro_func();\n    std::print(\"task.get() = {}\", task.get());\n    return 0;\n}\nThe coroutine yields and sends some data to the caller. The caller reads that data and prints it. When the compiler reads the co_ yield expression, it will generate a call to the yield_value function defined in the promise_type. Thus, we add the following code to the promise_type :\nstruct Task{\n    struct promise_type{\n        std::string output_data;\n\n        /* ... */\n        std::suspend_always yield_value(std::string msg) noexcept{\n            output_data = std::move(msg);\n        }\n    };\n\n    explicit Task(promise_type&){\n        std::println(\"Task(promise_type&)\");\n    }\n\n    ~Task() noexcept{\n        std::println(\"~Task()\");\n    }\n};\nThe function gets a std::string object and moves it to the output_data member variable of the promise type. But, this just keeps the data inside the promise_type. We still need a mechanism to get that data out of the coroutine.\n\nThe coroutine handle\nOnce we require a communication channel to and from a coroutine, we need a way to refer to a suspended or executing coroutine. The mechanism to refer to the coroutine object is through a pointer or handle called a coroutine handle. The C++ library header file &lt;coroutine&gt; defines a type std::coroutine_handle to work with coroutine handles.\nTwo functions are of interest to us in the std::coroutine_handle interface : resume() and destroy().\nstruct coroutine_handle&lt;promise_type&gt;{\n    /* ... */\n    void resume() const;\n    void destroy() const;\n    promise_type& promise() const;\n    static coroutine_handle from_promise(promise_type&);\n}\nWhat resume() does is simply, it resumes the suspended coroutine. It continues execution.\nIf we think of this coroutine frame or object living somewhere on the heap, where all of the state of execution is stored, one way to destroy this state is to let the coroutine run to completion. But, far more commonly, we would like to manage the lifetime externally and we can then just call the destroy() function which will then get rid of the coroutine state.\nNote that, the coroutine_handle is not a smart pointer type. So, you have to call the destroy() explicitly.\nThere’s two more functions .promise() and .from_promise(). These are used to convert from a coroutine to a promise object and vice versa.\nWe add the following functionality to our return type to manage the coroutine handle:\nstruct Task{\n    struct promise_type{\n        std::string output_data;\n\n        /* ... */\n        std::suspend_always yield_value(std::string msg) noexcept{\n            output_data = std::move(msg);\n        }\n    };\n\n    // Coroutine handle member-variable\n    std::coroutine_handle&lt;promise_type&gt; handle{};\n\n    // ReturnType(promise_type&) ctor initializes \n    // the coroutine handle member variable\n    explicit Task(promise_type& promise)\n    : handle { std::coroutine_handle&lt;promise_type&gt;::from_promise(promise) }\n    {\n        std::println(\"Task(promise_type&)\");\n    }\n\n    // Destructor\n    ~Task() noexcept{\n        std::println(\"~Task()\");\n        if(handle)\n            handle.destroy();\n    }\n};\nThe preceding code declares a coroutine handle of type std::coroutine_handle&lt;promise_type&gt; and creates the handle in the return type constructor. The handle is destroyed in the return type destructor.\nNow, back to our yielding coroutine. The only missing bit is a get() function for the caller to be able to extract the resultant string out of the promise.\nstd::string get(){\n    if(!handle.done()){\n        handle.resume();\n    }\n    return std::move(handle.promise().output_data);\n}\nThe get() function resumes the coroutine if it has not terminated and return the result stored in the output_data member variable of the promise. The full source code listing is shown below:\n#include &lt;coroutine&gt;\n#include &lt;print&gt;\n#include &lt;iostream&gt;\n#include &lt;string&gt;\n\nusing namespace std::string_literals;\n\nstruct Task{\n    struct promise_type{\n        std::string output_data{};\n\n        Task get_return_object(){\n            std::println(\"get_return_object()\");\n            return Task{ *this };\n        }\n\n        void return_void() noexcept {\n            std::println(\"return_void()\");\n        }\n\n        void unhandled_exception() noexcept {\n            std::println(\"unhandled_exception()\");\n        }\n\n        std::suspend_always initial_suspend() noexcept{\n            std::println(\"initial_suspend()\");\n            return {};\n        }\n\n        std::suspend_always final_suspend() noexcept{\n            std::println(\"final_suspend()\");\n            return {};\n        }\n\n        std::suspend_always yield_value(std::string msg) noexcept{\n            std::println(\"yield_value(std::string)\");\n            output_data = std::move(msg);\n            return {};\n        }\n    };\n\n    // Coroutine handle member-variable\n    std::coroutine_handle&lt;promise_type&gt; handle{};\n\n    // ReturnType(promise_type&) ctor initializes \n    // the coroutine handle member variable\n    explicit Task(promise_type& promise)\n    : handle { std::coroutine_handle&lt;promise_type&gt;::from_promise(promise) }\n    {\n        std::println(\"Task(promise_type&)\");\n    }\n\n    ~Task() noexcept{\n        std::println(\"~Task()\");\n        if(handle)\n            handle.destroy();\n    }\n\n    std::string get(){\n        std::println(\"get()\");\n        if(!handle.done())\n            handle.resume();\n\n        return std::move(handle.promise().output_data);\n    }\n};\n\nTask coro_func(){\n    co_yield \"Hello world from the coroutine\";\n    co_return;\n}\n\nint main(){\n    auto task = coro_func();\n    std::cout &lt;&lt; task.get() &lt;&lt; std::endl;\n}\nCompiler Explorer\nOutput:\nget_return_object()\nTask(promise_type&)\ninitial_suspend()\nget()\nyield_value(std::string)\nHello world from the coroutine\n~Task()\nThe output shows what is happening during the coroutine execution. The Task object is created after a call to get_return_object. The coroutine is initially suspended. The caller wants to get the message from the coroutine so get() is called, which resumes the coroutine. When the compiler sees co_yield statement in the coroutine, it generates an implicit called to yield_value(std::string). yield_value is called and the message is copied to the resultant member variable output_data in the promise. Finally, the message is printed by the caller function, and the coroutine returns."
  },
  {
    "objectID": "posts/coroutines/index.html#a-waiting-coroutine",
    "href": "posts/coroutines/index.html#a-waiting-coroutine",
    "title": "Coroutines",
    "section": "A waiting coroutine",
    "text": "A waiting coroutine\nWe are now going to implement a coroutine that can wait for the input data sent by the caller. In our example, the coroutine will wait until it gets a std::string object and then print it. We say that the coroutine waits, we mean it is suspended (that is, not executed) until the data is received.\nWe start with changes to both the coroutine and the caller function:\nTask coro_func(){\n    std::cout &lt;&lt; co_await std::string{};\n    co_return;\n}\n\nint main(){\n    auto task = coro_func();\n    task.put(\"To boldly go where no man has gone before\");\n    return 0;\n}\nIn the preceding code, the caller function calls the put() function(a method in the return type structure) and the coroutine calls co_await to wait for a std::string object from the caller.\nThe changes to the return type are simple, that is, just adding the put() function.\nvoid put(std::string msg){\n    handle.promise().input_data = std::move(msg);\n    if(!handle.done()){\n        handle.resume();\n    }\n}\nWe need to add the input_data variable to the promise structure. But, just with those changes to our first example and the coroutine handle from the previous example, the code cannot be compiled.\n#include &lt;print&gt;\n#include &lt;string&gt;\n#include &lt;coroutine&gt;\n#include &lt;iostream&gt;\n\nstruct Task{\n    struct promise_type{\n        std::string input_data{};\n\n        Task get_return_object() noexcept{\n            std::println(\"get_return_object\");\n            return Task{ *this };\n        } \n\n        void return_void() noexcept{\n            std::println(\"return_void\");\n        }\n\n        std::suspend_always initial_suspend() noexcept{\n            std::println(\"initial_suspend\");\n            return {};\n        }\n\n        std::suspend_always final_suspend() noexcept{\n            std::println(\"final_suspend\");\n            return {};\n        }\n        void unhandled_exception() noexcept{\n            std::println(\"unhandled_exception\");\n        }\n\n        std::suspend_always yield_value(std::string msg) noexcept{\n            std::println(\"yield_value\");\n            //output_data = std::move(msg);\n            return {};\n        }\n    };\n\n    std::coroutine_handle&lt;promise_type&gt; handle{};\n\n    explicit Task(promise_type& promise)\n    : handle{ std::coroutine_handle&lt;promise_type&gt;::from_promise(promise)}\n    {\n        std::println(\"Task(promise_type&) ctor\");\n    }\n\n    ~Task() noexcept{\n        if(handle)\n            handle.destroy();\n\n        std::println(\"~Task()\");\n    }\n\n    void put(std::string msg){\n        handle.promise().input_data = std::move(msg);\n        if(!handle.done())\n            handle.resume();\n    }\n};\n\nTask coro_func(){\n    std::cout &lt;&lt; co_await std::string{};\n    co_return;\n}\n\nint main(){\n    auto task = coro_func();\n    task.put(\"To boldly go where no man has gone before\");\n    return 0;\n}\nCompiler Explorer\nThe compiler gives us the following error:\n&lt;source&gt;: In function 'Task coro_func()':\n&lt;source&gt;:62:18: error: no member named 'await_ready' in 'std::string' {aka 'std::__cxx11::basic_string&lt;char&gt;'}\n   62 |     std::cout &lt;&lt; co_await std::string{};\n      |                  ^~~~~~~~\nLet’s explore more about what this error message means."
  },
  {
    "objectID": "posts/coroutines/index.html#what-is-an-awaitable",
    "href": "posts/coroutines/index.html#what-is-an-awaitable",
    "title": "Coroutines",
    "section": "What is an awaitable?",
    "text": "What is an awaitable?\nAn awaitable is any object, I can call co_await on. You can think of co_await like an operator, and its argument as an awaitable. The way to think about the operator co_await is that these are opportunities for suspension. These are the points where the coroutine can be paused, and the control-flow can be handed back to the caller. The awaitable controls what happens at these points. Similar to, how the promise_type provides hooks to control what happens at startup or when you return from the coroutine, the awaitable provides these hooks for what happens when we go into suspension. They may decide not to suspend at all, and let the execution just continue. Not every co_await call necessary suspends. It’s totally upto the coroutine-writer. Let’s try to implement such an awaitable.\nstruct Awaitable{\n    bool await_ready();\n    void await_suspend(std::coroutine_handle&lt;promise_type&gt;);\n    void await_resume(std::coroutine_handle&lt;promise_type&gt;);\n};\nThe first function is .await_ready() which returns a bool. This determines whether we do actually go into suspension or we just say, yeah, we are ready, and we don’t want to go into suspension, we want to continue execution and in that case we just return true.\nThe next function is .await_suspend() and that is the customization point that will get executed shortly before the coroutine function goes to sleep.\nThe next function is .await_resume() and that is the customization point that will get execute just after the coroutine is resumed.\nThe following code shows our implementation of the await_transform function and the Awaitable struct:\nauto await_transform(std::string) noexcept{\n    struct Awaitable{\n        promise_type& promise;\n\n        bool await_ready() const noexcept{\n            return true;    // Says, yeah we are ready\n                            // we don't need to sleep. Just go on.\n        }\n\n        std::string await_resume() const noexcept{\n            return std::move(promise.input_data);\n        }\n\n        void await_suspend(std::coroutine_handle&lt;promise_type&gt;) const noexcept{}\n\n    };\n\n    return Awaitable(*this);\n}\nThis is the code for the full example of the waiting coroutine:\n#include &lt;print&gt;\n#include &lt;string&gt;\n#include &lt;coroutine&gt;\n#include &lt;iostream&gt;\n\nstruct Task{\n    struct promise_type{\n        std::string input_data{};\n\n        Task get_return_object() noexcept{\n            std::println(\"get_return_object\");\n            return Task{ *this };\n        } \n\n        void return_void() noexcept{\n            std::println(\"return_void\");\n        }\n\n        std::suspend_always initial_suspend() noexcept{\n            std::println(\"initial_suspend\");\n            return {};\n        }\n\n        std::suspend_always final_suspend() noexcept{\n            std::println(\"final_suspend\");\n            return {};\n        }\n        void unhandled_exception() noexcept{\n            std::println(\"unhandled_exception\");\n        }\n\n        std::suspend_always yield_value(std::string msg) noexcept{\n            std::println(\"yield_value\");\n            //output_data = std::move(msg);\n            return {};\n        }\n\n        auto await_transform(std::string) noexcept{\n            struct Awaitable{\n                promise_type& promise;\n\n                bool await_ready() const noexcept{\n                    return true;    // Says, yeah we are ready\n                                    // we don't need to sleep. Just go on.\n                }\n\n                std::string await_resume() const noexcept{\n                    return std::move(promise.input_data);\n                }\n\n                void await_suspend(std::coroutine_handle&lt;promise_type&gt;) const noexcept{}\n\n            };\n\n            return Awaitable(*this);\n        }\n    };\n\n    std::coroutine_handle&lt;promise_type&gt; handle{};\n\n    explicit Task(promise_type& promise)\n    : handle{ std::coroutine_handle&lt;promise_type&gt;::from_promise(promise)}\n    {\n        std::println(\"Task(promise_type&) ctor\");\n    }\n\n    ~Task() noexcept{\n        if(handle)\n            handle.destroy();\n\n        std::println(\"~Task()\");\n    }\n\n    void put(std::string msg){\n        handle.promise().input_data = std::move(msg);\n        if(!handle.done())\n            handle.resume();\n    }\n};\n\nTask coro_func(){\n    std::cout &lt;&lt; co_await std::string{};\n    co_return;\n}\n\nint main(){\n    auto task = coro_func();\n    task.put(\"To boldly go where no man has gone before\");\n    return 0;\n}\nCompiler Explorer\nOutput:\nget_return_object\nTask(promise_type&) ctor\ninitial_suspend\nTo boldly go where no man has gone beforereturn_void\nfinal_suspend\n~Task()"
  },
  {
    "objectID": "posts/coroutines/index.html#coroutine-generators",
    "href": "posts/coroutines/index.html#coroutine-generators",
    "title": "Coroutines",
    "section": "Coroutine Generators",
    "text": "Coroutine Generators\nA generator is a coroutine that generates a sequence of elements by repeatedly resuming itself from the point that it was suspended.\nA generator can be seen as an infinite list, because it can generate an arbitrary number of elements.\nI present below the source code for a simple FibonacciGenerator.\n#include &lt;print&gt;\n#include &lt;string&gt;\n#include &lt;coroutine&gt;\n#include &lt;iostream&gt;\n#include &lt;utility&gt;\n\nstruct Generator{\n    struct promise_type{\n        int fibo_n{0};\n\n        Generator get_return_object() noexcept{\n            return Generator{ *this };\n        } \n\n        void return_void() noexcept{}\n\n        std::suspend_always initial_suspend() noexcept{\n            return {};\n        }\n\n        std::suspend_always final_suspend() noexcept{\n            return {};\n        }\n        void unhandled_exception() noexcept{}\n\n        std::suspend_always yield_value(int n) noexcept{\n            fibo_n = n;\n            return {};\n        }\n    };\n\n    std::coroutine_handle&lt;promise_type&gt; handle{};\n\n    explicit Generator(promise_type& promise)\n    : handle{ std::coroutine_handle&lt;promise_type&gt;::from_promise(promise)}\n    {}\n\n    ~Generator() noexcept{\n        if(handle)\n            handle.destroy();\n    }\n\n    int next(){\n        if(!handle.done())\n            handle.resume();\n        return handle.promise().fibo_n;\n    }\n};\n\nGenerator makeFibonacciGenerator(){\n    int i1{0};\n    int i2{1};\n    while(true){\n        co_yield i1;\n        i1 = std::exchange(i2, i1 + i2);\n    }\n    co_return;\n}\n\nint main(){\n    auto fibo_gen = makeFibonacciGenerator();\n    std::println(\"The first 10 numbers the Fibonacci sequence are : \");\n    for(int i{1}; i&lt;=10; ++i){\n        std::println(\"F[{}] = {}\", i, fibo_gen.next());\n    }\n    return 0;\n}\nCompiler Explorer"
  },
  {
    "objectID": "posts/rust_crash_course_I/index.html",
    "href": "posts/rust_crash_course_I/index.html",
    "title": "A crash course in Rust - I",
    "section": "",
    "text": "I have been working through the excellent Learn Rust With Entirely Too Many Linked Lists and I summarize my learnings about Rust language features and code snippets I tried here.\n\n\n\nA linked list is a data-structure consisting of a collection of nodes which together form a sequence. In its most basic form, each node contains data and a reference (pointer or link) to the next node in the sequence. Consider defining a List as follows:\npub enum List{\n    Empty,\n    Element(i32, List),\n}\n\npub fn main(){}\nLet’s go ahead and compile that.\n[quantdev@quasar-arch ownership]$ rustc first.rs -o first.out\nerror[E0072]: recursive type `List` has infinite size\n --&gt; first.rs:1:1\n  |\n1 | pub enum List{\n  | ^^^^^^^^^^^^^\n2 |     Empty,\n3 |     Element(i32, List),\n  |                  ---- recursive without indirection\n  |\nhelp: insert some indirection (e.g., a `Box`, `Rc`, or `&`) to break the cycle                ---- recursive without indirection\nIf we actually checkout the error message, we can see that rustc is actually telling us exactly how to solve this problem.\nhelp: insert some indirection (e.g., a `Box`, `Rc`, or `&`) to break the cycle                ---- recursive without indirection\nAlright, Box. What’s that? Let’s google rust box.  module documentation states that Box&lt;T&gt; casually referred to as a ‘box’, provides the simplest form of heap allocation in Rust. Boxes provide ownership for this allocation, and drop their contents when they go out of scope.\n\n\nMove a value from a stack to the heap by creating a Box:\nlet val: u8 = 5;\nlet boxed:Box&lt;u8&gt; = Box::new(val);\nMoving a value from a Box back to the stack by dereferencing it:\nlet boxed: Box&lt;u8&gt; = Box::new(5);\nlet val: u8 = *boxed;\nCreating a recursive data-structure\n#[derive(Debug)]\npub enum List{\n    Empty,\n    Element(i32, Box&lt;List&gt;),\n}\n\npub fn main(){\n    let list : List = List::Element(1, Box::new(List::Element(2, Box::new(List::Empty))));\n    println!(\"{list:?}\");\n}\nIf I compile and run this code, it gives me:\n[quantdev@quasar-arch ownership]$ rustc first.rs -o first.out\n[quantdev@quasar-arch ownership]$ ./first.out\nElement(1, Element(2, Empty))\nRecursive data-structures must be boxed, because if the definition of List looked like this:\nElement(T, List)\nit wouldn’t work."
  },
  {
    "objectID": "posts/rust_crash_course_I/index.html#introduction",
    "href": "posts/rust_crash_course_I/index.html#introduction",
    "title": "A crash course in Rust - I",
    "section": "",
    "text": "I have been working through the excellent Learn Rust With Entirely Too Many Linked Lists and I summarize my learnings about Rust language features and code snippets I tried here."
  },
  {
    "objectID": "posts/rust_crash_course_I/index.html#designing-a-basic-linked-list",
    "href": "posts/rust_crash_course_I/index.html#designing-a-basic-linked-list",
    "title": "A crash course in Rust - I",
    "section": "",
    "text": "A linked list is a data-structure consisting of a collection of nodes which together form a sequence. In its most basic form, each node contains data and a reference (pointer or link) to the next node in the sequence. Consider defining a List as follows:\npub enum List{\n    Empty,\n    Element(i32, List),\n}\n\npub fn main(){}\nLet’s go ahead and compile that.\n[quantdev@quasar-arch ownership]$ rustc first.rs -o first.out\nerror[E0072]: recursive type `List` has infinite size\n --&gt; first.rs:1:1\n  |\n1 | pub enum List{\n  | ^^^^^^^^^^^^^\n2 |     Empty,\n3 |     Element(i32, List),\n  |                  ---- recursive without indirection\n  |\nhelp: insert some indirection (e.g., a `Box`, `Rc`, or `&`) to break the cycle                ---- recursive without indirection\nIf we actually checkout the error message, we can see that rustc is actually telling us exactly how to solve this problem.\nhelp: insert some indirection (e.g., a `Box`, `Rc`, or `&`) to break the cycle                ---- recursive without indirection\nAlright, Box. What’s that? Let’s google rust box.  module documentation states that Box&lt;T&gt; casually referred to as a ‘box’, provides the simplest form of heap allocation in Rust. Boxes provide ownership for this allocation, and drop their contents when they go out of scope.\n\n\nMove a value from a stack to the heap by creating a Box:\nlet val: u8 = 5;\nlet boxed:Box&lt;u8&gt; = Box::new(val);\nMoving a value from a Box back to the stack by dereferencing it:\nlet boxed: Box&lt;u8&gt; = Box::new(5);\nlet val: u8 = *boxed;\nCreating a recursive data-structure\n#[derive(Debug)]\npub enum List{\n    Empty,\n    Element(i32, Box&lt;List&gt;),\n}\n\npub fn main(){\n    let list : List = List::Element(1, Box::new(List::Element(2, Box::new(List::Empty))));\n    println!(\"{list:?}\");\n}\nIf I compile and run this code, it gives me:\n[quantdev@quasar-arch ownership]$ rustc first.rs -o first.out\n[quantdev@quasar-arch ownership]$ ./first.out\nElement(1, Element(2, Empty))\nRecursive data-structures must be boxed, because if the definition of List looked like this:\nElement(T, List)\nit wouldn’t work."
  },
  {
    "objectID": "posts/pythonic_code/index.html",
    "href": "posts/pythonic_code/index.html",
    "title": "Pythonic code",
    "section": "",
    "text": "Context managers are a very useful feature in Python. Most of the time, we see contet managers around resource management. For example, in situations, when we open files, we want to make sure they are closed after processing (so we do not leak file descriptors). Or, if we open a connection to a service (or even a socket), we also want to be sure to close it accordingly. In all of these cases, you would normally have to remember to free all of the resources that were allocated and that is just thinking about the best case - there could be also be exceptions and error handling. Handling all possible combinations and execution paths of our program makes it harder. There is a elegant Pythonic way of handling this.\nwith open(filename) as fd:\n    process_file(fd)\nThe with statement (PEP-43) enters the context manager. In this case, the open function implements the context manager protocol, which means that the file will be automatically closed when the block is finished, even if an exception occurred.\nContext managers consist of two magic methods __enter__ and __exit__. On the first line of the context manager, the with statement will call the first method, __enter__, and whatever this method returns will be assigned to the variable after as. This is optional - we don’t really need to return anything specific on the __enter__ method, even if we do, there is still no strict reason to assign it to a variable if it is not needed.\nAfter this line is executed, the code enters a new context, where any other Python code can be run. After the last statement on the block is finished, the context will be exited, meaning that Python will call the __exit__ method of the original context manager object we first invoked.\nIf there is an exception or error inside the context manager block, the __exit__ method will still be called, which makes it convenient for safely cleaning up the conditions. In fact, this method receives the exceptions that was triggered on the block in case we want to handle it in a custom fashion.\nContext managers are a good way of seperating concerns and isolating parts of the code that should be kept independent, because if we mix them, then the logic will become harder to maintain.\nAs an example, consider a situation where we want to run a backup of our database with a script. The caveat is that the backup is offline, which means that we can only do it while the database is not running, and for this we have to stop it. After running the backup, we want to be sure that we start the process again, regardless of how the backup itself went.\nInstead of creating a monolithic function to do this, we can tackle this issue with context managers:\ndef stop_database():\n    run(\"systemctl stop postgresql.service\")\n\ndef start_database():\n    run(\"systemctl start postgresql.service\")\n\nclass DBHandler:\n    def __enter__(self):\n        stop_database()\n        return self\n    \n    def __exit__(self, exc_type, ex_value, ex_traceback):\n        start_database()\n    \ndef db_backup():\n    run(\"pg_dump database\")\n\ndef main():\n    with DBHandler():\n        db_backup()\n\n\nIn general, we can implement context managers like the one in the previous example. All we need is just a class that implements the __enter__ and __exit__ magic methods, and then that object will be able to support the context manager protocol. While this is the most common way for context managers to be implemented, it is not the only one.\nThe contextlib module in the Python standard library contains a lot of helper functions and objects to implement context managers or use ones already provided that can help us write more compact code.\nLets start by looking at the contextmanager decorator.\nWhen the contextlib.contextmanager decorator is applied to a function, it converts the code on that function into a context manager. The function in question has to be a particular kind of function called a generator function, which will separate statements into what is going to be on __enter__ and __exit__ magic methods respectively.\nThe equivalent code in the previous example can be written as:\nimport contextlib\n\n@contextlib.contextmanager\ndef db_handler():\n    try:\n        stop_database()\n        yield\n    finally:\n        start_database()\n\nwith db_handler():\n    db_backup()\nHere, we define the generator function and apply the @contextlib.contextmanager decorator to it. The function contains a yield statement, which makes it a generator function. Details on generators are not important at this point. All we need to know, is when the decorator is applied, everything before the yield statement will be run as if it were part of the __enter__ method. Then the yielded value is going to be the result of the context manager evaluation (what __enter__ would return and what would be assigned to the variable if we chose to assign it like as x: - in this case nothing is yielded).\nAt the yield statement, the generator function is suspended, and the context manager is entered, where, again we run the backup code for our database. After this completes, the execution resumes, so we can consider every line that comes after the yield statement will be part of __exit__ logic.\nWriting context managers like this has the advantage that it is easier to refactor existing functions, reuse code and in general a good idea when we need a context manager that doesn’t belong to a particular object.\nUsing context managers is considered idiomatic.\n\n\n\n\nThe use of comprehensions is recommended to create data-structures in a single instruction, instead of multiple operations. For example, if we wanted to create a list with calculations over some numbers in it, instead of:\nnumbers = []\nfor i in range(10):\n    numbers.append(run_calculation(i))\nwe could do:\nnumbers = [run_calculation(i) for i in range(10)]\nThe introduction of assignment expressions in PEP-572 is also very useful.\n# Compute partial sums in a list comprehension\ntotal = 0\npartial_sums = [total := total + v for v in values]\nprint(\"Total:\", total)\nThe := operator is informally known as the walrus operator.\n\n\nIn this example, the assignment expression helps avoid calling len() twice:\n\na = list(range(1,16))\nif (n := len(a)) &gt; 10:\n    print(f\"List is too long ({n} elements, expected &lt;= 10)\")\n\nList is too long (15 elements, expected &lt;= 10)\n\n\nThe operator is also useful with while loops that compute a value to test loop termination and then need that value again in the body of the loop.\nwhile (block := f.read(256)) != ' ':\n    process(block)\nA subexpression can be shared between a comprehension filter and its output.\n\n# Share a subexpression between a comprehension filter clause and its output\ndef f(x):\n    if x % 2 == 0:\n        return x**2\n    else:\n        return None\n\ndata = [1, 2, 3, 4, 5]\nfiltered_data = [y for x in data if (y := f(x)) is not None]\nfiltered_data\n\n[4, 16]\n\n\nUnparenthesized assignment expressions are prohibited at the top level of an expression statement.\nKeep in mind however, that a more compact code does not always mean better better code. If to write a one-liner, we have to create a convoluted expression, then its not worth it, and we would be better off using a naive approach. This is related to the Keep it simple, stupid(KISS) principle.\nAnother good reason for using assignment expressions in general is the performance considerations. If we have to use a function as part of our transformation logic, we don’t want to call that more than is necessary. Assigning the result of the function to a temporary identifier is a good optimization technique.\n\n\n\n\nAll of the properties and functions of object are public in Python, which is different from other languages where properties can have the access specifier public, private and protected. That is, there is no point in preventing the caller from invoking any attributes an object has.\nThere is no strict enforcement, but there are some conventions. An attribute that starts with an underscore is meant to be private to that object, and we expect that no external agent calls it (but again nothing preventing this).\n\n\nThere are some conventions and implementation details that make use of underscores in Python, which is an interesting topic in itself that’s worthy of analysis.\nLike I mentioned, by default, all attributes of an object in python are public. Consider the following example :\n\nclass Point:\n    def __init__(self, x_value, y_value):\n        self._x_value = x_value\n        self._y_value = y_value\n\np1 = Point(1.0, 2.0)\np1.__dict__\n\n{'_x_value': 1.0, '_y_value': 2.0}\n\n\nAttributes that start with an underscore must be respected as private and not called externally. Using a single underscore prefix is the Pythonic way of clearly delimiting the interface of the object.\nNote that, using too many internal methods and attributes could be a sign that a class has too many tasks and doesn’t comply with the single responsibility princple.\nThere is however, a common misconception that some attributes and methods can actually be made private. This is again a misconception. Let us imagine that the x_value and y_value attributes are defined with a leading double underscore instead.\nclass Point:\n    def __init__(self, x_value : float, y_value : FloatingPointError):\n        self.__x_value = x_value\n        self._y_value = y_value\n\n    def scale(self, scale_factor : float):\n        self.__x_value *= scale_factor\n        self._y_value *= scale_factor\n\n\np1 = Point(1.0, 2.0)\np1.scale(2.0)\np1.__x_value\nOutput:\n--------------------------------------------------------------------------\nAttributeError                            Traceback (most recent call last)\nCell In[7], line 13\n     11 p1 = Point(1.0, 2.0)\n     12 p1.scale(2.0)\n---&gt; 13 p1.__x_value\n\nAttributeError: 'Point' object has no attribute '__x_value'\nSome developers use this method to hide some attributes, thinking that x_value is now private and that no other object can modify it. Now, take a look at the exception that it raised when trying to access __x_value. It’s AttributeError saying that it doesn’t exist. It doesn’t say something like this is private,\nWhat’s actually happening is that with the double underscores, Python creates a different name for the attribute (this is called as name mangling). What it does is create the attribute with the following name instead &lt;class_name&gt;__&lt;attribute_name&gt;. In this case the attribute named Point__x_value will be created.\n\np1.__dict__\n\n{'_x_value': 1.0, '_y_value': 2.0}\n\n\nThe idea of a double underscore in Python is completely different. It was created as a means to override different methods of a class that is going to be extended several times. Double underscores are a non-Pythonic approach. If you need to defined attributes as private, use a single underscore and respect the Pythonic convention that it is a private attribute.\n\n\n\nTypically, in object-oriented design we create objects to represent an abstraction over an entity of the problem domain. In this sense, objects can encapsulate the behavior or data. And more often than not, the accuracy of the data determines if an object can be created or not. That is to say, entities can exist for certain values of the data only, and incorrect values should not be allowed.\nThat is, why we create validation methods, typically to be used in setter operations. However, in Python, we can encapsulate the setter and getter methods more compactly using properties.\nConsider the example of a geographical system that needs to deal with coordinates. There is only a certain range of values for which the latitude and the longitude make sense. Outside of those values, a coordinate cannot exist.\n\nclass Coordinate:\n    def __init__(self, lat: float, long: float) -&gt; None:\n        self._latitude = self._longitude = None\n        self.latitude = lat\n        self.longitude = long\n\n    @property\n    def latitude(self) -&gt; float:\n        return self._latitude\n\n    @latitude.setter\n    def latitude(self, lat_value: float) -&gt; None:\n        if lat_value not in range(-90, 90 + 1):\n            raise ValueError(f\"{lat_value} is an invalid value for latitude\")\n\n        self._latitude = lat_value\n\n    @property\n    def longitude(self)-&gt;float:\n        return self._longitude\n\n    @longitude.setter\n    def longitude(self, long_value:float) -&gt; None:\n        if long_value not in range(-180, 180+1):\n            raise ValueError(f\"{lat_value} is an invalid value for longitude\")\n\n        self._longitude = long_value\n\n\n\n\n\nA dataclass is a class that exists primarily to store values which are accessible by attribute lookup and not complex logic. There is a common boilerplate when it comes to initialization of such objects, which is to declare in the __init__ method all attributes that the object will have, and then set that to internal variables.\nclass Point:\n    def __init__(self, x:float, y:float) -&gt; None:\n        self._x = x\n        self._y = y\nSince Python 3.7 we can simplify this by using the dataclasses module, which was introduced in PEP-557. We’ll review this module briefly to understand how it helps us write compact code.\nThe module provides a @dataclass decorator objectr which when applied to a class, it’ll take all the class attributes with annotations and treat them as instance attributes, as if they were declared in the initialization method. When using this method, it will automatically generate the __init__ method on the class.\nAdditionally, this module provides a field object that will help us define particular traits for some of the attributes.\n\nfrom dataclasses import dataclass, field\n\n@dataclass\nclass VanillaOptionQuote:\n    strike : float\n    spot : float\n    implied_vol : float \n    underlying : str \n    time_to_maturity : float = field(default=1.0)\n\nThe Field objects describe each field. These objects are created internally and are returned by the fields() module-level method. Users should never instantiate a Field object directly. Its documented attributes are:\n\nname: Name of the field\ntype: The type of the field\ndefault: If provided, this will be th default value for this field.\ndefault_factory: If provided, it must be a zero-argument callable that will be called when a default value is needed for this field.\ninit: If true(default), this field is included as a parameter in the generated __init__ method.\n__repr__ : If true(default), this field is included in the string returned by __repr__ method.\n\nA good use-case for dataclass would be all those places when we need to use objects as data-containers or wrappers.\n\n\nIt is not possible to create truly immutable Python objects. However, by passing frozen=True to the @dataclass decorator you can emulate immutability. In that case, Data Classes will add __setattr__ and __delattr__ methods to the class. These methods will raise a FrozenInstanceError when invoked.\n\n\n\n\nattrs moves faster than could be accomodated if it were moved to the standard library.\nattrs supports additional features not being proposed here : validators, converters, metadata etc.\n\n\n\n\n\nIn python, we have objects that can be iterated by default. For example, lists, sets, tuples and dictionaries can not only hold data in the structure, but also be iterated over a for loop to get those values repeatedly.\nHowever, the built-in iterable objects are not the only kind we can have in a for loop. We can also create our own iterable, with the logic we define for iteration.\nIn order to achieve this, we rely again on magic methods. Iteration works in Python by its own protocol(namely the iterator protocol). When you try to iterate an object in the form for e in my_collection:..., at a high-level, Python checks for:\n\nIf the object contains one of the iterator methods - __next__ or __iter__.\nIf the object is a sequence and has __len__ and __get_item__\n\n\n\n\nfrom datetime import timedelta\nimport datetime as dt\n\nclass DateRange:\n    \"\"\"An iterable that contains its own iterator object.\"\"\"\n    def __init__(self, start_date: dt.date, end_date: dt.date):\n        self._start_date = start_date\n        self._end_date = end_date\n        self._present_date = start_date\n\n    def __iter__(self):\n        return self\n\n    def __next__(self):\n        if self._present_date &gt;= self._end_date:\n            raise StopIteration()\n\n        today = self._present_date\n        self._present_date += timedelta(days=1)\n        return today\n\nfor day in DateRange(dt.date(2026,1,1), dt.date(2026, 1, 8)):\n    print(f\"{day}\")        \n\n2026-01-01\n2026-01-02\n2026-01-03\n2026-01-04\n2026-01-05\n2026-01-06\n2026-01-07\n\n\n\n\n\nHere, the for loop starts a new iteration over our object. At this point Python will call the iter() function on it, which in turn will call the __iter__ magic method. On this method, it is decided to return self, indicating that the object is an iterable itself. Every step of the loop calls the next() function on this object, which delegates to __next__ method. When there is nothing else to produce, we have to signal this to Python by raising StopIteration exception.\n\nr = DateRange(dt.date(2026,1,1), dt.date(2026, 1, 8))\nprint(next(r))\nprint(next(r))\nprint(next(r))\nprint(next(r))\n\n2026-01-01\n2026-01-02\n2026-01-03\n2026-01-04\n\n\nThis example works, but it has a small problem - once exhausted, the iterable will continue to be empty, hence raising StopIteration.\nIf there are two or more consecutive for loops, only the first one will work, while the second one will remain empty. Because, there is only one shared iteration state. We should separate out the iterator from the iterable.\n\n\n\n\nMaybe our object does not define the __iter__() method, but we still want to be able to iterate over it. If __iter__ is not defined on the object, the iter() function will look for the presence of __getitem__, and if this is not found, it will raise TypeError.\nA sequence is an object that implements __len__ and __getitem__ magic methods and expects to be able to get the elements it contains, one at a time, in order, starting at \\(0\\) as the first index. This means that you should be careful in the logic so that you correctly implement __get_item__ to expect this type of index, or the iteration will not work.\nThe example from the previous section had the advantage that it uses less memory. This means that it is only holding one date at a time and knows how to produce the days one by one. However, it has the drawback that if we want to get to the nth element, we have no way to do so but iterate \\(n\\) times. until we reach it. This is a typical trade-off in CS between memory and CPU usage.\nThe implementation with an iterable will use memory, but take \\(O(n)\\) time, whereas implementing a sequence will use more(because we have to hold everything at once),but supports indexing in constant time.\n\nclass DateRangeSequence:\n    def __init__(self, start_date : dt.date, end_date:dt.date):\n        self._start_date = start_date\n        self._end_date = end_date\n        self._range = self._create_range()\n\n    def _create_range(self):\n        days = []\n        current_date = self._start_date\n        while current_date &lt; self._end_date:\n            days.append(current_date)\n            current_date += timedelta(days=1)\n\n        return days\n    \n    def __getitem__(self, day_idx):\n        return self._range[day_idx]\n\n    def __len__(self):\n        return len(self._range)\n\ns1 = DateRangeSequence(dt.date(2026,1,1), dt.date(2026,1,6))\nfor day in s1:\n    print(day)\n\n2026-01-01\n2026-01-02\n2026-01-03\n2026-01-04\n2026-01-05\n\n\n\n\n\nContainers are objects that implement a __contains__ method(that usually returns a boolean value). This method is called in the presence of the python keyword in.\n\nfrom dataclasses import dataclass\n\n@dataclass\nclass Interval:\n    left_end_point : float \n    right_end_point : float\n    exclude_right_end : bool = True\n\n    def __contains__(self, x_value : float):\n        if self.exclude_right_end:\n            return self.left_end_point &lt;= x_value and x_value &lt; self.right_end_point \n        else:\n            return self.left_end_point &lt;= x_value and x_value &lt;= self.right_end_point \n\ninterval = Interval(0.0,1.0)\nprint(f\"Is 0.5 contained in the interval [0,1) : {0.5 in interval}\")\nprint(f\"Is 1.0 contained in the interval [0,1) : {1.0 in interval}\")\n\nIs 0.5 contained in the interval [0,1) : True\nIs 1.0 contained in the interval [0,1) : False\n\n\n\n\n\nIt is possible to control the way attributes are obtained from objects by means of the __getattr__ magic method. When we call something like &lt;my_object&gt;.&lt;my_attribute&gt;, Python will look at &lt;my_attribute&gt; in the dictionary of the object, calling __get_attribute__. If this is not found (that is, the object does not have the attribute we are looking for), then the extra method __getattr__ is called, passing in the name of the attribute as a parameter.\nBy receiving this value, we can control the way things should be returned to our objects. We can even create new attributes on the fly.\n\nclass DynamicAttributes:\n    def __init__(self, attribute):\n        self.attribute = attribute\n    \n    def __getattr__(self, attr):\n        if attr.startswith(\"fallback_\"):\n            name = attr.replace(\"fallback_\", \"\")\n            return f\"[fallback resolved] {name}\"\n    \n        raise AttributeError(f\"{self.__class__.__name__} has no attribute {attr}\")\n\n\n\n\n\nfrom collections import defaultdict\n\nclass CallCount:\n    def __init__(self):\n        self._counts = defaultdict(int)\n\n    def __call__(self, argument):\n        self._counts[argument] += 1\n        return self._counts[argument]\n\ncall_count = CallCount()\nprint(call_count(\"Hello\"))\nprint(call_count(\"World\"))\nprint(call_count(\"Hello\"))\n\n1\n1\n2\n\n\n\n\n\nThe best way to implement these methods is to declare our class to inherit from the corresponding class defined in the collections.abc module.\nThese interfaces provide the methods that need to be implemented, so it’ll make it easier for you to define the class correctly.\nWith practice and experience, you become more fluent with these features of Python, until it becomes second nature for you wrap the logic you’re writing behind abstractions with nice and small interfaces. Give it enough time, and you’ll naturally think of having small, clean interfaces in your programs.\n\n\n\n\n\nDon’t use mutable objects as the default arguments of functions."
  },
  {
    "objectID": "posts/pythonic_code/index.html#context-managers",
    "href": "posts/pythonic_code/index.html#context-managers",
    "title": "Pythonic code",
    "section": "",
    "text": "Context managers are a very useful feature in Python. Most of the time, we see contet managers around resource management. For example, in situations, when we open files, we want to make sure they are closed after processing (so we do not leak file descriptors). Or, if we open a connection to a service (or even a socket), we also want to be sure to close it accordingly. In all of these cases, you would normally have to remember to free all of the resources that were allocated and that is just thinking about the best case - there could be also be exceptions and error handling. Handling all possible combinations and execution paths of our program makes it harder. There is a elegant Pythonic way of handling this.\nwith open(filename) as fd:\n    process_file(fd)\nThe with statement (PEP-43) enters the context manager. In this case, the open function implements the context manager protocol, which means that the file will be automatically closed when the block is finished, even if an exception occurred.\nContext managers consist of two magic methods __enter__ and __exit__. On the first line of the context manager, the with statement will call the first method, __enter__, and whatever this method returns will be assigned to the variable after as. This is optional - we don’t really need to return anything specific on the __enter__ method, even if we do, there is still no strict reason to assign it to a variable if it is not needed.\nAfter this line is executed, the code enters a new context, where any other Python code can be run. After the last statement on the block is finished, the context will be exited, meaning that Python will call the __exit__ method of the original context manager object we first invoked.\nIf there is an exception or error inside the context manager block, the __exit__ method will still be called, which makes it convenient for safely cleaning up the conditions. In fact, this method receives the exceptions that was triggered on the block in case we want to handle it in a custom fashion.\nContext managers are a good way of seperating concerns and isolating parts of the code that should be kept independent, because if we mix them, then the logic will become harder to maintain.\nAs an example, consider a situation where we want to run a backup of our database with a script. The caveat is that the backup is offline, which means that we can only do it while the database is not running, and for this we have to stop it. After running the backup, we want to be sure that we start the process again, regardless of how the backup itself went.\nInstead of creating a monolithic function to do this, we can tackle this issue with context managers:\ndef stop_database():\n    run(\"systemctl stop postgresql.service\")\n\ndef start_database():\n    run(\"systemctl start postgresql.service\")\n\nclass DBHandler:\n    def __enter__(self):\n        stop_database()\n        return self\n    \n    def __exit__(self, exc_type, ex_value, ex_traceback):\n        start_database()\n    \ndef db_backup():\n    run(\"pg_dump database\")\n\ndef main():\n    with DBHandler():\n        db_backup()\n\n\nIn general, we can implement context managers like the one in the previous example. All we need is just a class that implements the __enter__ and __exit__ magic methods, and then that object will be able to support the context manager protocol. While this is the most common way for context managers to be implemented, it is not the only one.\nThe contextlib module in the Python standard library contains a lot of helper functions and objects to implement context managers or use ones already provided that can help us write more compact code.\nLets start by looking at the contextmanager decorator.\nWhen the contextlib.contextmanager decorator is applied to a function, it converts the code on that function into a context manager. The function in question has to be a particular kind of function called a generator function, which will separate statements into what is going to be on __enter__ and __exit__ magic methods respectively.\nThe equivalent code in the previous example can be written as:\nimport contextlib\n\n@contextlib.contextmanager\ndef db_handler():\n    try:\n        stop_database()\n        yield\n    finally:\n        start_database()\n\nwith db_handler():\n    db_backup()\nHere, we define the generator function and apply the @contextlib.contextmanager decorator to it. The function contains a yield statement, which makes it a generator function. Details on generators are not important at this point. All we need to know, is when the decorator is applied, everything before the yield statement will be run as if it were part of the __enter__ method. Then the yielded value is going to be the result of the context manager evaluation (what __enter__ would return and what would be assigned to the variable if we chose to assign it like as x: - in this case nothing is yielded).\nAt the yield statement, the generator function is suspended, and the context manager is entered, where, again we run the backup code for our database. After this completes, the execution resumes, so we can consider every line that comes after the yield statement will be part of __exit__ logic.\nWriting context managers like this has the advantage that it is easier to refactor existing functions, reuse code and in general a good idea when we need a context manager that doesn’t belong to a particular object.\nUsing context managers is considered idiomatic."
  },
  {
    "objectID": "posts/pythonic_code/index.html#comprehensions-and-assignment-expressions",
    "href": "posts/pythonic_code/index.html#comprehensions-and-assignment-expressions",
    "title": "Pythonic code",
    "section": "",
    "text": "The use of comprehensions is recommended to create data-structures in a single instruction, instead of multiple operations. For example, if we wanted to create a list with calculations over some numbers in it, instead of:\nnumbers = []\nfor i in range(10):\n    numbers.append(run_calculation(i))\nwe could do:\nnumbers = [run_calculation(i) for i in range(10)]\nThe introduction of assignment expressions in PEP-572 is also very useful.\n# Compute partial sums in a list comprehension\ntotal = 0\npartial_sums = [total := total + v for v in values]\nprint(\"Total:\", total)\nThe := operator is informally known as the walrus operator.\n\n\nIn this example, the assignment expression helps avoid calling len() twice:\n\na = list(range(1,16))\nif (n := len(a)) &gt; 10:\n    print(f\"List is too long ({n} elements, expected &lt;= 10)\")\n\nList is too long (15 elements, expected &lt;= 10)\n\n\nThe operator is also useful with while loops that compute a value to test loop termination and then need that value again in the body of the loop.\nwhile (block := f.read(256)) != ' ':\n    process(block)\nA subexpression can be shared between a comprehension filter and its output.\n\n# Share a subexpression between a comprehension filter clause and its output\ndef f(x):\n    if x % 2 == 0:\n        return x**2\n    else:\n        return None\n\ndata = [1, 2, 3, 4, 5]\nfiltered_data = [y for x in data if (y := f(x)) is not None]\nfiltered_data\n\n[4, 16]\n\n\nUnparenthesized assignment expressions are prohibited at the top level of an expression statement.\nKeep in mind however, that a more compact code does not always mean better better code. If to write a one-liner, we have to create a convoluted expression, then its not worth it, and we would be better off using a naive approach. This is related to the Keep it simple, stupid(KISS) principle.\nAnother good reason for using assignment expressions in general is the performance considerations. If we have to use a function as part of our transformation logic, we don’t want to call that more than is necessary. Assigning the result of the function to a temporary identifier is a good optimization technique."
  },
  {
    "objectID": "posts/pythonic_code/index.html#properties-attributes-and-different-types-of-methods-for-objects",
    "href": "posts/pythonic_code/index.html#properties-attributes-and-different-types-of-methods-for-objects",
    "title": "Pythonic code",
    "section": "",
    "text": "All of the properties and functions of object are public in Python, which is different from other languages where properties can have the access specifier public, private and protected. That is, there is no point in preventing the caller from invoking any attributes an object has.\nThere is no strict enforcement, but there are some conventions. An attribute that starts with an underscore is meant to be private to that object, and we expect that no external agent calls it (but again nothing preventing this).\n\n\nThere are some conventions and implementation details that make use of underscores in Python, which is an interesting topic in itself that’s worthy of analysis.\nLike I mentioned, by default, all attributes of an object in python are public. Consider the following example :\n\nclass Point:\n    def __init__(self, x_value, y_value):\n        self._x_value = x_value\n        self._y_value = y_value\n\np1 = Point(1.0, 2.0)\np1.__dict__\n\n{'_x_value': 1.0, '_y_value': 2.0}\n\n\nAttributes that start with an underscore must be respected as private and not called externally. Using a single underscore prefix is the Pythonic way of clearly delimiting the interface of the object.\nNote that, using too many internal methods and attributes could be a sign that a class has too many tasks and doesn’t comply with the single responsibility princple.\nThere is however, a common misconception that some attributes and methods can actually be made private. This is again a misconception. Let us imagine that the x_value and y_value attributes are defined with a leading double underscore instead.\nclass Point:\n    def __init__(self, x_value : float, y_value : FloatingPointError):\n        self.__x_value = x_value\n        self._y_value = y_value\n\n    def scale(self, scale_factor : float):\n        self.__x_value *= scale_factor\n        self._y_value *= scale_factor\n\n\np1 = Point(1.0, 2.0)\np1.scale(2.0)\np1.__x_value\nOutput:\n--------------------------------------------------------------------------\nAttributeError                            Traceback (most recent call last)\nCell In[7], line 13\n     11 p1 = Point(1.0, 2.0)\n     12 p1.scale(2.0)\n---&gt; 13 p1.__x_value\n\nAttributeError: 'Point' object has no attribute '__x_value'\nSome developers use this method to hide some attributes, thinking that x_value is now private and that no other object can modify it. Now, take a look at the exception that it raised when trying to access __x_value. It’s AttributeError saying that it doesn’t exist. It doesn’t say something like this is private,\nWhat’s actually happening is that with the double underscores, Python creates a different name for the attribute (this is called as name mangling). What it does is create the attribute with the following name instead &lt;class_name&gt;__&lt;attribute_name&gt;. In this case the attribute named Point__x_value will be created.\n\np1.__dict__\n\n{'_x_value': 1.0, '_y_value': 2.0}\n\n\nThe idea of a double underscore in Python is completely different. It was created as a means to override different methods of a class that is going to be extended several times. Double underscores are a non-Pythonic approach. If you need to defined attributes as private, use a single underscore and respect the Pythonic convention that it is a private attribute.\n\n\n\nTypically, in object-oriented design we create objects to represent an abstraction over an entity of the problem domain. In this sense, objects can encapsulate the behavior or data. And more often than not, the accuracy of the data determines if an object can be created or not. That is to say, entities can exist for certain values of the data only, and incorrect values should not be allowed.\nThat is, why we create validation methods, typically to be used in setter operations. However, in Python, we can encapsulate the setter and getter methods more compactly using properties.\nConsider the example of a geographical system that needs to deal with coordinates. There is only a certain range of values for which the latitude and the longitude make sense. Outside of those values, a coordinate cannot exist.\n\nclass Coordinate:\n    def __init__(self, lat: float, long: float) -&gt; None:\n        self._latitude = self._longitude = None\n        self.latitude = lat\n        self.longitude = long\n\n    @property\n    def latitude(self) -&gt; float:\n        return self._latitude\n\n    @latitude.setter\n    def latitude(self, lat_value: float) -&gt; None:\n        if lat_value not in range(-90, 90 + 1):\n            raise ValueError(f\"{lat_value} is an invalid value for latitude\")\n\n        self._latitude = lat_value\n\n    @property\n    def longitude(self)-&gt;float:\n        return self._longitude\n\n    @longitude.setter\n    def longitude(self, long_value:float) -&gt; None:\n        if long_value not in range(-180, 180+1):\n            raise ValueError(f\"{lat_value} is an invalid value for longitude\")\n\n        self._longitude = long_value"
  },
  {
    "objectID": "posts/pythonic_code/index.html#using-dataclasses",
    "href": "posts/pythonic_code/index.html#using-dataclasses",
    "title": "Pythonic code",
    "section": "",
    "text": "A dataclass is a class that exists primarily to store values which are accessible by attribute lookup and not complex logic. There is a common boilerplate when it comes to initialization of such objects, which is to declare in the __init__ method all attributes that the object will have, and then set that to internal variables.\nclass Point:\n    def __init__(self, x:float, y:float) -&gt; None:\n        self._x = x\n        self._y = y\nSince Python 3.7 we can simplify this by using the dataclasses module, which was introduced in PEP-557. We’ll review this module briefly to understand how it helps us write compact code.\nThe module provides a @dataclass decorator objectr which when applied to a class, it’ll take all the class attributes with annotations and treat them as instance attributes, as if they were declared in the initialization method. When using this method, it will automatically generate the __init__ method on the class.\nAdditionally, this module provides a field object that will help us define particular traits for some of the attributes.\n\nfrom dataclasses import dataclass, field\n\n@dataclass\nclass VanillaOptionQuote:\n    strike : float\n    spot : float\n    implied_vol : float \n    underlying : str \n    time_to_maturity : float = field(default=1.0)\n\nThe Field objects describe each field. These objects are created internally and are returned by the fields() module-level method. Users should never instantiate a Field object directly. Its documented attributes are:\n\nname: Name of the field\ntype: The type of the field\ndefault: If provided, this will be th default value for this field.\ndefault_factory: If provided, it must be a zero-argument callable that will be called when a default value is needed for this field.\ninit: If true(default), this field is included as a parameter in the generated __init__ method.\n__repr__ : If true(default), this field is included in the string returned by __repr__ method.\n\nA good use-case for dataclass would be all those places when we need to use objects as data-containers or wrappers.\n\n\nIt is not possible to create truly immutable Python objects. However, by passing frozen=True to the @dataclass decorator you can emulate immutability. In that case, Data Classes will add __setattr__ and __delattr__ methods to the class. These methods will raise a FrozenInstanceError when invoked.\n\n\n\n\nattrs moves faster than could be accomodated if it were moved to the standard library.\nattrs supports additional features not being proposed here : validators, converters, metadata etc."
  },
  {
    "objectID": "posts/pythonic_code/index.html#iterable-objects",
    "href": "posts/pythonic_code/index.html#iterable-objects",
    "title": "Pythonic code",
    "section": "",
    "text": "In python, we have objects that can be iterated by default. For example, lists, sets, tuples and dictionaries can not only hold data in the structure, but also be iterated over a for loop to get those values repeatedly.\nHowever, the built-in iterable objects are not the only kind we can have in a for loop. We can also create our own iterable, with the logic we define for iteration.\nIn order to achieve this, we rely again on magic methods. Iteration works in Python by its own protocol(namely the iterator protocol). When you try to iterate an object in the form for e in my_collection:..., at a high-level, Python checks for:\n\nIf the object contains one of the iterator methods - __next__ or __iter__.\nIf the object is a sequence and has __len__ and __get_item__\n\n\n\n\nfrom datetime import timedelta\nimport datetime as dt\n\nclass DateRange:\n    \"\"\"An iterable that contains its own iterator object.\"\"\"\n    def __init__(self, start_date: dt.date, end_date: dt.date):\n        self._start_date = start_date\n        self._end_date = end_date\n        self._present_date = start_date\n\n    def __iter__(self):\n        return self\n\n    def __next__(self):\n        if self._present_date &gt;= self._end_date:\n            raise StopIteration()\n\n        today = self._present_date\n        self._present_date += timedelta(days=1)\n        return today\n\nfor day in DateRange(dt.date(2026,1,1), dt.date(2026, 1, 8)):\n    print(f\"{day}\")        \n\n2026-01-01\n2026-01-02\n2026-01-03\n2026-01-04\n2026-01-05\n2026-01-06\n2026-01-07\n\n\n\n\n\nHere, the for loop starts a new iteration over our object. At this point Python will call the iter() function on it, which in turn will call the __iter__ magic method. On this method, it is decided to return self, indicating that the object is an iterable itself. Every step of the loop calls the next() function on this object, which delegates to __next__ method. When there is nothing else to produce, we have to signal this to Python by raising StopIteration exception.\n\nr = DateRange(dt.date(2026,1,1), dt.date(2026, 1, 8))\nprint(next(r))\nprint(next(r))\nprint(next(r))\nprint(next(r))\n\n2026-01-01\n2026-01-02\n2026-01-03\n2026-01-04\n\n\nThis example works, but it has a small problem - once exhausted, the iterable will continue to be empty, hence raising StopIteration.\nIf there are two or more consecutive for loops, only the first one will work, while the second one will remain empty. Because, there is only one shared iteration state. We should separate out the iterator from the iterable."
  },
  {
    "objectID": "posts/pythonic_code/index.html#creating-sequences",
    "href": "posts/pythonic_code/index.html#creating-sequences",
    "title": "Pythonic code",
    "section": "",
    "text": "Maybe our object does not define the __iter__() method, but we still want to be able to iterate over it. If __iter__ is not defined on the object, the iter() function will look for the presence of __getitem__, and if this is not found, it will raise TypeError.\nA sequence is an object that implements __len__ and __getitem__ magic methods and expects to be able to get the elements it contains, one at a time, in order, starting at \\(0\\) as the first index. This means that you should be careful in the logic so that you correctly implement __get_item__ to expect this type of index, or the iteration will not work.\nThe example from the previous section had the advantage that it uses less memory. This means that it is only holding one date at a time and knows how to produce the days one by one. However, it has the drawback that if we want to get to the nth element, we have no way to do so but iterate \\(n\\) times. until we reach it. This is a typical trade-off in CS between memory and CPU usage.\nThe implementation with an iterable will use memory, but take \\(O(n)\\) time, whereas implementing a sequence will use more(because we have to hold everything at once),but supports indexing in constant time.\n\nclass DateRangeSequence:\n    def __init__(self, start_date : dt.date, end_date:dt.date):\n        self._start_date = start_date\n        self._end_date = end_date\n        self._range = self._create_range()\n\n    def _create_range(self):\n        days = []\n        current_date = self._start_date\n        while current_date &lt; self._end_date:\n            days.append(current_date)\n            current_date += timedelta(days=1)\n\n        return days\n    \n    def __getitem__(self, day_idx):\n        return self._range[day_idx]\n\n    def __len__(self):\n        return len(self._range)\n\ns1 = DateRangeSequence(dt.date(2026,1,1), dt.date(2026,1,6))\nfor day in s1:\n    print(day)\n\n2026-01-01\n2026-01-02\n2026-01-03\n2026-01-04\n2026-01-05"
  },
  {
    "objectID": "posts/pythonic_code/index.html#container-objects",
    "href": "posts/pythonic_code/index.html#container-objects",
    "title": "Pythonic code",
    "section": "",
    "text": "Containers are objects that implement a __contains__ method(that usually returns a boolean value). This method is called in the presence of the python keyword in.\n\nfrom dataclasses import dataclass\n\n@dataclass\nclass Interval:\n    left_end_point : float \n    right_end_point : float\n    exclude_right_end : bool = True\n\n    def __contains__(self, x_value : float):\n        if self.exclude_right_end:\n            return self.left_end_point &lt;= x_value and x_value &lt; self.right_end_point \n        else:\n            return self.left_end_point &lt;= x_value and x_value &lt;= self.right_end_point \n\ninterval = Interval(0.0,1.0)\nprint(f\"Is 0.5 contained in the interval [0,1) : {0.5 in interval}\")\nprint(f\"Is 1.0 contained in the interval [0,1) : {1.0 in interval}\")\n\nIs 0.5 contained in the interval [0,1) : True\nIs 1.0 contained in the interval [0,1) : False"
  },
  {
    "objectID": "posts/pythonic_code/index.html#dynamic-attributes",
    "href": "posts/pythonic_code/index.html#dynamic-attributes",
    "title": "Pythonic code",
    "section": "",
    "text": "It is possible to control the way attributes are obtained from objects by means of the __getattr__ magic method. When we call something like &lt;my_object&gt;.&lt;my_attribute&gt;, Python will look at &lt;my_attribute&gt; in the dictionary of the object, calling __get_attribute__. If this is not found (that is, the object does not have the attribute we are looking for), then the extra method __getattr__ is called, passing in the name of the attribute as a parameter.\nBy receiving this value, we can control the way things should be returned to our objects. We can even create new attributes on the fly.\n\nclass DynamicAttributes:\n    def __init__(self, attribute):\n        self.attribute = attribute\n    \n    def __getattr__(self, attr):\n        if attr.startswith(\"fallback_\"):\n            name = attr.replace(\"fallback_\", \"\")\n            return f\"[fallback resolved] {name}\"\n    \n        raise AttributeError(f\"{self.__class__.__name__} has no attribute {attr}\")"
  },
  {
    "objectID": "posts/pythonic_code/index.html#callable-objects",
    "href": "posts/pythonic_code/index.html#callable-objects",
    "title": "Pythonic code",
    "section": "",
    "text": "from collections import defaultdict\n\nclass CallCount:\n    def __init__(self):\n        self._counts = defaultdict(int)\n\n    def __call__(self, argument):\n        self._counts[argument] += 1\n        return self._counts[argument]\n\ncall_count = CallCount()\nprint(call_count(\"Hello\"))\nprint(call_count(\"World\"))\nprint(call_count(\"Hello\"))\n\n1\n1\n2"
  },
  {
    "objectID": "posts/pythonic_code/index.html#python-collections.abc-module",
    "href": "posts/pythonic_code/index.html#python-collections.abc-module",
    "title": "Pythonic code",
    "section": "",
    "text": "The best way to implement these methods is to declare our class to inherit from the corresponding class defined in the collections.abc module.\nThese interfaces provide the methods that need to be implemented, so it’ll make it easier for you to define the class correctly.\nWith practice and experience, you become more fluent with these features of Python, until it becomes second nature for you wrap the logic you’re writing behind abstractions with nice and small interfaces. Give it enough time, and you’ll naturally think of having small, clean interfaces in your programs."
  },
  {
    "objectID": "posts/pythonic_code/index.html#caveats",
    "href": "posts/pythonic_code/index.html#caveats",
    "title": "Pythonic code",
    "section": "",
    "text": "Don’t use mutable objects as the default arguments of functions."
  },
  {
    "objectID": "posts/pymalloc_deep_dive/index.html",
    "href": "posts/pymalloc_deep_dive/index.html",
    "title": "Pymalloc - Down the rabit hole",
    "section": "",
    "text": "Download the CPython source and build it in the debug mode to step into the interpreter’s internals.\ngit clone https://github.com/python/cpython.git\ncd cpython\n\n# Configure with debug options\n./configure --with-pydebug\n\n# Build (feel free to adjust -j)\nmake -j8\nThis will produce a local python binary."
  },
  {
    "objectID": "posts/pymalloc_deep_dive/index.html#blocks-pools-and-arenas",
    "href": "posts/pymalloc_deep_dive/index.html#blocks-pools-and-arenas",
    "title": "Pymalloc - Down the rabit hole",
    "section": "Blocks, Pools and Arenas",
    "text": "Blocks, Pools and Arenas\npymalloc allocates large memory regions called arenas from the system, then divides them into pools.\n\nArenas\nArenas are allocated from the system heap using mmap when available otherwise malloc. CPython arenas are \\(256\\)-KB on 32-bit systems and \\(1\\) MB on 64-bit systems. Each arena contains multiple pools.\n#ifdef USE_LARGE_ARENAS\n#define ARENA_BITS              20                    /* 1 MiB */\n#else\n#define ARENA_BITS              18                    /* 256 KiB */\n#endif\n#define ARENA_SIZE              (1 &lt;&lt; ARENA_BITS)\n#define ARENA_SIZE_MASK         (ARENA_SIZE - 1)\nArenas are scattered in the main memory. Each arena is a contiguous chunk of memory. CPython maintains a doubly linked list usable_arenas that tracks all the arena objects, that have atleast one pool available for allocation. The usable_arenas list is maintained in ascending order of each arena’s nfreepools (number of free pools). This sorting ensures that allocations preferentially use arenas with fewest free pools.\nOur main book-keeping data structure of interest is the arena_object. The usable_arenas doubly linked list strings together arena_object nodes . These contain meta-information of each arena with prevarena and nextarena pointers. Each of these nodes have a address field which is a pointer to the actual contiguous block of memory (\\(256\\)KB / \\(1\\)MB) returned by malloc.\n/* Record keeping for arenas. */\nstruct arena_object {\n    /* The address of the arena, as returned by malloc.  Note that 0\n     * will never be returned by a successful malloc, and is used\n     * here to mark an arena_object that doesn't correspond to an\n     * allocated arena.\n     */\n    uintptr_t address;\n\n    /* Pool-aligned pointer to the next pool to be carved off. */\n    pymem_block* pool_address;\n\n    /* The number of available pools in the arena:  free pools + never-\n     * allocated pools.\n     */\n    uint nfreepools;\n\n    /* The total number of pools in the arena, whether or not available. */\n    uint ntotalpools;\n\n    /* Singly-linked list of available pools. */\n    struct pool_header* freepools;\n    /* Whenever this arena_object is not associated with an allocated\n     * arena, the nextarena member is used to link all unassociated\n     * arena_objects in the singly-linked `unused_arena_objects` list.\n     * The prevarena member is unused in this case.\n     *\n     * When this arena_object is associated with an allocated arena\n     * with at least one available pool, both members are used in the\n     * doubly-linked `usable_arenas` list, which is maintained in\n     * increasing order of `nfreepools` values.\n\n     *\n     * Else this arena_object is associated with an allocated arena\n     * all of whose pools are in use.  `nextarena` and `prevarena`\n     * are both meaningless in this case.\n     */\n\n    struct arena_object* nextarena;\n    struct arena_object* prevarena;\n};\npool_address serves as the arena’s high water mark pointer that tracks where to carve off the next pool. It’s initialized when an arena is created and advances as pools are allocated.\nEach arena_object node also contains a field freepools of the type pool_header* which points to the head of a linked list which tracks available pools in the arena.\nWhen an arena’s nfreepools reaches zero (all pools allocated), it’s removed from usable_arenas linked list. Conversely, when a pool becomes empty and is added to an arena’s freepools, the arena may be added back to usable_arenas if it was previously full.\n\n\nPools\nPools are \\(4\\)KB subdivisions (or \\(16\\) Kb on large systems) of arenas. Normally, the size of the pool is equal to the size of a memory page. Limiting pool to the fixed size of blocks helps with fragmentation. Each pool manages blocks of single size class and can be in three states:\n\nUsed : Partially allocated blocks.\nFull : All blocks allocated.\nEmpty : All blocks available.\n\n/*\n * Size of the pools used for small blocks.  Must be a power of 2.\n */\n\n#ifdef USE_LARGE_POOLS\n#define POOL_BITS               14                  /* 16 KiB */\n#else\n#define POOL_BITS               12                  /* 4 KiB */\n#endif\n#define POOL_SIZE               (1 &lt;&lt; POOL_BITS)\nEach pool has a special header structure:\n/* Pool for small blocks. */\nstruct pool_header {\n\n    union { pymem_block *_padding;\n            uint count; } ref;          /* number of allocated blocks    */\n\n    pymem_block *freeblock;             /* pool's free list head         */\n\n    struct pool_header *nextpool;       /* next pool of this size class  */\n\n    struct pool_header *prevpool;       /* previous pool of this size class                             */\n\n    uint arenaindex;                    /* index into arenas of base adr */\n\n    uint szidx;                         /* block size class index        */\n\n    uint nextoffset;                    /* bytes to virgin block         */\n\n    uint maxnextoffset;                 /* largest valid nextoffset      */\n\n};\nPools of the same sized blocks are linked together using doubly linked list (the nextpool and prevpool fields). The szidx field keeps the size class index, whereas ref.count keeps the number of used blocks. The arenaindex stores the number of an arena in which this pool was created.\nIn order to efficient manage pools, a pool table called usedpools is maintained. A pool table is an array of pointers. It is segmented by the size class index i. For an index i, usedpools[i+1] points to the head of linked list of all partial used pools of the same size class i. Each node of this linked list is of type pool_header.\nIf a full pool has a block freed, then the pool is put back in the used state. The newly freed pool is added to the front of the approapriate usedpools[] list, so the next allocation for its size class will use the freed block.\nOn transition to empty, a pool is unlinked from its usedpools[] list and added to the front of the arena’s singly linked freepools list.\n\n\nBlocks\nBlocks are the actual allocated units, with sizes ranging from \\(8\\) to \\(512\\) bytes in \\(8\\)-byte increments.\n\n\n\nRequest in bytes\nSize of the allocated block\nSize class index\n\n\n\n\n1-8\n8\n0\n\n\n9-16\n16\n1\n\n\n17-24\n24\n2\n\n\n…\n…\n…\n\n\n505-512\n512\n63\n\n\n\nOn a 64-bit system, since an arena is \\(1\\) MB, there will always be \\(64\\) pools each of size \\(16\\)KB.\nWithin a pool, blocks of fixed size can be allocated and freed. Available blocks within a pool are listed in the singly linked list freeblock. Whenever a block is freed, its inserted at the front of the freeblock list. When a pool is initialized, only the first two blocks are linked within the freeblock list.\n\n\nBlock allocation API\nWhen a block of memory is requested by a memory domain that uses pymalloc, the API function pymalloc_alloc() is invoked. This function is a good place to insert a break-point and step through the code to test your knowledge of blocks, pools and arenas."
  },
  {
    "objectID": "posts/pymalloc_deep_dive/index.html#string-interning-explained",
    "href": "posts/pymalloc_deep_dive/index.html#string-interning-explained",
    "title": "Pymalloc - Down the rabit hole",
    "section": "string interning explained",
    "text": "string interning explained\nString interning is a method of storing only one copy of each distinct string value, which must be immutable. In Python3, we have a function sys.intern() and if we use this function, we can enter a string in the table of interned strings. We get a reference to the interned string.\nSo, we can gain a little extra performance on dictionary lookup (key comparisons after hashing can be done by a pointer compare instead of a string compare).\nNames used in programs are automatically interned. Dictionaries used to hold module, class or instance attributes have interned keys.\n\nfrom sys import intern\na, b = \"strin\", \"string\"\nprint(f\"{a + 'g' is b}\")    # Returns false\nintern(a + 'g') is intern(b) # returns True\n\nFalse\n\n\nTrue"
  },
  {
    "objectID": "posts/the_cpp_casts/index.html",
    "href": "posts/the_cpp_casts/index.html",
    "title": "The C++ casts",
    "section": "",
    "text": "Traditionally, C++ has supported four ways to perform those explicit type conversions we call casts - static_cast, dynamic_cast, const_cast and reinterprete_cast. C++11 added a fifth one duration_cast. Finally, C++20 introduced a sixth case bit_cast.\n\n\nThe best, most efficient tool in our type-casting toolset is static_cast. static_cast performs compile-time conversion between related types. It is mostly safe, costs essentially nothing in most cases, and can be used in a constexpr context.\nYou can also use static_cast in situations involving potential risks, such as converting an int to a float or vice versa. In the latter case, it explicitly acknowledges the loss of the decimal part.\nYou can can use static_cast to cast a pointer or a reference from a derived class to one of its direct or indirect base classes (as long as there is no ambiguity), which is totally safe.\nCasting from a base class to a derived class is extremely risky if the cast is incorrect, as it does not perform runtime checks.\nHere are some examples:\n#include &lt;print&gt;\n\nstruct B{ \n    virtual ~B() = default;\n};\n\nstruct D0: B { /*...*/ };\nstruct D1: B { /*...*/ };\n\nclass X{\n    public:\n    X(int, double){}\n};\n\nvoid f(D0*){}\nvoid f(D1*){}\n\nint main()\n{\n    const float x = 3.14159f;\n    int n = static_cast&lt;int&gt;(x);    // ok, no warning\n\n    X x0{ 3, 3.5 }; // ok\n\n    X x1(3.5, 0);   // compiles, \n    // probably warns (narrowing conversion)\n\n    //X x2{3.5, 0}; // does not compile\n                    // narrowing is not allowed within braces\n\n    X x3{ static_cast&lt;int&gt;(x), 3 }; // ok\n\n    D0 d0;\n    // illegal, no base-derived relatonship between D0 and D1\n    //D1* d1 = static_cast&lt;D1*&gt;(&d0);\n\n    B* b = static_cast&lt;B*&gt;(&d0);     // ok\n    // f(*b)                         // illegal\n    f(static_cast&lt;D0*&gt;(b));         // ok\n    f(static_cast&lt;D1*&gt;(b));         // compiles, but very dangerous\n    return 0;\n}\nCompiler Explorer Pay special attention to the last use of static_cast of the preceding example - converting from a base class to one of its derived classes is appropriately done with static_cast. However, you must ensure that the conversion leads to an object of the chosen type, as there is no run-time verification made of the validity of that conversion. Only compile-time checks are done.\n\n\n\nThere will be cases where you have a pointer or a reference to an object of some class type and that happens to be different (but related to) the type needed. This often happens - for example, in game engines where most classes derive from some Component base and functions tend to take Component* arguments but need to access members from an object of the derived class they expect.\nThe main problem here is, typically that the function’s interface is wrong - it accepts arguments of types that are insufficiently precise. Still, we all have software to deliver, and sometimes we need to make things work even though we made some choices along the way, that we will revisit later on.\nThe safe way to do such casts is dynamic_cast. This cast lets you convert a pointer or reference from one type to another, related type in a way that lets you test whether the conversion worked or not; with pointers, an incorrect conversion yields nullptr, whereas with references, an incorrect conversion throws std::bad_cast. The relatedness of types with dynamic_cast is not limited to base-derived relationships and includes casting from one base to another base in a multiple inheritance design. However, note that in most cases, dynamic_cast requires that the expression that is cast to another type is of the polymorphic type, in the sense that it must have atleast one virtual member function.\nHere are some examples:\n#include &lt;iostream&gt;\n\nstruct B0{\n    virtual int f() const = 0;\n    virtual ~B0() = default;\n};\n\nstruct B1{\n    virtual int g() const = 0;\n    virtual ~B1() = default;\n};\n\nclass D0 : public B0{\n    public:\n    int f() const override{\n        return 3;\n    }\n};\n\nclass D1 : public B1{\n    public:\n    int g() const override{\n        return 4;\n    }\n};\n\nclass D : public D0, public D1{};\n\nint f(D* p){\n    return p ? p -&gt; f() + p-&gt;g() : -1;\n}\n\n// g has the wrong interfacce: it accepts a D0& but \n// tries to use it as a D1&, which makes sense if the \n// referred object is publiclly D0 and D1 (for example)\n// class D\nint g(D0& d0){\n    D1& d1 = dynamic_cast&lt;D1&&gt;(d0); //throws if wrong\n    return d1.g();\n}\n\nint main()\n{\n    D d;\n    f(&d);      // ok\n    g(d);       // ok, D is a D0\n    D0 d0;\n    // calls f(nullptr) as &d0 does not point to a D\n    std::cout &lt;&lt; f(dynamic_cast&lt;D*&gt;(&d0)) &lt;&lt; \"\\n\";\n\n    try{\n        g(d0);  // compile, but will throw std::bad_cast\n    }catch(std::bad_cast& ex){\n        std::cerr &lt;&lt; \"Nice try!\" &lt;&lt; \"\\n\";\n    }\n    return 0;\n}\nCompiler Explorer\nNote that, even though this example displays a message when std::bad_cast ism thrown, this is in no way what we could call exception handling; we did not solve the problem, and code execution continues in a potentially corrupt state, which could make things worse in more serious code. In a toy example such as this, just letting the code fail and stop executing would also have been a more reasonable choice.\nNote that, the use of dynamic_cast requires binaries to be compiled with runtime type information(RTTI) included, leading to larger binaries. Unsurprisingly; due to these costs, some application domains will tend to avoid this cost.\n\n\n\nNeither static_cast nor dynamic_cast, can change cv-qualifiers of an expression. To do this, you need const_cast. With const_cast, you can add or remove the const or volatile qualifiers from an expression. As you might guess, this only makes sense on a pointer or a reference.\n\n\n\nSometimes, you just have to make the compiler believe you. For example, knowing sizeof(int) == 4 on your platform, you might want to treat int as char[4] to interoperate with an existing API that expects that type. Note that, you should ensure that this property holds (maybe through static_assert), rather than relying on the belief that the property holds on all platforms (it does not).\nThat’s what reinterpret_cast gives you - the ability to cast a pointer of some type to a pointer of an unrelated type. This can be used in situations where you seek to benefit from pointer-interconvertibility, just as this this can be used to lie to the type system in several rather dangerous and non-portable ways.\nAlso note that, reinterpret_cast only changes the type associated with an expression - for example, it does not perform the slight address adjustments, that static_cast would make when converting from a derived class to a base class in multiple inheritance situations.\nstruct B0{}\n\n\n\n\nC++ Memory Management by Patrice Roy, Packt Publishers"
  },
  {
    "objectID": "posts/the_cpp_casts/index.html#your-best-friend-most-of-the-time---static_cast",
    "href": "posts/the_cpp_casts/index.html#your-best-friend-most-of-the-time---static_cast",
    "title": "The C++ casts",
    "section": "",
    "text": "The best, most efficient tool in our type-casting toolset is static_cast. static_cast performs compile-time conversion between related types. It is mostly safe, costs essentially nothing in most cases, and can be used in a constexpr context.\nYou can also use static_cast in situations involving potential risks, such as converting an int to a float or vice versa. In the latter case, it explicitly acknowledges the loss of the decimal part.\nYou can can use static_cast to cast a pointer or a reference from a derived class to one of its direct or indirect base classes (as long as there is no ambiguity), which is totally safe.\nCasting from a base class to a derived class is extremely risky if the cast is incorrect, as it does not perform runtime checks.\nHere are some examples:\n#include &lt;print&gt;\n\nstruct B{ \n    virtual ~B() = default;\n};\n\nstruct D0: B { /*...*/ };\nstruct D1: B { /*...*/ };\n\nclass X{\n    public:\n    X(int, double){}\n};\n\nvoid f(D0*){}\nvoid f(D1*){}\n\nint main()\n{\n    const float x = 3.14159f;\n    int n = static_cast&lt;int&gt;(x);    // ok, no warning\n\n    X x0{ 3, 3.5 }; // ok\n\n    X x1(3.5, 0);   // compiles, \n    // probably warns (narrowing conversion)\n\n    //X x2{3.5, 0}; // does not compile\n                    // narrowing is not allowed within braces\n\n    X x3{ static_cast&lt;int&gt;(x), 3 }; // ok\n\n    D0 d0;\n    // illegal, no base-derived relatonship between D0 and D1\n    //D1* d1 = static_cast&lt;D1*&gt;(&d0);\n\n    B* b = static_cast&lt;B*&gt;(&d0);     // ok\n    // f(*b)                         // illegal\n    f(static_cast&lt;D0*&gt;(b));         // ok\n    f(static_cast&lt;D1*&gt;(b));         // compiles, but very dangerous\n    return 0;\n}\nCompiler Explorer Pay special attention to the last use of static_cast of the preceding example - converting from a base class to one of its derived classes is appropriately done with static_cast. However, you must ensure that the conversion leads to an object of the chosen type, as there is no run-time verification made of the validity of that conversion. Only compile-time checks are done."
  },
  {
    "objectID": "posts/the_cpp_casts/index.html#a-sign-somethings-wrong---dynamic_cast",
    "href": "posts/the_cpp_casts/index.html#a-sign-somethings-wrong---dynamic_cast",
    "title": "The C++ casts",
    "section": "",
    "text": "There will be cases where you have a pointer or a reference to an object of some class type and that happens to be different (but related to) the type needed. This often happens - for example, in game engines where most classes derive from some Component base and functions tend to take Component* arguments but need to access members from an object of the derived class they expect.\nThe main problem here is, typically that the function’s interface is wrong - it accepts arguments of types that are insufficiently precise. Still, we all have software to deliver, and sometimes we need to make things work even though we made some choices along the way, that we will revisit later on.\nThe safe way to do such casts is dynamic_cast. This cast lets you convert a pointer or reference from one type to another, related type in a way that lets you test whether the conversion worked or not; with pointers, an incorrect conversion yields nullptr, whereas with references, an incorrect conversion throws std::bad_cast. The relatedness of types with dynamic_cast is not limited to base-derived relationships and includes casting from one base to another base in a multiple inheritance design. However, note that in most cases, dynamic_cast requires that the expression that is cast to another type is of the polymorphic type, in the sense that it must have atleast one virtual member function.\nHere are some examples:\n#include &lt;iostream&gt;\n\nstruct B0{\n    virtual int f() const = 0;\n    virtual ~B0() = default;\n};\n\nstruct B1{\n    virtual int g() const = 0;\n    virtual ~B1() = default;\n};\n\nclass D0 : public B0{\n    public:\n    int f() const override{\n        return 3;\n    }\n};\n\nclass D1 : public B1{\n    public:\n    int g() const override{\n        return 4;\n    }\n};\n\nclass D : public D0, public D1{};\n\nint f(D* p){\n    return p ? p -&gt; f() + p-&gt;g() : -1;\n}\n\n// g has the wrong interfacce: it accepts a D0& but \n// tries to use it as a D1&, which makes sense if the \n// referred object is publiclly D0 and D1 (for example)\n// class D\nint g(D0& d0){\n    D1& d1 = dynamic_cast&lt;D1&&gt;(d0); //throws if wrong\n    return d1.g();\n}\n\nint main()\n{\n    D d;\n    f(&d);      // ok\n    g(d);       // ok, D is a D0\n    D0 d0;\n    // calls f(nullptr) as &d0 does not point to a D\n    std::cout &lt;&lt; f(dynamic_cast&lt;D*&gt;(&d0)) &lt;&lt; \"\\n\";\n\n    try{\n        g(d0);  // compile, but will throw std::bad_cast\n    }catch(std::bad_cast& ex){\n        std::cerr &lt;&lt; \"Nice try!\" &lt;&lt; \"\\n\";\n    }\n    return 0;\n}\nCompiler Explorer\nNote that, even though this example displays a message when std::bad_cast ism thrown, this is in no way what we could call exception handling; we did not solve the problem, and code execution continues in a potentially corrupt state, which could make things worse in more serious code. In a toy example such as this, just letting the code fail and stop executing would also have been a more reasonable choice.\nNote that, the use of dynamic_cast requires binaries to be compiled with runtime type information(RTTI) included, leading to larger binaries. Unsurprisingly; due to these costs, some application domains will tend to avoid this cost."
  },
  {
    "objectID": "posts/the_cpp_casts/index.html#playing-tricks-with-safety---const_cast",
    "href": "posts/the_cpp_casts/index.html#playing-tricks-with-safety---const_cast",
    "title": "The C++ casts",
    "section": "",
    "text": "Neither static_cast nor dynamic_cast, can change cv-qualifiers of an expression. To do this, you need const_cast. With const_cast, you can add or remove the const or volatile qualifiers from an expression. As you might guess, this only makes sense on a pointer or a reference."
  },
  {
    "objectID": "posts/the_cpp_casts/index.html#believe-me-compiler---reinterprete_cast",
    "href": "posts/the_cpp_casts/index.html#believe-me-compiler---reinterprete_cast",
    "title": "The C++ casts",
    "section": "",
    "text": "Sometimes, you just have to make the compiler believe you. For example, knowing sizeof(int) == 4 on your platform, you might want to treat int as char[4] to interoperate with an existing API that expects that type. Note that, you should ensure that this property holds (maybe through static_assert), rather than relying on the belief that the property holds on all platforms (it does not).\nThat’s what reinterpret_cast gives you - the ability to cast a pointer of some type to a pointer of an unrelated type. This can be used in situations where you seek to benefit from pointer-interconvertibility, just as this this can be used to lie to the type system in several rather dangerous and non-portable ways.\nAlso note that, reinterpret_cast only changes the type associated with an expression - for example, it does not perform the slight address adjustments, that static_cast would make when converting from a derived class to a base class in multiple inheritance situations.\nstruct B0{}"
  },
  {
    "objectID": "posts/the_cpp_casts/index.html#references",
    "href": "posts/the_cpp_casts/index.html#references",
    "title": "The C++ casts",
    "section": "",
    "text": "C++ Memory Management by Patrice Roy, Packt Publishers"
  },
  {
    "objectID": "posts/floating_point/index.html",
    "href": "posts/floating_point/index.html",
    "title": "Floating-point numbers",
    "section": "",
    "text": "Computer memory has a finite capacity. Real numbers in \\(\\mathbb{R}\\), do not, in general, however, have finite uniform representation. For example, consider representing the rational number \\(\\frac{4}{3}\\) as a decimal value: it is \\((1.333\\overline{3})_{10}\\) – it is impossible to do so exactly! Since only a finite number of digits can be stored in computer memory, the reals have to be approximated in some fashion (rounded or truncated), when represented on a computer.\nIn this tutorial, we’ll go over the basic ideas of floating-point representation and learn the limits of floating-point accuracy, when doing practical numerical computing.\n\n\n\nThere are two distinguishable ways of rounding off a real number \\(x\\) to a given number \\(t\\) of decimals.\nIn chopping, we simply leave off all decimals to the right of the \\(t\\)th digit. For example, 56.555 truncated to \\(t=1\\) decimal place yields 56.5.\nIn rounding to nearest, we choose a number with \\(t\\) decimals, which is the closest to \\(x\\). For example, consider rounding off 56.555 to \\(t=1\\) decimal place. There are two possible candidates: 56.5 and 56.6. On the real number line, 56.5 is at a distance of \\(|56.555 - 56.5|=0.55 \\times 10^{-1}\\) from 56.555, whilst 56.6 is at a distance of \\(|56.6 - 56.555|=0.45 \\times 10^{-1}\\). So, 56.6 is the nearest and we round to 56.6.\nIntuitively, we are comparing the fractional part of the number to the right of the \\(t\\)th digit, which is \\(0.055 = 0.55 \\times 10^{-1}\\) with \\(0.5 \\times 10^{-1}\\). As \\(0.55 \\times 10^{-1} &gt; 0.5 \\times 10^{-1}\\), we incremented the \\(t\\)th digit, which is 5 by 1.\nWhat if, we wished to round off 56.549 to \\(t=1\\) decimal places? Observe that, the fractional part is \\(0.49 \\times 10^{-1}\\). As \\(0.49 \\times 10^{-1} &lt; 0.5 \\times 10^{-1}\\), we leave the \\(t\\)th digit unchanged. So, the result is 56.5, which is indeed nearest to 56.549.\nIn general, let \\(p\\) be the fractional part of the number to the right of \\(t\\)th digit (after the decimal point). If \\(p&gt;0.5 \\times 10^{-t}\\), we increment the \\(t\\)th digit. If \\(p&lt;0.5 \\times 10^{-t}\\), we leave the \\(t\\)th digit unchanged.\nIn the case of a tie, when \\(x\\) is equidistant to two decimal \\(t\\)-digit numbers, we raise the \\(t\\)th decimal if it is odd or leave it unchanged if it is even. In this way, the error in rounding off a decimal number is positive or negative equally often.\nLet’s see some more examples of rounding and chopping, to make sure, this sinks in. Assume that, we are interested in rounding off all quantities to \\(t=3\\) decimal places:\n\n\nTable 1: Examples of rounding and chopping to \\(t=3\\) decimal places\n\n\n\\(x\\)\nRounding\nChopping\n\n\n\n\n0.2397\n0.240\n0.239\n\n\n0.23750\n0.238\n0.237\n\n\n0.23650\n0.236\n0.236\n\n\n0.23652\n0.237\n0.236\n\n\n\\(\\pi \\approx 3.1415926\\)\n3.142\n3.141\n\n\n\n\nThe difference between chopping and rounding has real-world implications! The Vancouver stock exchange index began trading in 1982, with a base value of 1000.00. Although the underlying stocks were performing decent, the index began hitting the low 500s at the end of 1983. A computer program re-calculated the value of the index thousands of times each day, and the program used chopping instead of rounding to the nearest. A rounded calculation gave a value of 1082.00.\n\n\n\nIn our daily life, we represent numbers using the decimal number system with base 10. In the decimal system, we’re aware, that if a digit \\(d_{-k}\\) stands \\(k\\) digits to the right of the decimal point, the value it contributes is \\(d_{-k} \\cdot 10^{-k}\\). For example the sequence of digits 4711.303 means:\n\\[\\begin{align*}\n4 \\cdot 10^3 + 7 \\cdot  10^2 + 1 \\cdot 10^1 + 1\\cdot 10^0 + 3 \\cdot 10^{-1} + 0 \\cdot 10^{-2} + 3 \\cdot 10^{-3} \\end{align*}\\]\nIn fact any integer \\(\\beta \\geq 2\\) (or \\(\\beta \\leq -2\\)) can be used as a base. Analogously, every real number \\(x \\in \\mathbb{R}\\) has a unique representation of the form:\n\\[\\begin{align*} x = d_n \\beta^n + d_{n-1}\\beta^{n-1} + \\ldots + d_1 \\beta^{1} + d_0 \\beta^0 + d_{-1}\\beta^{-1} + d_{-2} \\beta^{-2} + \\ldots \\end{align*}\\]\nor compactly \\(d_{n}\\ldots d_1 d_0.d_{-1} d_{-2} \\ldots\\), where the coefficients \\(d_i\\), the digits in system \\(\\beta\\), are positive integers such that \\(0 \\leq d_i &lt; \\beta\\).\n\n\nConsider the problem of conversion between two number systems with different bases. For the sake of concreteness, let’s try to convert \\((250)_{10}\\) to the binary format. We may write:\n\\[\\begin{align*} 250 = d_7 \\cdot 2^7 + d_6\\cdot 2^6 + d_5 \\cdot 2^5 + d_4\\cdot 2^4 + d_3\\cdot 2^3 + d_2\\cdot 2^2 + d_1\\cdot 2^1 + d_0 \\end{align*}\\]\nWe can pull out a factor of 2 from each term, except the last, and equivalently write:\n\\[\\begin{align*} 250 = 2 \\times (d_7 \\cdot 2^6 + d_6\\cdot 2^5 + d_5 \\cdot 2^4 + d_4\\cdot 2^3 + d_3\\cdot 2^2 + d_2\\cdot 2^1 + d_1) + d_0 \\end{align*}\\]\nIntuitively, therefore, if we were to divide \\(q_0=250\\) by 2, the expression in brackets, let’s call it \\(q_1\\), is the quotient and \\(d_0\\) is the remainder of the division. Similarly, since \\(q_1 = 2 \\times (d_7 \\cdot 2^5 + d_6\\cdot 2^4 + d_5 \\cdot 2^3 + d_4\\cdot 2^2 + d_3\\cdot 2^1 + d_2) + d_1\\), division by 2 would return the expression in the brackets as the quotient; call it \\(q_2\\), and \\(d_1\\) as the remainder.\nIn general, if \\(a\\) is an integer with base \\(\\alpha\\) and we want to determine it’s representation in a number system with base \\(\\beta\\), we perform successive divisions of \\(a\\) with \\(\\beta\\): set \\(q_0 = a\\) and\n\\[\\begin{align*} q_k = \\beta \\times q_{k+1} + d_k, \\quad k = 0,1,2,\\ldots \\end{align*}\\]\n\\(q_{k+1}\\) is the quotient and \\(d_k\\) is the remainder in the division.\nLet’s look at the result of applying the algorithm to \\((250)_{10}\\):\nk q_k q_k+1 d_k 0 250 250/2 = 125 0 1 125 125/2 = 62 1 2 62 62/2 = 31 0 3 31 31/2 = 15 1 4 15 15/2 = 7 1 5 7 7/2 = 3 1 6 3 3/2 = 1 1 7 1 1/2 = 0 1\nTherefore, \\((250)_{10} = (d_7 d_6 d_5 d_4 d_3 d_2 d_1 d_0)_2 = 1111\\,1010\\).\n\n\n\nIf the real number \\(a\\) is not an integer, we write it as \\(a = b + c\\), where \\(b\\) is the integer part and\n\\[\n\\begin{align*}\nc = c_{-1}\\beta^{-1} + c_{-2}\\beta^{-2} + c_{-3}\\beta^{-3} + \\ldots\n\\end{align*}\n\\]\nis the fractional part, where \\(c_{-1},c_{-2},c_{-3},\\ldots\\) are to be determined.\nObserve that, multiplying both sides by the base \\(\\beta\\) yields,\n\\[\\begin{align*} c \\cdot \\beta = \\underbrace{c_{-1}}_{\\text{Integer}} + \\underbrace{c_{-2}\\beta^{-1} + c_{-3}\\beta^{-2} + \\ldots}_{\\text{Fractional part}} \\end{align*}\\]\nan integer and a fractional portion. The integer portion is precisely \\(c_{-1}\\) – the first digit of \\(c\\) represented in base \\(\\beta\\). Consecutive digits are obtained as the integer parts, when successively multiplying \\(c\\) by \\(\\beta\\).\nIn general, if a fraction \\(c\\) must be converted to another number system with base \\(\\beta\\), we perform successive multiplications of \\(c\\) with \\(\\beta\\): set \\(p_0 = c\\) and\n\\[\\begin{align*} p_{k} \\cdot \\beta = c_{k-1} + p_{k-1}, \\quad k = 0,-1,-2,\\ldots \\end{align*}\\]\nLet’s look at an example of converting \\((0.15625)_{10}\\) to binary number system:\nk p_k p_k\\(\\cdot \\beta\\) c_k-1 p_k-1 0 0.15625 \\(0.15625 \\times 2 =0.3125\\) 0 0.3125 -1 0.3125 \\(0.3125 \\times 2 =0.625\\) 0 0.625 -2 0.625 \\(0.625 \\times 2 =1.25\\) 1 0.25 -3 0.25 \\(0.25 \\times 2 =0.50\\) 0 0.50 -4 0.50 \\(0.50 \\times 2 =1.00\\) 1 0.00\nfreestar Therefore, \\((0.15625)_{10} = 0.0010\\,1000\\) in the binary system.\n\n\n\nComputers are equipped to handle pieces of information of a fixed size called a word. Typical word lengths are 32-bits or 64-bits.\nEarly computers made numerical calculations in a fixed-point number system. That is, real numbers were represented using a fixed number of \\(t\\) binary digits in the fractional part. If the word-length of the computer is \\(s+1\\) bits, (including the sign bit), then only numbers in the bounded interval \\(I=[-2^{s-t},2^{s-t}]\\) are permitted. This limitation is problematic, since, for example, even when \\(x \\in I\\) and \\(y \\in I\\), it is possible that \\(x - y\\) is outside the bounds of the interval \\(I\\).\nIn a floating-point number system, a real number \\(a\\) is represented as:\nfreestar \\[\\begin{align*} a = \\pm m \\cdot \\beta^e, \\quad m = (0.d_1 d_2 d_3 \\ldots)_\\beta, \\quad e \\text{ an integer } \\end{align*}\\]\nThe fractional part \\(m\\) of the number is called the mantissa or significand. \\(e\\) is called the exponent and \\(\\beta\\) is the base. It’s clear that \\(d_1 \\neq 0\\), because if \\(d_1 = 0\\), then we can always decrease the exponent by 1 and shift the decimal point one place to the right.\nThe mantissa \\(m\\) and the exponent \\(e\\) are limited by the fixed word length in computers. \\(m\\) is rounded off to a number \\(\\overline{m}\\) with \\(t\\) digits and the exponent \\(e\\) lies in a certain range.\nThus, we can only represent floating-point numbers of the form:\n\\[\\begin{align*} a = \\pm \\overline{m} \\cdot \\beta^e, \\quad \\overline{m} = (0.d_1 d_2 d_3 \\ldots d_t)_\\beta, \\quad e_{min} \\leq e \\leq e_{max}, \\quad e \\in \\mathbf{Z} \\end{align*}\\]\nA floating-point number system \\(F\\) is completely characterized by the base \\(\\beta\\), precision \\(t\\), the numbers \\(e_{min}\\) and \\(e_{max}\\). Since \\(d_1 \\neq 0\\), the set \\(F\\), contains, including the number 0,\n\\[\\begin{align*} 2 (\\beta - 1) \\beta^{t-1}(e_{max} - e_{min} + 1) + 1 \\end{align*}\\]\nnumbers. Intuitively, there are 2 choices for the sign. The digit \\(d_1\\) can be chosen from the set \\(\\{1,2,\\ldots,\\beta - 1\\}\\). Each of the successive \\(t-1\\) digits can be chosen from \\(\\{0,1,2,\\ldots,\\beta - 1\\}\\). The exponent can be chosen from \\(e_{max} - e_{min} + 1\\) numbers. By the multiplication rule, there are \\(2 (\\beta - 1) \\beta^{t-1}(e_{max} - e_{min} + 1)\\) distinguishable numbers. Including the number 0 gives us the expression above.\n\n\n\n\nConsider a toy floating-point number system \\(F(\\beta = 2, t = 3, e_{min}=-1, e_{max}=2)\\). The set \\(F\\) contains exactly \\(2 \\cdot 16 + 1 = 33\\) numbers. The positive numbers in the set \\(F\\) are shown below:\n\\((0.d_1 d_2 d_3)_2\\) \\(2^e\\) Decimal representation \\((0.d_1 d_2 d_3)_2\\) \\(2^e\\) Decimal representation \\((0.100)_2\\) \\(2^{-1}\\) 0.25 \\((0.100)_2\\) \\(2^1\\) 1.00 \\((0.101)_2\\) \\(2^{-1}\\) 0.3125 \\((0.101)_2\\) \\(2^1\\) 1.25 \\((0.110)_2\\) \\(2^{-1}\\) 0.375 \\((0.110)_2\\) \\(2^1\\) 1.50 \\((0.111)_2\\) \\(2^{-1}\\) 0.4375 \\((0.111)_2\\) \\(2^1\\) 1.75 \\((0.100)_2\\) \\(2^0\\) 0.50 \\((0.100)_2\\) \\(2^2\\) 2.00 \\((0.101)_2\\) \\(2^0\\) 0.625 \\((0.101)_2\\) \\(2^2\\) 2.50 \\((0.110)_2\\) \\(2^0\\) 0.75 \\((0.110)_2\\) \\(2^2\\) 3.00 \\((0.111)_2\\) \\(2^0\\) 0.875 \\((0.111)_2\\) \\(2^2\\) 3.50 It is apparent that not all real numbers, for instance in, \\(\\mathbf{[1,2]}\\) are present in \\(\\mathbf{F}\\). Moreover, not all floating-point numbers are equally spaced; the spacing jumps by a factor of \\(\\beta\\) at each power of \\(\\beta\\).\nThe spacing of the floating-point numbers is characterized by the machine epsilon \\(\\mathbf{\\epsilon_M}\\), which is the distance from 1.0 to the next largest floating-point number.\nIf a real number \\(x\\) is in the range of the floating-point system, the obvious thing to do is to round off \\(x\\) to \\(\\overline{x}\\), where \\(\\overline{x}=\\text{float}(x)\\) is the floating-point number in \\(F\\), that is closest to \\(x\\). It should already be clear that representing \\(\\mathbf{x}\\) by \\(\\mathbf{float(x)}\\) introduces an error.\nOne interesting question is, how large is this error? It would be great if we could guarantee, that the round-off error at no point exceeds a certain amount. Everybody loves a guarantee! In other words, we seek an upper bound for the relative error:\n\\[\\begin{align*} \\frac{|fl(x) - x|}{|x|} \\end{align*}\\]\nRecall, from the earlier discussion, that when rounding \\(m\\) to \\(t\\) decimals, we leave the \\(t\\)th decimal unchanged, if the part \\(p\\), of the number to right of the \\(t\\)th decimal, is smaller than \\(\\frac{1}{2} \\times 10^{-t}\\), else raise the \\(t\\)th decimal by 1. Here, we are working with the generic base \\(\\beta\\) instead of the decimal base 10. Consequently, the round-off error in the mantissa is bounded by:\n\\[\\begin{align*} |\\overline{m} - m| \\leq \\frac{1}{2}\\cdot \\beta^{-t} \\end{align*}\\]\nThe relative round-off error in \\(x\\) is thus bounded by:\n\\[\\begin{align*} \\frac{|fl(x) - x|}{|x|} &= \\frac{|\\overline{m} - m| \\cdot \\beta^e}{m \\cdot \\beta^e}\\\\ &\\leq \\frac{\\frac{1}{2}\\cdot \\beta^{-t} \\cdot \\beta^e}{(0.1)_\\beta \\beta^e} \\quad \\quad \\{ m \\geq (0.1)_\\beta \\} \\\\ &= \\frac{1}{2} \\cdot \\beta^{-t + 1} \\end{align*}\\]\nModern floating-point standards such as the IEEE guarantee this upper bound. This upper bound is called the rounding unit, denoted by \\(\\mathbf{u}\\).\n\n\n\nActual computer hardware implementations of floating-point systems differ from the toy system, we just designed. Most current computers conform to the IEEE 754 standard for binary floating-point arithmetic. There is two main basic formats – single and double precision, requiring 32-bit and 64-bit storage.\nIn single-precision, a floating-point number \\(a\\) is stored as the sign \\(s\\) (1 bit), the exponent \\(e\\) (8 bits), the mantissa \\(m\\) (23 bits).\nIn double-precision, 11 bits are allocated to the exponent \\(e\\), whereas 52 bits are allocated to the mantissa \\(m\\). The exponent is stored as \\(b=e+1023\\).\nRendered by QuickLaTeX.com\nThe value \\(v\\) of the floating-point number \\(a\\) in the normal case is:\n\\[\\begin{align*} v = (-1)^s (1.m)_2 \\cdot 2^e, \\quad \\quad e_{min} \\leq e \\leq e_{max} \\end{align*}\\]\nNote, that the digit before the binary point is always 1, similar to the scientific notation we studied in high school. In that way, 1 bit is gained for the mantissa.\n\n\nConsider the following comparison:\n(0.10 + 0.20) == 0.30 Copy The result of this logical comparison is false. This abrupt behavior is expected because the floating-point system is broken. However, let’s take a deeper look at what’s going on.\nLet’s put 0.10 in the double-precision format. Because 0.10 is positive, the sign bit \\(s=0\\).\n0.10 in base-2 scientific notation can be written as \\((-1)^0 (1 + m) 2^{e}\\). This means we must factor 0.10 into a number \\((1 + m)\\) in the range \\(1 \\leq m &lt; 2\\) and a power of 2. If we divide 0.10 by different powers of 2, we get:\n\\[\\begin{align*} 0.10 / 2^{-1} &= 0.20\\\\ 0.10 / 2^{-2} &= 0.40\\\\ 0.10 / 2^{-3} &= 0.80\\\\ 0.10 / 2^{-4} &= 1.60 \\end{align*}\\]\nTherefore, \\(0.10 = 1.60 \\times 2^{-4}\\). The exponent is stored as \\(e + 1023=-4 + 1023 = 1019\\), so the bit pattern in the exponent part is \\((011\\, 1111\\, 1011)_2\\).\nThe mantissa \\(m\\) is the fractional part 0.60 in the binary form. Successive multiplication by 2 quickly yields \\(m = (0.1001\\, 1001\\, 1001\\, 1001\\, 1001\\, 1001\\, 1001\\, 1001\\, 1001\\, 1001\\, 1001\\, 1001\\, 1001 \\ldots)_2\\). However, the double-precision format allocates \\(t=52\\) bits to the mantissa, so we must round off \\(m\\) to 52 digits. The fractional part \\(p\\), after the 52nd digit, \\((0.1001 \\ldots)_2 \\times 2^{-52}\\) exceeds \\(\\frac{1}{2} \\beta^{-t} = (0.1)_2 \\times 2^{-52}\\). So, we raise the \\(t\\)th decimal by 1. Thus, the rounded mantissa is \\(\\overline{m}= (0.1001\\, 1001\\, 1001\\, 1001\\, 1001\\, 1001\\, 1001\\, 1001\\, 1001\\, 1001\\, 1001\\, 1001\\, 1010)_2\\).\nFinally, we put the binary strings in the correct order. So, 0.10 in the IEEE double-precision format is:\n\\[\\begin{align*} \\underbrace{0}_{s}\\,\\underbrace{011\\, 1111\\, 1011}_{e+1023}\\,\\underbrace{1001\\, 1001\\, 1001\\, 1001\\, 1001\\, 1001\\, 1001\\, 1001\\, 1001\\, 1001\\, 1001\\, 1001\\, 1010}_{\\overline{m}} \\end{align*}\\]\nThis machine number is approximately 0.10000000000000000555 in base 10. In a similar fashion, the closest machine number to 0.2 in the floating-point system is approximately 0.2000000000000000111. Therefore, float(0.1) + float(0.2) &gt; 0.30. On the right hand side, the closest machine number to 0.3 is 0.29999999999999998889. So, float(0.30) &lt; 0.30.\nTo summarize, algebraically equivalent statements are not necessarily numerically equivalent.\n\n\n\n\nIn this article, we’ve learned how the rules of chopping and rounding to the nearest work. We developed an algorithm for conversion between number systems. We also learnt that, any floating-point system is characterized by a quadruple \\(F(\\beta,t,e_{min},e_{max})\\). For example, the IEEE double-precision format is given as \\(F(\\beta=2,t=52,e_{min}=-1022,e_{max}=1023)\\). Because computers have finite memory capacity, the set of machine numbers, \\(\\mathbf{M}\\) are only a subset of the real numbers \\(\\mathbf{R}\\). The spacing between machine numbers in technical speak is called the machine epsilon.\nFurther, any real number \\(x\\) is always rounded off to the nearest machine number on a computer. The IEEE standards guarantee that the relative roundoff error is no more than a certain amount. Moreover, as programmers, we need to take proper care when doing floating-point operations."
  },
  {
    "objectID": "posts/floating_point/index.html#introduction",
    "href": "posts/floating_point/index.html#introduction",
    "title": "Floating-point numbers",
    "section": "",
    "text": "Computer memory has a finite capacity. Real numbers in \\(\\mathbb{R}\\), do not, in general, however, have finite uniform representation. For example, consider representing the rational number \\(\\frac{4}{3}\\) as a decimal value: it is \\((1.333\\overline{3})_{10}\\) – it is impossible to do so exactly! Since only a finite number of digits can be stored in computer memory, the reals have to be approximated in some fashion (rounded or truncated), when represented on a computer.\nIn this tutorial, we’ll go over the basic ideas of floating-point representation and learn the limits of floating-point accuracy, when doing practical numerical computing."
  },
  {
    "objectID": "posts/floating_point/index.html#rounding-and-chopping",
    "href": "posts/floating_point/index.html#rounding-and-chopping",
    "title": "Floating-point numbers",
    "section": "",
    "text": "There are two distinguishable ways of rounding off a real number \\(x\\) to a given number \\(t\\) of decimals.\nIn chopping, we simply leave off all decimals to the right of the \\(t\\)th digit. For example, 56.555 truncated to \\(t=1\\) decimal place yields 56.5.\nIn rounding to nearest, we choose a number with \\(t\\) decimals, which is the closest to \\(x\\). For example, consider rounding off 56.555 to \\(t=1\\) decimal place. There are two possible candidates: 56.5 and 56.6. On the real number line, 56.5 is at a distance of \\(|56.555 - 56.5|=0.55 \\times 10^{-1}\\) from 56.555, whilst 56.6 is at a distance of \\(|56.6 - 56.555|=0.45 \\times 10^{-1}\\). So, 56.6 is the nearest and we round to 56.6.\nIntuitively, we are comparing the fractional part of the number to the right of the \\(t\\)th digit, which is \\(0.055 = 0.55 \\times 10^{-1}\\) with \\(0.5 \\times 10^{-1}\\). As \\(0.55 \\times 10^{-1} &gt; 0.5 \\times 10^{-1}\\), we incremented the \\(t\\)th digit, which is 5 by 1.\nWhat if, we wished to round off 56.549 to \\(t=1\\) decimal places? Observe that, the fractional part is \\(0.49 \\times 10^{-1}\\). As \\(0.49 \\times 10^{-1} &lt; 0.5 \\times 10^{-1}\\), we leave the \\(t\\)th digit unchanged. So, the result is 56.5, which is indeed nearest to 56.549.\nIn general, let \\(p\\) be the fractional part of the number to the right of \\(t\\)th digit (after the decimal point). If \\(p&gt;0.5 \\times 10^{-t}\\), we increment the \\(t\\)th digit. If \\(p&lt;0.5 \\times 10^{-t}\\), we leave the \\(t\\)th digit unchanged.\nIn the case of a tie, when \\(x\\) is equidistant to two decimal \\(t\\)-digit numbers, we raise the \\(t\\)th decimal if it is odd or leave it unchanged if it is even. In this way, the error in rounding off a decimal number is positive or negative equally often.\nLet’s see some more examples of rounding and chopping, to make sure, this sinks in. Assume that, we are interested in rounding off all quantities to \\(t=3\\) decimal places:\n\n\nTable 1: Examples of rounding and chopping to \\(t=3\\) decimal places\n\n\n\\(x\\)\nRounding\nChopping\n\n\n\n\n0.2397\n0.240\n0.239\n\n\n0.23750\n0.238\n0.237\n\n\n0.23650\n0.236\n0.236\n\n\n0.23652\n0.237\n0.236\n\n\n\\(\\pi \\approx 3.1415926\\)\n3.142\n3.141\n\n\n\n\nThe difference between chopping and rounding has real-world implications! The Vancouver stock exchange index began trading in 1982, with a base value of 1000.00. Although the underlying stocks were performing decent, the index began hitting the low 500s at the end of 1983. A computer program re-calculated the value of the index thousands of times each day, and the program used chopping instead of rounding to the nearest. A rounded calculation gave a value of 1082.00."
  },
  {
    "objectID": "posts/floating_point/index.html#computer-number-systems",
    "href": "posts/floating_point/index.html#computer-number-systems",
    "title": "Floating-point numbers",
    "section": "",
    "text": "In our daily life, we represent numbers using the decimal number system with base 10. In the decimal system, we’re aware, that if a digit \\(d_{-k}\\) stands \\(k\\) digits to the right of the decimal point, the value it contributes is \\(d_{-k} \\cdot 10^{-k}\\). For example the sequence of digits 4711.303 means:\n\\[\\begin{align*}\n4 \\cdot 10^3 + 7 \\cdot  10^2 + 1 \\cdot 10^1 + 1\\cdot 10^0 + 3 \\cdot 10^{-1} + 0 \\cdot 10^{-2} + 3 \\cdot 10^{-3} \\end{align*}\\]\nIn fact any integer \\(\\beta \\geq 2\\) (or \\(\\beta \\leq -2\\)) can be used as a base. Analogously, every real number \\(x \\in \\mathbb{R}\\) has a unique representation of the form:\n\\[\\begin{align*} x = d_n \\beta^n + d_{n-1}\\beta^{n-1} + \\ldots + d_1 \\beta^{1} + d_0 \\beta^0 + d_{-1}\\beta^{-1} + d_{-2} \\beta^{-2} + \\ldots \\end{align*}\\]\nor compactly \\(d_{n}\\ldots d_1 d_0.d_{-1} d_{-2} \\ldots\\), where the coefficients \\(d_i\\), the digits in system \\(\\beta\\), are positive integers such that \\(0 \\leq d_i &lt; \\beta\\).\n\n\nConsider the problem of conversion between two number systems with different bases. For the sake of concreteness, let’s try to convert \\((250)_{10}\\) to the binary format. We may write:\n\\[\\begin{align*} 250 = d_7 \\cdot 2^7 + d_6\\cdot 2^6 + d_5 \\cdot 2^5 + d_4\\cdot 2^4 + d_3\\cdot 2^3 + d_2\\cdot 2^2 + d_1\\cdot 2^1 + d_0 \\end{align*}\\]\nWe can pull out a factor of 2 from each term, except the last, and equivalently write:\n\\[\\begin{align*} 250 = 2 \\times (d_7 \\cdot 2^6 + d_6\\cdot 2^5 + d_5 \\cdot 2^4 + d_4\\cdot 2^3 + d_3\\cdot 2^2 + d_2\\cdot 2^1 + d_1) + d_0 \\end{align*}\\]\nIntuitively, therefore, if we were to divide \\(q_0=250\\) by 2, the expression in brackets, let’s call it \\(q_1\\), is the quotient and \\(d_0\\) is the remainder of the division. Similarly, since \\(q_1 = 2 \\times (d_7 \\cdot 2^5 + d_6\\cdot 2^4 + d_5 \\cdot 2^3 + d_4\\cdot 2^2 + d_3\\cdot 2^1 + d_2) + d_1\\), division by 2 would return the expression in the brackets as the quotient; call it \\(q_2\\), and \\(d_1\\) as the remainder.\nIn general, if \\(a\\) is an integer with base \\(\\alpha\\) and we want to determine it’s representation in a number system with base \\(\\beta\\), we perform successive divisions of \\(a\\) with \\(\\beta\\): set \\(q_0 = a\\) and\n\\[\\begin{align*} q_k = \\beta \\times q_{k+1} + d_k, \\quad k = 0,1,2,\\ldots \\end{align*}\\]\n\\(q_{k+1}\\) is the quotient and \\(d_k\\) is the remainder in the division.\nLet’s look at the result of applying the algorithm to \\((250)_{10}\\):\nk q_k q_k+1 d_k 0 250 250/2 = 125 0 1 125 125/2 = 62 1 2 62 62/2 = 31 0 3 31 31/2 = 15 1 4 15 15/2 = 7 1 5 7 7/2 = 3 1 6 3 3/2 = 1 1 7 1 1/2 = 0 1\nTherefore, \\((250)_{10} = (d_7 d_6 d_5 d_4 d_3 d_2 d_1 d_0)_2 = 1111\\,1010\\).\n\n\n\nIf the real number \\(a\\) is not an integer, we write it as \\(a = b + c\\), where \\(b\\) is the integer part and\n\\[\n\\begin{align*}\nc = c_{-1}\\beta^{-1} + c_{-2}\\beta^{-2} + c_{-3}\\beta^{-3} + \\ldots\n\\end{align*}\n\\]\nis the fractional part, where \\(c_{-1},c_{-2},c_{-3},\\ldots\\) are to be determined.\nObserve that, multiplying both sides by the base \\(\\beta\\) yields,\n\\[\\begin{align*} c \\cdot \\beta = \\underbrace{c_{-1}}_{\\text{Integer}} + \\underbrace{c_{-2}\\beta^{-1} + c_{-3}\\beta^{-2} + \\ldots}_{\\text{Fractional part}} \\end{align*}\\]\nan integer and a fractional portion. The integer portion is precisely \\(c_{-1}\\) – the first digit of \\(c\\) represented in base \\(\\beta\\). Consecutive digits are obtained as the integer parts, when successively multiplying \\(c\\) by \\(\\beta\\).\nIn general, if a fraction \\(c\\) must be converted to another number system with base \\(\\beta\\), we perform successive multiplications of \\(c\\) with \\(\\beta\\): set \\(p_0 = c\\) and\n\\[\\begin{align*} p_{k} \\cdot \\beta = c_{k-1} + p_{k-1}, \\quad k = 0,-1,-2,\\ldots \\end{align*}\\]\nLet’s look at an example of converting \\((0.15625)_{10}\\) to binary number system:\nk p_k p_k\\(\\cdot \\beta\\) c_k-1 p_k-1 0 0.15625 \\(0.15625 \\times 2 =0.3125\\) 0 0.3125 -1 0.3125 \\(0.3125 \\times 2 =0.625\\) 0 0.625 -2 0.625 \\(0.625 \\times 2 =1.25\\) 1 0.25 -3 0.25 \\(0.25 \\times 2 =0.50\\) 0 0.50 -4 0.50 \\(0.50 \\times 2 =1.00\\) 1 0.00\nfreestar Therefore, \\((0.15625)_{10} = 0.0010\\,1000\\) in the binary system.\n\n\n\nComputers are equipped to handle pieces of information of a fixed size called a word. Typical word lengths are 32-bits or 64-bits.\nEarly computers made numerical calculations in a fixed-point number system. That is, real numbers were represented using a fixed number of \\(t\\) binary digits in the fractional part. If the word-length of the computer is \\(s+1\\) bits, (including the sign bit), then only numbers in the bounded interval \\(I=[-2^{s-t},2^{s-t}]\\) are permitted. This limitation is problematic, since, for example, even when \\(x \\in I\\) and \\(y \\in I\\), it is possible that \\(x - y\\) is outside the bounds of the interval \\(I\\).\nIn a floating-point number system, a real number \\(a\\) is represented as:\nfreestar \\[\\begin{align*} a = \\pm m \\cdot \\beta^e, \\quad m = (0.d_1 d_2 d_3 \\ldots)_\\beta, \\quad e \\text{ an integer } \\end{align*}\\]\nThe fractional part \\(m\\) of the number is called the mantissa or significand. \\(e\\) is called the exponent and \\(\\beta\\) is the base. It’s clear that \\(d_1 \\neq 0\\), because if \\(d_1 = 0\\), then we can always decrease the exponent by 1 and shift the decimal point one place to the right.\nThe mantissa \\(m\\) and the exponent \\(e\\) are limited by the fixed word length in computers. \\(m\\) is rounded off to a number \\(\\overline{m}\\) with \\(t\\) digits and the exponent \\(e\\) lies in a certain range.\nThus, we can only represent floating-point numbers of the form:\n\\[\\begin{align*} a = \\pm \\overline{m} \\cdot \\beta^e, \\quad \\overline{m} = (0.d_1 d_2 d_3 \\ldots d_t)_\\beta, \\quad e_{min} \\leq e \\leq e_{max}, \\quad e \\in \\mathbf{Z} \\end{align*}\\]\nA floating-point number system \\(F\\) is completely characterized by the base \\(\\beta\\), precision \\(t\\), the numbers \\(e_{min}\\) and \\(e_{max}\\). Since \\(d_1 \\neq 0\\), the set \\(F\\), contains, including the number 0,\n\\[\\begin{align*} 2 (\\beta - 1) \\beta^{t-1}(e_{max} - e_{min} + 1) + 1 \\end{align*}\\]\nnumbers. Intuitively, there are 2 choices for the sign. The digit \\(d_1\\) can be chosen from the set \\(\\{1,2,\\ldots,\\beta - 1\\}\\). Each of the successive \\(t-1\\) digits can be chosen from \\(\\{0,1,2,\\ldots,\\beta - 1\\}\\). The exponent can be chosen from \\(e_{max} - e_{min} + 1\\) numbers. By the multiplication rule, there are \\(2 (\\beta - 1) \\beta^{t-1}(e_{max} - e_{min} + 1)\\) distinguishable numbers. Including the number 0 gives us the expression above."
  },
  {
    "objectID": "posts/floating_point/index.html#why-are-floating-point-numbers-inaccurate",
    "href": "posts/floating_point/index.html#why-are-floating-point-numbers-inaccurate",
    "title": "Floating-point numbers",
    "section": "",
    "text": "Consider a toy floating-point number system \\(F(\\beta = 2, t = 3, e_{min}=-1, e_{max}=2)\\). The set \\(F\\) contains exactly \\(2 \\cdot 16 + 1 = 33\\) numbers. The positive numbers in the set \\(F\\) are shown below:\n\\((0.d_1 d_2 d_3)_2\\) \\(2^e\\) Decimal representation \\((0.d_1 d_2 d_3)_2\\) \\(2^e\\) Decimal representation \\((0.100)_2\\) \\(2^{-1}\\) 0.25 \\((0.100)_2\\) \\(2^1\\) 1.00 \\((0.101)_2\\) \\(2^{-1}\\) 0.3125 \\((0.101)_2\\) \\(2^1\\) 1.25 \\((0.110)_2\\) \\(2^{-1}\\) 0.375 \\((0.110)_2\\) \\(2^1\\) 1.50 \\((0.111)_2\\) \\(2^{-1}\\) 0.4375 \\((0.111)_2\\) \\(2^1\\) 1.75 \\((0.100)_2\\) \\(2^0\\) 0.50 \\((0.100)_2\\) \\(2^2\\) 2.00 \\((0.101)_2\\) \\(2^0\\) 0.625 \\((0.101)_2\\) \\(2^2\\) 2.50 \\((0.110)_2\\) \\(2^0\\) 0.75 \\((0.110)_2\\) \\(2^2\\) 3.00 \\((0.111)_2\\) \\(2^0\\) 0.875 \\((0.111)_2\\) \\(2^2\\) 3.50 It is apparent that not all real numbers, for instance in, \\(\\mathbf{[1,2]}\\) are present in \\(\\mathbf{F}\\). Moreover, not all floating-point numbers are equally spaced; the spacing jumps by a factor of \\(\\beta\\) at each power of \\(\\beta\\).\nThe spacing of the floating-point numbers is characterized by the machine epsilon \\(\\mathbf{\\epsilon_M}\\), which is the distance from 1.0 to the next largest floating-point number.\nIf a real number \\(x\\) is in the range of the floating-point system, the obvious thing to do is to round off \\(x\\) to \\(\\overline{x}\\), where \\(\\overline{x}=\\text{float}(x)\\) is the floating-point number in \\(F\\), that is closest to \\(x\\). It should already be clear that representing \\(\\mathbf{x}\\) by \\(\\mathbf{float(x)}\\) introduces an error.\nOne interesting question is, how large is this error? It would be great if we could guarantee, that the round-off error at no point exceeds a certain amount. Everybody loves a guarantee! In other words, we seek an upper bound for the relative error:\n\\[\\begin{align*} \\frac{|fl(x) - x|}{|x|} \\end{align*}\\]\nRecall, from the earlier discussion, that when rounding \\(m\\) to \\(t\\) decimals, we leave the \\(t\\)th decimal unchanged, if the part \\(p\\), of the number to right of the \\(t\\)th decimal, is smaller than \\(\\frac{1}{2} \\times 10^{-t}\\), else raise the \\(t\\)th decimal by 1. Here, we are working with the generic base \\(\\beta\\) instead of the decimal base 10. Consequently, the round-off error in the mantissa is bounded by:\n\\[\\begin{align*} |\\overline{m} - m| \\leq \\frac{1}{2}\\cdot \\beta^{-t} \\end{align*}\\]\nThe relative round-off error in \\(x\\) is thus bounded by:\n\\[\\begin{align*} \\frac{|fl(x) - x|}{|x|} &= \\frac{|\\overline{m} - m| \\cdot \\beta^e}{m \\cdot \\beta^e}\\\\ &\\leq \\frac{\\frac{1}{2}\\cdot \\beta^{-t} \\cdot \\beta^e}{(0.1)_\\beta \\beta^e} \\quad \\quad \\{ m \\geq (0.1)_\\beta \\} \\\\ &= \\frac{1}{2} \\cdot \\beta^{-t + 1} \\end{align*}\\]\nModern floating-point standards such as the IEEE guarantee this upper bound. This upper bound is called the rounding unit, denoted by \\(\\mathbf{u}\\)."
  },
  {
    "objectID": "posts/floating_point/index.html#ieee-floating-point-standard-in-a-nutshell",
    "href": "posts/floating_point/index.html#ieee-floating-point-standard-in-a-nutshell",
    "title": "Floating-point numbers",
    "section": "",
    "text": "Actual computer hardware implementations of floating-point systems differ from the toy system, we just designed. Most current computers conform to the IEEE 754 standard for binary floating-point arithmetic. There is two main basic formats – single and double precision, requiring 32-bit and 64-bit storage.\nIn single-precision, a floating-point number \\(a\\) is stored as the sign \\(s\\) (1 bit), the exponent \\(e\\) (8 bits), the mantissa \\(m\\) (23 bits).\nIn double-precision, 11 bits are allocated to the exponent \\(e\\), whereas 52 bits are allocated to the mantissa \\(m\\). The exponent is stored as \\(b=e+1023\\).\nRendered by QuickLaTeX.com\nThe value \\(v\\) of the floating-point number \\(a\\) in the normal case is:\n\\[\\begin{align*} v = (-1)^s (1.m)_2 \\cdot 2^e, \\quad \\quad e_{min} \\leq e \\leq e_{max} \\end{align*}\\]\nNote, that the digit before the binary point is always 1, similar to the scientific notation we studied in high school. In that way, 1 bit is gained for the mantissa.\n\n\nConsider the following comparison:\n(0.10 + 0.20) == 0.30 Copy The result of this logical comparison is false. This abrupt behavior is expected because the floating-point system is broken. However, let’s take a deeper look at what’s going on.\nLet’s put 0.10 in the double-precision format. Because 0.10 is positive, the sign bit \\(s=0\\).\n0.10 in base-2 scientific notation can be written as \\((-1)^0 (1 + m) 2^{e}\\). This means we must factor 0.10 into a number \\((1 + m)\\) in the range \\(1 \\leq m &lt; 2\\) and a power of 2. If we divide 0.10 by different powers of 2, we get:\n\\[\\begin{align*} 0.10 / 2^{-1} &= 0.20\\\\ 0.10 / 2^{-2} &= 0.40\\\\ 0.10 / 2^{-3} &= 0.80\\\\ 0.10 / 2^{-4} &= 1.60 \\end{align*}\\]\nTherefore, \\(0.10 = 1.60 \\times 2^{-4}\\). The exponent is stored as \\(e + 1023=-4 + 1023 = 1019\\), so the bit pattern in the exponent part is \\((011\\, 1111\\, 1011)_2\\).\nThe mantissa \\(m\\) is the fractional part 0.60 in the binary form. Successive multiplication by 2 quickly yields \\(m = (0.1001\\, 1001\\, 1001\\, 1001\\, 1001\\, 1001\\, 1001\\, 1001\\, 1001\\, 1001\\, 1001\\, 1001\\, 1001 \\ldots)_2\\). However, the double-precision format allocates \\(t=52\\) bits to the mantissa, so we must round off \\(m\\) to 52 digits. The fractional part \\(p\\), after the 52nd digit, \\((0.1001 \\ldots)_2 \\times 2^{-52}\\) exceeds \\(\\frac{1}{2} \\beta^{-t} = (0.1)_2 \\times 2^{-52}\\). So, we raise the \\(t\\)th decimal by 1. Thus, the rounded mantissa is \\(\\overline{m}= (0.1001\\, 1001\\, 1001\\, 1001\\, 1001\\, 1001\\, 1001\\, 1001\\, 1001\\, 1001\\, 1001\\, 1001\\, 1010)_2\\).\nFinally, we put the binary strings in the correct order. So, 0.10 in the IEEE double-precision format is:\n\\[\\begin{align*} \\underbrace{0}_{s}\\,\\underbrace{011\\, 1111\\, 1011}_{e+1023}\\,\\underbrace{1001\\, 1001\\, 1001\\, 1001\\, 1001\\, 1001\\, 1001\\, 1001\\, 1001\\, 1001\\, 1001\\, 1001\\, 1010}_{\\overline{m}} \\end{align*}\\]\nThis machine number is approximately 0.10000000000000000555 in base 10. In a similar fashion, the closest machine number to 0.2 in the floating-point system is approximately 0.2000000000000000111. Therefore, float(0.1) + float(0.2) &gt; 0.30. On the right hand side, the closest machine number to 0.3 is 0.29999999999999998889. So, float(0.30) &lt; 0.30.\nTo summarize, algebraically equivalent statements are not necessarily numerically equivalent."
  },
  {
    "objectID": "posts/floating_point/index.html#conclusion",
    "href": "posts/floating_point/index.html#conclusion",
    "title": "Floating-point numbers",
    "section": "",
    "text": "In this article, we’ve learned how the rules of chopping and rounding to the nearest work. We developed an algorithm for conversion between number systems. We also learnt that, any floating-point system is characterized by a quadruple \\(F(\\beta,t,e_{min},e_{max})\\). For example, the IEEE double-precision format is given as \\(F(\\beta=2,t=52,e_{min}=-1022,e_{max}=1023)\\). Because computers have finite memory capacity, the set of machine numbers, \\(\\mathbf{M}\\) are only a subset of the real numbers \\(\\mathbf{R}\\). The spacing between machine numbers in technical speak is called the machine epsilon.\nFurther, any real number \\(x\\) is always rounded off to the nearest machine number on a computer. The IEEE standards guarantee that the relative roundoff error is no more than a certain amount. Moreover, as programmers, we need to take proper care when doing floating-point operations."
  },
  {
    "objectID": "roadmap.html",
    "href": "roadmap.html",
    "title": "C++ Roadmap",
    "section": "",
    "text": "If you’re coming upto speed on modern C++, or preparing for technical-interviews, having a structured approach can be incredibly helpful. Most companies prefer strong critical thinking and basic knowledge over extensive knowledge and medium critical thinking, because software development needs constant learning. So its important to be really cracked at modern C++ language features and the standard library.\nQuant/quantitative developer roles are not just about doing math in a basement. You are expected to be a self-starter and quickly pick up a complex codebase. Strong coding, debugging skills, are therefore incredibly valuable in writing efficient code, or analysing a large codebase.\nI suggest the following critical path, a chronological sequence of resources that have helped me quickly come upto speed in a short span of time :"
  },
  {
    "objectID": "roadmap.html#books",
    "href": "roadmap.html#books",
    "title": "C++ Roadmap",
    "section": "Books",
    "text": "Books\n\nFundamentals.\n\nBeginning C++23 from Beginner to Pro, by Ivor Horton and Peter Van Weert\nC++ Move Semantics by Nicolai M. Josuttis.\nConcurrency in Action by Anthony Williams.\n\n\n\nSpecialized books.\n\nGeneric programming.\n\nTemplate Metaprogramming with C++ by Mariuz Bancilla.\n\n\n\nMemory Management.\n\nC++ Memory Management by Patrice Roy.\n\n\n\nMultithreaded and asynchronous programming.\n\nAsynchronous Programming with C++ by Javier Reguera-Salgado and Juan Antonio Rufes."
  },
  {
    "objectID": "roadmap.html#technical-interviews",
    "href": "roadmap.html#technical-interviews",
    "title": "C++ Roadmap",
    "section": "Technical Interviews",
    "text": "Technical Interviews\n\ngetcracked.io - One of the best collections of clever C++ interview puzzles maintained and updated by CodingJesus that truly test C++, OS and computer architecture concepts at deeper-level."
  },
  {
    "objectID": "roadmap.html#blog-rolls-worth-reading",
    "href": "roadmap.html#blog-rolls-worth-reading",
    "title": "C++ Roadmap",
    "section": "Blog-rolls worth reading",
    "text": "Blog-rolls worth reading\n\ncppstories - Excellent blog worth following for explorative learning with really cool toy examples by Bartlomiej Filipek (or Bartek) from Krakow, Poland"
  },
  {
    "objectID": "posts/implementing_vector/index.html",
    "href": "posts/implementing_vector/index.html",
    "title": "Implementing vector<T>",
    "section": "",
    "text": "In this blog post, we will write a naive vector&lt;T&gt; training implementation. Coding up these training implementations, handling corner cases, getting your code reviewed, revisiting your design is very effective at understanding the inner workings of STL data-strucures and writing good C++ code. I adopt a gradual refinement approach, so my first versions will be simpler but less efficient.\n\n\n– Bjarne Stroustrup\n\nInformally, a std::vector&lt;T&gt; represents a dynamically allocated array that can grow as needed. As with any array, a std::vector&lt;T&gt; is a sequence of elements of type T arranged contigously in memory. We will put our homegrown version of vector&lt;T&gt; under the dev namespace.\nThe internal representation of a vector like type has a book-keeping node that consists of: - A pointer to the raw data (a block of memory that will hold elements of type T) - Size of the container(the number of elements in the container) - Capacity\nIt’s important to distinguish between size and capacity. size is the number of elements currently in the container. When size == capacity, the container becomes full and will need to grow, which means allocating more member, copying the elements from the old storage to the new storage and getting rid of the old storage.\nFor those of you, who want to first attempt writing a basic implementation yourself, I present it in the form a task.\n\n\n\n\n\nImplement your own version of a vector with the following methods:\n\npush_back – Adds an element to the back.\nat – Retrieves an element by index.\ngetSize – Gets the size of the container.\ngetCapacity – Gets the capacity of the container.\nshrinkToFit – Shrinks the capacity to equal the size of the container.\npop_back – Removes the last element in the container. Will never be called on an empty container.\n\n\n\n\n\nDo not worry about memory alignment or advanced optimizations.\nDo not use std::vector in your dev::vector implementation.\nYour vector’s capacity must start at 1.\nThe capacity should triple every time it is reached.\n\nFor more such C++ coding tasks, visit getcracked.io.\n\n\n\nTake a look at my submission. I used uninitialized memory algorithms, where necessary.\n// Write your solution here\n// C++20 for C++\n\n#include &lt;cstddef&gt;\n#include &lt;cstdint&gt;\n#include &lt;format&gt;\n#include &lt;initializer_list&gt;\n#include &lt;memory&gt;\n#include &lt;print&gt;\n#include &lt;stdexcept&gt;\n#include &lt;type_traits&gt;\n#include &lt;utility&gt;\n\nnamespace getcracked {\ntemplate &lt;typename Element&gt;\nclass vector {\n    constexpr static std::size_t initial_capacity{1};\n\n   private:\n    Element* m_data;\n    std::size_t m_size;\n    std::size_t m_capacity;\n\n   public:\n    std::size_t get_size() const { return m_size; }\n    std::size_t get_capacity() const { return m_capacity; }\n    vector()\n        : m_data{static_cast&lt;Element*&gt;(operator new(sizeof(Element)))},\n          m_size{0},\n          m_capacity{initial_capacity} {}\n\n    vector(size_t n, Element& initial_value)\n        : m_data{static_cast&lt;Element*&gt;(operator new(sizeof(Element) * n))},\n          m_size{0},\n          m_capacity{n} {\n        try {\n            std::uninitialized_fill_n(m_data, n, initial_value);\n            m_size = n;\n        } catch (std::exception& ex) {\n            operator delete(m_data);\n            m_capacity = 0;\n        }\n    }\n\n    vector(std::initializer_list&lt;Element&gt; list)\n        : m_data{static_cast&lt;Element*&gt;(operator new(sizeof(Element) *\n                                                    list.size()))},\n          m_size{list.size()},\n          m_capacity{list.size()} {\n        try {\n            if constexpr (std::is_nothrow_move_constructible_v&lt;Element&gt;) {\n                std::uninitialized_move(list.begin(), list.end(), m_data);\n            } else {\n                std::uninitialized_copy(list.begin(), list.end(), m_data);\n            }\n        } catch (std::exception& ex) {\n            operator delete(m_data);\n            m_size = 0;\n            m_capacity = 0;\n        }\n    }\n\n    vector(const vector& other)\n        : m_data{operator new(sizeof(Element) * other.get_size())},\n          m_size{other.get_size()},\n          m_capacity{other.get_capacity()} {\n        try {\n            // Perform a deep-copy of all the elements\n            std::uninitialized_copy(other.m_data, other.m_data + other.m_size,\n                                    m_data);\n        } catch (std::exception& ex) {\n            operator delete(m_data);\n            std::string error_msg =\n                std::format(\"Error while copying in copy ctor {}\", ex.what());\n            throw std::logic_error(error_msg);\n        }\n    }\n\n    vector(vector&& other) noexcept\n        : m_data{std::exchange(other.m_data, nullptr)},\n          m_size{std::exchange(other.m_size, 0)},\n          m_capacity{std::exchange(other.m_capacity, 0)} {}\n\n    void swap(vector& other) noexcept {\n        std::swap(this-&gt;m_data, other.m_data);\n        std::swap(this-&gt;m_size, other.m_size);\n        std::swap(this-&gt;m_capacity, other.m_capacity);\n    }\n\n    vector& operator=(const vector& other) {\n        vector(other).swap(*this);\n        return *this;\n    }\n\n    vector& operator=(vector&& other) {\n        vector(std::move(other)).swap(*this);\n        return *this;\n    }\n\n    bool is_full() { return get_size() == get_capacity(); }\n\n    void push_back(Element element) {\n        std::size_t offset = get_size();\n        if (m_size == m_capacity - 1) {\n            // Allocate new memory\n            std::size_t new_size = get_size() + 1;\n            std::size_t new_capacity = 3 * m_capacity;\n            Element* new_memory_block = static_cast&lt;Element*&gt;(operator new(\n                sizeof(Element) * new_capacity));\n            Element* ptr_to_new_element{nullptr};\n\n            try {\n                // Construct the new element in new memory block\n                ptr_to_new_element =\n                    new (new_memory_block + offset) Element(element);\n            } catch (std::exception& ex) {\n                operator delete(new_memory_block);\n                std::string error_msg = std::format(\n                    \"Failed to copy-construct element : {}\", ex.what());\n                throw std::logi c_error(error_msg);\n            }\n\n            try {\n                // Copy/move- the elements from the old storage to new\n                if constexpr (std::is_nothrow_move_constructible_v&lt;Element&gt;) {\n                    std::uninitialized_move(m_data, m_data + offset,\n                                            new_memory_block);\n                } else {\n                    std::uninitialized_copy(m_data, m_data + offset,\n                                            new_memory_block);\n                }\n            } catch (std::exception& ex) {\n                std::destroy_at(ptr_to_new_element);\n                operator delete(new_memory_block);\n                std::string error_msg = std::format(\n                    \"Failed to copy/move data from old to new storage, \"\n                    \"exception : {}\",\n                    ex.what());\n                throw std::logic_error(error_msg);\n            }\n\n            // Destroy the objects in the old storage\n            auto p{m_data};\n            for (auto p{m_data}; p &lt; m_data + m_size; ++p) {\n                p-&gt;~Element();\n            }\n\n            // Deallocate old storage\n            operator delete(m_data);\n\n            // Reassign internal buffer pointer and update size and capacity\n            m_data = new_memory_block;\n            m_size = new_size;\n            m_capacity = new_capacity;\n        } else {\n            try {\n                std::construct_at(m_data + offset, element);\n                m_size += 1;\n            } catch (std::exception& ex) {\n                std::string error_msg = std::format(\n                    \"Failed to copy-construct element, exception : {}\",\n                    ex.what());\n                throw std::logic_error(error_msg);\n            }\n        }\n    }\n\n    const Element& at(std::size_t index) const {\n        if (index &lt; 0 || index &gt;= m_size)\n            throw std::out_of_range(\"Array index out of bounds!\");\n\n        return m_data[index];\n    }\n    void shrink_to_fit() {\n        // Allocate a new memory block of capacity = m_size\n        Element* new_memory_block =\n            static_cast&lt;Element*&gt;(operator new(sizeof(Element) * m_size));\n\n        try {\n            // Copy/move the elements from the old storage to new storage\n            if constexpr (std::is_nothrow_move_constructible_v&lt;Element&gt;) {\n                std::uninitialized_move(m_data, m_data + m_size,\n                                        new_memory_block);\n            } else {\n                std::uninitialized_copy(m_data, m_data + m_size,\n                                        new_memory_block);\n            }\n        } catch (std::exception& ex) {\n            operator delete(new_memory_block);\n            std::string error_msg = std::format(\n                \"Internal error in shrink_to_fit() : {}\", ex.what());\n            throw std::logic_error(error_msg);\n        }\n\n        // Destroy objects in old storage and deallocate memory\n        for (auto p{m_data}; p &lt; m_data + m_size; ++p) {\n            std::destroy_at&lt;Element&gt;(p);\n        }\n        // Deallocate memory\n        operator delete(m_data);\n\n        // Reassign internal buffer pointer and set size and capacity\n        m_data = new_memory_block;\n        m_capacity = m_size;\n    }\n    void pop_back() {\n        Element* ptr_to_last = m_data + m_size - 1;\n        std::destroy_at(ptr_to_last);\n        --m_size;\n    }\n};\n}  // namespace getcracked\n\nint main() {\n    getcracked::vector&lt;double&gt; v;\n    v.push_back(1);\n    v.push_back(2);\n    std::println(\"v[0] = {}\", v.at(0));\n    std::println(\"size = {}\", v.get_size());\n    std::println(\"capacity = {}\", v.get_capacity());\n}\nCompiler Explorer\n\n\n\n\n\nC++ containers usually expose iterators as part of their interface and ours will be no exception. We will define type aliases for the const and non-const iterator types, as this makes it simpler to implement alternatives.\n// ...\ntemplate &lt;typename T&gt;\nclass vector {\n    using value_type = T;\n    using size_type = std::size_t;\n    using pointer = T*;\n    using const_pointer = const T*;\n    using reference = T&;\n    using const_reference = const T&;\n    using iterator = pointer;\n    using const_iterator = const_pointer;\n    constexpr static std::size_t initial_capacity{1};\n\nprivate:\n    pointer m_data;\n    size_type m_size;\n    size_type m_capacity;\n\npublic:\n\n    iterator begin(){ return m_data; }\n    const_iterator begin() const{ return m_data; }\n    iterator end(){ return begin() + m_size; }\n    const_iterator end() const{ return begin() + m_size; }\n// ...\nCompiler Explorer\n\n\n\nThere is more to writing a convenient dynamic array type. For example, member functions that let you access the first() element or the last back() element or that let you access the element at a specific index in the array using square brackets are all to be expected.\n// ...\nreference operator[](size_type idx){\n    return m_data[idx];\n}\n\nconst_reference operator[](size_type idx) const{\n    return m_data[idx];\n}\n\n// precondition: !empty()\nreference front(){ return (*this)[0]; }\nconst_reference front() const { return (*this)[0]; }\nreference back(){ return (*this)[m_size - 1]; }\nconst_reference back() const{ return (*this)[m_size - 1]; }\nComparing two vector&lt;T&gt; objects for equivalence or lack thereof is a relatively easy matter if we use algorithms:\n//...\nbool operator==(const vector& other){\n    return size() == other.size() && \n        std::equal(begin(), end(), other.begin());\n}\n\n\n\nreserve(size_type new_capacity) increases the capacity of the vector(the total number of elements that the vector can hold without requiring reallocation) to a value that’s greater or equal to new_capacity. If new_capacity is greater than the current capacity(), new storage is allocated, otherwise the function does nothing.\nWe introduce the helper functions allocate_helper and copy_old_storage_to_new.\n// Dynamically allocates a chunk of uninitialized memory on the heap\n// that can hold `new_capacity` number of elements.\n// Allocation excepts are propogated to the caller.\npointer allocate_helper(size_type new_capacity){\n    return static_cast&lt;pointer&gt;(operator new(sizeof(value_type) * new_capacity));\n}\n\nvoid deallocate_helper(pointer ptr){\n    operator delete(ptr);\n}\n\n// Copies elements from old storage to new\n// If T's copy/move ctor throws, the objects already constructed are\n// destroyed and the exception is propagated to the caller.\nvoid copy_old_storage_to_new(pointer source_first, size_t num_elements, pointer destination_first){\n    if constexpr(std::is_nothrow_move_constructible_v&lt;T&gt;){\n        std::uninitialized_move(source_first, source_first + num_elements, destination_first);\n    }\n    else{\n        try{\n            std::uninitialized_copy(source_first, source_first + num_elements, destination_first);\n        }catch(std::exception& ex){\n            throw ex;\n        }\n    }\n}\n\nvoid reserve(size_type new_capacity){\n    if(new_capacity &lt;= capacity())\n        return;\n    \n    auto ptr_new_blk = allocate_helper(new_capacity);\n    try{\n        copy_old_storage_to_new(m_data, m_size, ptr_new_blk);\n    }catch(std::exception& ex){\n        deallocate_helper(ptr_new_blk);\n        throw ex;   // rethrow\n    }\n    \n    std::destroy(m_data, m_data + m_size);\n    deallocate_helper(m_data);\n    m_data = ptr_new_blk;\n    m_capacity = new_capacity;    \n}\nCompiler Explorer\nThere’s a general trick that you would have seen in all of this. Do not modify your object until you know, you can safely do. Try to do the potentially throwing operations first, then do the operations until you can mutate your object. You will sleep better, and the risks of object corruption will be alleviated.\n\n\n\nThe distinction between resize() and reserve() is that reserve() only affects the capacity of the container, whereas resize() modifies the size and capacity both.\nThe resize(size_type new_size) method resizes the container to contain count elements:\n\nIf the new_size is equal to the current size, do nothing.\nIf the current size is greater than the new_size, the container is reduced to its first new_size elements.\nIf the current size is less than new_size, then:\n\nAdditional default-constructed elements are appended.\n\n\nvoid resize(size_type new_size){\n    size_type current_size = m_size;\n    if(new_size == current_size)\n        return;\n\n    if(new_size &lt; current_size)\n    {\n        // Reduce the container to count elements\n        std::destroy(m_data + new_size, m_data + m_size);\n    }\n\n    if(new_size &gt; current_size)\n    {\n        reserve(new_size);\n\n        // Default construct elements at indicates\n        // [current_size,...,new_size-1]\n        for (auto p{ begin() + current_size }; p != begin() + new_size; ++p)\n            std::construct_at(p, value_type{});\n    }\n    m_size = new_size;\n}    \n\n\n\n\nWe will code up a push_back(T&&) member function that accepts a universal reference T&&. If T is move constructible, then the value will be moved. If T is copy constructible then the value will be copied.\nThe emplace_back(Args...) will take a variadic pack of constructor arguments, and then perfectly forward them to the constructor of a T object, that will be placed at the end of the container. A reference to the newly constructed object is returned by emplace_back(), for convenience, in case the user-code would like to use it right away.\nWe would like to first check whether the container is full. We have a dichotomy. If the container is full, we take the so-called slow path, else we take the fast lane.\n\n\nIn this case, we would like to grow our container; we allocate more memory, than what the container currently holds. We leave the memory uninitialized. Memory allocation, can of course, fail.\nWe then add the new value at the index m_size. Appending the new element may fail.\nWe copy/move construct the existing elements of the container from the old storage to the new block of storage.\nIf all three steps were successful, we deallocate the old storage and return it back before replacing the values in the member variables m_data, m_size and m_capacity.\nIf either of the last couple of steps fail, we free the newly obtained block of storage.\n\n\n\nIn this case, we simply copy/move construct value at the end of the container and update the size of the container.\n\n\n\nConsider the following edge-case, where the value to be added is an element of the vector itself. If there is a reallocation, then the elements of the container are relocated to a new region. So, value might become a dangling reference.\ndev::vector&lt;int&gt; vec{ 1 };\nfor (int i = 0; i &lt; 10; ++i) {\n    vec.push_back(vec.back());\n    EXPECT_EQ(vec.back(), 1);\n}\nOur design takes care of this edge case.\ntemplate&lt;typename U&gt;\nvoid push_back_slow_path(U&& value){\n    // allocate more memory\n    size_type offset = size();\n    size_type new_size = m_size + 1;\n    size_type new_capacity = growth_factor * capacity();\n    auto ptr_new_blk = allocate_helper(new_capacity);\n\n    try{\n        // Copy-construct the new value at the index m_size\n        std::construct_at(ptr_new_blk + m_size, value);\n    }catch(std::exception& ex){\n        deallocate_helper(ptr_new_blk);\n        throw ex;   // rethrow                \n    }\n    \n    try{\n        // copy/move construct the existing elements \n        // of the container from the old storage \n        // to the new block of storage.\n        copy_old_storage_to_new(m_data, m_size, ptr_new_blk);\n    }catch(std::exception& ex){\n        std::destroy_at(ptr_new_blk + m_size);\n        deallocate_helper(ptr_new_blk);\n        throw ex;   // rethrow\n    }\n\n    // deallocate the old storage, if we are here\n    deallocate_helper(m_data);\n\n    m_data = ptr_new_blk;\n    ++m_size;\n    m_capacity = new_capacity;\n}\n\ntemplate&lt;typename U&gt;\nvoid push_back_fast_path(U&& value){\n    std::construct_at(m_data + m_size, value);\n    ++m_size;\n}        \n\ntemplate&lt;typename U&gt;\nvoid push_back(U&& value)\n{\n    if(is_full())\n    {\n        push_back_slow_path(std::forward&lt;U&gt;(value));\n    }\n    else{\n        push_back_fast_path(std::forward&lt;U&gt;(value));\n    }\n}\n\n\n\nAgain we have a fork - emplace_back_slow_path and emplace_back_fast_path.\ntemplate&lt;typename... Args&gt;\nreference emplace_back_slow_path(Args... args){\n    // allocate more memory\n    size_type offset = size();\n    size_type new_size = m_size + 1;\n    size_type new_capacity = growth_factor * capacity();\n    auto ptr_new_blk = allocate_helper(new_capacity);\n\n    try{\n        // copy/move construct the existing elements \n        // of the container from the old storage \n        // to the new block of storage.\n        copy_old_storage_to_new(m_data, m_size, ptr_new_blk);\n    }catch(std::exception& ex){\n        deallocate_helper(ptr_new_blk);\n        throw ex;   // rethrow\n    }\n\n    std::construct_at(ptr_new_blk + m_size, std::forward&lt;Args&gt;(args)...);\n    deallocate_helper(m_data);\n    m_data = ptr_new_blk;\n    ++m_size;\n    return back();\n}\n\ntemplate&lt;typename... Args&gt;\nreference emplace_back_fast_path(Args... args){\n    std::construct_at(m_data + m_size, std::forward&lt;Args&gt;(args)...);\n    ++m_size;\n    return back();\n}\n\ntemplate&lt;typename... Args&gt;\nreference emplace_back(Args... args){\n    if(is_full())\n        return emplace_back_slow_path(std::forward&lt;Args&gt;(args)...);\n    else\n        return emplace_back_fast_path(std::forward&lt;Args&gt;(args)...);\n}\nCompiler Explorer\n\n\n\n\nThe insert function inserts the given value into the vector before the specified position, possibly using move-semantics. Note that, this kind of operation could be expensive for a vector, and if it is frequently used, it can trigger reallocation. The user should consider using std::list.\ntemplate&lt;typename U&gt;\niterator insert_slow_path(const_iterator insert_it, U&& value){\n    // If a reallocation is triggered, all iterators are\n    // invalidated and additionally `value` would also become a\n    // dangling reference, if it refers to an existing element of\n    // the vector.\n    // TODO\n}\n\ntemplate&lt;typename U&gt;\niterator insert_fast_path(const_iterator position, U&& value){\n    auto pos_ = position;\n    if constexpr (std::is_nothrow_move_constructible_v&lt;T&gt;) {\n        std::uninitialized_move(end() - 1, end(), end());\n        std::move_backward(pos_, end(), end());\n        *pos_ = std::move(value);\n    } else {\n        std::uninitialized_copy(end() - 1, end(), end());\n        std::copy_backward(pos_, end(), end());\n        *pos_ = value;\n    }\n    ++m_size;\n    return pos_;\n}\n\ntemplate&lt;typename U&gt;\niterator insert(const_iterator position, U&& value)\n{\n    if(is_full())\n        return insert_slow_path(position, std::forward&lt;U&gt;(value));\n    else\n        return insert_fast_path(position, std::forward&lt;U&gt;(value));\n}"
  },
  {
    "objectID": "posts/ranges_and_views/index.html#understanding-the-constrained-algorithms",
    "href": "posts/ranges_and_views/index.html#understanding-the-constrained-algorithms",
    "title": "C++ Ranges",
    "section": "",
    "text": "The standard library provides over a hundred general-purpose algorithms. Most of these algorithms have a new constrained version in std::ranges namespace. These algorithms are found in the &lt;algorithm&gt;, &lt;numeric&gt; and &lt;memory&gt; header.\n\nThey have the same name as the existing algorithms.\nThey have overloads that allow you to specify a range, either with a begin iterator and an end sentinel, or as a single range argument.\nThey have modified return types that provide more information about the execution.\nThey support projections to apply to the processed elements. A projection is an entity that can be invoked. It can be a pointer to a member function, a lambda expression, or a function pointer. Such a projection is applied to the range element before the algorithm logic uses the element.\n\nFrom cppreference.com, the rangified version of the copy_if algorithm has the following overloads:\ntemplate&lt; std::input_iterator I, std::sentinel_for&lt;I&gt; S, std::weakly_incrementable O,\n          class Proj = std::identity,\n          std::indirect_unary_predicate&lt;std::projected&lt;I, Proj&gt;&gt; Pred &gt;\nrequires std::indirectly_copyable&lt;I, O&gt;\nconstexpr copy_if_result&lt;I, O&gt;\n    copy_if( I first, S last, O result, Pred pred, Proj proj = {} );\ntemplate&lt; ranges::input_range R, std::weakly_incrementable O,\n          class Proj = std::identity,\n          std::indirect_unary_predicate&lt;\n              std::projected&lt;ranges::iterator_t&lt;R&gt;, Proj&gt;&gt; Pred &gt;\nrequires std::indirectly_copyable&lt;ranges::iterator_t&lt;R&gt;, O&gt;\nconstexpr copy_if_result&lt;ranges::borrowed_iterator_t&lt;R&gt;, O&gt;\n    copy_if( R&& r, O result, Pred pred, Proj proj = {} );\nThe signatures may look cryptic, but it’s easy to code up a few quick examples.\n#include &lt;iostream&gt;\n#include &lt;ranges&gt;\n#include &lt;algorithm&gt;\n#include &lt;vector&gt;\n\nnamespace stdr = std::ranges;\nnamespace stdv = std::ranges::views;\n\nint main()\n{\n    std::vector&lt;int&gt; v{1, 1, 2, 3, 5, 8, 13};\n    std::vector&lt;int&gt; o;\n\n    auto filter_odd = [](int n){ return n % 2 == 1; };\n    auto e1 = stdr::copy_if(v, std::back_inserter(o), filter_odd);\n\n    int arr[] = {1, 1, 2, 3, 5, 8, 13 };\n    auto e2 = stdr::copy_if(arr,\n        std::back_inserter(o), filter_odd\n    );\n\n    auto rng = stdr::iota_view(1,10);\n    auto e3 = stdr::copy_if(r, std::back_inserter(o), filter_odd);\n    return 0;\n}\nCompiler Explorer\nThese examples show two things: how to copy elements from a std::vector object and an array and how to copy elements from a view(a range adaptor). What they don’t show is projections. I’ll explore some examples on this shortly.\nOther constrained algorithms like all_of, any_of, none_of, find, find_if, copy, copy_if, move, copy_backward, move_backward, fill, fill_n, transform, sample, fold_left, fold_right are very useful in coding.\nA projection is an invocable entity. It’s basically a function adaptor. It affects the predicate, providing a way to perform function composition. It does not provide a way to change the algorithm. For instance, let’s say we have the following type:\nLet’s say we have the following type:\nstruct Point{\n    double x;\n    double y;\n};\nAlso, for the purpose of the explanation, let’s consider the following sequence of points:\nstd::vector&lt;Point&gt; points{\n    {1.0, 1.0},\n    {-1.0, 1.0},\n    {1.0, -1.0},\n    {-1.0, -1.0}\n}\nProjects allow us to perform composition on the predicate. For instance, let’s say we want to copy to a second vector all points below the \\(x\\)-axis (having a negative \\(y\\)-coordinate). We can code up the following:\nstd::vector&lt;Point&gt; points_below_x_axis;\nstdr::copy_if(points,\n    std::back_inserter(points_below_x_axis),\n    [](const Point& point){\n        return point.x &lt; 0;\n    }\n);\nHowever, we can also write equivalently:\nstd::vector&lt;Point&gt; points_below_x_axis;\nstdr::copy_if(points,\n    std::back_inserter(points_below_x_axis),\n    [](const Point& point){\n        return x &lt; 0;\n    },\n    &Point::x\n);\nThe projection, in this example, is the pointer-to-member expression &Point::x that is applied to each Point element before executing the predicate (which is a lambda expression). This is useful when already have reusable function objects/lambda expressions and you don’t want to write another one for passing different types."
  },
  {
    "objectID": "posts/ranges_and_views/index.html#writing-your-own-range-adaptor",
    "href": "posts/ranges_and_views/index.html#writing-your-own-range-adaptor",
    "title": "C++ Ranges",
    "section": "",
    "text": "The standard library contains a series of range adaptors that can be used for solving many different tasks. However, there are situations where we’d like to write our own custom randge adaptor."
  },
  {
    "objectID": "posts/implementing_vector/index.html#the-problem-statement",
    "href": "posts/implementing_vector/index.html#the-problem-statement",
    "title": "Implementing vector<T>",
    "section": "",
    "text": "Implement your own version of a vector with the following methods:\n\npush_back – Adds an element to the back.\nat – Retrieves an element by index.\ngetSize – Gets the size of the container.\ngetCapacity – Gets the capacity of the container.\nshrinkToFit – Shrinks the capacity to equal the size of the container.\npop_back – Removes the last element in the container. Will never be called on an empty container.\n\n\n\n\n\nDo not worry about memory alignment or advanced optimizations.\nDo not use std::vector in your dev::vector implementation.\nYour vector’s capacity must start at 1.\nThe capacity should triple every time it is reached.\n\nFor more such C++ coding tasks, visit getcracked.io."
  },
  {
    "objectID": "posts/implementing_vector/index.html#a-basic-implementation",
    "href": "posts/implementing_vector/index.html#a-basic-implementation",
    "title": "Implementing vector<T>",
    "section": "",
    "text": "Take a look at my submission. I used uninitialized memory algorithms, where necessary.\n// Write your solution here\n// C++20 for C++\n\n#include &lt;cstddef&gt;\n#include &lt;cstdint&gt;\n#include &lt;format&gt;\n#include &lt;initializer_list&gt;\n#include &lt;memory&gt;\n#include &lt;print&gt;\n#include &lt;stdexcept&gt;\n#include &lt;type_traits&gt;\n#include &lt;utility&gt;\n\nnamespace getcracked {\ntemplate &lt;typename Element&gt;\nclass vector {\n    constexpr static std::size_t initial_capacity{1};\n\n   private:\n    Element* m_data;\n    std::size_t m_size;\n    std::size_t m_capacity;\n\n   public:\n    std::size_t get_size() const { return m_size; }\n    std::size_t get_capacity() const { return m_capacity; }\n    vector()\n        : m_data{static_cast&lt;Element*&gt;(operator new(sizeof(Element)))},\n          m_size{0},\n          m_capacity{initial_capacity} {}\n\n    vector(size_t n, Element& initial_value)\n        : m_data{static_cast&lt;Element*&gt;(operator new(sizeof(Element) * n))},\n          m_size{0},\n          m_capacity{n} {\n        try {\n            std::uninitialized_fill_n(m_data, n, initial_value);\n            m_size = n;\n        } catch (std::exception& ex) {\n            operator delete(m_data);\n            m_capacity = 0;\n        }\n    }\n\n    vector(std::initializer_list&lt;Element&gt; list)\n        : m_data{static_cast&lt;Element*&gt;(operator new(sizeof(Element) *\n                                                    list.size()))},\n          m_size{list.size()},\n          m_capacity{list.size()} {\n        try {\n            if constexpr (std::is_nothrow_move_constructible_v&lt;Element&gt;) {\n                std::uninitialized_move(list.begin(), list.end(), m_data);\n            } else {\n                std::uninitialized_copy(list.begin(), list.end(), m_data);\n            }\n        } catch (std::exception& ex) {\n            operator delete(m_data);\n            m_size = 0;\n            m_capacity = 0;\n        }\n    }\n\n    vector(const vector& other)\n        : m_data{operator new(sizeof(Element) * other.get_size())},\n          m_size{other.get_size()},\n          m_capacity{other.get_capacity()} {\n        try {\n            // Perform a deep-copy of all the elements\n            std::uninitialized_copy(other.m_data, other.m_data + other.m_size,\n                                    m_data);\n        } catch (std::exception& ex) {\n            operator delete(m_data);\n            std::string error_msg =\n                std::format(\"Error while copying in copy ctor {}\", ex.what());\n            throw std::logic_error(error_msg);\n        }\n    }\n\n    vector(vector&& other) noexcept\n        : m_data{std::exchange(other.m_data, nullptr)},\n          m_size{std::exchange(other.m_size, 0)},\n          m_capacity{std::exchange(other.m_capacity, 0)} {}\n\n    void swap(vector& other) noexcept {\n        std::swap(this-&gt;m_data, other.m_data);\n        std::swap(this-&gt;m_size, other.m_size);\n        std::swap(this-&gt;m_capacity, other.m_capacity);\n    }\n\n    vector& operator=(const vector& other) {\n        vector(other).swap(*this);\n        return *this;\n    }\n\n    vector& operator=(vector&& other) {\n        vector(std::move(other)).swap(*this);\n        return *this;\n    }\n\n    bool is_full() { return get_size() == get_capacity(); }\n\n    void push_back(Element element) {\n        std::size_t offset = get_size();\n        if (m_size == m_capacity - 1) {\n            // Allocate new memory\n            std::size_t new_size = get_size() + 1;\n            std::size_t new_capacity = 3 * m_capacity;\n            Element* new_memory_block = static_cast&lt;Element*&gt;(operator new(\n                sizeof(Element) * new_capacity));\n            Element* ptr_to_new_element{nullptr};\n\n            try {\n                // Construct the new element in new memory block\n                ptr_to_new_element =\n                    new (new_memory_block + offset) Element(element);\n            } catch (std::exception& ex) {\n                operator delete(new_memory_block);\n                std::string error_msg = std::format(\n                    \"Failed to copy-construct element : {}\", ex.what());\n                throw std::logi c_error(error_msg);\n            }\n\n            try {\n                // Copy/move- the elements from the old storage to new\n                if constexpr (std::is_nothrow_move_constructible_v&lt;Element&gt;) {\n                    std::uninitialized_move(m_data, m_data + offset,\n                                            new_memory_block);\n                } else {\n                    std::uninitialized_copy(m_data, m_data + offset,\n                                            new_memory_block);\n                }\n            } catch (std::exception& ex) {\n                std::destroy_at(ptr_to_new_element);\n                operator delete(new_memory_block);\n                std::string error_msg = std::format(\n                    \"Failed to copy/move data from old to new storage, \"\n                    \"exception : {}\",\n                    ex.what());\n                throw std::logic_error(error_msg);\n            }\n\n            // Destroy the objects in the old storage\n            auto p{m_data};\n            for (auto p{m_data}; p &lt; m_data + m_size; ++p) {\n                p-&gt;~Element();\n            }\n\n            // Deallocate old storage\n            operator delete(m_data);\n\n            // Reassign internal buffer pointer and update size and capacity\n            m_data = new_memory_block;\n            m_size = new_size;\n            m_capacity = new_capacity;\n        } else {\n            try {\n                std::construct_at(m_data + offset, element);\n                m_size += 1;\n            } catch (std::exception& ex) {\n                std::string error_msg = std::format(\n                    \"Failed to copy-construct element, exception : {}\",\n                    ex.what());\n                throw std::logic_error(error_msg);\n            }\n        }\n    }\n\n    const Element& at(std::size_t index) const {\n        if (index &lt; 0 || index &gt;= m_size)\n            throw std::out_of_range(\"Array index out of bounds!\");\n\n        return m_data[index];\n    }\n    void shrink_to_fit() {\n        // Allocate a new memory block of capacity = m_size\n        Element* new_memory_block =\n            static_cast&lt;Element*&gt;(operator new(sizeof(Element) * m_size));\n\n        try {\n            // Copy/move the elements from the old storage to new storage\n            if constexpr (std::is_nothrow_move_constructible_v&lt;Element&gt;) {\n                std::uninitialized_move(m_data, m_data + m_size,\n                                        new_memory_block);\n            } else {\n                std::uninitialized_copy(m_data, m_data + m_size,\n                                        new_memory_block);\n            }\n        } catch (std::exception& ex) {\n            operator delete(new_memory_block);\n            std::string error_msg = std::format(\n                \"Internal error in shrink_to_fit() : {}\", ex.what());\n            throw std::logic_error(error_msg);\n        }\n\n        // Destroy objects in old storage and deallocate memory\n        for (auto p{m_data}; p &lt; m_data + m_size; ++p) {\n            std::destroy_at&lt;Element&gt;(p);\n        }\n        // Deallocate memory\n        operator delete(m_data);\n\n        // Reassign internal buffer pointer and set size and capacity\n        m_data = new_memory_block;\n        m_capacity = m_size;\n    }\n    void pop_back() {\n        Element* ptr_to_last = m_data + m_size - 1;\n        std::destroy_at(ptr_to_last);\n        --m_size;\n    }\n};\n}  // namespace getcracked\n\nint main() {\n    getcracked::vector&lt;double&gt; v;\n    v.push_back(1);\n    v.push_back(2);\n    std::println(\"v[0] = {}\", v.at(0));\n    std::println(\"size = {}\", v.get_size());\n    std::println(\"capacity = {}\", v.get_capacity());\n}\nCompiler Explorer"
  },
  {
    "objectID": "posts/implementing_vector/index.html#adding-support-for-other-methods",
    "href": "posts/implementing_vector/index.html#adding-support-for-other-methods",
    "title": "Implementing vector<T>",
    "section": "",
    "text": "C++ containers usually expose iterators as part of their interface and ours will be no exception. We will define type aliases for the const and non-const iterator types, as this makes it simpler to implement alternatives.\n// ...\ntemplate &lt;typename T&gt;\nclass vector {\n    using value_type = T;\n    using size_type = std::size_t;\n    using pointer = T*;\n    using const_pointer = const T*;\n    using reference = T&;\n    using const_reference = const T&;\n    using iterator = pointer;\n    using const_iterator = const_pointer;\n    constexpr static std::size_t initial_capacity{1};\n\nprivate:\n    pointer m_data;\n    size_type m_size;\n    size_type m_capacity;\n\npublic:\n\n    iterator begin(){ return m_data; }\n    const_iterator begin() const{ return m_data; }\n    iterator end(){ return begin() + m_size; }\n    const_iterator end() const{ return begin() + m_size; }\n// ...\nCompiler Explorer\n\n\n\nThere is more to writing a convenient dynamic array type. For example, member functions that let you access the first() element or the last back() element or that let you access the element at a specific index in the array using square brackets are all to be expected.\n// ...\nreference operator[](size_type idx){\n    return m_data[idx];\n}\n\nconst_reference operator[](size_type idx) const{\n    return m_data[idx];\n}\n\n// precondition: !empty()\nreference front(){ return (*this)[0]; }\nconst_reference front() const { return (*this)[0]; }\nreference back(){ return (*this)[m_size - 1]; }\nconst_reference back() const{ return (*this)[m_size - 1]; }\nComparing two vector&lt;T&gt; objects for equivalence or lack thereof is a relatively easy matter if we use algorithms:\n//...\nbool operator==(const vector& other){\n    return size() == other.size() && \n        std::equal(begin(), end(), other.begin());\n}\n\n\n\nreserve(size_type new_capacity) increases the capacity of the vector(the total number of elements that the vector can hold without requiring reallocation) to a value that’s greater or equal to new_capacity. If new_capacity is greater than the current capacity(), new storage is allocated, otherwise the function does nothing.\nWe introduce the helper functions allocate_helper and copy_old_storage_to_new.\n// Dynamically allocates a chunk of uninitialized memory on the heap\n// that can hold `new_capacity` number of elements.\n// Allocation excepts are propogated to the caller.\npointer allocate_helper(size_type new_capacity){\n    return static_cast&lt;pointer&gt;(operator new(sizeof(value_type) * new_capacity));\n}\n\nvoid deallocate_helper(pointer ptr){\n    operator delete(ptr);\n}\n\n// Copies elements from old storage to new\n// If T's copy/move ctor throws, the objects already constructed are\n// destroyed and the exception is propagated to the caller.\nvoid copy_old_storage_to_new(pointer source_first, size_t num_elements, pointer destination_first){\n    if constexpr(std::is_nothrow_move_constructible_v&lt;T&gt;){\n        std::uninitialized_move(source_first, source_first + num_elements, destination_first);\n    }\n    else{\n        try{\n            std::uninitialized_copy(source_first, source_first + num_elements, destination_first);\n        }catch(std::exception& ex){\n            throw ex;\n        }\n    }\n}\n\nvoid reserve(size_type new_capacity){\n    if(new_capacity &lt;= capacity())\n        return;\n    \n    auto ptr_new_blk = allocate_helper(new_capacity);\n    try{\n        copy_old_storage_to_new(m_data, m_size, ptr_new_blk);\n    }catch(std::exception& ex){\n        deallocate_helper(ptr_new_blk);\n        throw ex;   // rethrow\n    }\n    \n    std::destroy(m_data, m_data + m_size);\n    deallocate_helper(m_data);\n    m_data = ptr_new_blk;\n    m_capacity = new_capacity;    \n}\nCompiler Explorer\nThere’s a general trick that you would have seen in all of this. Do not modify your object until you know, you can safely do. Try to do the potentially throwing operations first, then do the operations until you can mutate your object. You will sleep better, and the risks of object corruption will be alleviated.\n\n\n\nThe distinction between resize() and reserve() is that reserve() only affects the capacity of the container, whereas resize() modifies the size and capacity both.\nThe resize(size_type new_size) method resizes the container to contain count elements:\n\nIf the new_size is equal to the current size, do nothing.\nIf the current size is greater than the new_size, the container is reduced to its first new_size elements.\nIf the current size is less than new_size, then:\n\nAdditional default-constructed elements are appended.\n\n\nvoid resize(size_type new_size){\n    size_type current_size = m_size;\n    if(new_size == current_size)\n        return;\n\n    if(new_size &lt; current_size)\n    {\n        // Reduce the container to count elements\n        std::destroy(m_data + new_size, m_data + m_size);\n    }\n\n    if(new_size &gt; current_size)\n    {\n        reserve(new_size);\n\n        // Default construct elements at indicates\n        // [current_size,...,new_size-1]\n        for (auto p{ begin() + current_size }; p != begin() + new_size; ++p)\n            std::construct_at(p, value_type{});\n    }\n    m_size = new_size;\n}"
  },
  {
    "objectID": "posts/implementing_vector/index.html#how-to-think-about-adding-elements-to-our-container",
    "href": "posts/implementing_vector/index.html#how-to-think-about-adding-elements-to-our-container",
    "title": "Implementing vector<T>",
    "section": "",
    "text": "We will code up a push_back(T&&) member function that accepts a universal reference T&&. If T is move constructible, then the value will be moved. If T is copy constructible then the value will be copied.\nThe emplace_back(Args...) will take a variadic pack of constructor arguments, and then perfectly forward them to the constructor of a T object, that will be placed at the end of the container. A reference to the newly constructed object is returned by emplace_back(), for convenience, in case the user-code would like to use it right away.\nWe would like to first check whether the container is full. We have a dichotomy. If the container is full, we take the so-called slow path, else we take the fast lane.\n\n\nIn this case, we would like to grow our container; we allocate more memory, than what the container currently holds. We leave the memory uninitialized. Memory allocation, can of course, fail.\nWe then add the new value at the index m_size. Appending the new element may fail.\nWe copy/move construct the existing elements of the container from the old storage to the new block of storage.\nIf all three steps were successful, we deallocate the old storage and return it back before replacing the values in the member variables m_data, m_size and m_capacity.\nIf either of the last couple of steps fail, we free the newly obtained block of storage.\n\n\n\nIn this case, we simply copy/move construct value at the end of the container and update the size of the container.\n\n\n\nConsider the following edge-case, where the value to be added is an element of the vector itself. If there is a reallocation, then the elements of the container are relocated to a new region. So, value might become a dangling reference.\ndev::vector&lt;int&gt; vec{ 1 };\nfor (int i = 0; i &lt; 10; ++i) {\n    vec.push_back(vec.back());\n    EXPECT_EQ(vec.back(), 1);\n}\nOur design takes care of this edge case.\ntemplate&lt;typename U&gt;\nvoid push_back_slow_path(U&& value){\n    // allocate more memory\n    size_type offset = size();\n    size_type new_size = m_size + 1;\n    size_type new_capacity = growth_factor * capacity();\n    auto ptr_new_blk = allocate_helper(new_capacity);\n\n    try{\n        // Copy-construct the new value at the index m_size\n        std::construct_at(ptr_new_blk + m_size, value);\n    }catch(std::exception& ex){\n        deallocate_helper(ptr_new_blk);\n        throw ex;   // rethrow                \n    }\n    \n    try{\n        // copy/move construct the existing elements \n        // of the container from the old storage \n        // to the new block of storage.\n        copy_old_storage_to_new(m_data, m_size, ptr_new_blk);\n    }catch(std::exception& ex){\n        std::destroy_at(ptr_new_blk + m_size);\n        deallocate_helper(ptr_new_blk);\n        throw ex;   // rethrow\n    }\n\n    // deallocate the old storage, if we are here\n    deallocate_helper(m_data);\n\n    m_data = ptr_new_blk;\n    ++m_size;\n    m_capacity = new_capacity;\n}\n\ntemplate&lt;typename U&gt;\nvoid push_back_fast_path(U&& value){\n    std::construct_at(m_data + m_size, value);\n    ++m_size;\n}        \n\ntemplate&lt;typename U&gt;\nvoid push_back(U&& value)\n{\n    if(is_full())\n    {\n        push_back_slow_path(std::forward&lt;U&gt;(value));\n    }\n    else{\n        push_back_fast_path(std::forward&lt;U&gt;(value));\n    }\n}\n\n\n\nAgain we have a fork - emplace_back_slow_path and emplace_back_fast_path.\ntemplate&lt;typename... Args&gt;\nreference emplace_back_slow_path(Args... args){\n    // allocate more memory\n    size_type offset = size();\n    size_type new_size = m_size + 1;\n    size_type new_capacity = growth_factor * capacity();\n    auto ptr_new_blk = allocate_helper(new_capacity);\n\n    try{\n        // copy/move construct the existing elements \n        // of the container from the old storage \n        // to the new block of storage.\n        copy_old_storage_to_new(m_data, m_size, ptr_new_blk);\n    }catch(std::exception& ex){\n        deallocate_helper(ptr_new_blk);\n        throw ex;   // rethrow\n    }\n\n    std::construct_at(ptr_new_blk + m_size, std::forward&lt;Args&gt;(args)...);\n    deallocate_helper(m_data);\n    m_data = ptr_new_blk;\n    ++m_size;\n    return back();\n}\n\ntemplate&lt;typename... Args&gt;\nreference emplace_back_fast_path(Args... args){\n    std::construct_at(m_data + m_size, std::forward&lt;Args&gt;(args)...);\n    ++m_size;\n    return back();\n}\n\ntemplate&lt;typename... Args&gt;\nreference emplace_back(Args... args){\n    if(is_full())\n        return emplace_back_slow_path(std::forward&lt;Args&gt;(args)...);\n    else\n        return emplace_back_fast_path(std::forward&lt;Args&gt;(args)...);\n}\nCompiler Explorer"
  },
  {
    "objectID": "posts/implementing_vector/index.html#implementing-insertconst_iterator-position-const-t-value",
    "href": "posts/implementing_vector/index.html#implementing-insertconst_iterator-position-const-t-value",
    "title": "Implementing vector<T>",
    "section": "",
    "text": "The insert function inserts the given value into the vector before the specified position, possibly using move-semantics. Note that, this kind of operation could be expensive for a vector, and if it is frequently used, it can trigger reallocation. The user should consider using std::list.\ntemplate&lt;typename U&gt;\niterator insert_slow_path(const_iterator insert_it, U&& value){\n    // If a reallocation is triggered, all iterators are\n    // invalidated and additionally `value` would also become a\n    // dangling reference, if it refers to an existing element of\n    // the vector.\n    // TODO\n}\n\ntemplate&lt;typename U&gt;\niterator insert_fast_path(const_iterator position, U&& value){\n    auto pos_ = position;\n    if constexpr (std::is_nothrow_move_constructible_v&lt;T&gt;) {\n        std::uninitialized_move(end() - 1, end(), end());\n        std::move_backward(pos_, end(), end());\n        *pos_ = std::move(value);\n    } else {\n        std::uninitialized_copy(end() - 1, end(), end());\n        std::copy_backward(pos_, end(), end());\n        *pos_ = value;\n    }\n    ++m_size;\n    return pos_;\n}\n\ntemplate&lt;typename U&gt;\niterator insert(const_iterator position, U&& value)\n{\n    if(is_full())\n        return insert_slow_path(position, std::forward&lt;U&gt;(value));\n    else\n        return insert_fast_path(position, std::forward&lt;U&gt;(value));\n}"
  },
  {
    "objectID": "posts/how_libstdcxx_map_is_implemented/index.html",
    "href": "posts/how_libstdcxx_map_is_implemented/index.html",
    "title": "How libstdc++ std::unordered_map is implemented?",
    "section": "",
    "text": "We all love maps. A map is simply a data-structure that allows you to associate a key with some kind of value. They are fast and help to solve a large number of problems. Have you wondered what the internal implementation of a map looks like? In this post, I am going to explore the implementation details of unordered associative containers from the standard library(GCC’s libstdc++ implementation).\nCurrently there are four types of unordered associative containers:\n\nstd::unordered_map\nstd::unordered_set\nstd::unordered_multimap\nstd::unordered_multiset\n\nUsually, they are implemented on top of some kind of container. I am going to jump into the implementation of this HashTable container directly, because that’s where all the interesting stuff is hidden.\nI’ll focus on the key-value containers with a unique set of keys(std::unordered_map and std::unordered_set) which have mostly similar logic.\nGCC’s implementation can be found in the hashtable.h header. There are a lot of names with leading underscores. Not everyone is used to such code, but the standard library implementers have no choice, but to avoid collisions with user-defined names."
  },
  {
    "objectID": "posts/how_libstdcxx_map_is_implemented/index.html#nodes",
    "href": "posts/how_libstdcxx_map_is_implemented/index.html#nodes",
    "title": "How libstdc++ std::unordered_map is implemented?",
    "section": "Nodes",
    "text": "Nodes\nOne of the basic building blocks of the _Hashtable is a node. Each node is allocated from the heap and stores container data along with metadata information to maintain the hash table data-structure.\nThe node itself is a compound entity and contains several parts, some of them, optional. The design of the node structs brings to mind Russian dolls, because they are nested to each other.\n\n\n\n\nRussian dolls\n\n\n\nThe more complex node type(with more data) is inherited from the simpler node type(with a little bit less data). Let us walk through the components bottom up(from simpler to complex).\nFirst, _Hash_node_base is defined in the following way. It has only _M_nxt field, which is a pointer to the next node of the hash table.\nstruct _Hash_node_base\n{\n    _Hash_node_base* _M_nxt;\n\n    _Hash_node_base() noexcept : _M_nxt() { }\n\n    _Hash_node_base(_Hash_node_base* __next) noexcept : _M_nxt(__next) { }\n};\nThe next one _Hash_node_value_base is a little bit more interesting(see the actual code here). _Hash_node_value_base is responsible for storing the actual element value in the _M_storage member variable. It also provides accessor methods to retrieve the stored value.\ntemplate&lt;typename _Value&gt;\nstruct _Hash_node_value_base\n{\n    using value_type = _Value;\n\n    __gnu_cxx::__aligned_buffer&lt;_Value&gt; _M_storage;\n\n    // ...\n};\nIt is a templated class with _Value template parameter that represents the value_type. _Value type is wrapped into __gnu_cxx::__aligned_buffer (thin wrapper around std::aligned_storage) to decouple memory allocation from actual object creation.\nThe next struct is _Hash_node_code_cache and it implements hash value caching logic. When searching for a key in an unordered map, (i) we need to compute the hash-code of the search key, \\(h(k)\\), (ii) find the right bucket idx = h(k) % table_size and then (iii) walk the collision chain comparing each node’s key with you key \\(k\\). When keys are large or complex like std::string, using the equality predicate and doing full key comparisons for every node in the chain is expensive. So, we can choose the cach the hash code with each node:\ntemplate&lt;typename _Value, bool __cache&gt;\nstruct _Hash_node_code_cache {\n    size_t _M_hash_code;  // Stored hash value\n};\n\n// Specialization when caching is disabled\ntemplate&lt;typename _Value&gt;\nstruct _Hash_node_code_cache&lt;_Value, false&gt; {\n  // Empty - no overhead\n};\nThis way Empty Base Class Optimization(EBCO) can be leveraged, since _Hash_node_code_cache will be extended by inheritance. And that’s exactly what _Hash_node_value is doing:\ntemplate&lt;typename _Value, bool _Cache_hash_code&gt;\n  struct _Hash_node_value\n  : _Hash_node_value_base&lt;_Value&gt;\n  , _Hash_node_code_cache&lt;_Cache_hash_code&gt;\n  { };\nThe size of the _Hash_node_value will be the same as size of _Hash_node_value_base&lt;_Value&gt; in case template argument _Cache_hash_code is false as _Hash_node_code_cache will be an empty struct.\nThe final piece of the puzzle is the _Hash_node that combines everything above together:\n template&lt;typename _Value, bool _Cache_hash_code&gt;\nstruct _Hash_node\n: _Hash_node_base\n, _Hash_node_value&lt;_Value, _Cache_hash_code&gt;\n{\n    _Hash_node*\n    _M_next() const noexcept\n    { return static_cast&lt;_Hash_node*&gt;(this-&gt;_M_nxt); }\n};\nBelow is a picture of the _Hash_node struct data layout to better visualize what’s going on.\n+==============================================================+\n| _Hash_node&lt;Value&gt;                                            |\n+______________________________________________________________+\n| inherits from _Hash_node_base                                |\n+--------------------------------------------------------------+\n|       _Hash_node_base*          _M_nxt; // ptr to next node  |\n+______________________________________________________________+\n| inherits from _Hash_node_value                               |\n+--------------------------------------------------------------+\n|   inherits from _Hash_node_value_base                        |\n+--------------------------------------------------------------+\n|       aligned_buffer&lt;Value&gt;     _M_storage;    // The value  |\n+--------------------------------------------------------------+\n|   inherits from _Hash_node_code_cache                        |\n+--------------------------------------------------------------+\n|       size_t                    _M_hash_code;  // Cached hash|\n+______________________________________________________________+\nSummarizing, _Hash_node (directly or inherited from base structs) contains the following data.\n\n_Hash_node_base* _M_nxt is a pointer to the next element in the linked list of hash table elements.\n__gnu_cxx::__aligned_buffer&lt;_Value&gt; _M_storage — node data itself. For example for std::unordered_map&lt;std::string, int&gt; container _Value template argument is std::pair&lt;const std::string, int&gt;.\nstd::size_t _M_hash_code optional cached value of key’s hash."
  },
  {
    "objectID": "posts/how_libstdcxx_map_is_implemented/index.html#hash-table",
    "href": "posts/how_libstdcxx_map_is_implemented/index.html#hash-table",
    "title": "How libstdc++ std::unordered_map is implemented?",
    "section": "Hash table",
    "text": "Hash table\nThe _Hashtable class is defined in the following way:\nclass _Hashtable{\n    private:\n    _Hash_node_base**   _M_buckets          = &_M_single_bucket;\n    std::size_t         _M_bucket_count     = 1;\n    _Hash_node_base     _M_before_begin;\n    std::size_t         _M_element_count    = 0;\n    _RehashPolicy       _M_rehash_policy;\n\n    // ...\n    _Hash_node_base*     _M_single_bucket    = nullptr;\n};\nThe Hashtable class itself is a combination of std::forward_list&lt;_Hash_node&gt; - a linked list containing the elements belonging to a bucket and std::vector&lt;std::forward_list&lt;_Hash_node&gt;::iterator&gt; - a vector(array) of pointers representing the buckets.\n_Hash_node_base** _M_buckets is an array of pointers to hash table nodes. One can think of it as _Hash_node_base* _M_buckets[] instead of a pointer to a pointer.\n_Hash_node_base _M_before_begin is a special node without any user data. This node stores a pointer to the first hash table element (if there is any) in _M_before_begin._M_nxt.\nOne interesting thing is that _M_buckets contains _Hash_node_base* instead of _Hash_node*. The reason is because _M_buckets is kind of a storage for two types of objects: actual hash table nodes and a special before begin node _M_before_begin. This should be a lot more clear from the example:\nSuppose we have the following code and we create std::unordered_map and insert \\(4\\) keys in this order \\(14, 25, 36, 19\\).\nstd::unordered_map&lt;int, int&gt; map;\n\nmap[14] = 14;\nmap[25] = 25;\nmap[36] = 36;\nmap[19] = 19;\nThen, the internal _Hashtable linked list will like the one in the picture below. The key order in the hash table is a reverse insertion order, so the key’s iteration order will be \\(19\\), \\(36\\), \\(25\\), \\(14\\).\n\n\n\nInternal _Hashtable linked list\n\n\nLet’s make a real hash table from the linked list by adding buckets.\nThere are \\(11\\) buckets in the picture, only two buckets are not empty - buckets at index \\(3\\) and \\(8\\).\nThin arrows are pointers from the _Hashtable internal linked list from the previous picture, this time slightly rearranged and grouped by buckets. Each bucket stores a pointer to the node before the first node from the bucket.\n\n\n\nInternal _Hashtable linked list\n\n\nBucket index 3 has keys 36, 25 and 19, but a _Hash_node_base* from _M_buckets array points to the element with a key 19, which is a previous element in the hash table iteration order. Same logic is true for the bucket index 8. For this bucket, _M_buckets array has a pointer to the _M_before_begin_node."
  },
  {
    "objectID": "posts/implementing_lru_cache/index.html",
    "href": "posts/implementing_lru_cache/index.html",
    "title": "Implementing LRU Cache",
    "section": "",
    "text": "Introduction\nA least recently used(LRU) cache is a fixed-size cache that behaves just like a regular lookup table, but remembers the order in which the elements are accessed. Once it’s user defined capacity is reached it uses the information to replace the least recently used element with a new one. This is ideal for caching function return values, where fast lookup of complex computations is favorable, but a memory blowup from caching all (input, output) pairs is to be avoided. We will first write a basic implementation of LRUCache.\nWe will then add functionality to connect all our caches to statistics objects that keep track of cache hits and misses for all keys and upon request, individual keys (similar to functools.lrucache in Python). You can also register arbitrary callbacks for hits, misses and accesses in general.\n\nTask\n\nDesign a data structure that follows the constraints of a Least Recently Used (LRU) cache.\nImplement the LRUCache class:\n\nLRUCache(int capacity) Initialize the LRU cache with positive size capacity.\nint get(int key) Return the value of the key if the key exists, otherwise return -1.\nvoid put(int key, int value) Update the value of the key if the key exists. Otherwise, add the key-value pair to the cache. If the number of keys exceeds the capacity from this operation, evict the least recently used key.\n\nThe functions get and put must each run in \\(O(1)\\) average time complexity.\n\n\nBasic implementation\nWe will use a std::list to track the usage of the keys and a std::unordered_map to provide fast access to the key-value pair in the last.\n// Write your solution here\n// C++20 for C++\n#include &lt;gtest/gtest.h&gt;\n#include &lt;cstddef&gt;\n#include &lt;cstdint&gt;\n#include &lt;format&gt;\n#include &lt;print&gt;\n#include &lt;stdexcept&gt;\n#include &lt;utility&gt;\n#include &lt;unordered_map&gt;\n#include &lt;list&gt;\n#include &lt;tuple&gt;\n\nnamespace dev {\n    /**\n    * @brief: LRU (Least Recently Used) policy\n    */\n    template&lt;\n        typename Key, \n        typename Value, \n        typename Container=std::unordered_map&lt;Key,typename std::list&lt;std::pair&lt;Key,Value&gt;&gt;::iterator&gt;&gt;\n    class LRUCache{\n        using lru_list_iterator = std::list&lt;std::pair&lt;Key,Value&gt;&gt;::iterator;\n\n        private:\n        Container m_dict;\n        std::list&lt;std::pair&lt;Key, Value&gt;&gt; m_lru_list; \n        size_t m_capacity;\n\n        public:\n        // explicit single-parameter constructor\n        explicit LRUCache(size_t capacity)\n        : m_dict{}\n        , m_lru_list{}\n        , m_capacity{ capacity }\n        {}\n\n        void touch(lru_list_iterator it){\n            m_lru_list.splice(m_lru_list.begin(), m_lru_list, it);\n        }\n\n        std::optional&lt;Value&gt; get(Key key){\n            auto it = m_dict.find(key);\n            std::optional&lt;Value&gt; result;\n            if(it == m_dict.end()){\n                result = std::nullopt;\n            }else{\n                auto [k,value] = *((*it).second);\n                result = value;\n                touch(it-&gt;second);\n            }\n            return result;\n        }\n\n        void put(Key key, Value value){\n            auto it = m_dict.find(key);\n            if(it == m_dict.end())\n            {\n                if(m_lru_list.size() == m_capacity)\n                {\n                    //Evict the least recently used (k,v) pair\n                    auto [lru_key, lru_value] = m_lru_list.back();\n                    m_dict.erase(lru_key);\n                    m_lru_list.pop_back();\n                }\n                    \n                // Insert the key-value pair\n                m_lru_list.push_front(std::pair{key, value});\n                m_dict[key] = m_lru_list.begin();\n            }else{\n                // Update the key-value pair\n                m_dict[key]-&gt;second = value;\n            }\n        }\n    };\n}  // namespace dev\n\n#include &lt;array&gt;\n\nTEST(CacheTest, SimplePut)\n{\n    dev::LRUCache&lt;std::string, int&gt; cache(1);\n\n    cache.put(\"test\", 666);\n\n    EXPECT_EQ(cache.get(\"test\"), 666);\n}\n\nTEST(CacheTest, PutWithUpdate)\n{\n    constexpr std::size_t TEST_CASE = 4;\n    dev::LRUCache&lt;std::string, std::size_t&gt; cache{TEST_CASE};\n\n    for (size_t i = 0; i &lt; TEST_CASE; ++i)\n    {\n        cache.put(std::to_string(i), i);\n\n        const auto value = cache.get(std::to_string(i));\n        ASSERT_EQ(i, value);\n    }\n\n    for (size_t i {0uz}; i &lt; TEST_CASE; ++i)\n    {\n        ASSERT_TRUE(cache.get(std::to_string(i)));\n        cache.put(std::to_string(i), i * 10);\n\n        const auto value = cache.get(std::to_string(i));\n        ASSERT_EQ(i * 10, value);\n    }\n}\n\nTEST(CacheTest, KeepsAllValuesWithinCapacity)\n{\n    constexpr int CACHE_CAP = 50;\n    const int TEST_RECORDS = 100;\n    dev::LRUCache&lt;int, int&gt; cache(CACHE_CAP);\n\n    for (int i = 0; i &lt; TEST_RECORDS; ++i)\n    {\n        cache.put(i, i);\n    }\n\n    for (int i = 0; i &lt; TEST_RECORDS - CACHE_CAP; ++i)\n    {\n        EXPECT_EQ(cache.get(i), std::nullopt);\n    }\n\n    for (int i = TEST_RECORDS - CACHE_CAP; i &lt; TEST_RECORDS; ++i)\n    {\n        EXPECT_EQ(i, cache.get(i));\n    }\n}\n\nTEST(CacheTest, PutAndGet){\n    dev::LRUCache&lt;int, int&gt; lru_cache(2);\n    lru_cache.put(1, 1); // cache is {1=1}\n    lru_cache.put(2, 2); // cache is {2=2, 1=1}\n    EXPECT_EQ(lru_cache.get(1), 1);    // return 1, cache is {1=1, 2=2} \n    lru_cache.put(3, 3); // evicts key 2, cache is {3=3, 1=1}\n    EXPECT_EQ(lru_cache.get(2), std::nullopt);    // returns std::nullopt (not found)\n    lru_cache.put(4, 4); // LRU key was 1, evicts key 1, cache is {4=4, 3=3}\n    EXPECT_EQ(lru_cache.get(1), std::nullopt);    // return std::nullopt (not found)\n    EXPECT_EQ(lru_cache.get(3), 3);    // return 3, cache is {3=3, 4=4}\n    EXPECT_EQ(lru_cache.get(4), 4);    // return 4, cache is {4=4, 3=3}\n}\n\nint main(int argc, char** argv) {\n    ::testing::InitGoogleTest(&argc, argv);\n    return RUN_ALL_TESTS();\n}\nCompiler Explorer"
  },
  {
    "objectID": "posts/implementing_string/index.html",
    "href": "posts/implementing_string/index.html",
    "title": "Implementing string",
    "section": "",
    "text": "Implementing a basic string class\n// Write your solution here\n// C++20 for C++\n#include &lt;gtest/gtest.h&gt;\n#include &lt;cstddef&gt;\n#include &lt;cstdint&gt;\n#include &lt;format&gt;\n#include &lt;print&gt;\n#include &lt;iostream&gt;\n#include &lt;stdexcept&gt;\n#include &lt;utility&gt;\n#include &lt;unordered_map&gt;\n#include &lt;list&gt;\n#include &lt;tuple&gt;\n#include &lt;bit&gt;\n#include &lt;bitset&gt;\n\nnamespace dev {\n    /**\n    * @brief: A string class\n    * The capacity is usually a power of 2, so the \n    * least significant bit of the m_capacity field\n    * is set to 0, to indicate string_long format. And\n    * if set to 1, it implies SSO. \n    */\n    template&lt;typename CharType&gt;\n    struct string_long{\n        using value_type = CharType;\n        using pointer = CharType*;\n        using reference = CharType&;\n\n        CharType*   m_buffer_ptr;     // 8 bytes\n        std::size_t m_size;     // 8 bytes\n        std::size_t m_capacity; // 8 bytes\n    };\n\n    template&lt;typename CharType&gt;\n    struct string_short{\n        using value_type = CharType;\n        using pointer = CharType*;\n        using reference = CharType&;\n        \n        static constexpr size_t m_capacity{23uz};\n\n        value_type  m_buffer[m_capacity]; // 23 bytes\n        unsigned char m_size;   // 1 byte\n    };\n\n    enum{ string_short_mask = 0x01 };\n    enum{ string_long_mask = 1uz };\n\n    template&lt;typename CharType=char&gt;\n    class string{\n        using value_type = CharType;\n        using pointer = CharType*;\n        using const_pointer = const CharType*;\n        using reference = CharType&;\n        using const_reference = const CharType&;\n        using size_type = std::size_t;\n\n        union {\n            string_long&lt;CharType&gt; l;\n            string_short&lt;CharType&gt; s;\n        } m_data;\n\n        public:\n\n        bool is_small() const{\n            return (m_data.s.m_size & string_short_mask);\n        }\n\n        bool is_long() const{\n            return !is_small();\n        }\n\n        pointer get_buffer(){\n            return is_long() ? m_data.l.m_buffer_ptr : m_data.s.m_buffer;\n        }\n\n        const_pointer get_buffer() const{\n            return is_long() ? m_data.l.m_buffer_ptr : m_data.s.m_buffer;\n        }        \n\n        void set_short_size(size_type size){\n            m_data.s.m_size = (size &lt;&lt; 1) | string_short_mask;\n            //std::println(\"m_data.s.m_size = {}\", m_data.s.m_size);\n        }\n\n        size_type get_short_size() const{\n            //std::println(\"get_short_size()\");\n            //std::println(\"m_data.s.m_size &gt;&gt; 1 = {}\", m_data.s.m_size &gt;&gt; 1);\n            return m_data.s.m_size &gt;&gt; 1;\n        }\n\n        size_type get_long_size() const{\n            //std::println(\"get_long_size()\");\n            return m_data.l.m_size;\n        }\n\n        void set_long_size(size_type size){\n            m_data.l.m_size = size;\n        }\n\n        size_type get_long_capacity() const{\n            return m_data.l.m_capacity & size_type(~(string_long_mask));\n        }\n\n        void set_long_capacity(size_t capacity){\n            m_data.l.m_capacity = capacity & ~(string_long_mask);\n        }\n\n        size_type get_short_capacity() const{\n            return 23;\n        }\n\n        size_t size() const{\n            return is_long() ? get_long_size() : get_short_size();\n        }\n\n        size_t capacity() const{\n            return is_long() ? get_long_capacity() : get_short_capacity();\n        }\n\n        pointer allocate_helper(size_t new_capacity){\n            return static_cast&lt;CharType*&gt;(operator new(new_capacity));\n        }\n\n        void deallocate_helper(pointer ptr)\n        {\n            operator delete(ptr);\n        }\n\n        string()\n        {\n            // Initialize as short string (empty)\n            m_data.s.m_buffer[0] = '\\0';\n            set_short_size(0);  // This sets bit 0 to mark as short\n        }\n\n        void construct_fast_path(const_pointer chars_array, size_t len){\n            for(auto i{0uz}; i &lt; len; ++i)\n                    m_data.s.m_buffer[i] = chars_array[i];\n\n            m_data.s.m_buffer[len] = '\\0';\n            set_short_size(len);\n        }\n\n        void construct_slow_path(const_pointer chars_array, size_t len){\n            size_t capacity = std::bit_ceil(len + 1); // +1 for '\\0'\n            m_data.l.m_buffer_ptr = allocate_helper(capacity);\n\n            for(auto i{0uz}; i&lt;len; ++i) \n            {\n                m_data.l.m_buffer_ptr[i] = chars_array[i];\n            }\n            m_data.l.m_buffer_ptr[len] = '\\0';\n            set_long_size(len);\n            set_long_capacity(capacity);\n        }\n\n        // constructors\n        string(const_pointer chars_array)\n        {\n            size_t len = strlen(chars_array);\n            if(len == 0)\n            {\n                m_data.s.m_buffer[0] = '\\0';\n                set_short_size(0);  // This sets bit 0 to mark as short\n                return;\n            }\n            if(len &lt; 23){\n                construct_fast_path(chars_array, len);\n            }\n            else{\n                construct_slow_path(chars_array, len);\n            }\n        }\n\n        //copy constructor\n        string(const dev::string&lt;CharType&gt;& other){\n            size_t len = other.size();\n            if(len == 0)\n            {\n                m_data.s.m_buffer[0] = '\\0';\n                set_short_size(0);  // This sets bit 0 to mark as short\n                return;\n            }\n\n            const_pointer other_ptr = other.get_buffer();\n            if(len &gt; 0 && len &lt; 23)\n                construct_fast_path(other_ptr, len);\n            else\n                construct_slow_path(other_ptr, len);\n        }\n\n        // move constructor\n        string(string&& other){\n            if(other.is_small()) // other is short string format\n            {\n                // copy the buffer \n                std::uninitialized_copy(\n                    other.m_data.s.m_buffer, \n                    other.m_data.s.m_buffer+other.size(),\n                    m_data.s.m_buffer\n                );\n\n                // zero out other's buffer\n                std::fill_n(\n                    other.m_data.s.m_buffer,\n                    other.size(),\n                    0\n                );\n\n                m_data.s.m_buffer[other.size()] = '\\0';\n                set_short_size(other.size());\n                other.set_short_size(0);\n            }\n            else{ //other is long string format\n                m_data.l.m_buffer_ptr = std::exchange(other.m_data.l.m_buffer_ptr, nullptr);\n                set_long_size(other.get_long_size());\n                set_long_capacity(other.get_long_capacity());\n                other.set_long_capacity(0);\n            }\n        }\n\n        // swap\n        void swap(dev::string&lt;CharType&gt;& other){\n            std::swap(m_data, other.m_data);\n        }\n\n        // copy assignment\n        string& operator=(const string& other)\n        {\n            string(other).swap(*this);\n            return *this;\n        }\n\n        // move assignment\n        string& operator=(string&& other){\n            string(std::move(other)).swap(*this);\n            return *this;\n        }\n\n        CharType& operator[](size_t index){\n            pointer buffer = get_buffer();\n            return buffer[index];\n        }\n\n        const_reference at(size_t index) const{\n            if(index &lt; 0 || index &gt;= size())\n                throw std::out_of_range(\"Index out of bounds!\");\n\n            const_pointer buffer = get_buffer();\n            return buffer[index];\n        }\n\n        bool operator==(const dev::string&lt;CharType&gt;& other) const{\n            if(size() != other.size())\n                return false;\n\n            for(auto i{0uz}; i &lt; size(); ++i)\n            {\n                if(at(i) != other.at(i))\n                    return false;\n            }\n            return true;\n        }\n\n        bool operator==(const_pointer other) const{\n            size_t other_len = strlen(other);\n            size_t my_len = size();\n\n            if(my_len != other_len)\n                return false;\n\n            if(my_len != 0)\n            {\n                for(auto i{0uz}; i &lt; my_len; ++i){\n                    if(at(i) != other[i])\n                        return false;\n                }\n            }\n            return true;\n        }\n\n        size_t empty() const{\n            return size() == 0;\n        }\n\n        // Append a character to the end\n        void push_back(CharType ch){\n            if(is_small())\n            {\n                \n            }\n        }\n\n        ~string() {\n            if (is_long()) {\n                operator delete(m_data.l.m_buffer_ptr);\n                m_data.l.m_buffer_ptr = nullptr;\n            }\n        }\n\n        CharType front(){\n            return at(0);\n        }\n\n        CharType back(){\n            return at(size() - 1);\n        }\n    };\n\n}  // namespace dev\n\nTEST(StringTest, DefaultCtorTest){\n    dev::string s1;\n    EXPECT_EQ(s1.size(), 0);\n    EXPECT_EQ(s1, \"\");\n\n    dev::string s2{};\n    EXPECT_EQ(s2.size(), 0);\n    EXPECT_EQ(s2, \"\");  \n}\n\nTEST(StringTest, CtorStringStackAllocationTest){\n    dev::string s1(\"Hello\");\n    EXPECT_EQ(s1.size(), 5);\n    EXPECT_EQ(s1, \"Hello\");\n\n    const char chars_array[] = \"World\";\n    dev::string s2(chars_array);\n    EXPECT_EQ(s2.size(), 5);\n    EXPECT_EQ(s2, \"World\");\n}\n\nTEST(StringTest, CtorStringHeapAllocationTest){\n    dev::string s1(\"C++ is a general-purpose and multi-paradigm programming language!\");\n    EXPECT_EQ(s1.size(), 65);\n    EXPECT_EQ(s1, \"C++ is a general-purpose and multi-paradigm programming language!\");\n}\n\nTEST(StringTest, CopyConstructSmallStringTest){\n    dev::string s1(\"Hello\");\n    dev::string s2(s1);\n    EXPECT_EQ(s1, \"Hello\");\n    EXPECT_EQ(s2.size(), 5);\n    for(auto i{0uz}; i&lt;s1.size(); ++i)\n        EXPECT_EQ(s2[i], s1[i]);\n}\n\nTEST(StringTest, CopyConstructLongStringTest){\n    dev::string s1(\"C++ is a general-purpose and multi-paradigm programming language!\");\n    dev::string s2(s1);\n    EXPECT_EQ(s1.size(), 65);\n    EXPECT_EQ(s2.size(), s1.size());\n    for(auto i{0uz}; i&lt;s1.size(); ++i)\n        EXPECT_EQ(s2[i], s1[i]);\n}\n\nTEST(StringTest, EmptyTest){\n    dev::string s1{};\n    EXPECT_EQ(s1.empty(), true);\n\n    dev::string s2(\"\");\n    EXPECT_EQ(s2.size(), 0);\n    EXPECT_EQ(s2.empty(), true);\n\n    dev::string s3;\n    EXPECT_EQ(s3.size(), 0);\n    EXPECT_EQ(s3.empty(), true);\n\n    dev::string s4{\"\"};\n    EXPECT_EQ(s4.size(), 0);\n    EXPECT_EQ(s4.empty(), true);\n}\n\nTEST(StringTest, SwapTest){\n    dev::string s1{\"Hello\"};\n    dev::string s2{\"World!\"};\n    s1.swap(s2);\n    EXPECT_EQ(s2, \"Hello\");\n    EXPECT_EQ(s2.size(), 5);\n    EXPECT_EQ(s1, \"World!\");\n    EXPECT_EQ(s1.size(), 6);\n}\n\nTEST(StringTest, MoveConstructorTest){\n    dev::string s1{dev::string{\"Hello\"}};\n    EXPECT_EQ(s1, \"Hello\");\n    EXPECT_EQ(s1.size(), 5);\n\n    dev::string s2{\"World!\"};\n    dev::string s3{std::move(s2)};\n    EXPECT_EQ(s3, \"World!\");\n    EXPECT_EQ(s3.size(), 6);\n    EXPECT_EQ(s2, \"\");\n    EXPECT_EQ(s2.size(), 0);\n}\n\nTEST(StringTest, CopyAssignmentTest)\n{\n    dev::string s1;\n    dev::string s2{\"Hello\"};\n    s1 = s2;\n    EXPECT_EQ(s2, \"Hello\");\n    EXPECT_EQ(s1, s2);\n\n    dev::string s3{\"Ouroboros\"};\n    s1 = s3;\n    EXPECT_EQ(s3, \"Ouroboros\");\n    EXPECT_EQ(s1, s3);\n    EXPECT_NE(s1, s2);\n}\n\nTEST(StringTest, MoveAssignmentTest){\n    dev::string s1{\"GNU is not Unix!\"};\n    s1 = dev::string{\"WINE is not an emulator!\"};\n    EXPECT_EQ(s1, \"WINE is not an emulator!\");\n    EXPECT_EQ(s1.size(), strlen(\"WINE is not an emulator!\"));\n\n    dev::string s2{\"pip installs packages\"};\n    size_t expected_len = s2.size();\n    s1 = std::move(s2);\n    EXPECT_EQ(s1, \"pip installs packages\");\n    EXPECT_EQ(s1.size(), expected_len);\n    EXPECT_EQ(s2, \"\");\n    EXPECT_EQ(s2.size(), 0);\n\n    // a moved from string can be moved to again\n    s2 = dev::string{\"Emacs makes a computer sing\"};\n    EXPECT_EQ(s2, \"Emacs makes a computer sing\");\n}\n\nTEST(StringTest, FrontTest)\n{\n    dev::string s{\"Small string optimization(SSO) is awesome!\"};\n    EXPECT_EQ(s.front(), 'S');\n}\n\nTEST(StringTest, BackTest)\n{\n    dev::string s{\"Small string optimization(SSO) is awesome!\"};\n    EXPECT_EQ(s.back(), '!');\n}\n\nTEST(StringTest, PushBackTest){\n    dev::string s{\"Brownian motion\"};\n\n}\n\nint main(int argc, char** argv) {\n    ::testing::InitGoogleTest(&argc, argv);\n    return RUN_ALL_TESTS();\n}\nCompiler Explorer"
  },
  {
    "objectID": "posts/type-erasure/index.html#step-1---how-to-write-a-container-that-holds-unrelated-types",
    "href": "posts/type-erasure/index.html#step-1---how-to-write-a-container-that-holds-unrelated-types",
    "title": "C++ Type erasure",
    "section": "Step 1 - How to write a container that holds unrelated types?",
    "text": "Step 1 - How to write a container that holds unrelated types?\nOn cppreference.com, std::function is defined as follows:\n\n\n\n\n\n\ntemplate&lt; class R, class... Args &gt;\nclass function&lt;R(Args...)&gt;;\nThe class template std::function is a general-purpose polymorphic function wrapper.\n\n\n\nstd::function has to be polymorphic, meaning it has to be able to hold completely unrelated types. They don’t have to be bound by an inheritance-hierarchy or any other sort of thing.\nOur end-goal looks something like this:\nstruct MagicFunctionContainer\n{};\n\nMagicFunctionContainer f1 = print_num;\nMagicFunctionContainer f2 = [](int i){ std::println({}, i); };\nMagicFunctionContainer f3 = PrintFunctor{};\nWe should be able to assign different objects of types like a free-standing function, a lambda expression or a functor to this MagicFunctionContainer.\nLet’s start with designing a container, which is constructible from completely unrelated types:\nstruct MagicFunctionContainer{\n    template&lt;typename Func&gt;\n    MagicFunctionContainer(Func&& func)\n    : m_func{std::forward&lt;Func&gt;(func)} \n    {}\n\n    void operator()(int i){\n        m_func(i);\n    }\n\n    private:\n    //void(*)(int) m_func;   // we need to think\n                             // of m_func's type\n};\nWe see that, there’s this container called MagicFunctionContainer. The most important thing to note is that, its constructor is now a templated constructor, so you can pass any type into the MaginFunctionContainer constructor, and it simply forwards the object func into m_func. We need to think, what the type of m_func is. We see that this function container also implements a function call operator operator(), which accepts an integer and returns type void. So, when this function container object is invoked with an integer i, it simply calls m_func(i) under the hood.\nAs long as we have defined the type of m_func, and its the correct type, this code satisfies our requirements. We now have a container, that can be constructed from completely unrelated types. How do we store these unrelated types? How do we now define what the type of m_func should be? The answer to this puzzle is step-2 of our design."
  },
  {
    "objectID": "posts/type-erasure/index.html#step-2---can-m_func-be-a-polymorphic-pointer-to-a-place-on-the-heap-that-will-hold-these-unrelated-types",
    "href": "posts/type-erasure/index.html#step-2---can-m_func-be-a-polymorphic-pointer-to-a-place-on-the-heap-that-will-hold-these-unrelated-types",
    "title": "C++ Type erasure",
    "section": "Step 2 - Can m_func be a polymorphic pointer to a place on the heap that will hold these unrelated types?",
    "text": "Step 2 - Can m_func be a polymorphic pointer to a place on the heap that will hold these unrelated types?\nThe classic type erasure pattern can be realized by first coding up a type-agnostic interface (a Concept class). Then we use an Impl class that wraps up the concrete type & provides the type-dependent implementation. Finally, we use dynamic polymorphism via virtual functions, but the caller only sees the interface.\n// Type erasure 101\n#include &lt;iostream&gt;\n#include &lt;memory&gt;\n\nnamespace dev{\n    struct Concept{\n        virtual void operator()(int i) = 0;\n        ~virtual Concept(){}\n    };\n\n    template&lt;typename Callable&gt;\n    struct Impl{\n\n        Impl(const Callable& callable) \n        : m_callable{callable}\n        {}\n\n        void operator()(int i){\n            m_callable(i);\n        }\n        \n        Callable m_callable;\n    };\n};\nEach time I get any new type Callable, I am creating an implementation Impl&lt;Callable&gt;, and passing that object into this new type.\nAny type Callable that implements operator()(int) can be stored in Impl&lt;Callable&gt;. And Impl&lt;Callable&gt; inherits from Concept.\nNow, what we’ve achieved so far is, that any Impl&lt;Callable&gt; object, as long as Callable implements the function call operator operator(), accepts an int, returns void can be assigned to a pointer to Concept, Concept*. Remember, all types Impl&lt;Callable_1&gt;, Impl&lt;Callable_2&gt;, …, Impl&lt;Callable_n&gt; inherit from Concept.\nWe can now finish the revisit the definition of MagicFunctionContainer.\nstruct MagicFunctionContainer{\n    template&lt;typename Func&gt;\n    MagicFunctionContainer(Func&& func)\n    : m_func{new Impl&lt;Func&gt;(func)} \n    {}\n\n    void operator()(int i){\n        if(m_func == nullptr)\n            throw std::bad_function_call();\n\n        (*m_func)(i);\n    }\n\n    private:\n    Concept* m_func{nullptr};   \n};\nIn the MagicFunctionContainer, I have still got the templated constructor. I have still got the function call operator. But, now I have type for m_func. m_func is a pointer to Concept. In the templated constructor, now what I’m doing is, each time I get any type Func, I am passing that object into this new type Impl&lt;Func&gt;. So, essentially a Concept* pointer is always pointing to an Impl&lt;Func&gt;.\nAs a result what happens is, although the MagicFunctionContainer is not templated itself, its constructor is templated and it’s m_func member variable is able to store different unrelated types."
  },
  {
    "objectID": "posts/type-erasure/index.html#refining-our-design-for-stdfunction",
    "href": "posts/type-erasure/index.html#refining-our-design-for-stdfunction",
    "title": "C++ Type erasure",
    "section": "Refining our design for std::function",
    "text": "Refining our design for std::function"
  },
  {
    "objectID": "posts/type-erasure/index.html#polishing-our-design-for-stdfunction-like-container",
    "href": "posts/type-erasure/index.html#polishing-our-design-for-stdfunction-like-container",
    "title": "C++ Type erasure",
    "section": "Polishing our design for std::function like container",
    "text": "Polishing our design for std::function like container\nWe can add some template magic and use concepts to constrain our template type parameter Func.\n#include &lt;print&gt;\n#include &lt;functional&gt;\n#include &lt;memory&gt;\n#include &lt;concepts&gt;\n\nnamespace dev{\n    template&lt;typename R, typename... Args&gt;\n    struct Concept{\n        virtual R operator()(Args... args) = 0;\n        virtual ~Concept(){}\n    };\n\n    template&lt;typename Func, typename R, typename... Args&gt;\n    struct Impl : Concept&lt;R, Args...&gt;{\n        Impl(Func func)\n        : m_func{ func }\n        {}\n\n        R operator()(Args... args) override{\n            return m_func(args...);\n        }\n\n        Func m_func;\n    };\n\n    template&lt;typename R, typename... Args&gt;\n    class function{\n        public:\n        template&lt;typename Func&gt;\n        requires std::invocable&lt;Func, Args...&gt;\n        function(Func func) \n        : m_func{ std::make_unique&lt;Impl&lt;Func,R,Args...&gt;&gt;(func)}\n        {}\n\n        R operator()(Args... args){\n            return (*m_func)(args...);\n        }\n\n        private:\n        std::unique_ptr&lt;Concept&lt;R, Args...&gt;&gt; m_func;\n    };\n}\n\n\nvoid print_num(int i){\n    std::println(\"{}\", i);\n}\n\nauto display_lambda = [](int i){\n    std::println(\"{}\", i);\n};\n\nstruct PrintFunctor{\n    void operator()(int i){\n        std::println(\"{}\", i);\n    }\n};\n\nint main()\n{\n    dev::function&lt;void, int&gt; f_print_num = print_num;\n    dev::function&lt;void, int&gt; f_display_lambda = display_lambda;\n    dev::function&lt;void, int&gt; f_print_functor = PrintFunctor{};\n\n    f_print_num(42);\n    f_display_lambda(5);\n    f_print_functor(17);\n    return 0;\n}\nCompiler Explorer"
  },
  {
    "objectID": "posts/type-erasure/index.html#step-1---code-up-a-container-that-can-hold-unrelated-different-types",
    "href": "posts/type-erasure/index.html#step-1---code-up-a-container-that-can-hold-unrelated-different-types",
    "title": "C++ Type erasure",
    "section": "Step 1 - Code up a container that can hold unrelated different types",
    "text": "Step 1 - Code up a container that can hold unrelated different types\nWe start with thinking about our shared_ptr class. So, we write a templated constructor shared_ptr(Y* ptr). You should be used to this by now - I can pass in any object to this. I later constrain this using the std::is_convertible_v&lt;Y*, T*&gt; type trait, to enforce that Y* is indeed convertible to T*.\nWe have another constructor that takes two parameters : a pointer to Y and a custom deleter.\nNow, the pointer to Y, Y* is convertible to pointer to T, T*. So, the pointer(address) itself is simply stored in the class as a T* member variable. So, I have a member variable T* m_underlying_ptr at the bottom. The question is how do we store the original object type Y* and the deleter type Deleter. As soon as I assign Y* ptr to T* m_underlying_ptr, I have lost information about the original object type Y*. How do we store the deleter and the true object type Y?\n#include &lt;iostream&gt;\n\ntemplate&lt;typename T&gt;\nclass shared_ptr{\n    public:\n\n    template&lt;typename Y&gt;\n    requires std::is_convertible_v&lt;Y*, T*&gt;\n    shared_ptr(Y* ptr)\n    : shared_ptr(ptr, std::default_delete&lt;Y&gt;{})\n    {}\n\n    // Templated constructor\n    template&lt;typename Y, typename Deleter&gt;\n    shared_ptr(Y* ptr, Deleter deleter)\n    : m_underlying_ptr{ptr}\n    // ???  \n    {}\n\n    // Destructor\n    ~shared_ptr(){\n        // Decrement the ref-count. If m_ref_count == 0, \n        // delete m_underlying_ptr using deleter \n    }\n\n    // Pointer like functions\n    const T* operator-&gt;() const{\n        return m_underlying_ptr;\n    }\n\n    private:\n    T* m_underlying_ptr;\n};"
  },
  {
    "objectID": "posts/type-erasure/index.html#step-2---coding-up-a-type-agnostic-interface-and-a-type-dependent-implementation",
    "href": "posts/type-erasure/index.html#step-2---coding-up-a-type-agnostic-interface-and-a-type-dependent-implementation",
    "title": "C++ Type erasure",
    "section": "Step 2 - Coding up a type-agnostic interface and a type-dependent implementation",
    "text": "Step 2 - Coding up a type-agnostic interface and a type-dependent implementation\nLet’s now write a Concept and Impl class that supports destruction using an instance of the custom Impl&lt;ObjType, Deleter&gt; type. We can actually define a ControlBlockBase and ControlBlockImpl&lt;ObjType, Deleter&gt; classes.\nnamespace dev {\n    // Type-agnostic Concept class\n    struct ControlBlockBase{\n        std::atomic&lt;std::size_t&gt; m_ref_count{1uz};\n        virtual ~ControlBlockBase() = default;\n    };\n\n    // Type dependent Impl&lt;ObjType,Deleter&gt; implementation\n    template&lt;typename ObjType, typename Deleter&gt;\n    struct ControlBlock : ControlBlockBase{\n        ControlBlock( ObjType* object_ptr, Deleter deleter)\n        : m_object_ptr{ object_ptr }\n        , m_deleter{ deleter }\n        {}\n\n        ~ControlBlock()\n        {\n            m_deleter(m_object_ptr);\n        }\n\n        private:\n        ObjType* m_object_ptr;\n        Deleter m_deleter;\n    };\n}  // namespace dev\nThe ControlBlock inherits from ControlBlockBase and it is templated. Concept itself is not templated, but the implementation control_block class is. In this case, it is templated on the ObjectType and the Deleter type. The constructor control_block(ObjectType*, Deleter) takes two parameters - the object type and the deleter. ObjectType is not the type parameter of the shared_ptr, which is T, but the type of the object passed to the shared_ptr() during construction.\nOn destruction of the control block, it calls the deleter on a pointer to ObjType - the correct type. It’s not going to call the deleter on the template type. We can now, finish up with our definition of the shared_ptr.\n#include &lt;iostream&gt;\n\ntemplate&lt;typename T&gt;\nclass shared_ptr{\n    public:\n\n    template&lt;typename Y&gt;\n    requires std::is_convertible_v&lt;Y*, T*&gt;\n    shared_ptr(Y* ptr)\n    : shared_ptr(ptr, std::default_delete&lt;Y&gt;{})\n    {}\n\n    // Templated constructor\n    template&lt;typename Y, typename Deleter&gt;\n    shared_ptr(Y* ptr, Deleter deleter)\n    : m_underlying_ptr{ptr}\n    , m_control_block_ptr{ new ControlBlock&lt;Y,Deleter&gt;(deleter) }\n    {}\n\n    // Destructor\n    ~shared_ptr(){\n        // Decrement the ref-count. If m_ref_count == 0, \n        // delete the control_block_ptr which will destroy the managed object \n        delete m_control_block_ptr;\n    }\n\n    // Pointer like functions\n    const T* operator-&gt;() const{\n        return m_underlying_ptr;\n    }\n\n    private:\n    T* m_underlying_ptr;\n    ControlBlockBase* m_control_block_ptr;  // Concept* pointer\n};\nObserve that, as long as the two shared_ptr types share the same signature, they can be assigned to each other and the destruction is going to be correct.\n#include &lt;memory&gt;\n\nstruct Foo{};\nstruct Bar{};\nint main()\n{\n    std::shared_ptr&lt;void&gt; ptr1{ new Foo() };\n    std::shared_ptr&lt;void&gt; ptr2{ new Bar() };\n    ptr1 = ptr2;\n}\nCompiler Explorer\nI was explaining earlier why a shared_ptr&lt;void&gt; is allowed whereas a unique_ptr&lt;void&gt; won’t compile.\nYou can see that, what the shared_ptr design does is, in the single parameter constructor, when you don’t pass a deleter, it uses a default deleter of the actual object type. It retains the information of the actual object type. It does not use a default deleter of template type parameter T.\n#include &lt;iostream&gt;\n\ntemplate&lt;typename T&gt;\nclass shared_ptr{\n    public:\n\n    template&lt;typename Y&gt;\n    requires std::is_convertible_v&lt;Y*, T*&gt;\n    shared_ptr(Y* ptr)\n    : shared_ptr(ptr, std::default_delete&lt;Y&gt;{}) // default deleter of ObjType\n    {}\n\n    // Templated constructor\n    template&lt;typename Y, typename Deleter&gt;\n    shared_ptr(Y* ptr, Deleter deleter)\n    : m_underlying_ptr{ptr}\n    , m_control_block_ptr{ new ControlBlock&lt;Y,Deleter&gt;(deleter) }\n    {}\n\n    // ...\n\n    private:\n    T* m_underlying_ptr;\n    ControlBlockBase* m_control_block_ptr;  // Concept* pointer\n};"
  },
  {
    "objectID": "posts/implementing_shared_ptr/index.html",
    "href": "posts/implementing_shared_ptr/index.html",
    "title": "Implementing shared_ptr<T>",
    "section": "",
    "text": "Introduction\nA shared_ptr&lt;T&gt; is a smart pointer that model shared co-ownership of the resource semantics. Many shared_ptr&lt;T&gt; objects work together to jointly own a T object in memory. The object will be automatically be destroyed and its memory freed when the last `shared_ptr goes out of scope.\nIf there are \\(100\\) shared pointers to the same object, and if \\(99\\) of those pointers go out of scope, the object will still be in memory. When the last shared pointer, the last owner of the resource goes out of scope, the object is destoyed and memory deallocated.\nTo keep track of how many shared pointers are currently referencing an object, shared_ptr&lt;T&gt; class stores some meta-data. The meta-data consists of a reference counter amongst other things.\nWhen you first construct a shared pointer to an object obj, the reference count is initialized to \\(1\\).\nstruct X{};\nstd::shared_ptr&lt;X&gt; sptr1 { new X() };   // ref-count = 1\nJust as you can have more than \\(1\\) raw pointers to the same object, you can have more than \\(1\\) shared pointers to the same object by copying sptr1. The shared_ptr copy constructor is designed to increment the reference counter. The shared_ptr destructor is designed to decrement the reference counter.\nstruct X{};\nint main()\n{\n    std::shared_ptr&lt;X&gt; sptr1 { new X() };   // ref-count = 1\n    {\n        std::shared_ptr&lt;X&gt; sptr2{ sptr1 };  // ref-count = 2\n        {\n            std::shared_ptr&lt;X&gt; sptr3{ sptr2 }; // ref-count = 3\n        }// ref-count = 2\n    }// ref-count = 1\n} // ref-count = 0, ~X() called\nUnlike unique_ptr&lt;T&gt;, shared_ptr&lt;T&gt; objects are copyable.\n\n\nMinimalistic shared_ptr implementation\nWriting a homegrown version of shared_ptr&lt;T&gt; implementation is fun! You could have multiple handles (pointers) to the same shared resource(object). So, a shared_ptr object needs to track the reference count. The tracking is done through a control block. The control block holds meta-information. Since multiple shared_ptr share the same control block, the shared_ptr implementation only stores a pointer to the control block.\n// Write your solution here\n// C++20 for C++\n#include &lt;gtest/gtest.h&gt;\n#include &lt;cstddef&gt;\n#include &lt;cstdint&gt;\n#include &lt;format&gt;\n#include &lt;initializer_list&gt;\n#include &lt;memory&gt;\n#include &lt;print&gt;\n#include &lt;stdexcept&gt;\n#include &lt;type_traits&gt;\n#include &lt;utility&gt;\n#include &lt;atomic&gt;\n\nnamespace dev {\n    // Type-agnostic Concept class\n    struct ControlBlockBase{\n        std::atomic&lt;std::size_t&gt; m_ref_count{1uz};\n        virtual ~ControlBlockBase() = default;\n    };\n\n    // Type dependent Impl&lt;ObjType,Deleter&gt; implementation\n    template&lt;typename ObjType, typename Deleter&gt;\n    struct ControlBlock : ControlBlockBase{\n        ControlBlock( ObjType* object_ptr, Deleter deleter)\n        : m_object_ptr{ object_ptr }\n        , m_deleter{ deleter }\n        {}\n\n        ~ControlBlock()\n        {\n            m_deleter(m_object_ptr);\n        }\n\n        ObjType* m_object_ptr;\n        Deleter m_deleter;\n    };\n\n    template&lt;typename ObjType&gt;\n    struct ControlBlockWithStorage : ControlBlockBase{\n        ObjType m_object;\n\n        template&lt;typename... Args&gt;\n        ControlBlockWithStorage(Args&&... args) \n        : m_object{ ObjType(std::forward&lt;Args&gt;(args)...)}\n        {}\n\n        ~ControlBlockWithStorage() {} \n    };\n\n    template&lt;typename T&gt;\n    class shared_ptr{\n        private:\n        ControlBlockBase* m_control_block_ptr;\n        T* m_raw_underlying_ptr;\n\n        using pointer = T*;\n        using const_pointer = const T*;\n\n        public:\n        // Templated constructor\n        template&lt;typename Y, typename Deleter&gt;\n        shared_ptr(Y* ptr, Deleter deleter)\n        {\n            if(ptr)\n            {\n                m_control_block_ptr = new ControlBlock&lt;Y,Deleter&gt;(ptr, deleter);\n                m_raw_underlying_ptr = ptr;\n            }\n            else{\n                m_control_block_ptr = nullptr;\n                m_raw_underlying_ptr = nullptr;\n            }\n        }     \n\n        template&lt;typename Y&gt;\n        requires std::is_convertible_v&lt;Y*, T*&gt;\n        explicit shared_ptr(Y* ptr)\n        : shared_ptr(ptr, std::default_delete&lt;Y&gt;{})\n        {}\n\n        explicit shared_ptr(T* ptr)\n        : shared_ptr&lt;T&gt;(ptr, std::default_delete&lt;T&gt;{})\n        {}\n\n        explicit shared_ptr(std::nullptr_t)\n        : m_control_block_ptr{ nullptr }\n        , m_raw_underlying_ptr{ nullptr }\n        {}\n\n        // default constructor\n        shared_ptr()\n        : m_raw_underlying_ptr{ nullptr }\n        , m_control_block_ptr{ nullptr }\n        {}\n\n        // copy constructor\n        shared_ptr(const shared_ptr&lt;T&gt;& other)\n        : m_raw_underlying_ptr{ other.m_raw_underlying_ptr }\n        , m_control_block_ptr { other.m_control_block_ptr }\n        {\n            auto& ref_count = m_control_block_ptr-&gt;m_ref_count;\n            ref_count.fetch_add(1);\n        }\n\n        // swap\n        template&lt;typename U&gt;\n        requires std::is_convertible_v&lt;U*, T*&gt;\n        void swap(shared_ptr&lt;U&gt;& other){\n            std::swap(m_raw_underlying_ptr, other.m_raw_underlying_ptr);\n            std::swap(m_control_block_ptr, other.m_control_block_ptr);\n        }\n\n        // copy assignment\n        shared_ptr& operator=(const shared_ptr&lt;T&gt;& other)\n        {\n            shared_ptr(other).swap(*this);\n            return *this;\n        }\n\n        // move constructor\n        shared_ptr(shared_ptr&lt;T&gt;&& other)\n        : m_raw_underlying_ptr{ std::exchange(other.m_raw_underlying_ptr, nullptr) }\n        , m_control_block_ptr { std::exchange(other.m_control_block_ptr, nullptr) }\n        {}\n\n        // move assignment\n        shared_ptr& operator=(shared_ptr&& other)\n        {\n            shared_ptr(std::move(other)).swap(*this);\n            return *this;\n        }\n\n        pointer get(){\n            return m_raw_underlying_ptr;\n        }\n\n        pointer operator-&gt;(){\n            return m_raw_underlying_ptr;\n        }\n\n        T operator*(){\n            return *m_raw_underlying_ptr;\n        }\n\n        T operator[](std::size_t idx){\n            return m_raw_underlying_ptr[idx];\n        }\n\n        std::size_t use_count(){\n            if(m_raw_underlying_ptr)\n                return m_control_block_ptr-&gt;m_ref_count.load();\n            else\n                return 0;\n        }\n\n        bool operator==(const shared_ptr& other) const{\n            return m_raw_underlying_ptr == other.m_raw_underlying_ptr;\n        }\n\n        bool operator==(std::nullptr_t) const{\n            return m_raw_underlying_ptr == nullptr;\n        }\n\n        void release_resources(){\n            if(m_raw_underlying_ptr)\n            {\n                auto& ref_count = m_control_block_ptr-&gt;m_ref_count;\n                std::size_t ref_count_0 = ref_count.fetch_sub(1);\n                // If ref_count_0 == 1, I am the last owner of this resource.\n                if(ref_count_0 == 1)\n                {\n                    delete m_control_block_ptr;\n                    m_raw_underlying_ptr = nullptr;\n                    m_control_block_ptr = nullptr;\n                }\n            }\n        }\n\n        void reset_helper(){\n            release_resources();\n            m_control_block_ptr = nullptr;\n            m_raw_underlying_ptr = nullptr;\n        }\n        // reset(Y*) replaces the managed object\n        template&lt;typename Y&gt;\n        void reset(Y* ptr){\n            reset_helper();\n            if(ptr)\n            {\n                m_control_block_ptr = new ControlBlock&lt;Y,std::default_delete&lt;Y&gt;&gt;(ptr, std::default_delete&lt;Y&gt;{});\n                m_raw_underlying_ptr = ptr;\n            }\n        }\n\n        template&lt;typename Y, typename Deleter&gt;\n        void reset(Y* ptr, Deleter deleter){\n            reset_helper();\n            if(ptr)\n            {\n                m_control_block_ptr = new ControlBlock&lt;Y,Deleter&gt;(ptr, deleter);\n                m_raw_underlying_ptr = ptr;\n            }\n        }\n   \n        ~shared_ptr(){\n            release_resources();\n        }\n\n        private:\n        template&lt;typename... Args&gt;    \n        explicit shared_ptr(ControlBlockWithStorage&lt;T&gt;* control_block_ptr)\n        : m_control_block_ptr{ control_block_ptr }\n        {\n            m_raw_underlying_ptr = &(control_block_ptr-&gt;m_object);\n        }\n\n        template&lt;typename ObjType, typename... Args&gt;\n        friend shared_ptr&lt;ObjType&gt; make_shared(Args&&... args);\n    };\n\n    template&lt;typename T, typename... Args&gt;\n    shared_ptr&lt;T&gt; make_shared(Args&&... args){\n        return shared_ptr( new ControlBlockWithStorage&lt;T&gt;(std::forward&lt;Args&gt;(args)...) );\n    }\n\n    template&lt;typename T&gt;\n    shared_ptr(T*) -&gt; shared_ptr&lt;T&gt;;\n\n    template&lt;typename T, typename Deleter&gt;\n    shared_ptr(T*, Deleter) -&gt; shared_ptr&lt;T&gt;;\n\n}  // namespace dev\n\nTEST(SharedPtrTest, DefaultConstructorTest) {\n    dev::shared_ptr&lt;void&gt; ptr1;\n    EXPECT_EQ(ptr1, nullptr);\n}\n\nTEST(SharedPtrTest, ConstructorWithRawPtr){\n    // Contructor that takes T* \n    int* raw_ptr = new int(42);\n    dev::shared_ptr&lt;int&gt; ptr1(raw_ptr);\n    \n    EXPECT_EQ(*ptr1, 42);\n    EXPECT_EQ(ptr1.get(), raw_ptr);\n\n    dev::shared_ptr&lt;int&gt; ptr2{ new int(17) };\n    EXPECT_EQ(*ptr2, 17);\n    EXPECT_NE(ptr2.get(), nullptr);\n\n    dev::shared_ptr&lt;void&gt; ptr3{ nullptr };\n    EXPECT_EQ(ptr3, nullptr);\n}\n\nTEST(SharedPtrTest, RefCountingTest){\n    int* raw_ptr = new int(42);\n    {\n        dev::shared_ptr ptr1(raw_ptr);\n        EXPECT_EQ(ptr1.use_count(), 1);\n        {\n            dev::shared_ptr ptr2 = ptr1;\n            EXPECT_EQ(ptr1.use_count(), 2);\n            {\n                dev::shared_ptr ptr3 = ptr2;\n                EXPECT_EQ(ptr1.use_count(), 3);\n            }\n            EXPECT_EQ(ptr1.use_count(), 2);\n        }\n        EXPECT_EQ(ptr1.use_count(), 1);\n    }\n}\n\n\nTEST(SharedPtrTest, CopyConstructorTest){\n    /* Copy constructor */\n    int* raw_ptr = new int(42);\n    dev::shared_ptr&lt;int&gt; p1(raw_ptr);\n\n    dev::shared_ptr&lt;int&gt; p2 = p1;\n    EXPECT_EQ(*p2 == 42, true);\n    EXPECT_EQ(p2.get(), raw_ptr);\n    EXPECT_EQ(p1.use_count(), 2);\n}\n\nTEST(SharedPtrTest, MoveConstructorTest){\n    /* Move constructor*/\n    dev::shared_ptr&lt;int&gt; ptr1(new int(28));\n    EXPECT_EQ(*ptr1, 28);\n    EXPECT_EQ(ptr1.use_count(), 1);\n\n    dev::shared_ptr&lt;int&gt; ptr2 = std::move(ptr1);\n    EXPECT_EQ(*ptr2, 28);\n    EXPECT_EQ(ptr2.use_count(), 1);\n    EXPECT_EQ(ptr1, nullptr);\n    EXPECT_EQ(ptr1.use_count(), 0);\n\n    dev::shared_ptr&lt;int&gt; ptr3 = std::move(ptr2);\n    EXPECT_EQ(*ptr3, 28);\n    EXPECT_EQ(ptr3.use_count(), 1);\n    EXPECT_EQ(ptr2, nullptr);\n    EXPECT_EQ(ptr2.use_count(), 0);\n    \n}\n\nTEST(SharedPtrTest, CopyAssignmentTest){\n    /* Copy Assignment */\n    dev::shared_ptr&lt;double&gt; p1(new double(2.71828));\n    dev::shared_ptr&lt;double&gt; p2(new double(3.14159));\n    dev::shared_ptr p3{p1};\n    dev::shared_ptr p4{p1};\n    \n    EXPECT_EQ(p1.use_count(), 3);\n    EXPECT_EQ(p2.use_count(), 1);\n    p1 = p2;\n\n    EXPECT_EQ(p1.get(), p2.get());\n    EXPECT_EQ(p1.use_count(), 2);\n    EXPECT_EQ(*p1, *p2);\n}\n\nTEST(SharedPtrTest, MoveAssignmentTest){\n    /* Move Assignment */\n    dev::shared_ptr&lt;int&gt; p1(new int(42));\n    dev::shared_ptr&lt;int&gt; p2(new int(28));\n    p2 = std::move(p1);\n    EXPECT_NE(p2.get(), nullptr);\n    EXPECT_EQ(*p2, 42);\n    EXPECT_EQ(p1, nullptr);\n    EXPECT_EQ(p1.use_count(), 0);\n}\n\n/* swap() : swap the managed objects */\nTEST(SharedPtrTest, SwapTest){\n    int* first = new int(42);\n    int* second = new int(17);\n\n    dev::shared_ptr&lt;int&gt; p1(first);\n    dev::shared_ptr&lt;int&gt; p2(second);\n\n    p1.swap(p2);\n\n    EXPECT_EQ(p2.get() == first && p1.get() == second, true);\n    EXPECT_EQ(((*p1) == 17) && ((*p2) == 42), true);\n}\n\n// Observers\n/* get() : Returns a pointer to the \n    managed object or nullptr*/\nTEST(SharedPtrTest, GetTest){\n    double* resource = new double(0.50);\n    dev::shared_ptr p(resource);\n\n    EXPECT_EQ(p.get(), resource);\n    EXPECT_EQ(*(p.get()) , 0.50);\n}\n\n// Pointer-like functions\nTEST(SharedPtrTest, IndirectionOperatorTest) {\n    /* indirection operator* to dereference pointer to \n    managed object, member access operator -&gt; \n    to call member function*/\n    struct X {\n        int _n;\n\n        X() = default;\n        X(int n) : _n{n} {}\n        ~X() = default;\n        int foo() { return _n; }\n    };\n\n    dev::shared_ptr&lt;X&gt; ptr(new X(10));\n    EXPECT_EQ((*ptr)._n, 10);\n    EXPECT_EQ(ptr-&gt;foo(), 10);\n}\n\n// reset the managed pointer\nTEST(SharedPtrTest, ResetPointerTest){\n    struct Resource{};\n    Resource* resource_ptr = new Resource();\n    dev::shared_ptr&lt;Resource&gt; ptr1(resource_ptr);\n    dev::shared_ptr ptr2{ ptr1 };\n    dev::shared_ptr ptr3{ ptr1 };\n    EXPECT_EQ(ptr1.get(), resource_ptr);\n    EXPECT_EQ(ptr1.use_count(), 3);\n\n    ptr1.reset(new Resource());\n    EXPECT_NE(ptr1.get(), resource_ptr);\n    EXPECT_EQ(ptr1.use_count(), 1);\n    EXPECT_EQ(ptr2.get(), resource_ptr);\n    EXPECT_EQ(ptr2.use_count(), 2);\n}\n\nTEST(SharedPtrTest, MakeSharedTest){\n    struct OptionQuote{\n        std::pair&lt;std::string, std::string&gt; underlying;\n        double strike;\n        double expiry;\n        double implied_vol;\n    };\n\n    dev::shared_ptr&lt;OptionQuote&gt; quote_ptr = dev::make_shared&lt;OptionQuote&gt;(std::make_pair(\"USD\", \"JPY\"), 100.0, 1.0, 0.25);\n    EXPECT_NE(quote_ptr, nullptr);\n    EXPECT_EQ(quote_ptr-&gt;strike, 100.0);\n    EXPECT_EQ(quote_ptr-&gt;expiry, 1.0);\n    EXPECT_EQ(quote_ptr-&gt;implied_vol, 0.25);\n    EXPECT_EQ(quote_ptr-&gt;underlying, std::make_pair(\"USD\", \"JPY\"));\n}\n\nint main(int argc, char** argv) {\n    ::testing::InitGoogleTest(&argc, argv);\n    return RUN_ALL_TESTS();\n}\nCompiler Explorer\nYou can play around the code files, build the project and run unit tests for this (naive) toy-implementation of shared_ptr by cloning my GitHub repo.\n\n\n\nReferences\n\n\nC++ Memory Management by Patrice Roy."
  },
  {
    "objectID": "posts/implementing_shared_ptr/index.html#writing-the-shared_ptrt-destructor",
    "href": "posts/implementing_shared_ptr/index.html#writing-the-shared_ptrt-destructor",
    "title": "Implementing shared_ptr<T>",
    "section": "Writing the ~shared_ptr<T>() destructor",
    "text": "Writing the ~shared_ptr&lt;T&gt;() destructor\nThe destructor is tricky to get right.\nA naive algorithm for destruction could be that, if *m_ref_count_ptr == 1, call delete on both pointees, otherwise decrement the counter. It is possible that two threads enter the destructor concurrently with *m_ref_count_ptr=2, and neither thread sees *m_ref_count_ptr==1 and the pointees are never destroyed.\nAnother algorithm could be to decrement *m_ref_count_ptr. If *m_ref_count_ptr==0, invoke delete’s. There is a possibility that two threads enter the destructor concurrently, with *m_ref_count_ptr=2, then both concurrently decrement *m_ref_count_ptr leading to the possibility of both seeing *m_ref_count_ptr=0, resulting in double deletion."
  },
  {
    "objectID": "posts/auto_type_deduction_rules/index.html",
    "href": "posts/auto_type_deduction_rules/index.html",
    "title": "auto type deduction rules",
    "section": "",
    "text": "This weekend, I tried to solve a fun puzzle - the C++ auto type deduction gauntlet and thought of creating a quick cheatsheet on auto type deduction rules. I encourage you to give it a shot.\nauto is a placeholder type that gets replaced typically by deduction from an initializer.\nWhenever you have:\nauto [some_modifiers] x = expression;\nyou have three general cases:\n\nauto x : The object being assigned is allowed to decay. We strip the RHS expression of all CV-qualifiers such as const and reference modifiers & to deduce the by-value type of x.\nauto& x or auto&& x : It preserves references and CV-qualifiers.\nconst auto& x : We specify the qualifiers, auto simply deduces the base type.\n\nThere is special treatment for expressions that are functions or arrays:\n\nWhen initializing a reference(auto&), array/function types are preserved.\nOtherwise, it decays to a pointer before type deduction."
  },
  {
    "objectID": "posts/auto_type_deduction_rules/index.html#basics",
    "href": "posts/auto_type_deduction_rules/index.html#basics",
    "title": "auto type deduction rules",
    "section": "Basics",
    "text": "Basics\nauto v = 5;\nThis is fairly straight-forward. The deduced type is int. The value category of v is lvalue.\nauto v = 0.1;\nFloating-point values default to the larger double, rather than float. The value category of v is lvalue.\nint x;\nauto v = x;\nThe deduced type is int and the value category of v is lvalue.\nauto i{0uz};\nThe u suffix is used for unsigned integer literals and the z suffix is used for the signed version of std::size_t. The suffix uz deduces to std::size_t.\nThe type size_t is an implementation-defined unsigned integer type that is large enough to contain the size in bytes of any object.\nauto v=5, w=0.1\nI didn’t get this puzzle. But, this will fail to compile. All types in an expression defined with auto have be the same.\nint x;\nauto v = &x;\n& is the address-of operator. So, the type of v is deduced as pointer-to-int int*. The value category of v is lvalue.\nint x[5];\nauto v = x;\nx is an array of \\(5\\) ints, its type is int [5]. C-style arrays decay to a pointer. So, the type of v is int*. v is an lvalue.\nauto v = nullptr;\nnullptr is a value of type std::nullptr_t.\nauto v = {1, 2, 3};\n\\(1\\), \\(2\\) and \\(3\\) are ints. So, the type of v is deduced as std::initializer_list&lt;int&gt;. If the curly-braced initializer list were {1, 2.5, 4}, type deduction would fail, because we require all types in an initializer list to be the same.\nauto v{1, 2, 3};\nCurly braced direct initialization only works with a single scalar value e.g. auto v{1}.\nauto x = {17};\nThe type of x is deduced as std::initializer_list&lt;int&gt;.\nTo summarize:\n\nauto + copy list initialization : If all elements are of type T, auto is deduced as std::initializer_list&lt;T&gt;.\nauto + direct list initialization :\n\n\\(1\\) element in braces \\(\\implies\\) auto deduces the type of element by-value.\n\\(&gt;1\\) element \\(\\implies\\) error(ill-formed).\n\n\nint foo(int x){\n    return x;\n}\n\nauto v = foo;\nv is deduced as a function pointer, int (*) int. According to the C++ standard, a function is an object that occupies memory storage and has a lifetime. Hence, foo is an lvalue expression."
  },
  {
    "objectID": "posts/auto_type_deduction_rules/index.html#intermediate",
    "href": "posts/auto_type_deduction_rules/index.html#intermediate",
    "title": "auto type deduction rules",
    "section": "Intermediate",
    "text": "Intermediate\nWe now explore how references and CV-qualifiers are handled.\nvolatile const int x = 1;\nauto v = x;\nWe strip all modifiers off x, so that results in an int. Thus, auto is deduced as int. auto always drops top-level CV qualifiers.\nvolatile const int x = 1;\nauto v = &x;\nI didn’t quite get this one. It turns out that CV qualifiers applied to pointed-to. So, type of x is deduced as volatile const int*. The next code snip also shows the same:\n#include &lt;cassert&gt;\n#include &lt;type_traits&gt;\n\nint main(){\n    const int& x{42};\n    auto& y = x;\n    static_assert(std::is_same_v&lt;decltype(y), const int&&gt;);\n    return 0;\n}\nCompiler Explorer\nint x;\nint& y = x;\nauto v = y;\ny is an lvalue reference to x. The type of y decays to int.\nint x;\nauto& v = x;\nThe type of v is deduced as int&. v is an lvalue reference.\nint x[5];\nauto& v = x;\nauto is deduced as int [5]. The type of v is a reference to an array of \\(5\\) ints.\nint foo(const int x) {\n    return x;\n}\nauto v = foo;\nFunctions are lvalues and the function name is a pointer to function object in memory. CV-qualifiers on parameters are thrown away during function resolution. Hence, auto is deduced as int (*)(int)."
  },
  {
    "objectID": "posts/auto_type_deduction_rules/index.html#advanced",
    "href": "posts/auto_type_deduction_rules/index.html#advanced",
    "title": "auto type deduction rules",
    "section": "Advanced",
    "text": "Advanced\nint x;\nauto&& v = x;\nauto&& v is a forwarding reference. x is an lvalue and lvalues bind to lvalue references. Here, we get an lvalue reference.\nauto x = [] () -&gt; int { \n    return 1;\n};\nauto&& v = x();\nThe return value of the function call is a prvalue. It will bind to an rvalue reference. So, the type of v is deduced as int&&.\nint x;\nauto y = [&] () -&gt; int& { \n    return x;\n};\nauto&& v = y();\nThe result of the function call y() is an lvalue, so the type of v is deduced to be int&.\nstruct Foo {};\nauto&& v = Foo{};\nThe call to the constructor Foo{} creates a temporary Foo instance - a prvalue. Hence, the type of v is deduced as Foo&&.\nvoid f(auto& param);\n\nint x{22};\nconst int cx = x;\nconst int& rx = x;\n\nf(x);   // [1]\nf(cx);  // [2]\nf(rx);  // [3]\nauto& preserves references and CV-qualifiers. In the function call f(x), the type of param is deduced as int&. In the function call f(cx), the type of param is deduced as const int&. In the function call f(rx), the type of param is deduced as const int&.\nSolving these auto type deduction puzzles prompted me to go watch Scott Meyer’s talk on type deduction from CppCon 2014. At 25:10, he says:\n\nIt is important to distinguish between an expression that is const, and an expression that contains const.\n\nThe most common place this issue occurs, is when we are dealing with pointers. Observe the following code snip:\nint* const cpi;\nauto p1 = cpi;\n\nconst int* pci;\nauto p2 = pci;\n\nconst int* const cpci;\nauto p3 = cpci;\nYou can have a constant pointer-to-int, in which case the expression is a constant. Or you can have a pointer-to-const, in which case you have a expression containing const. And you can have a constant pointer to const, which is a constant expression that contains a const.\nWhen deducing auto, we are deducing by-value. The top-level const/volatile is dropped. Applying this rule, we have the following:\n\nThe type of p1 is deduced as int*.\nThe type of p2 is deduced as const int*.\nThe type of p3 is deduced as const int*.\n\nTHe fact that p3 is const is ignored. The fact that p3 contains const is not ignored.\nint x{22};\nconst int* pcx = &x;\nauto ppcx = &pcx;\nThe expression &pcx contains const. So, the type of ppcx is deduced as const int**."
  },
  {
    "objectID": "posts/auto_type_deduction_rules/index.html#lambda-capture-type-deduction",
    "href": "posts/auto_type_deduction_rules/index.html#lambda-capture-type-deduction",
    "title": "auto type deduction rules",
    "section": "Lambda capture type deduction",
    "text": "Lambda capture type deduction\nThe captures of a lambda expression defines the outside variables that are accessible from within the lambda function body. There are three kinds of lambda capture:\n\nBy reference: Uses type deduction rules for reference parameters.\nInit capture: Uses auto type deduction rules.\nBy value: CV qualifiers are retained.\n\nRecall that, C++14 allows init-captures. You can create new data members in the closure type on the fly. Then, we can access those variables inside the lambda.\nThe key takeaway is that the simple by-value capture \\(\\neq\\) by-value init capture. Observe the following code snip:\n{\n    const int cx{0};\n    auto func = [cx](){};   // by-value capture\n                            // The type of `cx` is `const int`\n}\n\n{\n    const int cx{0};\n    auto func = [cx = cx](){};   // init-capture\n                                 // The type of `cx` is `int`\n}\nThis is an interesting wrinkle that exists for by-value lambda captures.\nObserve the following code snip:\n{\n    int cx{0};\n    auto func = [cx]{ cx = 10; };   // error\n    func();\n}\nIn this lambda expression, cx is captured by value. The type cx is deduced as int. Recall, that the function call operator is const. You can’t modify a non-const member variable inside a const member function. So, this would be a compile error.\nIf you declare your lambda as mutable, it means that the function call operator is not const. Observe the next code snip. If we have a local variable which is const and we capture it by value, then it will be copied into the class as a const.\n{\n    const int cx{0};\n    auto func = [cx] mutable { cx = 10; };  // still error\n}\nMy next example, is a real mind-bender borrowed from slide 31 of Scott Meyer’s talk. Observe the code snip below. What is the deduced type of param?\ntemplate&lt;typename T&gt;\nvoid f(const T& param);\n\nstruct Widget{};\n\nstd::vector&lt;Widget&gt; createVec();\n\nconst auto vw = createVec();\n\nif(!vw.empty()){\n    f(&vw[0]);\n}\nFirst, the function createVec() returns a vector&lt;Widget&gt; by value. auto deduction rules apply. So, the type of vw is deduced as const std::vector&lt;Widget&gt;. So, all elements of the vector are considered immutable and are of type const Widget. If the vector is not empty, f receives the address of the element of the vector. This is a pointer-to-const Widget, it contains const. Thus, the base type T is deduced as Widget* const. param is a const reference to T, so the type of param is deduced as const Widget* const &."
  },
  {
    "objectID": "posts/auto_type_deduction_rules/index.html#decltype-type-deduction",
    "href": "posts/auto_type_deduction_rules/index.html#decltype-type-deduction",
    "title": "auto type deduction rules",
    "section": "decltype type deduction",
    "text": "decltype type deduction\n\nIf you apply decltype to a (unparenthesized) name, it will give you the declared type of that name. It’s not the same as auto, because in auto deduction, top-level CV-qualifiers are dropped.\nIf the argument is any other expression of type T:\n\nIf the value category of the expression is xvalue, then decltype yields T&&.\nIf the value category of the expression is a prvalue, then decltype yield T.\nIf the value category of the expression is a lvalue, then decltype yields T&.\n\n\ndecltype merely inspects the type of the expression statically at compile-time. It does not evaluate the expression. Let’s try and solve a few more puzzles.\nint x;\ndecltype(auto) v = (x);\nThe expression (x) is an lvalue, so decltype(auto) deduces to an lvalue reference of type int&.\nstruct Foo {};\ndecltype(auto) v = Foo{};\nThe expression Foo{} is a prvalue. For any prvalue expression e, decltype(e) evaluates to the type of e.\nint x;\ndecltype(auto) v = std::move(x);\nThe expression std::move(x) is an xvalue. The type of v is deduced as int&&.\nint foo(int x) {\n    return x;\n}\ndecltype(auto) v = foo;\nfoo is an lvalue of type int (*) (int). So, the type of v is deduced as int (*)(int).\nint foo(int x) {\n    return x;\n}\ndecltype(auto) v = (foo);\n(foo) is an lvalue expression of type int (*) (int). So, the type of v is deduced to be int (*) (int) &.\nclass Base {\n    public:\n        auto foo() {\n            return this;\n        };\n};\n\nclass Derived : public Base {\n};\n\nDerived d;\nauto v = d.foo();\nDerived inherits foo() from Base, so you can access Base::foo() using a Derived object. Further, this in Base::foo() returns a Base*, so the type of v is deduced as Base*."
  },
  {
    "objectID": "posts/auto_type_deduction_rules/index.html#challenge-puzzle",
    "href": "posts/auto_type_deduction_rules/index.html#challenge-puzzle",
    "title": "auto type deduction rules",
    "section": "Challenge Puzzle",
    "text": "Challenge Puzzle\nObserve the code snippet below. What gets printed?\n// Headers\n\nint main() {\n    int x { 3 };\n    decltype((x = 4)) y = x;\n    std::cout &lt;&lt; x;\n\n    return 0;\n}\nFor more such puzzles, visit getcracked.io."
  },
  {
    "objectID": "posts/move-semantics/index.html#challenge-puzzle",
    "href": "posts/move-semantics/index.html#challenge-puzzle",
    "title": "Move semantics and perfect forwarding",
    "section": "Challenge puzzle",
    "text": "Challenge puzzle\nObserve the below code snip. What is the output printed?\n#include &lt;iostream&gt;\nstruct A {\n    A(int x) : x(x) {}\n    A(const A& a) { x = 1; }\n    A(A&& a) { x = 2; }\n    int x;\n};\n\nvoid foo(A t) {\n    std::cout &lt;&lt; t.x;\n}\n\nA bar(){\n    A a(5);\n    return a;\n}\n\nA foobar(){\n    return A(6);\n}\n\nA&& baz(A&& arg){\n    return std::move(arg);\n}\n\nint main() {\n    A a(3);\n    foo(a);\n    foo(A(4));\n    std::cout &lt;&lt; bar().x;\n    std::cout &lt;&lt; foobar().x;\n    A result{ baz(A(7)) };\n    std::cout &lt;&lt; result.x;\n}\nCompiler Explorer\nFor more such puzzles, visit getcracked.io"
  },
  {
    "objectID": "posts/std::variant/index.html",
    "href": "posts/std::variant/index.html",
    "title": "std::variant",
    "section": "",
    "text": "Using std::variant\nA std::variant is a closed-discriminated union. Variants simply have internal memory for maximum size of the underlying types plus a fixed overhead to manage which alternative is used. No heap memory is allocated. The resulting object has value semantics. Copying a variant is implemented as a deep-copy, it creates a new variant object with the current value of the alternative in its own memory."
  },
  {
    "objectID": "posts/std_variant/index.html",
    "href": "posts/std_variant/index.html",
    "title": "std::variant",
    "section": "",
    "text": "Using std::variant\nA std::variant is a closed-discriminated union. Variants simply have internal memory for maximum size of the underlying types plus a fixed overhead to manage which alternative is used. No heap memory is allocated. The resulting object has value semantics. Copying a variant is implemented as a deep-copy, it creates a new variant object with the current value of the alternative in its own memory.\n#include &lt;iostream&gt;\n#include &lt;variant&gt;\n#include &lt;string&gt;\n\nint main(){\n    // initialized with string alternative\n    std::variant&lt;int, std::string&gt; var{\"hi\"};   \n    std::cout &lt;&lt; var.index() &lt;&lt; \"\\n\";\n\n    // now holds int alternative\n    var = 42;\n    std::cout &lt;&lt; var.index() &lt;&lt; \"\\n\";\n\n    try{\n        int i = std::get&lt;0&gt;(var);  // access by index\n        int j = std::get&lt;int&gt;(var); //access by type\n        std::string s = std::get&lt;std::string&gt;(var); //error\n    }catch(const std::bad_variant_access& e){\n        std::cerr &lt;&lt; \"Exception: \" &lt;&lt; e.what() &lt;&lt; \"\\n\";\n    }\n    return 0;\n}\nCompiler Explorer\nOutput:\nProgram returned: 0\nProgram stdout\n\n1\n0\n\nProgram stderr\n\nException: std::get: wrong index for variant\nThe default constructor for std::variant always initializes the first type with the default constructor. If there is no default constructor for the first type, calling the default constructor for the variant is a compile-time error.\nTo support variants, where the first type has no default constructor, a special helper type is provided: std::monostate. Objects of type std::monostate always have the same state."
  },
  {
    "objectID": "newsletter.html",
    "href": "newsletter.html",
    "title": "Newsletter",
    "section": "",
    "text": "Subscribe to get new posts delivered directly to your inbox."
  }
]