[
  {
    "objectID": "roadmap.html",
    "href": "roadmap.html",
    "title": "C++ Roadmap",
    "section": "",
    "text": "If you’re coming upto speed on modern C++, or preparing for technical-interviews, having a structured approach can be incredibly helpful. Most companies prefer strong critical thinking and basic knowledge over extensive knowledge and medium critical thinking, because software development needs constant learning. So its important to be really cracked at modern C++ language features and the standard library.\nQuant/quantitative developer roles are not just about doing math in a basement. You are expected to be a self-starter and quickly pick up a complex codebase. Strong coding, debugging skills, are therefore incredibly valuable in writing efficient code, or analysing a large codebase.\nI suggest the following critical path, a chronological sequence of resources that have helped me quickly come upto speed in a short span of time :"
  },
  {
    "objectID": "posts/shared_ptr/index.html",
    "href": "posts/shared_ptr/index.html",
    "title": "shared_ptr - A custom implementation",
    "section": "",
    "text": "Introduction\nshared_ptr&lt;T&gt; is tricky to implement, since it is a wrapper over raw underlying pointer of type T* and a reference counter. This post is partly inspired by the fantastic book C++ Memory Management by Patrice Roy. The toy examples in this book are very instructive and I highly reckon you order a copy.\nIf you follow the instructions in my GitHub repo, you should be able to build the source and run unit tests against my homegrown version of shared_ptr&lt;T&gt;.\n\n\nBasic functionalities expected out of a shared_ptr&lt;T&gt; implementation.\n#include &lt;gtest/gtest.h&gt;\n#include &lt;thread&gt;\n#include &lt;atomic&gt;\n#include \"shared_ptr.h\"\n\nTEST(SharedPtrTest, ParametrizedCTorTest)\n{\n    /* Contructor that takes T* */\n    int* raw_ptr = new int(42);\n    dev::shared_ptr&lt;int&gt; p1(raw_ptr);\n    \n    EXPECT_EQ(*p1 == 42,true);\n    EXPECT_EQ(p1.get(), raw_ptr);\n\n    dev::shared_ptr&lt;int&gt; p2 = new int(17);\n    EXPECT_EQ(*p2 == 17,true);\n    EXPECT_EQ(p2.get() != nullptr, true);\n}\n\nTEST(SharedPtrTest, RefCountingTest){\n    int* raw_ptr = new int(42);\n    {\n        dev::shared_ptr ptr1 = raw_ptr;\n        EXPECT_EQ(ptr1.use_count() == 1, true);\n        {\n            dev::shared_ptr ptr2 = ptr1;\n            EXPECT_EQ(ptr1.use_count() == 2, true);\n            {\n                dev::shared_ptr ptr3 = ptr2;\n                EXPECT_EQ(ptr1.use_count() == 3, true);\n            }\n            EXPECT_EQ(ptr1.use_count() == 2, true);\n        }\n        EXPECT_EQ(ptr1.use_count() == 1, true);\n    }\n}\n\nTEST(SharedPtrTest, MultithreadedConstructionAndDestructionTest){\n    using namespace std::chrono_literals;\n    dev::shared_ptr ptr = new int(42);\n    std::atomic&lt;bool&gt; go{false};\n    EXPECT_EQ(ptr.use_count() == 1, true);\n\n    std::thread t1([&]{\n        dev::shared_ptr&lt;int&gt; ptr1 = ptr;\n        while(!go.load());\n        std::cout &lt;&lt; \"\\nRef Count = \" &lt;&lt; ptr.use_count();\n        std::this_thread::sleep_for(1s);\n    });\n\n    std::thread t2([&]{\n        dev::shared_ptr&lt;int&gt; ptr2 = ptr;\n        while(!go.load());\n        std::cout &lt;&lt; \"\\nRef Count = \" &lt;&lt; ptr.use_count();\n        std::this_thread::sleep_for(1s);\n    });\n\n    std::this_thread::sleep_for(1s);\n    go.store(true);\n    t1.join();\n    t2.join();\n    EXPECT_EQ(ptr.use_count() == 1, true);\n}\n\nTEST(SharedPtrTest, CopyConstructorTest){\n    /* Copy constructor */\n    int* raw_ptr = new int(42);\n    dev::shared_ptr&lt;int&gt; p1(raw_ptr);\n\n    dev::shared_ptr&lt;int&gt; p2 = p1;\n    EXPECT_EQ(*p2 == 42, true);\n    EXPECT_EQ(p2.get(), raw_ptr);\n}\n\nTEST(SharedPtrTest, MoveConstructorTest){\n    /* Move constructor*/\n    dev::shared_ptr&lt;int&gt; p1(new int(28));\n    dev::shared_ptr&lt;int&gt; p2 = std::move(p1);\n    dev::shared_ptr&lt;int&gt; p3 = std::move(p2);\n    EXPECT_EQ(*p3 == 28, true);\n}\n\nTEST(SharedPtrTest, CopyAssignmentTest){\n    /* Copy Assignment */\n    dev::shared_ptr&lt;double&gt; p1(new double(2.71828));\n    dev::shared_ptr&lt;double&gt; p2(new double(3.14159));\n\n    EXPECT_EQ(*p2 == 3.14159, true);\n    p2 = p1;\n    EXPECT_EQ(p2.get() == p1.get(), true );\n    EXPECT_EQ(*p2 == *p1, true);\n}\n\nTEST(SharedPtrTest, MoveAssignmentTest){\n    /* Move Assignment */\n    dev::shared_ptr&lt;int&gt; p1(new int(42));\n    dev::shared_ptr&lt;int&gt; p2(new int(28));\n    p2 = std::move(p1);\n    EXPECT_EQ(p2.get() != nullptr, true);\n    EXPECT_EQ(*p2 == 42, true);\n}\n\n/* reset() :  replaces the managed object */\nTEST(SharedPtrTest, ResetSharedPtr) {\n    dev::shared_ptr&lt;int&gt; ptr(new int(10));\n    ptr.reset(new int(20));\n    EXPECT_EQ(ptr != nullptr, true);\n    EXPECT_EQ(*ptr == 20, true);\n\n    // Self-reset test\n    ptr.reset(ptr.get());\n}\n\n/* swap() : swap the managed objects */\nTEST(SharedPtrTest, SwapTest){\n    int* first = new int(42);\n    int* second = new int(17);\n\n    dev::shared_ptr&lt;int&gt; p1(first);\n    dev::shared_ptr&lt;int&gt; p2(second);\n\n    swap(p1, p2);\n\n    EXPECT_EQ(p2.get() == first && p1.get() == second, true);\n    EXPECT_EQ(((*p1) == 17) && ((*p2) == 42), true);\n}\n\n// Observers\n/* get() : Returns a pointer to the \n    managed object or nullptr*/\nTEST(SharedPtrTest, GetTest){\n    double* resource = new double(0.50);\n    dev::shared_ptr p(resource);\n\n    EXPECT_EQ(p.get() == resource, true);\n    EXPECT_EQ(*(p.get()) == 0.50, true);\n}\n\n// Pointer-like functions\nTEST(SharedPtrTest, IndirectionOperatorTest) {\n    /* indirection operator* to dereference pointer to \n    managed object, member access operator -&gt; \n    to call member function*/\n    struct X {\n        int _n;\n\n        X() = default;\n        X(int n) : _n{n} {}\n        ~X() = default;\n        int foo() { return _n; }\n    };\n\n    dev::shared_ptr&lt;X&gt; ptr(new X(10));\n    EXPECT_EQ((*ptr)._n == 10, true);\n    EXPECT_EQ(ptr-&gt;foo() == 10, true);\n}\n\n\nModern C++ Implementation.\n#include&lt;format&gt;\n#include&lt;atomic&gt;\n\nnamespace dev{\n    template&lt;typename T&gt;\n    class shared_ptr{\n        public:\n\n        /* Default constructor*/\n        shared_ptr() = default;\n\n        /* Parametrized constructor : Takes ownership of the pointee */\n        shared_ptr(T* ptr) \n        : m_raw_underlying_ptr{ptr}\n        {\n            try{\n                m_ref_count_ptr = new std::atomic&lt;unsigned long long&gt;(1LL);\n            }catch(...){\n                delete ptr;\n                throw;\n            }\n        }\n\n        /* Copy constructor : Implements shared \n        co-ownership of the pointee semantics */\n        shared_ptr(const shared_ptr& other)\n        : m_raw_underlying_ptr{other.m_raw_underlying_ptr}\n        , m_ref_count_ptr{other.m_ref_count_ptr}\n        {\n            if(m_ref_count_ptr)\n                ++(*m_ref_count_ptr);   //Atomic pre-increment\n        }\n\n        /* Move constructor : Represents the transfer of \n        ownership */\n        shared_ptr(shared_ptr&& other)\n        : m_raw_underlying_ptr{ std::exchange(other.m_raw_underlying_ptr, nullptr)}\n        , m_ref_count_ptr{ std::exchange(other.m_ref_count_ptr, nullptr)}\n        {}\n\n        /* Swap : Swap two shared_ptr objects member by member */\n        void swap(shared_ptr& other){\n            using std::swap;\n            std::swap(m_raw_underlying_ptr, other.m_raw_underlying_ptr);\n            std::swap(m_ref_count_ptr, other.m_ref_count_ptr);\n        }\n\n        friend void swap(shared_ptr& lhs, shared_ptr& rhs){\n            lhs.swap(rhs);\n        }\n\n        /* Copy assignment operator : Release the current \n        held resource and share the ownership of the \n        resource specified by args */\n        shared_ptr& operator=(const shared_ptr& other){\n            shared_ptr{ other }.swap(*this);\n            return *this;\n        }\n\n        /* Move assignment : Release the currently held \n        resource and transfer the ownership of resource \n        specified in args */\n        shared_ptr& operator=(shared_ptr&& other){\n            shared_ptr{ std::move(other) }.swap(*this);\n            return *this;\n        }\n\n        ~shared_ptr(){\n            if(m_ref_count_ptr){\n                unsigned long long expected = m_ref_count_ptr-&gt;load();\n                \n                // Decrement the reference count\n                while(expected &gt; 0 \n                    && !m_ref_count_ptr-&gt;compare_exchange_weak(expected, expected - 1));\n\n                auto desired = expected - 1;\n                if(desired == 0){   // We are the last user of *m_ref_underlying_ptr\n                    delete m_raw_underlying_ptr;\n                    delete m_ref_count_ptr;\n                }\n            }\n        }\n\n        /* get() - Returns the stored pointer */\n        T* get(){\n            return m_raw_underlying_ptr;\n        }\n\n        const T* get() const{\n            return m_raw_underlying_ptr;\n        }\n\n        T& operator*() noexcept {\n            return *m_raw_underlying_ptr;\n        }\n\n        const T& operator*() const noexcept{\n            return *m_raw_underlying_ptr;\n        }\n\n        T* operator-&gt;() noexcept{\n            return m_raw_underlying_ptr;\n        }\n        \n        const T* operator-&gt;() const noexcept{\n            return m_raw_underlying_ptr;\n        }\n\n        /* Comparison operator*/\n        bool operator==(const shared_ptr& other) const noexcept{\n            return (m_raw_underlying_ptr == other.m_raw_underlying_ptr);\n        }\n\n        bool operator!=(const shared_ptr& other) const noexcept{\n            return !(*this == other);\n        }\n\n        unsigned long long use_count() const noexcept{\n            if(m_ref_count_ptr)\n                return m_ref_count_ptr-&gt;load();\n            else\n                return 0;\n        }\n        \n        /* Replaces the managed resource */\n        void reset(T* ptr){\n            if(m_raw_underlying_ptr != ptr)\n                shared_ptr(ptr).swap(*this);\n        }\n\n        private:\n        T* m_raw_underlying_ptr{nullptr};\n        std::atomic&lt;unsigned long long&gt;* m_ref_count_ptr{nullptr};\n    };\n}"
  },
  {
    "objectID": "posts/type-traits-101/index.html",
    "href": "posts/type-traits-101/index.html",
    "title": "Type Traits 101",
    "section": "",
    "text": "Meta-programs are programs that treat other programs as data. They could be other programs or itself. A meta-function is not a function, but a class or struct. Metafunctions are not part of the language and have no formal language support. They exist purely as an idiomatic use of the existing language features. Now, since their use is not enforced by the language, their used has to be dictated by a convention. Over the years, the C++ community has created common set of standard conventions. Actually this work goes back all the way to Boost type_traits.\nMetafunctions are not functions. Technically, they are a class with zero or more template parameters and zero+ return types and values. The convention is that a metafunction should return just one thing, like a regular function. The convention was developed over time, so there are plenty of existing examples that do not follow this convention. More modern metafunctions do follow this convention."
  },
  {
    "objectID": "posts/type-traits-101/index.html#how-do-we-return-from-a-metafunction",
    "href": "posts/type-traits-101/index.html#how-do-we-return-from-a-metafunction",
    "title": "Type Traits 101",
    "section": "How do we return from a metafunction",
    "text": "How do we return from a metafunction\nIf we have to return a value, basically, we are going to expose a public field named value.\ntemplate&lt;typename T&gt;\nstruct TheAnswer{\n    static constexpr int value = 42;\n};\nAnd if we are going to return a type, we are going to expose a public field named type.\ntemplate&lt;typename T&gt;\nstruct Echo{\n    using type = T;\n};\nNow, here’s kind of the difference between regular functions and metafunctions. A regular function in C++ always works on some form of data and it’s always going to return to you some piece of data as well. Amongst metafunctions, we have value metafunctions that work on values like we are used to and then we have metafunctions that work entirely on types and they yield back some type to you. And so in the both of the examples above, we return something by exposing the public members of a class."
  },
  {
    "objectID": "posts/type-traits-101/index.html#value-metafunctions",
    "href": "posts/type-traits-101/index.html#value-metafunctions",
    "title": "Type Traits 101",
    "section": "Value metafunctions",
    "text": "Value metafunctions\nA value metafunction is kind of like a simple regular function. Let’s look at a simple regular function - the integer identity function.\nint int_identity(int x)\n{\n    return x;\n}\n\nassert(42 == int_identity(42));\nThis function just applies the identity transformation on any integer passed to it, and spits out the same number. A simple metafunction for identity - we can call it the intIdentity metafunction would look like this:\ntemplate&lt;int X&gt;\nstruct intIdentity{\n    static constexpr int value = X;\n};\n\nstatic_assert(42 == IntIdentity&lt;42&gt;::value);\nWe see that it’s not that much different. You return a value by having a static data-member called value and it has the metafunction’s return value. IntIdentity&lt;42&gt;::value is where we are calling the metafunction. Now, this convention needs to be adhered to, because if you give your metafunction some other name such as my_value, for example, if you write:\ntemplate&lt;int X&gt;\nstruct intIdentity{\n    static constexpr int my_value = X;\n};\n\nstatic_assert(42 == IntIdentity&lt;42&gt;::value);\nit’s not going to work well with other things.\n\nGeneric Identity Function\nLet’s look at the generic identity function.\ntemplate&lt;typename T&gt;\nT identity(T x){\n    return x;\n}\n\n//Returned type will be 42\nassert(42 == identity(42));\n\n// Returned type will be unsigned long long\nassert(42ul == identity(42ul))\nThis is just a function that will be an identity for any type. You give me a value of any type and I will give you that value back. Now we can create a generic identity metafunction as well:\ntemplate&lt;typename T, T x&gt;\nstruct ValueIdentity{\n    static constexpr T value = x;\n};\n\n// The type of value will be int\nstatic_assert(42 == identity&lt;int,42&gt;::value);\n\n// The type of value will unsigned long long\nstatic_assert(42ull == identity&lt;unsigned long long,42ull&gt;::value);\nValueIdentity is a generic metafunction, so we have to first feed it the type int and then the value 42. It’s a little cumbersome, but you get used to it after a while.\nIn C++17, things get a little bit easier with generic metafunctions, because we have this cool keyword called auto. I won’t go into all the details of auto. For now, it basically means that the template will accept and deduce the type of any non-type template parameter.\ntemplate&lt;auto X&gt;\nstruct ValueIdentity{\n    static constexpr auto value = X;\n};\n\n// The type of value will be int\nstatic_assert(42 == identity&lt;int,42&gt;::value);\n\n// The type of value will unsigned long long\nstatic_assert(42ull == identity&lt;unsigned long long,42ull&gt;::value);\nLet’s look at another function sum(). We can do this in a regular function, and we can do this in a metafunction as well.\nint sum(int x, int y){\n    return x + y;\n}\n\ntemplate&lt;int X, int Y&gt;\nstruct intSum{\n    static constexpr int value = X + Y;\n};\n\nstatic_assert(42 == IntSum&lt;30,12&gt;::value);\nSo, we can also create a generic version of this:\ntemplate&lt;typename X, typename Y&gt;\nauto sum(T x, Ty){\n    return x + y;\n}\n\ntemplate&lt;auto X, auto Y&gt;\nstruct Sum{\n    static constexpr auto value = X + Y;\n};"
  },
  {
    "objectID": "posts/type-traits-101/index.html#type-metafunctions",
    "href": "posts/type-traits-101/index.html#type-metafunctions",
    "title": "Type Traits 101",
    "section": "Type metafunctions",
    "text": "Type metafunctions\nType metafunctions are the workhorse of doing type transformations. You can manipulate types through type metafunctions. Type *metafunctions are going to return just a type.\nHere’s our TypeIdentity function:\ntemplate&lt;typename T&gt;\nstruct TypeIdentity{\n    using type = T;\n}\nJust like we have ValueIdentity, where given any value, it’s going you the value back; we have TypeIdentity, where you give it any type, and it’s going to give you the type back.\nC++20 actually introduces std::type_identity, which is pretty much what we see above.\n\nCalling Type Metafunctions\nWhen we call a value metafunction, we can easily call the function:\nValueIdentity&lt;42&gt;::value\nValueIdentity is the metafunction, it’s passed the parameter 42 in the angle brackets (just like parentheses for a regular value function) and ::value is how I get it’s value back.\nWhen I call a type metafunction, it’s the same way. The function call consists of the metafunction name std::type_identity, the parameters to the metafunction in angle brackets (&lt;42&gt;) and ::type is how I get it’s value back.\n#include &lt;iostream&gt;\n#include &lt;type_traits&gt;\n\nint main()\n{\n    using T = std::type_identity&lt;int&gt;::type;\n    return 0;\n}\nCompiler Explorer"
  },
  {
    "objectID": "posts/type-traits-101/index.html#understanding-name-binding-and-dependent-types",
    "href": "posts/type-traits-101/index.html#understanding-name-binding-and-dependent-types",
    "title": "Type Traits 101",
    "section": "Understanding name binding and dependent types",
    "text": "Understanding name binding and dependent types\nName binding is the process of establishing, determining explicitly the type of each name (declaration) in a template. There are two kinds of names used within a template: dependent and non-dependent names. Names that depend on a template parameter are called dependent names.\n\nFor dependent names, name binding is performed at the point of template instantiation.\nFor non-dependent names, name binding is performed at the point of template definition.\n\nConsider the following C++ code:\n// Ref: Template metaprogramming with C++\n// Mariusz Bancilla, pages 123 \n#include &lt;iostream&gt;\n\ntemplate&lt;typename T&gt;\nstruct handler{\n    void handle(T value)    //[1] handle is a dependent name\n    {\n        std::cout &lt;&lt; \"handler&lt;T&gt;: \" &lt;&lt; value &lt;&lt; '\\n';\n    }\n};\n\ntemplate&lt;typename T&gt;\nstruct parser{\n    void parse(T arg){      //[2] parse is a dependent name\n        arg.handle(x);\n    }\n\n    double x;                  //[3] x is a non-dependent name\n};\n\nint main(){\n    handler&lt;double&gt; doubleHandler;                //[5] template instantiation\n    parser&lt;handler&lt;double&gt;&gt; doubleParser(3.14);   //[6] template instantiation\n    doubleParser.parse(doubleHandler);\n    return 0;\n}\nWhen the compiler sees dependent names, e.g. at points [1] and [2], it cannot determine the type-signature of these functions. So, parse() and handle() are not bound at this point.\nThe declaration double x at point [3] declares a non-dependent type. So, the type of the variable x is known and bound.\nContinuing with the code, at point [4], there is a template specialization for the handler class template for the type int.\nTemplate instantiation happens at points [5] and [6]. At point [5], handler&lt;double&gt;::handle is bound to handle and at point [6], parser&lt;handler&lt;double&gt;&gt;::parse is bound to parse.\n\nTwo-phase name lookup\nName binding happens differently for dependent names (those that depend on a template parameter) and non-dependent names. When the compiler passes throuh the definition of a template, it needs to figure out whether a name is dependent or non-dependent. Further, name binding depends upon this categorization. Thus, the instantiation of a template happens in 2-phases.\n\nThe first phase occurs at the point of the definition when the template syntax is checked and the names are categorized as dependent or non-dependent.\nThe second phase occurs at the point of template instantiation when the template arguments are substituted for the template parameters. Name binding for dependent names happens at this point.\n\nThis process in two steps is called the two-phase name lookup.\nConsider the following C++ code:\n// Ref: Template metaprogramming with C++\n// Mariusz Bancilla, pages 125\ntemplate&lt;typename T&gt;\nstruct base_parser\n{\n    void init()                     // [1] non-dependent name\n    {\n        std::cout &lt;&lt; \"init\\n\";\n    }\n};\n\ntemplate&lt;typename T&gt;\nstruct parser::public base_parser&lt;T&gt;\n{\n    void parse(){                  // [2] non-dependent name\n        // The compiler at [3] will try to bind init(), as it's a non-dependent name.\n        // However, base_parser has not yet been instantiated. This will result in a \n        // compile-error\n        //init();                  // [3] non-dependent name\n        std::cout &lt;&lt; \"parse\\n\";\n    }\n};\n\nint main(){\n    parser&lt;double&gt; p;\n    p.parse();\n}\nThe call to init() inside the parse() member function has been commented out. Uncommenting it will cause a compile error.\nThe intention here is to call the base-class init() function. However, the compiler will issue an error, because it’s not able to find init(). The reason is that init() is a non-dependent name. Therefore, it must be bound at the time of the definition of the parser template. Although, base_parser&lt;T&gt;::init() exists, this template has still not been instantiated. The compiler cannot assume its what we want to call, because the primary template base_parser can always be specialized and init() can be defined as something else.\nThis problem can be fixed, by making init a dependent name. This can be done by either prefixing it with this-&gt; or with base_parser&lt;T&gt;::.\n\n\nDependent type names\nThere are cases where a dependent name is a type. Consider the following C++ code:\n#include &lt;iostream&gt;\n\ntemplate&lt;typename T&gt;\nstruct base_parser{\n    using value_type = T;\n};\n\ntemplate&lt;typename T&gt;\nstruct parser: base_parser&lt;T&gt;{\n    void parse(){\n        // value_type v{};  // [1] : Error\n        // base_parser&lt;T&gt;::value_type v{};  //[2] :Error\n        std::cout &lt;&lt; \"parse\\n\";\n    }\n};\n\nint main()\n{\n    parser&lt;double&gt; p;\n    p.parse();\n    return 0;\n}\nCompiler Explorer\nIn this code snippet, the metafunction base_parser is an identity metafunction and returns back the type you give it. base_parser&lt;T&gt;::value_type is actually a dependent type, which depends on the template parameter T. At point [1] and [2], the compiler does not know what T will be. If it attempts to bind the name v, it will fail. We need to tell the compiler explicitly base_parser&lt;T&gt;::value_type is a dependent type. You do that using the typename keyword.\n#include &lt;iostream&gt;\n\ntemplate&lt;typename T&gt;\nstruct base_parser{\n    using value_type = T;\n};\n\ntemplate&lt;typename T&gt;\nstruct parser: base_parser&lt;T&gt;{\n    void parse(){\n        // value_type v{};  // [1] : Error\n        // base_parser&lt;T&gt;::value_type v{};  //[2] :Error\n        typename base_parser&lt;T&gt;::value_type v{};  //[3] :Ok\n        std::cout &lt;&lt; \"parse\\n\";\n    }\n};\n\nint main()\n{\n    parser&lt;double&gt; p;\n    p.parse();\n    return 0;\n}\nSo, any time, when calling a type metafunction, if the compiler does not know what ::type is, you must prefix it using the typename keyword, if we want to treat it as a type."
  },
  {
    "objectID": "posts/type-traits-101/index.html#convenience-calling-functions",
    "href": "posts/type-traits-101/index.html#convenience-calling-functions",
    "title": "Type Traits 101",
    "section": "Convenience calling functions",
    "text": "Convenience calling functions\nValue metafunctions often use helper functions (variable templates) ending with _v. For example, we often define the helper function:\ntemplate &lt;auto X&gt;\ninline constexpr auto ValueIdentity_v = ValueIdentity&lt;X&gt;::value;\n\nstatic_assert(42 == ValueIdentity&lt;42&gt;::value);\nstatic_assert(42 == ValueIdentity_v&lt;42&gt;)\nWe are just calling the ValueIdentity&lt;&gt; metafunction, grabbing its value and storing it into this variable ValueIdentity_v. This is a convenient way of calling value metafunctions. It does require you to instantiate an extra variable template.\nIt’s really helpful when we start using it with types. Type metafunctions use alias templates ending with _t. It helps us get rid of the entire typename dance.\ntemplate &lt;typename T&gt;\nusing TypeIdentity_t = typename TypeIdentity&lt;T&gt;::type;\n\nstatic_assert(std::is_same_v&lt;int, TypeIdentity_t&lt;int&gt;);\nInstead of calling the TypeIdentity metafunction with the parameter int and writing ::type to get its value, I can just call the metafunction with _t and with its parameters in angle brackets(&lt;&gt;).\nThese calling conventions are easier to use. But each one must be explicitly hand-written. So, every time you write a metafunction, if you want to provide convenience capabilities, you also have to write the convenience variable template or alias template."
  },
  {
    "objectID": "posts/type-traits-101/index.html#useful-metafunctions-to-think-of",
    "href": "posts/type-traits-101/index.html#useful-metafunctions-to-think-of",
    "title": "Type Traits 101",
    "section": "Useful metafunctions to think of",
    "text": "Useful metafunctions to think of\nHow is std::remove_pointer metafunction implemented? You can intuitively come up with what it must look like:\ntemplate&lt;typename T&gt;\nstruct RemovePointer{\n    using type = T;\n};\n\n// template specialization\ntemplate&lt;typename T&gt;\nstruct RemovePointer&lt;T*&gt;{\n    using type = T;\n};\nIf the std::remove_pointer metafunction receives int* as a parameter, the specialized version of the template kicks in, as int* is matched against T*. Here is the full implementation of std::remove_pointer&lt;T&gt;:\ntemplate &lt;class T&gt; struct remove_pointer                    { using type = T };\ntemplate &lt;class T&gt; struct remove_pointer&lt;T*&gt;                { using type = T };\ntemplate &lt;class T&gt; struct remove_pointer&lt;T* const&gt;          { using type = T };\ntemplate &lt;class T&gt; struct remove_pointer&lt;T* volatile&gt;       { using type = T };\ntemplate &lt;class T&gt; struct remove_pointer&lt;T* const volatile&gt; { using type = T };\nAs you can see, the same technique is applied to more subtle edge cases.\nHow about std::remove_reference?\ntemplate&lt;typename T&gt;\nstruct RemoveReference{\n    using type = T;\n};\n\n// template specialization\ntemplate&lt;typename T&gt;\nstruct RemoveReference&lt;T&&gt;{\n    using type = T;\n};\n\n// template specialization\ntemplate&lt;typename T&gt;\nstruct RemoveReference&lt;T&&&gt;{\n    using type = T;\n};\nBut, removing qualifiers from types is only the tip of the iceberg. How are std::enable_if and std::conditional implemented? Take a guess!\nThe type metafunction std::enable_if returns the type T, if the predicate B is true.\ntemplate &lt;bool B, typename T&gt;\nstruct EnableIf{};\n\ntemplate &lt;typename T&gt;\nstruct EnableIf&lt;true,T&gt;{\n    using type = T;\n};\nThe type metafunction std::conditional returns T, if the predicate B is true, otherwise returns F. It’s a compile-time if-else operating with types.\ntemplate &lt;bool B, typename T, typename F&gt;\nstruct Conditional{\n    using type = T;\n};\n\ntemplate &lt;typename T, typename F&gt;\nstruct Conditional&lt;false, T, F&gt;{\n    using type = F;\n};\nThe type metafunction std::remove_const removes any top-level const qualifier. It’s a transformation trait. Let’s look at the usage of this metafunction to ensure we handle all cases correctly.\nWe could try to implement it from scratch as follows:\n//Primary template : do nothing if there's no const\ntemplate&lt;typename T&gt;\nstruct RemoveConst : std::type_identity&lt;T&gt; {};\n\n//Partial specialization \ntemplate&lt;typename T&gt; struct RemoveConst&lt;T const&gt;{\n    using type = T;\n}\nand likewise for removing volatile.\ntemplate &lt;typename T&gt;\nstruct RemoveVolatile {\n    using Type = T;\n};\n\n// remove volatile\ntemplate &lt;typename T&gt;\nstruct RemoveVolatile&lt;volatile T&gt; {\n    using Type = T;\n};\nRemoveConst and RemoveVolatile can be composed into RemoveCV.\ntemplate &lt;typename T&gt;\nstruct RemoveCVT : RemoveConst&lt;RemoveVolatile&lt;T&gt;&gt; {};\nI hope you enjoyed the warm-up. Now, let’s try and implement std::decay from scratch."
  },
  {
    "objectID": "posts/type-traits-101/index.html#implementing-stddecay",
    "href": "posts/type-traits-101/index.html#implementing-stddecay",
    "title": "Type Traits 101",
    "section": "Implementing std::decay",
    "text": "Implementing std::decay\nSince C++11, std::decay was introduced into &lt;type_traits&gt;. It is used to decay a type, or to convert a type into it’s corresponding by-value type. It will remove any top-level cv-qualifiers (const, volatile) and reference qualifiers for the specified type. For example, int& is turned into int. An array type becomes a pointer to its element types. A function type becomes a pointer to the function.\n\nNon-Array and Non-function case\nWe handle the non-array and non-function cases first.\n// RemoveConst and RemoveVolatile can be composed into RemoveCV\ntemplate &lt;typename T&gt;\nstruct DecayT : RemoveCVT&lt;RemoveReference&lt;T&gt;&gt; {};\n\n\nArray-to-pointer decay\nNow, we take array types into account. Below are partial specialisations to convert an array type into a pointer to its element type:\n// unbounded array\ntemplate &lt;typename T&gt;\nstruct DecayT&lt;T[]&gt; {\n    using Type = T*;\n};\n\n// bounded array\ntemplate &lt;typename T, std::size_t N&gt;\nstruct DecayT&lt;T[N]&gt; {\n    using Type = T*;\n};\n\n\nFunction-to-pointer decay\nWe want to recognise a function regardless of its return type and parameter types, and then get its function pointer. Because there are different number of parameters, we need to employ variadic templates:\ntemplate &lt;typename Ret, typename...Args&gt;\nstruct DecayT&lt;Ret(Args...)&gt; {\n    using Type = Ret(*)(Args...);\n};"
  },
  {
    "objectID": "posts/type-traits-101/index.html#stdintegral_constant-metafunction",
    "href": "posts/type-traits-101/index.html#stdintegral_constant-metafunction",
    "title": "Type Traits 101",
    "section": "std::integral_constant metafunction",
    "text": "std::integral_constant metafunction\nThe std:integral_constant wraps a static constant of the specified type. It is a value meta-function. In fact, it is an identity meta-function, so that, std::integral_constant&lt;char,'a'&gt;::value returns a. It is also a type meta-function. Here’s a possible implementation:\ntemplate&lt;class T, T v&gt;\nstruct integral_constant\n{\n    static constexpr T value = v;\n    \n    using value_type = T;\n    \n    using type = integral_constant; // using injected-class-name\n    \n    constexpr operator value_type() const noexcept { return value; }\n    \n    constexpr value_type operator()() const noexcept { return value; } // since c++14\n};\nNow, std::true_type is simply the compile-time constant defined as std::integral_constant&lt;bool,true&gt;. std::false_type is the compile-time constant defined as std::integral_constant&lt;bool,false&gt;."
  },
  {
    "objectID": "posts/type-traits-101/index.html#stdis_same",
    "href": "posts/type-traits-101/index.html#stdis_same",
    "title": "Type Traits 101",
    "section": "std::is_same",
    "text": "std::is_same\nstd::is_same&lt;T1,T2&gt; is a comparison metafunction for types. We have a primary template:\n// Primary template\ntemplate&lt;typename T1, typename T2&gt;\nstruct is_same : std::false_type {};\nIt takes two types as arguments. If the two types are the same, we have the explicit specialisation:\n// Template metaprogramming \n// Mariusz Bancila \ntemplate&lt;typename T&gt;\nstruct is_same&lt;T,T&gt;{\n    using value = std::true_type;\n}\n\n// Convenience - variable template\ntemplate&lt;typename T1, typename T2&gt;\nconstexpr inline bool is_same_v = is_same&lt;T1,T2&gt;::value;\nNow, we can define is_floating_point as an alias template:\ntemplate&lt;class T&gt;\nusing is_floating_point = std::bool_constant&lt;\n         // Note: standard floating-point types\n         std::is_same&lt;float, typename std::remove_cv&lt;T&gt;::type&gt;::value\n         || std::is_same&lt;double, typename std::remove_cv&lt;T&gt;::type&gt;::value\n         || std::is_same&lt;long double, typename std::remove_cv&lt;T&gt;::type&gt;::value\n\n         // Note: extended floating-point types (C++23, if supported)\n         || std::is_same&lt;std::float16_t, typename std::remove_cv&lt;T&gt;::type&gt;::value\n         || std::is_same&lt;std::float32_t, typename std::remove_cv&lt;T&gt;::type&gt;::value\n         || std::is_same&lt;std::float64_t, typename std::remove_cv&lt;T&gt;::type&gt;::value\n         || std::is_same&lt;std::float128_t, typename std::remove_cv&lt;T&gt;::type&gt;::value\n         || std::is_same&lt;std::bfloat16_t, typename std::remove_cv&lt;T&gt;::type&gt;::value\n&gt;;"
  },
  {
    "objectID": "posts/type-traits-101/index.html#examples-of-using-type-traits",
    "href": "posts/type-traits-101/index.html#examples-of-using-type-traits",
    "title": "Type Traits 101",
    "section": "Examples of using type traits",
    "text": "Examples of using type traits\nConsider the below widget and gadget classes:\n#include &lt;array&gt;\n#include &lt;iterator&gt;\n#include &lt;iostream&gt;\n#include &lt;string&gt;\n\nstruct widget{\n    int id;\n    std::string name;\n\n    std::ostream& write(std::ostream& os) const{\n        os &lt;&lt; id &lt;&lt; std::endl;\n        return os;\n    }\n};\n\nstruct gadget{\n    int id;\n    std::string name;\n\n    friend std::ostream& operator&lt;&lt;(std::ostream& os, gadget const & g);\n};\n\nstd::ostream& operator&lt;&lt;(std::ostream& os, gadget const & g){\n    os &lt;&lt; g.id &lt;&lt; \",\" &lt;&lt; g.name &lt;&lt; \"\\n\";\n    return os;\n}\n\nint main(){\n    return 0;\n}\nCompiler Explorer\nThe widget class contains a member function write. However, for the gadget class, the stream operator &lt;&lt; is overloaded for the same purpose. We can write the following code using these classes:\nwidget w{1, \"one\"};\nw.write(std::cout);\n\ngagdet g{2, \"two\"}\nstd::cout &lt;&lt; g\nHowever, we want to write a function template that enables us to treat them the same way. In other words, instead of using either write or the &lt;&lt; operator, we should be able to write the following:\nserialize(std::cout, w);\nserialize(std::cout, g);\nHow would such a function template look? How can we know whether a type provides a write method or has the &lt;&lt; operator overloaded? In other words, we need to query if a type supports write. We can write our own type trait.\nLet’s write a type metafunction uses_write&lt;T&gt; which returns true, if T is widget and false otherwise.\ntemplate&lt;typename T&gt;\nstruct uses_write {\n    static inline constexpr bool value = false;\n};\n\ntemplate&lt;&gt;\nstruct uses_write&lt;widget&gt;{\n    static inline constexpr bool value = true;\n};\nNext, let’s assume for simplicity that types that don’t provide a write() member function always overload the output stream operator &lt;&lt;.\nI can write a primary template to handle the default case.\ntemplate&lt;bool B&gt;\nstruct serializer{\n\n    template&lt;typename T&gt;\n    static void serialize(std::ostream& os, T const & obj){\n        os &lt;&lt; obj;\n    }\n};\nI can specialize this template to handle the case where T supports write.\nstruct serializer&lt;true&gt;{\n\n    template&lt;typename T&gt;\n    static void serialize(std::ostream& os, T const & obj){\n        obj.write(os);\n    }\n};\nWe can now write a free-standing function serialize function, that calls the type-metafunction use_write&lt;T&gt; to determine which function to dispatch at compile-time.\ntemplate &lt;typename T&gt;\nvoid serialize(std::ostream& os, T const & obj){\n    serializer&lt;uses_write&lt;T&gt;::value&gt;::serialize(os, obj);\n}\nCompiler Explorer"
  },
  {
    "objectID": "posts/thread-safe-stack/index.html",
    "href": "posts/thread-safe-stack/index.html",
    "title": "Thread-Safe Stack Implementation",
    "section": "",
    "text": "We can use C++ synchronization primitives to implement a basic thread-safe stack and queue.\n\n\n\n\n#include &lt;iostream&gt;\n#include &lt;stack&gt;\n#include &lt;algorithm&gt;\n#include &lt;thread&gt;\n#include &lt;mutex&gt;\n#include &lt;memory&gt;\n#include &lt;type_traits&gt;\n#include &lt;concepts&gt;\n#include &lt;shared_mutex&gt;\n\nnamespace dev {\n   \n    template&lt;typename T&gt;\n    \n    class threadsafe_stack {\n    public:\n\n        using Mutex = std::shared_mutex;\n\n        /* Constructors */\n        \n        // Default constructor\n        threadsafe_stack() {}\n\n        /*\n        * This stack is copy-constructible. The copy constructor locks the mutex in the \n        * source object and then copies the internal stack.\n        */\n        threadsafe_stack(const threadsafe_stack& other) {\n            std::unique_lock&lt;Mutex&gt; lck(other.mtx);\n            m_stack = other.m_stack;\n        }\n\n        // Copy assignment\n        threadsafe_stack& operator=(const threadsafe_stack& other) = delete;\n\n        ~threadsafe_stack() = default;\n\n        /*\n        * pop() is a wrapper over std::stack&lt;T&gt;::top() and std::stack&lt;T&gt;::pop().\n        * This interface avoids any race conditions that occur between calls to top()\n        * and pop().\n        */\n        std::shared_ptr&lt;T&gt; pop()\n        {\n            std::unique_lock&lt;Mutex&gt; lck(mtx);\n            if (m_stack.empty())\n                throw std::exception(\"Exception - pop() invoked on an empty stack!\");\n\n            auto result = std::make_shared&lt;T&gt;(std::move(m_stack.top()));\n            m_stack.pop();\n            return result;\n        }\n\n        void pop(T& result)\n        {\n            std::unique_lock&lt;Mutex&gt; lck(mtx);\n            if (m_stack.empty())\n                throw std::exception(\"Exception - pop() invoked on an empty stack\");\n\n            result = std::move(m_stack.top());\n            m_stack.pop();\n        }\n\n        void push(T value)\n        {\n            std::unique_lock&lt;Mutex&gt; lck(mtx);\n            m_stack.push(std::move(value));\n        }\n\n        int size() {\n            std::shared_lock&lt;Mutex&gt; lck(mtx);\n            return m_stack.size();\n        }\n\n        /* \n        * Acquire a std::shared_lock&lt;Mtx&gt; on the mutex, so multiple\n        * readers can read the stack.\n        */\n        bool empty() {\n            std::shared_lock&lt;Mutex&gt; lck(mtx);\n            return m_stack.empty();\n        }\n\n    private:\n        std::stack&lt;T&gt; m_stack;\n        Mutex mtx;\n    };\n}\n\nint main()\n{\n    dev::threadsafe_stack&lt;int&gt; stck;\n    \n    std::thread writer1(\n        [&stck]() {\n            for (int i{ 1 };i &lt;= 1000;++i) {\n                stck.push(i);\n            }\n        }\n    );\n\n    std::thread writer2(\n        [&stck]() {\n            for (int i{ 1001 };i &lt;= 2000;++i) {\n                stck.push(i);\n            }\n        }\n    );\n\n    writer1.join();\n    writer2.join();\n\n    std::cout &lt;&lt; \"\\n\" &lt;&lt; \"Stack size = \" &lt;&lt; stck.size();\n}"
  },
  {
    "objectID": "posts/thread-safe-stack/index.html#thread-safe-stack",
    "href": "posts/thread-safe-stack/index.html#thread-safe-stack",
    "title": "Thread-Safe Stack Implementation",
    "section": "",
    "text": "#include &lt;iostream&gt;\n#include &lt;stack&gt;\n#include &lt;algorithm&gt;\n#include &lt;thread&gt;\n#include &lt;mutex&gt;\n#include &lt;memory&gt;\n#include &lt;type_traits&gt;\n#include &lt;concepts&gt;\n#include &lt;shared_mutex&gt;\n\nnamespace dev {\n   \n    template&lt;typename T&gt;\n    \n    class threadsafe_stack {\n    public:\n\n        using Mutex = std::shared_mutex;\n\n        /* Constructors */\n        \n        // Default constructor\n        threadsafe_stack() {}\n\n        /*\n        * This stack is copy-constructible. The copy constructor locks the mutex in the \n        * source object and then copies the internal stack.\n        */\n        threadsafe_stack(const threadsafe_stack& other) {\n            std::unique_lock&lt;Mutex&gt; lck(other.mtx);\n            m_stack = other.m_stack;\n        }\n\n        // Copy assignment\n        threadsafe_stack& operator=(const threadsafe_stack& other) = delete;\n\n        ~threadsafe_stack() = default;\n\n        /*\n        * pop() is a wrapper over std::stack&lt;T&gt;::top() and std::stack&lt;T&gt;::pop().\n        * This interface avoids any race conditions that occur between calls to top()\n        * and pop().\n        */\n        std::shared_ptr&lt;T&gt; pop()\n        {\n            std::unique_lock&lt;Mutex&gt; lck(mtx);\n            if (m_stack.empty())\n                throw std::exception(\"Exception - pop() invoked on an empty stack!\");\n\n            auto result = std::make_shared&lt;T&gt;(std::move(m_stack.top()));\n            m_stack.pop();\n            return result;\n        }\n\n        void pop(T& result)\n        {\n            std::unique_lock&lt;Mutex&gt; lck(mtx);\n            if (m_stack.empty())\n                throw std::exception(\"Exception - pop() invoked on an empty stack\");\n\n            result = std::move(m_stack.top());\n            m_stack.pop();\n        }\n\n        void push(T value)\n        {\n            std::unique_lock&lt;Mutex&gt; lck(mtx);\n            m_stack.push(std::move(value));\n        }\n\n        int size() {\n            std::shared_lock&lt;Mutex&gt; lck(mtx);\n            return m_stack.size();\n        }\n\n        /* \n        * Acquire a std::shared_lock&lt;Mtx&gt; on the mutex, so multiple\n        * readers can read the stack.\n        */\n        bool empty() {\n            std::shared_lock&lt;Mutex&gt; lck(mtx);\n            return m_stack.empty();\n        }\n\n    private:\n        std::stack&lt;T&gt; m_stack;\n        Mutex mtx;\n    };\n}\n\nint main()\n{\n    dev::threadsafe_stack&lt;int&gt; stck;\n    \n    std::thread writer1(\n        [&stck]() {\n            for (int i{ 1 };i &lt;= 1000;++i) {\n                stck.push(i);\n            }\n        }\n    );\n\n    std::thread writer2(\n        [&stck]() {\n            for (int i{ 1001 };i &lt;= 2000;++i) {\n                stck.push(i);\n            }\n        }\n    );\n\n    writer1.join();\n    writer2.join();\n\n    std::cout &lt;&lt; \"\\n\" &lt;&lt; \"Stack size = \" &lt;&lt; stck.size();\n}"
  },
  {
    "objectID": "posts/the_markov_property/index.html",
    "href": "posts/the_markov_property/index.html",
    "title": "The Markov Property",
    "section": "",
    "text": "Let’s start by exhibiting the Markov property of Brownian motion. To see this, consider \\((\\mathcal{F}_t,t\\geq 0)\\), the natural filtration of the Brownian motion \\((B_t,t\\geq 0)\\). Consider \\(g(B_t)\\) for some time \\(t\\) and bounded function \\(g\\). (For example, \\(g\\) could be an indicator function.) Consider also a random variable \\(W\\) that is \\(\\mathcal{F}_s\\) measurable for \\(s &lt; t\\). (For example, \\(W\\) could be \\(B_s\\) or \\(1_{B_s &gt; 0}\\).) Let’s compute \\(\\mathbb{E}[g(B_t)W]\\).\n\\[\\begin{align*}\n\\mathbb{E}[g(B_t)W] &= \\mathbb{E}[\\mathbb{E}[Wg(B_t - B_s + B_s)|\\mathcal{F}_s]]\n\\end{align*}\\]\nThe random variable \\((B_t - B_s)\\) follows a \\(\\mathcal{N}(0,t-s)\\) distribution. By LOTUS,\n\\[\n\\begin{align*}\n\\mathbb{E}[g(B_t)W]\n&= \\int_{\\mathbb{R}} \\mathbb{E}[W g(y + B_s)|\\mathcal{F_s}]f_{(B_t - B_s)|B_s}(y) dy\\\\\n&= \\{\\text{ Using the fact that }B_t - B_s \\perp B_s\\}\\\\\n&= \\int_{\\mathbb{R}} \\mathbb{E}[W g(y + B_s)]f_{(B_t - B_s)}(y)dy\\\\\n&= \\int_{\\mathbb{R}} \\mathbb{E}[W g(y + B_s)]\\frac{e^{-\\frac{y^2}{2(t-s)}}}{\\sqrt{2\\pi(t-s)}}dy\n\\end{align*}\n\\]\nBy Fubini’s theorem, the integral and the expectation operator can be interchanged, and since \\(W\\) is \\(\\mathcal{F}_s\\) measurable, it follows from the definition of conditional expectations that:\n\\[\n\\begin{align*}\n\\mathbb{E}[Wg(B_t)] = \\mathbb{E}[W\\mathbb{E}[g(B_t)|\\mathcal{F}_s]] = \\mathbb{E}\\left[W\\int_{\\mathbb{R}}g(y + B_s)]\\frac{e^{-\\frac{y^2}{2(t-s)}}}{\\sqrt{2\\pi(t-s)}}dy\\right]\n\\end{align*}\n\\]\nIt follows that:\n\\[\n\\begin{align*}\n\\mathbb{E}[g(B_t)|\\mathcal{F}_s] = \\int_{\\mathbb{R}}g(y + B_s)]\\frac{e^{-\\frac{y^2}{2(t-s)}}}{\\sqrt{2\\pi(t-s)}}dy\n\\end{align*}\n\\tag{1}\\]\nWe make two important observations. First, the right hand side is a function of \\(s,t\\) and \\(B_s\\) only (and not of the Brownian motion before time s). In particular, we have:\n\\[\n\\mathbb{E}[g(B_t)|\\mathcal{F}_s] = \\mathbb{E}[g(B_t)|B_s]\n\\]\nThis holds for any bounded function \\(g\\). In particular, it holds for all indicator functions. This implies that the conditional distribution of \\(B_t\\) given \\(\\mathcal{F}_s\\) depends solely on \\(B_s\\), and not on other values before time \\(s\\). Second, the right-hand side is time-homogenous in the sense that it depends on the time difference \\(t-s\\).\nWe have just shown that Brownian motion is a time-homogenous Markov process.\n\nDefinition 1 (Markov process.) Consider a stochastic process \\((X_t,t\\geq 0)\\) and its natural filtration \\((\\mathcal{F}_t,t\\geq 0)\\). It is said to be a Markov process if and only if for any (bounded) function \\(g: \\mathbb{R} \\to \\mathbb{R}\\), we have:\n\\[\n\\mathbb{E}[g(X_t) | \\mathcal{F}_s] = \\mathbb{E}[g(X_t) | X_s], \\quad \\forall t \\geq 0, \\forall s \\leq t\n\\tag{2}\\]\n\nThis implies that \\(\\mathbb{E}[g(X_t)|\\mathcal{F}_s]\\) is an explicit function of \\(s\\), \\(t\\) and \\(X_s\\). It is said to be time-homogenous, if it is a function of \\(t-s\\) and \\(X_s\\). Since the above holds for all bounded \\(g\\), the conditional distribution of \\(X_t\\) given \\(\\mathcal{F}_s\\) is the same as the conditional distribution of \\(X_t\\) given \\(X_s\\).\nOne way to compute the conditional distribution of \\(X_t\\) given \\(\\mathcal{F}_s\\) is to compute the conditional MGF given \\(\\mathcal{F}_s\\), that is:\n\\[\n\\mathbb{E}[e^{a X_t}|\\mathcal{F}_s], \\quad a \\geq 0\n\\tag{3}\\]\nThe process would be Markov, if the conditional MGF is an explicit function of \\(s\\), \\(t\\) and \\(X_s\\).\n\nExample 1 (Brownian Motion is Markov) Let \\((B_t,t\\geq 0)\\) be a standard brownian motion. Our claim is that the brownian motion is a markov process.\n\nProof.\nWe have:\n\\[\\begin{align*}\n\\mathbb{E}[e^{a B_t}|\\mathcal{F}_s] &= \\mathbb{E}[e^{a (B_t - B_s + B_s)}|\\mathcal{F}_s]\\\\\n& \\{ \\text{ since }B_s \\text{ is }\\mathcal{F}_s-\\text{ measurable }\\}\\\\\n&= e^{a B_s} \\mathbb{E}[e^{a (B_t - B_s)}|\\mathcal{F}_s]\\\\\n& \\{ \\text{ since }B_t - B_s \\perp \\mathcal{F}_s \\}\\\\\n&= e^{a B_s} \\mathbb{E}[e^{a (B_t - B_s)}]\\\\\n&= e^{a B_s} e^{\\frac{1}{2}a^2(t-s)}\n\\end{align*}\\]\nThis closes the proof. \\(\\blacksquare\\)\nAn equivalent (but more symmetric) way to express the Markov property is to say that the future of the process is independent of the past, when conditioned on the present. Concretely, this means that for any \\(r &lt; s&lt; t\\), we have that \\(X_t\\) is independent of \\(X_r\\), when we condition on \\(X_s\\).\nThe conditional distribution of \\(X_t\\) given \\(X_s\\) is well described using transition probabilities. We will more interested in a case well these probabilities admit a density \\(f_{X_t|X_s=x}(y)\\). More precisely, for such a Markov process, we have:\n\\[\n\\begin{align*}\n\\mathbb{E}[g(X_t)|X_s = x] &= \\int_{\\mathbb{R}} g(y) f_{X_t|X_s=x}(y) dy\\\\\n&=\\int_{\\mathbb{R}} g(y) p(y,t|x,s) dy\n\\end{align*}\n\\]\nHere, we explicitly write the left-hand side as a function of space, that is, the position \\(X_s\\), by fixing \\(X_s = x\\). In words, the transition probability density \\(p(y,t|x,s)\\) represents the probability density that starting from \\(X_s = x\\) at time \\(s\\), the process ends up at \\(X_t = y\\) at time \\(t &gt; s\\). If the process is time-homogenous, this only depends on the time difference \\((t-s)\\) and we write \\(p(y,t|x,s)\\). From Equation 1, we can write: \\[\n\\mathbb{E}[g(B_t)|B_s = x] = \\int_{\\mathbb{R}} g(u + x) \\frac{e^{-\\frac{u^2}{2(t-s)}}}{\\sqrt{2\\pi(t-s)}} du\n\\]\nIn the above expression, the random variable \\(B_t - B_s\\) takes some value \\(u \\in \\mathbb{R}\\) and \\(B_s = x\\) is fixed. Then, \\(B_t\\) takes the value \\(u + x\\). Let \\(y = u + x\\). Then, \\(u = y - x\\). Consequently, we may write:\n\\[\n\\mathbb{E}[g(B_t)|B_s = x] = \\int_{\\mathbb{R}} g(y) \\frac{e^{-\\frac{(y-x)^2}{2(t-s)}}}{\\sqrt{2\\pi(t-s)}} dy\n\\]\nSo, the transition density function for standard Brownian motion is:\n\\[\np(y,t|x,0)= \\frac{e^{-\\frac{(y-x)^2}{2s}}}{\\sqrt{2\\pi s}}, \\quad s&gt;0, x,y\\in\\mathbb{R}\n\\tag{4}\\]\nThis function is sometimes called the heat kernel, as it relates to the heat equation.\nThe Markov property is very convenient to compute quantities, as we shall see throughout the chapter. As a first example, we remark that it is easy to express joint probabilities of a markov process \\((X_t,t\\geq 0)\\) at different times. Consider the functions \\(f = \\mathbf{1}_A\\) and \\(g = \\mathbf{1}_B\\) from \\(\\mathbb{R} \\to \\mathbb{R}\\), where \\(A\\) and \\(B\\) are two intervals in \\(\\mathbb{R}\\). Let’s compute \\(\\mathbb{P}(X_{t_1} \\in A, X_{t_2} \\in B) = \\mathbb{E}[\\mathbf{1}_{A} \\mathbf{1}_{B}] = \\mathbb{E}[f(X_{t_1}) g(X_{t_2})]\\) for \\(t_1 &lt; t_2\\). By the properties of conditional expectation and the Markov property, we have:\n\\[\\begin{align*}\n\\mathbb{P}(X_{t_1} \\in A, X_{t_2} \\in B) &= \\mathbb{E}[f(X_{t_1})g(X_{t_2})]\\\\\n&= \\mathbb{E}[f(X_{t_1})\\mathbb{E}[g(X_{t_2})|\\mathcal{F}_{t_1}]]\\\\\n&= \\mathbb{E}[f(X_{t_1})\\mathbb{E}[g(X_{t_2})|X_{t_1}]]\n\\end{align*}\\]\nAssuming that the process is time-homogenous and admits a transition density \\(p(y,t|x,0)\\) as for Brownian motion, this becomes:\n\\[\\begin{align*}\n\\mathbb{P}(X_{t_1} \\in A, X_{t_2} \\in B) &= \\int_{\\mathbb{R}} f(x_1) \\left(\\int_{\\mathbb{R}} g(x_2) p(x_2,t_2|x_1,t_1) dx_2 \\right) p(x_1,t_1|x_0,0) dx_1\\\\\n&= \\int_{A} \\left(\\int_{B} p(x_2,t_2|x_1,t_1) dx_2 \\right) p(x_1,t_1|x_0,0) dx_1\n\\end{align*}\\]\nThis easily generalizes to any finite-dimensional distribution of \\((X_t, t\\geq 0)\\).\n\nExample 2 (Markov versus Martingale.) Martingales are not markov processes in general and markov processes are not martingales in general. There are processes such as brownian motion that enjoy both. An example of a markov process that is not a martingale is a Brownian motion with a drift \\((X_t, t \\geq 0)\\), where \\(X_t = \\sigma B_t + \\mu t\\). Conversely, take \\(Y_t = \\int_0^t X_s dB_s\\), where \\(X_s = \\int_0^s B_u dB_u\\). The integrand \\(X_s\\) depends on whole Brownian motion path upto time \\(s\\) and not just on \\(B_s\\).\n\n\n\n\n\n\n\nFunctions of Markov Processes\n\n\n\nIt might be tempting to think that if \\((X_t,t\\geq 0)\\) is a Markov process, then the process defined by \\(Y_t = f(X_t)\\) for some reasonable function \\(f\\) is also Markov. Indeed, one could hope to write for an arbitrary bounded function \\(g\\):\n\\[\n\\begin{align*}\n\\mathbb{E}[g(Y_t)|\\mathcal{F}_s] = \\mathbb{E}[g(f(X_t))|\\mathcal{F}_s] = \\mathbb{E}[g(f(X_t))|\\mathcal{X}_s]\n\\end{align*}\n\\tag{5}\\]\nby using the Markov property of \\((X_t,t\\geq 0)\\). The flaw in this reasoning is that the Markov property should hold for the natural fitration \\((\\mathcal{F}_t^Y,t\\geq 0)\\) of the process \\((Y_t,t\\geq 0)\\) and not the one of \\((X_t,t\\geq 0)\\), \\((\\mathcal{F}_t^X,t\\geq 0)\\). It might be that the filtration \\((\\mathcal{F}_t^Y,t\\geq 0)\\) has less information that \\((\\mathcal{F}_t^X,t\\geq 0)\\), especially, if the function \\(f\\) is not one-to-one. For example, if \\(f(x)=x^2\\), then \\(\\mathcal{F}_t^Y\\) has less information than \\(\\mathcal{F}_t^X\\) as we cannot recover the sign of \\(X_t\\) knowing \\(Y_t\\). In other words, the second equality may not hold. In some cases, a function of a Brownian motion might be Markov, even when \\(f\\) is not one-to-one.\n\n\nIt turns out that diffusions such as the Ornstein-Uhlenbeck process and the Brownian bridge are Markov processes.\n\nTheorem 1 (Diffusions are Markov processes.) Let \\((B_t,t\\geq 0)\\) be a standard Brownian motion. Let \\(\\mu : \\mathbb{R} \\to \\mathbb{R}\\) and \\(\\sigma: \\mathbb{R} \\to \\mathbb{R}\\) be differentiable functions with bounded derivatives on \\([0,T]\\). Then, the diffusion with the SDE\n\\[\ndX_t = \\mu(X_t) dt + \\sigma(X_t)dB_t, \\quad X_0 = x_0\n\\]\ndefines a time-homogenous markov process on \\([0,T]\\).\n\nAn analogous statement holds for time-inhomogenous diffusions. The proof is generalization of the Markov property of Brownian motion. We take advantage of the independence of Brownian increments.\nProof.\nBy the existence and uniqueness theorem, this stochastic initial value problem(SIVP) defines a unique continous adapted process \\((X_t,t\\leq T)\\). Let \\((\\mathcal{F}_t^X,t\\geq 0)\\) be the natural filtration of \\((X_t,t\\leq T)\\). For a fixed \\(t &gt; 0\\), consider the process \\(W_s = B_{t+s} - B_t, s \\geq 0\\). Let \\((\\mathcal{F}_t,t \\geq 0)\\) be the natural filtration of \\((B_t,t \\geq 0)\\). It turns out that the process \\((W_s,s \\geq 0)\\) is a standard brownian motion independent of \\(\\mathcal{F}_t\\) (Exercise 1). For \\(s \\geq 0\\), we consider the SDE:\n\\[\ndY_s = \\mu (Y_s) ds + \\sigma(Y_s) dW_s, \\quad Y_0 = X_t\n\\]\nAgain by the existence and uniqueness theorem, there exists a unique solution to the SIVP that is adapted to the natural filtration of \\(W\\). Note that, the shifted process \\((X_{t+s},s\\geq 0)\\) is the solution to this SIVP since:\n\\[\\begin{align*}\nX_{t+s} &= X_{t} + \\int_{t}^{t+s}\\mu(X_u) du + \\int_{t}^{t+s}\\sigma(X_u) dB_u\n\\end{align*}\\]\nPerform a change of variable \\(v = u - t\\). Then, \\(dv = du\\), \\(dB_u = B(u_2) - B(u_1)= B(t + v_2) - B(t + v_1) = W(v_2) - W(v_1) = dW_v\\). So,\n\\[\\begin{align*}\nX_{t+s} &= X_{t} + \\int_{0}^{s}\\mu(X_{t+v}) dv + \\int_{0}^{s}\\sigma(X_{t+v}) dW_v\n\\end{align*}\\]\nLet \\(Y_v= X_{t+v}\\), \\(Y_0 = X_t\\). Then,\n\\[\\begin{align*}\nY_s &= Y_0 + \\int_{0}^{s}\\mu(Y_v) dv + \\int_{0}^{s}\\sigma(Y_v) dW_v\n\\end{align*}\\]\nThus, we conclude that for any interval \\(A\\):\n\\[\n\\mathbb{P}(X_{t+s} \\in A|\\mathcal{F}_t^X) = \\mathbb{P}(Y_s \\in A | \\mathcal{F}_t^X)\n\\]\nBut, since \\((Y_s,s \\geq 0)\\) depends on \\(\\mathcal{F}_t^X\\) only through \\(X_t\\) (because \\((W_s,s \\geq 0)\\) is independent of \\(\\mathcal{F}_t\\)), we conclude that \\(\\mathbb{P}(X_{t+s} \\in A|\\mathcal{F}_t^X) = \\mathbb{P}(X_{t+s} \\in A|X_t)\\), so \\((X_t,t \\geq 0)\\) is a time-homogenous markov process. \\(\\blacksquare\\)"
  },
  {
    "objectID": "posts/the_markov_property/index.html#the-markov-property-for-diffusions",
    "href": "posts/the_markov_property/index.html#the-markov-property-for-diffusions",
    "title": "The Markov Property",
    "section": "",
    "text": "Let’s start by exhibiting the Markov property of Brownian motion. To see this, consider \\((\\mathcal{F}_t,t\\geq 0)\\), the natural filtration of the Brownian motion \\((B_t,t\\geq 0)\\). Consider \\(g(B_t)\\) for some time \\(t\\) and bounded function \\(g\\). (For example, \\(g\\) could be an indicator function.) Consider also a random variable \\(W\\) that is \\(\\mathcal{F}_s\\) measurable for \\(s &lt; t\\). (For example, \\(W\\) could be \\(B_s\\) or \\(1_{B_s &gt; 0}\\).) Let’s compute \\(\\mathbb{E}[g(B_t)W]\\).\n\\[\\begin{align*}\n\\mathbb{E}[g(B_t)W] &= \\mathbb{E}[\\mathbb{E}[Wg(B_t - B_s + B_s)|\\mathcal{F}_s]]\n\\end{align*}\\]\nThe random variable \\((B_t - B_s)\\) follows a \\(\\mathcal{N}(0,t-s)\\) distribution. By LOTUS,\n\\[\n\\begin{align*}\n\\mathbb{E}[g(B_t)W]\n&= \\int_{\\mathbb{R}} \\mathbb{E}[W g(y + B_s)|\\mathcal{F_s}]f_{(B_t - B_s)|B_s}(y) dy\\\\\n&= \\{\\text{ Using the fact that }B_t - B_s \\perp B_s\\}\\\\\n&= \\int_{\\mathbb{R}} \\mathbb{E}[W g(y + B_s)]f_{(B_t - B_s)}(y)dy\\\\\n&= \\int_{\\mathbb{R}} \\mathbb{E}[W g(y + B_s)]\\frac{e^{-\\frac{y^2}{2(t-s)}}}{\\sqrt{2\\pi(t-s)}}dy\n\\end{align*}\n\\]\nBy Fubini’s theorem, the integral and the expectation operator can be interchanged, and since \\(W\\) is \\(\\mathcal{F}_s\\) measurable, it follows from the definition of conditional expectations that:\n\\[\n\\begin{align*}\n\\mathbb{E}[Wg(B_t)] = \\mathbb{E}[W\\mathbb{E}[g(B_t)|\\mathcal{F}_s]] = \\mathbb{E}\\left[W\\int_{\\mathbb{R}}g(y + B_s)]\\frac{e^{-\\frac{y^2}{2(t-s)}}}{\\sqrt{2\\pi(t-s)}}dy\\right]\n\\end{align*}\n\\]\nIt follows that:\n\\[\n\\begin{align*}\n\\mathbb{E}[g(B_t)|\\mathcal{F}_s] = \\int_{\\mathbb{R}}g(y + B_s)]\\frac{e^{-\\frac{y^2}{2(t-s)}}}{\\sqrt{2\\pi(t-s)}}dy\n\\end{align*}\n\\tag{1}\\]\nWe make two important observations. First, the right hand side is a function of \\(s,t\\) and \\(B_s\\) only (and not of the Brownian motion before time s). In particular, we have:\n\\[\n\\mathbb{E}[g(B_t)|\\mathcal{F}_s] = \\mathbb{E}[g(B_t)|B_s]\n\\]\nThis holds for any bounded function \\(g\\). In particular, it holds for all indicator functions. This implies that the conditional distribution of \\(B_t\\) given \\(\\mathcal{F}_s\\) depends solely on \\(B_s\\), and not on other values before time \\(s\\). Second, the right-hand side is time-homogenous in the sense that it depends on the time difference \\(t-s\\).\nWe have just shown that Brownian motion is a time-homogenous Markov process.\n\nDefinition 1 (Markov process.) Consider a stochastic process \\((X_t,t\\geq 0)\\) and its natural filtration \\((\\mathcal{F}_t,t\\geq 0)\\). It is said to be a Markov process if and only if for any (bounded) function \\(g: \\mathbb{R} \\to \\mathbb{R}\\), we have:\n\\[\n\\mathbb{E}[g(X_t) | \\mathcal{F}_s] = \\mathbb{E}[g(X_t) | X_s], \\quad \\forall t \\geq 0, \\forall s \\leq t\n\\tag{2}\\]\n\nThis implies that \\(\\mathbb{E}[g(X_t)|\\mathcal{F}_s]\\) is an explicit function of \\(s\\), \\(t\\) and \\(X_s\\). It is said to be time-homogenous, if it is a function of \\(t-s\\) and \\(X_s\\). Since the above holds for all bounded \\(g\\), the conditional distribution of \\(X_t\\) given \\(\\mathcal{F}_s\\) is the same as the conditional distribution of \\(X_t\\) given \\(X_s\\).\nOne way to compute the conditional distribution of \\(X_t\\) given \\(\\mathcal{F}_s\\) is to compute the conditional MGF given \\(\\mathcal{F}_s\\), that is:\n\\[\n\\mathbb{E}[e^{a X_t}|\\mathcal{F}_s], \\quad a \\geq 0\n\\tag{3}\\]\nThe process would be Markov, if the conditional MGF is an explicit function of \\(s\\), \\(t\\) and \\(X_s\\).\n\nExample 1 (Brownian Motion is Markov) Let \\((B_t,t\\geq 0)\\) be a standard brownian motion. Our claim is that the brownian motion is a markov process.\n\nProof.\nWe have:\n\\[\\begin{align*}\n\\mathbb{E}[e^{a B_t}|\\mathcal{F}_s] &= \\mathbb{E}[e^{a (B_t - B_s + B_s)}|\\mathcal{F}_s]\\\\\n& \\{ \\text{ since }B_s \\text{ is }\\mathcal{F}_s-\\text{ measurable }\\}\\\\\n&= e^{a B_s} \\mathbb{E}[e^{a (B_t - B_s)}|\\mathcal{F}_s]\\\\\n& \\{ \\text{ since }B_t - B_s \\perp \\mathcal{F}_s \\}\\\\\n&= e^{a B_s} \\mathbb{E}[e^{a (B_t - B_s)}]\\\\\n&= e^{a B_s} e^{\\frac{1}{2}a^2(t-s)}\n\\end{align*}\\]\nThis closes the proof. \\(\\blacksquare\\)\nAn equivalent (but more symmetric) way to express the Markov property is to say that the future of the process is independent of the past, when conditioned on the present. Concretely, this means that for any \\(r &lt; s&lt; t\\), we have that \\(X_t\\) is independent of \\(X_r\\), when we condition on \\(X_s\\).\nThe conditional distribution of \\(X_t\\) given \\(X_s\\) is well described using transition probabilities. We will more interested in a case well these probabilities admit a density \\(f_{X_t|X_s=x}(y)\\). More precisely, for such a Markov process, we have:\n\\[\n\\begin{align*}\n\\mathbb{E}[g(X_t)|X_s = x] &= \\int_{\\mathbb{R}} g(y) f_{X_t|X_s=x}(y) dy\\\\\n&=\\int_{\\mathbb{R}} g(y) p(y,t|x,s) dy\n\\end{align*}\n\\]\nHere, we explicitly write the left-hand side as a function of space, that is, the position \\(X_s\\), by fixing \\(X_s = x\\). In words, the transition probability density \\(p(y,t|x,s)\\) represents the probability density that starting from \\(X_s = x\\) at time \\(s\\), the process ends up at \\(X_t = y\\) at time \\(t &gt; s\\). If the process is time-homogenous, this only depends on the time difference \\((t-s)\\) and we write \\(p(y,t|x,s)\\). From Equation 1, we can write: \\[\n\\mathbb{E}[g(B_t)|B_s = x] = \\int_{\\mathbb{R}} g(u + x) \\frac{e^{-\\frac{u^2}{2(t-s)}}}{\\sqrt{2\\pi(t-s)}} du\n\\]\nIn the above expression, the random variable \\(B_t - B_s\\) takes some value \\(u \\in \\mathbb{R}\\) and \\(B_s = x\\) is fixed. Then, \\(B_t\\) takes the value \\(u + x\\). Let \\(y = u + x\\). Then, \\(u = y - x\\). Consequently, we may write:\n\\[\n\\mathbb{E}[g(B_t)|B_s = x] = \\int_{\\mathbb{R}} g(y) \\frac{e^{-\\frac{(y-x)^2}{2(t-s)}}}{\\sqrt{2\\pi(t-s)}} dy\n\\]\nSo, the transition density function for standard Brownian motion is:\n\\[\np(y,t|x,0)= \\frac{e^{-\\frac{(y-x)^2}{2s}}}{\\sqrt{2\\pi s}}, \\quad s&gt;0, x,y\\in\\mathbb{R}\n\\tag{4}\\]\nThis function is sometimes called the heat kernel, as it relates to the heat equation.\nThe Markov property is very convenient to compute quantities, as we shall see throughout the chapter. As a first example, we remark that it is easy to express joint probabilities of a markov process \\((X_t,t\\geq 0)\\) at different times. Consider the functions \\(f = \\mathbf{1}_A\\) and \\(g = \\mathbf{1}_B\\) from \\(\\mathbb{R} \\to \\mathbb{R}\\), where \\(A\\) and \\(B\\) are two intervals in \\(\\mathbb{R}\\). Let’s compute \\(\\mathbb{P}(X_{t_1} \\in A, X_{t_2} \\in B) = \\mathbb{E}[\\mathbf{1}_{A} \\mathbf{1}_{B}] = \\mathbb{E}[f(X_{t_1}) g(X_{t_2})]\\) for \\(t_1 &lt; t_2\\). By the properties of conditional expectation and the Markov property, we have:\n\\[\\begin{align*}\n\\mathbb{P}(X_{t_1} \\in A, X_{t_2} \\in B) &= \\mathbb{E}[f(X_{t_1})g(X_{t_2})]\\\\\n&= \\mathbb{E}[f(X_{t_1})\\mathbb{E}[g(X_{t_2})|\\mathcal{F}_{t_1}]]\\\\\n&= \\mathbb{E}[f(X_{t_1})\\mathbb{E}[g(X_{t_2})|X_{t_1}]]\n\\end{align*}\\]\nAssuming that the process is time-homogenous and admits a transition density \\(p(y,t|x,0)\\) as for Brownian motion, this becomes:\n\\[\\begin{align*}\n\\mathbb{P}(X_{t_1} \\in A, X_{t_2} \\in B) &= \\int_{\\mathbb{R}} f(x_1) \\left(\\int_{\\mathbb{R}} g(x_2) p(x_2,t_2|x_1,t_1) dx_2 \\right) p(x_1,t_1|x_0,0) dx_1\\\\\n&= \\int_{A} \\left(\\int_{B} p(x_2,t_2|x_1,t_1) dx_2 \\right) p(x_1,t_1|x_0,0) dx_1\n\\end{align*}\\]\nThis easily generalizes to any finite-dimensional distribution of \\((X_t, t\\geq 0)\\).\n\nExample 2 (Markov versus Martingale.) Martingales are not markov processes in general and markov processes are not martingales in general. There are processes such as brownian motion that enjoy both. An example of a markov process that is not a martingale is a Brownian motion with a drift \\((X_t, t \\geq 0)\\), where \\(X_t = \\sigma B_t + \\mu t\\). Conversely, take \\(Y_t = \\int_0^t X_s dB_s\\), where \\(X_s = \\int_0^s B_u dB_u\\). The integrand \\(X_s\\) depends on whole Brownian motion path upto time \\(s\\) and not just on \\(B_s\\).\n\n\n\n\n\n\n\nFunctions of Markov Processes\n\n\n\nIt might be tempting to think that if \\((X_t,t\\geq 0)\\) is a Markov process, then the process defined by \\(Y_t = f(X_t)\\) for some reasonable function \\(f\\) is also Markov. Indeed, one could hope to write for an arbitrary bounded function \\(g\\):\n\\[\n\\begin{align*}\n\\mathbb{E}[g(Y_t)|\\mathcal{F}_s] = \\mathbb{E}[g(f(X_t))|\\mathcal{F}_s] = \\mathbb{E}[g(f(X_t))|\\mathcal{X}_s]\n\\end{align*}\n\\tag{5}\\]\nby using the Markov property of \\((X_t,t\\geq 0)\\). The flaw in this reasoning is that the Markov property should hold for the natural fitration \\((\\mathcal{F}_t^Y,t\\geq 0)\\) of the process \\((Y_t,t\\geq 0)\\) and not the one of \\((X_t,t\\geq 0)\\), \\((\\mathcal{F}_t^X,t\\geq 0)\\). It might be that the filtration \\((\\mathcal{F}_t^Y,t\\geq 0)\\) has less information that \\((\\mathcal{F}_t^X,t\\geq 0)\\), especially, if the function \\(f\\) is not one-to-one. For example, if \\(f(x)=x^2\\), then \\(\\mathcal{F}_t^Y\\) has less information than \\(\\mathcal{F}_t^X\\) as we cannot recover the sign of \\(X_t\\) knowing \\(Y_t\\). In other words, the second equality may not hold. In some cases, a function of a Brownian motion might be Markov, even when \\(f\\) is not one-to-one.\n\n\nIt turns out that diffusions such as the Ornstein-Uhlenbeck process and the Brownian bridge are Markov processes.\n\nTheorem 1 (Diffusions are Markov processes.) Let \\((B_t,t\\geq 0)\\) be a standard Brownian motion. Let \\(\\mu : \\mathbb{R} \\to \\mathbb{R}\\) and \\(\\sigma: \\mathbb{R} \\to \\mathbb{R}\\) be differentiable functions with bounded derivatives on \\([0,T]\\). Then, the diffusion with the SDE\n\\[\ndX_t = \\mu(X_t) dt + \\sigma(X_t)dB_t, \\quad X_0 = x_0\n\\]\ndefines a time-homogenous markov process on \\([0,T]\\).\n\nAn analogous statement holds for time-inhomogenous diffusions. The proof is generalization of the Markov property of Brownian motion. We take advantage of the independence of Brownian increments.\nProof.\nBy the existence and uniqueness theorem, this stochastic initial value problem(SIVP) defines a unique continous adapted process \\((X_t,t\\leq T)\\). Let \\((\\mathcal{F}_t^X,t\\geq 0)\\) be the natural filtration of \\((X_t,t\\leq T)\\). For a fixed \\(t &gt; 0\\), consider the process \\(W_s = B_{t+s} - B_t, s \\geq 0\\). Let \\((\\mathcal{F}_t,t \\geq 0)\\) be the natural filtration of \\((B_t,t \\geq 0)\\). It turns out that the process \\((W_s,s \\geq 0)\\) is a standard brownian motion independent of \\(\\mathcal{F}_t\\) (Exercise 1). For \\(s \\geq 0\\), we consider the SDE:\n\\[\ndY_s = \\mu (Y_s) ds + \\sigma(Y_s) dW_s, \\quad Y_0 = X_t\n\\]\nAgain by the existence and uniqueness theorem, there exists a unique solution to the SIVP that is adapted to the natural filtration of \\(W\\). Note that, the shifted process \\((X_{t+s},s\\geq 0)\\) is the solution to this SIVP since:\n\\[\\begin{align*}\nX_{t+s} &= X_{t} + \\int_{t}^{t+s}\\mu(X_u) du + \\int_{t}^{t+s}\\sigma(X_u) dB_u\n\\end{align*}\\]\nPerform a change of variable \\(v = u - t\\). Then, \\(dv = du\\), \\(dB_u = B(u_2) - B(u_1)= B(t + v_2) - B(t + v_1) = W(v_2) - W(v_1) = dW_v\\). So,\n\\[\\begin{align*}\nX_{t+s} &= X_{t} + \\int_{0}^{s}\\mu(X_{t+v}) dv + \\int_{0}^{s}\\sigma(X_{t+v}) dW_v\n\\end{align*}\\]\nLet \\(Y_v= X_{t+v}\\), \\(Y_0 = X_t\\). Then,\n\\[\\begin{align*}\nY_s &= Y_0 + \\int_{0}^{s}\\mu(Y_v) dv + \\int_{0}^{s}\\sigma(Y_v) dW_v\n\\end{align*}\\]\nThus, we conclude that for any interval \\(A\\):\n\\[\n\\mathbb{P}(X_{t+s} \\in A|\\mathcal{F}_t^X) = \\mathbb{P}(Y_s \\in A | \\mathcal{F}_t^X)\n\\]\nBut, since \\((Y_s,s \\geq 0)\\) depends on \\(\\mathcal{F}_t^X\\) only through \\(X_t\\) (because \\((W_s,s \\geq 0)\\) is independent of \\(\\mathcal{F}_t\\)), we conclude that \\(\\mathbb{P}(X_{t+s} \\in A|\\mathcal{F}_t^X) = \\mathbb{P}(X_{t+s} \\in A|X_t)\\), so \\((X_t,t \\geq 0)\\) is a time-homogenous markov process. \\(\\blacksquare\\)"
  },
  {
    "objectID": "posts/the_markov_property/index.html#the-strong-markov-property",
    "href": "posts/the_markov_property/index.html#the-strong-markov-property",
    "title": "The Markov Property",
    "section": "The Strong Markov Property",
    "text": "The Strong Markov Property\nThe Doob’s Optional Stopping theorem extended some properties of martingales to stopping times. The Markov property can also be extended to stopping times for certain processes. These processes are called strong Markov processes.\nWe know, that the sigma-algebra \\(\\mathcal{F}_t\\) represents the set of all observable events upto time \\(t\\). What is the sigma-algebra of observable events at a random stopping time \\(\\tau\\)?\n\nDefinition 2 (\\(\\sigma\\)-algebra of \\(\\tau\\)-past) Let \\((\\Omega,\\mathcal{F},\\{\\mathcal{F}_t\\}_{t\\geq 0},\\mathbb{P})\\) be a filtered probability space. The sigma-algebra at the stopping time \\(\\tau\\) is then:\n\\[\n\\mathcal{F}_{\\tau} = \\{A \\in \\mathcal{F}_\\infty : A \\cap \\{\\tau \\leq t\\} \\in \\mathcal{F}_t, \\forall t \\geq 0 \\}\n\\tag{6}\\]\n\nIn words, an event \\(A\\) is in \\(\\mathcal{F}_\\tau\\), if we can determine if \\(A\\) and \\(\\{\\tau \\leq t\\}\\) both occurred or not based on the information \\(\\mathcal{F}_t\\) known at any arbitrary time \\(t\\). You should be able to tell the value of the random variable \\(\\mathbf{1}_A \\cdot \\mathbf{1}_{\\{\\tau \\leq t\\}}\\) given \\(\\mathcal{F}_t\\) for any arbitrary time \\(t \\geq 0\\).\nFor example, if \\(\\tau &lt; \\infty\\), the event \\(\\{B_\\tau &gt; 0\\}\\) is in \\(\\mathcal{F}_\\tau\\). However, the event \\(\\{B_1 &gt; 0\\}\\) is not in \\(\\mathcal{F}_\\tau\\) in general, since \\(A \\cap \\{\\tau \\leq t\\}\\) is not in \\(\\mathcal{F}_t\\) for \\(t &lt; 1\\). Roughly speaking, a random variable that is \\(\\mathcal{F}_\\tau\\)-measurable should be thought of as an explicit function of \\(X_\\tau\\). With this new object, we are ready to define the strong markov property.\n\nDefinition 3 (Strong Markov Property) Let \\((X_t,t\\geq 0)\\) be a stochastic process and let \\((\\mathcal{F}_t,t\\geq 0)\\) be its natural filtration. The process \\((X_t,t\\geq 0)\\) is said to be strong markov if for any stopping time \\(\\tau\\) for the filtration of the process and any bounded function \\(g\\):\n\\[\n\\mathbb{E}[g(X_{t+\\tau})|\\mathcal{F}_\\tau] = \\mathbb{E}[g(X_{t+\\tau})|X_\\tau]\n\\]\n\nThis means that \\(X_{t+\\tau}\\) depends on \\(\\mathcal{F}_\\tau\\) solely through \\(X_\\tau\\) (whenever \\(\\tau &lt; \\infty\\)). It turns out that Brownian motion is a strong markov process. In fact a stronger statement holds which generalizes Exercise 1.\n\nTheorem 2 Let \\(\\tau\\) be a stopping time for the filtration of the Brownian motion \\((B_t,t\\geq 0)\\) such that \\(\\tau &lt; \\infty\\). Then, the process:\n\\[\n(B_{t+\\tau} - B_{\\tau},t\\geq 0)\n\\]\nis a standard brownian motion independent of \\(\\mathcal{F}_\\tau\\).\n\n\nExample 3 (Brownian motion is strong Markov) To see this, let’s compute the conditional MGF as in Equation 3. We have:\n\\[\n\\begin{align*}\n\\mathbb{E}[e^{aB_{t+\\tau}}|\\mathcal{F}_\\tau] &= \\mathbb{E}[e^{a(B_{t+\\tau} - B_\\tau + B_\\tau)}|\\mathcal{F}_\\tau]\\\\\n&= e^{aB_\\tau} \\mathbb{E}[e^{a(B_{t+\\tau} - B_\\tau)}|\\mathcal{F}_\\tau]\\\\\n& \\{ B_\\tau \\text{ is }\\mathcal{F}_\\tau-\\text{measurable }\\}\\\\\n&= e^{aB_\\tau}\\mathbb{E}[e^{a(B_{t+\\tau} - B_\\tau)}]\\\\\n& \\{ (B_{t+\\tau} - B_\\tau) \\perp \\mathcal{F}_\\tau\\}\\\\\n&= e^{aB_\\tau}e^{\\frac{1}{2}a^2 t}\\\\\n\\end{align*}\n\\]\nThus, the conditional MGF is an explicit function of \\(B_\\tau\\) and \\(t\\). This proves the proposition. \\(\\blacksquare\\)\n\nProof of Theorem 2.\nWe first consider for fixed \\(n\\) the discrete valued stopping time:\n\\[\n\\tau_n = \\frac{k + 1}{2^n}, \\quad \\text{ if } \\frac{k}{2^n} \\leq \\tau &lt; \\frac{k+1}{2^n}, k\\in \\mathbb{N}\n\\]\nIn other words, if \\(\\tau\\) occurs in the interval \\([\\frac{k}{2^n},\\frac{k+1}{2^n})\\), we stop at the next dyadic \\(\\frac{k+1}{2^n}\\). By construction \\(\\tau_n\\) depends only on the process in the past. Consider the process \\(W_t = B_{t + \\tau_n} - B_{\\tau_n}, t \\geq 0\\). We show it is a standard brownian motion independent of \\(\\tau_n\\). This is feasible as we can decompose over the discrete values taken by \\(\\tau_n\\). More, precisely, take \\(E \\in \\mathcal{F}_{\\tau_n}\\), and some generic event \\(\\{W_t \\in A\\}\\) for the process \\(W\\). Then, by decomposing over the values of \\(\\tau_n\\), we have:\n\\[\n\\begin{align*}\n\\mathbb{P}(\\{W_t \\in A\\} \\cap E) &= \\sum_{k=0}^\\infty \\mathbb{P}\\left(\\{W_t \\in A\\} \\cap E \\cap \\{\\tau_n = \\frac{k}{2^n}\\}\\right)\\\\\n&= \\sum_{k=0}^\\infty \\mathbb{P}\\left(\\{(B_{t+k/2^n} - B_{k/2^n}) \\in A\\} \\cap E \\cap \\{\\tau_n = \\frac{k}{2^n}\\}\\right)\\\\\n&= \\sum_{k=0}^\\infty \\mathbb{P}\\left(\\{(B_{t+k/2^n} - B_{k/2^n}) \\in A\\}\\right) \\times \\mathbb{P}\\left( E \\cap \\{\\tau_n = \\frac{k}{2^n}\\}\\right)\n\\end{align*}\n\\]\nsince \\((B_{t+k/2^n} - B_{k/2^n})\\) is independent of \\(\\mathcal{F}_{k/2^n}\\) by Exercise 1 and since \\(E \\cap \\{\\tau_n = \\frac{k}{2^n}\\} \\in \\mathcal{F}_{k/2^n}\\) by definition of stopping time. But, given \\(\\{\\tau_n = k/2^n\\}\\), the event \\(\\{(B_{t+k/2^n} - B_{k/2^n}) \\in A\\}\\) is the same as \\(\\{B_t \\in A\\} = \\{W_t \\in A\\}\\), since this process is now a standard brownian motion. Thus, \\(\\mathbb{P}\\{(B_{t+k/2^n} - B_{k/2^n}) \\in A\\} = \\mathbb{P}\\{B_t \\in A\\} = \\mathbb{P}\\{W_t \\in A\\}\\), dropping the dependence on \\(k\\). The sum over \\(k\\) then yields:\n\\[\n\\mathbb{P}\\left(\\{W_t \\in A\\}\\cap E\\right) = \\mathbb{P}(W_t \\in A) \\mathbb{P}(E)\n\\]\nas claimed. The extension to \\(\\tau\\) is done by using continuity of paths. We have:\n\\[\n\\lim_{n \\to \\infty} B_{t + \\tau_n} - B_{\\tau_n} = B_{t+\\tau} - B_{\\tau} \\text{ almost surely}\n\\]\nNote, that this only uses right continuity! Moreover, this implies that \\(B_{t+\\tau} - B_\\tau\\) is independent of \\(\\mathcal{F}_{\\tau_n}\\) for all \\(n\\). Again by (right-)continuity this extends to independence of \\(\\mathcal{F}_\\tau\\). The limiting distribution of the process is obtained by looking at the finite dimensional distributions of the increments of \\(B_{t+\\tau_n} - B_{\\tau_n}\\) for a finite number of \\(t\\)’s and taking the limit as above. \\(\\blacksquare\\)\nMost diffusions also enjoy the strong markov property, as long as the functions \\(\\sigma\\) and \\(\\mu\\) encoding the volatility and drift are nice enough. This is the case for the diffusions we have considered.\n\nTheorem 3 (Most diffusions are strong markov) Consider a diffusion \\((X_t,t\\leq T)\\) as as in Theorem 1. Then, the diffusion has strong markov property.\n\nThe proof follows the line of the one of Theorem 1\nProof.\nConsider the time-homogenous diffusion:\n\\[\ndX_t = \\mu(X_t)dt + \\sigma(X_t)dB_t\n\\]\nBy the existence and uniqueness theorem, this SIVP defines a unique continuous adapted process \\((X_t,t \\geq 0)\\). Let \\(\\mathfrak{F}=(\\mathcal{F}_t^X,t \\geq 0)\\) be the natural filtration of \\((X_t, t\\leq T)\\). Let \\(\\tau\\) be a stopping time for the filtration \\(\\mathfrak{F}\\) and consider the process \\(W_t = B_{t+\\tau} - B_\\tau\\). From Theorem 2, we know that the process \\((W_t,t\\geq 0)\\) is a standard brownian motion independent \\(\\mathcal{F}_\\tau\\). For \\(s \\geq 0\\), we consider the SDE:\n\\[\ndY_s = \\mu(Y_s)ds + \\sigma(Y_s)dW_s, \\quad Y_0 = X_\\tau\n\\tag{7}\\]\nAgain by the existence and uniqueness theorem, there exists a unique solution to the SIVP that is adapted to the natural filtration of \\(W\\). We claim that \\((X_{s+\\tau},s \\geq 0)\\) is the solution to this equation, since:\n\\[\nX_{s+\\tau} = X_\\tau + \\int_\\tau^{s+\\tau} \\mu(X_u)du + \\int_{\\tau}^{s+\\tau} \\sigma(X_u)dB_u\n\\]\nPerform a change of variable \\(v = u - \\tau\\). Then, the limits of integration bare, \\(v = 0\\) and \\(v = s\\). And \\(dv = du\\).\n\\(dB_u \\approx B_{u_2} - B_{u_1} = B(v_1 + \\tau) - B(v_2 + \\tau) = W(v_2) - W(v_1) =dW_v\\).\n\\[\nX_{s+\\tau} = X_\\tau + \\int_0^{s} \\mu(X_{v+\\tau})dv + \\int_{0}^{s} \\sigma(X_{v+\\tau})dW_v\n\\]\nIf we let \\(Y_0 = X_\\tau\\), \\(Y_v = X_{v+\\tau}\\), we recover the dynamics of \\((Y_v,v \\geq 0)\\) in Equation 7. So, \\((X_{s+\\tau},s\\geq 0)\\) is the solution to the SIVP in Equation 7. Thus, we conclude for any interval \\(A\\):\n\\[\n\\mathbb{P}(X_{s+\\tau} \\in A | \\mathcal{F}_\\tau^X) = \\mathbb{P}(Y_v \\in A| \\mathcal{F}_\\tau^X)\n\\]\nBut, since \\((Y_v,v\\geq 0)\\) depends on \\(\\mathcal{F}_\\tau^X\\) only through \\(X_\\tau\\), we conclude that \\(\\mathbb{P}(X_{s + \\tau} \\in A | \\mathcal{F}_\\tau^X) = \\mathbb{P}(X_{s + \\tau} \\in A| X_\\tau)\\). Consequently, \\((X_t,t \\geq 0)\\) is a strong-markov process. \\(\\blacksquare\\)\n\n\n\n\n\n\nExtension of optional sampling\n\n\n\nConsider a continuous martingale \\((M_t, t\\leq T)\\) for a filtration \\((\\mathcal{F}_t, t\\geq 0)\\) and a stopping time \\(\\tau\\) for the same filtration. Suppose we would like to compute for some \\(T\\):\n\\[\n\\mathbb{E}[M_T \\mathbf{1}_{\\{\\tau \\leq T\\}}]\n\\]\nIt would be tempting to condition on \\(\\mathcal{F}_\\tau\\) and write \\(\\mathbb{E}[M_T |\\mathcal{F}_\\tau] = M_\\tau\\) on the event \\(\\{\\tau \\leq T\\}\\). We would then conclude that:\n\\[\n\\mathbb{E}[M_T 1_{\\{\\tau \\leq T\\}}] = \\mathbb{E}[1_{\\{\\tau \\leq T\\}} \\mathbb{E}[M_T|\\mathcal{F}_\\tau] ] = \\mathbb{E}[M_\\tau 1_{\\{\\tau \\leq T\\}}]\n\\]\nIn some sense, we have extended the martingale property to stopping times. This property can be proved under reasonable assumptions on \\((M_t,t\\leq T)\\) (for example, if it is positive). Indeed, it suffices to approximate \\(\\tau\\) by discrete valued stopping time \\(\\tau_n\\) as in the proof of Theorem 2. One can then apply martingale property at a fixed time."
  },
  {
    "objectID": "posts/the_markov_property/index.html#the-heat-equation",
    "href": "posts/the_markov_property/index.html#the-heat-equation",
    "title": "The Markov Property",
    "section": "The Heat Equation",
    "text": "The Heat Equation\nWe look at more detail on how PDEs come up when computing quantities related to Markov processes.\n\nExample 4 (Heat Equation and Brownian motion) Let \\(f(t,x)\\) be a function of time and space. The heat equation in \\(1+1\\)-dimension (one dimension of time, one dimension of space) is the PDE:\n\\[\n\\begin{align*}\n\\frac{\\partial f}{\\partial t} &= \\frac{1}{2}\\frac{\\partial^2 f}{\\partial x^2}\n\\end{align*}\n\\tag{8}\\]\nIn \\(1+d\\) (one dimension of time, \\(d\\) dimensions of space), the heat equation is:\n\\[\n\\begin{align*}\n\\frac{\\partial f}{\\partial t} &= \\frac{1}{2}\\nabla^2 f\n\\end{align*}\n\\tag{9}\\]\nwhere \\(\\nabla^2\\) is the Laplacian operator.\nThe solutions to these PDEs can be expressed as an expectation over Brownian motion paths.\nLet \\((X_t,t \\geq 0)\\) be a brownian motion and let \\(f(t,x)\\) represent the PDF of \\(X_t\\). Then (as we will see) satisfies the PDE:\n\\[\n\\begin{align*}\n\\partial_{t}f(t,x) = \\frac{1}{2}\\partial_x^2 f(t,x)\n\\end{align*}\n\\]\nSuppose the Brownian motion is at \\(y\\) in the present. Suppose the present is a specific time \\(t_1\\). The joint probability density that \\(\\{X_{t}=x,X_{t_1}=y\\}\\) is:\n\\[\n\\begin{align*}\np(x, t, y, t_1) = f(y,t_1) \\cdot p(x,t|y,t_1)\n\\end{align*}\n\\]\nwhere \\(p(x,t|y,t_1)\\) is the transition probability density function.\nSince \\(f(t,x)\\) is the density of \\(X_t\\) and since we have a formula for the joint density of \\(X_{t_1}\\) and \\(X_t\\), we can view \\(f(t,x)\\) as the marginal of the joint density. You find the marginal density by integrating out the variables you are not interested in, \\(X_{t_1}\\) in this case. In the abstract, this is:\n\\[\n\\begin{align*}\nf(t,x) &= \\int_{-\\infty}^{\\infty} p(x, t, y, t_1)dy\\\\\n&= \\int_{-\\infty}^{\\infty} f(t_1,y) p(x,t_2 | y,t_1) dy\n\\end{align*}\n\\]\nOur claim is that \\(f\\) indeed satisfies the PDE (Equation 8).\nThe gaussian transition probability density function (heat kernel) \\(p(x,t|y,0)\\) is given by:\n\\[\np(x,t|y,0) = \\frac{1}{\\sqrt{2\\pi t}}\\exp\\left(-\\frac{(x-y)^2}{2t}\\right)\n\\]\nDifferentiating \\(p\\) with respect to \\(t\\), we have:\n\\[\n\\begin{align*}\n\\frac{\\partial}{\\partial t} p(x,t|y,0) &= \\frac{\\sqrt{2\\pi t} \\exp\\left(-\\frac{(x-y)^2}{2t}\\right) \\frac{\\partial}{\\partial t}\\left(-\\frac{(x-y)^2}{2t}\\right) - \\exp\\left(-\\frac{(x-y)^2}{2t}\\right)\\sqrt{2\\pi}\\left(\\frac{1}{2\\sqrt{t}}\\right)}{2\\pi t}\\\\\n&=\\sqrt{2\\pi}\\exp\\left(-\\frac{(x-y)^2}{2t}\\right) \\frac{\\frac{(x-y)^2}{2t^{3/2}} - \\frac{t}{2t^{3/2}}}{2\\pi t}\\\\\n&= \\exp\\left(-\\frac{(x-y)^2}{2t}\\right) \\frac{(x-y)^2 - t}{\\sqrt{2\\pi} (2t^{5/2}) }\n\\end{align*}\n\\tag{10}\\]\nDifferentiating \\(p\\) with respect to \\(x\\), we have:\n\\[\n\\begin{align*}\n\\frac{\\partial }{\\partial x} p(x,t|y,0) &= \\frac{1}{\\sqrt{2\\pi t}}\\exp\\left[-\\frac{(x-y)^2}{2t}\\right]\\frac{\\partial}{\\partial x}\\left(-\\frac{(x-y)^2}{2t}\\right)\\\\\n&= \\frac{1}{\\sqrt{2\\pi t}} \\cdot \\left(-\\frac{1}{\\cancel{2} t}\\right) \\exp\\left[-\\frac{(x-y)^2}{2t}\\right] \\cdot \\cancel{2}(x-y)\\\\\n&= -\\frac{1}{t\\sqrt{2\\pi t}} (x-y)\\exp\\left[-\\frac{(x-y)^2}{2t}\\right]\n\\end{align*}\n\\tag{11}\\]\nDifferentiating again with respect to space, we have:\n\\[\n\\begin{align*}\n\\frac{\\partial^2}{\\partial x^2} p(x,t|y,0) &= -\\frac{1}{t\\sqrt{2\\pi t}} \\left[\\exp\\left\\{-\\frac{(x-y)^2}{2}\\right\\} + (x-y)\\exp\\left\\{-\\frac{(x-y)^2}{2}\\right\\}\\left(-\\frac{2(x-y)}{2y}\\right)\\right]\\\\\n&=-\\frac{1}{t\\sqrt{2\\pi t}}\\exp\\left\\{-\\frac{(x-y)^2}{2}\\right\\} \\left[1 - \\frac{(x-y)^2}{t}\\right]\\\\\n&=\\frac{1}{t\\sqrt{2\\pi t}}\\exp\\left\\{-\\frac{(x-y)^2}{2}\\right\\} \\left[\\frac{(x-y)^2 - t}{t}\\right]\\\\\n&=\\frac{1}{\\sqrt{2\\pi}}\\exp\\left\\{-\\frac{(x-y)^2}{2}\\right\\} \\cdot \\frac{(x-y)^2 - t}{t^{5/2}}\n\\end{align*}\n\\tag{12}\\]\nFrom Equation 10 and Equation 12, it follows that:\n\\[\n\\frac{\\partial}{\\partial t} p(x,t|y,0) = \\frac{1}{2}\\frac{\\partial ^2}{\\partial x^2} p(x,t|y,0)\n\\]\nThus,\n\\[\n\\begin{align*}\n\\frac{\\partial}{\\partial t} \\int_{-\\infty}^\\infty g(y) p(x,t|y,0)dy &= \\frac{1}{2}\\frac{\\partial^2}{\\partial x^2} \\int_{-\\infty}^\\infty g(y) p(x,t|y,0)dy \\\\\n\\frac{\\partial }{\\partial t}f(t,x) &= \\frac{1}{2}\\frac{\\partial^2 }{\\partial x^2} f(t,x)\n\\end{align*}\n\\]"
  },
  {
    "objectID": "posts/the_markov_property/index.html#solution-to-the-heat-pde-as-an-expectation-over-brownian-motion-paths",
    "href": "posts/the_markov_property/index.html#solution-to-the-heat-pde-as-an-expectation-over-brownian-motion-paths",
    "title": "The Markov Property",
    "section": "Solution to the heat PDE as an expectation over Brownian-motion paths",
    "text": "Solution to the heat PDE as an expectation over Brownian-motion paths\nConsider again the heat PDE:\n\\[\n\\begin{align*}\n\\frac{\\partial f}{\\partial t} = \\frac{1}{2}\\frac{\\partial^2 f }{\\partial x^2}\n\\end{align*}\n\\]\nwith the initial condition\n\\[\nf(0,x) = g(x)\n\\]"
  },
  {
    "objectID": "posts/the_markov_property/index.html#robert-browns-erratic-motion-of-pollen",
    "href": "posts/the_markov_property/index.html#robert-browns-erratic-motion-of-pollen",
    "title": "The Markov Property",
    "section": "Robert Brown’s erratic motion of pollen",
    "text": "Robert Brown’s erratic motion of pollen\nIn the summer of 1827, the Scottish botanist Robert Brown observed that microscopic pollen grains suspended in water move in an erratic, highly irregular, zigzag pattern. It was only in 1905, that Albert Einstein could provide a satisfactory explanation of Brownian motion. He asserted that Brownian motion originates in the continual bombardment of the pollen grains by the molecules of the surrounding water. As a result of continual collisions, the particles themselves had the same kinetic energy as the water molecules. Thus, he showed that Brownian motion provided a solution (in a certain sense) to Fourier’s famous heat equation\n\\[\n\\frac{\\partial u}{\\partial t}(t,x) = \\kappa \\frac{\\partial^2 u}{\\partial x^2}(t,x)\n\\]\n\nAlbert Einstein’s proof of the existence of Brownian motion\nWe now summarize Einstein’s original 1905 argument. Let’s say that we are interested in the motion along the horizontal \\(x\\)-axis. Let’s say we drop brownian particles in a liquid. Let \\(f(t,x)\\) represent the number of particles per unit volume (density) at position \\(x\\) at time \\(t\\). So, the number of particles in a small interval \\(I=[x,x+dx]\\) of width \\(dx\\) will be \\(f(t,x)dx\\).\nNow, as time progresses, the number of particles in this interval \\(I\\) will change. The brownian particles will zig-zag upon bombardment by the molecules of the liquid. Some particles will move out of the interval \\(I\\), while other particles will move in.\nLet’s consider a timestep of length \\(\\tau\\). Einstein’s probabilistic approach was to model the distance travelled by the particles or displacement of the particles as a random variable \\(\\Delta\\). To determine how many particles end up in the interval \\(I\\), we start with the area to the right of the interval \\(I\\).\nThe density of particles at \\(x+\\Delta\\) is \\(f(t,x+\\Delta)\\); the number of particles in a small interval of length \\(dx\\) is \\(f(t,x+\\Delta)dx\\). If we represent the probability density of the displacement by \\(\\phi(\\Delta)\\), then the number of particles at \\(x+\\Delta\\) that will move to \\(x\\) will be \\(dx \\cdot f(t,x+\\Delta)\\phi(\\Delta)\\). We can apply the same logic to the left hand side. The number of particles at \\(x - \\Delta\\) that will move to \\(x\\) will be \\(dx \\cdot f(t,x-\\Delta)\\phi(-\\Delta)\\). Assume that \\(\\phi(\\Delta) = \\phi(-\\Delta)\\).\nNow, if we integrate these movements across the real line, then we get the number of particles at \\(x\\) at a short time later \\(t + \\tau\\).\n\\[\nf(t+ \\tau,x) dx = dx \\int_{-\\infty}^{\\infty} f(t,x+\\Delta) \\phi(\\Delta) d\\Delta\n\\]\nNow, we can get rid of \\(dx\\).\n\\[\nf(t+ \\tau,x) = \\int_{-\\infty}^{\\infty} f(t,x+\\Delta) \\phi(\\Delta) d\\Delta\n\\tag{13}\\]\nThe Taylor’s series expansion of \\(f(t+\\tau,x)\\) centered at \\(t\\) (holding \\(x\\) constant) is:\n\\[\nf(t + \\tau,x) = f(t,x) + \\frac{\\partial f}{\\partial t}\\tau + O(\\tau^2)\n\\]\nThe Taylor’s series expansion of \\(f(t,x+\\Delta)\\) centered at \\(x\\) (holding \\(t\\) constant) is:\n\\[\nf(t,x+\\Delta) = f(t,x) + \\frac{\\partial f}{\\partial x}\\Delta + \\frac{1}{2}\\frac{\\partial^2 f}{\\partial x^2}\\Delta^2 + O(\\Delta^3)\n\\]\nWe can now substitute these into Equation 13 to get:\n\\[\n\\begin{align*}\nf(t,x) + \\frac{\\partial f}{\\partial t}\\tau &= \\int_{-\\infty}^{\\infty}\\left(f(t,x) + \\frac{\\partial f}{\\partial x}\\Delta + \\frac{1}{2}\\frac{\\partial^2 f}{\\partial x^2}\\Delta^2\\right) \\phi(\\Delta)d\\Delta\\\\\n&= f(t,x) \\int_{-\\infty}^{\\infty} \\phi(\\Delta)d\\Delta \\\\\n&+ \\frac{\\partial f} {\\partial x} \\int_{-\\infty}^{\\infty} \\Delta \\phi(\\Delta)d\\Delta \\\\\n&+ \\frac{1}{2}\\frac{\\partial^2 f}{\\partial x^2}\\int_{-\\infty}^{\\infty}\\Delta^2 \\phi(\\Delta)d\\Delta\n\\end{align*}\n\\]\nNow, since the probability distribution of displacement \\(\\phi(\\cdot)\\) is symmetric around the origin, the second term is zero. And we know, that if we integrate the density over \\(\\mathbb{R}\\), we should get one, so the first term equals one. So, we get:\n\\[\nf(t,x) + \\frac{\\partial f}{\\partial t}\\tau = f(t,x) + \\frac{1}{2}\\frac{\\partial^2 f}{\\partial x^2}\\int_{-\\infty}^{\\infty}\\Delta^2 \\phi(\\Delta)d\\Delta\n\\]\nNow, we can cancel the \\(f\\) on both sides and then shift \\(\\tau\\) to the right hand side:\n\\[\n\\frac{\\partial f}{\\partial t} =  \\left(\\frac{1}{2\\tau} \\int_{-\\infty}^{\\infty}\\Delta^2 \\phi(\\Delta)d\\Delta \\right)\\frac{\\partial^2 f}{\\partial x^2}\n\\]\nDefine \\(D:= \\left(\\frac{1}{2\\tau} \\int_{-\\infty}^{\\infty}\\Delta^2 \\phi(\\Delta)d\\Delta \\right)\\). Then, we have:\n\\[\n\\frac{\\partial f}{\\partial t} =  D\\frac{\\partial^2 f}{\\partial x^2}\n\\]\nThe microscopic interpretation of the diffusion coefficient is, that its just the average of the squared displacements. The larger the \\(D\\), the faster the brownian particles move."
  },
  {
    "objectID": "posts/the_markov_property/index.html#kolmogorovs-backward-equation",
    "href": "posts/the_markov_property/index.html#kolmogorovs-backward-equation",
    "title": "The Markov Property",
    "section": "Kolmogorov’s Backward Equation",
    "text": "Kolmogorov’s Backward Equation\nThink of \\(y\\) and \\(t\\) as being current values and \\(y'\\) and \\(t'\\) being future values. The transition probability density function \\(p(y',t'|y,t)\\) of a diffusion satisfies two equations - one involving derivatives with respect to a future state and time (\\(y'\\) and \\(t'\\)) called forward equation and the other involving derivatives with respect to the current state and current time (\\(y\\) and \\(t\\)) called the backward equation. These two equations are parabolic partial differential equations not dissimilar to the Black-Scholes equation.\n\nTheorem 4 (Backward equation with initial value) Let \\((X_t,t\\geq 0)\\) be a diffusion in \\(\\mathbb{R}\\) with the SDE:\n\\[\ndX_t = \\sigma(X_t)dB_t + \\mu(X_t) dt\n\\]\nLet \\(g\\in C^2(\\mathbb{R})\\) be such that \\(g\\) is \\(0\\) outside an interval. Then, the solution of the PDE with initial value\n\\[\n\\begin{align*}\n\\frac{\\partial f}{\\partial t}(t,x) &= \\frac{\\sigma(x)^2}{2}\\frac{\\partial^2 f}{\\partial x^2} + \\mu(x)\\frac{\\partial f}{\\partial x}\\\\\nf(0,x) &= g(x)\n\\end{align*}\n\\tag{14}\\]\nhas the representation:\n\\[\nf(t,x) = \\mathbb{E}[g(X_t)|X_0 = x]\n\\]\n\nProof.\nStep 1. Let’s fix \\(t\\) and consider the function of space \\(h(x)=f(t,x)=\\mathbb{E}[g(X_t)|X_0=x]\\). Applying Ito’s formula to \\(h\\), we have:\n\\[\\begin{align}\ndh(X_s) &= h'(X_s) dX_s + \\frac{1}{2}h''(X_s) (dX_s)^2\\\\\n&= h'(X_s) (\\sigma(X_s)dB_s + \\mu(X_s) ds) + \\frac{\\sigma(X_s)^2}{2}h''(X_s)ds\\\\\n&= \\sigma(X_s)h'(X_s)dB_s + \\left(\\frac{\\sigma(X_s)^2}{2}h''(X_s) + \\mu(X_s)h'(X_s)\\right)ds\n\\end{align}\\]\nIn the integral form this is:\n\\[\\begin{align*}\nh(X_s) - h(X_0) &= \\int_0^s \\sigma(X_u)h'(X_u)dB_u \\\\\n&+ \\int_0^s \\left(\\frac{\\sigma(X_u)^2}{2}h''(X_u) + \\mu(X_u)h'(X_u)\\right)du \\tag{1}\n\\end{align*}\\]\nStep 2. Take expectations on both sides, divide by \\(s\\) and let \\(s \\to 0\\). We are interested in taking the derivative with respect to \\(s\\) at \\(s_0=0\\).\nThe expectation of the first term on the right hand side is zero, by the properties of the Ito integral.\nThe integrand of the second term (RHS) is a conditional expectation \\(\\mathbb{E}[\\xi(X_u)|X_0 = x]\\), it is an average at time \\(u\\), of the paths of the process starting at initial position \\(X_0 = x\\), so it is a function of \\(u\\) and \\(x\\). So, \\(\\mathbb{E}[\\xi(X_u)|X_0 = x] = p(u,x)\\). Suppressing the argument \\(x\\), we have the representation:\n\\[\\begin{align}\n\\int_0^s p(u) du\n\\end{align}\\]\nRecall that, if \\(p\\) is a continuous function, then it is Riemann integrable. Further, since integration and differentiation are inverse operations, there exists a unique antiderivative \\(P\\) given by\n\\[\nP(s) = \\int_{0}^{s}p(u)du\n\\]\nsatisfying \\(P'(0) = p(0)\\).\nBy the definition of the derivative:\n\\[P'(0) = \\lim_{s \\to 0} \\frac{P(s) - P(0)}{s} = \\lim_{s\\to 0} \\frac{P(s)}{s} = p(0) \\quad \\{ P(0)=0 \\text{ by definition }\\}\\]\nThus, we have:\n\\[\np(0,x) = \\mathbb{E}[\\xi(X_0)|X_0 = x] = \\frac{\\sigma(x)^2}{2} h''(x) + \\mu(x)h'(x)\n\\]\nStep 3. As for the left-hand side, we have:\n\\[\n\\lim_{s \\to 0} \\frac{\\mathbb{E}[h(X_s)|X_0 = x] - h(X_0)}{s} = \\lim_{s \\to 0} \\frac{\\mathbb{E}[h(X_s)|X_0 = x] - f(t,x)}{s}\n\\]\nTo prove that this limit is \\(\\frac{\\partial f}{\\partial t}(t,x)\\), it remains to show that \\(\\mathbb{E}[h(X_s)|X_0 = x]=\\mathbb{E}[g(X_{t+s})|X_0 = x]=f(t+s,x)\\).\nTo see this, note that \\(h(X_s) = \\mathbb{E}[g(X_{t+s})|X_s]\\). We deduce:\n\\[\\begin{align*}\n\\mathbb{E}[h(X_s)|X_0 = x] &= \\mathbb{E}[\\mathbb{E}[g(X_{t+s})|X_s]|X_0 = x]\\\\\n&= \\mathbb{E}[\\mathbb{E}[g(X_{t+s})|\\mathcal{F}_s]|X_0 = x]\\\\\n& \\{ (X_t,t\\geq 0) \\text{ is Markov }\\} \\\\\n&= \\mathbb{E}[g(X_{t+s})|X_0 = x]\\\\\n& \\{ \\text{ Tower property }\\} \\\\\n&= f(t+s,x)\n\\end{align*}\\]\nThis closes the proof. \\(\\blacksquare\\)\nThe backward equation (Equation 14) can be conveniently written in terms of the generator of the diffusion.\n\nDefinition 4 (Generator of a diffusion) The generator of a diffusion with SDE \\(dX_t = \\sigma(X_t) dB_t + \\mu(X_t)dt\\) is the differential operator acting on functions of space defined by :\n\\[\nA = \\frac{\\sigma(x)^2}{2}\\frac{\\partial }{\\partial x^2} + \\mu(x)\\frac{\\partial}{\\partial x}\n\\]\n\nWith this notation, the backward equation for the function \\(f(t,x)\\) takes the form:\n\\[\n\\frac{\\partial f}{\\partial x}(t,x) = Af(t,x)\n\\]\nwhere it is understood that \\(A\\) acts only on the space variable. Theorem 4 gives a nice interpretation of the generator: it quantifies how much the function \\(f(t,x) = \\mathbb{E}[g(X_t)|X_0 = x]\\) changes in a small time interval."
  },
  {
    "objectID": "posts/the_markov_property/index.html#the-heat-equation-as-a-special-case-of-the-backward-equation",
    "href": "posts/the_markov_property/index.html#the-heat-equation-as-a-special-case-of-the-backward-equation",
    "title": "The Markov Property",
    "section": "The heat equation as a special case of the Backward equation",
    "text": "The heat equation as a special case of the Backward equation\nLet \\((B_t,t\\geq 0)\\) be a standard brownian motion. Then, the generator is:\n\\[\nA = \\frac{1}{2}\\frac{\\partial^2 f}{\\partial x^2}(t,x)\n\\]\nThen, by Theorem 4, the solution of the heat PDE\n\\[\n\\begin{align*}\n\\frac{\\partial f}{\\partial t}(t,x) = Af(x) = \\frac{1}{2}\\frac{\\partial^2 f}{\\partial x^2}(t,x)\n\\end{align*}\n\\]\nwith initial value \\(f(0,x)=g(x)\\) has the stochastic representation:\n\\[f(t,x) = \\mathbb{E}[g(B_t)|B_0 = x]\\]\nIt can be represented as an average of \\(g(B_t)\\) over all Brownian motion paths starting at the location \\(x\\).\n\nExample 5 (Generator of the Ornstein Uhlenbeck Process) The SDE of the Ornstein-Uhlenbeck process is:\n\\[\ndX_t = dB_t - X_t dt\n\\]\nThis means that its generator is:\n\\[\nA = \\frac{1}{2}\\frac{\\partial^2}{\\partial x^2} - x \\frac{\\partial}{\\partial x}\n\\]\n\n\nExample 6 (Generator of Geometric Brownian Motion) Recall that the geometric Brownian motion\n\\[\nS_t = S_0 \\exp(\\sigma B_t + \\mu t)\n\\]\nsatisfies the SDE:\n\\[\ndS_t = \\sigma S_t dB_t + \\left(\\mu + \\frac{\\sigma^2}{2}\\right) S_t dt\n\\]\nIn particular, the generator of geometric Brownian motion is :\n\\[\nA = \\frac{\\sigma^2 x^2}{2} x \\frac{\\partial^2}{\\partial x^2} + \\left(\\mu + \\frac{\\sigma^2}{2}\\right)\\frac{\\partial}{\\partial x}\n\\]\n\nFor applications, in particular in mathematical finance, it is important to solve the backward equation with terminal value instead of with initial value. The reversal of time causes the appearance of an extra minus sign in the equation.\n\nTheorem 5 (Backward equation with terminal value) Let \\((X_t,t\\leq T)\\) be a diffusion with the dynamics:\n\\[\ndX_t = \\sigma(X_t) dB_t + \\mu(X_t)dt\n\\]\nLet \\(g\\in C^2(\\mathbb{R})\\) be such that \\(g\\) is \\(0\\) outside an interval. Then, the solution of the PDE with terminal value at time \\(T\\)\n\\[\n\\begin{align*}\n-\\frac{\\partial f}{\\partial t} &= \\frac{\\sigma(x)^2}{2}\\frac{\\partial^2 f}{\\partial x^2} + \\mu(x)\\frac{\\partial f}{\\partial x}\\\\\nf(T,x) &= g(x)\n\\end{align*}\n\\tag{15}\\]\nhas the representation:\n\\[\nf(t,x) = \\mathbb{E}[g(X_T)|X_t = x]\n\\]\n\n\n\n\n\n\n\nBackward equation with terminal value appears in the martingale condition\n\n\n\nOne way to construct a martingale for the filtration \\((\\mathcal{F}_t,t\\geq 0)\\) is to take\n\\[\nM_t = \\mathbb{E}[Y | \\mathcal{F}_t]\n\\]\nwhere \\(Y\\) is some integrable random variable. The martingale property then follows from the tower property of the conditional expectation. In the setup of Theorem 5, the random variable \\(Y\\) is \\(g(X_T)\\). By the Markov property of diffusion, we therefore have:\n\\[\nf(t,X_t) = \\mathbb{E}[g(X_T)|X_t] = \\mathbb{E}[g(X_T)|\\mathcal{F}_t]\n\\]\nIn other words, the solution to the backward equation with terminal value evaluated at \\(X_t = x\\) yields a martingale for the natural filtration of the process. This is a different point of view on the procedure we have used many times now: To get a martingale of the form \\(f(t,X_t)\\), apply the Ito’s formula to \\(f(t,X_t)\\) and set the \\(dt\\) term to zero. The PDE we obtain is the backward equation with terminal value. In fact, the proof of the theorem takes this exact route.\n\n\nProof.\nConsider \\(f(t,X_t)\\) and apply Ito’s formula.\n\\[\n\\begin{align*}\ndf(t,X_t) &= \\frac{\\partial f}{\\partial t} dt + \\frac{\\partial f}{\\partial x}dX_t + \\frac{1}{2}\\frac{\\partial^2 f}{\\partial x^2} dX_t \\cdot dX_t\\\\\n&= \\frac{\\partial f}{\\partial t} dt + \\frac{\\partial f}{\\partial x}(\\sigma(X_t) dB_t + \\mu(X_t)dt) + \\frac{\\sigma(X_t)^2}{2}\\frac{\\partial^2 f}{\\partial x^2} dt\\\\\n&= \\sigma(X_t) dB_t + \\left(\\frac{\\partial f}{\\partial t} + \\frac{\\sigma(X_t)^2}{2}\\frac{\\partial^2 f}{\\partial x^2} + \\mu(X_t)\\frac{\\partial f}{\\partial x}\\right)dt\n\\end{align*}\n\\]\nSince \\(f(t,x)\\) is a solution to the equation, we get that the \\(dt\\) term is \\(0\\) and \\(f(t,X_t)\\) is a martingale for the Brownian filtration (and thus also for the natural filtration of the diffusion, which contains less information). In particular we have:\n\\[\nf(t,X_t) = \\mathbb{E}[f(T,X_T)|\\mathcal{F}_t] = \\mathbb{E}[g(X_T)|\\mathcal{F}_t]\n\\]\nSince \\((X_t,t\\leq T)\\) is a Markov process, we finally get:\n\\[\nf(t,x) = \\mathbb{E}[g(X_T)|X_t = x]\n\\]\n\nExample 7 (Martingales of geometric Brownian motion) Let \\((S_t, \\geq 0)\\) be a geometric brownian motion with SDE:\n\\[\ndS_t = \\sigma S_t dB_t + \\left(\\mu + \\frac{\\sigma^2}{2}\\right)dt\n\\]\nAs we saw in Example 6, its generator is:\n\\[\nA = \\frac{\\sigma^2 x^2}{2}\\frac{\\partial^2}{\\partial x^2} + x\\left(\\mu+\\frac{\\sigma^2}{2}\\right)\\frac{\\partial}{\\partial x}\n\\]\nIn view of Theorem 5, if \\(f(t,x)\\) satisfies the PDE\n\\[\n\\frac{\\partial f}{\\partial t} + \\frac{\\sigma^2 x^2}{2}\\frac{\\partial^2 f}{\\partial x^2} + x\\left(\\mu+\\frac{\\sigma^2}{2}\\right)\\frac{\\partial f}{\\partial x}\n\\]\nthen processes of the form \\(f(t,S_t)\\) will be martingales for the natural filtration."
  },
  {
    "objectID": "posts/the_markov_property/index.html#kolmogorovs-forward-equation",
    "href": "posts/the_markov_property/index.html#kolmogorovs-forward-equation",
    "title": "The Markov Property",
    "section": "Kolmogorov’s forward equation",
    "text": "Kolmogorov’s forward equation\nThe companion equation to the backward equation is the Kolmogorov forward equation or forward equation. It is also known as the Fokker-Planck equation from its physics origin. The equation is very useful as it is satisfied by the transition density function \\(p(y',t'|y,t)\\) of a time-homogenous diffusion. It involves the adjoint of the generator.\n\nDefinition 5 (Adjoint of the generator) The adjoint \\(A^*\\) of the generator of a diffusion \\((X_t,t\\geq 0)\\) with SDE:\n\\[\ndX_t = \\sigma(X_t)dB_t + \\mu(X_t)dt\n\\]\nis the differential operator acting on a function of space \\(f(x)\\) as follows:\n\\[\nA^*f(x) = \\frac{1}{2}\\frac{\\partial^2 }{\\partial x^2} \\frac{\\sigma(x)^2}{2} f(x) - \\frac{\\partial }{\\partial x}\\mu(x)f(x)\n\\tag{16}\\]\n\nNote the differences with the generator in Definition 4: there is an extra minus sign and the derivatives also act on the volatility and the drift.\n\nExample 8 (The generator of Brownian motion is self-adjoint) In the case of standard brownian motion, it is easy to check that:\n\\[\nA^* = \\frac{1}{2}\\frac{\\partial^2}{\\partial x^2}\n\\]\nand\n\\[\nA^* = \\frac{1}{2}\\nabla^2\n\\]\nin the multivariate case. In other words, the generator and its adjoint are the same. In this case, the operator is self-adjoint.\n\n\nExample 9 We see that the adjoint of the generator acting on \\(f(x)\\) for geometric Brownian motion is:\n\\[\nA^*f(x) = \\frac{1}{2}\\frac{\\partial^2}{\\partial x^2} (\\sigma^2 x^2 f(x)) - \\frac{\\partial}{\\partial x} \\left(\\left(\\mu + \\frac{\\sigma^2}{2}\\right) x f(x)\\right)\n\\]\nUsing the product rule in differentiating we get:\n\\[\nA^*[f(x)] = \\frac{\\sigma^2}{2}\\left(2x f(x) + x^2 f''(x)\\right) - \\left(\\left(\\mu + \\frac{\\sigma^2}{2}\\right)\\left(f(x) + x f'(x)\\right)\\right)\n\\]\n\n\nExample 10 The generator for the Ornstein-Uhlenbeck process was given in Example 5. The adjoint acting on \\(f\\) is therefore:\n\\[\n\\begin{align*}\nA^*f(x) &= \\frac{1}{2}\\frac{\\partial^2}{\\partial x^2}(f(x)) - \\frac{\\partial}{\\partial x}(- x f(x))\\\\\n&= \\frac{f''(x)}{2} + (f(x)+xf'(x))\n\\end{align*}\n\\]\n\nThe forward equation takes the following form for a function \\(f(t,x)\\) of time and space:\n\\[\n\\frac{\\partial f}{\\partial t} = A^* f\n\\tag{17}\\]\nFor brownian motion, since \\(A^* = A\\), the backward and forward equations are the same. As advertised earlier, the forward equation is satisfied by the transition \\(p_t(y',t'|y,t)\\) of a diffusion. Before showing this in general, we verify it in the Brownian case.\n\nExample 11 Recall that the transition probability density \\(p(y,t|x,0)\\) for Brownian motion, or heat kernel, is:\n\\[\np(y,t|x,0) = \\frac{e^{-\\frac{(y-x)^2}{2}}}{\\sqrt{2\\pi t}}\n\\]\nHere, the space variable will be \\(y\\) and \\(x\\) will be fixed. The relevant function is thus \\(f(t,y) = p(y,t|x,0)\\). The adjoint operator acting on the space variable \\(y\\) is \\(A^* = A = \\frac{1}{2}\\frac{\\partial^2}{\\partial y^2}\\). The relevant time and space derivatives are given by Equation 10 and Equation 12.\nWe conclude that \\(f(t,y)=p(y,t|x,0)\\) is a solution of the forward equation.\n\nWhere does the form of the adjoint operator Equation 16 come from? In some sense, the adjoint operator plays a role similar to that of the transpose of a matrix in linear algebra. The adjoint acts on the function on the left. To see this, consider two functions \\(f,g\\) of space on which the generator \\(A\\) of a diffusion is well-defined. In particular, let’s assume that the functions are zero outside an interval. Consider the quantity\n\\[\n\\int_{\\mathbb{R}}g(x)A(f(x))dx = \\int_{\\mathbb{R}} g(x)\\left(\\frac{\\sigma(x)^2 }{2}f''(x) + \\mu(x)f'(x)\\right)dx\n\\]\nThis quantity can represent for example the average of \\(Af(x)\\) over some PDF \\(g(x)\\). In the above, \\(A\\) acts on the function on the right. To make the operator act on \\(g\\), we integrate by parts. This gives for the second term:\n\\[\n\\int_{\\mathbb{R}} g(x)\\mu(x)f'(x)dx = g(x)\\mu(x)f(x)\\Bigg|_{-\\infty}^{\\infty}-\\int_{\\mathbb{R}}f(x)\\frac{d}{dx}(g(x)\\mu(x))dx\n\\]\nThe boundary term \\(g(x)f(x)\\mu(x)\\Bigg|_{-\\infty}^\\infty\\) is \\(0\\) by the assumptions on \\(f,g\\). This term on \\(\\sigma\\) is obtained by integrating by parts twice:\n\\[\n\\begin{align*}\n\\int_{\\mathbb{R}} g(x) \\frac{\\sigma(x)^2}{2}f''(x)dx &= g(x) \\frac{\\sigma(x)^2}{2}f'(x)\\Bigg|_{-\\infty}^{\\infty} - \\int_{\\mathbb{R}}\\frac{d}{dx}\\left(g(x) \\frac{\\sigma(x)^2}{2}\\right) f'(x)dx\\\\\n-\\int_{\\mathbb{R}} \\frac{d}{dx}\\left(g(x) \\frac{\\sigma(x)^2}{2}\\right)f'(x)dx &= -\\frac{d}{dx}\\left(g(x) \\frac{\\sigma(x)^2}{2}\\right)f(x) \\Bigg|_{-\\infty}^{\\infty} + \\int_{\\mathbb{R}}\\frac{d^2}{dx^2}\\left(g(x) \\frac{\\sigma(x)^2}{2}\\right)f(x)dx\n\\end{align*}\n\\]\nThus,\n\\[\n\\begin{align*}\n\\int_{\\mathbb{R}}g(x) Af(x)dx &= \\int_{\\mathbb{R}}\\left(\\frac{1}{2}\\frac{d^2}{dx^2}(g(x) \\sigma(x)^2) - \\frac{d}{dx}(g(x)\\mu(x))\\right)f(x)dx\\\\\n&= \\int_{\\mathbb{R}}(A^*g(x))f(x)dx\n\\end{align*}\n\\tag{18}\\]\n\nTheorem 6 (Forward equation and transition probability) Let \\((X_t,t\\geq 0)\\) be a diffusion with SDE:\n\\[\ndX_t = \\sigma(X_t)dB_t + \\mu(X_t)dt, \\quad X_0 = x_0\n\\]\nLet \\(p(x,t|x_0,0)\\) be the transition probability density function for a fixed \\(x_0\\). Then, the function \\(f(t,y) = p(y,t|x_0,0)\\) is a solution of the PDE\n\\[\n\\frac{\\partial f}{\\partial t} = A^* f\n\\]\nwhere \\(A^*\\) is the adjoint of \\(A\\).\n\nProof.\nLet \\(h(x)\\) be some arbitrary function of space that is \\(0\\) outside an interval. We compute :\n\\[\n\\frac{1}{\\epsilon}(\\mathbb{E}[h(X_{t+\\epsilon}) - \\mathbb{E}[h(X_t)]])\n\\]\ntwo different ways and take the limit as \\(\\epsilon \\to 0\\).\nOn one hand, we have by the definition of the transition density\n\\[\n\\frac{1}{\\epsilon}\\left(\\mathbb{E}[h(X_{t+\\epsilon})]-\\mathbb{E}[h(X_t)]\\right) = \\int_{\\mathbb{R}}\\frac{1}{\\epsilon}(p(x,t+\\epsilon|x,0) - p(x,t|x_0,0))h(x)dx\n\\]\nBy taking the limit \\(\\epsilon \\to 0\\) inside the integral (assuming this is fine), we get:\n\\[\n\\int_{\\mathbb{R}} \\frac{\\partial}{\\partial t}p(x,t|x_0,0)h(x)dx\n\\tag{19}\\]\nOn the other hand, Ito’s formula implies\n\\[\n\\begin{align*}\ndh(X_s) &= \\frac{\\partial h}{\\partial x} dX_s + \\frac{1}{2} \\frac{\\partial^2 h}{\\partial x^2} (dX_s)^2\\\\\n&= \\frac{\\partial h}{\\partial x} (\\sigma(X_s) dB_s + \\mu(X_s)ds) + \\frac{1}{2} \\frac{\\partial^2 h}{\\partial x^2} (\\sigma(X_s)^2 ds)\\\\\n&= \\sigma(X_s)\\frac{\\partial h}{\\partial x} dB_s + \\left(\\mu(X_s) \\frac{\\partial h}{\\partial x} + \\frac{\\sigma(X_s)^2}{2}\\frac{\\partial^2 h}{\\partial x^2}\\right)ds\\\\\nh(X_{t+\\epsilon}) - h(X_t) &= \\int_{t}^{t+\\epsilon}\\sigma(X_s)\\frac{\\partial h}{\\partial x} dB_s + \\int_{t}^{t+\\epsilon}(Ah(x))ds\\\\\n\\mathbb{E}[h(X_{t+\\epsilon})] - \\mathbb{E}[h(X_t)] &= \\underbrace{\\mathbb{E}\\left[\\int_{t}^{t+\\epsilon}\\sigma(X_s)\\frac{\\partial h}{\\partial x} dB_s\\right]}_{0} + \\int_{t}^{t+\\epsilon}\\mathbb{E}[Ah(X_s)]ds\n\\end{align*}\n\\]\nDividing by \\(\\epsilon\\) and taking the limit as \\(\\epsilon \\to 0\\), we have:\n\\[\n\\begin{align*}\n\\lim_{\\epsilon \\to 0} \\frac{1}{\\epsilon} (\\mathbb{E}[h(X_{t+\\epsilon})] - \\mathbb{E}[h(X_t)]) &= \\mathbb{E}[Ah(X_t)]\\\\\n&= \\int_{\\mathbb{R}} p(x,t|x_0,0) Ah(x) dx\n\\end{align*}\n\\]\nThis can be written using Equation 18 as,\n\\[\n\\int_{\\mathbb{R}}(A^* p(x,t|x_0,0)) h(x) dx\n\\]\nSince \\(h\\) is arbitrary, we conclude that:\n\\[\n\\frac{\\partial}{\\partial t}p(x,t|x_0,0) = A^* p(x,t|x_0,0)\n\\tag{20}\\]\n\nExample 12 (Forward equation and invariant probability.) The Ornstein-Uhlenbeck process converges to a stationary distribution as noted in the example here. For example, for the SDE of the form\n\\[\ndX_t = -X_t dt + dB_t\n\\]\nwith \\(X_0\\) a Gaussian of mean \\(0\\) and variance \\(1/2\\), the PDF of \\(X_t\\), is, for all \\(t\\) is:\n\\[\nf(x) = \\frac{1}{\\sqrt{\\pi}} e^{-x^2}\n\\tag{21}\\]\nThis invariant distribution can be seen from the point of view of the forward equation. Indeed since the PDF is constant in time, the forward equation simply becomes:\n\\[\nA^* f = 0\n\\tag{22}\\]\n\n\nExample 13 The SDE of the Ornstein-Uhlenbeck process can be generated as follows. Consider \\(V(x)\\), a smooth function of space such that \\(\\int_{\\mathbb{R}} e^{-2V(x)}dx&lt;\\infty\\). The Smoluchowski equation is the SDE of the form:\n\\[\ndX_t = dB_t - V'(X_t) dt\n\\tag{23}\\]\nThe SDE can be interpreted as follows: \\(X_t\\) represents the position of a particle on \\(\\mathbb{R}\\). The position varies due to the Brownian fluctuations and also due to a force \\(V'(X_t)\\) that depends on the position. The function \\(V(x)\\) should then be thought of as the potential with which the particle moves, since the force (field) is the (negative) derivative of the potential function in Newtonian physics. The generator of this diffusion is:\n\\[\nA = \\frac{1}{2}\\frac{\\partial^2}{\\partial x^2} - V'(x)\\frac{\\partial}{\\partial x}\n\\]\nThis diffusion admits an invariant distribution :\n\\[\nf(x) = Ce^{-2V(x)}\n\\]\nwhere \\(C\\) is such that \\(\\int_{\\mathbb{R}}f(x)dx = 1\\)."
  },
  {
    "objectID": "posts/the_markov_property/index.html#the-feynman-kac-formula",
    "href": "posts/the_markov_property/index.html#the-feynman-kac-formula",
    "title": "The Markov Property",
    "section": "The Feynman-Kac Formula",
    "text": "The Feynman-Kac Formula\nWe saw in Example 4 that the solution of the heat equation:\n\\[\n\\frac{\\partial f}{\\partial t} = \\frac{1}{2}\\frac{\\partial^2 f}{\\partial x^2}\n\\]\ncan be represented as an average over Brownian paths. This representation was extended to diffusions in theorem Theorem 4 where the second derivative in the equation is replaced by the generator of the corresponding diffusion. How robust is this representation? In other words, is it possible to slightly change the PDE and still get a stochastic representation representation for the solution? The answer to this question is yes, when a term of the form \\(r(x)f(t,x)\\) is added to the equation, where \\(r(x)\\) is a well-behaved function of space (for example, piecewise continuous). The stochastic representation of the PDE in this case bears the name Feynman-Kac formula, making a fruitful collaboration between the physicist Richard Feynman and the mathematician Mark Kac. By the way, you pronounce “Kac” as “cats”. His name is Polish. People who immigrated from Poland before him spelled their names as “Katz”. The case when \\(r(x)\\) is linear will be important in the applications to mathematical finance, where it represents the contribution of the interest rate.\n\nTheorem 7 (Initial Value Problem) Let \\((X_t,t\\geq 0)\\) be a diffusion in \\(\\mathbb{R}\\) with the SDE:\n\\[\ndX_t = \\sigma(X_t) dB_t + \\mu(X_t)dt\n\\]\nLet \\(g\\in C^2(\\mathbb{R})\\) be such that \\(g\\) is \\(0\\) outside an interval. Then, the solution of the PDE with initial value\n\\[\n\\begin{align*}\n\\frac{\\partial f}{\\partial t}(t,x) &= \\frac{\\sigma(x)^2}{2}\\frac{\\partial^2 f}{\\partial x^2}(t,x) + \\mu(x)\\frac{\\partial f}{\\partial x}(t,x) - r(x)f(x)\\\\\nf(0,x) &= g(x)\n\\end{align*}\n\\tag{24}\\]\nhas the stochastic representation:\n\\[\nf(t,x) = \\mathbb{E}\\left[g(X_t)\\exp\\left(-\\int_0^t r(X_s) ds\\right)\\Bigg| X_0 = x\\right]\n\\]\n\nProof.\nThe proof is again based on Ito’s formula. For a fixed \\(t\\), we consider the process:\n\\[\nM_s = f(t-s, X_s) \\exp\\left(-\\int_0^s r(X_u) du\\right), \\quad s \\leq t\n\\]\nWrite \\(Z_s = \\exp\\left(-\\int_0^s r(X_u) du\\right)\\) and \\(V_s = f(t-s,X_s)\\). A direct application of Ito’s formula yields:\nLet \\(R_s = -\\int_0^s r(X_u) du\\). So, \\(dR_t = r(X_t) dt\\). \\((R_t,t\\geq 0)\\) is a random variable, because \\(r(X_s)\\) depends on how \\((X_s, s \\leq t)\\) evolves, it is stochastic, but for very small intervals of time \\(r(X_s)\\) is a constant, and hence the process \\((R_t,t\\geq 0)\\) is said to be locally deterministic.\n\\[\n\\begin{align*}\nZ_s &= e^{-R_s}\\\\\ndZ_s &= -e^{-R_s} dR_s + \\frac{1}{2}e^{R_s} (dR_s)^2\\\\\n&= -Z_s r(X_s) ds\n\\end{align*}\n\\]\nand\n\\[\n\\begin{align*}\ndV_s &= \\frac{\\partial}{\\partial s}f(t-s, X_s)ds + \\frac{\\partial}{\\partial x}f(t-s, X_s)dX_s + \\frac{1}{2}\\frac{\\partial^2}{\\partial x^2}f(t-s,X_s)(dX_s)^2\\\\\n&= -f_s ds + f_x (\\sigma(X_s)dB_s + \\mu(X_s)ds) + \\frac{1}{2}f_{xx} \\sigma(X_s)^2 ds \\\\\n&= \\sigma(X_s) f_x dB_s + \\\\\n&+ \\left\\{-f_s + \\mu(X_s)f_x + \\frac{\\sigma(X_s)^2}{2}f_{xx}\\right\\}ds\n\\end{align*}\n\\]\nRecall that \\(t\\) is fixed here, and we differentiate with respect to \\(s\\) in time. Since \\(f(t,x)\\) is a solution of the PDE, we can write the second equation as:\n\\[\ndV_s = \\sigma(X_s) f_x dB_s + r(X_s) f(t-s,X_s)ds\n\\]\nNow, by Ito’s product rule, we finally have:\n\\[\n\\begin{align*}\ndM_s &= V_s dZ_s + Z_s dV_s + dZ_s dV_s\\\\\n&= -f(t-s,X_s)Z_s r(X_s) ds + Z_s (\\sigma(X_s) f_x dB_s + r(X_s) f(t-s,X_s)ds) + 0\\\\\n&= \\sigma(X_s)Z_s f_x dB_s\n\\end{align*}\n\\]\nThis proves that \\((M_s, s \\leq t)\\) is a martingale. We conclude that:\n\\[\n\\mathbb{E}[M_t] = \\mathbb{E}[M_0]\n\\]\nUsing the definition of \\(M_t\\), this yields:\n\\[\n\\mathbb{E}[M_t] = \\mathbb{E}\\left[f(0,X_t)\\exp\\left(-\\int_0^t r(X_u) du\\right)\\right] = \\mathbb{E}\\left[g(X_t)\\exp\\left(-\\int_0^t r(X_u) du\\right)\\right] = \\mathbb{E}[M_0] = f(t,x)\n\\]\nThis proves the theorem. \\(\\blacksquare\\)\nAs for the backward equation, it is natural to consider the terminal value problem for the same PDE.\n\nTheorem 8 (Terminal Value Problem) Let \\((X_t,t \\leq T)\\) be a diffusion in \\(\\mathbb{R}\\) with the SDE:\n\\[\ndX_t = \\sigma(X_t) dB_t + \\mu(X_t) dt\n\\]\nLet \\(g\\in C^2(\\mathbb{R})\\) be such that \\(g\\) is \\(0\\) outside an interval. Then, the solution of the PDE with initial value\n\\[\n\\begin{align*}\n-\\frac{\\partial f}{\\partial t}(t,x) &= \\frac{\\sigma(x)^2}{2}\\frac{\\partial^2 f}{\\partial x^2}(t,x) + \\mu(x)\\frac{\\partial f}{\\partial x}(t,x) - r(x)f(t,x)\\\\\nf(T,x) &= g(x)\n\\end{align*}\n\\]\nhas the stochastic representation :\n\\[\nf(t,x) = \\mathbb{E}\\left[g(X_T)\\exp\\left(-\\int_t^T r(X_u) du\\right)\\Bigg|X_t = x\\right]\n\\]\n\nProof.\nThe proof is similar by considering instead\n\\[\nM_t = f(t,X_t)\\exp\\left(-\\int_0^t r(X_u) du\\right)\n\\]\n\nTheorem 9 (Generalized version.) Let \\(V\\in C^2(\\mathbb{R})\\) be the payout function. Then, the solution to the PDE\n\\[\n\\begin{align*}\n\\left(\\frac{\\partial}{\\partial t} + \\mu(t,x)\\frac{\\partial}{\\partial x} + \\frac{1}{2}\\sigma^2(t,x)\\frac{\\partial^2}{\\partial x^2}\\right)f = r(t,x)f(t,x) + B(t,x)\n\\end{align*}\n\\]\nwith the boundary condition:\n\\[\nf(T,x) = V(x)\n\\]\nhas the stochastic representation:\n\\[\nf(t,x)=\\mathbb{E}_t\\left[\\exp\\left(-\\int_t^T r(u,X_u) du\\right)V(X_T)\\right] - \\mathbb{E}_t\\left[\\int_{t}^T \\exp\\left(-\\int_t^s r(u,X_u) du\\right)B(s,X_s)ds\\right]\n\\]\nwhere \\((X_t,t\\leq T)\\) is a diffusion in \\(\\mathbb{R}\\) with the dynamics :\n\\[\ndX_t = \\sigma(t,X_t) dB_t + \\mu(t,X_t)dt\n\\]\n\nProof\nFor brevity, I drop the space coordinates in the below derivations.\nDefine \\(Z_s = \\exp\\left(-\\int_t^s r_u du\\right)\\). Consider the process\n\\[\nY(s) = Z_s f(s,X_s) - \\int_t^s Z_s B_s ds\n\\]\nBy Ito’s product rule:\n\\[\n\\begin{align*}\ndY_s &= dZ_s f + Z_s df + dZ_s df - Z_s B_s ds\n\\end{align*}\n\\]\nSince \\(dZ_s df = O(dt dt)\\) it can be dropped. We have:\n\\[\n\\begin{align*}\ndY_s &= -r_s Z_s f ds + Z_s \\left(f_s ds + f_x dX_s + \\frac{1}{2}f_{xx}(dX_s)^2\\right) - Z_s B_s ds\\\\\n&= -r_s Z_s f ds + Z_s \\left[f_s ds + f_x (\\mu ds + \\sigma dW_s) + \\frac{1}{2}\\sigma^2f_{xx}ds\\right] - Z_s B_s ds \\\\\n&= -r_s Z_s f ds + Z_s \\left[\\left(f_s + \\mu f_x  + \\frac{1}{2}\\sigma^2f_{xx}\\right)ds + \\sigma f_x dW_s \\right]  - Z_s B_s ds\n\\end{align*}\n\\]\nWe can substitute the term in the round brackets \\(\\left(f_s + \\mu f_x + \\frac{1}{2}\\sigma^2f_{xx}\\right) = r_s f + B_s\\), since \\(f\\) satisfies the PDE. So, we have:\n\\[\n\\begin{align*}\ndY_s\n&= -r_s Z_s f ds + Z_s \\left[\\left(r_s f + B_s\\right)ds + \\sigma f_x dW_s \\right]  - Z_s B_s ds\\\\\n&= Z_s \\sigma f_x dW_s\n\\end{align*}\n\\]\nSo, the process \\((Y_s,s\\leq T)\\) is a martingale. Integrating the above equation from \\(t\\) to \\(T\\), we have:\n\\[\nY(T) - Y(t) = \\int_t^T Z_s \\sigma f_x dW_s\n\\]\nUpon taking expectations, conditioned on \\(X_t = x\\) and observing that the RHS is an Ito integral, which has zero expectation, it follows that:\n\\[\n\\mathbb{E}_t[Y_T|X_t = x] =  \\mathbb{E}_t[Y_t|X_t = x]\n\\]\nOn the right hand side, \\(Y_t = f(t,X_t) =f(t,x)\\). It follows that:\n\\[\n\\begin{align*}\nf(t,x) &= \\mathbb{E}_t\\left[Z_T f(T,X_T) - \\int_{t}^T Z_s B_s ds \\right]\\\\\n&= \\mathbb{E}_t\\left[Z_T V(X_T)\\right] - \\mathbb{E}_t\\left[\\int_{t}^T Z_s B_s ds \\right]\n\\end{align*}\n\\]\nThis closes the proof. \\(\\blacksquare\\)"
  },
  {
    "objectID": "posts/the_markov_property/index.html#exercises",
    "href": "posts/the_markov_property/index.html#exercises",
    "title": "The Markov Property",
    "section": "Exercises",
    "text": "Exercises\n\nExercise 1 (Shifted Brownian Motion) Let \\((B_t,t\\geq 0)\\) be a standard brownian motion. Fix \\(t &gt; 0\\). Show that the process \\((W_s,s \\geq 0)\\) with \\(W_s = B_{t+s} - B_t\\) is a standard brownian motion independent of \\(\\mathcal{F}_t\\).\n\nSolution.\nAt \\(s = 0\\), \\(W(0) = B(t) - B(t) = 0\\).\nConsider any arbitrary times \\(t_1 &lt; t_2\\). We have:\n\\[\\begin{align*}\nW(t_2) - W(t_1) &= (B(t + t_2) - B(t)) - (B(t + t_1) - B(t))\\\\\n&= B(t + t_2) - B(t + t_1)\n\\end{align*}\\]\nNow, \\(B(t + t_2) - B(t + t_1) \\sim \\mathcal{N}(0,t_2 - t_1)\\). So, \\(W(t_2) - W(t_1)\\) is a Gaussian random variable with mean \\(0\\) and variance \\(t_2 - t_1\\).\nFinally, consider any finite set of times \\(0=t_0 &lt; t_1 &lt; t_2 &lt; \\ldots &lt; t_n = T\\). Then, \\(t &lt; t + t_1 &lt; t + t_2 &lt; \\ldots &lt; t + t_n\\). We have that, \\(B(t + t_1) - B(t)\\), \\(B(t + t_2) - B(t + t_1)\\), \\(B(t + t_3) - B(t + t_2)\\), \\(\\ldots\\), \\(B(t+T) - B(t+t_{n-1})\\) are independent random variables. Consequently, \\(W(t_1) - W(0)\\), \\(W(t_2) - W(t_1)\\), \\(W(t_3) - W(t_2)\\), \\(\\ldots\\), \\(W(t_n) - W(t_{n-1})\\) are independent random variables. So, \\((W_s,s\\geq 0)\\) is a standard brownian motion.\nAlso, we have:\n\\[\\begin{align*}\n\\mathbb{E}[W(s)|\\mathcal{F}_t] &= \\mathbb{E}[B(t + s) - B(t)|\\mathcal{F}_t]\\\\\n& \\{ B(t+s) - B(t) \\perp \\mathcal{F}_t \\}\\\\\n&= \\mathbb{E}[B(t + s) - B(t)]\\\\\n&= \\mathbb{E}[W(s)]\n\\end{align*}\\]\nThus, \\(W(s)\\) is independent of \\(\\mathcal{F}_t\\), it does not depend upon the information available upto time \\(t\\)."
  },
  {
    "objectID": "posts/spectral_theorem/index.html",
    "href": "posts/spectral_theorem/index.html",
    "title": "The Spectral Theorem",
    "section": "",
    "text": "Spectral Theorem\nEvery real, symmetric matrix is orthogonally diagonalizable.\n\nTheorem 1 (Spectral Theorem) Every real symmetric matrix is diagonalizable.\nLet \\(A\\) be a \\(n \\times n\\) real symmetric matrix. Then,\n\nThe eigenvalues of \\(A\\) are real.\nThere exists an orthonormal basis \\(\\{\\mathbf{q}_1,\\ldots,\\mathbf{q}_n\\}\\) for \\(\\mathbb{R}^n\\) consisting of the eigenvectors of \\(A\\). That is, there is an orthogonal matrix \\(Q\\) so that \\(A = QAQ^{-1}\\).\n\n\n\n\n\n\n\n\nSpectral values\n\n\n\nThe term spectrum refers to the eigenvalues of a matrix, or more, generally a linear operator. In Physics, the spectral energy lines of atoms (e.g. Balmer lines of the Hydrogen atom), are characterized as the eigenvalues of the governing quantum mechanical Schrodinger operator.\n\n\nProof.\nClaim. The eigenvalues of \\(A\\) are real.\n\\[\n\\begin{align*}\n\\langle A\\mathbf{x}, \\mathbf{y} \\rangle &= (A \\mathbf{x})' \\mathbf{y}\\\\\n&= \\mathbf{x}'A' \\mathbf{y}\\\\\n&= \\langle \\mathbf{x},A'\\mathbf{y}\\rangle\n\\end{align*}\n\\]\nSince, for a symmetric matrix \\(A\\), \\(A = A'\\), it follows that:\n\\[\n\\langle A\\mathbf{x},\\mathbf{y}\\rangle = \\langle \\mathbf{x}, A\\mathbf{y} \\rangle\n\\]\nOr using the dot-product notation, we could write:\n\\[\n(A\\mathbf{x})\\cdot \\mathbf{y} = \\mathbf{x}\\cdot (A\\mathbf{y})\n\\tag{1}\\]\nSuppose \\(\\mathbf{v}\\neq\\mathbf{0}\\) is a non-zero vector in \\(\\mathbf{R}^n\\) such that there exists a complex scalar \\(\\lambda\\), satisfying:\n\\[\nA \\mathbf{v} = \\lambda \\mathbf{v}\n\\tag{2}\\]\nWe can now take the complex conjugate of the eigenvalue equation. Remember that \\(A\\) is a real matrix, so \\(\\bar{A} = A\\). Thus, we have the conjugated version of the eigenvalue equation:\n\\[\n\\overline{(A\\mathbf{v})}=\\overline{A}\\overline{\\mathbf{v}} = A\\overline{\\mathbf{v}} = \\overline{\\lambda \\mathbf{v}} = \\overline{\\lambda}\\overline{\\mathbf{v}}\n\\tag{3}\\]\nUsing the eigenvalue equation (Equation 2), we can write:\n\\[\n(A \\mathbf{v})\\cdot \\overline{\\mathbf{v}} = (\\lambda \\mathbf{v}) \\cdot \\overline{\\mathbf{v}} = \\lambda (\\mathbf{v} \\cdot \\overline{\\mathbf{v}})\n\\]\nAlternatively, using Equation 1 and Equation 3, we have:\n\\[\n(A \\mathbf{v})\\cdot \\overline{\\mathbf{v}} = \\mathbf{v} \\cdot (A\\overline{\\mathbf{v}}) = \\mathbf{v} \\cdot (\\overline{\\lambda} \\overline{\\mathbf{v}}) = \\overline{\\lambda} (\\mathbf{v} \\cdot \\overline{\\mathbf{v}})\n\\]\nConsequently,\n\\[\n(\\lambda - \\overline{\\lambda})(\\mathbf{v}\\cdot \\overline{\\mathbf{v}}) = 0\n\\]\nSince, \\(\\mathbf{v} \\neq \\mathbf{0}\\), \\(\\lambda = \\overline{\\lambda}\\). Therefore, \\(\\lambda \\in \\mathbb{R}\\).\nClaim. \\(A\\) is orthogonally diagonalizable.\nWe proceed by induction.\nFor \\(n=1\\), \\(A\\) and \\(v\\) are scalars, so \\(Av = \\lambda v\\), where \\(\\lambda = A\\). Thus, we can pick any non-zero scalar \\(v\\) to form a basis in \\(\\mathbf{R}\\). And \\(A=P^{-1}\\Lambda P\\), where \\(P=I\\) and \\(\\Lambda = A\\).\nInductive hypotheis. Every \\(k \\times k\\) matrix is diagonalisable for \\(k=1,2,3,\\ldots,n-1\\).\nClaim. Let \\(A \\in \\mathbf{R}^{n \\times n}\\) be symmetric. Then, we are interested to prove that \\(A\\) is diagonalizable. We break the induction part into 3 steps.\nEvery square matrix \\(A\\) has atleast one eigenvalue. Suppose \\(\\lambda_{1}\\) is an eigenvalue of the matrix \\(A\\) and has a corresponding eigenvector \\(\\mathbf{v}_1\\). By part (I), we know that \\(\\lambda_{1}\\in\\mathbf{R}\\). We can normalize \\(\\mathbf{v}_1\\) as \\(\\mathbf{q}_{1} = \\mathbf{v}_1/||\\mathbf{v}_1||\\), so that it is an eigenvector with eigenvalue \\(\\lambda_{1}\\). (Obviously, this is no problem, since if \\(A\\mathbf{v}_1 = \\lambda_1 \\mathbf{v}_1\\), it implies \\(A (\\mathbf{v}_1/||\\mathbf{v}_1||) = \\lambda_1 (\\mathbf{v}_1/||\\mathbf{v}_1||)\\). It follows that, \\(A \\mathbf{q}_1 = \\lambda_1 \\mathbf{q}_1\\). )\nNow, we can extend this to a basis \\(\\{\\mathbf{q}_{1},\\mathbf{w}_{2},\\ldots,\\mathbf{w}_{n}\\}\\) of \\(\\mathbf{R}^n\\). By the Gram-Schmidt orthogonalization algorithm, given the basis \\(\\{\\mathbf{q}_{1},\\mathbf{w}_{2},\\ldots,\\mathbf{w}_{n}\\}\\), we can find a corresponding orthonormal basis \\(\\{\\mathbf{q}_{1},\\mathbf{q}_{2},\\ldots,\\mathbf{q}_{n}\\}\\) of \\(\\mathbf{R}^n\\).\nNow, we huddle these basis vectors together as column-vectors of a matrix and formulate the matrix \\(P\\).\n\\[\n\\begin{align*}\nP & =\\left[\\begin{array}{cccc}\n\\mathbf{\\mathbf{q}_{1}} & \\mathbf{q}_{2} & \\ldots & \\mathbf{q}_{n}\\end{array}\\right]\n\\end{align*}\n\\]\nBy definition, \\(P\\) is an orthogonal matrix. So, \\(P^{-1} = P^T\\).\nDefine\n\\[\n\\begin{align*}\nB & =P^{-1}AP\n\\end{align*}\n\\]\nStep I. \\(B\\) is symmetric.\nWe have:\n\\[\n\\begin{align*}\nB^{T} & =(P^{-1}AP)^{T}\\\\\n& =(P^{T}AP)^{T} & \\{P^{-1}=P^{T}\\}\\\\\n& =P^{T}A^{T}(P^{T})^{T}\\\\\n& =P^{T}A^{T}P\\\\\n& =P^{T}AP & \\{A\\text{ is symmetric}\\}\\\\\n& =B\n\\end{align*}\n\\]\nWe are now going to try and write \\(B\\) in the block form to try to see the structure that this matrix must have and hope that it looks like, it is going to be diagonal.\nStep II. The structure of \\(B\\).\nThe way we do this, is to consider the matrix \\(B\\) post-multiplied by \\(\\mathbf{e}_{1}\\). Consider \\(B\\mathbf{e}_{1}\\). This should actually give us the first column of \\(B\\). Now, we also know that \\(B=P^{T}AP\\). So, we could actually say, well,\n\\[\n\\begin{align*}\nP^{T}AP\\mathbf{e}_{1} & =P^{T}A\\mathbf{q}_{1}\n\\end{align*}\n\\]\nNow, remember that \\(\\mathbf{q}_{1}\\) is the normalized eigenvector corresponding to the eigenvalue \\(\\lambda_{1}\\). So, \\(A\\mathbf{q}_{1}=\\lambda_{1}\\mathbf{q}_{1}\\). That means, this is equal to:\n\\[\\begin{align*}\nP^{T}A\\mathbf{q}_{1} & =P^{T}\\lambda_{1}\\mathbf{q}_{1}\\\\\n& =\\lambda_{1}P^{t}\\mathbf{q}_{1}\\\\\n& =\\lambda_{1}\\left[\\begin{array}{c}\n\\mathbf{q}_{1}^{T}\\\\\n\\mathbf{q}_{2}^{T}\\\\\n\\vdots\\\\\n\\mathbf{q}_{n}^{T}\n\\end{array}\\right]\\mathbf{q}_{1}\\\\\n& =\\lambda_{1}\\left[\\begin{array}{c}\n\\mathbf{q}_{1}^{T}\\mathbf{q}_{1}\\\\\n\\mathbf{q}_{2}^{T}\\mathbf{q}_{1}\\\\\n\\vdots\\\\\n\\mathbf{q}_{n}^{T}\\mathbf{q}_{1}\n\\end{array}\\right]\\\\\n& =\\lambda_{1}\\left[\\begin{array}{c}\n1\\\\\n0\\\\\n\\vdots\\\\\n0\n\\end{array}\\right]\\\\\n& =\\left[\\begin{array}{c}\n\\lambda_{1}\\\\\n0\\\\\n0\\\\\n0\n\\end{array}\\right]\n\\end{align*}\\]\nThis is the first column of the matrix \\(B\\). Since \\(B=B^{T}\\), the first row should also be\n\\[\n\\begin{bmatrix}\n\\lambda_1 & 0 & 0 & \\ldots & 0\n\\end{bmatrix}\n\\]\nSo, we can write the matrix \\(B\\) in the block form:\n\\[\\begin{align*}\nB & =\\left[\\begin{array}{cc}\n\\lambda_{1} & O\\\\\nO & C\n\\end{array}\\right]\n\\end{align*}\\]\nThe first row and the first column are satisying the need to be diagonal.\nStep III.\nWe know that \\(C\\) is a \\(n-1\\times n-1\\) symmetric matrix. By the induction hypothesis, there exists an orthogonal matrix \\(Q\\) such that \\(D=Q^{-1}CQ = Q^T C Q\\).\nNow, define the matrix \\(R\\) as:\n\\[\\begin{equation}\nR:=P\\left[\\begin{array}{cc}\n1 & 0_{1\\times n-1}\\\\\n0_{n-1\\times1} & Q\n\\end{array}\\right]\n\\end{equation}\\]\nClaim. Our claim is that \\(R\\) is orthogonal and \\(R^{-1}AR\\) is diagonal.\n\nWe have:\n\n\\[\\begin{align*}\nR^{-1} & =\\left[\\begin{array}{cc}\n1 & 0_{1\\times n-1}\\\\\n0_{n-1\\times1} & Q^{-1}\n\\end{array}\\right]P^{-1} & \\{\\text{Reverse order law}\\}\\\\\n& =\\left[\\begin{array}{cc}\n1 & 0_{1\\times n-1}\\\\\n0_{n-1\\times1} & Q^{T}\n\\end{array}\\right]P^{T} & \\{P\\text{ and }Q\\text{ are orthogonal}\\}\n\\end{align*}\\]\nBut,\n\\[\\begin{align*}\nR^{T} & =\\left[\\begin{array}{cc}\n1 & 0_{1\\times n-1}\\\\\n0_{n-1\\times1} & Q^{T}\n\\end{array}\\right]P^{T}\n\\end{align*}\\]\nSo,\n\\[\\begin{align*}\nR^{T} & =R^{-1}\n\\end{align*}\\]\nThus, \\(R\\) is orthogonal.\n\nWell, let’s compute \\(R^{-1}AR\\).\n\n\\[\\begin{align*}\nR^{-1}AR & =R^{T}AR & \\{R\\text{ is orthogonal}\\}\\\\\n& =\\left[\\begin{array}{cc}\n1 & 0_{1\\times n-1}\\\\\n0_{n-1\\times1} & Q^{T}\n\\end{array}\\right]P^{T}AP\\left[\\begin{array}{cc}\n1 & 0_{1\\times n-1}\\\\\n0_{n-1\\times1} & Q\n\\end{array}\\right]\\\\\n& =\\left[\\begin{array}{cc}\n1 & 0_{1\\times n-1}\\\\\n0_{n-1\\times1} & Q^{T}\n\\end{array}\\right]B\\left[\\begin{array}{cc}\n1 & 0_{1\\times n-1}\\\\\n0_{n-1\\times1} & Q\n\\end{array}\\right]\\\\\n& =\\left[\\begin{array}{cc}\n1 & 0_{1\\times n-1}\\\\\n0_{n-1\\times1} & Q^{T}\n\\end{array}\\right]\\left[\\begin{array}{cc}\n\\lambda_{1} & 0_{1\\times n-1}\\\\\n0_{n-1\\times1} & C\n\\end{array}\\right]\\left[\\begin{array}{cc}\n1 & 0_{1\\times n-1}\\\\\n0_{n-1\\times1} & Q\n\\end{array}\\right]\\\\\n& =\\left[\\begin{array}{cc}\n\\lambda_{1} & 0_{1\\times n-1}\\\\\n0_{n-1\\times1} & Q^{T}C\n\\end{array}\\right]\\left[\\begin{array}{cc}\n1 & 0_{1\\times n-1}\\\\\n0_{n-1\\times1} & Q\n\\end{array}\\right]\\\\\n& =\\left[\\begin{array}{cc}\n\\lambda_{1} & 0_{1\\times n-1}\\\\\n0_{n-1\\times1} & Q^{T}CQ\n\\end{array}\\right]\n\\end{align*}\\]\nSince \\(Q^{T}CQ\\) is diagonal, it follows that \\(R^{-1}AR\\) is diagonal. This closes the proof. \\(\\blacksquare\\)"
  },
  {
    "objectID": "posts/rule-of-five/index.html",
    "href": "posts/rule-of-five/index.html",
    "title": "Rule of Five",
    "section": "",
    "text": "Introduction\nThe rule-of-five states that, if a class C has one of user-declared\n\nDestructor ~C\nCopy constructor C(const C&)\nCopy assignment operator C& operator=(const C&)\nMove constructor C(C&&)\nMove assignment operator C& operator=(C&&)\n\nit should declare all five special member functions.\nUser-declared != User-provided. Any explicitly defaulted (=default) or deleted (=delete) functions count as user-declared.\nA function is user-provided if it is user-declared and not explicitly defaulted or deleted.\n\n\nHinnant Table\nThe infamous Hinnant table elaborates the various special members implicitly generated by the compiler in the presence of user-declared special functions.\n\n\n\nHinnant table"
  },
  {
    "objectID": "posts/properties-of-brownian-motion/index.html",
    "href": "posts/properties-of-brownian-motion/index.html",
    "title": "Properties of Brownian Motion",
    "section": "",
    "text": "Let \\(B(t)\\) be a fixed Brownian motion. We give below some simple properties that follow directly from the definition of the Brownian Motion.\n\nFor any \\(t\\geq0\\), \\(B(t)\\) is normally distributed with mean \\(0\\) and variance \\(t\\). For any \\(s,t\\geq0\\) we have \\(\\mathbb{E}(B_{s}B_{t})=\\min\\{s,t\\}\\).\n\nProof. From condition (1), we have that \\(B_{0}=0\\). From condition (2), \\(B_{t}-B_{0}=B_{t}\\) is normally distributed with mean \\(0\\) and variance \\(t\\).\nAssume that \\(s&lt;t\\).\nWe have:\n\\[\\begin{aligned}\n\\mathbb{E}(B_{s}B_{t}) & =\\mathbb{E}\\left[B_{s}(B_{t}-B_{s}+B_{s})\\right] & \\{\\text{Write }B_{t}=B_{t}-B_{s}+B_{s}\\}\\\\\n& =\\mathbb{E}[B_{s}(B_{t}-B_{s})]+\\mathbb{E}[B_{s}^{2}] & \\{\\text{Linearity of expectations}\\}\\\\\n& =\\mathbb{E}[B_{s}]\\mathbb{E}(B_{t}-B_{s})+s & \\{B_{s},(B_{t}-B_{s})\\text{ are independent}\\}\\\\\n& =0\\cdot0+s\\\\\n& =s\n\\end{aligned}\\]\nThis closes the proof. ◻ :::\n\n(Translation Invariance) For fixed \\(t_{0}\\geq0\\), the stochastic process \\(\\tilde{B}(t)=B(t+t_{0})-B(t_{0})\\) is also a Brownian motion.\n\n\nProof. Proof. Firstly, the stochastic process \\(\\tilde{B}(t)\\) is such that:\n(1) \\(\\tilde{B}(0)=B(t_{0})-B(t_{0})=0\\). Hence, it satisfies condition (1).\n(2) Let \\(s&lt;t\\). We have: \\(\\tilde{B}(t)-\\tilde{B}(s)=B(t+t_{0})-B(s+t_{0})\\) which a Gaussian random variable with mean 0 and variance \\(t-s\\). Hence, for \\(a\\leq b\\),\n\\[\\begin{aligned}\n\\mathbb{P}\\{a\\leq & \\tilde{B}(t)\\leq b\\}=\\frac{1}{\\sqrt{2\\pi(t-s)}}\\int_{a}^{b}e^{-\\frac{x^{2}}{2(t-s)}}dx\n\\end{aligned}\\]\nHence, it satisfies condition (2).\n(3) To check condition (3) for \\(\\tilde{B}(t)\\), we may assume \\(t_{0}&gt;0\\). Then, for any \\(0\\leq t_{1}\\leq t_{2}\\leq\\ldots\\leq t_{n}\\), we have:\n\\[0&lt;t_{0}\\leq t_{0}+t_{1}\\leq t_{0}+t_{2}\\leq\\ldots\\leq t_{0}+t_{n}\\]\nSo, \\(B(t_{1}+t_{0})-B(t_{0})\\), \\(B(t_{2}+t_{0})-B(t_{1}+t_{0})\\), \\(\\ldots\\), \\(B(t_{k}+t_{0})-B(t_{k-1}+t_{0})\\), \\(\\ldots\\), \\(B(t_{n}+t_{0})-B(t_{n-1}+t_{0})\\) are independent random variables. Consequently, \\(\\tilde{B}(t)\\) satisfies condition (3).\nThis closes the proof. ◻\n\nThe above translation invariance property says that a Brownian motion starts afresh at any moment as a new Brownian motion.\n\n(Scaling Invariance) For any real number \\(\\lambda&gt;0\\), the stochastic process \\(\\tilde{B}(t)=B(\\lambda t)/\\sqrt{\\lambda}\\) is also a Brownian motion.\n\n\nProof. Proof. The scaled stochastic process \\(\\tilde{B}(t)\\) is such that:\n(1) \\(\\tilde{B}(0)=0\\). Hence it satisfies condition (1).\n(2) Let \\(s&lt;t\\). Then, \\(\\lambda s&lt;\\lambda t\\). We have:\n\\[\\begin{aligned}\n\\tilde{B}(t)-\\tilde{B}(s) & =\\frac{1}{\\sqrt{\\lambda}}(B(\\lambda t)-B(\\lambda s))\n\\end{aligned}\\]\nNow, \\(B(\\lambda t)-B(\\lambda s)\\) is a Gaussian random variable with mean \\(0\\) and variance \\(\\lambda(t-s)\\). We know that, if \\(X\\) is a random variable with mean \\(\\mu\\) and variance \\(\\sigma^{2}\\), \\(Z=\\left(\\frac{X-\\mu}{\\sigma}\\right)\\) has mean \\(0\\) and variance \\(1\\). Consequently, \\(\\frac{B(\\lambda t)-B(\\lambda s)}{\\sqrt{\\lambda}}\\) is a Gaussian random variable with mean \\(0\\) and variance \\((t-s)\\).\nHence, \\(\\tilde{B}(t)-\\tilde{B}(s)\\) is normal distributed with mean \\(0\\) and variance \\(t-s\\) and it satisfies condition (2).\n(3) To check condition (3) for \\(\\tilde{B}(t)\\), we may assume \\(t_{0}&gt;0\\). Then, for any \\(0\\leq t_{1}\\leq t_{2}\\leq\\ldots\\leq t_{n}\\), we have:\n\\[0\\leq\\lambda t_{1}\\leq\\lambda t_{2}\\leq\\ldots\\leq\\lambda t_{n}\\]\nConsequently, the random variables \\(B(\\lambda t_{k})-B(\\lambda t_{k-1})\\), \\(k=1,2,3,\\ldots,n\\) are independent. Hence it follows that \\(\\frac{1}{\\sqrt{\\lambda}}[B(\\lambda t_{k})-B(\\lambda t_{k-1})]\\) for \\(k=1,2,\\ldots,n\\) are also independent random variables.\nThis closes the proof. ◻\n\nIt follows from the scaling invariance property that for any \\(\\lambda&gt;0\\) and \\(0\\leq t_{1}\\leq t_{2}\\leq\\ldots\\leq t_{n}\\), the random vectors:\n\\[(B(\\lambda t_{1}),B(\\lambda t_{2}),\\ldots,B(\\lambda t_{n}))\\quad(\\sqrt{\\lambda}B(t_{1}),\\sqrt{\\lambda}B(t_{1}),\\ldots,\\sqrt{\\lambda}B(t_{n}))\\]\nhave the same distribution.\nThe scaling property shows that Brownian motion is self-similar, much like a fractal. To see this, suppose we zoom into a Brownian motion path very close to zero, say on the interval \\([0,10^{-6}]\\). If the Brownian motion path were smooth and differentiable, the closer we zoom in around the origin, the flatter the function will look. In the limit, we would essentially see a straight line given by the derivative at \\(0\\). However, what we see with the Brownian motion is very different. The scaling property means that for \\(a=10^{-6}\\),\n\\[\n\\begin{aligned}\n(B_{10^{-6}t,}t\\in[0,1]) & \\stackrel{\\text{distrib.}}{=}(10^{-3}B_{t},t\\in[0,1])\n\\end{aligned}\n\\]\nwhere \\(\\stackrel{\\text{distrib.}}{=}\\) means equality of the distribution of the two processes. In other words, Brownian motion on \\([0,10^{-6}]\\) looks like a Browian motion on \\([0,1]\\), but with its amplitude multiplied by a factor of \\(10^{-3}\\). In particular, it will remain rugged as we zoom in, unlike a smooth function.\n\n(Reflection at time \\(s\\)) The process \\((-B_{t},t\\geq0)\\) is a Brownian motion. More generally, for any \\(s\\geq0\\), the process \\((\\tilde{B}(t),t\\geq0)\\) defined by:\n\\[\\begin{aligned}\n\\tilde{B}(t) & =\\begin{cases}\nB_{t} & \\text{if }t\\leq s\\\\\nB_{s}-(B_{t}-B_{s}) & \\text{if }t&gt;s\n\\end{cases}\\label{eq:reflection-property}\n\\end{aligned}\\]\nis a Brownian motion.\n\n\nProof. Proof. (a) Consider the process \\(\\tilde{B}(t)=(-B_{t},t\\geq0)\\).\n(1) \\(\\tilde{B}(0)=0\\).\n(2) If \\(X\\) is a Gaussian random variable with mean \\(0\\) and variance \\(t-s\\), \\(-X\\) is also Gaussian with mean \\(0\\) and variance \\(t-s\\). Thus, \\(\\tilde{B}(t)-\\tilde{B}(s)=-(B(t)-B(s))\\) is also Gaussian with mean \\(0\\) and variance \\((t-s)\\). Hence condition (2) is satisfied.\n(3) Assume that \\(0\\leq t_{0}\\leq t_{1}\\leq\\ldots\\leq t_{n}\\). Then, the random variables \\(-(B(t_{k})-B(t_{k-1}))\\) are independent for \\(k=1,2,3,\\ldots,n\\). Hence, condition (3) is satisfied.\n(b) Consider the process \\(\\tilde{B}(t)\\) as defined in ([eq:reflection-property]).\nFix an \\(s\\geq0\\).\n(1) Let \\(t=0\\). Then, \\(t\\leq s\\). \\(\\tilde{B}(t)=\\tilde{B}(0)=B(0)=0\\).\n(2) Let \\(t_{1}&lt;t_{2}\\leq s\\). Then, \\(\\tilde{B}(t_{2})-\\tilde{B}(t_{1})=B(t_{2})-B(t_{1})\\). This is a Gaussian random variable with mean \\(0\\) and variance \\(t_{2}-t_{1}\\).\nLet \\(t_{1}&lt;s&lt;t_{2}\\). Then, \\(\\tilde{B}(t_{2})-\\tilde{B}(t_{1})=B(s)-(B(t_{2})-B(s))-B(t_{1})=(B(s)-B(t_{1}))-(B(t_{2})-B(s))\\). Since, \\(B(s)-B(t_{1})\\) and \\(B(t_{2})-B(s)\\) are independent Gaussian random variables, any linear combination of these is Gaussian. Moreover, its mean is zero. The variance is given by:\n\\[\\begin{aligned}\nVar[\\tilde{B}(t_{2})-\\tilde{B}(t_{1})] & =Var[B(s)-B(t_{1})]+Var[B(t_{2})-B(s)]\\\\\n& =(s-t_{1})+(t_{2}-s)\\\\\n& =t_{2}-t_{1}\n\\end{aligned}\\]\nLet \\(s&lt;t_{1}&lt;t_{2}\\). Then, \\[\\begin{aligned}\n\\tilde{B}(t_{2})-\\tilde{B}(t_{1}) & =B_{s}-(B_{t_{2}}-B_{s})-(B_{s}-(B_{t_{1}}-B_{s}))\\\\\n& =\\cancel{B_{s}}-(B_{t_{2}}-\\cancel{B_{s}})-(\\cancel{B_{s}}-(B_{t_{1}}-\\cancel{B_{s}}))\\\\\n& =-(B_{t_{2}}-B_{t_{1}})\n\\end{aligned}\\]\nHence, \\(\\tilde{B}(t_{2})-\\tilde{B}(t_{1})\\) is again a Gaussian random variable with mean \\(0\\) and variance \\(t_{2}-t_{1}\\). Hence, condition (3) is satisfied.\n(3) Assume that \\(0\\leq t_{1}\\leq\\ldots\\leq t_{k-1}\\leq s\\leq t_{k}\\leq\\ldots\\leq t_{n}\\). From the above discussion, the increments \\(\\tilde{B}(t_{2})-\\tilde{B}(t_{1})\\), \\(\\ldots\\), \\(\\tilde{B}(s)-\\tilde{B}(t_{k-1})\\), \\(\\tilde{B}(t_{k})-\\tilde{B}(s)\\), \\(\\ldots\\), \\(\\tilde{B}(t_{n})-\\tilde{B}(t_{n-1})\\) are independent increments. The increment \\(\\tilde{B}(t_{k})-\\tilde{B}(t_{k-1})\\) only depends on the random variables \\(\\tilde{B}(s)-\\tilde{B}(t_{k-1})\\) and \\(\\tilde{B}(t_{k})-\\tilde{B}(s)\\). Thus, \\(\\tilde{B}(t_{2})-\\tilde{B}(t_{1})\\), \\(\\ldots\\), \\(\\tilde{B}(t_{k})-\\tilde{B}(t_{k-1})\\), \\(\\ldots\\), \\(\\tilde{B}(t_{n})-\\tilde{B}(t_{n-1})\\) are independent. ◻\n\n\n(Time Reversal). Let \\((B_{t},t\\geq0)\\) be a Brownian motion. Show that the process \\((B_{1}-B_{1-t},t\\in[0,1])\\) has the distribution of a standard brownian motion on \\([0,1]\\).\n\n\nProof. Proof. (1) At \\(t=0\\), \\(B(1)-B(1-t)=B(1)-B(1)=0\\).\n(2) Let \\(s&lt;t\\). Then, \\(1-t&lt;1-s\\). So, the increment :\n\\[\\begin{aligned}\n(B(1)-B(1-t))-(B(1)-B(1-s)) & =B(1-s)-B(1-t)\n\\end{aligned}\\]\nhas a Gaussian distribution. It’s mean is \\(0\\) and variance is \\((1-s)-(1-t)=t-s\\).\n(3) Let \\(0\\leq t_{1}\\leq t_{2}\\leq\\ldots\\leq t_{n}\\). Then:\n\\[1-t_{n}\\leq\\ldots\\leq1-t_{k}\\leq1-t_{k-1}\\leq\\ldots\\leq1-t_{2}\\leq1-t_{1}\\]\nConsider the increments of the process for \\(k=1,2,\\ldots,n\\):\n\\[\\begin{aligned}\n(B(1)-B(1-t_{k}))-(B(1)-B(1-t_{k-1})) & =B(1-t_{k-1})-B(1-t_{k})\n\\end{aligned}\\]\nThey are independent random variables. Hence, condition (3) is satisfied. ◻\n\n\n(Evaluating Brownian Probabilities). Let’s compute the probability that \\(B_{1}&gt;0\\) and \\(B_{2}&gt;0\\). We know from the definition that \\((B_{1},B_{2})\\) is a Gaussian vector with mean \\(0\\) and covariance matrix:\n\\[\\begin{aligned}\nC & =\\left[\\begin{array}{cc}\n1 & 1\\\\\n1 & 2\n\\end{array}\\right]\n\\end{aligned}\\]\nThe determinant of \\(C\\) is \\(1\\). By performing row operations on the augmented matrix \\([C|I]\\) we find that:\n\\[\\begin{aligned}\nC^{-1} & =\\left[\\begin{array}{cc}\n2 & -1\\\\\n-1 & 1\n\\end{array}\\right]\n\\end{aligned}\\]\nThus, the probability \\(\\mathbb{P}(B_{1}&gt;0,B_{2}&gt;0)\\) can be expressed as:\n\\[\\begin{aligned}\n\\mathbb{P}(B_{1}&gt;0,B_{2}&gt;0) & =\\frac{1}{\\sqrt{(2\\pi)^{2}}}\\int_{0}^{\\infty}\\int_{0}^{\\infty}\\exp\\left[-\\frac{1}{2}(2x_{1}^{2}-2x_{1}x_{2}+x_{2}^{2}\\right]dx_{2}dx_{1}\n\\end{aligned}\\]\nThis integral can be evaluated using a calculator or software and is equal to \\(3/8\\). The probability can also be computed using the independence of increments. The increments \\((B_{1},B_{2}-B_{1})\\) are IID standard Gaussians. We know their joint PDF. It remains to integrate over the correct region of \\(\\mathbf{R}^{2}\\) which in this case will be:\n\\[\\begin{aligned}\nD^{*} & =\\{(z_{1},z_{2}):(z_{1}&gt;0,z_{1}+z_{2}&gt;0)\\}\n\\end{aligned}\\]\nWe have:\n\\[\\begin{aligned}\n\\mathbb{P}(B_{1}&gt;0,B_{2}&gt;0) & =\\frac{1}{2\\pi}\\int_{0}^{\\infty}\\int_{z_{2}=-z_{1}}^{z_{2}=\\infty}e^{-(z_{1}^{2}+z_{2}^{2})/2}dz_{2}dz_{1}\n\\end{aligned}\\]\nIt turns out that this integral can be evaluated exactly. Indeed by writing \\(B_{1}=Z_{1}\\) and \\(Z_{2}=B_{2}-B_{1}\\) and splitting the probability on the event \\(\\{Z_{2}\\geq0\\}\\) and its complement, we have that \\(\\mathbb{P}(B_{1}\\geq0,B_{2}\\geq0)\\) equals:\n\\[\\begin{aligned}\n\\mathbb{P}(B_{1}\\geq0,B_{2}\\geq0) & =\\mathbb{P}(Z_{1}\\geq0,Z_{1}+Z_{2}&gt;0,Z_{2}\\geq0)+\\mathbb{P}(Z_{1}\\geq0,Z_{1}+Z_{2}&gt;0,Z_{2}&lt;0)\\\\\n& =\\mathbb{P}(Z_{1}\\geq0,Z_{2}\\geq0)+\\mathbb{P}(Z_{1}\\geq0,Z_{1}&gt;-Z_{2},-Z_{2}&gt;0)\\\\\n& =\\mathbb{P}(Z_{1}\\geq0,Z_{2}\\geq0)+\\mathbb{P}(Z_{1}\\geq0,Z_{1}&gt;Z_{2},Z_{2}&gt;0)\\\\\n& =\\frac{1}{4}+\\frac{1}{8}\\\\\n& =\\frac{3}{8}\n\\end{aligned}\\]\nNote that, by symmetry, \\(\\mathbb{P}(Z_{1}\\geq0,Z_{1}&gt;Z_{2},Z_{2}&gt;0)=\\mathbb{P}(Z_{1}\\geq0,Z_{1}\\leq Z_{2},Z_{2}&gt;0)=\\frac{1}{8}\\).\n\n\n(Another look at Ornstein Uhlenbeck process.) Consider the process \\((X_{t},t\\in\\mathbf{R})\\) defined by :\n\\[\\begin{aligned}\nX_{t} & =\\frac{e^{-2t}}{\\sqrt{2}}B(e^{4t}),\\quad t\\in\\mathbf{R}\n\\end{aligned}\\]\nHere the process \\((B_{e^{4t}},t\\ge0)\\) is called a time change of Brownian motion, since the time is now quantitfied by an increasing function of \\(t\\) namely \\(e^{4t}\\). The example \\((B(\\lambda t),t\\geq0)\\) in the scaling property is another example of time change.\n\nIt turns out that \\((X_{t},t\\in\\mathbf{R})\\) is a stationary Ornstein-Uhlenbeck process. (Here the index of time is \\(\\mathbf{R}\\) instead of \\([0,\\infty)\\), but the definition also applies as the process is stationary. Since the original brownian motion \\(B(t)\\) is a Gaussian process, any finite dimensional vector \\((B(t_{1}),\\ldots,B(t_{n}))\\) is Gaussian. It follows that:\n\\[(B(T_{1}),\\ldots,B(T_{n}))=\\frac{1}{\\sqrt{2}}(e^{-2t_{1}}B(e^{4t_{1}}),\\ldots,e^{-2t_{n}}B(e^{4t_{n}}))\\]\nis also a Gaussian vector. (Note, once we fix \\(t_{1},t_{2},\\ldots,t_{n}\\), \\(e^{-4t_{1}},\\ldots,e^{-4t_{n}}\\) are constants.) Hence, \\((X_{t},t\\in\\mathbf{R})\\) is a Gaussian process.\nThe mean of \\((X_{t},t\\in\\mathbf{R})\\) is:\n\\[\\begin{aligned}\n\\mathbb{E}[X_{t}] & =\\frac{e^{-2t}}{\\sqrt{2}}\\mathbb{E}[B(e^{4t})]=0\n\\end{aligned}\\]\nAnd if \\(s&lt;t\\),\n\\[\\begin{aligned}\n\\mathbb{E}[X_{s}X_{t}] & =\\frac{e^{-2(s+t)}}{2}\\mathbb{E}[B(e^{4s})B(e^{4t})]\\\\\n& =\\frac{e^{-2(s+t)}}{2}e^{4s}\\\\\n& =\\frac{e^{-2(t-s)}}{2}\n\\end{aligned}\\]\nTwo Gaussian processes having the same mean and covariance have the same distribution. Hence, it proves the claim that \\((X_{t})\\) is a stationary OU process.\n\n\n\nFirst we review the definitions of the Riemann integral and the Riemann-Stieljtes integral in Calculus.\n\nA partition \\(P\\) of \\([a,b]\\) is a finite set of points from \\([a,b]\\) that includes both \\([a,b].\\)The notational convention is to always list the points of a partition \\(P=\\{a=x_{0},x_{1},x_{2},\\ldots,x_{n}=b\\}\\) in increasing order. Thus:\n\\[a=x_{0}&lt;x_{1}&lt;\\ldots&lt;x_{k-1}&lt;x_{k}&lt;\\ldots&lt;x_{n}=b\\]\n\nFor each subinterval \\([x_{k-1},x_{k}]\\) of \\(P\\), let\n\\[\\begin{aligned}\nm_{k} & =\\inf\\{f(x):x\\in[x_{k-1},x_{k}]\\}\\\\\nM_{k} & =\\sup\\{f(x):x\\in[x_{k-1},x_{k}]\\}\n\\end{aligned}\\]\nThe lower sum of \\(f\\) with respect to \\(P\\) is given by :\n\\[\\begin{aligned}\nL(f,P) & =\\sum_{k=1}^{n}m_{k}(x_{k}-x_{k-1})\n\\end{aligned}\\]\nThe upper sum of \\(f\\) with respect to \\(P\\) is given by:\n\\[\\begin{aligned}\nU(f,P) & =\\sum_{k=1}^{n}M_{k}(x_{k}-x_{k-1})\n\\end{aligned}\\]\nFor a particular partition \\(P\\), it is clear that \\(U(f,P)\\geq L(f,P)\\) because \\(M_{k}\\geq m_{k}\\) for all \\(k=0,1,2,\\ldots,n\\).\n\nA partition \\(Q\\) is called a refinement of \\(P\\) if \\(Q\\) contains all of the points of \\(P\\); that is \\(Q\\subseteq P\\).\n\n\nIf \\(P\\subseteq Q\\), then \\(L(f,P)\\leq L(f,Q)\\) and \\(U(f,Q)\\leq U(f,P)\\).\n\n\nProof. Proof. Consider what happens when we refine \\(P\\) by adding a single point \\(z\\) to some subinterval \\([x_{k-1},x_{k}]\\) of \\(P\\). We have:\n\\[\\begin{aligned}\nm_{k}(x_{k}-x_{k-1}) & =m_{k}(x_{k}-z)+m_{k}(z-x_{k-1})\\\\\n& \\leq m_{k}'(x_{k}-z)+m_{k}''(z-x_{k-1})\n\\end{aligned}\\]\nwhere\n\\[\\begin{aligned}\nm_{k}' & =\\inf\\{f(x):x\\in[z,x_{k}]\\}\\\\\nm_{k}'' & =\\inf\\{f(x):x\\in[x_{k-1},z]\\}\n\\end{aligned}\\]\nBy induction we have:\n\\[\\begin{aligned}\nL(f,P) & \\leq L(f,Q)\\\\\nU(f,Q) & \\leq U(f,P)\n\\end{aligned}\\] ◻\n\n\nIf \\(P_{1}\\) and \\(P_{2}\\) are any two partitions of \\([a,b]\\), then \\(L(f,P_{1})\\leq U(f,P_{2})\\).\n\n\nProof. Proof. Let \\(Q=P_{1}\\cup P_{2}\\). Then, \\(P_{1}\\subseteq Q\\) and \\(P_{2}\\subseteq Q\\). Thus, \\(L(f,P_{1})\\leq L(f,Q)\\leq U(f,Q)\\leq L(f,P_{2})\\). ◻\n\n\nLet \\(\\mathcal{P}\\) be the collection of all possible partitions of the interval \\([a,b]\\). The upper integral of \\(f\\) is defined to be:\n\\[\\begin{aligned}\nU(f) & =\\inf\\{U(f,P):P\\in\\mathcal{P}\\}\n\\end{aligned}\\]\nThe lower integral of \\(f\\) is defined by:\n\\[\\begin{aligned}\nL(f) & =\\sup\\{L(f,P):P\\in\\mathcal{P}\\}\n\\end{aligned}\\]\n\nConsider the set of all upper sums of \\(f\\) - \\(\\{U(f,P):P\\in\\mathcal{P}\\}\\). Take an arbitrary partition \\(P'\\in\\mathcal{P}\\). Since \\(L(f,P')\\leq U(f,P)\\) for all \\(P\\in\\mathcal{P}\\), by the Axiom of Completeness(AoC), \\(\\inf\\{U(f,P):P\\in\\mathcal{P}\\}\\) exists.We can similarly argue for the supremum of all lower Riemann sums.\n\nFor any bounded function \\(f\\) on \\([a,b]\\), it is always the case that \\(U(f)\\geq L(f)\\).\n\n\nProof. Proof. By the properties of the infimum of a set, \\((\\forall\\epsilon&gt;0)\\), \\(\\exists P(\\epsilon)\\) such that \\(U(f)&lt;U(f,P(\\epsilon))&lt;U(f)+\\epsilon\\). Pick \\(\\epsilon=1,\\frac{1}{2},\\frac{1}{3}\\ldots,\\frac{1}{n},\\ldots\\). Thus, we can produce a sequence of partitions \\(P_{n}\\) such that :\n\\[U(f)&lt;\\ldots&lt;U(f,P_{n})&lt;U(f)+\\frac{1}{n}\\]\nConsequently, \\(\\lim U(f,P_{n})=U(f)\\). Similarly, we can produce a sequence of partitions \\((Q_{m})\\) such that :\n\\[L(f)-\\frac{1}{m}&lt;\\ldots&lt;L(f,Q_{m})&lt;L(f)\\]\nWe know that:\n\\[\\begin{aligned}\nL(f,Q_{m}) & \\leq U(f,P_{n})\n\\end{aligned}\\]\nKeeping \\(m\\) fixed and passing to the limit, as \\(n\\to\\infty\\) on both sides, we have:\n\\[\\begin{aligned}\n\\lim_{n\\to\\infty}L(f,Q_{m}) & \\leq\\lim_{n\\to\\infty}U(f,P_{n})\\quad\\left\\{ \\text{Order Limit Theorem}\\right\\} \\\\\nL(f,Q_{m}) & \\leq U(f)\n\\end{aligned}\\]\nNow, passing to the limit, as \\(m\\to\\infty\\) on both sides, we have:\n\\[\\begin{aligned}\n\\lim_{m\\to\\infty}L(f,Q_{m}) & \\leq\\lim_{m\\to\\infty}U(f)\\quad\\left\\{ \\text{Order Limit Theorem}\\right\\} \\\\\nL(f) & \\leq U(f)\n\\end{aligned}\\] ◻\n\n\n(Riemann Integrability). A bounded function \\(f\\) on the interval \\([a,b]\\) is said to be Riemann integrable if \\(U(f)=L(f)\\). In this case, we define \\(\\int_{a}^{b}f\\) or \\(\\int_{a}^{b}f(x)dx\\) to be the common value:\n\\[\\begin{aligned}\n\\int_{a}^{b}f(x)dx & =U(f)=L(f)\n\\end{aligned}\\]\n\n\n(Integrability Criterion) A bounded function \\(f\\) is integrable on \\([a,b]\\) if and only if, for every \\(\\epsilon&gt;0\\), there exists a partition \\(P_{\\epsilon}\\) of \\([a,b]\\) such that:\n\\[\\begin{aligned}\nU(f,P_{\\epsilon})-L(f,P_{\\epsilon}) & &lt;\\epsilon\n\\end{aligned}\\]\n\n\nProof. Proof. (\\(\\Longleftarrow\\) direction.) Let \\(\\epsilon&gt;0\\). If such a partition \\(P_{\\epsilon}\\) exists, then:\n\\[U(f)-L(f)\\leq U(f,P_{\\epsilon})-L(f,P_{\\epsilon})&lt;\\epsilon\\]\nBecause \\(\\epsilon\\) is arbitrary, it follows that \\(U(f)=L(f)\\) and hence \\(f\\) is Riemann integrable.\n(\\(\\Longrightarrow\\) direction.) Let \\(f\\) be a bounded function on \\([a,b]\\) such that \\(f\\) is Riemann integrable.\nPick an arbitrary \\(\\epsilon&gt;0\\).\nThen, since \\(U(f)=\\inf\\{U(f,P):P\\in\\mathcal{P}\\}\\), there exists \\(P_{\\epsilon}\\in\\mathcal{P}\\), such that \\(U(f)&lt;U(f,P_{\\epsilon})&lt;U(f)+\\frac{\\epsilon}{2}\\). Since \\(L(f)=\\sup\\{L(f,P):P\\in\\mathcal{P}\\}\\), there exists \\(P_{\\epsilon}\\in\\mathcal{P}\\), such that \\(L(f)-\\frac{\\epsilon}{2}&lt;L(f,P_{\\epsilon})&lt;L(f)\\). Consequently,\n\\[\\begin{aligned}\nU(f,P_{\\epsilon})-L(f,P_{\\epsilon}) & &lt;U(f)+\\frac{\\epsilon}{2}-\\left(L(f)-\\frac{\\epsilon}{2}\\right)\\\\\n& =U(f)-L(f)+\\epsilon\\\\\n& =\\epsilon\n\\end{aligned}\\] ◻\n\n\n\n\nA point \\(c\\) is called a discontinuity of the first kind or jump point if both limits \\(g(c+)=\\lim_{t\\uparrow c}g(t)\\) and \\(g(c-)=\\lim_{t\\downarrow c}g(t)\\) exist and are not equal. The jump at \\(c\\) is defined as \\(\\Delta g(c)=g(c+)-g(c-)\\). Any other discontinuity is said to be of the second kind.\n\n\nConsider the function\n\\[\\begin{aligned}\nf(x) & =\\sin\\left(\\frac{1}{x}\\right)\n\\end{aligned}\\]\nLet \\(x_{n}=\\frac{1}{2n\\pi}\\). Then, \\(f(x_{n})=(0,0,0,\\ldots)\\). Next, consider \\(y_{n}=\\frac{1}{\\pi/2+2n\\pi}\\). Then, \\(f(y_{n})=(1,1,1,\\ldots)\\). Consequently, \\(f\\) is not continuous at \\(0\\). Hence, limits from the left or right don’t exist. Consequently, this is a discontinuity of the second kind.\n\nFunctions in stochastic calculus are functions without discontinuities of the second kind, that is functions have both left and right hand limits at any point of the domain and have one-sided limits at the boundary. These functions are called regular functions. It is often agreed to identify functions if they have the same right and left limits at any point.\nThe class \\(D=D[0,T]\\) of right-continuous functions on \\([0,T]\\) with left limits has a special name, cadlag functions (which is the abbreviation of right continuous with left limits in French). Sometimes these processes are called R.R.C. for regular right continuous. Notice that this class of processes includes \\(C\\), the class of continuous functions.\nLet \\(g\\in D\\) be a cadlag function, then, by definition, all the discontinuities of \\(g\\) are jumps. An important result in analysis is that, a function can have no more than a countable number of discontinuities.\n\n\n\nIf \\(g\\) is a function of a real variable, its variation over the interval \\([a,b]\\) is defined as:\n\\[\\begin{aligned}\nV_{g}([a,b]) & =\\sup\\left\\{ \\sum_{i=1}^{n}\\left|g(t_{i})-g(t_{i-1})\\right|\\right\\} \\label{eq:total-variation-of-a-function}\n\\end{aligned}\\]\nwhere the supremum is taken over all partitions \\(P\\in\\mathcal{P}\\).\nClearly, by the Triangle Inequality, the sums in ([eq:total-variation-of-a-function]) increase as new points are added to the partitions. Therefore, the variation of \\(g\\) is:\n\\[\\begin{aligned}\nV_{g}([a,b]) & =\\lim_{||\\Delta_{n}||\\to0}\\sum_{i=1}^{n}\\left|g(t_{i})-g(t_{i-1})\\right|\n\\end{aligned}\\]\nwhere \\(||\\Delta_{n}||=\\max_{1\\leq i\\leq n}(t_{i}-t_{i-1})\\). If \\(V_{g}([a,b])\\) is finite, then \\(g\\) is said to be a function of finite variation on \\([a,b]\\). If \\(g\\) is a function of \\(t\\geq0\\), then the variation of \\(g\\) as a function of \\(t\\) is defined by:\n\\[\\begin{aligned}\nV_{g}(t) & =V_{g}([0,t])\n\\end{aligned}\\]\nClearly, \\(V_{g}(t)\\) is an increasing function of \\(t\\).\n\n\\(g\\) is a function of finite variation if \\(V_{g}(t)&lt;\\infty\\) for all \\(t\\in[0,\\infty)\\). \\(g\\) is of bounded variation if \\(\\sup_{t}V_{g}(t)&lt;\\infty\\), in other words there exists \\(C\\), for all \\(t\\), such that \\(V_{g}(t)&lt;C\\). Here \\(C\\) is independent of \\(t\\).\n\n\n(1) If \\(g(t)\\) is increasing then for any \\(i\\), \\(g(t_{i})\\geq g(t_{i-1})\\), resulting in a telescopic sum, where all terms excluding the first and the last cancel out, leaving\n\\[\\begin{aligned}\nV_{g}(t) & =g(t)-g(0)\n\\end{aligned}\\]\n(2) If \\(g(t)\\) is decreasing, then similarly,\n\\[\\begin{aligned}\nV_{g}(t) & =g(0)-g(t)\n\\end{aligned}\\]\n\n\nIf \\(g(t)\\) is differentiable with continuous derivative \\(g'(t)\\), \\(g(t)=\\int_{0}^{t}g'(s)ds\\) then\n\\[\\begin{aligned}\nV_{g}(t) & =\\int_{0}^{t}|g'(s)|ds\n\\end{aligned}\\]\n\n\nProof. Proof. By definition,\n\\[\\begin{aligned}\nV_{g}(t) & =\\lim_{||\\Delta_{n}\\to0||}\\sum_{i=1}^{n}|g(t_{i})-g(t_{i-1})|\n\\end{aligned}\\]\nSince \\(g\\) is continuous and differentiable on \\([t_{i-1},t_{i}]\\), there exists \\(z_{i}\\in(t_{i-1},t_{i})\\) such, that \\(g(t_{i})-g(t_{i-1})=g'(z_{i})(t_{i}-t_{i-1})\\). Therefore, we can write:\n\\[\\begin{aligned}\n{1}\nV_{g}(t) & =\\lim_{||\\Delta_{n}\\to0||}\\sum_{i=1}^{n}|g'(z_{i})|(t_{i}-t_{i-1})\\\\\n& =\\int_{0}^{t}|g'(s)|ds\n\\end{aligned}\\] ◻\n\n\nIf \\(g\\) is continuous, \\(g'\\) exists and \\(\\int_{0}^{t}|g'(s)|ds\\) is finite, then \\(g\\) is of finite variation.\n\n\nThe function \\(g(t)=t\\sin(1/t)\\) for \\(t&gt;0\\) and \\(g(0)=0\\) is continuous on \\([0,1]\\) and differentiable at all points except zero, but is not of bounded variation on any interval that includes \\(0\\). Consider the partition \\(\\{x_{n}\\}=\\left\\{ \\frac{1}{\\pi/2+n\\pi}\\right\\}\\). Thus,\n\\[\\begin{aligned}\n\\sin(\\frac{1}{x_{n}}) & =\\begin{cases}\n1 & \\text{if }n\\text{ is even}\\\\\n-1 & \\text{if }n\\text{ is odd}\n\\end{cases}\n\\end{aligned}\\]\nThus,\n\\[\\begin{aligned}\nf(x_{n}) & =\\begin{cases}\nx_{n} & n\\text{ is even}\\\\\n-x_{n} & n\\text{ is odd}\n\\end{cases}\n\\end{aligned}\\]\nTherefore,\n\\[\\begin{aligned}\n\\sum_{n=1}^{m}|f(x_{n})-f(x_{n-1})| & =\\sum_{n=1}^{m}(x_{n}+x_{n-1})\\\\\n& =x_{0}+x_{n}+2\\sum_{n=1}^{m-1}x_{n}\\\\\n& \\geq\\sum_{n=1}^{m-1}x_{n}\n\\end{aligned}\\]\nThis is the lower bound on the variation of \\(g\\) on the partition \\(\\{0,x_{m},\\ldots,x_{1},x_{0},1\\}\\). Now, passing to the limit as \\(m\\) approaches infinity, \\(\\sum\\frac{1}{\\pi/2+n\\pi}\\) is a divergent series. Consequently, \\(V_{g}([0,1])\\) has unbounded variation.\n\n\n\n\n\nAny function \\(g:[0,\\infty)\\to\\mathbf{R}\\) is of bounded variation if and only if it can be expressed as the difference of two increasing functions:\n\\[\\begin{aligned}\ng(t) & =a(t)-b(t)\n\\end{aligned}\\]\n\n\nProof. Proof. (\\(\\Longrightarrow\\)direction). If \\(g\\) is of finite variation, \\(V_{g}(t)&lt;\\infty\\) for all \\(t\\), and we can write:\n\\[\\begin{aligned}\ng(t) & =V_{g}(t)-(V_{g}(t)-g(t))\n\\end{aligned}\\]\nLet \\(a(t)=V_{g}(t)\\) and \\(b(t)=V_{g}(t)-g(t)\\). Clearly, both \\(a(t)\\) and \\(b(t)\\) are increasing functions.\n(\\(\\Longleftarrow\\)direction). Suppose a function \\(g\\) can be expressed as a difference of two bounded increasing functions. Then,\n\\[\\begin{aligned}\nV_{g}(t) & =\\lim_{||\\Delta_{n}||\\to0}\\sum_{i=1}^{n}|(a(t_{i})-b(t_{i}))-(a(t_{i-1})-b(t_{i-1})|\\\\\n& \\quad\\{\\text{ Telescoping sum }\\}\\\\\n& =a(t)-b(t)-(a(0)-b(0))\n\\end{aligned}\\]\nSince both \\(a(t)\\) and \\(b(t)\\) are bounded, \\(g\\) has bounded variation. ◻\n\n\n\n\nLet \\(g\\) be a montonically increasing function on a finite closed interval \\([a,b]\\). A bounded function \\(f\\) defined on \\([a,b]\\) is said to Riemann-Stieltjes integrable with respect to \\(g\\) if the following limit exists:\n\\[\\begin{aligned}\n\\int_{a}^{b}f(t)dg(t) & =\\lim_{||\\Delta_{n}||\\to0}\\sum_{i=1}^{n}f(\\tau_{i})(g(t_{i})-g(t_{i-1}))\\label{eq:riemann-stieltjes-integral}\n\\end{aligned}\\]\nwhere \\(\\tau_{i}\\) is an evaluation point in the interval \\([t_{i-1},t_{i}]\\). It is a well-known fact that continuous functions are Riemann integrable and Riemann-Stieltjes integrable with respect to any monotonically increasing function on \\([a,b]\\).\nWe ask the following question. For any continuous functions \\(f\\) and \\(g\\) on \\([a,b]\\), can we define the integral \\(\\int_{a}^{b}f(t)dg(t)\\) by Equation ([eq:riemann-stieltjes-integral])?\nConsider the special case \\(f=g\\), namely, the integral:\n\\[\\int_{a}^{b}f(t)df(t)\\]\nLet \\(\\Delta_{n}=\\{a=t_{0},t_{1},\\ldots,t_{n}=b\\}\\) be a partition of \\([a,b]\\). Let \\(L_{n}\\) and \\(R_{n}\\) denote the corresponding Riemann sums with the evaluation points \\(\\tau_{i}=t_{i-1}\\) and \\(\\tau_{i}=t_{i}\\), respectively, namely,\n\\[\\begin{aligned}\nL_{n} & =\\sum_{i=1}^{n}f(t_{i-1})(f(t_{i})-f(t_{i-1}))\\label{eq:left-riemann-sum}\\\\\nR_{n} & =\\sum_{i=1}^{n}f(t_{i})(f(t_{i})-f(t_{i-1}))\\label{eq:right-riemann-sum}\n\\end{aligned}\\]\nIs it true that, \\(\\lim L_{n}=\\lim R_{n}\\) as \\(||\\Delta_{n}||\\to0\\)? Observe that:\n\\[R_{n}-L_{n}=\\sum_{i=1}^{n}(f(t_{i})-f(t_{i-1}))^{2}\\label{eq:quadratic-variation}\\]\n\\[R_{n}+L_{n}=\\sum_{i=1}^{n}(f(t_{i})^{2}-f(t_{i-1})^{2})=f(b)^{2}-f(a)^{2}\\label{eq:sum-of-left-and-right-riemann-sums}\\]\nTherefore, \\(R_{n}\\) and \\(L_{n}\\) are given by:\n\\[R_{n}=\\frac{1}{2}\\left(f(b)^{2}-f(a)^{2}+\\sum_{i=1}^{n}(f(t_{i})-f(t_{i-1}))^{2}\\right)\\]\n\\[L_{n}=\\frac{1}{2}\\left(f(b)^{2}-f(a)^{2}-\\sum_{i=1}^{n}(f(t_{i})-f(t_{i-1}))^{2}\\right)\\]\nThe limit of the right-hand side of equation ([eq:quadratic-variation]) is called the quadratic variation of the function \\(f\\) on \\([a,b]\\). Obviously, \\(\\lim_{||\\Delta_{n}||\\to0}R_{n}\\neq\\lim_{||\\Delta_{n}||\\to0}L_{n}\\) if and only the quadratic variation of the function \\(f\\) is non-zero.\n\nLet \\(f\\) be a \\(C^{1}\\)-function that is \\(f'(t)\\) is a continuous function. Then, by the mean value theorem:\n\\[\\begin{aligned}\n|R_{n}-L_{n}| & =\\sum_{i=1}^{n}(f(t_{i})-f(t_{i-1}))^{2}\\\\\n& =\\sum_{i=1}^{n}(f'(t_{i}^{*})(t_{i}-t_{i-1}))^{2}\\\\\n& \\quad\\{\\text{Mean Value Theorem}\\}\\\\\n& \\leq\\sum_{i=1}^{n}\\left\\Vert f'\\right\\Vert _{\\infty}^{2}(t_{i}-t_{i-1})^{2}\\\\\n& \\quad\\{\\text{ Interior Extremum Theorem }\\}\\\\\n& \\leq\\left\\Vert f'\\right\\Vert _{\\infty}^{2}\\left\\Vert \\Delta_{n}\\right\\Vert \\sum_{i=1}^{n}(t_{i}-t_{i-1})\\\\\n& =\\left\\Vert f'\\right\\Vert _{\\infty}^{2}\\left\\Vert \\Delta_{n}\\right\\Vert (b-a)\n\\end{aligned}\\]\nwhere \\(\\left\\Vert f'\\right\\Vert _{\\infty}=\\sup_{x\\in[a,b]}f(x)\\). Thus, the limit as \\(\\left\\Vert \\Delta_{n}\\right\\Vert \\to0\\) of the distance \\(|R_{n}-L_{n}|\\) also approaches zero. Thus, \\(\\lim L_{n}=\\lim R_{n}\\) as \\(\\left\\Vert \\Delta_{n}\\right\\Vert \\to0\\) and the Riemann-Stieltjes integral exists. By equation ([eq:sum-of-left-and-right-riemann-sums]), we have:\n\\[\\lim_{\\left\\Vert \\Delta_{n}\\right\\Vert \\to0}L_{n}=\\lim_{\\left\\Vert \\Delta_{n}\\right\\Vert \\to0}R_{n}=\\frac{1}{2}(f(b)^{2}-f(a)^{2})\\]\nOn the other hand, for such a \\(C^{1}\\)-function \\(f\\), we may simply define the integral \\(\\int_{a}^{b}f(t)df(t)\\) by:\n\\[\\begin{aligned}\n\\int_{a}^{b}f(t)df(t) & =\\int_{a}^{b}f(t)f'(t)dt\n\\end{aligned}\\]\nThen, by the fundamental theorem of Calculus:\n\\[\\int_{a}^{b}f(t)df(t)=\\int_{a}^{b}f(t)f'(t)dt=\\frac{1}{2}f(t)^{2}|_{a}^{b}=\\frac{1}{2}(f(b)^{2}-f(a)^{2})\\]\n\n\nThere is a very close relationship between functions with bounded variation and functions for which the classical integral makes sense. For the Ito integral, the quadratic variation plays a similar role. The quadratic variation of a smooth fuction \\(f\\in C^{1}([0,t])\\) is zero.\n\n\nSuppose \\(f\\) is a continuous function satisfying the condition\n\\[\\begin{aligned}\n|f(t)-f(s)| & \\leq C|t-s|^{1/2}\n\\end{aligned}\\]\nwhere \\(0&lt;C&lt;1\\).\nIn this case we have:\n\\[0\\leq|R_{n}-L_{n}|\\leq C^{2}\\sum_{i=1}^{n}(t_{i}-t_{i-1})=C^{2}(b-a)\\]\nHence, \\(\\lim R_{n}\\neq\\lim L_{n}\\) as \\(\\left\\Vert \\Delta_{n}\\right\\Vert \\to0\\) when \\(a\\neq b\\). Consequently, the integral \\(\\int_{a}^{b}f(t)df(t)\\) cannot be defined for such a function \\(f\\). Observe that the quandratic variation of the function is \\(b-a\\) (non-zero).\n\nWe see from the above examples, that definining the integral \\(\\int_{a}^{b}f(t)dg(t)\\) even when \\(f=g\\) is a non-trivial problem. Consider the question posed earlier - if \\(f\\) and \\(g\\) are continuous functions on \\([a,b]\\), can we define the integral \\(\\int_{a}^{b}f(t)dg(t)\\)? There is no simple answer to this question. But then in view of example ([ex:non-zero-quadratic-variation-example]), we can ask another question:\nQuestion. Are there continuous functions \\(f\\) satisfying the condition\n\\[\\begin{aligned}\n|f(t)-f(s)| & \\leq C|t-s|^{1/2}\n\\end{aligned}\\]\n\n\n\nConsider a random walk starting at \\(0\\) with jumps \\(h\\) and \\(-h\\) equally at times \\(\\delta\\), \\(2\\delta\\), \\(\\ldots\\) where \\(h\\) and \\(\\delta\\) are positive numbers. More precisely, let \\(\\{X_{n}\\}_{n=1}^{\\infty}\\) be a sequence of independent and identically distributed random variables with :\n\\[\\begin{aligned}\n\\mathbb{P}\\{X_{j}=h\\} & =\\mathbb{P}\\{X_{j}=-h\\}=\\frac{1}{2}\n\\end{aligned}\\]\nLet \\(Y_{\\delta,h}(0)=0\\) and put:\n\\[\\begin{aligned}\nY_{\\delta,h}(n\\delta) & =X_{1}+X_{2}+\\ldots+X_{n}\n\\end{aligned}\\]\nFor \\(t&gt;0\\), define \\(Y_{\\delta,h}(t)\\) by linearization that is, for \\(n\\delta&lt;t&lt;(n+1)\\delta\\), define:\n\\[\\begin{aligned}\nY_{\\delta,h}(t) & =\\frac{(n+1)\\delta-t}{\\delta}Y_{\\delta,h}(n\\delta)+\\frac{t-n\\delta}{\\delta}Y_{\\delta,h}((n+1)\\delta)\n\\end{aligned}\\]\nWe can think of \\(Y_{\\delta,h}(t)\\) as the position of the random walk at time \\(t\\). In particular, \\(X_{1}+X_{2}+\\ldots+X_{n}\\) is the position of this random walk at time \\(n\\delta\\).\nQuestion. What is the limit of the random walk \\(Y_{\\delta,h}\\) as \\(\\delta,h\\to0\\)?\nRecall that the characteristic function of a random variable \\(X\\) is \\(\\phi_{X}(\\lambda)=\\mathbb{E}\\exp[i\\lambda X]\\). In order to find out the answer, let us compute the following limit of the characteristic function of \\(Y_{\\delta,h}(t)\\):\n\\[\\lim_{\\delta,h\\to0}\\mathbb{E}\\exp\\left[i\\lambda Y_{\\delta,h}(t)\\right]\\]\nwhere \\(\\lambda\\in\\mathbf{R}\\)is fixed. For heuristic derivation, let \\(t=n\\delta\\) and so \\(n=t/\\delta\\). Then we have:\n\\[\\begin{aligned}\n\\mathbb{E}\\exp\\left[i\\lambda Y_{\\delta,h}(t)\\right] & =\\prod_{j=1}^{n}\\mathbb{E}e^{i\\lambda X_{j}}\\\\\n& =\\prod_{j=1}^{n}\\left(\\frac{1}{2}e^{i\\lambda h}+\\frac{1}{2}e^{-i\\lambda h}\\right)\\\\\n& =\\left(\\frac{1}{2}e^{i\\lambda h}+\\frac{1}{2}e^{-i\\lambda h}\\right)^{n}\\\\\n& =\\left(\\cos\\lambda h\\right)^{n}\\\\\n& =\\left(\\cos\\lambda h\\right)^{t/\\delta}\n\\end{aligned}\\]\nFor fixed \\(t\\) and \\(\\lambda\\), when \\(\\delta\\) and \\(h\\) independently approach \\(0\\), the limit of \\(\\mathbb{E}\\exp\\left[i\\lambda Y_{\\delta,h}(t)\\right]\\) may not exist. For example, holding \\(h\\) constant, letting \\(\\delta\\to0\\), since \\(-1\\leq\\cos\\theta\\leq1\\), the function \\(\\left(\\cos\\lambda h\\right)^{t/\\delta}\\to0\\). Holding \\(\\delta\\) constant, letting \\(h\\to0\\), the function \\(\\left(\\cos\\lambda h\\right)^{t/\\delta}\\to1\\). In order for the limit to exist, we impose a certain relationship between \\(\\delta\\) and \\(h\\). However, depending on the relationship, we may obtain different limits.\nLet \\(u=\\cos(\\lambda h)^{1/\\delta}\\). Then \\(\\ln u=\\frac{1}{\\delta}\\ln\\cos(\\lambda h)\\). Note that:\n\\[\\begin{aligned}\n\\cos(\\lambda h) & \\approx1-\\frac{1}{2}\\lambda^{2}h^{2}\n\\end{aligned}\\]\nAnd \\(\\ln(1+x)\\approx x\\). Hence,\n\\[\\ln\\cos(\\lambda h)\\approx\\ln\\left(1-\\frac{1}{2}\\lambda^{2}h^{2}\\right)\\approx-\\frac{1}{2}\\lambda^{2}h^{2}\\]\nTherefore for small \\(\\lambda\\) and \\(h\\), we have \\(\\ln u\\approx-\\frac{1}{2\\delta}\\lambda^{2}h^{2}\\) and so:\n\\[\\begin{aligned}\nu & \\approx\\exp\\left[-\\frac{1}{2\\delta}\\lambda^{2}h^{2}\\right]\n\\end{aligned}\\]\nIn particular, if \\(\\delta\\) and \\(h\\) are related by \\(h^{2}=\\delta\\), then\n\\[\\begin{aligned}\n\\lim_{\\delta\\to0}\\mathbb{E}\\exp\\left[i\\lambda Y_{\\delta,h}(t)\\right] & =e^{-\\frac{1}{2}\\lambda^{2}t}\n\\end{aligned}\\]\nBut, \\(e^{-\\frac{1}{2}\\lambda^{2}t}\\) is the characteristic function of a Gaussian random variable with mean \\(0\\) and variance \\(t\\). Thus, we have derived the following theorem about the limit of the random walk \\(Y_{\\delta,h}\\) as \\(\\delta,h\\to0\\) in such a way that \\(h^{2}=\\delta\\).\n\nLet \\(Y_{\\delta,h}(t)\\) be the random walk starting at \\(0\\) with jumps \\(h\\) and \\(-h\\) equally likely at times \\(\\delta\\), \\(2\\delta\\), \\(3\\delta\\), \\(\\ldots\\). Assume that \\(h^{2}=\\delta\\). Then, for each \\(t\\geq0\\), the limit:\n\\[\\begin{aligned}\n\\lim_{\\delta\\to0}Y_{\\delta,h}(t) & =B(t)\n\\end{aligned}\\] exists in distribution. Moreover, we have:\n\\[\\begin{aligned}\n\\mathbb{E}e^{i\\lambda B(t)} & =e^{-\\frac{1}{2}\\lambda^{2}t}\n\\end{aligned}\\]\n\n\n(Quadratic Variation of a Brownian motion). Let \\((B_{t},t\\ge0)\\) be a standard brownian motion. Then, for any sequence of partitions \\((t_{j},j\\leq n)\\) of \\([0,t]\\) we have:\n\\[\\begin{aligned}\n\\left\\langle B\\right\\rangle _{t} & =\\sum_{j=1}^{n}(B_{t_{j+1}}-B_{t_{j}})^{2}\\stackrel{L^{2}}{\\to}t\n\\end{aligned}\\]\nwhere the convergence is in the \\(L^{2}\\) sense.\n\n\nIt is reasonable to have some sort of convergence as we are dealing with a sum of independent random variables. However, the conclusion would not hold if the increments were not squared. So there is something more at play here.\n\n\nProof. Proof. We have:\n\\[\\begin{aligned}\n\\mathbb{E}\\left[\\left(\\sum_{j=0}^{n-1}(B(t_{j+1})-B(t_{j}))^{2}-t\\right)^{2}\\right] & =\\mathbb{E}\\left[\\left(\\sum_{j=0}^{n-1}(B(t_{j+1})-B(t_{j}))^{2}-\\sum_{j=0}^{n-1}(t_{j+1}-t_{j})\\right)^{2}\\right]\\\\\n& =\\mathbb{E}\\left[\\left(\\sum_{j=0}^{n-1}\\left\\{ (B(t_{j+1})-B(t_{j}))^{2}-(t_{j+1}-t_{j})\\right\\} \\right)^{2}\\right]\n\\end{aligned}\\]\nFor simplicity, we define the variables \\(X_{j}=(B(t_{j+1})-B(t_{j}))^{2}-(t_{j+1}-t_{j})\\). Then, we may write:\n\\[\\begin{aligned}\n\\mathbb{E}\\left[\\left(\\sum_{j=0}^{n-1}(B(t_{j+1})-B(t_{j}))^{2}-t\\right)^{2}\\right] & =\\mathbb{E}\\left[\\left(\\sum_{j=0}^{n-1}X_{j}\\right)^{2}\\right]\\\\\n& =\\mathbb{E}\\left[\\sum_{i=0}^{n-1}\\sum_{j=0}^{n-1}X_{i}X_{j}\\right]\\\\\n& =\\sum_{i=0}^{n-1}\\sum_{j=0}^{n-1}\\mathbb{E}[X_{i}X_{j}]\n\\end{aligned}\\]\nNow, the random variables \\(X_{j}\\) are independent.\nThe expectation of \\(X_{j}\\) is \\(\\mathbb{E}[X_{j}]=\\mathbb{E}(B(t_{j+1})-B(t_{j}))^{2}-(t_{j+1}-t_{j})=0\\).\nSince, \\(X_{i}\\) and \\(X_{j}\\) are independent, for \\(i\\neq j\\), \\(\\mathbb{E}[X_{i}X_{j}]=\\mathbb{E}X_{i}\\cdot\\mathbb{E}X_{j}=0\\).\nHence, we have:\n\\[\\begin{aligned}\n\\mathbb{E}\\left[\\left(\\sum_{j=0}^{n-1}(B(t_{j+1})-B(t_{j}))^{2}-t\\right)^{2}\\right] & =\\sum_{i=0}^{n-1}\\mathbb{E}[X_{i}^{2}]\n\\end{aligned}\\]\nWe now develop the expectation of the square of \\(X_{i}\\). We have:\n\\[\\begin{aligned}\n\\mathbb{E}[X_{i}^{2}] & =\\mathbb{E}\\left[\\left((B(t_{i+1})-B(t_{i}))^{2}-(t_{i+1}-t_{i})\\right)^{2}\\right]\\\\\n& =\\mathbb{E}\\left[((B(t_{i+1})-B(t_{i}))^{4}-2(B(t_{i+1})-B(t_{i}))^{2}(t_{i+1}-t_{i})+(t_{i+1}-t_{i})^{2}\\right]\n\\end{aligned}\\]\nThe MGF of the random variable \\(B(t_{i+1})-B(t_{i})\\) is :\n\\[\\begin{aligned}\n\\phi(\\lambda) & =\\exp\\left[\\frac{\\lambda^{2}(t_{i+1}-t_{i})}{2}\\right]\\\\\n\\phi'(\\lambda) & =\\lambda(t_{i+1}-t_{i})\\exp\\left[\\frac{\\lambda^{2}(t_{i+1}-t_{i})}{2}\\right]\\\\\n\\phi''(\\lambda) & =\\left[(t_{i+1}-t_{i})+\\lambda^{2}(t_{i+1}-t_{i})^{2}\\right]\\exp\\left[\\frac{\\lambda^{2}(t_{i+1}-t_{i})}{2}\\right]\\\\\n\\phi^{(3)}(\\lambda) & =\\left[3\\lambda(t_{i+1}-t_{i})^{2}+\\lambda^{3}(t_{i+1}-t_{i})^{3}\\right]\\exp\\left[\\frac{\\lambda^{2}(t_{i+1}-t_{i})}{2}\\right]\\\\\n\\phi^{(4)}(\\lambda) & =\\left[3(t_{i+1}-t_{i})^{2}+6\\lambda^{2}(t_{i+1}-t_{i})^{3}+\\lambda^{4}(t_{i+1}-t_{i})^{4}\\right]\\exp\\left[\\frac{\\lambda^{2}(t_{i+1}-t_{i})}{2}\\right]\n\\end{aligned}\\]\nThus, \\(\\mathbb{E}[(B(t_{i+1})-B(t_{i}))^{4}]=3(t_{i+1}-t_{i})^{2}\\). Consequently,\n\\[\\begin{aligned}\n\\mathbb{E}[X_{i}^{2}] & =\\mathbb{E}[(B(t_{i+1})-B(t_{i}))^{4}]-2(t_{i+1}-t_{i})\\mathbb{E}[(B(t_{i+1})-B(t_{i}))^{2}]+(t_{i+1}-t_{i})^{2}\\\\\n& =3(t_{i+1}-t_{i})^{2}-2(t_{i+1}-t_{i})^{2}+(t_{i+1}-t_{i})^{2}\\\\\n& =2(t_{i+1}-t_{i})^{2}\n\\end{aligned}\\]\nPutting all this together, we finally have that:\n\\[\\begin{aligned}\n\\mathbb{E}\\left[\\left(\\sum_{j=0}^{n-1}(B(t_{j+1})-B(t_{j}))^{2}-t\\right)^{2}\\right] & =2\\sum_{i=0}^{n-1}(t_{i+1}-t_{i})^{2}\\label{eq:second-moment-of-qv}\\\\\n& \\leq2\\left\\Vert \\Delta_{n}\\right\\Vert \\sum_{i=0}^{n-1}(t_{i+1}-t_{i})\\nonumber \\\\\n& =2\\left\\Vert \\Delta_{n}\\right\\Vert \\cdot t\\nonumber\n\\end{aligned}\\]\nAs \\(n\\to\\infty\\), \\(\\left\\Vert \\Delta_{n}\\right\\Vert \\to0\\). Hence,\n\\[\\begin{aligned}\n\\lim_{n\\to\\infty}\\mathbb{E}\\left[\\left(\\sum_{j=0}^{n-1}(B(t_{j+1})-B(t_{j}))^{2}-t\\right)^{2}\\right] & =0\n\\end{aligned}\\]\nHence, the sequence of random variables\n\\[\\begin{aligned}\n\\sum_{j=0}^{n-1}(B(t_{j+1})-B(t_{j}))^{2} & \\stackrel{L^{2}}{\\to}t\n\\end{aligned}\\] ◻\n\n\n(Quadratic Variation of a Brownian Motion Path). Let \\((B_{s},s\\geq0)\\) be a Brownian motion. For every \\(n\\in\\mathbf{N}\\), consider the dyadic partition \\((t_{j},j\\leq2^{n})\\) of \\([0,t]\\) where \\(t_{j}=\\frac{j}{2^{n}}t\\). Then we have that:\n\\[\\begin{aligned}\n\\left\\langle B\\right\\rangle _{t} & =\\sum_{j=1}^{2^{n}-1}(B_{t_{j+1}}-B_{t_{j}})^{2}\\stackrel{a.s.}{\\to}t\n\\end{aligned}\\]\n\n\nProof. Proof. We have \\((t_{i+1}-t_{i})=\\frac{t}{2^{n}}.\\) Borrowing equation ([eq:second-moment-of-qv]) from the proof of theorem ([th:quadratic-variation-of-bm-approaches-t-in-mean-square]), we have that:\n\\[\\begin{aligned}\n\\mathbb{E}\\left[\\left(\\sum_{j=0}^{2^{n}-1}(B(t_{j+1})-B(t_{j}))^{2}-t\\right)^{2}\\right] & =2\\sum_{i=0}^{2^{n}-1}\\left(\\frac{t}{2^{n}}\\right)^{2}\\\\\n& =2\\cdot(2^{n})\\cdot\\frac{t^{2}}{2^{2n}}\\\\\n& =\\frac{2t^{2}}{2^{n}}\n\\end{aligned}\\]\nBy Chebyshev’s inequality,\n\\[\\begin{aligned}\n\\mathbb{P}\\left(\\left|\\sum_{j=0}^{2^{n}-1}(B(t_{j+1})-B(t_{j}))^{2}-t\\right|&gt;\\epsilon\\right) & \\leq\\frac{1}{\\epsilon^{2}}\\mathbb{E}\\left[\\left(\\sum_{j=0}^{2^{n}-1}(B(t_{j+1})-B(t_{j}))^{2}-t\\right)^{2}\\right]\\\\\n& \\leq\\frac{1}{\\epsilon^{2}}\\cdot\\frac{2t^{2}}{2^{n}}\n\\end{aligned}\\]\nDefine \\(A_{n}:=\\left\\{ \\left|\\sum_{j=0}^{2^{n}-1}(B(t_{j+1})-B(t_{j}))^{2}-t\\right|&gt;\\epsilon\\right\\}\\). Since, \\(\\sum\\frac{1}{2^{n}}\\) is a convergent series, any multiple of it, \\((2t^{2}/\\epsilon^{2})\\sum\\frac{1}{2^{n}}\\) also converges. Now, \\(0\\leq\\mathbb{P}(A_{n})\\leq\\frac{(2t^{2}/\\epsilon^{2})}{2^{n}}\\). By the comparison test, \\(\\sum\\mathbb{P}(A_{n})\\) converges to a finite value. By Theorem ([th:sufficient-condition-for-almost-sure-convergence]),\n\\[\\begin{aligned}\n\\sum_{j=0}^{2^{n}-1}(B(t_{j+1})-B(t_{j}))^{2} & \\stackrel{a.s.}{\\to}t\n\\end{aligned}\\] ◻\n\nWe are now ready to show that every Brownian motion path has infinite variation.\nIf \\(g\\) is a \\(C^{1}\\) function,\n\\[\\begin{aligned}\n\\int_{0}^{t}|g'(t)|dt & =\\int_{0}^{t}\\sqrt{g'(t)^{2}}dt\\\\\n& \\leq\\int_{0}^{t}\\sqrt{1+g'(t)^{2}}dt\\\\\n& =l_{g}(t)\n\\end{aligned}\\]\nwhere \\(l_{g}(t)\\) is the arclength of the function \\(g\\) between \\([0,t]\\). So, \\(V_{g}(t)\\leq l_{g}(t)\\) and further:\n\\[\\begin{aligned}\nl_{g}(t) & =\\int_{0}^{t}\\sqrt{1+g'(t)^{2}}dt\\\\\n& \\leq\\int_{0}^{t}\\left(1+\\sqrt{g'(t)^{2}}\\right)dt\\\\\n& \\leq t+V_{g}(t)\n\\end{aligned}\\]\nConsequently,\n\\[\\begin{aligned}\nV_{g}(t) & \\leq l_{g}(t)\\leq t+V_{g}(t)\n\\end{aligned}\\]\nThe total variation of the function is finite if and only if it’s arclength is.\nHence, intuitively, our claim is that a Brownian motion path on \\([0,T]\\) has infinite arc-length. Since \\(g\\in C^{1}([a,b])\\Longrightarrow(V_{g}(t)&lt;\\infty)\\), it follows that \\((V_{g}(t)\\to\\infty)\\Longrightarrow g\\notin C^{1}\\).\n\n(Brownian Motion paths have unbounded total variation.)  Let \\((B_{s},s\\geq0)\\) be a Brownian motion. Then, the random functions \\(B(s,\\omega)\\) on the interval \\([0,t]\\) have unbounded variation almost surely.\n\n\nProof. Proof. Take the sequence of dyadic partitions of \\([0,t]\\): \\(t_{j}=\\frac{j}{2^{n}}t\\), \\(n\\in\\mathbf{N}\\), \\(j\\leq2^{n}\\). By pulling out the worst increment, we have the trivial bound for every \\(\\omega\\):\n\\[\\begin{aligned}\n\\sum_{j=0}^{2^{n}-1}(B_{t_{j+1}}(\\omega)-B_{t_{j}}(\\omega))^{2} & \\leq\\max_{0\\leq j\\leq2^{n}}\\left|B_{t_{j+1}}(\\omega)-B_{t_{j}}(\\omega)\\right|\\cdot\\sum_{j=0}^{2^{n}-1}(B_{t_{j+1}}(\\omega)-B_{t_{j}}(\\omega))\\label{eq:trivial-upper-bound-on-quadratic-variation}\n\\end{aligned}\\]\nWe proceed by contradiction. Let \\(A'\\) be the set of all \\(\\omega\\), for which the Brownian motion paths have bounded total variation. Let \\(A\\) be event that the Brownian motion paths have unbounded variation.\nBy the definition of total variation, that would imply, \\(\\exists M\\in\\mathbf{N}\\) :\n\\[\\begin{aligned}\n(\\forall\\omega\\in A')\\quad\\lim_{n\\to\\infty}\\sum_{j=0}^{2^{n}-1}\\left|(B_{t_{j+1}}(\\omega)-B_{t_{j}}(\\omega))\\right| & &lt;M\n\\end{aligned}\\]\nSince Brownian Motion paths are continuous on the compact set \\([\\frac{j}{2^{n}}t,\\frac{j+1}{2^{n}}t]\\), they are uniformly continuous. So, as \\(n\\to\\infty\\), \\(|t_{j+1}-t_{j}|\\to0\\) and therefore \\(|B_{t_{j+1}}(\\omega)-B_{t_{j}}(\\omega)|\\to0\\). And consequently, \\(\\max_{0\\leq j\\leq2^{n}}\\left|B_{t_{j+1}}(\\omega)-B_{t_{j}}(\\omega)\\right|\\to0\\).\nThus, for every \\(\\omega\\in A'\\), the right hand side of the inequality ([eq:trivial-upper-bound-on-quadratic-variation]), converges to \\(0\\) and therefore the left hand side converges to \\(0\\). But, this contradicts the fact that \\(\\left\\langle B\\right\\rangle _{t}\\stackrel{a.s.}{\\to}t\\). So, \\(A'\\) is a null set, and \\(\\mathbb{P}(A')=0\\) and \\(\\mathbb{P}(A)=1\\). This closes the proof. ◻\n\n\n\n\n\nIf we make the simplifying assumption that the process paths are continuous, we obtain the set of all continuous functions on \\([0,T]\\), denoted by \\(C[0,T]\\). This is a very rich space. In a more general model, it is assumed that the process paths are right continuous with left limits (regular right-continuous RRC, cadlag) functions.\nLet the sample space \\(\\Omega=D[0,T]\\) be the set of all RRC functions on \\([0,T]\\). An element of this set is a RRC function from \\([0,T]\\) into \\(\\mathbf{R}\\). First we must decide what kind of sets of these functions are measurable? The simplest set for which we would like to calculate the probabilities are sets of the form \\(\\{a\\leq S(t_{1})\\leq b\\}\\) for some \\(t_{1}\\). If \\(S(t)\\) represents the price of a stock at time \\(t\\), then the probability of such a set gives the probability that the stock price at time \\(t_{1}\\) is between \\(a\\) and \\(b\\). We are also interested in how the price of the stock at time \\(t_{1}\\) affects the price at another time \\(t_{2}\\). Thus, we need to talk about the joint distribution of stock prices \\(S(t_{1})\\) and \\(S(t_{2})\\). This means that we need to define probability on the sets of the form \\(\\{S(t_{1})\\in B_{1},S(t_{2})\\in B_{2}\\}\\) where \\(B_{1}\\) and \\(B_{2}\\) are intervals on the line. More generally, we would like to have all the finite-dimensional distributions of the process \\(S(t)\\), that is, the probabilities of the sets: \\(\\{S(t_{1})\\in B_{1},S(t_{2})\\in B_{2},\\ldots,S(t_{n})\\in B_{n}\\}\\) for any choice of \\(0\\leq t_{1}\\leq\\ldots\\leq t_{n}\\leq T\\).\nThe sets of the form \\(A=\\{\\omega(\\cdot)\\in D[0,T]:\\omega(t_{1})\\in B_{1},\\ldots,\\omega(t_{n})\\in B_{n}\\}\\), where \\(B_{i}\\)’s are borel subsets of \\(\\mathbf{R}\\), are called cylinder sets or finite-dimensional rectangles.\nThe stochastic process \\(S(t)\\) is just a (function-valued) random variable on this sample space, which takes some value \\(\\omega(t)\\) - the value of the function \\(\\omega\\) at \\(t\\).\nLet \\(\\mathcal{R}\\) be the colllection of all cylindrical subsets of \\(D[0,1]\\). Obviously \\(\\mathcal{R}\\) is not a \\(\\sigma\\)-field.\nProbability is first defined by on the elements of \\(\\mathcal{R}\\). Let \\(A\\subseteq\\mathcal{R}\\).\n\\[\\begin{aligned}\n\\mathbb{P}(A) & =\\int_{B_{1}}\\cdots\\int_{B_{n}}\\prod_{i=1}^{n}\\frac{1}{\\sqrt{(2\\pi)(t_{i}-t_{i-1})}}\\exp\\left[-\\frac{(u_{i}-u_{i-1})^{2}}{2(t_{i}-t_{i-1})}\\right]du_{1}\\cdots du_{n}\n\\end{aligned}\\]\nand then extended to the \\(\\sigma\\)-field generated by taking unions, complements and intersections of cylinders. We take the smallest \\(\\sigma\\)-algebra containing all the cylindrical subsets of \\(D[0,1]\\). Thus, \\(\\mathcal{F}=\\mathcal{B}(D[0,1])\\).\nHence, \\((\\Omega,\\mathcal{F},\\mathbb{P})=(D[0,1],\\mathcal{B}(D[0,1]),\\mathbb{P})\\) is a probability space. It is called the Wiener space and \\(\\mathbb{P}\\) here is called the Wiener measure.\n\n\n\nAs discussed in the previous section, a stochastic process is determined by its finite-dimensional distribution. In studying stochastic processes, it is often natural to think of them as function-valued random variables in \\(t\\). Let \\(S(t)\\) be defined for \\(0\\leq t\\leq T\\), then for a fixed \\(\\omega\\), it is a function in \\(t\\), called the sample path or a realization of \\(S\\). Finite-dimensional distributions do not determine the continuity property of sample paths. The following example illustrates this.\n\nLet \\(X(t)=0\\) for all \\(t\\), \\(0\\leq t\\leq1\\) and \\(\\tau\\) be a uniformly distributed random variable on \\([0,1]\\). Let \\(Y(t)=0\\) for \\(t\\neq\\tau\\) and \\(Y(t)=1\\) if \\(t=\\tau.\\) Then, for any fixed \\(t\\), \\(\\mathbb{P}(Y(t)\\neq0)=\\mathbb{P}(\\tau=t)=0\\), and hence \\(\\mathbb{P}(Y(t)=0)=1\\). So, that all one-dimensional distributions of \\(X(t)\\) and \\(Y(t)\\) are the same. Similarly, all finite-dimensional distributions of \\(X\\) and \\(Y\\) are the same. However, the sample paths of the process \\(X\\), that is, the functions \\(X(t)_{0\\leq t\\leq1}\\) are continuous in \\(t\\), whereas every sample path \\(Y(t)_{0\\leq t\\leq1}\\) has a jump at the (random) point \\(\\tau\\). Notice that, \\(\\mathbb{P}(X(t)=Y(t))=1\\) for all \\(t\\), \\(0\\leq t\\leq1\\).\n\n\nTwo stochastic processes are called versions (modifications) of one another if\n\\[\\mathbb{P}(X(t)=Y(t))=1\\quad\\text{for all }0\\leq t\\leq T\\]\n\nThus, the two processes in the example ([ex:modifications-of-a-stochastic-process]) are versions of one another, one has continuous sample paths, the other does not. If we agree to pick any version of the process we want, then we can pick the continous version when it exists. In general, we choose the smoothest possible version of the process.\nFor two processes, \\(X\\) and \\(Y\\), denote by \\(N_{t}=\\{X(t)\\neq Y(t)\\}\\), \\(0\\leq t\\leq T\\). In the above example, \\(\\mathbb{P}(N_{t})=\\mathbb{P}(\\tau=t)=0\\) for any \\(t\\), \\(0\\leq t\\leq1\\). However, \\(\\mathbb{P}(\\bigcup_{0\\leq t\\leq1}N_{t})=\\mathbb{P}(\\tau=t\\:\\text{for some }t\\:\\text{in }[0,1])=1\\). Although, each of \\(N_{t}\\) is a \\(\\mathbb{P}\\)-null set, the union \\(N=\\bigcup_{0\\leq t\\leq1}N_{t}\\) contains uncountably many null sets, and in this particular case it is a set of of probability one.\nIf it happens that \\(\\mathbb{P}(N)=0\\), then \\(N\\) is called an evanescent set, and the processes \\(X\\) and \\(Y\\) are called indistinguishable. Note that in this case, \\(\\mathbb{P}(\\{\\omega:\\exists t:X(t)\\neq Y(t)\\})=\\mathbb{P}(\\bigcup_{0\\leq t\\leq1}\\{X(t)\\neq Y(t))=0\\) and \\(\\mathbb{P}(\\bigcap_{0\\leq t\\leq1}\\{X(t)=Y(t)\\})=1\\). It is clear, that if the time is discrete, then any two versions of the process are indistinguishable. It is also not hard to see, that if \\(X(t)\\) and \\(Y(t)\\) are versions of one another and they are both right-continuous, they are indistinguishable.\n\n(Paul Levy’s construction of Brownian Motion). Standard Brownian motion exists.\n\n\nProof. Proof. I reproduce the standard proof as present in Brownian Motion by Morters and Peres. I added some remarks for greater clarity.\nLet\n\\[\\begin{aligned}\n\\mathcal{D}_{n} & =\\left\\{ \\frac{k}{2^{n}}:k=0,1,2,\\ldots,2^{n}\\right\\}\n\\end{aligned}\\]\nbe a finite set of dyadic points.\nLet\n\\[\\begin{aligned}\n\\mathcal{D} & =\\bigcup_{n=0}^{\\infty}\\mathcal{D}_{n}\n\\end{aligned}\\]\nLet \\(\\{Z_{t}:t\\in\\mathcal{D}\\}\\) be a collection of independent, standard normally distributed random variables. This is a countable set of random variables.\nLet \\(B(0):=0\\) and \\(B(1):=Z_{1}\\).\nFor each \\(n\\in\\mathbf{N}\\), we define the random variables \\(B(d)\\), \\(d\\in\\mathcal{D}_{n}\\) such that, the following invariant holds:\n(1) for all \\(r&lt;s&lt;t\\) in \\(\\mathcal{D}_{n}\\) the random variable \\(B(t)-B(s)\\) is normally distributed with mean zero and variance \\(t-s\\) and is independent of \\(B(s)-B(r)\\).\n(2) the vectors \\((B(d):d\\in\\mathcal{D}_{n})\\) and \\((Z_{t}:t\\in\\mathcal{D}\\setminus\\mathcal{D}_{n})\\) are independent.\nNote that we have already done this for \\(\\mathcal{D}_{0}=\\{0,1\\}\\). Proceeding inductively, let’s assume that the above holds for some \\(n-1\\). We are interested to prove that the invariant also holds for \\(n\\).\nWe define \\(B(d)\\) for \\(d\\in\\mathcal{D}_{n}\\backslash\\mathcal{D}_{n-1}\\) by:\n\\[\\begin{aligned}\nB(d) & =\\frac{B(d-2^{-n})+B(d+2^{-n})}{2}+\\frac{Z_{d}}{2^{(n+1)/2}}\n\\end{aligned}\\]\nNote that, the points \\(0,\\frac{1}{2^{n-1}},\\ldots,\\frac{k}{2^{n-1}},\\frac{k+1}{2^{n-1}},\\ldots,1\\) belong to \\(\\mathcal{D}_{n-1}\\). The first summand is the linear interpolation of the values of \\(B\\) at the neighbouring points of \\(d\\) in \\(\\mathcal{D}_{n-1}\\). That is,\n\\[\\begin{aligned}\nB\\left(\\frac{2k+1}{2^{n}}\\right) & =\\frac{B\\left(\\frac{k}{2^{n-1}}\\right)+B\\left(\\frac{k+1}{2^{n-1}}\\right)}{2}+\\frac{Z_{d}}{2^{(n+1)/2}}\n\\end{aligned}\\]\nSince \\(P(n-1)\\) holds, \\(B(d-2^{-n})\\) and \\(B(d+2^{-n})\\) are have no dependence on \\((Z_{t}:t\\in\\mathcal{D}\\setminus\\mathcal{D}_{n-1})\\). Consequently, \\(B(d)\\) has no dependence on \\((Z_{t}:t\\in\\mathcal{D}\\setminus\\mathcal{D}_{n})\\) and the second property is fulfilled.\nMoreover, as \\(\\frac{1}{2}[B(d+2^{-n})-B(d-2^{-n})]\\) depends only on \\((Z_{t}:t\\in\\mathcal{D}_{n-1})\\), it is independent of \\(\\frac{Z_{d}}{2^{(n+1)/2}}\\). By our induction assumptions, they are both nromally distributed with mean \\(0\\) and variance \\(\\frac{1}{2^{(n+1)}}\\).\nSo, their sum and difference random variables\n\\[\\begin{aligned}\nB(d)-B(d-2^{-n}) & =\\frac{B(d+2^{-n})-B(d-2^{-n})}{2}+\\frac{Z_{d}}{2^{(n+1)/2}}\\\\\nB(d+2^{-n})-B(d) & =\\frac{B(d+2^{-n})-B(d-2^{-n})}{2}-\\frac{Z_{d}}{2^{(n+1)/2}}\n\\end{aligned}\\]\nare also independent, with mean \\(0\\) and variance \\(\\frac{1}{2^{n}}\\) (the variance of independent random variables is the sum of the variances).\nIndeed all increments \\(B(d)-B(d-2^{-n})\\) for \\(d\\in\\mathcal{D}_{n}\\setminus\\{0\\}\\) are independent. To see this, it suffices to show that they are pairwise independent. We have seen in the previous paragraph that the pairs \\(B(d)-B(d-2^{-n})\\) and \\(B(d+2^{-n})-B(d)\\) with \\(d\\in\\mathcal{D}_{n}\\setminus\\mathcal{D}_{n-1}\\) are independent. The other possibility is that the increments are over the intervals separated by some \\(d\\in\\mathcal{D}_{n-1}\\). For concreteness, if \\(n\\) were \\(3\\), then the increments, \\(B_{7/8}-B_{6/8}\\) and \\(B_{5/8}-B_{4/8}\\) are seperated by \\(d=\\frac{3}{4}\\in\\mathcal{D}_{2}\\). Choose \\(d\\in\\mathcal{D}_{j}\\) with this property and minimal \\(j\\), so, the two intervals are contained in \\([d-2^{-j},d]\\) and \\([d,d+2^{-j}]\\) respectively. By induction, the increments over these two intervals of length \\(2^{-j}\\) are independent and the increments over the intervals of length \\(2^{-n}\\) are constructed from the independent increments \\(B(d)-B(d-2^{-j})\\) and \\(B(d+2^{-j})-B(d)\\) using a disjoint set of variables \\((Z_{t}:t\\in\\mathcal{D}_{n})\\). Hence, they are independent and this implies pairwise independence. This implies the first property. Consequently, the vector of increments \\((B(d)-B(d-2^{-n})\\) for all \\(d\\in\\mathcal{D}_{n}\\) is Gaussian.\nHaving thus chosen the value of the process on all the dyadic points, we interpolate between them. Formally, we define:\n\\[\\begin{aligned}\nF_{0}(t) & =\\begin{cases}\nZ_{1} & \\text{for }t=1\\\\\n0 & \\text{for }t=0\\\\\n\\text{\\text{linear in between}}\n\\end{cases}\n\\end{aligned}\\]\nand for each \\(n\\geq1\\),\n\\[\\begin{aligned}\nF_{n}(t) & =\\begin{cases}\n\\frac{Z_{t}}{2^{(n+1)/2}} & \\text{for }t\\in\\mathcal{D}\\setminus\\mathcal{D}_{n-1}\\\\\n0 & \\text{for }t\\in\\mathcal{D}_{n-1}\\\\\n\\text{\\text{linear between consecutive points in }\\ensuremath{\\mathcal{D}_{n}}}\n\\end{cases}\n\\end{aligned}\\]\nThese functions are continuous on \\([0,1]\\) and for all \\(n\\) and \\(d\\in\\mathcal{D}_{n}\\), we have:\n\\[\\begin{aligned}\nB(d) & =\\sum_{i=0}^{n}F_{i}(d)=\\sum_{i=0}^{\\infty}F_{i}(d)\\label{eq:claim-of-induction-for-bd}\n\\end{aligned}\\]\nTo see this, assume that above equation holds for all \\(d\\in\\mathcal{D}_{n-1}\\).\nLet’s consider the point \\(d\\in\\mathcal{D}_{n}\\setminus\\mathcal{D}_{n-1}\\).\n\\[\\begin{aligned}\nB(d) & =\\frac{B(d-2^{-n})+B(d+2^{-n})}{2}+\\frac{Z_{d}}{2^{(n+1)/2}}\\nonumber \\\\\n& =\\sum_{i=0}^{n-1}\\frac{F_{i}(d-2^{-n})+F_{i}(d+2^{-n})}{2}+\\frac{Z_{d}}{2^{(n+1)/2}}\\label{eq:expression-for-bd}\n\\end{aligned}\\]\nNow, \\(d-2^{-n}\\) and \\(d+2^{-n}\\) belong to \\(\\mathcal{D}_{n-1}\\) and are not in \\(\\bigcup_{i&lt;n-1}\\mathcal{D}_{i}\\). Therefore, for \\(i=0,1,\\ldots,n-2\\), the points \\((d-2^{-n},F_{i}(d-2^{-n}))\\) and \\((d+2^{-n},F_{i}(d+2^{-n})\\) lie on some straight line and have \\((d,F_{i}(d))\\) as their midpoint. Moreover, \\(d-2^{-n}\\) and \\(d+2^{-n}\\) are vertices in \\(\\mathcal{D}_{n-1}\\). So, by definition of \\(F_{n-1}(d)\\), we have \\(F_{n-1}(d)=[F_{n-1}(d-2^{-n})+F_{n-1}(d+2^{-n})]/2\\).\nTo summarize, the first term on the right hand side of expression ([eq:expression-for-bd]) is equal to \\(\\sum_{i=0}^{n-1}F_{i}(d)\\). By mathematical induction, it follows that the claim ([eq:claim-of-induction-for-bd]) is true for all \\(n\\in\\mathbf{N}\\).\nIt’s extremely easy to find an upper bound on the probability contained in the Gaussian tails. Suppose \\(X\\sim N(0,1)\\) and let \\(x&gt;0\\). We are interested in the tail probability \\(\\mathbb{P}(X&gt;x)\\). We have:\n\\[\\begin{aligned}\n\\mathbb{P}(X&gt;x) & =\\int_{x}^{\\infty}e^{-x^{2}/2}dx=\\int_{x}^{\\infty}\\frac{xe^{-x^{2}/2}dx}{x}\n\\end{aligned}\\]\nLet \\(u=\\frac{1}{x}\\) and \\(dv=xe^{-x^{2}/2}dx\\). We have:\n\n\n\n\\(u=\\frac{1}{x}\\)\n\\(dv=xe^{-x^{2}/2}dx\\)\n\n\n\n\n\\(du=-\\frac{1}{x^{2}}dx\\)\n\\(v=-e^{-x^{2}/2}\\)\n\n\n\nThus,\n\\[\\begin{aligned}\n\\mathbb{P}(X&gt;x) & =-\\left.\\frac{1}{x}e^{-x^{2}/2}\\right|_{x}^{\\infty}-\\int_{x}^{\\infty}\\frac{e^{-x^{2}/2}}{x^{2}}dx\\\\\n& =\\frac{e^{-x^{2}/2}}{x}-\\int_{x}^{\\infty}\\frac{e^{-x^{2}/2}}{x^{2}}dx\\\\\n& \\quad\\left\\{ I(x)=\\int_{x}^{\\infty}\\frac{e^{-x^{2}/2}}{x^{2}}\\geq0\\right\\} \\\\\n& \\leq\\frac{e^{-x^{2}/2}}{x}\n\\end{aligned}\\]\nThus, for \\(c&gt;1\\) and large \\(n\\), we have:\n\\[\\begin{aligned}\n\\mathbb{P}(|Z_{d}|\\geq c\\sqrt{n}) & \\leq\\frac{1}{c\\sqrt{n}}e^{-c^{2}n/2}\\leq\\exp\\left(-\\frac{c^{2}n}{2}\\right)\n\\end{aligned}\\]\nSo, the series:\n\\[\\begin{aligned}\n\\sum_{n=0}^{\\infty}\\mathbb{P}\\left\\{ \\text{There exists atleast one }d\\in\\mathcal{D}_{n}\\text{ with }|Z_{d}|\\geq c\\sqrt{n}\\right\\}  & \\leq\\sum_{n=0}^{\\infty}\\sum_{d\\in\\mathcal{D}_{n}}\\mathbb{P}\\left\\{ |Z_{d}|\\geq c\\sqrt{n}\\right\\} \\\\\n& \\leq\\sum_{n=0}^{\\infty}(2^{n}+1)\\exp\\left(-\\frac{c^{2}n}{2}\\right)\n\\end{aligned}\\]\nNow, the series \\((a_{n})\\) given by, \\(a_{n}:=(2^{n}+1)e^{-c^{2}n/2}\\) has the ratio between successive terms:\n\\[\\begin{aligned}\n\\lim\\left|\\frac{a_{n+1}}{a_{n}}\\right| & =\\lim_{n\\to\\infty}\\frac{2^{n+1}+1}{2^{n}+1}\\cdot\\frac{e^{(c^{2}n)/2}}{e^{c^{2}(n+1)/2}}\\\\\n& =\\lim_{n\\to\\infty}\\frac{\\frac{1}{2}+\\frac{1}{2^{n}}}{1+\\frac{1}{2^{n}}}\\cdot\\frac{1}{e^{c^{2}/2}}\\\\\n& =\\frac{1}{2e^{c^{2}/2}}\n\\end{aligned}\\]\nIf this ratio is less than unity, that is \\(c&gt;\\sqrt{2\\log2}\\), than by the ratio test, \\(\\sum(2^{n}+1)e^{-c^{2}n/2}\\) converges to a finite value. Fix such a \\(c\\).\nBy BCL1(Borel-Cantelli Lemma), if \\(A_{n}:=\\left\\{ \\text{There exists atleast one }d\\in\\mathcal{D}_{n}\\text{ with }|Z_{d}|\\geq c\\sqrt{n}\\right\\}\\) and \\(\\sum_{n=0}^{\\infty}\\mathbb{P}(A_{n})\\) converges to a finite value, then the event \\(A_{n}\\) occurs finitely many times with probability \\(1\\). There exists \\(N\\in\\mathbf{N}\\), such that for all \\(n\\geq N\\), \\(A_{n}\\) fails to occur with probability \\(1\\). Thus, for all \\(n\\geq N\\), \\(\\{Z_{d}\\leq c\\sqrt{n}\\}\\) occurs with probability \\(1\\). It follows that:\n\\[\\begin{aligned}\n\\sup_{t\\in[0,1]}F_{n}(t) & \\leq\\frac{c\\sqrt{n}}{2^{(n+1)/2}}\n\\end{aligned}\\]\nDefine\n\\[\\begin{aligned}\nM_{n} & =\\frac{c\\sqrt{n}}{2^{(n+1)/2}}\n\\end{aligned}\\]\nSince \\(\\sum M_{n}\\) converges, by the Weierstrass \\(M\\)-test, the infinite series of functions \\(\\sum_{n=0}^{\\infty}F_{n}(t)\\) converges uniformly on \\([0,1].\\) Since, each \\(F_{n}(t)\\) is piecewise linear and continuous, by the Term-by-Term continuity theorem, \\(\\sum_{n=0}^{\\infty}F_{n}(t)\\) is continuous on \\([0,1]\\). ◻\n\n\n\n\nLike the Brownian motion, the Poisson process is defined as a process with stationary and independent increments.\n\n A process \\((N_{t},t\\geq0)\\) defined on \\((\\Omega,\\mathcal{F},\\mathbb{P})\\) has the distribution of the Poisson process with rate \\(\\lambda&gt;0\\), if and only if the following hold:\n(1) \\(N_{0}=0\\).\n(2) For any \\(s&lt;t\\), the increment \\(N_{t}-N_{s}\\) is a Poisson random variable with parameter \\(\\lambda(t-s).\\)\n(3) For any \\(n\\in\\mathbf{N}\\) and any choice \\(0&lt;t_{1}&lt;t_{2}&lt;\\ldots&lt;t_{n}&lt;\\infty\\), the increments \\(N_{t_{2}}-N_{t_{1}},N_{t_{3}}-N_{t_{2}},\\ldots,N_{t_{n}}-N_{t_{n-1}}\\) are independent.\n\nPoisson paths can be sampled using this definition. By construction, it is not hard to see that the paths of Poisson processes are piecewise, constant, integer-valued and non-decreasing. In particular, the paths of Poisson processes have finite variation. Poisson paths are much simpler than the ones of Brownian motion in many ways!\n\n(Simulating the Poisson Process.) Use the definition ([def:poisson-process]) to generate \\(10\\) paths of the Poisson process with rate \\(1\\) on the interval \\([0,10]\\) with step-size \\(0.01\\).\n\ndef generatePoissonProcess(lam,T,stepSize):\n    N = int(T/stepSize)\n    x = np.random.poisson(lam=lam,size=N)\n    y = np.cumsum(x)\n    y = np.concatenate([[0.0],y])\n    return y\nWe can construct a Poisson process as follows. Consider \\((\\tau_{j},j\\in\\mathbf{N})\\) IID exponential random variables with parameter \\(1/\\lambda\\). One should think of \\(\\tau_{j}\\) as the waiting time from the \\((j-1)\\)st to the \\(j\\)th jump. Then, one defines :\n\\[\\begin{aligned}\nN_{t} & =\\#\\{k:\\tau_{1}+\\tau_{2}+\\ldots+\\tau_{k}\\leq t\\}\\\\\n& =\\text{Number of jumps upto and including time }t\n\\end{aligned}\\]\nNow, here is an idea! What about defining a new process with stationary and independent increments using a given distribution other than Poisson and Gaussian? Is this even possible? The answer is yes, but only if the distribution satisfies the property of being infinitely divisible. To see this, consider the value of the process at time \\(1\\), \\(N_{1}\\). Then, no matter how many subintervals we chop the interval \\([0,1]\\) into, we must have the increments add up to \\(N_{1}\\). In other words, we must be able to write \\(N_{1}\\) as a sum of \\(n\\) IID random variables for every possible \\(n\\). This is certainly true for Poisson random variables and Gaussian random variables. Another example is the Cauchy distribution. In general, processes that can be constructed using independent, stationary increments are called Levy processes.\n\nTime Inversion. Let \\((B_{t},t\\geq0)\\) be a standard brownian motion. We consider the process:\n\\[\\begin{aligned}\nX_{t} & =tB_{1/t}\\quad\\text{for }t&gt;0\n\\end{aligned}\\]\nThis property relates the behavior of \\(t\\) large to the behavior of \\(t\\) small.\n\n(a) Show that \\((X_{t},t&gt;0)\\) has the distribution of Brownian motion on \\(t&gt;0\\).\nProof.\nLike \\(B(t)\\), it is an easy exercise to prove that \\(X(t)\\) is also a Gaussian process.\nWe have, \\(\\mathbb{E}[X_{s}]=0\\).\nLet \\(s&lt;t\\). We have:\n\\[\\begin{aligned}\nCov(X_{s},X_{t}) & =\\mathbb{E}[sB(1/s)\\cdot tB(1/t)]\\\\\n& =st\\mathbb{E}[B(1/s)\\cdot B(1/t)]\\\\\n& =st\\cdot\\frac{1}{t}\\\\\n& \\quad\\left\\{ \\because\\frac{1}{t}&lt;\\frac{1}{s}\\right\\} \\\\\n& =s\n\\end{aligned}\\]\nConsequently, \\(X(t)\\) has the distribution of a Brownian motion.\n(b) Argue that \\(X(t)\\) converges to \\(0\\) as \\(t\\to0\\) in the sense of \\(L^{2}\\)-convergence. It is possible to show convergence almost surely so that \\((X_{t},t\\geq0)\\) is really a Brownian motion for \\(t\\geq0\\).\nSolution.\nLet \\((t_{n})\\) be any arbitrary sequence of positive real numbers approaching \\(0\\) and consider the sequence of random variables \\((X(t_{n}))_{n=1}^{\\infty}\\). We have:\n\\[\\begin{aligned}\n\\mathbb{E}\\left[X(t_{n})^{2}\\right] & =\\mathbb{E}\\left[t_{n}^{2}B(1/t_{n})^{2}\\right]\\\\\n& =t_{n}^{2}\\mathbb{E}\\left[B(1/t_{n})^{2}\\right]\\\\\n& =t_{n}^{2}\\cdot\\frac{1}{t_{n}}\\\\\n& =t_{n}\n\\end{aligned}\\]\nHence,\n\\[\\begin{aligned}\n\\lim\\mathbb{E}\\left[X(t_{n})^{2}\\right] & =\\lim t_{n}=0\n\\end{aligned}\\]\nSince \\((t_{n})\\) was an arbitrary sequence, it follows that \\(\\lim_{t\\to0}\\mathbb{E}[(X(t))^{2}]=0\\).\n(c) Use this property of Brownian motion to show the law of large numbers for Brownian motion:\n\\[\\begin{aligned}\n\\lim_{t\\to\\infty}\\frac{X(t)}{t} & =0\\quad\\text{almost surely}\n\\end{aligned}\\]\nSolution.\nWhat we need to do is to show that \\(X(t)\\to0\\) as \\(t\\to0\\) almost surely. That would show that \\(\\frac{B(1/t)}{1/t}\\to0\\) as \\(t\\to0\\) almost surely, which is the same as showing \\(\\frac{B(t)}{t}\\to0\\) as \\(t\\to\\infty\\), which is the law of large numbers for Brownian motion.\nWhat we have done in part (b), is to prove the claim that \\(\\mathbb{E}[X(t)^{2}]\\to0\\) as \\(t\\to0\\), which shows convergence in the \\(L^{2}\\) sense and hence convergence in probability. This is infact the weak law of large numbers. \\(\\frac{B(t)}{t}\\stackrel{\\mathbb{\\mathbf{P}}}{\\to}0\\) as \\(t\\to\\infty\\).\nFor \\(t&gt;0\\), continuity is clear. However, it is the proof that as \\(t\\to0\\), \\(X(t)\\to0\\) almost surely which we have not done.\nNote that, the limit \\(X(t)\\to0\\) as \\(t\\to0\\) if and only if \\((\\forall n\\geq1)\\), \\((\\exists m\\geq1)\\), such that \\(\\forall r\\in\\mathbb{Q}\\cap(0,\\frac{1}{m}]\\), we have \\(|X(r)|=\\left|rB\\left(\\frac{1}{r}\\right)\\right|\\leq\\frac{1}{n}\\).\nTo understand the above, we just recall the \\(\\epsilon-\\delta\\) definition of continuity. Note that \\(\\frac{1}{n}\\) plays the role of \\(\\epsilon\\) and \\(\\frac{1}{m}\\) works as \\(\\delta\\).\nThat is,\n\\[\\begin{aligned}\n\\Omega^{X}:=\\left\\{ \\lim_{t\\to0}X(t)=0\\right\\}  & =\\bigcap_{n\\geq1}\\bigcup_{m\\geq1}\\bigcap_{r\\in\\mathbb{Q}\\cap(0,\\frac{1}{m}]}\\left\\{ \\left|X(r)\\right|\\leq\\frac{1}{n}\\right\\}\n\\end{aligned}\\]\nAlso, note that \\(X(t)\\) is continuous on all \\([a,1]\\) for all \\(a&gt;0\\), thus, uniformly continuous on \\([a,1]\\), and hence uniformly continuous on \\(\\mathbb{Q}\\cap(0,1]\\). So, there exists a continuous extension of \\(X(t)\\) on \\([0,1]\\). We already know from part (a), that \\((X(t))_{t&gt;0}\\) and \\((B(t))_{t&gt;0}\\) have the same finite dimensional distributions. Therefore, the RHS event has the same probability as \\(\\Omega^{B}:=\\bigcap_{n\\geq1}\\bigcup_{m\\geq1}\\bigcap_{r\\in\\mathbb{Q}\\cap(0,\\frac{1}{m}]}\\left\\{ \\left|B(r)\\right|\\leq\\frac{1}{n}\\right\\}\\). Since \\(B(t)\\to0\\) as \\(t\\to0\\) almost surely, the event \\(\\Omega^{B}\\) has probability \\(1\\). Thus, \\(\\mathbb{P}\\left\\{ \\lim_{t\\to0}X(t)=0\\right\\} =1\\).\nThis actually shows that \\(X(t)\\) is a bonafide standard brownian motion, as we have established continuity as well."
  },
  {
    "objectID": "posts/properties-of-brownian-motion/index.html#properties-of-brownian-motion.-1",
    "href": "posts/properties-of-brownian-motion/index.html#properties-of-brownian-motion.-1",
    "title": "Properties of Brownian Motion",
    "section": "",
    "text": "Let \\(B(t)\\) be a fixed Brownian motion. We give below some simple properties that follow directly from the definition of the Brownian Motion.\n\nFor any \\(t\\geq0\\), \\(B(t)\\) is normally distributed with mean \\(0\\) and variance \\(t\\). For any \\(s,t\\geq0\\) we have \\(\\mathbb{E}(B_{s}B_{t})=\\min\\{s,t\\}\\).\n\nProof. From condition (1), we have that \\(B_{0}=0\\). From condition (2), \\(B_{t}-B_{0}=B_{t}\\) is normally distributed with mean \\(0\\) and variance \\(t\\).\nAssume that \\(s&lt;t\\).\nWe have:\n\\[\\begin{aligned}\n\\mathbb{E}(B_{s}B_{t}) & =\\mathbb{E}\\left[B_{s}(B_{t}-B_{s}+B_{s})\\right] & \\{\\text{Write }B_{t}=B_{t}-B_{s}+B_{s}\\}\\\\\n& =\\mathbb{E}[B_{s}(B_{t}-B_{s})]+\\mathbb{E}[B_{s}^{2}] & \\{\\text{Linearity of expectations}\\}\\\\\n& =\\mathbb{E}[B_{s}]\\mathbb{E}(B_{t}-B_{s})+s & \\{B_{s},(B_{t}-B_{s})\\text{ are independent}\\}\\\\\n& =0\\cdot0+s\\\\\n& =s\n\\end{aligned}\\]\nThis closes the proof. ◻ :::\n\n(Translation Invariance) For fixed \\(t_{0}\\geq0\\), the stochastic process \\(\\tilde{B}(t)=B(t+t_{0})-B(t_{0})\\) is also a Brownian motion.\n\n\nProof. Proof. Firstly, the stochastic process \\(\\tilde{B}(t)\\) is such that:\n(1) \\(\\tilde{B}(0)=B(t_{0})-B(t_{0})=0\\). Hence, it satisfies condition (1).\n(2) Let \\(s&lt;t\\). We have: \\(\\tilde{B}(t)-\\tilde{B}(s)=B(t+t_{0})-B(s+t_{0})\\) which a Gaussian random variable with mean 0 and variance \\(t-s\\). Hence, for \\(a\\leq b\\),\n\\[\\begin{aligned}\n\\mathbb{P}\\{a\\leq & \\tilde{B}(t)\\leq b\\}=\\frac{1}{\\sqrt{2\\pi(t-s)}}\\int_{a}^{b}e^{-\\frac{x^{2}}{2(t-s)}}dx\n\\end{aligned}\\]\nHence, it satisfies condition (2).\n(3) To check condition (3) for \\(\\tilde{B}(t)\\), we may assume \\(t_{0}&gt;0\\). Then, for any \\(0\\leq t_{1}\\leq t_{2}\\leq\\ldots\\leq t_{n}\\), we have:\n\\[0&lt;t_{0}\\leq t_{0}+t_{1}\\leq t_{0}+t_{2}\\leq\\ldots\\leq t_{0}+t_{n}\\]\nSo, \\(B(t_{1}+t_{0})-B(t_{0})\\), \\(B(t_{2}+t_{0})-B(t_{1}+t_{0})\\), \\(\\ldots\\), \\(B(t_{k}+t_{0})-B(t_{k-1}+t_{0})\\), \\(\\ldots\\), \\(B(t_{n}+t_{0})-B(t_{n-1}+t_{0})\\) are independent random variables. Consequently, \\(\\tilde{B}(t)\\) satisfies condition (3).\nThis closes the proof. ◻\n\nThe above translation invariance property says that a Brownian motion starts afresh at any moment as a new Brownian motion.\n\n(Scaling Invariance) For any real number \\(\\lambda&gt;0\\), the stochastic process \\(\\tilde{B}(t)=B(\\lambda t)/\\sqrt{\\lambda}\\) is also a Brownian motion.\n\n\nProof. Proof. The scaled stochastic process \\(\\tilde{B}(t)\\) is such that:\n(1) \\(\\tilde{B}(0)=0\\). Hence it satisfies condition (1).\n(2) Let \\(s&lt;t\\). Then, \\(\\lambda s&lt;\\lambda t\\). We have:\n\\[\\begin{aligned}\n\\tilde{B}(t)-\\tilde{B}(s) & =\\frac{1}{\\sqrt{\\lambda}}(B(\\lambda t)-B(\\lambda s))\n\\end{aligned}\\]\nNow, \\(B(\\lambda t)-B(\\lambda s)\\) is a Gaussian random variable with mean \\(0\\) and variance \\(\\lambda(t-s)\\). We know that, if \\(X\\) is a random variable with mean \\(\\mu\\) and variance \\(\\sigma^{2}\\), \\(Z=\\left(\\frac{X-\\mu}{\\sigma}\\right)\\) has mean \\(0\\) and variance \\(1\\). Consequently, \\(\\frac{B(\\lambda t)-B(\\lambda s)}{\\sqrt{\\lambda}}\\) is a Gaussian random variable with mean \\(0\\) and variance \\((t-s)\\).\nHence, \\(\\tilde{B}(t)-\\tilde{B}(s)\\) is normal distributed with mean \\(0\\) and variance \\(t-s\\) and it satisfies condition (2).\n(3) To check condition (3) for \\(\\tilde{B}(t)\\), we may assume \\(t_{0}&gt;0\\). Then, for any \\(0\\leq t_{1}\\leq t_{2}\\leq\\ldots\\leq t_{n}\\), we have:\n\\[0\\leq\\lambda t_{1}\\leq\\lambda t_{2}\\leq\\ldots\\leq\\lambda t_{n}\\]\nConsequently, the random variables \\(B(\\lambda t_{k})-B(\\lambda t_{k-1})\\), \\(k=1,2,3,\\ldots,n\\) are independent. Hence it follows that \\(\\frac{1}{\\sqrt{\\lambda}}[B(\\lambda t_{k})-B(\\lambda t_{k-1})]\\) for \\(k=1,2,\\ldots,n\\) are also independent random variables.\nThis closes the proof. ◻\n\nIt follows from the scaling invariance property that for any \\(\\lambda&gt;0\\) and \\(0\\leq t_{1}\\leq t_{2}\\leq\\ldots\\leq t_{n}\\), the random vectors:\n\\[(B(\\lambda t_{1}),B(\\lambda t_{2}),\\ldots,B(\\lambda t_{n}))\\quad(\\sqrt{\\lambda}B(t_{1}),\\sqrt{\\lambda}B(t_{1}),\\ldots,\\sqrt{\\lambda}B(t_{n}))\\]\nhave the same distribution.\nThe scaling property shows that Brownian motion is self-similar, much like a fractal. To see this, suppose we zoom into a Brownian motion path very close to zero, say on the interval \\([0,10^{-6}]\\). If the Brownian motion path were smooth and differentiable, the closer we zoom in around the origin, the flatter the function will look. In the limit, we would essentially see a straight line given by the derivative at \\(0\\). However, what we see with the Brownian motion is very different. The scaling property means that for \\(a=10^{-6}\\),\n\\[\n\\begin{aligned}\n(B_{10^{-6}t,}t\\in[0,1]) & \\stackrel{\\text{distrib.}}{=}(10^{-3}B_{t},t\\in[0,1])\n\\end{aligned}\n\\]\nwhere \\(\\stackrel{\\text{distrib.}}{=}\\) means equality of the distribution of the two processes. In other words, Brownian motion on \\([0,10^{-6}]\\) looks like a Browian motion on \\([0,1]\\), but with its amplitude multiplied by a factor of \\(10^{-3}\\). In particular, it will remain rugged as we zoom in, unlike a smooth function.\n\n(Reflection at time \\(s\\)) The process \\((-B_{t},t\\geq0)\\) is a Brownian motion. More generally, for any \\(s\\geq0\\), the process \\((\\tilde{B}(t),t\\geq0)\\) defined by:\n\\[\\begin{aligned}\n\\tilde{B}(t) & =\\begin{cases}\nB_{t} & \\text{if }t\\leq s\\\\\nB_{s}-(B_{t}-B_{s}) & \\text{if }t&gt;s\n\\end{cases}\\label{eq:reflection-property}\n\\end{aligned}\\]\nis a Brownian motion.\n\n\nProof. Proof. (a) Consider the process \\(\\tilde{B}(t)=(-B_{t},t\\geq0)\\).\n(1) \\(\\tilde{B}(0)=0\\).\n(2) If \\(X\\) is a Gaussian random variable with mean \\(0\\) and variance \\(t-s\\), \\(-X\\) is also Gaussian with mean \\(0\\) and variance \\(t-s\\). Thus, \\(\\tilde{B}(t)-\\tilde{B}(s)=-(B(t)-B(s))\\) is also Gaussian with mean \\(0\\) and variance \\((t-s)\\). Hence condition (2) is satisfied.\n(3) Assume that \\(0\\leq t_{0}\\leq t_{1}\\leq\\ldots\\leq t_{n}\\). Then, the random variables \\(-(B(t_{k})-B(t_{k-1}))\\) are independent for \\(k=1,2,3,\\ldots,n\\). Hence, condition (3) is satisfied.\n(b) Consider the process \\(\\tilde{B}(t)\\) as defined in ([eq:reflection-property]).\nFix an \\(s\\geq0\\).\n(1) Let \\(t=0\\). Then, \\(t\\leq s\\). \\(\\tilde{B}(t)=\\tilde{B}(0)=B(0)=0\\).\n(2) Let \\(t_{1}&lt;t_{2}\\leq s\\). Then, \\(\\tilde{B}(t_{2})-\\tilde{B}(t_{1})=B(t_{2})-B(t_{1})\\). This is a Gaussian random variable with mean \\(0\\) and variance \\(t_{2}-t_{1}\\).\nLet \\(t_{1}&lt;s&lt;t_{2}\\). Then, \\(\\tilde{B}(t_{2})-\\tilde{B}(t_{1})=B(s)-(B(t_{2})-B(s))-B(t_{1})=(B(s)-B(t_{1}))-(B(t_{2})-B(s))\\). Since, \\(B(s)-B(t_{1})\\) and \\(B(t_{2})-B(s)\\) are independent Gaussian random variables, any linear combination of these is Gaussian. Moreover, its mean is zero. The variance is given by:\n\\[\\begin{aligned}\nVar[\\tilde{B}(t_{2})-\\tilde{B}(t_{1})] & =Var[B(s)-B(t_{1})]+Var[B(t_{2})-B(s)]\\\\\n& =(s-t_{1})+(t_{2}-s)\\\\\n& =t_{2}-t_{1}\n\\end{aligned}\\]\nLet \\(s&lt;t_{1}&lt;t_{2}\\). Then, \\[\\begin{aligned}\n\\tilde{B}(t_{2})-\\tilde{B}(t_{1}) & =B_{s}-(B_{t_{2}}-B_{s})-(B_{s}-(B_{t_{1}}-B_{s}))\\\\\n& =\\cancel{B_{s}}-(B_{t_{2}}-\\cancel{B_{s}})-(\\cancel{B_{s}}-(B_{t_{1}}-\\cancel{B_{s}}))\\\\\n& =-(B_{t_{2}}-B_{t_{1}})\n\\end{aligned}\\]\nHence, \\(\\tilde{B}(t_{2})-\\tilde{B}(t_{1})\\) is again a Gaussian random variable with mean \\(0\\) and variance \\(t_{2}-t_{1}\\). Hence, condition (3) is satisfied.\n(3) Assume that \\(0\\leq t_{1}\\leq\\ldots\\leq t_{k-1}\\leq s\\leq t_{k}\\leq\\ldots\\leq t_{n}\\). From the above discussion, the increments \\(\\tilde{B}(t_{2})-\\tilde{B}(t_{1})\\), \\(\\ldots\\), \\(\\tilde{B}(s)-\\tilde{B}(t_{k-1})\\), \\(\\tilde{B}(t_{k})-\\tilde{B}(s)\\), \\(\\ldots\\), \\(\\tilde{B}(t_{n})-\\tilde{B}(t_{n-1})\\) are independent increments. The increment \\(\\tilde{B}(t_{k})-\\tilde{B}(t_{k-1})\\) only depends on the random variables \\(\\tilde{B}(s)-\\tilde{B}(t_{k-1})\\) and \\(\\tilde{B}(t_{k})-\\tilde{B}(s)\\). Thus, \\(\\tilde{B}(t_{2})-\\tilde{B}(t_{1})\\), \\(\\ldots\\), \\(\\tilde{B}(t_{k})-\\tilde{B}(t_{k-1})\\), \\(\\ldots\\), \\(\\tilde{B}(t_{n})-\\tilde{B}(t_{n-1})\\) are independent. ◻\n\n\n(Time Reversal). Let \\((B_{t},t\\geq0)\\) be a Brownian motion. Show that the process \\((B_{1}-B_{1-t},t\\in[0,1])\\) has the distribution of a standard brownian motion on \\([0,1]\\).\n\n\nProof. Proof. (1) At \\(t=0\\), \\(B(1)-B(1-t)=B(1)-B(1)=0\\).\n(2) Let \\(s&lt;t\\). Then, \\(1-t&lt;1-s\\). So, the increment :\n\\[\\begin{aligned}\n(B(1)-B(1-t))-(B(1)-B(1-s)) & =B(1-s)-B(1-t)\n\\end{aligned}\\]\nhas a Gaussian distribution. It’s mean is \\(0\\) and variance is \\((1-s)-(1-t)=t-s\\).\n(3) Let \\(0\\leq t_{1}\\leq t_{2}\\leq\\ldots\\leq t_{n}\\). Then:\n\\[1-t_{n}\\leq\\ldots\\leq1-t_{k}\\leq1-t_{k-1}\\leq\\ldots\\leq1-t_{2}\\leq1-t_{1}\\]\nConsider the increments of the process for \\(k=1,2,\\ldots,n\\):\n\\[\\begin{aligned}\n(B(1)-B(1-t_{k}))-(B(1)-B(1-t_{k-1})) & =B(1-t_{k-1})-B(1-t_{k})\n\\end{aligned}\\]\nThey are independent random variables. Hence, condition (3) is satisfied. ◻\n\n\n(Evaluating Brownian Probabilities). Let’s compute the probability that \\(B_{1}&gt;0\\) and \\(B_{2}&gt;0\\). We know from the definition that \\((B_{1},B_{2})\\) is a Gaussian vector with mean \\(0\\) and covariance matrix:\n\\[\\begin{aligned}\nC & =\\left[\\begin{array}{cc}\n1 & 1\\\\\n1 & 2\n\\end{array}\\right]\n\\end{aligned}\\]\nThe determinant of \\(C\\) is \\(1\\). By performing row operations on the augmented matrix \\([C|I]\\) we find that:\n\\[\\begin{aligned}\nC^{-1} & =\\left[\\begin{array}{cc}\n2 & -1\\\\\n-1 & 1\n\\end{array}\\right]\n\\end{aligned}\\]\nThus, the probability \\(\\mathbb{P}(B_{1}&gt;0,B_{2}&gt;0)\\) can be expressed as:\n\\[\\begin{aligned}\n\\mathbb{P}(B_{1}&gt;0,B_{2}&gt;0) & =\\frac{1}{\\sqrt{(2\\pi)^{2}}}\\int_{0}^{\\infty}\\int_{0}^{\\infty}\\exp\\left[-\\frac{1}{2}(2x_{1}^{2}-2x_{1}x_{2}+x_{2}^{2}\\right]dx_{2}dx_{1}\n\\end{aligned}\\]\nThis integral can be evaluated using a calculator or software and is equal to \\(3/8\\). The probability can also be computed using the independence of increments. The increments \\((B_{1},B_{2}-B_{1})\\) are IID standard Gaussians. We know their joint PDF. It remains to integrate over the correct region of \\(\\mathbf{R}^{2}\\) which in this case will be:\n\\[\\begin{aligned}\nD^{*} & =\\{(z_{1},z_{2}):(z_{1}&gt;0,z_{1}+z_{2}&gt;0)\\}\n\\end{aligned}\\]\nWe have:\n\\[\\begin{aligned}\n\\mathbb{P}(B_{1}&gt;0,B_{2}&gt;0) & =\\frac{1}{2\\pi}\\int_{0}^{\\infty}\\int_{z_{2}=-z_{1}}^{z_{2}=\\infty}e^{-(z_{1}^{2}+z_{2}^{2})/2}dz_{2}dz_{1}\n\\end{aligned}\\]\nIt turns out that this integral can be evaluated exactly. Indeed by writing \\(B_{1}=Z_{1}\\) and \\(Z_{2}=B_{2}-B_{1}\\) and splitting the probability on the event \\(\\{Z_{2}\\geq0\\}\\) and its complement, we have that \\(\\mathbb{P}(B_{1}\\geq0,B_{2}\\geq0)\\) equals:\n\\[\\begin{aligned}\n\\mathbb{P}(B_{1}\\geq0,B_{2}\\geq0) & =\\mathbb{P}(Z_{1}\\geq0,Z_{1}+Z_{2}&gt;0,Z_{2}\\geq0)+\\mathbb{P}(Z_{1}\\geq0,Z_{1}+Z_{2}&gt;0,Z_{2}&lt;0)\\\\\n& =\\mathbb{P}(Z_{1}\\geq0,Z_{2}\\geq0)+\\mathbb{P}(Z_{1}\\geq0,Z_{1}&gt;-Z_{2},-Z_{2}&gt;0)\\\\\n& =\\mathbb{P}(Z_{1}\\geq0,Z_{2}\\geq0)+\\mathbb{P}(Z_{1}\\geq0,Z_{1}&gt;Z_{2},Z_{2}&gt;0)\\\\\n& =\\frac{1}{4}+\\frac{1}{8}\\\\\n& =\\frac{3}{8}\n\\end{aligned}\\]\nNote that, by symmetry, \\(\\mathbb{P}(Z_{1}\\geq0,Z_{1}&gt;Z_{2},Z_{2}&gt;0)=\\mathbb{P}(Z_{1}\\geq0,Z_{1}\\leq Z_{2},Z_{2}&gt;0)=\\frac{1}{8}\\).\n\n\n(Another look at Ornstein Uhlenbeck process.) Consider the process \\((X_{t},t\\in\\mathbf{R})\\) defined by :\n\\[\\begin{aligned}\nX_{t} & =\\frac{e^{-2t}}{\\sqrt{2}}B(e^{4t}),\\quad t\\in\\mathbf{R}\n\\end{aligned}\\]\nHere the process \\((B_{e^{4t}},t\\ge0)\\) is called a time change of Brownian motion, since the time is now quantitfied by an increasing function of \\(t\\) namely \\(e^{4t}\\). The example \\((B(\\lambda t),t\\geq0)\\) in the scaling property is another example of time change.\n\nIt turns out that \\((X_{t},t\\in\\mathbf{R})\\) is a stationary Ornstein-Uhlenbeck process. (Here the index of time is \\(\\mathbf{R}\\) instead of \\([0,\\infty)\\), but the definition also applies as the process is stationary. Since the original brownian motion \\(B(t)\\) is a Gaussian process, any finite dimensional vector \\((B(t_{1}),\\ldots,B(t_{n}))\\) is Gaussian. It follows that:\n\\[(B(T_{1}),\\ldots,B(T_{n}))=\\frac{1}{\\sqrt{2}}(e^{-2t_{1}}B(e^{4t_{1}}),\\ldots,e^{-2t_{n}}B(e^{4t_{n}}))\\]\nis also a Gaussian vector. (Note, once we fix \\(t_{1},t_{2},\\ldots,t_{n}\\), \\(e^{-4t_{1}},\\ldots,e^{-4t_{n}}\\) are constants.) Hence, \\((X_{t},t\\in\\mathbf{R})\\) is a Gaussian process.\nThe mean of \\((X_{t},t\\in\\mathbf{R})\\) is:\n\\[\\begin{aligned}\n\\mathbb{E}[X_{t}] & =\\frac{e^{-2t}}{\\sqrt{2}}\\mathbb{E}[B(e^{4t})]=0\n\\end{aligned}\\]\nAnd if \\(s&lt;t\\),\n\\[\\begin{aligned}\n\\mathbb{E}[X_{s}X_{t}] & =\\frac{e^{-2(s+t)}}{2}\\mathbb{E}[B(e^{4s})B(e^{4t})]\\\\\n& =\\frac{e^{-2(s+t)}}{2}e^{4s}\\\\\n& =\\frac{e^{-2(t-s)}}{2}\n\\end{aligned}\\]\nTwo Gaussian processes having the same mean and covariance have the same distribution. Hence, it proves the claim that \\((X_{t})\\) is a stationary OU process."
  },
  {
    "objectID": "posts/properties-of-brownian-motion/index.html#properties-of-the-paths.",
    "href": "posts/properties-of-brownian-motion/index.html#properties-of-the-paths.",
    "title": "Properties of Brownian Motion",
    "section": "",
    "text": "First we review the definitions of the Riemann integral and the Riemann-Stieljtes integral in Calculus.\n\nA partition \\(P\\) of \\([a,b]\\) is a finite set of points from \\([a,b]\\) that includes both \\([a,b].\\)The notational convention is to always list the points of a partition \\(P=\\{a=x_{0},x_{1},x_{2},\\ldots,x_{n}=b\\}\\) in increasing order. Thus:\n\\[a=x_{0}&lt;x_{1}&lt;\\ldots&lt;x_{k-1}&lt;x_{k}&lt;\\ldots&lt;x_{n}=b\\]\n\nFor each subinterval \\([x_{k-1},x_{k}]\\) of \\(P\\), let\n\\[\\begin{aligned}\nm_{k} & =\\inf\\{f(x):x\\in[x_{k-1},x_{k}]\\}\\\\\nM_{k} & =\\sup\\{f(x):x\\in[x_{k-1},x_{k}]\\}\n\\end{aligned}\\]\nThe lower sum of \\(f\\) with respect to \\(P\\) is given by :\n\\[\\begin{aligned}\nL(f,P) & =\\sum_{k=1}^{n}m_{k}(x_{k}-x_{k-1})\n\\end{aligned}\\]\nThe upper sum of \\(f\\) with respect to \\(P\\) is given by:\n\\[\\begin{aligned}\nU(f,P) & =\\sum_{k=1}^{n}M_{k}(x_{k}-x_{k-1})\n\\end{aligned}\\]\nFor a particular partition \\(P\\), it is clear that \\(U(f,P)\\geq L(f,P)\\) because \\(M_{k}\\geq m_{k}\\) for all \\(k=0,1,2,\\ldots,n\\).\n\nA partition \\(Q\\) is called a refinement of \\(P\\) if \\(Q\\) contains all of the points of \\(P\\); that is \\(Q\\subseteq P\\).\n\n\nIf \\(P\\subseteq Q\\), then \\(L(f,P)\\leq L(f,Q)\\) and \\(U(f,Q)\\leq U(f,P)\\).\n\n\nProof. Proof. Consider what happens when we refine \\(P\\) by adding a single point \\(z\\) to some subinterval \\([x_{k-1},x_{k}]\\) of \\(P\\). We have:\n\\[\\begin{aligned}\nm_{k}(x_{k}-x_{k-1}) & =m_{k}(x_{k}-z)+m_{k}(z-x_{k-1})\\\\\n& \\leq m_{k}'(x_{k}-z)+m_{k}''(z-x_{k-1})\n\\end{aligned}\\]\nwhere\n\\[\\begin{aligned}\nm_{k}' & =\\inf\\{f(x):x\\in[z,x_{k}]\\}\\\\\nm_{k}'' & =\\inf\\{f(x):x\\in[x_{k-1},z]\\}\n\\end{aligned}\\]\nBy induction we have:\n\\[\\begin{aligned}\nL(f,P) & \\leq L(f,Q)\\\\\nU(f,Q) & \\leq U(f,P)\n\\end{aligned}\\] ◻\n\n\nIf \\(P_{1}\\) and \\(P_{2}\\) are any two partitions of \\([a,b]\\), then \\(L(f,P_{1})\\leq U(f,P_{2})\\).\n\n\nProof. Proof. Let \\(Q=P_{1}\\cup P_{2}\\). Then, \\(P_{1}\\subseteq Q\\) and \\(P_{2}\\subseteq Q\\). Thus, \\(L(f,P_{1})\\leq L(f,Q)\\leq U(f,Q)\\leq L(f,P_{2})\\). ◻\n\n\nLet \\(\\mathcal{P}\\) be the collection of all possible partitions of the interval \\([a,b]\\). The upper integral of \\(f\\) is defined to be:\n\\[\\begin{aligned}\nU(f) & =\\inf\\{U(f,P):P\\in\\mathcal{P}\\}\n\\end{aligned}\\]\nThe lower integral of \\(f\\) is defined by:\n\\[\\begin{aligned}\nL(f) & =\\sup\\{L(f,P):P\\in\\mathcal{P}\\}\n\\end{aligned}\\]\n\nConsider the set of all upper sums of \\(f\\) - \\(\\{U(f,P):P\\in\\mathcal{P}\\}\\). Take an arbitrary partition \\(P'\\in\\mathcal{P}\\). Since \\(L(f,P')\\leq U(f,P)\\) for all \\(P\\in\\mathcal{P}\\), by the Axiom of Completeness(AoC), \\(\\inf\\{U(f,P):P\\in\\mathcal{P}\\}\\) exists.We can similarly argue for the supremum of all lower Riemann sums.\n\nFor any bounded function \\(f\\) on \\([a,b]\\), it is always the case that \\(U(f)\\geq L(f)\\).\n\n\nProof. Proof. By the properties of the infimum of a set, \\((\\forall\\epsilon&gt;0)\\), \\(\\exists P(\\epsilon)\\) such that \\(U(f)&lt;U(f,P(\\epsilon))&lt;U(f)+\\epsilon\\). Pick \\(\\epsilon=1,\\frac{1}{2},\\frac{1}{3}\\ldots,\\frac{1}{n},\\ldots\\). Thus, we can produce a sequence of partitions \\(P_{n}\\) such that :\n\\[U(f)&lt;\\ldots&lt;U(f,P_{n})&lt;U(f)+\\frac{1}{n}\\]\nConsequently, \\(\\lim U(f,P_{n})=U(f)\\). Similarly, we can produce a sequence of partitions \\((Q_{m})\\) such that :\n\\[L(f)-\\frac{1}{m}&lt;\\ldots&lt;L(f,Q_{m})&lt;L(f)\\]\nWe know that:\n\\[\\begin{aligned}\nL(f,Q_{m}) & \\leq U(f,P_{n})\n\\end{aligned}\\]\nKeeping \\(m\\) fixed and passing to the limit, as \\(n\\to\\infty\\) on both sides, we have:\n\\[\\begin{aligned}\n\\lim_{n\\to\\infty}L(f,Q_{m}) & \\leq\\lim_{n\\to\\infty}U(f,P_{n})\\quad\\left\\{ \\text{Order Limit Theorem}\\right\\} \\\\\nL(f,Q_{m}) & \\leq U(f)\n\\end{aligned}\\]\nNow, passing to the limit, as \\(m\\to\\infty\\) on both sides, we have:\n\\[\\begin{aligned}\n\\lim_{m\\to\\infty}L(f,Q_{m}) & \\leq\\lim_{m\\to\\infty}U(f)\\quad\\left\\{ \\text{Order Limit Theorem}\\right\\} \\\\\nL(f) & \\leq U(f)\n\\end{aligned}\\] ◻\n\n\n(Riemann Integrability). A bounded function \\(f\\) on the interval \\([a,b]\\) is said to be Riemann integrable if \\(U(f)=L(f)\\). In this case, we define \\(\\int_{a}^{b}f\\) or \\(\\int_{a}^{b}f(x)dx\\) to be the common value:\n\\[\\begin{aligned}\n\\int_{a}^{b}f(x)dx & =U(f)=L(f)\n\\end{aligned}\\]\n\n\n(Integrability Criterion) A bounded function \\(f\\) is integrable on \\([a,b]\\) if and only if, for every \\(\\epsilon&gt;0\\), there exists a partition \\(P_{\\epsilon}\\) of \\([a,b]\\) such that:\n\\[\\begin{aligned}\nU(f,P_{\\epsilon})-L(f,P_{\\epsilon}) & &lt;\\epsilon\n\\end{aligned}\\]\n\n\nProof. Proof. (\\(\\Longleftarrow\\) direction.) Let \\(\\epsilon&gt;0\\). If such a partition \\(P_{\\epsilon}\\) exists, then:\n\\[U(f)-L(f)\\leq U(f,P_{\\epsilon})-L(f,P_{\\epsilon})&lt;\\epsilon\\]\nBecause \\(\\epsilon\\) is arbitrary, it follows that \\(U(f)=L(f)\\) and hence \\(f\\) is Riemann integrable.\n(\\(\\Longrightarrow\\) direction.) Let \\(f\\) be a bounded function on \\([a,b]\\) such that \\(f\\) is Riemann integrable.\nPick an arbitrary \\(\\epsilon&gt;0\\).\nThen, since \\(U(f)=\\inf\\{U(f,P):P\\in\\mathcal{P}\\}\\), there exists \\(P_{\\epsilon}\\in\\mathcal{P}\\), such that \\(U(f)&lt;U(f,P_{\\epsilon})&lt;U(f)+\\frac{\\epsilon}{2}\\). Since \\(L(f)=\\sup\\{L(f,P):P\\in\\mathcal{P}\\}\\), there exists \\(P_{\\epsilon}\\in\\mathcal{P}\\), such that \\(L(f)-\\frac{\\epsilon}{2}&lt;L(f,P_{\\epsilon})&lt;L(f)\\). Consequently,\n\\[\\begin{aligned}\nU(f,P_{\\epsilon})-L(f,P_{\\epsilon}) & &lt;U(f)+\\frac{\\epsilon}{2}-\\left(L(f)-\\frac{\\epsilon}{2}\\right)\\\\\n& =U(f)-L(f)+\\epsilon\\\\\n& =\\epsilon\n\\end{aligned}\\] ◻\n\n\n\n\nA point \\(c\\) is called a discontinuity of the first kind or jump point if both limits \\(g(c+)=\\lim_{t\\uparrow c}g(t)\\) and \\(g(c-)=\\lim_{t\\downarrow c}g(t)\\) exist and are not equal. The jump at \\(c\\) is defined as \\(\\Delta g(c)=g(c+)-g(c-)\\). Any other discontinuity is said to be of the second kind.\n\n\nConsider the function\n\\[\\begin{aligned}\nf(x) & =\\sin\\left(\\frac{1}{x}\\right)\n\\end{aligned}\\]\nLet \\(x_{n}=\\frac{1}{2n\\pi}\\). Then, \\(f(x_{n})=(0,0,0,\\ldots)\\). Next, consider \\(y_{n}=\\frac{1}{\\pi/2+2n\\pi}\\). Then, \\(f(y_{n})=(1,1,1,\\ldots)\\). Consequently, \\(f\\) is not continuous at \\(0\\). Hence, limits from the left or right don’t exist. Consequently, this is a discontinuity of the second kind.\n\nFunctions in stochastic calculus are functions without discontinuities of the second kind, that is functions have both left and right hand limits at any point of the domain and have one-sided limits at the boundary. These functions are called regular functions. It is often agreed to identify functions if they have the same right and left limits at any point.\nThe class \\(D=D[0,T]\\) of right-continuous functions on \\([0,T]\\) with left limits has a special name, cadlag functions (which is the abbreviation of right continuous with left limits in French). Sometimes these processes are called R.R.C. for regular right continuous. Notice that this class of processes includes \\(C\\), the class of continuous functions.\nLet \\(g\\in D\\) be a cadlag function, then, by definition, all the discontinuities of \\(g\\) are jumps. An important result in analysis is that, a function can have no more than a countable number of discontinuities.\n\n\n\nIf \\(g\\) is a function of a real variable, its variation over the interval \\([a,b]\\) is defined as:\n\\[\\begin{aligned}\nV_{g}([a,b]) & =\\sup\\left\\{ \\sum_{i=1}^{n}\\left|g(t_{i})-g(t_{i-1})\\right|\\right\\} \\label{eq:total-variation-of-a-function}\n\\end{aligned}\\]\nwhere the supremum is taken over all partitions \\(P\\in\\mathcal{P}\\).\nClearly, by the Triangle Inequality, the sums in ([eq:total-variation-of-a-function]) increase as new points are added to the partitions. Therefore, the variation of \\(g\\) is:\n\\[\\begin{aligned}\nV_{g}([a,b]) & =\\lim_{||\\Delta_{n}||\\to0}\\sum_{i=1}^{n}\\left|g(t_{i})-g(t_{i-1})\\right|\n\\end{aligned}\\]\nwhere \\(||\\Delta_{n}||=\\max_{1\\leq i\\leq n}(t_{i}-t_{i-1})\\). If \\(V_{g}([a,b])\\) is finite, then \\(g\\) is said to be a function of finite variation on \\([a,b]\\). If \\(g\\) is a function of \\(t\\geq0\\), then the variation of \\(g\\) as a function of \\(t\\) is defined by:\n\\[\\begin{aligned}\nV_{g}(t) & =V_{g}([0,t])\n\\end{aligned}\\]\nClearly, \\(V_{g}(t)\\) is an increasing function of \\(t\\).\n\n\\(g\\) is a function of finite variation if \\(V_{g}(t)&lt;\\infty\\) for all \\(t\\in[0,\\infty)\\). \\(g\\) is of bounded variation if \\(\\sup_{t}V_{g}(t)&lt;\\infty\\), in other words there exists \\(C\\), for all \\(t\\), such that \\(V_{g}(t)&lt;C\\). Here \\(C\\) is independent of \\(t\\).\n\n\n(1) If \\(g(t)\\) is increasing then for any \\(i\\), \\(g(t_{i})\\geq g(t_{i-1})\\), resulting in a telescopic sum, where all terms excluding the first and the last cancel out, leaving\n\\[\\begin{aligned}\nV_{g}(t) & =g(t)-g(0)\n\\end{aligned}\\]\n(2) If \\(g(t)\\) is decreasing, then similarly,\n\\[\\begin{aligned}\nV_{g}(t) & =g(0)-g(t)\n\\end{aligned}\\]\n\n\nIf \\(g(t)\\) is differentiable with continuous derivative \\(g'(t)\\), \\(g(t)=\\int_{0}^{t}g'(s)ds\\) then\n\\[\\begin{aligned}\nV_{g}(t) & =\\int_{0}^{t}|g'(s)|ds\n\\end{aligned}\\]\n\n\nProof. Proof. By definition,\n\\[\\begin{aligned}\nV_{g}(t) & =\\lim_{||\\Delta_{n}\\to0||}\\sum_{i=1}^{n}|g(t_{i})-g(t_{i-1})|\n\\end{aligned}\\]\nSince \\(g\\) is continuous and differentiable on \\([t_{i-1},t_{i}]\\), there exists \\(z_{i}\\in(t_{i-1},t_{i})\\) such, that \\(g(t_{i})-g(t_{i-1})=g'(z_{i})(t_{i}-t_{i-1})\\). Therefore, we can write:\n\\[\\begin{aligned}\n{1}\nV_{g}(t) & =\\lim_{||\\Delta_{n}\\to0||}\\sum_{i=1}^{n}|g'(z_{i})|(t_{i}-t_{i-1})\\\\\n& =\\int_{0}^{t}|g'(s)|ds\n\\end{aligned}\\] ◻\n\n\nIf \\(g\\) is continuous, \\(g'\\) exists and \\(\\int_{0}^{t}|g'(s)|ds\\) is finite, then \\(g\\) is of finite variation.\n\n\nThe function \\(g(t)=t\\sin(1/t)\\) for \\(t&gt;0\\) and \\(g(0)=0\\) is continuous on \\([0,1]\\) and differentiable at all points except zero, but is not of bounded variation on any interval that includes \\(0\\). Consider the partition \\(\\{x_{n}\\}=\\left\\{ \\frac{1}{\\pi/2+n\\pi}\\right\\}\\). Thus,\n\\[\\begin{aligned}\n\\sin(\\frac{1}{x_{n}}) & =\\begin{cases}\n1 & \\text{if }n\\text{ is even}\\\\\n-1 & \\text{if }n\\text{ is odd}\n\\end{cases}\n\\end{aligned}\\]\nThus,\n\\[\\begin{aligned}\nf(x_{n}) & =\\begin{cases}\nx_{n} & n\\text{ is even}\\\\\n-x_{n} & n\\text{ is odd}\n\\end{cases}\n\\end{aligned}\\]\nTherefore,\n\\[\\begin{aligned}\n\\sum_{n=1}^{m}|f(x_{n})-f(x_{n-1})| & =\\sum_{n=1}^{m}(x_{n}+x_{n-1})\\\\\n& =x_{0}+x_{n}+2\\sum_{n=1}^{m-1}x_{n}\\\\\n& \\geq\\sum_{n=1}^{m-1}x_{n}\n\\end{aligned}\\]\nThis is the lower bound on the variation of \\(g\\) on the partition \\(\\{0,x_{m},\\ldots,x_{1},x_{0},1\\}\\). Now, passing to the limit as \\(m\\) approaches infinity, \\(\\sum\\frac{1}{\\pi/2+n\\pi}\\) is a divergent series. Consequently, \\(V_{g}([0,1])\\) has unbounded variation.\n\n\n\n\n\nAny function \\(g:[0,\\infty)\\to\\mathbf{R}\\) is of bounded variation if and only if it can be expressed as the difference of two increasing functions:\n\\[\\begin{aligned}\ng(t) & =a(t)-b(t)\n\\end{aligned}\\]\n\n\nProof. Proof. (\\(\\Longrightarrow\\)direction). If \\(g\\) is of finite variation, \\(V_{g}(t)&lt;\\infty\\) for all \\(t\\), and we can write:\n\\[\\begin{aligned}\ng(t) & =V_{g}(t)-(V_{g}(t)-g(t))\n\\end{aligned}\\]\nLet \\(a(t)=V_{g}(t)\\) and \\(b(t)=V_{g}(t)-g(t)\\). Clearly, both \\(a(t)\\) and \\(b(t)\\) are increasing functions.\n(\\(\\Longleftarrow\\)direction). Suppose a function \\(g\\) can be expressed as a difference of two bounded increasing functions. Then,\n\\[\\begin{aligned}\nV_{g}(t) & =\\lim_{||\\Delta_{n}||\\to0}\\sum_{i=1}^{n}|(a(t_{i})-b(t_{i}))-(a(t_{i-1})-b(t_{i-1})|\\\\\n& \\quad\\{\\text{ Telescoping sum }\\}\\\\\n& =a(t)-b(t)-(a(0)-b(0))\n\\end{aligned}\\]\nSince both \\(a(t)\\) and \\(b(t)\\) are bounded, \\(g\\) has bounded variation. ◻\n\n\n\n\nLet \\(g\\) be a montonically increasing function on a finite closed interval \\([a,b]\\). A bounded function \\(f\\) defined on \\([a,b]\\) is said to Riemann-Stieltjes integrable with respect to \\(g\\) if the following limit exists:\n\\[\\begin{aligned}\n\\int_{a}^{b}f(t)dg(t) & =\\lim_{||\\Delta_{n}||\\to0}\\sum_{i=1}^{n}f(\\tau_{i})(g(t_{i})-g(t_{i-1}))\\label{eq:riemann-stieltjes-integral}\n\\end{aligned}\\]\nwhere \\(\\tau_{i}\\) is an evaluation point in the interval \\([t_{i-1},t_{i}]\\). It is a well-known fact that continuous functions are Riemann integrable and Riemann-Stieltjes integrable with respect to any monotonically increasing function on \\([a,b]\\).\nWe ask the following question. For any continuous functions \\(f\\) and \\(g\\) on \\([a,b]\\), can we define the integral \\(\\int_{a}^{b}f(t)dg(t)\\) by Equation ([eq:riemann-stieltjes-integral])?\nConsider the special case \\(f=g\\), namely, the integral:\n\\[\\int_{a}^{b}f(t)df(t)\\]\nLet \\(\\Delta_{n}=\\{a=t_{0},t_{1},\\ldots,t_{n}=b\\}\\) be a partition of \\([a,b]\\). Let \\(L_{n}\\) and \\(R_{n}\\) denote the corresponding Riemann sums with the evaluation points \\(\\tau_{i}=t_{i-1}\\) and \\(\\tau_{i}=t_{i}\\), respectively, namely,\n\\[\\begin{aligned}\nL_{n} & =\\sum_{i=1}^{n}f(t_{i-1})(f(t_{i})-f(t_{i-1}))\\label{eq:left-riemann-sum}\\\\\nR_{n} & =\\sum_{i=1}^{n}f(t_{i})(f(t_{i})-f(t_{i-1}))\\label{eq:right-riemann-sum}\n\\end{aligned}\\]\nIs it true that, \\(\\lim L_{n}=\\lim R_{n}\\) as \\(||\\Delta_{n}||\\to0\\)? Observe that:\n\\[R_{n}-L_{n}=\\sum_{i=1}^{n}(f(t_{i})-f(t_{i-1}))^{2}\\label{eq:quadratic-variation}\\]\n\\[R_{n}+L_{n}=\\sum_{i=1}^{n}(f(t_{i})^{2}-f(t_{i-1})^{2})=f(b)^{2}-f(a)^{2}\\label{eq:sum-of-left-and-right-riemann-sums}\\]\nTherefore, \\(R_{n}\\) and \\(L_{n}\\) are given by:\n\\[R_{n}=\\frac{1}{2}\\left(f(b)^{2}-f(a)^{2}+\\sum_{i=1}^{n}(f(t_{i})-f(t_{i-1}))^{2}\\right)\\]\n\\[L_{n}=\\frac{1}{2}\\left(f(b)^{2}-f(a)^{2}-\\sum_{i=1}^{n}(f(t_{i})-f(t_{i-1}))^{2}\\right)\\]\nThe limit of the right-hand side of equation ([eq:quadratic-variation]) is called the quadratic variation of the function \\(f\\) on \\([a,b]\\). Obviously, \\(\\lim_{||\\Delta_{n}||\\to0}R_{n}\\neq\\lim_{||\\Delta_{n}||\\to0}L_{n}\\) if and only the quadratic variation of the function \\(f\\) is non-zero.\n\nLet \\(f\\) be a \\(C^{1}\\)-function that is \\(f'(t)\\) is a continuous function. Then, by the mean value theorem:\n\\[\\begin{aligned}\n|R_{n}-L_{n}| & =\\sum_{i=1}^{n}(f(t_{i})-f(t_{i-1}))^{2}\\\\\n& =\\sum_{i=1}^{n}(f'(t_{i}^{*})(t_{i}-t_{i-1}))^{2}\\\\\n& \\quad\\{\\text{Mean Value Theorem}\\}\\\\\n& \\leq\\sum_{i=1}^{n}\\left\\Vert f'\\right\\Vert _{\\infty}^{2}(t_{i}-t_{i-1})^{2}\\\\\n& \\quad\\{\\text{ Interior Extremum Theorem }\\}\\\\\n& \\leq\\left\\Vert f'\\right\\Vert _{\\infty}^{2}\\left\\Vert \\Delta_{n}\\right\\Vert \\sum_{i=1}^{n}(t_{i}-t_{i-1})\\\\\n& =\\left\\Vert f'\\right\\Vert _{\\infty}^{2}\\left\\Vert \\Delta_{n}\\right\\Vert (b-a)\n\\end{aligned}\\]\nwhere \\(\\left\\Vert f'\\right\\Vert _{\\infty}=\\sup_{x\\in[a,b]}f(x)\\). Thus, the limit as \\(\\left\\Vert \\Delta_{n}\\right\\Vert \\to0\\) of the distance \\(|R_{n}-L_{n}|\\) also approaches zero. Thus, \\(\\lim L_{n}=\\lim R_{n}\\) as \\(\\left\\Vert \\Delta_{n}\\right\\Vert \\to0\\) and the Riemann-Stieltjes integral exists. By equation ([eq:sum-of-left-and-right-riemann-sums]), we have:\n\\[\\lim_{\\left\\Vert \\Delta_{n}\\right\\Vert \\to0}L_{n}=\\lim_{\\left\\Vert \\Delta_{n}\\right\\Vert \\to0}R_{n}=\\frac{1}{2}(f(b)^{2}-f(a)^{2})\\]\nOn the other hand, for such a \\(C^{1}\\)-function \\(f\\), we may simply define the integral \\(\\int_{a}^{b}f(t)df(t)\\) by:\n\\[\\begin{aligned}\n\\int_{a}^{b}f(t)df(t) & =\\int_{a}^{b}f(t)f'(t)dt\n\\end{aligned}\\]\nThen, by the fundamental theorem of Calculus:\n\\[\\int_{a}^{b}f(t)df(t)=\\int_{a}^{b}f(t)f'(t)dt=\\frac{1}{2}f(t)^{2}|_{a}^{b}=\\frac{1}{2}(f(b)^{2}-f(a)^{2})\\]\n\n\nThere is a very close relationship between functions with bounded variation and functions for which the classical integral makes sense. For the Ito integral, the quadratic variation plays a similar role. The quadratic variation of a smooth fuction \\(f\\in C^{1}([0,t])\\) is zero.\n\n\nSuppose \\(f\\) is a continuous function satisfying the condition\n\\[\\begin{aligned}\n|f(t)-f(s)| & \\leq C|t-s|^{1/2}\n\\end{aligned}\\]\nwhere \\(0&lt;C&lt;1\\).\nIn this case we have:\n\\[0\\leq|R_{n}-L_{n}|\\leq C^{2}\\sum_{i=1}^{n}(t_{i}-t_{i-1})=C^{2}(b-a)\\]\nHence, \\(\\lim R_{n}\\neq\\lim L_{n}\\) as \\(\\left\\Vert \\Delta_{n}\\right\\Vert \\to0\\) when \\(a\\neq b\\). Consequently, the integral \\(\\int_{a}^{b}f(t)df(t)\\) cannot be defined for such a function \\(f\\). Observe that the quandratic variation of the function is \\(b-a\\) (non-zero).\n\nWe see from the above examples, that definining the integral \\(\\int_{a}^{b}f(t)dg(t)\\) even when \\(f=g\\) is a non-trivial problem. Consider the question posed earlier - if \\(f\\) and \\(g\\) are continuous functions on \\([a,b]\\), can we define the integral \\(\\int_{a}^{b}f(t)dg(t)\\)? There is no simple answer to this question. But then in view of example ([ex:non-zero-quadratic-variation-example]), we can ask another question:\nQuestion. Are there continuous functions \\(f\\) satisfying the condition\n\\[\\begin{aligned}\n|f(t)-f(s)| & \\leq C|t-s|^{1/2}\n\\end{aligned}\\]\n\n\n\nConsider a random walk starting at \\(0\\) with jumps \\(h\\) and \\(-h\\) equally at times \\(\\delta\\), \\(2\\delta\\), \\(\\ldots\\) where \\(h\\) and \\(\\delta\\) are positive numbers. More precisely, let \\(\\{X_{n}\\}_{n=1}^{\\infty}\\) be a sequence of independent and identically distributed random variables with :\n\\[\\begin{aligned}\n\\mathbb{P}\\{X_{j}=h\\} & =\\mathbb{P}\\{X_{j}=-h\\}=\\frac{1}{2}\n\\end{aligned}\\]\nLet \\(Y_{\\delta,h}(0)=0\\) and put:\n\\[\\begin{aligned}\nY_{\\delta,h}(n\\delta) & =X_{1}+X_{2}+\\ldots+X_{n}\n\\end{aligned}\\]\nFor \\(t&gt;0\\), define \\(Y_{\\delta,h}(t)\\) by linearization that is, for \\(n\\delta&lt;t&lt;(n+1)\\delta\\), define:\n\\[\\begin{aligned}\nY_{\\delta,h}(t) & =\\frac{(n+1)\\delta-t}{\\delta}Y_{\\delta,h}(n\\delta)+\\frac{t-n\\delta}{\\delta}Y_{\\delta,h}((n+1)\\delta)\n\\end{aligned}\\]\nWe can think of \\(Y_{\\delta,h}(t)\\) as the position of the random walk at time \\(t\\). In particular, \\(X_{1}+X_{2}+\\ldots+X_{n}\\) is the position of this random walk at time \\(n\\delta\\).\nQuestion. What is the limit of the random walk \\(Y_{\\delta,h}\\) as \\(\\delta,h\\to0\\)?\nRecall that the characteristic function of a random variable \\(X\\) is \\(\\phi_{X}(\\lambda)=\\mathbb{E}\\exp[i\\lambda X]\\). In order to find out the answer, let us compute the following limit of the characteristic function of \\(Y_{\\delta,h}(t)\\):\n\\[\\lim_{\\delta,h\\to0}\\mathbb{E}\\exp\\left[i\\lambda Y_{\\delta,h}(t)\\right]\\]\nwhere \\(\\lambda\\in\\mathbf{R}\\)is fixed. For heuristic derivation, let \\(t=n\\delta\\) and so \\(n=t/\\delta\\). Then we have:\n\\[\\begin{aligned}\n\\mathbb{E}\\exp\\left[i\\lambda Y_{\\delta,h}(t)\\right] & =\\prod_{j=1}^{n}\\mathbb{E}e^{i\\lambda X_{j}}\\\\\n& =\\prod_{j=1}^{n}\\left(\\frac{1}{2}e^{i\\lambda h}+\\frac{1}{2}e^{-i\\lambda h}\\right)\\\\\n& =\\left(\\frac{1}{2}e^{i\\lambda h}+\\frac{1}{2}e^{-i\\lambda h}\\right)^{n}\\\\\n& =\\left(\\cos\\lambda h\\right)^{n}\\\\\n& =\\left(\\cos\\lambda h\\right)^{t/\\delta}\n\\end{aligned}\\]\nFor fixed \\(t\\) and \\(\\lambda\\), when \\(\\delta\\) and \\(h\\) independently approach \\(0\\), the limit of \\(\\mathbb{E}\\exp\\left[i\\lambda Y_{\\delta,h}(t)\\right]\\) may not exist. For example, holding \\(h\\) constant, letting \\(\\delta\\to0\\), since \\(-1\\leq\\cos\\theta\\leq1\\), the function \\(\\left(\\cos\\lambda h\\right)^{t/\\delta}\\to0\\). Holding \\(\\delta\\) constant, letting \\(h\\to0\\), the function \\(\\left(\\cos\\lambda h\\right)^{t/\\delta}\\to1\\). In order for the limit to exist, we impose a certain relationship between \\(\\delta\\) and \\(h\\). However, depending on the relationship, we may obtain different limits.\nLet \\(u=\\cos(\\lambda h)^{1/\\delta}\\). Then \\(\\ln u=\\frac{1}{\\delta}\\ln\\cos(\\lambda h)\\). Note that:\n\\[\\begin{aligned}\n\\cos(\\lambda h) & \\approx1-\\frac{1}{2}\\lambda^{2}h^{2}\n\\end{aligned}\\]\nAnd \\(\\ln(1+x)\\approx x\\). Hence,\n\\[\\ln\\cos(\\lambda h)\\approx\\ln\\left(1-\\frac{1}{2}\\lambda^{2}h^{2}\\right)\\approx-\\frac{1}{2}\\lambda^{2}h^{2}\\]\nTherefore for small \\(\\lambda\\) and \\(h\\), we have \\(\\ln u\\approx-\\frac{1}{2\\delta}\\lambda^{2}h^{2}\\) and so:\n\\[\\begin{aligned}\nu & \\approx\\exp\\left[-\\frac{1}{2\\delta}\\lambda^{2}h^{2}\\right]\n\\end{aligned}\\]\nIn particular, if \\(\\delta\\) and \\(h\\) are related by \\(h^{2}=\\delta\\), then\n\\[\\begin{aligned}\n\\lim_{\\delta\\to0}\\mathbb{E}\\exp\\left[i\\lambda Y_{\\delta,h}(t)\\right] & =e^{-\\frac{1}{2}\\lambda^{2}t}\n\\end{aligned}\\]\nBut, \\(e^{-\\frac{1}{2}\\lambda^{2}t}\\) is the characteristic function of a Gaussian random variable with mean \\(0\\) and variance \\(t\\). Thus, we have derived the following theorem about the limit of the random walk \\(Y_{\\delta,h}\\) as \\(\\delta,h\\to0\\) in such a way that \\(h^{2}=\\delta\\).\n\nLet \\(Y_{\\delta,h}(t)\\) be the random walk starting at \\(0\\) with jumps \\(h\\) and \\(-h\\) equally likely at times \\(\\delta\\), \\(2\\delta\\), \\(3\\delta\\), \\(\\ldots\\). Assume that \\(h^{2}=\\delta\\). Then, for each \\(t\\geq0\\), the limit:\n\\[\\begin{aligned}\n\\lim_{\\delta\\to0}Y_{\\delta,h}(t) & =B(t)\n\\end{aligned}\\] exists in distribution. Moreover, we have:\n\\[\\begin{aligned}\n\\mathbb{E}e^{i\\lambda B(t)} & =e^{-\\frac{1}{2}\\lambda^{2}t}\n\\end{aligned}\\]\n\n\n(Quadratic Variation of a Brownian motion). Let \\((B_{t},t\\ge0)\\) be a standard brownian motion. Then, for any sequence of partitions \\((t_{j},j\\leq n)\\) of \\([0,t]\\) we have:\n\\[\\begin{aligned}\n\\left\\langle B\\right\\rangle _{t} & =\\sum_{j=1}^{n}(B_{t_{j+1}}-B_{t_{j}})^{2}\\stackrel{L^{2}}{\\to}t\n\\end{aligned}\\]\nwhere the convergence is in the \\(L^{2}\\) sense.\n\n\nIt is reasonable to have some sort of convergence as we are dealing with a sum of independent random variables. However, the conclusion would not hold if the increments were not squared. So there is something more at play here.\n\n\nProof. Proof. We have:\n\\[\\begin{aligned}\n\\mathbb{E}\\left[\\left(\\sum_{j=0}^{n-1}(B(t_{j+1})-B(t_{j}))^{2}-t\\right)^{2}\\right] & =\\mathbb{E}\\left[\\left(\\sum_{j=0}^{n-1}(B(t_{j+1})-B(t_{j}))^{2}-\\sum_{j=0}^{n-1}(t_{j+1}-t_{j})\\right)^{2}\\right]\\\\\n& =\\mathbb{E}\\left[\\left(\\sum_{j=0}^{n-1}\\left\\{ (B(t_{j+1})-B(t_{j}))^{2}-(t_{j+1}-t_{j})\\right\\} \\right)^{2}\\right]\n\\end{aligned}\\]\nFor simplicity, we define the variables \\(X_{j}=(B(t_{j+1})-B(t_{j}))^{2}-(t_{j+1}-t_{j})\\). Then, we may write:\n\\[\\begin{aligned}\n\\mathbb{E}\\left[\\left(\\sum_{j=0}^{n-1}(B(t_{j+1})-B(t_{j}))^{2}-t\\right)^{2}\\right] & =\\mathbb{E}\\left[\\left(\\sum_{j=0}^{n-1}X_{j}\\right)^{2}\\right]\\\\\n& =\\mathbb{E}\\left[\\sum_{i=0}^{n-1}\\sum_{j=0}^{n-1}X_{i}X_{j}\\right]\\\\\n& =\\sum_{i=0}^{n-1}\\sum_{j=0}^{n-1}\\mathbb{E}[X_{i}X_{j}]\n\\end{aligned}\\]\nNow, the random variables \\(X_{j}\\) are independent.\nThe expectation of \\(X_{j}\\) is \\(\\mathbb{E}[X_{j}]=\\mathbb{E}(B(t_{j+1})-B(t_{j}))^{2}-(t_{j+1}-t_{j})=0\\).\nSince, \\(X_{i}\\) and \\(X_{j}\\) are independent, for \\(i\\neq j\\), \\(\\mathbb{E}[X_{i}X_{j}]=\\mathbb{E}X_{i}\\cdot\\mathbb{E}X_{j}=0\\).\nHence, we have:\n\\[\\begin{aligned}\n\\mathbb{E}\\left[\\left(\\sum_{j=0}^{n-1}(B(t_{j+1})-B(t_{j}))^{2}-t\\right)^{2}\\right] & =\\sum_{i=0}^{n-1}\\mathbb{E}[X_{i}^{2}]\n\\end{aligned}\\]\nWe now develop the expectation of the square of \\(X_{i}\\). We have:\n\\[\\begin{aligned}\n\\mathbb{E}[X_{i}^{2}] & =\\mathbb{E}\\left[\\left((B(t_{i+1})-B(t_{i}))^{2}-(t_{i+1}-t_{i})\\right)^{2}\\right]\\\\\n& =\\mathbb{E}\\left[((B(t_{i+1})-B(t_{i}))^{4}-2(B(t_{i+1})-B(t_{i}))^{2}(t_{i+1}-t_{i})+(t_{i+1}-t_{i})^{2}\\right]\n\\end{aligned}\\]\nThe MGF of the random variable \\(B(t_{i+1})-B(t_{i})\\) is :\n\\[\\begin{aligned}\n\\phi(\\lambda) & =\\exp\\left[\\frac{\\lambda^{2}(t_{i+1}-t_{i})}{2}\\right]\\\\\n\\phi'(\\lambda) & =\\lambda(t_{i+1}-t_{i})\\exp\\left[\\frac{\\lambda^{2}(t_{i+1}-t_{i})}{2}\\right]\\\\\n\\phi''(\\lambda) & =\\left[(t_{i+1}-t_{i})+\\lambda^{2}(t_{i+1}-t_{i})^{2}\\right]\\exp\\left[\\frac{\\lambda^{2}(t_{i+1}-t_{i})}{2}\\right]\\\\\n\\phi^{(3)}(\\lambda) & =\\left[3\\lambda(t_{i+1}-t_{i})^{2}+\\lambda^{3}(t_{i+1}-t_{i})^{3}\\right]\\exp\\left[\\frac{\\lambda^{2}(t_{i+1}-t_{i})}{2}\\right]\\\\\n\\phi^{(4)}(\\lambda) & =\\left[3(t_{i+1}-t_{i})^{2}+6\\lambda^{2}(t_{i+1}-t_{i})^{3}+\\lambda^{4}(t_{i+1}-t_{i})^{4}\\right]\\exp\\left[\\frac{\\lambda^{2}(t_{i+1}-t_{i})}{2}\\right]\n\\end{aligned}\\]\nThus, \\(\\mathbb{E}[(B(t_{i+1})-B(t_{i}))^{4}]=3(t_{i+1}-t_{i})^{2}\\). Consequently,\n\\[\\begin{aligned}\n\\mathbb{E}[X_{i}^{2}] & =\\mathbb{E}[(B(t_{i+1})-B(t_{i}))^{4}]-2(t_{i+1}-t_{i})\\mathbb{E}[(B(t_{i+1})-B(t_{i}))^{2}]+(t_{i+1}-t_{i})^{2}\\\\\n& =3(t_{i+1}-t_{i})^{2}-2(t_{i+1}-t_{i})^{2}+(t_{i+1}-t_{i})^{2}\\\\\n& =2(t_{i+1}-t_{i})^{2}\n\\end{aligned}\\]\nPutting all this together, we finally have that:\n\\[\\begin{aligned}\n\\mathbb{E}\\left[\\left(\\sum_{j=0}^{n-1}(B(t_{j+1})-B(t_{j}))^{2}-t\\right)^{2}\\right] & =2\\sum_{i=0}^{n-1}(t_{i+1}-t_{i})^{2}\\label{eq:second-moment-of-qv}\\\\\n& \\leq2\\left\\Vert \\Delta_{n}\\right\\Vert \\sum_{i=0}^{n-1}(t_{i+1}-t_{i})\\nonumber \\\\\n& =2\\left\\Vert \\Delta_{n}\\right\\Vert \\cdot t\\nonumber\n\\end{aligned}\\]\nAs \\(n\\to\\infty\\), \\(\\left\\Vert \\Delta_{n}\\right\\Vert \\to0\\). Hence,\n\\[\\begin{aligned}\n\\lim_{n\\to\\infty}\\mathbb{E}\\left[\\left(\\sum_{j=0}^{n-1}(B(t_{j+1})-B(t_{j}))^{2}-t\\right)^{2}\\right] & =0\n\\end{aligned}\\]\nHence, the sequence of random variables\n\\[\\begin{aligned}\n\\sum_{j=0}^{n-1}(B(t_{j+1})-B(t_{j}))^{2} & \\stackrel{L^{2}}{\\to}t\n\\end{aligned}\\] ◻\n\n\n(Quadratic Variation of a Brownian Motion Path). Let \\((B_{s},s\\geq0)\\) be a Brownian motion. For every \\(n\\in\\mathbf{N}\\), consider the dyadic partition \\((t_{j},j\\leq2^{n})\\) of \\([0,t]\\) where \\(t_{j}=\\frac{j}{2^{n}}t\\). Then we have that:\n\\[\\begin{aligned}\n\\left\\langle B\\right\\rangle _{t} & =\\sum_{j=1}^{2^{n}-1}(B_{t_{j+1}}-B_{t_{j}})^{2}\\stackrel{a.s.}{\\to}t\n\\end{aligned}\\]\n\n\nProof. Proof. We have \\((t_{i+1}-t_{i})=\\frac{t}{2^{n}}.\\) Borrowing equation ([eq:second-moment-of-qv]) from the proof of theorem ([th:quadratic-variation-of-bm-approaches-t-in-mean-square]), we have that:\n\\[\\begin{aligned}\n\\mathbb{E}\\left[\\left(\\sum_{j=0}^{2^{n}-1}(B(t_{j+1})-B(t_{j}))^{2}-t\\right)^{2}\\right] & =2\\sum_{i=0}^{2^{n}-1}\\left(\\frac{t}{2^{n}}\\right)^{2}\\\\\n& =2\\cdot(2^{n})\\cdot\\frac{t^{2}}{2^{2n}}\\\\\n& =\\frac{2t^{2}}{2^{n}}\n\\end{aligned}\\]\nBy Chebyshev’s inequality,\n\\[\\begin{aligned}\n\\mathbb{P}\\left(\\left|\\sum_{j=0}^{2^{n}-1}(B(t_{j+1})-B(t_{j}))^{2}-t\\right|&gt;\\epsilon\\right) & \\leq\\frac{1}{\\epsilon^{2}}\\mathbb{E}\\left[\\left(\\sum_{j=0}^{2^{n}-1}(B(t_{j+1})-B(t_{j}))^{2}-t\\right)^{2}\\right]\\\\\n& \\leq\\frac{1}{\\epsilon^{2}}\\cdot\\frac{2t^{2}}{2^{n}}\n\\end{aligned}\\]\nDefine \\(A_{n}:=\\left\\{ \\left|\\sum_{j=0}^{2^{n}-1}(B(t_{j+1})-B(t_{j}))^{2}-t\\right|&gt;\\epsilon\\right\\}\\). Since, \\(\\sum\\frac{1}{2^{n}}\\) is a convergent series, any multiple of it, \\((2t^{2}/\\epsilon^{2})\\sum\\frac{1}{2^{n}}\\) also converges. Now, \\(0\\leq\\mathbb{P}(A_{n})\\leq\\frac{(2t^{2}/\\epsilon^{2})}{2^{n}}\\). By the comparison test, \\(\\sum\\mathbb{P}(A_{n})\\) converges to a finite value. By Theorem ([th:sufficient-condition-for-almost-sure-convergence]),\n\\[\\begin{aligned}\n\\sum_{j=0}^{2^{n}-1}(B(t_{j+1})-B(t_{j}))^{2} & \\stackrel{a.s.}{\\to}t\n\\end{aligned}\\] ◻\n\nWe are now ready to show that every Brownian motion path has infinite variation.\nIf \\(g\\) is a \\(C^{1}\\) function,\n\\[\\begin{aligned}\n\\int_{0}^{t}|g'(t)|dt & =\\int_{0}^{t}\\sqrt{g'(t)^{2}}dt\\\\\n& \\leq\\int_{0}^{t}\\sqrt{1+g'(t)^{2}}dt\\\\\n& =l_{g}(t)\n\\end{aligned}\\]\nwhere \\(l_{g}(t)\\) is the arclength of the function \\(g\\) between \\([0,t]\\). So, \\(V_{g}(t)\\leq l_{g}(t)\\) and further:\n\\[\\begin{aligned}\nl_{g}(t) & =\\int_{0}^{t}\\sqrt{1+g'(t)^{2}}dt\\\\\n& \\leq\\int_{0}^{t}\\left(1+\\sqrt{g'(t)^{2}}\\right)dt\\\\\n& \\leq t+V_{g}(t)\n\\end{aligned}\\]\nConsequently,\n\\[\\begin{aligned}\nV_{g}(t) & \\leq l_{g}(t)\\leq t+V_{g}(t)\n\\end{aligned}\\]\nThe total variation of the function is finite if and only if it’s arclength is.\nHence, intuitively, our claim is that a Brownian motion path on \\([0,T]\\) has infinite arc-length. Since \\(g\\in C^{1}([a,b])\\Longrightarrow(V_{g}(t)&lt;\\infty)\\), it follows that \\((V_{g}(t)\\to\\infty)\\Longrightarrow g\\notin C^{1}\\).\n\n(Brownian Motion paths have unbounded total variation.)  Let \\((B_{s},s\\geq0)\\) be a Brownian motion. Then, the random functions \\(B(s,\\omega)\\) on the interval \\([0,t]\\) have unbounded variation almost surely.\n\n\nProof. Proof. Take the sequence of dyadic partitions of \\([0,t]\\): \\(t_{j}=\\frac{j}{2^{n}}t\\), \\(n\\in\\mathbf{N}\\), \\(j\\leq2^{n}\\). By pulling out the worst increment, we have the trivial bound for every \\(\\omega\\):\n\\[\\begin{aligned}\n\\sum_{j=0}^{2^{n}-1}(B_{t_{j+1}}(\\omega)-B_{t_{j}}(\\omega))^{2} & \\leq\\max_{0\\leq j\\leq2^{n}}\\left|B_{t_{j+1}}(\\omega)-B_{t_{j}}(\\omega)\\right|\\cdot\\sum_{j=0}^{2^{n}-1}(B_{t_{j+1}}(\\omega)-B_{t_{j}}(\\omega))\\label{eq:trivial-upper-bound-on-quadratic-variation}\n\\end{aligned}\\]\nWe proceed by contradiction. Let \\(A'\\) be the set of all \\(\\omega\\), for which the Brownian motion paths have bounded total variation. Let \\(A\\) be event that the Brownian motion paths have unbounded variation.\nBy the definition of total variation, that would imply, \\(\\exists M\\in\\mathbf{N}\\) :\n\\[\\begin{aligned}\n(\\forall\\omega\\in A')\\quad\\lim_{n\\to\\infty}\\sum_{j=0}^{2^{n}-1}\\left|(B_{t_{j+1}}(\\omega)-B_{t_{j}}(\\omega))\\right| & &lt;M\n\\end{aligned}\\]\nSince Brownian Motion paths are continuous on the compact set \\([\\frac{j}{2^{n}}t,\\frac{j+1}{2^{n}}t]\\), they are uniformly continuous. So, as \\(n\\to\\infty\\), \\(|t_{j+1}-t_{j}|\\to0\\) and therefore \\(|B_{t_{j+1}}(\\omega)-B_{t_{j}}(\\omega)|\\to0\\). And consequently, \\(\\max_{0\\leq j\\leq2^{n}}\\left|B_{t_{j+1}}(\\omega)-B_{t_{j}}(\\omega)\\right|\\to0\\).\nThus, for every \\(\\omega\\in A'\\), the right hand side of the inequality ([eq:trivial-upper-bound-on-quadratic-variation]), converges to \\(0\\) and therefore the left hand side converges to \\(0\\). But, this contradicts the fact that \\(\\left\\langle B\\right\\rangle _{t}\\stackrel{a.s.}{\\to}t\\). So, \\(A'\\) is a null set, and \\(\\mathbb{P}(A')=0\\) and \\(\\mathbb{P}(A)=1\\). This closes the proof. ◻"
  },
  {
    "objectID": "posts/properties-of-brownian-motion/index.html#what-exactly-is-omegamathcalfmathbbp-in-mathematical-finance",
    "href": "posts/properties-of-brownian-motion/index.html#what-exactly-is-omegamathcalfmathbbp-in-mathematical-finance",
    "title": "Properties of Brownian Motion",
    "section": "",
    "text": "If we make the simplifying assumption that the process paths are continuous, we obtain the set of all continuous functions on \\([0,T]\\), denoted by \\(C[0,T]\\). This is a very rich space. In a more general model, it is assumed that the process paths are right continuous with left limits (regular right-continuous RRC, cadlag) functions.\nLet the sample space \\(\\Omega=D[0,T]\\) be the set of all RRC functions on \\([0,T]\\). An element of this set is a RRC function from \\([0,T]\\) into \\(\\mathbf{R}\\). First we must decide what kind of sets of these functions are measurable? The simplest set for which we would like to calculate the probabilities are sets of the form \\(\\{a\\leq S(t_{1})\\leq b\\}\\) for some \\(t_{1}\\). If \\(S(t)\\) represents the price of a stock at time \\(t\\), then the probability of such a set gives the probability that the stock price at time \\(t_{1}\\) is between \\(a\\) and \\(b\\). We are also interested in how the price of the stock at time \\(t_{1}\\) affects the price at another time \\(t_{2}\\). Thus, we need to talk about the joint distribution of stock prices \\(S(t_{1})\\) and \\(S(t_{2})\\). This means that we need to define probability on the sets of the form \\(\\{S(t_{1})\\in B_{1},S(t_{2})\\in B_{2}\\}\\) where \\(B_{1}\\) and \\(B_{2}\\) are intervals on the line. More generally, we would like to have all the finite-dimensional distributions of the process \\(S(t)\\), that is, the probabilities of the sets: \\(\\{S(t_{1})\\in B_{1},S(t_{2})\\in B_{2},\\ldots,S(t_{n})\\in B_{n}\\}\\) for any choice of \\(0\\leq t_{1}\\leq\\ldots\\leq t_{n}\\leq T\\).\nThe sets of the form \\(A=\\{\\omega(\\cdot)\\in D[0,T]:\\omega(t_{1})\\in B_{1},\\ldots,\\omega(t_{n})\\in B_{n}\\}\\), where \\(B_{i}\\)’s are borel subsets of \\(\\mathbf{R}\\), are called cylinder sets or finite-dimensional rectangles.\nThe stochastic process \\(S(t)\\) is just a (function-valued) random variable on this sample space, which takes some value \\(\\omega(t)\\) - the value of the function \\(\\omega\\) at \\(t\\).\nLet \\(\\mathcal{R}\\) be the colllection of all cylindrical subsets of \\(D[0,1]\\). Obviously \\(\\mathcal{R}\\) is not a \\(\\sigma\\)-field.\nProbability is first defined by on the elements of \\(\\mathcal{R}\\). Let \\(A\\subseteq\\mathcal{R}\\).\n\\[\\begin{aligned}\n\\mathbb{P}(A) & =\\int_{B_{1}}\\cdots\\int_{B_{n}}\\prod_{i=1}^{n}\\frac{1}{\\sqrt{(2\\pi)(t_{i}-t_{i-1})}}\\exp\\left[-\\frac{(u_{i}-u_{i-1})^{2}}{2(t_{i}-t_{i-1})}\\right]du_{1}\\cdots du_{n}\n\\end{aligned}\\]\nand then extended to the \\(\\sigma\\)-field generated by taking unions, complements and intersections of cylinders. We take the smallest \\(\\sigma\\)-algebra containing all the cylindrical subsets of \\(D[0,1]\\). Thus, \\(\\mathcal{F}=\\mathcal{B}(D[0,1])\\).\nHence, \\((\\Omega,\\mathcal{F},\\mathbb{P})=(D[0,1],\\mathcal{B}(D[0,1]),\\mathbb{P})\\) is a probability space. It is called the Wiener space and \\(\\mathbb{P}\\) here is called the Wiener measure."
  },
  {
    "objectID": "posts/properties-of-brownian-motion/index.html#continuity-and-regularity-of-paths.",
    "href": "posts/properties-of-brownian-motion/index.html#continuity-and-regularity-of-paths.",
    "title": "Properties of Brownian Motion",
    "section": "",
    "text": "As discussed in the previous section, a stochastic process is determined by its finite-dimensional distribution. In studying stochastic processes, it is often natural to think of them as function-valued random variables in \\(t\\). Let \\(S(t)\\) be defined for \\(0\\leq t\\leq T\\), then for a fixed \\(\\omega\\), it is a function in \\(t\\), called the sample path or a realization of \\(S\\). Finite-dimensional distributions do not determine the continuity property of sample paths. The following example illustrates this.\n\nLet \\(X(t)=0\\) for all \\(t\\), \\(0\\leq t\\leq1\\) and \\(\\tau\\) be a uniformly distributed random variable on \\([0,1]\\). Let \\(Y(t)=0\\) for \\(t\\neq\\tau\\) and \\(Y(t)=1\\) if \\(t=\\tau.\\) Then, for any fixed \\(t\\), \\(\\mathbb{P}(Y(t)\\neq0)=\\mathbb{P}(\\tau=t)=0\\), and hence \\(\\mathbb{P}(Y(t)=0)=1\\). So, that all one-dimensional distributions of \\(X(t)\\) and \\(Y(t)\\) are the same. Similarly, all finite-dimensional distributions of \\(X\\) and \\(Y\\) are the same. However, the sample paths of the process \\(X\\), that is, the functions \\(X(t)_{0\\leq t\\leq1}\\) are continuous in \\(t\\), whereas every sample path \\(Y(t)_{0\\leq t\\leq1}\\) has a jump at the (random) point \\(\\tau\\). Notice that, \\(\\mathbb{P}(X(t)=Y(t))=1\\) for all \\(t\\), \\(0\\leq t\\leq1\\).\n\n\nTwo stochastic processes are called versions (modifications) of one another if\n\\[\\mathbb{P}(X(t)=Y(t))=1\\quad\\text{for all }0\\leq t\\leq T\\]\n\nThus, the two processes in the example ([ex:modifications-of-a-stochastic-process]) are versions of one another, one has continuous sample paths, the other does not. If we agree to pick any version of the process we want, then we can pick the continous version when it exists. In general, we choose the smoothest possible version of the process.\nFor two processes, \\(X\\) and \\(Y\\), denote by \\(N_{t}=\\{X(t)\\neq Y(t)\\}\\), \\(0\\leq t\\leq T\\). In the above example, \\(\\mathbb{P}(N_{t})=\\mathbb{P}(\\tau=t)=0\\) for any \\(t\\), \\(0\\leq t\\leq1\\). However, \\(\\mathbb{P}(\\bigcup_{0\\leq t\\leq1}N_{t})=\\mathbb{P}(\\tau=t\\:\\text{for some }t\\:\\text{in }[0,1])=1\\). Although, each of \\(N_{t}\\) is a \\(\\mathbb{P}\\)-null set, the union \\(N=\\bigcup_{0\\leq t\\leq1}N_{t}\\) contains uncountably many null sets, and in this particular case it is a set of of probability one.\nIf it happens that \\(\\mathbb{P}(N)=0\\), then \\(N\\) is called an evanescent set, and the processes \\(X\\) and \\(Y\\) are called indistinguishable. Note that in this case, \\(\\mathbb{P}(\\{\\omega:\\exists t:X(t)\\neq Y(t)\\})=\\mathbb{P}(\\bigcup_{0\\leq t\\leq1}\\{X(t)\\neq Y(t))=0\\) and \\(\\mathbb{P}(\\bigcap_{0\\leq t\\leq1}\\{X(t)=Y(t)\\})=1\\). It is clear, that if the time is discrete, then any two versions of the process are indistinguishable. It is also not hard to see, that if \\(X(t)\\) and \\(Y(t)\\) are versions of one another and they are both right-continuous, they are indistinguishable.\n\n(Paul Levy’s construction of Brownian Motion). Standard Brownian motion exists.\n\n\nProof. Proof. I reproduce the standard proof as present in Brownian Motion by Morters and Peres. I added some remarks for greater clarity.\nLet\n\\[\\begin{aligned}\n\\mathcal{D}_{n} & =\\left\\{ \\frac{k}{2^{n}}:k=0,1,2,\\ldots,2^{n}\\right\\}\n\\end{aligned}\\]\nbe a finite set of dyadic points.\nLet\n\\[\\begin{aligned}\n\\mathcal{D} & =\\bigcup_{n=0}^{\\infty}\\mathcal{D}_{n}\n\\end{aligned}\\]\nLet \\(\\{Z_{t}:t\\in\\mathcal{D}\\}\\) be a collection of independent, standard normally distributed random variables. This is a countable set of random variables.\nLet \\(B(0):=0\\) and \\(B(1):=Z_{1}\\).\nFor each \\(n\\in\\mathbf{N}\\), we define the random variables \\(B(d)\\), \\(d\\in\\mathcal{D}_{n}\\) such that, the following invariant holds:\n(1) for all \\(r&lt;s&lt;t\\) in \\(\\mathcal{D}_{n}\\) the random variable \\(B(t)-B(s)\\) is normally distributed with mean zero and variance \\(t-s\\) and is independent of \\(B(s)-B(r)\\).\n(2) the vectors \\((B(d):d\\in\\mathcal{D}_{n})\\) and \\((Z_{t}:t\\in\\mathcal{D}\\setminus\\mathcal{D}_{n})\\) are independent.\nNote that we have already done this for \\(\\mathcal{D}_{0}=\\{0,1\\}\\). Proceeding inductively, let’s assume that the above holds for some \\(n-1\\). We are interested to prove that the invariant also holds for \\(n\\).\nWe define \\(B(d)\\) for \\(d\\in\\mathcal{D}_{n}\\backslash\\mathcal{D}_{n-1}\\) by:\n\\[\\begin{aligned}\nB(d) & =\\frac{B(d-2^{-n})+B(d+2^{-n})}{2}+\\frac{Z_{d}}{2^{(n+1)/2}}\n\\end{aligned}\\]\nNote that, the points \\(0,\\frac{1}{2^{n-1}},\\ldots,\\frac{k}{2^{n-1}},\\frac{k+1}{2^{n-1}},\\ldots,1\\) belong to \\(\\mathcal{D}_{n-1}\\). The first summand is the linear interpolation of the values of \\(B\\) at the neighbouring points of \\(d\\) in \\(\\mathcal{D}_{n-1}\\). That is,\n\\[\\begin{aligned}\nB\\left(\\frac{2k+1}{2^{n}}\\right) & =\\frac{B\\left(\\frac{k}{2^{n-1}}\\right)+B\\left(\\frac{k+1}{2^{n-1}}\\right)}{2}+\\frac{Z_{d}}{2^{(n+1)/2}}\n\\end{aligned}\\]\nSince \\(P(n-1)\\) holds, \\(B(d-2^{-n})\\) and \\(B(d+2^{-n})\\) are have no dependence on \\((Z_{t}:t\\in\\mathcal{D}\\setminus\\mathcal{D}_{n-1})\\). Consequently, \\(B(d)\\) has no dependence on \\((Z_{t}:t\\in\\mathcal{D}\\setminus\\mathcal{D}_{n})\\) and the second property is fulfilled.\nMoreover, as \\(\\frac{1}{2}[B(d+2^{-n})-B(d-2^{-n})]\\) depends only on \\((Z_{t}:t\\in\\mathcal{D}_{n-1})\\), it is independent of \\(\\frac{Z_{d}}{2^{(n+1)/2}}\\). By our induction assumptions, they are both nromally distributed with mean \\(0\\) and variance \\(\\frac{1}{2^{(n+1)}}\\).\nSo, their sum and difference random variables\n\\[\\begin{aligned}\nB(d)-B(d-2^{-n}) & =\\frac{B(d+2^{-n})-B(d-2^{-n})}{2}+\\frac{Z_{d}}{2^{(n+1)/2}}\\\\\nB(d+2^{-n})-B(d) & =\\frac{B(d+2^{-n})-B(d-2^{-n})}{2}-\\frac{Z_{d}}{2^{(n+1)/2}}\n\\end{aligned}\\]\nare also independent, with mean \\(0\\) and variance \\(\\frac{1}{2^{n}}\\) (the variance of independent random variables is the sum of the variances).\nIndeed all increments \\(B(d)-B(d-2^{-n})\\) for \\(d\\in\\mathcal{D}_{n}\\setminus\\{0\\}\\) are independent. To see this, it suffices to show that they are pairwise independent. We have seen in the previous paragraph that the pairs \\(B(d)-B(d-2^{-n})\\) and \\(B(d+2^{-n})-B(d)\\) with \\(d\\in\\mathcal{D}_{n}\\setminus\\mathcal{D}_{n-1}\\) are independent. The other possibility is that the increments are over the intervals separated by some \\(d\\in\\mathcal{D}_{n-1}\\). For concreteness, if \\(n\\) were \\(3\\), then the increments, \\(B_{7/8}-B_{6/8}\\) and \\(B_{5/8}-B_{4/8}\\) are seperated by \\(d=\\frac{3}{4}\\in\\mathcal{D}_{2}\\). Choose \\(d\\in\\mathcal{D}_{j}\\) with this property and minimal \\(j\\), so, the two intervals are contained in \\([d-2^{-j},d]\\) and \\([d,d+2^{-j}]\\) respectively. By induction, the increments over these two intervals of length \\(2^{-j}\\) are independent and the increments over the intervals of length \\(2^{-n}\\) are constructed from the independent increments \\(B(d)-B(d-2^{-j})\\) and \\(B(d+2^{-j})-B(d)\\) using a disjoint set of variables \\((Z_{t}:t\\in\\mathcal{D}_{n})\\). Hence, they are independent and this implies pairwise independence. This implies the first property. Consequently, the vector of increments \\((B(d)-B(d-2^{-n})\\) for all \\(d\\in\\mathcal{D}_{n}\\) is Gaussian.\nHaving thus chosen the value of the process on all the dyadic points, we interpolate between them. Formally, we define:\n\\[\\begin{aligned}\nF_{0}(t) & =\\begin{cases}\nZ_{1} & \\text{for }t=1\\\\\n0 & \\text{for }t=0\\\\\n\\text{\\text{linear in between}}\n\\end{cases}\n\\end{aligned}\\]\nand for each \\(n\\geq1\\),\n\\[\\begin{aligned}\nF_{n}(t) & =\\begin{cases}\n\\frac{Z_{t}}{2^{(n+1)/2}} & \\text{for }t\\in\\mathcal{D}\\setminus\\mathcal{D}_{n-1}\\\\\n0 & \\text{for }t\\in\\mathcal{D}_{n-1}\\\\\n\\text{\\text{linear between consecutive points in }\\ensuremath{\\mathcal{D}_{n}}}\n\\end{cases}\n\\end{aligned}\\]\nThese functions are continuous on \\([0,1]\\) and for all \\(n\\) and \\(d\\in\\mathcal{D}_{n}\\), we have:\n\\[\\begin{aligned}\nB(d) & =\\sum_{i=0}^{n}F_{i}(d)=\\sum_{i=0}^{\\infty}F_{i}(d)\\label{eq:claim-of-induction-for-bd}\n\\end{aligned}\\]\nTo see this, assume that above equation holds for all \\(d\\in\\mathcal{D}_{n-1}\\).\nLet’s consider the point \\(d\\in\\mathcal{D}_{n}\\setminus\\mathcal{D}_{n-1}\\).\n\\[\\begin{aligned}\nB(d) & =\\frac{B(d-2^{-n})+B(d+2^{-n})}{2}+\\frac{Z_{d}}{2^{(n+1)/2}}\\nonumber \\\\\n& =\\sum_{i=0}^{n-1}\\frac{F_{i}(d-2^{-n})+F_{i}(d+2^{-n})}{2}+\\frac{Z_{d}}{2^{(n+1)/2}}\\label{eq:expression-for-bd}\n\\end{aligned}\\]\nNow, \\(d-2^{-n}\\) and \\(d+2^{-n}\\) belong to \\(\\mathcal{D}_{n-1}\\) and are not in \\(\\bigcup_{i&lt;n-1}\\mathcal{D}_{i}\\). Therefore, for \\(i=0,1,\\ldots,n-2\\), the points \\((d-2^{-n},F_{i}(d-2^{-n}))\\) and \\((d+2^{-n},F_{i}(d+2^{-n})\\) lie on some straight line and have \\((d,F_{i}(d))\\) as their midpoint. Moreover, \\(d-2^{-n}\\) and \\(d+2^{-n}\\) are vertices in \\(\\mathcal{D}_{n-1}\\). So, by definition of \\(F_{n-1}(d)\\), we have \\(F_{n-1}(d)=[F_{n-1}(d-2^{-n})+F_{n-1}(d+2^{-n})]/2\\).\nTo summarize, the first term on the right hand side of expression ([eq:expression-for-bd]) is equal to \\(\\sum_{i=0}^{n-1}F_{i}(d)\\). By mathematical induction, it follows that the claim ([eq:claim-of-induction-for-bd]) is true for all \\(n\\in\\mathbf{N}\\).\nIt’s extremely easy to find an upper bound on the probability contained in the Gaussian tails. Suppose \\(X\\sim N(0,1)\\) and let \\(x&gt;0\\). We are interested in the tail probability \\(\\mathbb{P}(X&gt;x)\\). We have:\n\\[\\begin{aligned}\n\\mathbb{P}(X&gt;x) & =\\int_{x}^{\\infty}e^{-x^{2}/2}dx=\\int_{x}^{\\infty}\\frac{xe^{-x^{2}/2}dx}{x}\n\\end{aligned}\\]\nLet \\(u=\\frac{1}{x}\\) and \\(dv=xe^{-x^{2}/2}dx\\). We have:\n\n\n\n\\(u=\\frac{1}{x}\\)\n\\(dv=xe^{-x^{2}/2}dx\\)\n\n\n\n\n\\(du=-\\frac{1}{x^{2}}dx\\)\n\\(v=-e^{-x^{2}/2}\\)\n\n\n\nThus,\n\\[\\begin{aligned}\n\\mathbb{P}(X&gt;x) & =-\\left.\\frac{1}{x}e^{-x^{2}/2}\\right|_{x}^{\\infty}-\\int_{x}^{\\infty}\\frac{e^{-x^{2}/2}}{x^{2}}dx\\\\\n& =\\frac{e^{-x^{2}/2}}{x}-\\int_{x}^{\\infty}\\frac{e^{-x^{2}/2}}{x^{2}}dx\\\\\n& \\quad\\left\\{ I(x)=\\int_{x}^{\\infty}\\frac{e^{-x^{2}/2}}{x^{2}}\\geq0\\right\\} \\\\\n& \\leq\\frac{e^{-x^{2}/2}}{x}\n\\end{aligned}\\]\nThus, for \\(c&gt;1\\) and large \\(n\\), we have:\n\\[\\begin{aligned}\n\\mathbb{P}(|Z_{d}|\\geq c\\sqrt{n}) & \\leq\\frac{1}{c\\sqrt{n}}e^{-c^{2}n/2}\\leq\\exp\\left(-\\frac{c^{2}n}{2}\\right)\n\\end{aligned}\\]\nSo, the series:\n\\[\\begin{aligned}\n\\sum_{n=0}^{\\infty}\\mathbb{P}\\left\\{ \\text{There exists atleast one }d\\in\\mathcal{D}_{n}\\text{ with }|Z_{d}|\\geq c\\sqrt{n}\\right\\}  & \\leq\\sum_{n=0}^{\\infty}\\sum_{d\\in\\mathcal{D}_{n}}\\mathbb{P}\\left\\{ |Z_{d}|\\geq c\\sqrt{n}\\right\\} \\\\\n& \\leq\\sum_{n=0}^{\\infty}(2^{n}+1)\\exp\\left(-\\frac{c^{2}n}{2}\\right)\n\\end{aligned}\\]\nNow, the series \\((a_{n})\\) given by, \\(a_{n}:=(2^{n}+1)e^{-c^{2}n/2}\\) has the ratio between successive terms:\n\\[\\begin{aligned}\n\\lim\\left|\\frac{a_{n+1}}{a_{n}}\\right| & =\\lim_{n\\to\\infty}\\frac{2^{n+1}+1}{2^{n}+1}\\cdot\\frac{e^{(c^{2}n)/2}}{e^{c^{2}(n+1)/2}}\\\\\n& =\\lim_{n\\to\\infty}\\frac{\\frac{1}{2}+\\frac{1}{2^{n}}}{1+\\frac{1}{2^{n}}}\\cdot\\frac{1}{e^{c^{2}/2}}\\\\\n& =\\frac{1}{2e^{c^{2}/2}}\n\\end{aligned}\\]\nIf this ratio is less than unity, that is \\(c&gt;\\sqrt{2\\log2}\\), than by the ratio test, \\(\\sum(2^{n}+1)e^{-c^{2}n/2}\\) converges to a finite value. Fix such a \\(c\\).\nBy BCL1(Borel-Cantelli Lemma), if \\(A_{n}:=\\left\\{ \\text{There exists atleast one }d\\in\\mathcal{D}_{n}\\text{ with }|Z_{d}|\\geq c\\sqrt{n}\\right\\}\\) and \\(\\sum_{n=0}^{\\infty}\\mathbb{P}(A_{n})\\) converges to a finite value, then the event \\(A_{n}\\) occurs finitely many times with probability \\(1\\). There exists \\(N\\in\\mathbf{N}\\), such that for all \\(n\\geq N\\), \\(A_{n}\\) fails to occur with probability \\(1\\). Thus, for all \\(n\\geq N\\), \\(\\{Z_{d}\\leq c\\sqrt{n}\\}\\) occurs with probability \\(1\\). It follows that:\n\\[\\begin{aligned}\n\\sup_{t\\in[0,1]}F_{n}(t) & \\leq\\frac{c\\sqrt{n}}{2^{(n+1)/2}}\n\\end{aligned}\\]\nDefine\n\\[\\begin{aligned}\nM_{n} & =\\frac{c\\sqrt{n}}{2^{(n+1)/2}}\n\\end{aligned}\\]\nSince \\(\\sum M_{n}\\) converges, by the Weierstrass \\(M\\)-test, the infinite series of functions \\(\\sum_{n=0}^{\\infty}F_{n}(t)\\) converges uniformly on \\([0,1].\\) Since, each \\(F_{n}(t)\\) is piecewise linear and continuous, by the Term-by-Term continuity theorem, \\(\\sum_{n=0}^{\\infty}F_{n}(t)\\) is continuous on \\([0,1]\\). ◻"
  },
  {
    "objectID": "posts/properties-of-brownian-motion/index.html#a-point-of-comparison-the-poisson-process.",
    "href": "posts/properties-of-brownian-motion/index.html#a-point-of-comparison-the-poisson-process.",
    "title": "Properties of Brownian Motion",
    "section": "",
    "text": "Like the Brownian motion, the Poisson process is defined as a process with stationary and independent increments.\n\n A process \\((N_{t},t\\geq0)\\) defined on \\((\\Omega,\\mathcal{F},\\mathbb{P})\\) has the distribution of the Poisson process with rate \\(\\lambda&gt;0\\), if and only if the following hold:\n(1) \\(N_{0}=0\\).\n(2) For any \\(s&lt;t\\), the increment \\(N_{t}-N_{s}\\) is a Poisson random variable with parameter \\(\\lambda(t-s).\\)\n(3) For any \\(n\\in\\mathbf{N}\\) and any choice \\(0&lt;t_{1}&lt;t_{2}&lt;\\ldots&lt;t_{n}&lt;\\infty\\), the increments \\(N_{t_{2}}-N_{t_{1}},N_{t_{3}}-N_{t_{2}},\\ldots,N_{t_{n}}-N_{t_{n-1}}\\) are independent.\n\nPoisson paths can be sampled using this definition. By construction, it is not hard to see that the paths of Poisson processes are piecewise, constant, integer-valued and non-decreasing. In particular, the paths of Poisson processes have finite variation. Poisson paths are much simpler than the ones of Brownian motion in many ways!\n\n(Simulating the Poisson Process.) Use the definition ([def:poisson-process]) to generate \\(10\\) paths of the Poisson process with rate \\(1\\) on the interval \\([0,10]\\) with step-size \\(0.01\\).\n\ndef generatePoissonProcess(lam,T,stepSize):\n    N = int(T/stepSize)\n    x = np.random.poisson(lam=lam,size=N)\n    y = np.cumsum(x)\n    y = np.concatenate([[0.0],y])\n    return y\nWe can construct a Poisson process as follows. Consider \\((\\tau_{j},j\\in\\mathbf{N})\\) IID exponential random variables with parameter \\(1/\\lambda\\). One should think of \\(\\tau_{j}\\) as the waiting time from the \\((j-1)\\)st to the \\(j\\)th jump. Then, one defines :\n\\[\\begin{aligned}\nN_{t} & =\\#\\{k:\\tau_{1}+\\tau_{2}+\\ldots+\\tau_{k}\\leq t\\}\\\\\n& =\\text{Number of jumps upto and including time }t\n\\end{aligned}\\]\nNow, here is an idea! What about defining a new process with stationary and independent increments using a given distribution other than Poisson and Gaussian? Is this even possible? The answer is yes, but only if the distribution satisfies the property of being infinitely divisible. To see this, consider the value of the process at time \\(1\\), \\(N_{1}\\). Then, no matter how many subintervals we chop the interval \\([0,1]\\) into, we must have the increments add up to \\(N_{1}\\). In other words, we must be able to write \\(N_{1}\\) as a sum of \\(n\\) IID random variables for every possible \\(n\\). This is certainly true for Poisson random variables and Gaussian random variables. Another example is the Cauchy distribution. In general, processes that can be constructed using independent, stationary increments are called Levy processes.\n\nTime Inversion. Let \\((B_{t},t\\geq0)\\) be a standard brownian motion. We consider the process:\n\\[\\begin{aligned}\nX_{t} & =tB_{1/t}\\quad\\text{for }t&gt;0\n\\end{aligned}\\]\nThis property relates the behavior of \\(t\\) large to the behavior of \\(t\\) small.\n\n(a) Show that \\((X_{t},t&gt;0)\\) has the distribution of Brownian motion on \\(t&gt;0\\).\nProof.\nLike \\(B(t)\\), it is an easy exercise to prove that \\(X(t)\\) is also a Gaussian process.\nWe have, \\(\\mathbb{E}[X_{s}]=0\\).\nLet \\(s&lt;t\\). We have:\n\\[\\begin{aligned}\nCov(X_{s},X_{t}) & =\\mathbb{E}[sB(1/s)\\cdot tB(1/t)]\\\\\n& =st\\mathbb{E}[B(1/s)\\cdot B(1/t)]\\\\\n& =st\\cdot\\frac{1}{t}\\\\\n& \\quad\\left\\{ \\because\\frac{1}{t}&lt;\\frac{1}{s}\\right\\} \\\\\n& =s\n\\end{aligned}\\]\nConsequently, \\(X(t)\\) has the distribution of a Brownian motion.\n(b) Argue that \\(X(t)\\) converges to \\(0\\) as \\(t\\to0\\) in the sense of \\(L^{2}\\)-convergence. It is possible to show convergence almost surely so that \\((X_{t},t\\geq0)\\) is really a Brownian motion for \\(t\\geq0\\).\nSolution.\nLet \\((t_{n})\\) be any arbitrary sequence of positive real numbers approaching \\(0\\) and consider the sequence of random variables \\((X(t_{n}))_{n=1}^{\\infty}\\). We have:\n\\[\\begin{aligned}\n\\mathbb{E}\\left[X(t_{n})^{2}\\right] & =\\mathbb{E}\\left[t_{n}^{2}B(1/t_{n})^{2}\\right]\\\\\n& =t_{n}^{2}\\mathbb{E}\\left[B(1/t_{n})^{2}\\right]\\\\\n& =t_{n}^{2}\\cdot\\frac{1}{t_{n}}\\\\\n& =t_{n}\n\\end{aligned}\\]\nHence,\n\\[\\begin{aligned}\n\\lim\\mathbb{E}\\left[X(t_{n})^{2}\\right] & =\\lim t_{n}=0\n\\end{aligned}\\]\nSince \\((t_{n})\\) was an arbitrary sequence, it follows that \\(\\lim_{t\\to0}\\mathbb{E}[(X(t))^{2}]=0\\).\n(c) Use this property of Brownian motion to show the law of large numbers for Brownian motion:\n\\[\\begin{aligned}\n\\lim_{t\\to\\infty}\\frac{X(t)}{t} & =0\\quad\\text{almost surely}\n\\end{aligned}\\]\nSolution.\nWhat we need to do is to show that \\(X(t)\\to0\\) as \\(t\\to0\\) almost surely. That would show that \\(\\frac{B(1/t)}{1/t}\\to0\\) as \\(t\\to0\\) almost surely, which is the same as showing \\(\\frac{B(t)}{t}\\to0\\) as \\(t\\to\\infty\\), which is the law of large numbers for Brownian motion.\nWhat we have done in part (b), is to prove the claim that \\(\\mathbb{E}[X(t)^{2}]\\to0\\) as \\(t\\to0\\), which shows convergence in the \\(L^{2}\\) sense and hence convergence in probability. This is infact the weak law of large numbers. \\(\\frac{B(t)}{t}\\stackrel{\\mathbb{\\mathbf{P}}}{\\to}0\\) as \\(t\\to\\infty\\).\nFor \\(t&gt;0\\), continuity is clear. However, it is the proof that as \\(t\\to0\\), \\(X(t)\\to0\\) almost surely which we have not done.\nNote that, the limit \\(X(t)\\to0\\) as \\(t\\to0\\) if and only if \\((\\forall n\\geq1)\\), \\((\\exists m\\geq1)\\), such that \\(\\forall r\\in\\mathbb{Q}\\cap(0,\\frac{1}{m}]\\), we have \\(|X(r)|=\\left|rB\\left(\\frac{1}{r}\\right)\\right|\\leq\\frac{1}{n}\\).\nTo understand the above, we just recall the \\(\\epsilon-\\delta\\) definition of continuity. Note that \\(\\frac{1}{n}\\) plays the role of \\(\\epsilon\\) and \\(\\frac{1}{m}\\) works as \\(\\delta\\).\nThat is,\n\\[\\begin{aligned}\n\\Omega^{X}:=\\left\\{ \\lim_{t\\to0}X(t)=0\\right\\}  & =\\bigcap_{n\\geq1}\\bigcup_{m\\geq1}\\bigcap_{r\\in\\mathbb{Q}\\cap(0,\\frac{1}{m}]}\\left\\{ \\left|X(r)\\right|\\leq\\frac{1}{n}\\right\\}\n\\end{aligned}\\]\nAlso, note that \\(X(t)\\) is continuous on all \\([a,1]\\) for all \\(a&gt;0\\), thus, uniformly continuous on \\([a,1]\\), and hence uniformly continuous on \\(\\mathbb{Q}\\cap(0,1]\\). So, there exists a continuous extension of \\(X(t)\\) on \\([0,1]\\). We already know from part (a), that \\((X(t))_{t&gt;0}\\) and \\((B(t))_{t&gt;0}\\) have the same finite dimensional distributions. Therefore, the RHS event has the same probability as \\(\\Omega^{B}:=\\bigcap_{n\\geq1}\\bigcup_{m\\geq1}\\bigcap_{r\\in\\mathbb{Q}\\cap(0,\\frac{1}{m}]}\\left\\{ \\left|B(r)\\right|\\leq\\frac{1}{n}\\right\\}\\). Since \\(B(t)\\to0\\) as \\(t\\to0\\) almost surely, the event \\(\\Omega^{B}\\) has probability \\(1\\). Thus, \\(\\mathbb{P}\\left\\{ \\lim_{t\\to0}X(t)=0\\right\\} =1\\).\nThis actually shows that \\(X(t)\\) is a bonafide standard brownian motion, as we have established continuity as well."
  },
  {
    "objectID": "posts/positive_definiteness/index.html",
    "href": "posts/positive_definiteness/index.html",
    "title": "Positive Definiteness",
    "section": "",
    "text": "Definition 1. A real-valued symmetric matrix \\(A\\) is positive-definite (written as \\(A \\succ 0\\)), if for every real valued vector \\(\\mathbf{x} \\in \\mathbf{R}^n \\setminus \\{\\mathbf{0}\\}\\), the quadratic form\n\\[\\begin{align*}\nq(\\mathbf{x}) = \\mathbf{x}^T A \\mathbf{x} &gt; 0\n\\end{align*}\\]\nThe real-value symmetric matrix \\(A\\) is positive semi-definite (written as \\(A \\succeq 0\\)) if :\n\\[\\begin{align*}\nq(\\mathbf{x}) = \\mathbf{x}^T A \\mathbf{x} \\geq 0\n\\end{align*}\\]\n\\(\\forall \\mathbf{x} \\in \\mathbf{R}^n \\setminus \\{\\mathbf{0}\\}\\).\nIntuitively, positive definite matrices are like strictly positive real numbers. Consider a scalar \\(a &gt; 0\\). The sign of \\(ax\\) will depend on the sign of \\(x\\). And \\(x\\cdot ax &gt; 0\\). However, if \\(a &lt; 0\\), multiplying it with \\(x\\) will flip the sign, so \\(x\\) and \\(ax\\) have opposite signs and \\(x \\cdot ax &lt; 0\\).\nIf \\(A \\succ 0\\), then by definition \\(\\mathbf{x}^T A \\mathbf{x} &gt; 0\\) for all \\(\\mathbf{x} \\in \\mathbf{R}^n\\). Thus, the vector \\(\\mathbf{x}\\) and it’s transformed self \\(A\\mathbf{x}\\) should make an angle \\(\\theta \\in \\left[-\\frac{\\pi}{2},\\frac{\\pi}{2}\\right]\\). Both \\(\\mathbf{x}\\) and \\(A\\mathbf{x}\\) lie on the same side of the hyperplane \\(\\mathbf{x}^{\\perp}\\).\n\n%load_ext itikz\n\n\n\nShow the code\n%%itikz --temp-dir --tex-packages=tikz --tikz-libraries=arrows --implicit-standalone\n\\begin{tikzpicture}[scale=1.5]\n\\draw [-&gt;] (-2,0) -- (6,0) node [below] {\\huge $x_1$};\n\\draw [-&gt;] (0,-2) -- (0,6) node [above] {\\huge $x_2$};\n\\draw [-&gt;] (0,0) -- (3,1) node [above] {\\huge $\\mathbf{x}$};\n\\draw [-&gt;] (0,0) -- (2,5) node [above] {\\huge $A\\mathbf{x}$};\n\\draw [dashed] (-2,6) -- (1,-3) node [] {\\huge $\\mathbf{x}^{\\perp}$};\n\\draw[draw=green!50!black,thick] (1,1/3) arc (18.43:68.19:1) node [midway,above] {\\huge $\\theta$};\n\\end{tikzpicture}"
  },
  {
    "objectID": "posts/positive_definiteness/index.html#positive-definite-matrices",
    "href": "posts/positive_definiteness/index.html#positive-definite-matrices",
    "title": "Positive Definiteness",
    "section": "",
    "text": "Definition 1. A real-valued symmetric matrix \\(A\\) is positive-definite (written as \\(A \\succ 0\\)), if for every real valued vector \\(\\mathbf{x} \\in \\mathbf{R}^n \\setminus \\{\\mathbf{0}\\}\\), the quadratic form\n\\[\\begin{align*}\nq(\\mathbf{x}) = \\mathbf{x}^T A \\mathbf{x} &gt; 0\n\\end{align*}\\]\nThe real-value symmetric matrix \\(A\\) is positive semi-definite (written as \\(A \\succeq 0\\)) if :\n\\[\\begin{align*}\nq(\\mathbf{x}) = \\mathbf{x}^T A \\mathbf{x} \\geq 0\n\\end{align*}\\]\n\\(\\forall \\mathbf{x} \\in \\mathbf{R}^n \\setminus \\{\\mathbf{0}\\}\\).\nIntuitively, positive definite matrices are like strictly positive real numbers. Consider a scalar \\(a &gt; 0\\). The sign of \\(ax\\) will depend on the sign of \\(x\\). And \\(x\\cdot ax &gt; 0\\). However, if \\(a &lt; 0\\), multiplying it with \\(x\\) will flip the sign, so \\(x\\) and \\(ax\\) have opposite signs and \\(x \\cdot ax &lt; 0\\).\nIf \\(A \\succ 0\\), then by definition \\(\\mathbf{x}^T A \\mathbf{x} &gt; 0\\) for all \\(\\mathbf{x} \\in \\mathbf{R}^n\\). Thus, the vector \\(\\mathbf{x}\\) and it’s transformed self \\(A\\mathbf{x}\\) should make an angle \\(\\theta \\in \\left[-\\frac{\\pi}{2},\\frac{\\pi}{2}\\right]\\). Both \\(\\mathbf{x}\\) and \\(A\\mathbf{x}\\) lie on the same side of the hyperplane \\(\\mathbf{x}^{\\perp}\\).\n\n%load_ext itikz\n\n\n\nShow the code\n%%itikz --temp-dir --tex-packages=tikz --tikz-libraries=arrows --implicit-standalone\n\\begin{tikzpicture}[scale=1.5]\n\\draw [-&gt;] (-2,0) -- (6,0) node [below] {\\huge $x_1$};\n\\draw [-&gt;] (0,-2) -- (0,6) node [above] {\\huge $x_2$};\n\\draw [-&gt;] (0,0) -- (3,1) node [above] {\\huge $\\mathbf{x}$};\n\\draw [-&gt;] (0,0) -- (2,5) node [above] {\\huge $A\\mathbf{x}$};\n\\draw [dashed] (-2,6) -- (1,-3) node [] {\\huge $\\mathbf{x}^{\\perp}$};\n\\draw[draw=green!50!black,thick] (1,1/3) arc (18.43:68.19:1) node [midway,above] {\\huge $\\theta$};\n\\end{tikzpicture}"
  },
  {
    "objectID": "posts/positive_definiteness/index.html#convex-functions",
    "href": "posts/positive_definiteness/index.html#convex-functions",
    "title": "Positive Definiteness",
    "section": "Convex functions",
    "text": "Convex functions\nThere is a second geometric way to think about positive definite matrices : a quadratic form is convex when the matrix is symmetric and positive definite.\nDefinition 2. (Convex function) A function \\(f:\\mathbf{R}^n \\to \\mathbf{R}\\) is convex, if for all \\(\\mathbf{x},\\mathbf{y}\\in \\mathbf{R}^n\\) and \\(0 \\leq \\lambda \\leq 1\\), we have:\n\\[\\begin{align*}\nf(\\lambda \\mathbf{x} + (1-\\lambda)\\mathbf{y}) \\leq \\lambda f(\\mathbf{x}) + (1-\\lambda) f(\\mathbf{y}) \\tag{1}\n\\end{align*}\\]\nProposition 3. Assume that the function \\(f:\\mathbf{R}^n \\to \\mathbf{R}\\) is differentiable. Then, \\(f\\) is convex, if and only if, for all \\(\\mathbf{x},\\mathbf{y} \\in \\mathbf{R}^n\\), the inequality\n\\[\\begin{align*}\nf(\\mathbf{y}) \\geq f(\\mathbf{x}) + \\nabla f(\\mathbf{y})^T (\\mathbf{y} - \\mathbf{x}) \\tag{2}\n\\end{align*}\\]\nis satisfied.\nProof.\n\\(\\Longrightarrow\\) direction.\nAssume that \\(f\\) is convex and let \\(\\mathbf{x} \\neq \\mathbf{y} \\in \\mathbf{R}^n\\). The convexity of \\(f\\) implies that:\n\\[\\begin{align*}\nf((\\mathbf{x} + \\mathbf{y})/2) \\leq \\frac{1}{2}f(\\mathbf{x}) + \\frac{1}{2}f(\\mathbf{y})\n\\end{align*}\\]\nDenote now \\(\\mathbf{h} = \\mathbf{y}-\\mathbf{x}\\). Then this inequality reads:\n\\[\\begin{align*}\nf(\\mathbf{x} + \\mathbf{h}/2) \\leq \\frac{1}{2} f(\\mathbf{x}) + \\frac{1}{2}f(\\mathbf{x} + \\mathbf{h})\n\\end{align*}\\]\nUsing elementary transformations, we have:\n\\[\\begin{align*}\n\\frac{f(\\mathbf{x} + \\mathbf{h}/2)}{1/2} &\\leq f(\\mathbf{x}) + f(\\mathbf{x} + \\mathbf{h}) \\\\\nf(\\mathbf{x} + \\mathbf{h}) - f(\\mathbf{x}) &\\geq \\frac{f(\\mathbf{x} + \\mathbf{h}/2) - f(\\mathbf{x})}{1/2}\n\\end{align*}\\]\nRepeating this line of argumentation:\n\\[\\begin{align*}\nf(\\mathbf{x} + \\mathbf{h}) - f(\\mathbf{x}) \\geq \\frac{f(\\mathbf{x} + \\mathbf{h}/2) - f(\\mathbf{x})}{1/2} \\geq \\frac{f(\\mathbf{x} + \\mathbf{h}/4) - f(\\mathbf{x})}{1/4}\n\\end{align*}\\]\nConsequently,\n\\[\\begin{align*}\nf(\\mathbf{x} + \\mathbf{h}) - f(\\mathbf{x}) \\geq \\frac{f(\\mathbf{x} + 2^{-k}\\mathbf{h}) - f(\\mathbf{x})}{2^{-k}} \\tag{2}\n\\end{align*}\\]\nBy the order limit theorem,\n\\[\\begin{align*}\nf(\\mathbf{x} + \\mathbf{h}) - f(\\mathbf{x}) \\geq \\lim_{k \\to \\infty}\\frac{f(\\mathbf{x} + 2^{-k}\\mathbf{h}) - f(\\mathbf{x})}{2^{-k}} = D_{\\mathbf{h}}f(\\mathbf{x}) = \\nabla f(\\mathbf{x}) \\cdot (\\mathbf{y} - \\mathbf{x})\n\\end{align*}\\]\nReplacing \\(\\mathbf{y}-\\mathbf{x}\\) by \\(\\mathbf{h}\\), we have:\n\\[\\begin{align*}\nf(\\mathbf{y}) \\geq f(\\mathbf{x}) + \\nabla f(\\mathbf{x})^T (\\mathbf{y} - \\mathbf{x})\n\\end{align*}\\]\n\\(\\Longleftarrow\\) direction.\nLet \\(\\mathbf{w}, \\mathbf{z} \\in \\mathbf{R}^n\\). Moreover, denote:\n\\[\\begin{align*}\n\\mathbf{x} := \\lambda \\mathbf{w} + (1-\\lambda)\\mathbf{z}\n\\end{align*}\\]\nThen, the inequality in (1) implies that:\n\\[\\begin{align*}\nf(\\mathbf{w}) &\\geq f(\\mathbf{x}) + \\nabla f(\\mathbf{x})^T (\\mathbf{w} - \\mathbf{x})\\\\\nf(\\mathbf{z}) &\\geq f(\\mathbf{x}) + \\nabla f(\\mathbf{x})^T (\\mathbf{z} - \\mathbf{x}) \\tag{3}\n\\end{align*}\\]\nNote moreover that:\n\\[\\begin{align*}\n\\mathbf{w} - \\mathbf{x} &= (1-\\lambda)(\\mathbf{w}-\\mathbf{z})\\\\\n\\mathbf{z} - \\mathbf{x} &= \\lambda(\\mathbf{z}-\\mathbf{w})\n\\end{align*}\\]\nThus, if we multiply the first line in (3) with \\(\\lambda\\) and the second line with \\((1-\\lambda)\\) and then add the two inequalities, we obtain:\n\\[\\begin{align*}\n\\lambda f(\\mathbf{w}) + (1-\\lambda)f(\\mathbf{z}) &\\geq f(\\mathbf{x}) + \\nabla f(\\mathbf{x})[\\lambda(1-\\lambda)(\\mathbf{w} - \\mathbf{z} + \\mathbf{z} - \\mathbf{w})\\\\\n&=f(\\lambda \\mathbf{w} + (1-\\lambda)\\mathbf{z})\n\\end{align*}\\]\nSince \\(\\mathbf{w}\\) and \\(\\mathbf{z}\\) were arbitrary, this proves the convexity of \\(f\\).\nThe convexity of a differentiable function can either be characterized by the fact that all secants lie above the graph or that all tangents lie below the graph.\nWe state the next corollary without proof.\nCorollary 4. Assume that \\(f:\\mathbf{R}^n \\to \\mathbf{R}\\) is convex and differentiable. Then \\(\\mathbf{x}^*\\) is a global minimizer of \\(f\\), if and only if \\(\\nabla f(\\mathbf{x}^{*}) = 0\\).\n\nHessians of convex functions.\nProposition 5. (Second derivative test) Let \\(f:X\\subseteq\\mathbf{R}^n \\to \\mathbf{R}\\) be a \\(C^2\\) function and suppose that \\(\\mathbf{a}\\in X\\) is a critical point of \\(f\\). If the hessian \\(\\nabla^2 f(\\mathbf{a})\\) is positive definite, then \\(f\\) has a local minimum at \\(\\mathbf{a}\\).\nProof.\nLet \\(q(\\mathbf{x}) = \\mathbf{x}^T A \\mathbf{x}\\) be a quadratic form. We have:\n\\[\\begin{align*}\nq(\\lambda \\mathbf{h}) &= (\\lambda \\mathbf{x}^T) A (\\lambda \\mathbf{x})\\\\\n&= \\lambda^2 \\mathbf{x}^T A \\mathbf{x}\\\\\n&= \\lambda^2 q(\\mathbf{x}) \\tag{4}\n\\end{align*}\\]\nWe show that if \\(A\\) is the symmetric matrix associated with a positive definite quadratic form \\(q(\\mathbf{x})\\), then there exists \\(M &gt; 0\\) such that:\n\\[\\begin{align*}\nq(\\mathbf{h}) \\geq M ||\\mathbf{h}||^2 \\tag{5}\n\\end{align*}\\]\nfor all \\(\\mathbf{h} \\in \\mathbf{R}^n\\).\nFirst note that when \\(\\mathbf{h} = \\mathbf{0}\\), then \\(q(\\mathbf{h})=q(\\mathbf{0})=0\\), so the conclusion holds trivially in this case.\nNext, suppose that when \\(\\mathbf{h}\\) is a unit vector, that is \\(||\\mathbf{h}||=1\\). The set of all unit vectors in \\(\\mathbf{R}^n\\) is an \\((n-1)\\)-dimensional hypersphere, which is a compact set. By the extreme-value theorem, the restriction of \\(q\\) to \\(S\\) must achieve a global minimum value \\(M\\) somewhere on \\(S\\). Thus, \\(q(\\mathbf{h}) \\geq M\\) for all \\(\\mathbf{h} \\in S\\).\nFinally, let \\(\\mathbf{h}\\) be any nonzero vector in \\(\\mathbf{R}^n\\). Then, its normalization \\(\\mathbf{h}/||\\mathbf{h}||\\) is a unit vector and also lies in \\(S\\). Therefore, by the result of step 1, we have:\n\\[\\begin{align*}\nq(\\mathbf{h}) &= q\\left(||\\mathbf{h}|| \\cdot \\frac{\\mathbf{h}}{||\\mathbf{h}||} \\right)\\\\\n&= ||\\mathbf{h}||^2 q\\left(\\frac{\\mathbf{h}}{||\\mathbf{h}||}\\right)\\\\\n&\\geq M ||\\mathbf{h}||^2\n\\end{align*}\\]\nWe can now prove the theorem.\nBy the second order Taylor’s formula, we have that, for the critical point \\(\\mathbf{a}\\) of \\(f\\),\n\\[\\begin{align*}\nf(\\mathbf{x}) = f(\\mathbf{a}) + \\nabla f(\\mathbf{x})\\cdot(\\mathbf{x} - \\mathbf{a}) + \\frac{1}{2}(\\mathbf{x} - \\mathbf{a})^T \\nabla^2 f(\\mathbf{a}) (\\mathbf{x} - \\mathbf{a}) + R_2(\\mathbf{x},\\mathbf{a}) \\tag{6}\n\\end{align*}\\]\nwhere \\(R_2(\\mathbf{x},\\mathbf{a})/||\\mathbf{x}-\\mathbf{a}||^2 \\to 0\\) as \\(\\mathbf{x} \\to \\mathbf{a}\\).\nIf \\(\\nabla^2 f(\\mathbf{a}) \\succ 0\\), then\n\\[\\begin{align*}\n\\frac{1}{2}(\\mathbf{x} - \\mathbf{a})^T \\nabla^2 f(\\mathbf{a}) (\\mathbf{x} - \\mathbf{a}) \\geq M||\\mathbf{x} - \\mathbf{a}||^2 \\tag{7}\n\\end{align*}\\]\nPick \\(\\epsilon = M\\). By the definition of limits, since \\(R_2(\\mathbf{x},\\mathbf{a})/||\\mathbf{x} - \\mathbf{a}||^2 \\to 0\\) as \\(\\mathbf{x} \\to \\mathbf{a}\\), there exists \\(\\delta &gt; 0\\), such that for all \\(||\\mathbf{x} - \\mathbf{a}||&lt;\\delta\\), \\(|R_2(\\mathbf{x},\\mathbf{a})|/||\\mathbf{x} - \\mathbf{a}||^2 &lt; M\\). Or equivalently,\n\\[\\begin{align*}\n|R_2(\\mathbf{x},\\mathbf{a})| &lt; M||\\mathbf{x}-\\mathbf{a}||^2\n\\end{align*}\\]\nthat is:\n\\[\\begin{align*}\n-M||\\mathbf{x}-\\mathbf{a}||^2 &lt; R_2(\\mathbf{x},\\mathbf{a}) &lt; M||\\mathbf{x}-\\mathbf{a}||^2 \\tag{8}\n\\end{align*}\\]\nPutting together (6), (7) and (8),\n\\[\\begin{align*}\nf(\\mathbf{x}) - f(\\mathbf{a}) &gt; 0\n\\end{align*}\\]\nso that \\(f\\) has a minimum at \\(\\mathbf{a}\\).\nProposition 6. A twice differentiable function \\(f:\\mathbf{R}^n \\to \\mathbf{R}\\) is convex, if and only if, the hessian \\(\\nabla^2 f(\\mathbf{x})\\) is positive semi-definite for all \\(\\mathbf{x}\\in\\mathbf{R}^n\\).\nProof.\nAssume first that \\(f\\) is convex and let \\(\\mathbf{x}\\in\\mathbf{R}^n\\). Define the \\(g:\\mathbf{R}^n \\to \\mathbf{R}\\) as a function of the vector \\(\\mathbf{y}\\) setting:\n\\[\\begin{align*}\ng(\\mathbf{y}) := f(\\mathbf{y}) - \\nabla f(\\mathbf{x})^T (\\mathbf{y} - \\mathbf{x})\n\\end{align*}\\]\nConsider the mapping \\(T(\\mathbf{y}) = -\\nabla f(\\mathbf{x})^T (\\mathbf{y} - \\mathbf{x})\\). We have:\n\\[\\begin{align*}\nT(\\lambda \\mathbf{y}_1 + (1-\\lambda)\\mathbf{y}_2) &= -\\nabla f(\\mathbf{x})^T (\\lambda \\mathbf{y}_1 + (1-\\lambda)\\mathbf{y}_2 - \\mathbf{x}) \\\\\n&= \\lambda [-\\nabla f(\\mathbf{x})^T (\\mathbf{y}_1 - \\mathbf{x})] + (1-\\lambda)[-\\nabla f(\\mathbf{x})^T (\\mathbf{y}_2 - \\mathbf{x})]\\\\\n&=\\lambda T(\\mathbf{y}_1) + (1-\\lambda)T(\\mathbf{y}_2)\n\\end{align*}\\]\nThus, \\(T\\) is an affine transformation.\nSince an affine transformation is convex and \\(f\\) is convex, their sum \\(g\\) is also convex. Moreover \\(g\\) is a function of \\(\\mathbf{y}\\), treating \\(\\mathbf{x}\\) as a constant, we have:\n\\[\\begin{align*}\n\\nabla g(\\mathbf{y}) = \\nabla f(\\mathbf{y}) - \\nabla f(\\mathbf{x})\n\\end{align*}\\]\nand\n\\[\\begin{align*}\n\\nabla^2 g(\\mathbf{y}) = \\nabla^2 f(\\mathbf{y})\n\\end{align*}\\]\nfor all \\(\\mathbf{y} \\in \\mathbf{R}^n\\). In particular, \\(\\nabla g(\\mathbf{x}) = 0\\). Thus, corollary (4) implies that \\(\\mathbf{x}\\) is a global minimizer of \\(g\\). Now, the second order necessary condition for a minimizer implies that \\(\\nabla^2 g(\\mathbf{x})\\) is positive semi-definite. Since \\(\\nabla^2 g(\\mathbf{x}) = \\nabla^2 f(\\mathbf{x})\\), this proves that the Hessian of \\(f\\) is positive semi-definite for all \\(\\mathbf{x} \\in \\mathbf{R}^n\\).\nThus, a function \\(f\\) is convex, if its Hessian is everywhere positive semi-definite. This allows us to test whether a given function is convex."
  },
  {
    "objectID": "posts/positive_definiteness/index.html#tests-for-positive-definiteness",
    "href": "posts/positive_definiteness/index.html#tests-for-positive-definiteness",
    "title": "Positive Definiteness",
    "section": "Tests for positive definiteness",
    "text": "Tests for positive definiteness\nOne of the most important theorems of finite dimensional vector spaces is the spectral theorem. Every real symmetric matrix \\(A\\) is orthogonally diagonalizable. It admits \\(A = Q\\Lambda Q^T\\) factorization, where \\(Q\\) is an orthogonal matrix and \\(\\Lambda = diag(\\lambda_1,\\ldots,\\lambda_n)\\).\nFrom basic algebra, we know that, if \\(A\\) is a non-singular matrix, with all it’s pivot elements \\(a_{kk}^{(k)}\\) non-zero in the Gaussian elimination process, then \\(A=LDU\\) where \\(L\\) and \\(U\\) are lower and upper unitriangular matrices and \\(D\\) is a diagonal matrix consisting of the pivots of \\(A\\). If \\(A\\) is symmetric, then it admits the unique factorization \\(A = LDL^T\\).\nConsider the quadratic form \\(q(\\mathbf{x}) = \\mathbf{x}^T A \\mathbf{x}\\). Substituting \\(A = Q \\Lambda Q^T\\), we have:\n\\[\\begin{align*}\nq(\\mathbf{x}) &= \\mathbf{x}^T A \\mathbf{x} \\\\\n&= \\mathbf{x}^T Q \\Lambda Q^T \\mathbf{x} \\\\\n&= (Q^T \\mathbf{x})^T \\Lambda (Q^T \\mathbf{x}) \\tag{9}\n\\end{align*}\\]\nBut, the matrix \\(Q = [\\mathbf{q}_1,\\mathbf{q}_2,\\ldots,\\mathbf{q}_n]\\). Moreover, \\(A=Q\\Lambda Q^T\\) implies that \\(AQ^{-1} = AQ^T = \\Lambda Q^T\\). Therefore:\n\\[\\begin{align*}\nA\\begin{bmatrix}\n\\mathbf{q}_1\\\\\n\\mathbf{q}_2\\\\\n\\vdots\\\\\n\\mathbf{q}_n\n\\end{bmatrix}=\\begin{bmatrix}\n\\lambda_1 \\\\\n& \\lambda_2 \\\\\n& & \\ddots \\\\\n& & & \\lambda_n\n\\end{bmatrix}\\begin{bmatrix}\n\\mathbf{q}_1\\\\\n\\mathbf{q}_2\\\\\n\\vdots\\\\\n\\mathbf{q}_n\n\\end{bmatrix}\n\\end{align*}\\]\nSo, \\(\\mathbf{q}_1,\\ldots,\\mathbf{q}_n\\) are the eigenvectors of \\(A\\). Now,\n\\[\\begin{align*}\n\\mathbf{q}_1 &= [q_{11}, q_{21}, \\ldots,q_{n1}]^T = q_{11} \\mathbf{e}_1 + q_{21} \\mathbf{e}_2 + \\ldots + q_{n1} \\mathbf{e}_n\\\\\n\\mathbf{q}_2 &= [q_{12}, q_{22}, \\ldots,q_{n2}]^T = q_{12} \\mathbf{e}_1 + q_{22} \\mathbf{e}_2 + \\ldots + q_{n2} \\mathbf{e}_n\\\\\n\\vdots \\\\\n\\mathbf{q}_n &= [q_{1n}, q_{2n}, \\ldots,q_{nn}]^T = q_{1n} \\mathbf{e}_1 + q_{2n} \\mathbf{e}_2 + \\ldots + q_{nn} \\mathbf{e}_n\n\\end{align*}\\]\nSo,\n\\[\\begin{align*}\nQ = \\begin{bmatrix}\nq_{11} & \\ldots & q_{1n}\\\\\n\\vdots & & \\vdots \\\\\nq_{n1} & \\ldots & q_{nn}\n\\end{bmatrix}\n\\end{align*}\\]\nis the change of basis matrix from the standard basis \\(\\mathcal{B}_{old}=\\{\\mathbf{e}_1,\\ldots,\\mathbf{e}_n\\}\\) to the eigenvector basis \\(\\mathcal{B}_{new}=\\{\\mathbf{q}_1,\\ldots,\\mathbf{q}_n\\}\\).\nIf \\(\\mathbf{x}\\) are the coordinates of a vector in the standard basis and \\(\\mathbf{y}\\) are its coordinates in the eigenvector basis, then \\(\\mathbf{x}=Q\\mathbf{y}\\).\nHence, substituting \\(\\mathbf{y}=Q^{-1}\\mathbf{x}=Q^T \\mathbf{x}\\) in equation (9), the quadratic form becomes:\n\\[\\begin{align*}\nq(\\mathbf{x}) &= \\mathbf{x}^T A \\mathbf{x} = \\mathbf{y}^T \\Lambda \\mathbf{y}\\\\\n&=\\lambda_1 y_1^2 + \\lambda_2 y_2^2 + \\ldots + \\lambda_n y_n^2\n\\end{align*}\\]\nwhere we have changed the axes to be aligned across the eigenvectors of \\(A\\).\nThe coefficients \\(\\lambda_i\\) are the diagonal entries of \\(\\Lambda\\) and are the pivots of \\(A\\). The quadratic form is strictly positive for all \\(\\mathbf{y}\\), if and only if the eigenvalues \\(\\lambda_1 &gt; 0\\), \\(\\lambda_2 &gt;0\\), \\(\\ldots\\), \\(\\lambda_n &gt; 0\\).\nTheorem 7. (Positive definiteness) Let \\(A \\in \\mathbf{R}^{n \\times n}\\) be a real symmetric positive definite(SPD) matrix. Then, the following statements are equivalent:\n\n\\(A\\) is non-singular and has positive pivot elements when performing Gaussian elimination (without row exchanges).\n\\(A\\) admits a factorization \\(A = Q \\Lambda Q^T\\), where \\(\\Lambda = diag(\\lambda_1,\\ldots,\\lambda_n)\\) such that \\(\\lambda_i &gt; 0\\) for all \\(i=1,2,3,\\ldots,n\\)."
  },
  {
    "objectID": "posts/positive_definiteness/index.html#cholesky-factorization",
    "href": "posts/positive_definiteness/index.html#cholesky-factorization",
    "title": "Positive Definiteness",
    "section": "Cholesky Factorization",
    "text": "Cholesky Factorization\nWe can push the result above slightly further in the positive definite case. Since, each eigen value \\(\\lambda_i\\) is positive, the quadratic form can be written as a sum of squares:\n\\[\\begin{align*}\n\\lambda_1 y_1^2 + \\lambda_2 y_2^2 + \\ldots + \\lambda_n y_n^2 &= (\\sqrt{\\lambda_1} y_1)^2 + \\ldots + (\\sqrt{\\lambda_n} y_n)^2\\\\\n&= z_1^2 + z^2 + \\ldots + z_n^2\n\\end{align*}\\]\nwhere \\(z_i =\\sqrt{\\lambda_i}y_i\\). In the matrix form, we are writing:\n\\[\\begin{align*}\n\\hat{q}(\\mathbf{y}) &= \\mathbf{y}^T \\Lambda \\mathbf{y}\\\\\n&= \\mathbf{z}^T \\mathbf{z}\\\\\n&= ||\\mathbf{z}||^2\n\\end{align*}\\]\nwhere \\(\\mathbf{z} = S\\mathbf{y}\\) with \\(S=diag(\\sqrt{\\lambda_1},\\ldots,\\sqrt{\\lambda_n})\\). Since \\(\\Lambda = S^2=SS^T\\), \\(S\\) can be thought as the square root of the original matrix \\(\\Lambda\\). Substituting back into the equation \\(A=Q\\Lambda Q^T\\), we deduce the Cholesky factorization:\n\\[\\begin{align*}\nA &= Q\\Lambda Q^T\\\\\n&= QS S^T Q^T\\\\\n&= MM^T\n\\end{align*}\\]"
  },
  {
    "objectID": "posts/positive_definiteness/index.html#level-plots-of-a-positive-definite-quadratic-form-are-ellipsoids",
    "href": "posts/positive_definiteness/index.html#level-plots-of-a-positive-definite-quadratic-form-are-ellipsoids",
    "title": "Positive Definiteness",
    "section": "Level plots of a positive definite quadratic form are ellipsoids",
    "text": "Level plots of a positive definite quadratic form are ellipsoids\nConsider the level plot of a positive definite quadratic form \\(q(\\mathbf{x})\\):\n\\[\\begin{align*}\nq(\\mathbf{x}) = \\hat{q}(\\mathbf{y}) &= 1 \\\\\n\\lambda_1 y_1^2 + \\ldots + \\lambda_n y_n^2 &= 1\\\\\n\\frac{y_1^2}{\\left(\\frac{1}{\\sqrt{\\lambda_1}}\\right)^2}+\\frac{y_2^2}{\\left(\\frac{1}{\\sqrt{\\lambda_2}}\\right)^2} + \\ldots + \\frac{y_n^2}{\\left(\\frac{1}{\\sqrt{\\lambda_n}}\\right)^2} &= 1\n\\end{align*}\\]\nThus, the level plot of a positive definite quadratic form is an ellipse (if \\(n=2\\)) or an ellipsoid (if \\(n &gt; 2\\)) with axes aligned along the eigenvectors and lengths \\(\\frac{1}{\\sqrt{\\lambda_i}}\\), \\(i=1,2,3,\\ldots,n\\).\n\nimport numpy as np\nimport matplotlib.pyplot as plt\n\nA = np.array([[4, 3], [3, 4]])\n\neigenvalues, eigenvectors = np.linalg.eig(A)\n\n# The parameteric equation of an ellipse is\n# (x(theta),y(theta))=(a cos theta, b sin theta)\n# where a and b are semi-major and semi-minor axes\ntheta = np.linspace(0, 2 * np.pi, 10000)\ny1 = np.sqrt(1 / eigenvalues[0]) * np.cos(theta)\ny2 = np.sqrt(1 / eigenvalues[1]) * np.sin(theta)\n\nY = np.array([y1,y2])\n\n# The change of basis matrix from the standard basis to the eigen vector basis\n# is Q. So, x = Q y, where Q = [q_1,q_2]; q_1, q_2 are the eigenvectors of A.\n\nQ = eigenvectors.T\nX = np.dot(Q, Y)\nx1 = X[0,:]\nx2 = X[1,:]\n\nplt.xlim([-1, 1])\nplt.grid(True)\nplt.title(r'$q(\\mathbf{x})=\\mathbf{x}^T A \\mathbf{x} = 1$')\nplt.xlabel(r'$x_1$')\nplt.ylabel(r'$x_2$')\nplt.plot(x1, x2)\nplt.show()"
  },
  {
    "objectID": "posts/numpy-and-pandas-cheatsheet/index.html",
    "href": "posts/numpy-and-pandas-cheatsheet/index.html",
    "title": "numpy and pandas CheatSheet",
    "section": "",
    "text": "np.arange(start, stop, step) returns evenly spaced values in a given interval.\n\nimport numpy as np\n\nnp.arange(0.0, 1.1, 0.1)\n\narray([0. , 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1. ])"
  },
  {
    "objectID": "posts/numpy-and-pandas-cheatsheet/index.html#np.arangestartstopstep",
    "href": "posts/numpy-and-pandas-cheatsheet/index.html#np.arangestartstopstep",
    "title": "numpy and pandas CheatSheet",
    "section": "",
    "text": "np.arange(start, stop, step) returns evenly spaced values in a given interval.\n\nimport numpy as np\n\nnp.arange(0.0, 1.1, 0.1)\n\narray([0. , 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1. ])"
  },
  {
    "objectID": "posts/numpy-and-pandas-cheatsheet/index.html#np.zerosshape",
    "href": "posts/numpy-and-pandas-cheatsheet/index.html#np.zerosshape",
    "title": "numpy and pandas CheatSheet",
    "section": "np.zeros(shape)",
    "text": "np.zeros(shape)\n\nnp.zeros(shape=(3,3))\n\narray([[0., 0., 0.],\n       [0., 0., 0.],\n       [0., 0., 0.]])"
  },
  {
    "objectID": "posts/numpy-and-pandas-cheatsheet/index.html#np.zeros_like",
    "href": "posts/numpy-and-pandas-cheatsheet/index.html#np.zeros_like",
    "title": "numpy and pandas CheatSheet",
    "section": "np.zeros_like",
    "text": "np.zeros_like\n\nx = np.array([\n    [1, 2, 3, 4],\n    [5, 6, 7, 8],\n    [9,10,11,12]\n])\n\nnp.zeros_like(x)\n\narray([[0, 0, 0, 0],\n       [0, 0, 0, 0],\n       [0, 0, 0, 0]])"
  },
  {
    "objectID": "posts/numpy-and-pandas-cheatsheet/index.html#np.onesshape",
    "href": "posts/numpy-and-pandas-cheatsheet/index.html#np.onesshape",
    "title": "numpy and pandas CheatSheet",
    "section": "np.ones(shape)",
    "text": "np.ones(shape)\n\nimport numpy as np\n\n# The matrix of all ones of size 3 x 3\nnp.ones(shape=(3,3))\n\narray([[1., 1., 1.],\n       [1., 1., 1.],\n       [1., 1., 1.]])"
  },
  {
    "objectID": "posts/numpy-and-pandas-cheatsheet/index.html#np.eyen_rowsm_cols",
    "href": "posts/numpy-and-pandas-cheatsheet/index.html#np.eyen_rowsm_cols",
    "title": "numpy and pandas CheatSheet",
    "section": "np.eye(N_rows,M_cols)",
    "text": "np.eye(N_rows,M_cols)\n\nimport numpy as np\n\n# Identity matrix of size 3 x 3\nnp.eye(3,3)\n\narray([[1., 0., 0.],\n       [0., 1., 0.],\n       [0., 0., 1.]])"
  },
  {
    "objectID": "posts/numpy-and-pandas-cheatsheet/index.html#np.anyarray_like-axis-keepdims",
    "href": "posts/numpy-and-pandas-cheatsheet/index.html#np.anyarray_like-axis-keepdims",
    "title": "numpy and pandas CheatSheet",
    "section": "np.any(array_like, axis, keepdims)",
    "text": "np.any(array_like, axis, keepdims)\nTests whether any array element along a given axis evaluates to True.\n\nimport numpy as np\n\nnp.any([[True, False], [True, True]])\n\nnp.True_\n\n\n\nnp.any([[True, False], [True, True]], axis=0)\n\narray([ True,  True])\n\n\n\nnp.any([[True, False], [True, False]], axis=0)\n\narray([ True, False])\n\n\n\nnp.any([[True, False], [True, False]], axis=1)\n\narray([ True,  True])\n\n\n\nnp.any([[True, False], [True, False]], axis=1, keepdims=True)\n\narray([[ True],\n       [ True]])"
  },
  {
    "objectID": "posts/numpy-and-pandas-cheatsheet/index.html#np.allarray_like-axis-keepdims",
    "href": "posts/numpy-and-pandas-cheatsheet/index.html#np.allarray_like-axis-keepdims",
    "title": "numpy and pandas CheatSheet",
    "section": "np.all(array_like, axis, keepdims)",
    "text": "np.all(array_like, axis, keepdims)\n\nimport numpy as np\n\nnp.all([[True, False], [True, True]])\n\nnp.False_\n\n\n\nnp.all([[True, False], [True, True]], axis=0)\n\narray([ True, False])\n\n\n\nnp.all([[True, False], [True, False]], axis=1)\n\narray([False, False])"
  },
  {
    "objectID": "posts/numpy-and-pandas-cheatsheet/index.html#np.tilearray-reps",
    "href": "posts/numpy-and-pandas-cheatsheet/index.html#np.tilearray-reps",
    "title": "numpy and pandas CheatSheet",
    "section": "np.tile(array, reps)",
    "text": "np.tile(array, reps)\nConstructs an array by repeating the array reps number of times.\n\nimport numpy as np\n\na = np.array([0, 1, 2])\nnp.tile(a, 2)\n\narray([0, 1, 2, 0, 1, 2])\n\n\n\nimport numpy as np\n\na = np.array([0, 1, 2])\nnp.tile(a, (2, 2))\n\narray([[0, 1, 2, 0, 1, 2],\n       [0, 1, 2, 0, 1, 2]])"
  },
  {
    "objectID": "posts/numpy-and-pandas-cheatsheet/index.html#np.repeatarray-repeats-axis",
    "href": "posts/numpy-and-pandas-cheatsheet/index.html#np.repeatarray-repeats-axis",
    "title": "numpy and pandas CheatSheet",
    "section": "np.repeat(array, repeats, axis)",
    "text": "np.repeat(array, repeats, axis)\nRepeats each element of an array after themselves.\n\nnp.repeat(3,4)\n\narray([3, 3, 3, 3])\n\n\n\nx = np.array([\n    [1, 2],\n    [3, 4],\n    [5, 6]\n])\n\nnp.repeat(x, repeats=2,axis=0)\n\narray([[1, 2],\n       [1, 2],\n       [3, 4],\n       [3, 4],\n       [5, 6],\n       [5, 6]])\n\n\n\nnp.repeat(x, repeats = 2, axis=1)\n\narray([[1, 1, 2, 2],\n       [3, 3, 4, 4],\n       [5, 5, 6, 6]])"
  },
  {
    "objectID": "posts/numpy-and-pandas-cheatsheet/index.html#broadcasting",
    "href": "posts/numpy-and-pandas-cheatsheet/index.html#broadcasting",
    "title": "numpy and pandas CheatSheet",
    "section": "Broadcasting",
    "text": "Broadcasting\nThe term broadcasting describes how NumPy treats arrays with different shapes during arithmetic operations. Subject to certain constraints, the smaller array is broadcast across the larger array, so that they have compatible shapes. Broadcasting provides a means of vectorizing array operations so that looping occurs in C, instead of Python.\nFor example, let \\(\\mathbf{x}=[x_0, x_1, \\ldots, x_{n-1}]\\) be a column vector and let \\(k\\) be a scalar.\nThe scalar multiplication \\(\\mathbf{y} = k \\mathbf{x}\\) multiplies each element \\(x_0, x_1, x_2, \\ldots, x_{n-1}\\) by \\(k\\).\nWe can think of the scalar \\(k\\) as being stretched during the arithmetic operation into a vector with the same length as \\(\\mathbf{x}\\). The stretching analogy is only conceptual. NumPy is smart enough to use the original scalar value without actually making copies."
  },
  {
    "objectID": "posts/numpy-and-pandas-cheatsheet/index.html#np.wherecondition-x-y",
    "href": "posts/numpy-and-pandas-cheatsheet/index.html#np.wherecondition-x-y",
    "title": "numpy and pandas CheatSheet",
    "section": "np.where(condition, x, y)",
    "text": "np.where(condition, x, y)\nFor each element \\(x\\) in the array, if the array-element satisfies the condition, then x values are returned, else y values are returned.\n\nimport numpy as np\n\nx = np.arange(10)\nx &gt; 5   # this returns a filter mask - an array of booleans\n\narray([False, False, False, False, False, False,  True,  True,  True,\n        True])\n\n\n\nx[x &gt; 5]\n\narray([6, 7, 8, 9])\n\n\n\nnp.where(x &gt; 5, x**2, x)\n\narray([ 0,  1,  2,  3,  4,  5, 36, 49, 64, 81])"
  },
  {
    "objectID": "posts/numpy-and-pandas-cheatsheet/index.html#pandas.dataframedatacolumns",
    "href": "posts/numpy-and-pandas-cheatsheet/index.html#pandas.dataframedatacolumns",
    "title": "numpy and pandas CheatSheet",
    "section": "pandas.DataFrame(data,columns)",
    "text": "pandas.DataFrame(data,columns)\nA pandas.DataFrame represents a two dimensional, size-mutable, potentially heterogenous collection of data.\ndata can be any iterable, dict or another dataframe.\n\nimport pandas as pd\nfrom datetime import date\ndata = {\n    'Date' : [ date(2025,1,31), date(2025,2,1)],\n    'Close price' : [ 101.25, 103.00 ]\n}\n\ndf = pd.DataFrame(data)\ndf\n\n\n\n\n\n\n\n\nDate\nClose price\n\n\n\n\n0\n2025-01-31\n101.25\n\n\n1\n2025-02-01\n103.00"
  },
  {
    "objectID": "posts/numpy-and-pandas-cheatsheet/index.html#indexing-a-dataframe",
    "href": "posts/numpy-and-pandas-cheatsheet/index.html#indexing-a-dataframe",
    "title": "numpy and pandas CheatSheet",
    "section": "Indexing a DataFrame",
    "text": "Indexing a DataFrame\n\n# Access a single value for a row/column label pair\ndf.at[1, 'Close price']\n\nnp.float64(103.0)\n\n\n\ndf.at[1, 'Close price'] = 102.50\n\n\n# Accessing a group of rows and columns by label(s) or boolean array\ndf.loc[0]\n\nDate           2025-01-31\nClose price        101.25\nName: 0, dtype: object\n\n\n\ndf = pd.DataFrame({\n    'A' : [1, 2, 3, 4, 5, 6],\n    'B' : [7, 8, 9, 10, 11, 12],\n    'C' : [13, 14, 15, 16, 17, 18]\n})\ndf\n\n\n\n\n\n\n\n\nA\nB\nC\n\n\n\n\n0\n1\n7\n13\n\n\n1\n2\n8\n14\n\n\n2\n3\n9\n15\n\n\n3\n4\n10\n16\n\n\n4\n5\n11\n17\n\n\n5\n6\n12\n18\n\n\n\n\n\n\n\n\n# Accessing a group of rows and columns by label(s) or boolean array\ndf.loc[0]\n\nA     1\nB     7\nC    13\nName: 0, dtype: int64\n\n\n\n# Integer location based indexing\ndf.iloc[1:3,1]\n\n1    8\n2    9\nName: B, dtype: int64"
  },
  {
    "objectID": "posts/numpy-and-pandas-cheatsheet/index.html#filtering-data",
    "href": "posts/numpy-and-pandas-cheatsheet/index.html#filtering-data",
    "title": "numpy and pandas CheatSheet",
    "section": "Filtering data",
    "text": "Filtering data\n\n# This produces a filter mask\ndf['B'] &gt;= 10\n\n0    False\n1    False\n2    False\n3     True\n4     True\n5     True\nName: B, dtype: bool\n\n\n\ndf[df['B'] &gt;= 10]\n\n\n\n\n\n\n\n\nA\nB\nC\n\n\n\n\n3\n4\n10\n16\n\n\n4\n5\n11\n17\n\n\n5\n6\n12\n18"
  },
  {
    "objectID": "posts/numpy-and-pandas-cheatsheet/index.html#data-transformation",
    "href": "posts/numpy-and-pandas-cheatsheet/index.html#data-transformation",
    "title": "numpy and pandas CheatSheet",
    "section": "Data transformation",
    "text": "Data transformation\n\ndf['B'] = df.apply(lambda row: row['B'] ** 2 , axis=1)\ndf\n\n\n\n\n\n\n\n\nA\nB\nC\n\n\n\n\n0\n1\n49\n13\n\n\n1\n2\n64\n14\n\n\n2\n3\n81\n15\n\n\n3\n4\n100\n16\n\n\n4\n5\n121\n17\n\n\n5\n6\n144\n18"
  },
  {
    "objectID": "posts/norms/index.html",
    "href": "posts/norms/index.html",
    "title": "Norms",
    "section": "",
    "text": "Consider geometric vectors \\(\\mathbf{x}, \\mathbf{y} \\in \\mathbf{R}^2\\). The scalar product(dot-product) of these two vectors is defined by:\n\\[\n\\mathbf{x} \\cdot \\mathbf{y} = x_1 y_1 + x_2 y_2\n\\]\nAn inner-product is a mathematical generalization of the dot-product.\n\n\\[\n\\newcommand{\\norm}[1]{\\left\\lVert#1\\right\\rVert}\n\\newcommand{\\normp}[2]{\\left\\lVert\\mathbf{#1}\\right\\rVert_{#2}}\n\\newcommand\\inner[2]{\\left\\langle #1, #2 \\right\\rangle}\n\\newcommand{\\bf}[1]{\\mathbf{#1}}\n\\newcommand{\\R}{\\mathbf{R}}\n\\newcommand{\\RR}[1]{\\mathbf{R}^2}\n\\newcommand{\\RRR}[1]{\\mathbf{R}^3}\n\\newcommand{\\C}{\\mathbf{C}}\n\\newcommand{\\CC}[1]{\\mathbf{C}^2}\n\\newcommand{\\CCC}[1]{\\mathbf{C}^3}\n\\]\n\n\nDefinition 1 (Inner product) Let \\(V\\) be a vector space and \\(F\\) be a scalar field, which is either \\(\\bf{R}\\) or \\(\\bf{C}\\). Let \\(\\inner{\\cdot}{\\cdot}\\) be a map from \\(V\\times V \\to F\\). Then, \\(\\inner{\\cdot}{\\cdot}\\) is an inner product if for all \\(\\bf{u},\\bf{v}, \\bf{w} \\in V\\), it satisfies:\n\n\n\\[\n\\inner{\\bf{v}}{\\bf{v}} \\geq 0 \\quad \\text { and } \\quad  \\inner{\\bf{v}}{\\bf{v}} = 0 \\Longleftrightarrow \\bf{v} = \\bf{0}\n\\]\n\n\n\n\\[\n\\inner{\\bf{u} + \\bf{v}}{\\bf{w}} = \\inner{\\bf{u}}{\\bf{w}} + \\inner{\\bf{v}}{\\bf{w}}\n\\]\n\n\n\n\\[\n\\begin{align*}\n\\inner{\\alpha \\bf{v}}{\\bf{w}} &= \\overline{\\alpha} \\inner{\\bf{v}}{\\bf{w}}\\\\\n\\inner{\\bf{v}}{\\alpha \\bf{w}} &= \\alpha \\inner{\\bf{v}}{\\bf{w}}\n\\end{align*}\n\\]\n\n\n\n\\[\n\\inner{\\bf{v}}{\\bf{w}} = \\overline{\\inner{\\bf{w}}{\\bf{v}}}\n\\]\n\n\nThe most important example of inner-product is the Euclidean inner product on \\(\\C^n\\). Let \\(\\bf{w},\\bf{z}\\) be (column) vectors in \\(\\C^n\\).\n\\[\n\\inner{\\bf{w}}{\\bf{z}} = (\\bf{w}^H \\bf{z}) =  \\overline{w_1}z_1 + \\overline{w_2}z_2 + \\ldots + \\overline{w_n} z_n\n\\]\nFirstly,\n\\[\n\\begin{align*}\n\\inner{\\bf{v} + \\bf{w}}{\\bf{z}} &= (\\bf{v} + \\bf{w})^H \\bf{z} & \\{ \\text{ Definition }\\}\\\\\n&= (\\bf{v}^H + \\bf{w}^H)\\bf{z} & \\{ \\overline{z_1 + z_2} = \\overline{z_1} + \\overline{z_2}; z_1,z_2\\in \\C \\}\\\\\n&= \\bf{v}^H \\bf{z} + \\bf{w}^H \\bf{z}\\\\\n&= \\inner{\\bf{v}}{\\bf{z}} + \\inner{\\bf{w}}{\\bf{z}}\n\\end{align*}\n\\]\nSo, it is additive in the first slot.\nNext, let \\(\\alpha \\in \\C\\).\n\\[\n\\begin{align*}\n\\inner{\\alpha\\bf{u}}{\\bf{v}} &= (\\alpha \\bf{u})^H \\bf{v}  & \\{ \\text{ Definition }\\}\\\\\n&= \\overline{\\alpha} \\bf{u}^H \\bf{v} = \\overline{\\alpha} \\inner{\\bf{u}}{\\bf{v}}\n\\end{align*}\n\\]\nand\n\\[\n\\begin{align*}\n\\inner{\\bf{u}}{\\alpha\\bf{v}} &= (\\bf{u})^H \\bf{ \\alpha v}  & \\{ \\text{ Definition }\\}\\\\\n&= \\alpha \\bf{u}^H \\bf{v} = \\alpha \\inner{\\bf{u}}{\\bf{v}}\n\\end{align*}\n\\]\nIt is homogenous.\nFinally,\n\\[\n\\begin{align*}\n\\inner{\\bf{v}}{\\bf{w}} &= \\sum_{i=1}^n \\overline{v_i}w_i\\\\\n&= \\sum_{i=1}^n \\overline{v_i \\overline{w_i}}\\\\\n&= \\overline{\\left(\\sum_{i=1}^n \\overline{w_i} v_i\\right)}\\\\\n&= \\overline{\\inner{\\bf{w}}{\\bf{v}}}\n\\end{align*}\n\\]"
  },
  {
    "objectID": "posts/norms/index.html#inner-product",
    "href": "posts/norms/index.html#inner-product",
    "title": "Norms",
    "section": "",
    "text": "Consider geometric vectors \\(\\mathbf{x}, \\mathbf{y} \\in \\mathbf{R}^2\\). The scalar product(dot-product) of these two vectors is defined by:\n\\[\n\\mathbf{x} \\cdot \\mathbf{y} = x_1 y_1 + x_2 y_2\n\\]\nAn inner-product is a mathematical generalization of the dot-product.\n\n\\[\n\\newcommand{\\norm}[1]{\\left\\lVert#1\\right\\rVert}\n\\newcommand{\\normp}[2]{\\left\\lVert\\mathbf{#1}\\right\\rVert_{#2}}\n\\newcommand\\inner[2]{\\left\\langle #1, #2 \\right\\rangle}\n\\newcommand{\\bf}[1]{\\mathbf{#1}}\n\\newcommand{\\R}{\\mathbf{R}}\n\\newcommand{\\RR}[1]{\\mathbf{R}^2}\n\\newcommand{\\RRR}[1]{\\mathbf{R}^3}\n\\newcommand{\\C}{\\mathbf{C}}\n\\newcommand{\\CC}[1]{\\mathbf{C}^2}\n\\newcommand{\\CCC}[1]{\\mathbf{C}^3}\n\\]\n\n\nDefinition 1 (Inner product) Let \\(V\\) be a vector space and \\(F\\) be a scalar field, which is either \\(\\bf{R}\\) or \\(\\bf{C}\\). Let \\(\\inner{\\cdot}{\\cdot}\\) be a map from \\(V\\times V \\to F\\). Then, \\(\\inner{\\cdot}{\\cdot}\\) is an inner product if for all \\(\\bf{u},\\bf{v}, \\bf{w} \\in V\\), it satisfies:\n\n\n\\[\n\\inner{\\bf{v}}{\\bf{v}} \\geq 0 \\quad \\text { and } \\quad  \\inner{\\bf{v}}{\\bf{v}} = 0 \\Longleftrightarrow \\bf{v} = \\bf{0}\n\\]\n\n\n\n\\[\n\\inner{\\bf{u} + \\bf{v}}{\\bf{w}} = \\inner{\\bf{u}}{\\bf{w}} + \\inner{\\bf{v}}{\\bf{w}}\n\\]\n\n\n\n\\[\n\\begin{align*}\n\\inner{\\alpha \\bf{v}}{\\bf{w}} &= \\overline{\\alpha} \\inner{\\bf{v}}{\\bf{w}}\\\\\n\\inner{\\bf{v}}{\\alpha \\bf{w}} &= \\alpha \\inner{\\bf{v}}{\\bf{w}}\n\\end{align*}\n\\]\n\n\n\n\\[\n\\inner{\\bf{v}}{\\bf{w}} = \\overline{\\inner{\\bf{w}}{\\bf{v}}}\n\\]\n\n\nThe most important example of inner-product is the Euclidean inner product on \\(\\C^n\\). Let \\(\\bf{w},\\bf{z}\\) be (column) vectors in \\(\\C^n\\).\n\\[\n\\inner{\\bf{w}}{\\bf{z}} = (\\bf{w}^H \\bf{z}) =  \\overline{w_1}z_1 + \\overline{w_2}z_2 + \\ldots + \\overline{w_n} z_n\n\\]\nFirstly,\n\\[\n\\begin{align*}\n\\inner{\\bf{v} + \\bf{w}}{\\bf{z}} &= (\\bf{v} + \\bf{w})^H \\bf{z} & \\{ \\text{ Definition }\\}\\\\\n&= (\\bf{v}^H + \\bf{w}^H)\\bf{z} & \\{ \\overline{z_1 + z_2} = \\overline{z_1} + \\overline{z_2}; z_1,z_2\\in \\C \\}\\\\\n&= \\bf{v}^H \\bf{z} + \\bf{w}^H \\bf{z}\\\\\n&= \\inner{\\bf{v}}{\\bf{z}} + \\inner{\\bf{w}}{\\bf{z}}\n\\end{align*}\n\\]\nSo, it is additive in the first slot.\nNext, let \\(\\alpha \\in \\C\\).\n\\[\n\\begin{align*}\n\\inner{\\alpha\\bf{u}}{\\bf{v}} &= (\\alpha \\bf{u})^H \\bf{v}  & \\{ \\text{ Definition }\\}\\\\\n&= \\overline{\\alpha} \\bf{u}^H \\bf{v} = \\overline{\\alpha} \\inner{\\bf{u}}{\\bf{v}}\n\\end{align*}\n\\]\nand\n\\[\n\\begin{align*}\n\\inner{\\bf{u}}{\\alpha\\bf{v}} &= (\\bf{u})^H \\bf{ \\alpha v}  & \\{ \\text{ Definition }\\}\\\\\n&= \\alpha \\bf{u}^H \\bf{v} = \\alpha \\inner{\\bf{u}}{\\bf{v}}\n\\end{align*}\n\\]\nIt is homogenous.\nFinally,\n\\[\n\\begin{align*}\n\\inner{\\bf{v}}{\\bf{w}} &= \\sum_{i=1}^n \\overline{v_i}w_i\\\\\n&= \\sum_{i=1}^n \\overline{v_i \\overline{w_i}}\\\\\n&= \\overline{\\left(\\sum_{i=1}^n \\overline{w_i} v_i\\right)}\\\\\n&= \\overline{\\inner{\\bf{w}}{\\bf{v}}}\n\\end{align*}\n\\]"
  },
  {
    "objectID": "posts/norms/index.html#norms",
    "href": "posts/norms/index.html#norms",
    "title": "Norms",
    "section": "Norms",
    "text": "Norms\nVery often, to quantify errors or measure distances one needs to compute the magnitude(length) of a vector or a matrix. Norms are a mathematical generalization(abstraction) for length.\n\nDefinition 2 (Vector norm) Let \\(\\nu:V \\to \\mathbf{R}\\). Then, \\(\\nu\\) is a (vector) norm if for all \\(\\mathbf{x},\\mathbf{y}\\in V\\) and for all \\(\\alpha \\in \\mathbf{C}\\), \\(\\nu(\\cdot)\\) satisfies:\n\nPositive Semi-Definiteness\n\\[\\nu(\\mathbf{x}) \\geq 0, \\quad \\forall \\bf{x}\\in V\\]\nand\n\\[\\nu(\\mathbf{x})=0 \\Longleftrightarrow \\mathbf{x}=\\mathbf{0}\\]\n\n\nHomogeneity\n\\[\\nu(\\alpha \\mathbf{x}) = |\\alpha|\\nu(\\mathbf{x})\\]\n\n\nTriangle inequality\n\\[\\nu(\\mathbf{x} + \\mathbf{y}) \\leq \\nu(\\mathbf{x}) + \\nu(\\mathbf{y})\\]\n\n\n\nThe vector \\(2-\\)norm\nThe length of a vector is most commonly measured by the square root of the sum of the squares of the components of the vector, also known as the euclidean norm.\n\nDefinition 3 (Vector \\(2-\\)norm) The vector \\(2-\\) norm, \\(||\\cdot||:\\mathbf{C}^n \\to \\mathbf{R}\\) is defined for \\(\\mathbf{x}\\in\\mathbf{C}^n\\) by:\n\\[\n\\norm{\\bf{x}}_2 = \\sqrt{|\\chi_1|^2 + |\\chi_2|^2 + |\\chi_n|^2} = \\sqrt{\\sum_{i=1}^n |\\chi_i^2|}\n\\]\nEquivalently, it can be defined as:\n\\[\n\\norm{\\bf{x}}_2 = \\sqrt{\\inner{\\bf{x}}{\\bf{x}}} =  (\\bf{x}^H \\bf{x})^{1/2} = \\sqrt{\\overline{\\chi_1}\\chi_1 +\\overline{\\chi_2}\\chi_2+\\ldots+\\overline{\\chi_n}\\chi_n}\n\\]\n\nTo prove that the vector \\(2-\\)norm is indeed a valid norm(just calling it a norm, doesn’t mean it is, after all), we need a result known as the Cauchy-Schwarz inequality. This inequality relates the magnitude of the dot-product(inner-product) of two vectors to the product of their two norms : if \\(\\bf{x},\\bf{y} \\in \\R^n\\), then \\(|\\bf{x}^T \\bf{y}|\\leq \\norm{\\bf{x}}_2\\cdot\\norm{\\bf{y}}_2\\).\nBefore we rigorously prove this result, let’s review the idea of orthogonality.\n\nDefinition 4 (Orthogonal vectors) Two vectors \\(\\bf{u},\\bf{v} \\in V\\) are said to be orthogonal to each other if and only if their inner product equals zero:\n\\[\n\\inner{\\bf{u}}{\\bf{v}} = 0\n\\]\n\n\nTheorem 1 (Pythagorean Theorem) If \\(\\bf{u}\\) and \\(\\bf{v}\\) are orthogonal vectors, then\n\\[\n\\inner{\\bf{u} + \\bf{v}}{\\bf{u} + \\bf{v}} = \\inner{\\bf{u}}{\\bf{u}} + \\inner{\\bf{v}}{\\bf{v}}\n\\]\n\nProof.\nWe have:\n\\[\n\\begin{align*}\n\\inner{\\bf{u} + \\bf{v}}{\\bf{u}+\\bf{v}} &= \\inner{\\bf{u}}{\\bf{u} + \\bf{v}} + \\inner{\\bf{v}}{\\bf{u} + \\bf{v}} & \\{ \\text{ Additivity in the first slot }\\}\\\\\n&= \\overline{\\inner{\\bf{u} + \\bf{v}}{\\bf{u}}} + \\overline{\\inner{\\bf{u} + \\bf{v}}{\\bf{v}}} & \\{ \\text{ Conjugate symmetry }\\}\\\\\n&= \\overline{\\inner{\\bf{u}}{\\bf{u}}} + \\overline{\\inner{\\bf{v}}{\\bf{u}}} + \\overline{\\inner{\\bf{u}}{\\bf{v}}} + \\overline{\\inner{\\bf{v}}{\\bf{v}}} \\\\\n&= \\inner{\\bf{u}}{\\bf{u}} + \\inner{\\bf{u}}{\\bf{v}} + \\inner{\\bf{v}}{\\bf{u}} + \\inner{\\bf{v}}{\\bf{v}} \\\\\n&= \\inner{\\bf{u}}{\\bf{u}} + 0 + 0 + \\inner{\\bf{v}}{\\bf{v}} & \\{ \\bf{u} \\perp \\bf{v}\\}\\\\\n&= \\inner{\\bf{u}}{\\bf{u}} + \\inner{\\bf{v}}{\\bf{v}}\n\\end{align*}\n\\]\nThis closes the proof. \\(\\blacksquare\\)\nIn the special case that \\(V=\\C^n\\) or \\(V=\\R^n\\), the pythagorean theorem reduces to:\n\\[\n\\norm{\\bf{u} + \\bf{v}}_2^2 = \\norm{\\bf{u}}_2^2 + \\norm{\\bf{v}}_2^2\n\\]"
  },
  {
    "objectID": "posts/norms/index.html#cauchy-schwarz-inequality",
    "href": "posts/norms/index.html#cauchy-schwarz-inequality",
    "title": "Norms",
    "section": "Cauchy-Schwarz Inequality",
    "text": "Cauchy-Schwarz Inequality\nSuppose \\(\\bf{u},\\bf{v}\\in V\\). We would like to write \\(\\bf{u}\\) as a scalar multiple of \\(\\bf{v}\\) plus a vector \\(\\bf{w}\\) orthogonal to \\(\\bf{v}\\), as suggested in the picture below. Intuitively, we would like to write an orthogonal decomposition of \\(\\bf{u}\\).\n\n%load_ext itikz\n\n\n\nShow the code\n%%itikz --temp-dir --tex-packages=tikz --tikz-libraries=arrows,arrows.meta --implicit-standalone\n\\begin{tikzpicture}[scale=2.0]\n    \\draw [-{Stealth[length=5mm]}](0.0,0.0) -- (7,0);\n    \\draw [-{Stealth[length=5mm]}] (0.0,0.0) -- (7,4);\n    \\node []  at (3.5,2.25) {\\large $\\mathbf{u}$};\n    \\draw [dashed] (7,0) -- (7,4);\n    \\node [circle,fill,minimum size = 0.5mm] at (5,0) {};\n    \\node []  at (5,-0.40) {\\large $\\mathbf{v}$};\n    \\node []  at (7,-0.40) {\\large $\\alpha\\mathbf{v}$};\n    \\node []  at (7.4,2.0) {\\large $\\mathbf{w}$};\n\\end{tikzpicture}\n\n\n\n\n\nTo discover how to write \\(\\bf{u}\\) as a scalar multiple of \\(\\bf{v}\\) plus a vector orthogonal to \\(\\bf{v}\\), let \\(\\alpha\\) denote a scalar. Then,\n\\[\n\\bf{u} = \\alpha \\bf{v} + (\\bf{u} - \\alpha \\bf{v})\n\\]\nThus, we need to choose \\(\\alpha\\) so that \\(\\bf{v}\\) and \\(\\bf{w} = \\bf{u} - \\alpha{v}\\) are mutually orthogonal. Thus, we must set:\n\\[\n\\inner{\\bf{u} - \\alpha\\bf{v}}{\\bf{v}} = \\inner{\\bf{u}}{\\bf{v}} - \\alpha \\inner{\\bf{v}}{\\bf{v}} = 0\n\\]\nThe equation above shows that we choose \\(\\alpha\\) to be \\(\\inner{\\bf{u}}{\\bf{v}}/\\inner{\\bf{v}}{\\bf{v}}\\) (assume that \\(\\bf{v} \\neq \\bf{0}\\) to avoid division by 0). Making this choice of \\(\\alpha\\), we can write:\n\\[\n\\bf{u} = \\frac{\\inner{\\bf{u}}{\\bf{v}}}{\\inner{\\bf{v}}{\\bf{v}}}\\bf{v} + \\left(\\bf{u} - \\frac{\\inner{\\bf{u}}{\\bf{v}}}{\\inner{\\bf{v}}{\\bf{v}}}\\bf{v}\\right)\n\\tag{1}\\]\nThe equation above will be used in the proof the Cauchy-Schwarz inequality, one of the most important inequalities in mathematics\n\nTheorem 2 (Cauchy-Schwarz Inequality) Let \\(\\bf{x},\\bf{y}\\in V\\). Then\n\\[\n|\\inner{\\bf{u}}{\\bf{v}}|^2 \\leq \\inner{\\bf{u}}{\\bf{u}}\\inner{\\bf{v}}{\\bf{v}}\n\\tag{2}\\]\n\nProof.\nLet \\(\\bf{u},\\bf{v} \\in V\\). If \\(\\bf{v} = \\bf{0}\\), then both sides of Equation 2 equal \\(0\\) and the inequality holds. Thus, we assume that \\(\\bf{v}\\neq \\bf{0}\\). Consider the orthogonal decomposition:\n\\[\n\\bf{u} = \\frac{\\inner{\\bf{u}}{\\bf{v}}}{\\inner{\\bf{v}}{\\bf{v}}} \\bf{v} + \\bf{w}\n\\]\nwhere \\(\\bf{w}\\) is orthogonal to \\(\\bf{v}\\) (\\(\\bf{w}\\) is taken to be the second term on the right hand side of Equation 1). By the Pythagorean theorem:\n\\[\n\\begin{align*}\n\\inner{\\bf{u}}{\\bf{u}} &= \\inner{\\frac{\\inner{\\bf{u}}{\\bf{v}}}{\\inner{\\bf{v}}{\\bf{v}}} \\bf{v}}{\\frac{\\inner{\\bf{u}}{\\bf{v}}}{\\inner{\\bf{v}}{\\bf{v}}} \\bf{v}}+\\inner{\\bf{w}}{\\bf{w}}\\\\\n&= \\overline{\\left(\\frac{\\inner{\\bf{u}}{\\bf{v}}}{\\inner{\\bf{v}}{\\bf{v}}}\\right)}\\left(\\frac{\\inner{\\bf{u}}{\\bf{v}}}{\\inner{\\bf{v}}{\\bf{v}}}\\right)\\inner{\\bf{v}}{\\bf{v}} + \\inner{\\bf{w}}{\\bf{w}}\\\\\n&= \\frac{\\overline{\\inner{\\bf{u}}{\\bf{v}}}\\inner{\\bf{u}}{\\bf{v}}}{\\overline{\\inner{\\bf{v}}{\\bf{v}}}} + \\inner{\\bf{w}}{\\bf{w}}\\\\\n&= \\frac{|\\inner{\\bf{u}}{\\bf{v}}|^2}{\\inner{\\bf{v}}{\\bf{v}}} + \\inner{\\bf{w}}{\\bf{w}}\n\\end{align*}\n\\]\nSince \\(\\inner{\\bf{w}}{\\bf{w}} \\geq 0\\), it follows that:\n\\[\n\\inner{\\bf{u}}{\\bf{u}} \\geq \\frac{|\\inner{\\bf{u}}{\\bf{v}}|^2}{\\inner{\\bf{v}}{\\bf{v}}}\n\\]\nConsequently, we have:\n\\[\n|\\inner{\\bf{u}}{\\bf{v}}|^2 \\leq \\inner{\\bf{u}}{\\bf{u}}\\inner{\\bf{v}}{\\bf{v}}\n\\]\nThis closes the proof. \\(\\blacksquare\\)\nIn the special case, that \\(V=\\R^n\\) or \\(V=\\C^n\\), we have:\n\\[\n|\\inner{\\bf{u}}{\\bf{v}}| \\leq \\norm{\\bf{u}}_2 \\norm{\\bf{v}}_2\n\\]"
  },
  {
    "objectID": "posts/norms/index.html#euclidean-norm",
    "href": "posts/norms/index.html#euclidean-norm",
    "title": "Norms",
    "section": "Euclidean Norm",
    "text": "Euclidean Norm\n\nProposition 1 (Well-definedness of the Euclidean norm) Let \\(\\norm{\\cdot}:\\mathbf{C}^n \\to \\mathbf{C}\\) be the euclidean norm. Our claim is, it is well-defined.\n\nProof.\nLet \\(\\bf{z} = (z_1,z_2,\\ldots,z_n) \\in \\C^n\\). Clearly, it is positive semi-definite.\n\\[\n\\begin{align*}\n\\norm{\\bf{z}}_2 = \\bf{z}^H \\bf{z} &= \\overline{z_1} z_1 +\\overline{z_2}z_2 + \\ldots + \\overline{z_n} z_n\\\\\n&= \\sum_{i=1}^n |z_i|^2 \\geq 0\n\\end{align*}\n\\]\nIt is also homogenous. Let \\(\\alpha \\in \\C\\).\n\\[\n\\begin{align*}\n\\norm{\\alpha \\bf{z}}_2 &= \\norm{(\\alpha z_1, \\alpha z_2,\\ldots,\\alpha z_n)}_2\\\\\n&=\\sqrt{\\sum_{i=1}^n |\\alpha z_i|^2}\\\\\n&=|\\alpha|\\sqrt{\\sum_{i=1}^n |z_i|^2} \\\\\n&= |\\alpha|\\norm{\\bf{z}}_2\n\\end{align*}\n\\]\nLet’s verify, if the triangle inequality is satisfied. Let \\(\\bf{x}, \\bf{y}\\in\\C^n\\) be arbitrary vectors.\n\\[\n\\begin{align*}\n\\norm{\\bf{x} + \\bf{y}}_2^2 &= |(\\bf{x} + \\bf{y})^H(\\bf{x} + \\bf{y})|\\\\\n&= |(\\bf{x}^H + \\bf{y}^H)(\\bf{x} + \\bf{y})|\\\\\n&= |\\bf{x}^H \\bf{x} + \\bf{y}^H \\bf{y} + \\bf{y}^H \\bf{x} + \\bf{x}^H \\bf{y}|\\\\\n&\\leq \\norm{\\bf{x}}_2^2 + \\norm{\\bf{y}}_2^2 + |\\inner{\\bf{y}}{\\bf{x}}| + |\\inner{\\bf{x}}{\\bf{y}}|\\\\\n&\\leq \\norm{\\bf{x}}_2^2 + \\norm{\\bf{y}}_2^2 + \\norm{\\bf{y}}_2 \\norm{\\bf{x}}_2  + \\norm{\\bf{x}}_2 \\norm{\\bf{y}}_2 & \\{ \\text{ Cauchy-Schwarz } \\}\\\\\n&\\leq \\norm{\\bf{x}}_2^2 + \\norm{\\bf{y}}_2^2 +  2\\norm{\\bf{x}}_2 \\norm{\\bf{y}}_2\\\\\n&= (\\norm{\\bf{x}}_2 + \\norm{\\bf{y}}_2)^2\n\\end{align*}\n\\]\nConsequently, \\(\\norm{\\bf{x} + \\bf{y}}_2 \\leq \\norm{\\bf{x}}_2 + \\norm{\\bf{y}}_2\\)."
  },
  {
    "objectID": "posts/norms/index.html#the-vector-1-norm",
    "href": "posts/norms/index.html#the-vector-1-norm",
    "title": "Norms",
    "section": "The vector \\(1-\\)norm",
    "text": "The vector \\(1-\\)norm\n\nDefinition 5 (The vector \\(1-\\)norm) The vector \\(1\\)-norm, \\(\\norm{\\cdot}_1 : \\C^n \\to \\R\\) is defined for all \\(\\bf{x}\\in\\C^n\\) by:\n\\[\n\\norm{\\bf{x}}_1 = |\\chi_1| + |\\chi_2| + \\ldots + |\\chi_n| =\\sum_{i=1}^n |\\chi_i|\n\\]\n\n\nTheorem 3 The vector \\(1\\)-norm is well-defined.\n\nProof.\nPositive semi-definitess.\nThe absolute value of complex numbers is non-negative.\n\\[\n\\norm{\\bf{x}}_1 = |\\chi_1| + |\\chi_2| + \\ldots + |\\chi_n| \\geq |\\chi_i| \\geq 0\n\\]\nHomogeneity.\n\\[\n\\norm{\\alpha\\bf{x}}_1 = \\sum_{i=1}^{n}|\\alpha \\chi_i| = |\\alpha| \\sum_{i=1}^{n}|\\chi_i| = |\\alpha| \\norm{\\bf{x}}_1\n\\]\nTriangle Inequality.\n\\[\n\\begin{align*}\n\\norm{\\bf{x} + \\bf{y}} &= \\norm{(\\chi_1 + \\psi_1, \\ldots,\\chi_n + \\psi_n)}_1\\\\\n&= \\sum_{i=1}^n |\\chi_i + \\psi_i|\\\\\n&\\leq \\sum_{i=1}^n |\\chi_i| + |\\psi_i| & \\{ \\text{ Triangle inequality for complex numbers }\\}\\\\\n&= \\sum_{i=1}^n |\\chi_i| + \\sum_{i=1}^{n} |\\psi_i| & \\{ \\text{ Commutativity }\\}\\\\\n&= \\norm{\\bf{x}}_1 + \\norm{\\bf{y}}_1\n\\end{align*}\n\\]\nHence, the three axioms are satisfied. \\(\\blacksquare\\)"
  },
  {
    "objectID": "posts/norms/index.html#jensens-inequality",
    "href": "posts/norms/index.html#jensens-inequality",
    "title": "Norms",
    "section": "Jensen’s inequality",
    "text": "Jensen’s inequality\n\nConvex functions and combinations\nA function \\(f\\) is said to be convex on over an interval \\(I\\), if for all \\(x_1,x_2 \\in I\\), and every \\(p \\in [0,1]\\), we have:\n\\[\nf(px_1 + (1-p)x_2) \\leq pf(x_1) + (1-p)f(x_2)\n\\]\nIn other words, all chords(secants) joining any two points on \\(f\\), lie above the graph of \\(f\\). Note that, if \\(0 \\leq p \\leq 1\\), then \\(\\min(x_1,x_2) \\leq px_1 + (1-p)x_2 \\leq \\max(x_1,x_2)\\). More generally, for non-negative real numbers \\(p_1, p_2, \\ldots, p_n\\) summing to one, that is, satisfying \\(\\sum_{i=1}^n p_i = 1\\), and for any points \\(x_1,\\ldots,x_n \\in I\\), the point \\(\\sum_{i=1}^n \\lambda_i x_i\\) is called a convex combination of \\(x_1,\\ldots,x_n\\). Since:\n\\[ \\min(x_1,\\ldots,x_n) \\leq \\sum_{i=1}^n p_i x_i \\leq \\max(x_1,\\ldots,x_n)\\]\nevery convex combination of any finite number of points in \\(I\\) is again a point of \\(I\\).\nIntuitively, \\(\\sum_{i=1}^{n}p_i x_i\\) simply represents the center of mass of the points \\(x_1,\\ldots,x_n\\) with weights \\(p_1,\\ldots,p_n\\).\n\n\nProving Jensen’s inequality\nJensen’s inequality named after the Danish engineer Johan Jensen (1859-1925) can be stated as follows:\n\nTheorem 4 Let \\(n \\in \\bf{Z}_+\\) be a positive integer and let \\(f:I \\to \\R\\) be a convex function over the interval \\(I \\subseteq \\R\\). For any (not necessarily distinct) points \\(x_1,\\ldots,x_n \\in I\\), and non-negative real numbers \\(p_1,\\ldots,p_n \\in \\R\\) summing to one,\n\\[\nf(\\sum_{i=1}^n p_i x_i) \\leq \\sum_{i=1}^n p_i f(x_i)\n\\]\n\nProof.\nWe proceed by induction. Since \\(f\\) is convex, by definition, \\(\\forall x_1,x_2 \\in I\\), and any \\(p_1,p_2\\in \\R\\), such that \\(p_1 + p_2 = 1\\), we have \\(f(p_1 x_1 + p_2 x_2) \\leq p_1 f(x_1) + p_2 f(x_2)\\). So, the claim is true for \\(n=2\\).\nInductive hypothesis. Assume that \\(\\forall x_1,\\ldots,x_{k} \\in I\\) and any \\(p_1,\\ldots,p_k \\in \\R\\), such that \\(\\sum_{i=1}^k p_i = 1\\), we have \\(f(\\sum_{i=1}^k p_i x_i) \\leq \\sum_{i=1}^k p_i f(x_i)\\).\nClaim. The Jensen’s inequality holds for \\(k+1\\) points in \\(I\\).\nProof.\nLet \\(x_1,\\ldots,x_k, x_{k+1}\\) be arbitrary points in \\(I\\) and consider any convex combination of these points \\(\\sum_{i=1}^{k+1}p_i x_i\\), \\(p_i \\in [0,1], i \\in \\{1,2,3,\\ldots,k+1\\}, \\sum_{i=1}^{k+1}p_i = 1\\).\nDefine:\n\\[\nz := \\frac{p_1 x_1 + p_2 x_2 + \\ldots + p_k x_k}{\\sum_{i=1}^k p_i}\n\\]\nSince, \\(z\\) is a convex combination of \\(\\{x_1,\\ldots,x_k\\}\\), \\(z \\in I\\). Moreover, by the inductive hypothesis, since \\(f\\) is convex,\n\\[\n\\begin{align*}\nf(z) &= f\\left(\\frac{p_1 x_1 + p_2 x_2 + \\ldots + p_k x_k}{\\sum_{i=1}^k p_i}\\right)\\\\\n&\\leq \\frac{p_1}{\\sum_{i=1}^k p_i}f(x_1) + \\frac{p_2}{\\sum_{i=1}^k p_i}f(x_2) + \\ldots + \\frac{p_k}{\\sum_{i=1}^k p_i}f(x_k) \\\\\n&= \\frac{p_1}{1-p_{k+1}}f(x_1) + \\frac{p_2}{1-p_{k+1}}f(x_2) + \\ldots + \\frac{p_k}{1-p_{k+1}}f(x_k) \\\\\n\\end{align*}\n\\]\nSince \\(0 \\leq 1 - p_{k+1} \\leq 1\\), we deduce that:\n\\[\n(1 - p_{k+1})f(z) \\leq p_1 f(x_1) + \\ldots + p_k f(x_k)\n\\]\nWe have: \\[\n\\begin{align*}\nf(p_1 x_1 + \\ldots + p_k x_k + p_{k+1} x_{k+1}) &= f((1-p_{k+1})z + p_{k+1}x_{k+1})\\\\\n&\\leq (1-p_{k+1})f(z) + p_{k+1}f(x_{k+1}) & \\{ \\text{ Jensen's inequality for }n=2\\}\\\\\n&\\leq p_1 f(x_1) + \\ldots + p_k f(x_k) + p_{k+1}f(x_{k+1}) & \\{ \\text{ Deduction from the inductive hypothesis }\\}\n\\end{align*}\n\\]\nThis closes the proof. \\(\\blacksquare\\)"
  },
  {
    "objectID": "posts/norms/index.html#youngs-inequality",
    "href": "posts/norms/index.html#youngs-inequality",
    "title": "Norms",
    "section": "Young’s Inequality",
    "text": "Young’s Inequality\nYoung’s inequality is named after the English mathematician William Henry Young and can be stated as follows:\n\nTheorem 5 (Young’s inequality) For any non-negative real numbers \\(a\\) and \\(b\\) and any positive real numbers \\(p,q\\) satisfying \\(\\frac{1}{p} + \\frac{1}{q}=1\\), we have:\n\\[\nab \\leq \\frac{a^p}{p} + \\frac{b^q}{q}\n\\]\n\nProof.\nLet \\(f(x) = \\log x\\). Since \\(f\\) is concave, we can reverse the Jensen’s inequality. Consequently:\n\\[\n\\begin{align*}\n\\log(\\frac{a^p}{p} + \\frac{b^q}{q}) &\\geq \\frac{1}{p}\\log a^p + \\frac{1}{q}\\log b^q\\\\\n&= \\frac{1}{p}\\cdot p \\log a + \\frac{1}{q}\\cdot q \\log b\\\\\n&= \\log (ab)\n\\end{align*}\n\\]\nSince \\(\\log x\\) is monotonic increasing,\n\\[\n\\frac{a^p}{p} + \\frac{b^q}{q} \\geq ab\n\\]\nThis closes the proof. \\(\\blacksquare\\)"
  },
  {
    "objectID": "posts/norms/index.html#holders-inequality",
    "href": "posts/norms/index.html#holders-inequality",
    "title": "Norms",
    "section": "Holder’s inequality",
    "text": "Holder’s inequality\nWe can use Young’s inequality to prove the Holder’s inequality, named after the German mathematician Otto Ludwig Holder (1859-1937).\n\nTheorem 6 (Holder’s inequality) For any pair of vectors \\(\\bf{x},\\bf{y}\\in \\C^n\\), and for any positive real numbers satisfying \\(p\\) and \\(q\\), we have \\(\\frac{1}{p} + \\frac{1}{q} = 1\\) we have:\n\\[\n\\sum_{i=1}^{n}|x_i y_i| \\leq \\left(\\sum_{i=1}^n |x_i|^p\\right)^{1/p} \\left(\\sum_{i=1}^n |y_i|^q\\right)^{1/q}\n\\]\n\nProof.\nApply Young’s inequality to \\(a = \\frac{|x_i|}{\\left(\\sum_{i=1}^n |x_i|^p\\right)^{1/p}}\\) and \\(b = \\frac{|y_i|}{\\left(\\sum_{i=1}^n |y_i|^q\\right)^{1/q}}\\). We get:\n\\[\n\\begin{align*}\n\\frac{|x_i||y_i|}{\\left(\\sum_{i=1}^n |x_i|^p\\right)^{1/p}\\left(\\sum_{i=1}^n |y_i|^q\\right)^{1/q}} &\\leq \\frac{1}{p} \\frac{|x_i|^p}{\\sum_{i=1}^n |x_i|^p} + \\frac{1}{q}\\frac{|y_i|^q}{\\sum_{i=1}^n |y_i|^q}\n\\end{align*}\n\\]\nSumming on both sides, we get:\n\\[\n\\begin{align*}\n\\frac{\\sum_{i=1}^n|x_i y_i|}{\\left(\\sum_{i=1}^n |x_i|^p\\right)^{1/p}\\left(\\sum_{i=1}^n |y_i|^q\\right)^{1/q}} &\\leq \\frac{1}{p} \\frac{\\sum_{i=1}^n |x_i|^p}{\\sum_{i=1}^n |x_i|^p} + \\frac{1}{q}\\frac{\\sum_{i=1}^n|y_i|^q}{\\sum_{i=1}^n |y_i|^q}\\\\\n&= \\frac{1}{p} + \\frac{1}{q}\\\\\n&= 1\\\\\n\\sum_{i=1}^n |x_i y_i| &\\leq \\left(\\sum_{i=1}^n |x_i|^p\\right)^{1/p}\\left(\\sum_{i=1}^n |y_i|^q\\right)^{1/q}\n\\end{align*}\n\\]\nThis closes the proof. \\(\\blacksquare\\)"
  },
  {
    "objectID": "posts/norms/index.html#the-vector-p-norm",
    "href": "posts/norms/index.html#the-vector-p-norm",
    "title": "Norms",
    "section": "The vector \\(p\\)-norm",
    "text": "The vector \\(p\\)-norm\nThe vector \\(1\\)-norm and \\(2\\)-norm are special cases of the \\(p\\)-norm.\n\nDefinition 6 (\\(p\\)-norm) Given \\(p \\geq 1\\), the vector \\(p\\)-norm \\(\\norm{\\cdot}_p : \\C^n \\to \\R\\) is defined by :\n\\[\n\\norm{\\bf{x}}_p = \\left(\\sum_{i=1}^n |\\chi_i|^p\\right)^{1/p}\n\\]\n\n\nTheorem 7 The vector \\(p\\)-norm is a well-defined norm.\n\nProof.\nPositive semi-definite\nWe have:\n\\[\n\\begin{align*}\n\\norm{\\bf{x}}_p &= \\left(\\sum_{i=1}^n |\\chi_i|^p \\right)^{1/p}\\\\\n&\\geq \\left(|\\chi_i|^p \\right)^{1/p}\\\\\n&= |\\chi_i| \\geq 0\n\\end{align*}\n\\]\nHomogeneity\nWe have:\n\\[\n\\begin{align*}\n\\norm{\\alpha \\bf{x}}_p &= \\left(\\sum_{i=1}^n |\\alpha \\chi_i|^p \\right)^{1/p}\\\\\n&= \\left(\\sum_{i=1}^n |\\alpha|^p |\\chi_i|^p \\right)^{1/p}\\\\\n&= |\\alpha|\\left(\\sum_{i=1}^n |\\chi_i|^p \\right)^{1/p} &= |\\alpha|\\norm{\\bf{x}}_p\n\\end{align*}\n\\]\nTriangle Inequality\nDefine \\(\\frac{1}{q} := 1 - \\frac{1}{p}\\). \\(\\Longrightarrow (p-1)q = p\\).\nBy the Holder’s inequality: \\[\n\\begin{align*}\n\\sum_{i=1}^n |x_i||x_i + y_i|^{p-1} &\\leq \\left(\\sum_{i=1}^n |x_i|^p\\right)^{1/p} \\left(\\sum_{i=1}^n |x_i + y_i|^{(p-1)q}\\right)^{1/q}\\\\\n\\sum_{i=1}^n |y_i||x_i + y_i|^{p-1} &\\leq \\left(\\sum_{i=1}^n |y_i|^p\\right)^{1/p} \\left(\\sum_{i=1}^n |x_i + y_i|^{(p-1)q}\\right)^{1/q}\n\\end{align*}\n\\]\nSumming, we get:\n\\[\n\\begin{align*}\n\\sum_{i=1}^n |x_i + y_i|^{p} &\\leq \\left\\{\\left(\\sum_{i=1}^n |x_i|^p\\right)^{1/p}+ \\left(\\sum_{i=1}^n |y_i|^p\\right)^{1/p}\\right\\} \\left(\\sum_{i=1}^n |x_i + y_i|^{(p-1)q}\\right)^{1/q}\\\\\n&= \\left\\{\\left(\\sum_{i=1}^n |x_i|^p\\right)^{1/p}+ \\left(\\sum_{i=1}^n |y_i|^p\\right)^{1/p}\\right\\}\\left(\\sum_{i=1}^n |x_i + y_i|^{p}\\right)^{1-\\frac{1}{p}}\\\\\n\\Longrightarrow \\left(\\sum_{i=1}^n |x_i + y_i|^{p}\\right)^{1/p} &\\leq \\left\\{\\left(\\sum_{i=1}^n |x_i|^p\\right)^{1/p}+ \\left(\\sum_{i=1}^n |y_i|^p\\right)^{1/p}\\right\\}\n\\end{align*}\n\\]\nThis closes the proof. \\(\\blacksquare\\)"
  },
  {
    "objectID": "posts/norms/index.html#the-vector-infty-norm",
    "href": "posts/norms/index.html#the-vector-infty-norm",
    "title": "Norms",
    "section": "The vector \\(\\infty\\)-norm",
    "text": "The vector \\(\\infty\\)-norm\n\nDefinition 7 (\\(\\infty\\)-norm) The vector \\(\\infty\\)-norm, \\(\\norm{\\cdot}:\\C^n \\to \\R\\) is defined for \\(\\bf{x} \\in \\C^n\\) by:\n\\[\n\\norm{\\bf{x}}_\\infty = \\max\\{|\\chi_1|,|\\chi_2|,\\ldots,|\\chi_n|\\}\n\\]\nThe \\(\\infty\\)-norm simply measures how long the vector is by the magnitude of its largest entry.\n\n\nTheorem 8 The vector \\(\\infty\\)-norm is well-defined.\n\nProof.\nPositive semi-definiteness\nWe have:\n\\[\n\\norm{\\bf{x}}_{\\infty} = \\max_{1\\leq i \\leq n} |\\chi_i| \\geq |\\xi_i| \\geq 0\n\\]\nHomogeneity\nWe have:\n\\[\n\\norm{\\alpha \\bf{x}}_{\\infty} = \\max_{1\\leq i \\leq n}|\\alpha \\chi_i| =\\max_{1\\leq i \\leq n}|\\alpha|| \\chi_i| = |\\alpha| \\max_{1\\leq i \\leq n}|\\chi_i| = |\\alpha|\\norm{\\bf{x}}_{\\infty}\n\\]\nTriangle Inequality\n\\[\n\\begin{align*}\n\\norm{\\bf{x} + \\bf{y}}_\\infty &= \\max_{i=1}^m |\\chi_i + \\xi_i|\\\\\n&\\leq \\max_{i=1}^m (|\\chi_i| + |\\xi_i|)\\\\\n&\\leq \\max_{i=1}^m |\\chi_i| + \\max_{i=1}^m |\\xi_i|\\\\\n&= \\norm{\\bf{x}}_\\infty + \\norm{\\bf{y}}_\\infty\n\\end{align*}\n\\]"
  },
  {
    "objectID": "posts/norms/index.html#equivalence-of-vector-norms",
    "href": "posts/norms/index.html#equivalence-of-vector-norms",
    "title": "Norms",
    "section": "Equivalence of vector norms",
    "text": "Equivalence of vector norms\nAs I was saying earlier, we often measure if a vector is small or large or the distance between two vectors by computing norms. It would be unfortunate, if a vector were small in one norm, yet large in another. Fortunately, the next theorem excludes this possibility.\n\nTheorem 9 (Equivalence of vector norms) Let \\(\\norm{\\cdot}_a:\\C^n \\to \\R\\) and \\(\\norm{\\cdot}_b:\\C^n\\to \\R\\) both be vector norms. Then there exist positive scalars \\(C_1\\) and \\(C_2\\) such that for \\(\\bf{x}\\in \\C^n\\),\n\\[\nC_1 \\norm{\\bf{x}}_b \\leq \\norm{\\bf{x}}_a \\leq C_2 \\norm{\\bf{x}}_b\n\\]\n\nProof.\nWe can prove equivalence of norms in four steps, the last which uses the extreme value theorem from Real Analysis.\n\nStep 1: It is sufficient to consider \\(\\norm{\\cdot}_b = \\norm{\\cdot}_1\\) (transitivity).\nWe will show that it is sufficient to prove that \\(\\norm{\\cdot}_a\\) is equivalent to \\(\\norm{\\cdot}_1\\) because norm equivalence is transitive: if two norms are equivalent to \\(\\norm{\\cdot}_1\\), then they are equivalent to each other. In particular, suppose both \\(\\norm{\\cdot}_a\\) and \\(\\norm{\\cdot}_{a'}\\) are equivalent to \\(\\norm{\\cdot}_1\\) for constants \\(0 \\leq C_1 \\leq C_2\\) and \\(0 \\leq C_1' \\leq C_2'\\) respectively:\n\\[\nC_1 \\norm{\\bf{x}}_1 \\leq \\norm{\\bf{x}}_a \\leq C_2 \\norm{\\bf{x}}_1\n\\]\nand\n\\[\nC_1' \\norm{\\bf{x}}_1 \\leq \\norm{\\bf{x}}_{a'} \\leq C_2' \\norm{\\bf{x}}_1\n\\]\nThen, it immediately follows that:\n\\[\n\\norm{\\bf{x}}_{a'} \\leq C_2' \\norm{\\bf{x}}_1 \\leq \\frac{C_2'}{C_1} \\norm{\\bf{x}}_a\n\\]\nand\n\\[\n\\norm{\\bf{x}}_{a'} \\geq C_1' \\norm{\\bf{x}}_1 \\geq \\frac{C_1'}{C_2} \\norm{\\bf{x}}_a\n\\]\nand hence \\(\\norm{\\cdot}_a\\) and \\(\\norm{\\cdot}_{a'}\\) are equivalent. \\(\\blacksquare\\)\n\n\nStep 2: It is sufficient to consider only \\(\\bf{x}\\) with \\(\\norm{\\bf{x}}_1 = 1\\).\nWe wish to show that\n\\[\nC_1 \\norm{\\bf{x}}_1 \\leq \\norm{\\bf{x}}_a \\leq C_2 \\norm{\\bf{x}}_1\n\\]\nis true for all \\(\\bf{x} \\in V\\) for some \\(C_1\\), \\(C_2\\). It is trivially true for \\(\\bf{x}=\\bf{0}\\), so we only need to consider \\(\\bf{x}\\neq\\bf{0}\\), in which case, we can divide by \\(\\norm{\\bf{x}}_1\\), to obtain the condition:\n\\[\nC_1 \\leq \\norm{\\frac{\\bf{x}}{\\norm{\\bf{x}}_1 }}_a \\leq C_2\n\\]\nThe vector \\(\\bf{u} = \\frac{\\bf{x}}{\\norm{\\bf{x}}_1}\\) is a unit vector in the \\(1\\)-norm, \\(\\norm{\\bf{u}}_1 = 1\\). So, we can write:\n\\[\nC_1 \\leq \\norm{\\bf{u}}_a \\leq C_2\n\\]\nWe have the desired result. \\(\\blacksquare\\)\n\n\nStep 3: Any norm \\(\\norm{\\cdot}_a\\) is continuous under \\(\\norm{\\cdot}_1\\).\nWe wish to show that any norm \\(\\norm{\\cdot}_a\\) is a continuous function on \\(V\\) under the topology induced by \\(\\norm{\\cdot}_1\\). That is, we wish to show that for any \\(\\epsilon &gt; 0\\), there exists \\(\\delta &gt; 0\\), such that for all \\(\\norm{\\bf{x} - \\bf{c}}_1 &lt; \\delta\\), we have \\(\\norm{\\norm{\\bf{x}}_a - \\norm{\\bf{c}}_a}_1 &lt; \\epsilon\\).\nWe prove this into two steps. First, by the triangle inequality on \\(\\norm{\\cdot}_a\\), it follows that:\n\\[\n\\begin{align*}\n\\norm{\\bf{x}}_a - \\norm{\\bf{c}}_a &= \\norm{\\bf{c} + (\\bf{x} - \\bf{c})}_a - \\norm{\\bf{c}}_a \\\\\n&\\leq \\norm{\\bf{c}}_a + \\norm{(\\bf{x} - \\bf{c})}_a - \\norm{\\bf{c}}_a\\\\\n&= \\norm{(\\bf{x} - \\bf{c})}_a\n\\end{align*}\n\\]\nAnd\n\\[\n\\begin{align*}\n\\norm{\\bf{c}}_a - \\norm{\\bf{x}}_a &\\leq \\norm{(\\bf{x} - \\bf{c})}_a\n\\end{align*}\n\\]\nand hence:\n\\[\n|\\norm{\\bf{x}}_a - \\norm{\\bf{c}}_a| \\leq \\norm{(\\bf{x} - \\bf{c})}_a\n\\]\nSecond applying the triangle inequality again, and writing \\(\\bf{x} = \\sum_{i=1}^n \\alpha_i \\bf{e}_i\\) and \\(\\bf{c} = \\sum_{i=1}^n \\alpha_i' \\bf{e}_i\\) in our basis, we obtain:\n\\[\n\\begin{align*}\n\\norm{\\bf{x}-\\bf{c}}_a &= \\norm{\\sum_{i=1}^n (\\alpha_i - \\alpha_i')\\bf{e}_i}_a\\\\\n&\\leq \\sum_{i=1}^n \\norm{(\\alpha_i - \\alpha_i')\\bf{e}_i}_a & \\{ \\text{ Triangle Inequality }\\}\\\\\n&= \\sum_{i=1}^n |(\\alpha_i - \\alpha_i')|\\norm{\\bf{e}_i}_a \\\\\n&= \\norm{\\bf{x} - \\bf{c}}_1 \\left(\\max_i \\norm{\\bf{e}_i}_a \\right)\n\\end{align*}\n\\]\nTherefore, if we choose:\n\\[\n\\delta = \\frac{\\epsilon}{\\left(\\max_i \\norm{\\bf{e}_i}_a \\right)}\n\\]\nit immediate follows that:\n\\[\\begin{align*}\n\\norm{\\bf{x} - \\bf{c}}_1 &&lt; \\delta \\\\\n\\Longrightarrow |\\norm{\\bf{x}}_a - \\norm{\\bf{c}}_a| &\\leq \\norm{\\bf{x} - \\bf{c}}_a \\\\ &\\leq \\norm{\\bf{x} - \\bf{c}}_1 \\left(\\max_i \\norm{\\bf{e}_i}_a \\right) \\\\\n& \\leq \\frac{\\epsilon}{\\left(\\max_i \\norm{\\bf{e}_i}_a \\right)} \\left(\\max_i \\norm{\\bf{e}_i}_a \\right) = \\epsilon\n\\end{align*}\n\\]\nThis proves (uniform) continuity. \\(\\blacksquare\\)\n\n\nStep 4: The maximum and minimum of \\(\\norm{\\cdot}_a\\) on the unit ball\nLet \\(K:=\\{\\bf{u}:\\norm{\\bf{u}}_1 = 1\\}\\). Then, \\(K\\) is a compact set. Since \\(\\norm{\\cdot}_a\\) is continuous on \\(K\\), by the extreme value theorem, \\(\\norm{\\cdot}_a\\) must achieve a supremum and infimum on the set. So, for all \\(\\bf{u}\\) with \\(\\norm{\\bf{u}}_1 = 1\\), there exists \\(C_1,C_2 &gt; 0\\), such that:\n\\[ C_1 \\leq \\norm{\\bf{u}}_a \\leq C_2\\]\nas required by step 2. And we are done! \\(\\blacksquare\\)\n\n\nDeriving the constants \\(C_{1,\\infty}\\), \\(C_{\\infty,1}\\)\nLet’s write a python implementation of the various norms.\n\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport itertools\nimport seaborn as sns\n\nsns.set_style(\"whitegrid\")\n\ndef one_norm(x):\n    return np.sum(np.abs(x))\n\ndef two_norm(x):\n    return np.sqrt(np.sum(x**2))\n\ndef p_norm(x,p):\n    return np.pow(np.sum(np.abs(x)**p),1.0/p)\n\ndef infty_norm(x):\n    return np.max(np.abs(x))\n\ndef get_vectors_eq_norm_val(func, val, lower_bound, upper_bound):\n    x_1 = np.linspace(lower_bound, upper_bound, \n    int((upper_bound - lower_bound)*100 + 1))\n    x_2 = np.linspace(lower_bound, upper_bound, \n    int((upper_bound - lower_bound)*100 + 1))\n\n    pts = np.array(list(itertools.product(x_1, x_2)))\n    norm_arr = np.array(list(map(func, pts)))\n\n    pts_norm_list = list(zip(pts,norm_arr))\n\n    pts_with_norm_eq_val = []\n    for pt in pts_norm_list:\n        if pt[1] == val:\n            pts_with_norm_eq_val.append(pt[0])\n\n    return np.array(pts_with_norm_eq_val)\n\nNow, we can glean useful information by visualizing the set of points(vectors) with a given norm.\n\n\nShow the code\npts1 = get_vectors_eq_norm_val(\n    func=infty_norm, val=1.0, lower_bound=-1.0, upper_bound=1.0\n)\n\npts2 = get_vectors_eq_norm_val(\n    func=one_norm, val=2.0, lower_bound=-2.0, upper_bound=2.0\n)\n\nplt.grid(True)\nplt.xlabel(r\"$x_1$\")\nplt.ylabel(r\"$x_2$\")\na = plt.scatter(pts1[:, 0], pts1[:, 1], s=2)\nb = plt.scatter(pts2[:, 0], pts2[:, 1], s=2)\n# c = plt.scatter(pts_with_unit_infty_norm[:,0],pts_with_unit_infty_norm[:,1],s=2)\n\nplt.legend(\n    (a, b), (r\"$||\\mathbf{x}||_\\infty = 1$\", r\"$||\\mathbf{x}||_1=2$\"), loc=\"lower left\"\n)\nplt.show()\n\n\n\n\n\nThe blue rectangle represents all vectors \\(\\bf{x}\\in\\R^2\\) with unit \\(\\infty\\)-norm, \\(\\norm{\\bf{x}}_\\infty = 1\\). The orange rhombus represents all vectors \\(\\bf{x}\\) with \\(\\norm{\\bf{x}}_1 = 2\\). All points on or outside the blue square represent vectors \\(\\bf{y}\\), such that \\(\\norm{\\bf{y}}_\\infty \\geq 1\\). Hence, if \\(\\norm{\\bf{y}}_1 = 2\\), \\(\\norm{\\bf{y}}_\\infty \\geq 1\\).\nNow, pick any \\(\\bf{z}\\neq \\bf{0}\\). Then, \\(2\\norm{\\frac{\\bf{z}}{\\norm{\\bf{z}}_1}}_1 =2\\). Thus, \\(\\norm{\\frac{2\\bf{z}}{\\norm{\\bf{z}}_1}}_\\infty \\geq 1\\). So, it follows that if \\(\\bf{z}\\in\\R^2\\) is any arbitrary vector, \\(\\norm{\\bf{z}}_1 \\leq 2 \\norm{\\bf{z}}_\\infty\\).\nIn general, if \\(\\bf{x}\\in\\C^n\\), then:\n\\[\n\\begin{align*}\n\\norm{\\bf{x}}_1 &= \\sum_{i=1}^n |x_i|\\\\\n&\\leq \\sum_{i=1}^n \\max\\{|x_i|:i=1,2,\\ldots,n\\}\\\\\n&= n \\norm{\\bf{x}}_\\infty\n\\end{align*}\n\\]\nNext, in the below plot, the orange rhombus represents vectors \\(\\bf{x}\\in\\R^2\\), such that \\(\\normp{x}{1} = 1\\) and all points on or outside the orange rhombus are such that \\(\\normp{y}{1} \\geq 1\\). The blue square represents vectors \\(\\normp{y}{\\infty} = 1\\). Consequently, if \\(\\normp{y}{1} = 1\\), then \\(\\normp{y}{\\infty} \\leq \\normp{y}{1}\\). In general, if \\(\\bf{x}\\in C^n\\), we have:\n\\[\n\\begin{align*}\n\\normp{x}{\\infty} &= \\max\\{|x_1|,\\ldots,|x_n|\\}\\\\\n&\\leq \\sum_{i=1}^n |x_i|=\\normp{x}{1}\n\\end{align*}\n\\]\nPutting together, we have:\n\\[\n\\begin{align*}\n\\normp{x}{\\infty} \\leq C_{\\infty,1} \\normp{x}{1} \\\\\n\\normp{x}{1} \\leq C_{1,\\infty} \\normp{x}{\\infty}\n\\end{align*}\n\\]\nwhere \\(C_{\\infty,1} = 1\\) and \\(C_{1,\\infty}=n\\).\n\n\nShow the code\npts1 = get_vectors_eq_norm_val(\n    func=infty_norm, val=1.0, lower_bound=-1.0, upper_bound=1.0\n)\n\npts2 = get_vectors_eq_norm_val(\n    func=one_norm, val=1.0, lower_bound=-2.0, upper_bound=2.0\n)\n\nplt.grid(True)\nplt.xlabel(r\"$x_1$\")\nplt.ylabel(r\"$x_2$\")\na = plt.scatter(pts1[:, 0], pts1[:, 1], s=2)\nb = plt.scatter(pts2[:, 0], pts2[:, 1], s=2)\n# c = plt.scatter(pts_with_unit_infty_norm[:,0],pts_with_unit_infty_norm[:,1],s=2)\n\nplt.legend(\n    (a, b), (r\"$||\\mathbf{x}||_\\infty = 1$\", r\"$||\\mathbf{x}||_1=1$\"), loc=\"lower left\"\n)\nplt.show()\n\n\n\n\n\n\n\nDeriving the constants \\(C_{1,2}\\), \\(C_{2,1}\\)\nWe can also derive the constants \\(C_{1,2}\\) and \\(C_{2,1}\\). We have:\nLet \\(\\bf{x}\\in\\C^n\\) be an arbitrary vector. And let \\(\\bf{y}=(1+0i,\\ldots,1+0i)\\). By the Cauchy-Schwarz inequality,\n\\[\n\\begin{align*}\n\\sum_{i=1}^n |x_i| \\leq \\left(\\sum_{i=1}^n |x_i|^2\\right)^{1/2}\\sqrt{n}\n\\end{align*}\n\\]\nSo, our claim is \\(\\normp{x}{1} \\leq \\sqrt{n}\\normp{x}{2}\\).\nAlso, consider the vector \\(\\bf{v}=\\left(\\frac{1}{\\sqrt{n}},\\ldots,\\frac{1}{\\sqrt{n}}\\right)\\). \\(\\norm{\\bf{v}}_1 = \\sqrt{n}\\norm{\\bf{v}}_2\\). So, the bound is tight.\nMoreover:\n\\[\n\\begin{align*}\n\\normp{x}{2}^2 &= \\sum_{i=1}^n |x_i|^2 \\\\\n&\\leq \\sum_{i=1}^n |x_i|^2 + \\sum_{i \\neq j}|x_i||x_j|\\\\\n&= \\sum_{i=1}^n |x_i|^2 + \\sum_{i &lt; j}2|x_i||x_j|\\\\\n&= \\left(\\sum_{i=1}^n |x_i|\\right)^2\n\\end{align*}\n\\]\nSo, \\(\\normp{x}{2} \\leq \\normp{x}{1}\\). Consider the standard basis vector \\(\\bf{e}_1 = (1,0,0,\\ldots,0)\\). \\(\\norm{\\bf{e}_1}_2 = \\norm{\\bf{e}_1}_1\\). Hence, the bound is tight. We conclude that:\n\\[\n\\begin{align*}\n\\normp{x}{1} \\leq C_{1,2} \\normp{x}{2}\\\\\n\\normp{x}{2} \\leq C_{2,1} \\normp{x}{1}\n\\end{align*}\n\\]\nwhere \\(C_{1,2} = \\sqrt{n}\\) and \\(C_{2,1} = 1\\).\n\n\nDeriving the constants \\(C_{2,\\infty}\\) and \\(C_{\\infty,2}\\)\nLet \\(x \\in \\C^n\\). We have:\n\\[\n\\begin{align}\n\\norm{x}_2^2 & = \\sum_{i=0}^{n-1}|\\chi_i|^2\\\\\n&\\leq\\sum_{i=0}^{n-1} (\\max_{i=0}^{n-1}|\\chi_i|)^2\\\\\n&= n \\norm{x}_\\infty\n\\end{align}\n\\]\nSo, \\(\\norm{x}_2 \\leq \\sqrt{n} \\norm{x}_\\infty\\).\nMoreover, let \\(x = (1, 1, \\ldots, 1)^T\\). Then, \\(\\norm{x}_2 = \\sqrt{n}\\) and \\(\\norm{x}_\\infty = 1\\), so \\(\\norm{x}_2 = \\sqrt{n}\\norm{x}_\\infty\\). Hence, it is a tight inequality.\nAlso, we have:\n\\[\n\\begin{align*}\n\\norm{x}_\\infty^2 &= \\max \\{|\\chi_0|^2,|\\chi_1|^2,\\ldots,|\\chi_{n-1}^2|\\}\\\\\n&\\leq \\max \\{\\sum_{i=0}^{n-1}|\\chi_i|^2,\\sum_{i=0}^{n-1}|\\chi_i|^2,\\ldots,\\sum_{i=0}^{n-1}|\\chi_i|^2|\\}\\\\\n&= \\norm{x}_2^2\n\\end{align*}\n\\]\nMoreover, let \\(x = (1, 0)\\). Then, \\(\\norm{x}_2 = 1\\) and \\(\\norm{x}_\\infty = 1\\). So, \\(\\norm{x}_\\infty = \\norm{x}_2\\). Hence, the inequality is tight."
  },
  {
    "objectID": "posts/norms/index.html#matrix-norms",
    "href": "posts/norms/index.html#matrix-norms",
    "title": "Norms",
    "section": "Matrix Norms",
    "text": "Matrix Norms\nThe analysis of matrix algorithms requires the use of matrix norms. For example, the quality of a linear system solution may be poor, if the matrix of coefficients is nearly singular. To quantify the notion of singularity, we need a measure of the distance on the space of matrices. Matrix norms can be used to provide that measure.\n\nDefinitions\nSince \\(\\R^{m \\times n}\\) is isomorphic \\(\\R^{mn}\\), the definition of a matrix norm is equivalent to the definition of a vector norm. In particular, \\(f:\\R^{m \\times n} \\to \\R\\) is a matrix norm, if the following three properties holds:\n\\[\n\\begin{align*}\nf(A) \\geq 0, & & A \\in \\R^{m \\times n}\\\\\nf(A + B) \\leq f(A) + f(B), & & A,B \\in \\R^{m \\times n}\\\\\nf(\\alpha A) = |\\alpha|f(A), & & \\alpha \\in \\R, A \\in \\R^{m \\times n}\n\\end{align*}\n\\]\nThe most frequently used matrix norms in numerical linear algebra are the Frobenius norm and the \\(p\\)-norms.\n\nDefinition 8 (Frobenius Norm) The Frobenius norm \\(\\norm{\\cdot}_F : \\C^{m \\times n} \\to \\R\\) is defined for \\(A \\in \\C^{m \\times n}\\) by:\n\\[\n\\norm{A}_F = \\left(\\sum_{i=1}^m \\sum_{j=1}^n |a_{ij}|^2\\right)^{1/2}\n\\]\n\n\nTheorem 10 The Frobenius norm is a well-defined norm.\n\nProof.\nPositive Semi-definite\nWe have:\n\\[\n\\begin{align*}\n\\norm{A}_F &= \\left(\\sum_{i=1}^m \\sum_{j=1}^n |a_{ij}|^2\\right)^{1/2}\\\\\n&\\geq \\left( |a_{ij}|^2\\right)^{1/2} = |a_{ij}|\\\\\n&\\geq 0\n\\end{align*}\n\\]\nTriangle Inequality\nWe have:\n\\[\n\\begin{align*}\n\\norm{A + B}_F^2 &= \\sum_{i=1}^m \\sum_{j=1}^n |a_{ij} + b_{ij}|^2 \\\\\n&\\leq \\sum_{i=1}^m \\sum_{j=1}^n \\left(|a_{ij}|^2 + |b_{ij}|^2 + 2|a_{ij}||b_{ij}|\\right)\\\\\n&= \\sum_{i=1}^m \\sum_{j=1}^n |a_{ij}|^2 + \\sum_{i=1}^m \\sum_{j=1}^n |b_{ij}|^2 + 2\\sum_{i=1}^m \\sum_{j=1}^n|a_{ij}||b_{ij}|\\\\\n&\\leq \\sum_{i=1}^m \\sum_{j=1}^n |a_{ij}|^2 + \\sum_{i=1}^m \\sum_{j=1}^n |b_{ij}|^2 + 2\\left(\\sum_{i=1}^m \\sum_{j=1}^n|a_{ij}|^2\\right)^{1/2}\\left(\\sum_{i=1}^m \\sum_{j=1}^n|b_{ij}|^2\\right)^{1/2} & \\{\\text{ Cauchy-Schwarz }\\}\\\\\n&= \\norm{A}_F^2 + \\norm{B}_F^2 + 2\\norm{A}_F \\norm{B}_F\\\\\n&= (\\norm{A}_F + \\norm{B}_F)^2\\\\\\\\\n\\Longrightarrow \\norm{A + B}_F &\\leq \\norm{A}_F + \\norm{B}_F\n\\end{align*}\n\\]\nHomogeneity\nWe have:\n\\[\n\\begin{align*}\n\\norm{\\alpha A}_F &= \\left(\\sum_{i=1}^m \\sum_{j=1}^n |\\alpha a_{ij}|^2\\right)^{1/2}\\\\\n&=\\left(\\sum_{i=1}^m \\sum_{j=1}^n |\\alpha|^2 |a_{ij}|^2\\right)^{1/2}\\\\\n&= |\\alpha| \\norm{A}_F\n\\end{align*}\n\\]\nThis closes the proof. \\(\\blacksquare\\)\n\nDefinition 9 (Induced matrix norm) Let \\(\\norm{\\cdot}_\\mu : \\C^m \\to \\R\\) and \\(\\norm{\\cdot}_\\nu : \\C^n \\to R\\) be vector norms. Define \\(\\norm{\\cdot}_{\\mu,\\nu} : \\C^{m \\times n} \\to R\\) by:\n\\[\n\\norm{A}_{\\mu,\\nu} = \\sup_{\\bf{x}\\neq\\bf{0}} \\frac{\\norm{A\\bf{x}}_\\mu}{\\norm{\\bf{x}}_\\nu}\n\\]\nMatrix norms that are defined in this way are called induced matrix norms.\n\nLet us start by interpreting this. How large \\(A\\) is, as measured by \\(\\norm{A}_{\\mu,\\nu}\\) is defined as the most that \\(A\\) magnifies the length of non-zero vectors, where the length of the \\(\\bf{x}\\) is measured with the norm \\(\\norm{\\cdot}_\\nu\\) and the length of the transformed vector \\(A\\bf{x}\\) is measured with the norm \\(\\norm{\\cdot}_\\mu\\).\nTwo comments are in order. First,\n\\[\n\\begin{align*}\n\\sup_{\\bf{x}\\neq\\bf{0}} \\frac{\\norm{A\\bf{x}}_\\mu}{\\norm{\\bf{x}}_\\nu} = \\sup_{\\bf{x} \\neq \\bf{0}} \\norm{A\\frac{\\bf{x}}{\\norm{\\bf{x}}_\\nu}}_\\mu = \\sup_{\\norm{\\bf{u}}_\\nu = 1} \\norm{A\\bf{u}}_\\mu\n\\end{align*}\n\\]\nSecond, it is not immediately obvious, that there is a vector \\(\\bf{x}\\) for which a supremum is attained. The fact is there is always such a vector \\(\\bf{x}\\). The \\(K=\\{\\bf{u}:\\norm{\\bf{u}}_\\nu = 1\\}\\) is a compact set, and \\(\\norm{\\cdot}_\\mu : \\C^m \\to \\R\\) is a continuous function. Continuous functions preserve compact sets. So, the supremum exists and further it belongs to \\(\\{A\\bf{x}:\\norm{\\bf{x}}_\\nu = 1\\}\\).\n\nTheorem 11 The induced matrix norm \\(\\norm{\\cdot}_{\\mu,\\nu} : \\C^{m \\times n} \\to \\R\\) is a well-defined norm.\n\nProof\nTo prove this, we merely check if the three conditions are met:\nLet \\(A,B \\in \\C^{m \\times n}\\) and \\(\\alpha \\in \\C\\) be arbitrarily chosen. Then:\nPositive definite\nLet \\(A \\neq 0\\). That means, at least one of the columns of \\(A\\) is not a zero-vector. Partition \\(A\\) by columns:\n\\[\n\\left[\n    \\begin{array}{c|c|c|c}\n        a_{1} & a_2 & \\ldots & a_{n}\n    \\end{array}\n\\right]\n\\]\nLet us assume that, it is the \\(j\\)-th column \\(a_j\\), that is non-zero. Let \\(\\bf{e}_j\\) be the column of \\(I\\)(the identity matrix) indexed with \\(j\\). Then:\n\\[\n\\begin{align*}\n\\norm{A}_{\\mu,\\nu} &= \\sup \\frac{\\norm{A\\bf{x}}_\\mu}{\\norm{\\bf{x}}_\\nu} & \\{ \\text{ Definition }\\}\\\\\n&\\geq \\frac{\\norm{A\\bf{e}_j}_\\mu}{\\norm{\\bf{e}_j}_\\nu}\\\\\n&= \\frac{\\norm{a_j}_\\mu}{\\norm{\\bf{e}_j}_\\nu} & \\{ A\\bf{e}_j = a_j \\}\\\\\n&&gt; 0 & \\{ \\text{ we assumed } a_j \\neq \\bf{0}\\}\n\\end{align*}\n\\]\nHomogeneity\nWe have:\n\\[\n\\begin{align*}\n\\norm{\\alpha A}_{\\mu,\\nu} &= \\sup_{\\bf{x}\\neq \\bf{0}} \\frac{\\norm{\\alpha A \\bf{x}}_\\mu}{\\norm{\\bf{x}}_\\nu} & \\{ \\text{ Definition }\\}\\\\\n&= \\sup_{\\bf{x}\\neq \\bf{0}} \\frac{|\\alpha|\\norm{A\\bf{x}}_\\mu}{\\norm{\\bf{x}}_\\nu} & \\{ \\text{ Homogeneity of vector norm }\\norm{\\cdot}_\\mu\\}\\\\\n&= |\\alpha|\\sup_{\\bf{x}\\neq \\bf{0}} \\frac{\\norm{A\\bf{x}}_\\mu}{\\norm{\\bf{x}}_\\nu} & \\{ \\text{ Algebra }\\}\\\\\n&= |\\alpha|\\norm{A}_{\\mu,\\nu}\n\\end{align*}\n\\]\nTriangle Inequality\nWe have:\n\\[\n\\begin{align*}\n\\norm{A + B}_{\\mu,\\nu} &= \\max_{\\bf{x}\\neq \\bf{0}} \\frac{\\norm{(A + B) \\bf{x}}_\\mu}{\\norm{\\bf{x}}_\\nu} & \\{ \\text{ Definition }\\}\\\\\n&= \\max_{\\bf{x}\\neq \\bf{0}} \\frac{\\norm{(A\\bf{x} + B\\bf{x})}_\\mu}{\\norm{\\bf{x}}_\\nu} & \\{ \\text{ Distribute }\\}\\\\\n&\\leq \\max_{\\bf{x}\\neq \\bf{0}} \\frac{\\norm{(A\\bf{x}}_\\mu + \\norm{B\\bf{x}}_\\mu}{\\norm{\\bf{x}}_\\nu} & \\{ \\text{ Triangle inequality for vector norms }\\}\\\\\n&= \\max_{\\bf{x}\\neq \\bf{0}} \\left(\\frac{\\norm{(A\\bf{x}}_\\mu}{\\norm{\\bf{x}}_\\nu} + \\frac{\\norm{(A\\bf{x}}_\\mu}{\\norm{\\bf{x}}_\\nu} \\right) & \\{ \\text{ Algebra }\\}\\\\\n&= \\max_{\\bf{x}\\neq \\bf{0}} \\frac{\\norm{(A\\bf{x}}_\\mu}{\\norm{\\bf{x}}_\\nu} + \\max_{\\bf{x}\\neq \\bf{0}} \\frac{\\norm{(A\\bf{x}}_\\mu}{\\norm{\\bf{x}}_\\nu} \\\\\n&= \\norm{A}_{\\mu,\\nu} + \\norm{B}_{\\mu,\\nu} & \\{ \\text{ Definition }\\}\n\\end{align*}\n\\]\nThis closes the proof. \\(\\blacksquare\\)\nWhen \\(\\norm{\\cdot}_\\mu\\) and \\(\\norm{\\cdot}_\\nu\\) are the same norm, the induced norm becomes:\n\\[\n\\norm{A}_\\mu = \\max_{\\bf{x}\\neq\\bf{0}} \\frac{\\norm{A\\bf{x}}_\\mu}{\\norm{\\bf{x}}_\\mu}\n\\]\nor equivalently:\n\\[\n\\norm{A}_\\mu = \\max_{\\norm{\\bf{u}}_\\mu = 1} \\norm{A\\bf{u}}_\\mu\n\\]\n\nExample 1 Consider the vector \\(p\\)-norm \\(\\norm{\\cdot}_p:\\C^n \\to \\R\\) and let us denote the induced matrix norm \\(|||\\cdot|||:\\C^{m \\times n} \\to \\R\\) by \\(|||A||| = \\max_{\\bf{x}\\neq\\bf{0}}\\frac{\\norm{A\\bf{x}}_p}{\\norm{\\bf{x}}_p}\\). Prove that \\(|||\\bf{y}||| = \\norm{\\bf{y}}_p\\) for all \\(\\bf{y}\\in\\C^m\\).\n\nProof.\nWe have:\n\\[\n\\begin{align*}\n|||\\bf{y}||| &= \\frac{\\norm{\\bf{y}x}_p}{\\norm{x}_p} & \\{ \\text{ Definition }\\}\\\\\n&= \\frac{|x_1| \\norm{\\bf{y}}_p}{|x_1|} & \\{ x \\text{ has to be } 1 \\times 1, \\text{ a scalar }\\}\\\\\n&= \\norm{\\bf{y}}_p\n\\end{align*}\n\\]\nThe last example is important. One can view a vector \\(\\bf{y}\\in \\C^m\\) as an \\(m \\times 1\\) matrix. What this last exercise tells us is that regardless of whether we view \\(\\bf{y}\\) as a matrix or a vector, \\(\\norm{y}_p\\) is the same.\nWe already encountered the vector \\(p\\)-norms as an important class of vector norms. The matrix \\(p\\)-norm is induced by the corresponding vector norm.\n\nDefinition 10 (The matrix \\(p\\)-norm) For any vector \\(p\\)-norm, define the corresponding matrix \\(p\\)-norm \\(\\norm{\\cdot}_p : \\C^{m \\times n} \\to \\R\\) by:\n\\[\n\\norm{A}_p = \\max_{\\bf{x}\\neq\\bf{0}} \\frac{\\norm{A\\bf{x}}_p}{\\norm{\\bf{x}}_p} \\quad \\text{ or equivalently } \\quad \\norm{A}_p = \\max_{\\norm{\\bf{x}}_p = 1} \\norm{A\\bf{x}}_p\n\\]\n\nIn practice, the matrix \\(2\\)-norm is of great theoretical importance, but difficult to evaluate, except for special matrices. The \\(1\\)-norm, the \\(\\infty\\)-norm and Frobenius norms are straightforward and relatively cheap to compute.\nLet us instantiate the definition of the vector \\(p\\)-norm where \\(p=2\\), giving us a matrix norm induced by the vector \\(2\\)-norm or the Euclidean norm:\n\nDefinition 11 (The matrix \\(2\\)-norm) Define the matrix \\(2\\)-norm \\(\\norm{\\cdot}_2:\\C^{m \\times n} \\to \\R\\) by :\n\\[\n\\norm{A}_2 = \\max_{\\bf{x}\\neq\\bf{0}} \\frac{\\norm{A\\bf{x}}_2}{\\norm{\\bf{x}}_2} = \\max_{\\norm{\\bf{x}}_2 = 1} \\norm{A\\bf{x}}_2\n\\]\n\n\n\n\n\n\n\nNote\n\n\n\nThe problem with the matrix \\(2\\)-norm is that it is hard to compute. In future posts, we shall find out that if \\(A\\) is a Hermitian matrix (\\(A = A^H\\)), then \\(\\norm{A}_2 = |\\lambda_1|\\) where \\(\\lambda_1\\) is the eigenvalue of \\(A\\) that is largest in magnitude.\nRecall from basic linear algebra, that computing eigenvalues involves computing the roots of polynomials, and for polynomials of degree three or greater, this is a non-trivial task. We shall see that the matrix \\(2\\)-norm plays an important part in theory, but less so in practical computation.\n\n\n\nExample 2 Show that:\n\\[\n\\norm{\\begin{bmatrix}\nd_1 & 0 \\\\\n0 & d_2\n\\end{bmatrix}}_2 = \\max(|d_1|,|d_2|)\n\\]\n\nSolution\nWe have:\n\\[\n\\begin{align*}\n\\norm{\\begin{bmatrix}\nd_1 & 0 \\\\\n0 & d_2\n\\end{bmatrix}}_2^2 &= \\max_{\\norm{\\bf{x}}_2 = 1} \\norm{\\begin{bmatrix}\nd_1 & 0 \\\\\n0 & d_2\n\\end{bmatrix}\\begin{bmatrix}x_1 \\\\ x_2\\end{bmatrix}}_2^2 & \\{ \\text{ Definition }\\}\\\\\n&= \\max_{\\norm{\\bf{x}}_2 = 1}|d_1x_1|^2 + |d_2 x_2|^2\\\\\n&\\leq \\max_{\\norm{\\bf{x}}_2 = 1} [\\max(|d_1|,|d_2|)^2 |x_1|^2 + \\max(|d_1|,|d_2|)^2 |x_2|^2]\\\\\n&= \\max(|d_1|,|d_2|)^2 \\max_{\\norm{\\bf{x}}_2 = 1} (|x_1|^2 + |x_2|^2)\\\\\n&= \\max(|d_1|,|d_2|)^2\n\\end{align*}\n\\]\nMoreover, if we take \\(\\bf{x} = \\bf{e}_1\\) and \\(\\bf{x}=\\bf{e}_2\\), we get:\n\\[\n\\begin{align*}\n\\norm{\\begin{bmatrix}\nd_1 & 0 \\\\\n0 & d_2\n\\end{bmatrix}}_2^2  &= \\max_{\\norm{\\bf{x}}_2 = 1} \\norm{\\begin{bmatrix}\nd_1 & 0 \\\\\n0 & d_2\n\\end{bmatrix}\\begin{bmatrix}x_1 \\\\ x_2\\end{bmatrix}}_2 & \\{ \\text{ Definition }\\}\\\\\n&\\geq  \\norm{\\begin{bmatrix}\nd_1 & 0 \\\\\n0 & d_2\n\\end{bmatrix}\\begin{bmatrix}1 \\\\ 0\\end{bmatrix}}_2^2 \\\\\n&= |d_1|^2\n\\end{align*}\n\\]\nand\n\\[\n\\begin{align*}\n\\norm{\\begin{bmatrix}\nd_1 & 0 \\\\\n0 & d_2\n\\end{bmatrix}}_2^2  &= \\max_{\\norm{\\bf{x}}_2 = 1} \\norm{\\begin{bmatrix}\nd_1 & 0 \\\\\n0 & d_2\n\\end{bmatrix}\\begin{bmatrix}x_1 \\\\ x_2\\end{bmatrix}}_2 & \\{ \\text{ Definition }\\}\\\\\n&\\geq  \\norm{\\begin{bmatrix}\nd_1 & 0 \\\\\n0 & d_2\n\\end{bmatrix}\\begin{bmatrix}0 \\\\ 1\\end{bmatrix}}_2 \\\\\n&= |d_2|^2\n\\end{align*}\n\\]\nConsequently,\n\\[\n\\norm{\\begin{bmatrix}\nd_1 & 0 \\\\\n0 & d_2\n\\end{bmatrix}}_2^2 \\geq \\max(|d_1|,|d_2|)^2\n\\]\nWe conclude that\n\\[\n\\norm{\\begin{bmatrix}\nd_1 & 0 \\\\\n0 & d_2\n\\end{bmatrix}}_2 = \\max(|d_1|,|d_2|)\n\\]\n\n\n\n\n\n\nTip\n\n\n\nThe proof of the last example builds on a general principle: Showing that \\(\\max_{x \\in D} f(x) = \\alpha\\) for some function \\(f:D \\to \\R\\) can be broken down into showing that both:\n\\[\n\\max_{x \\in D} f(x) \\leq \\alpha\n\\]\nand\n\\[\n\\max_{x \\in D} f(x) \\geq \\alpha\n\\]\nIn turn, showing that \\(\\max_{x \\in D}f(x) \\geq \\alpha\\) can often be accomplished by showing that there exists a vector \\(y \\in D\\) such that \\(f(y) = \\alpha\\) since then\n\\[\n\\max_{x \\in D}f(x) \\geq f(y) = \\alpha\n\\]\nWe will use this technique in future proofs involving matrix norms.\n\n\n\nExercise 1 Let \\(D \\in C^{m \\times m}\\) be a diagonal matrix \\(diag(d_1,d_2,\\ldots,d_m)\\). Show that:\n\\[\n\\norm{D}_2 = \\max_{j=1}^{m} |d_j|\n\\]\n\nSolution.\nWe have:\n\\[\n\\begin{align*}\n\\norm{D}_2^2 &= \\max_{\\norm{\\bf{x}}_2 = 1} \\norm{\n    \\begin{bmatrix}\n    d_1 \\\\\n    & d_2 \\\\\n    & & \\ddots\\\\\n    & & & d_m\n    \\end{bmatrix}\n    \\begin{bmatrix}\n    x_1\\\\\n    x_2\\\\\n    \\vdots\\\\\n    x_m\n    \\end{bmatrix}\n}_2^2 \\{ \\text{ Definition }\\}\\\\\n&=\\max_{\\norm{\\bf{x}}_2 = 1} \\norm{\n    \\begin{bmatrix}\n    d_1 x_1\\\\\n    d_2 x_2\\\\\n    \\vdots\\\\\n    d_m x_m\n    \\end{bmatrix}\n}_2^2\\\\\n&= \\max_{\\norm{\\bf{x}}_2 = 1} \\sum_{j=1}^m |d_j x_j|^2\\\\\n&\\leq \\max_{\\norm{\\bf{x}}_2 = 1} \\sum_{j=1}^m \\max(|d_1|,\\ldots,|d_m|)^2 |x_j|^2\\\\\n&= \\max(|d_1|,\\ldots,|d_m|)^2 \\max_{\\norm{\\bf{x}}_2 = 1} \\sum_{j=1}^m |x_j|^2 \\\\\n&= \\max(|d_1|,\\ldots,|d_m|)^2\n\\end{align*}\n\\]\nMoreover, if we take take \\(\\bf{x} = \\bf{e}_j\\), the standard basis vector with its \\(j\\)-th coordinate equal to one, we find that\n\\[\n\\norm{D}_2^2 \\geq |d_j|^2\n\\]\nConsequently, \\(\\norm{D}_2^2 \\geq \\max(|d_1|,\\ldots,|d_m|)^2\\).\nThis closes the proof. \\(\\blacksquare\\)\n\nExercise 2 Let \\(\\bf{y}\\in\\C^m\\) and \\(\\bf{x} \\in \\C^n\\). Show that:\n\\[\n\\norm{\\bf{y}\\bf{x}^H}_2 = \\norm{\\bf{y}}_2 \\norm{\\bf{x}}_2\n\\]\n\nProof.\nFrom the Cauchy-Schwarz inequality, we know that:\n\\[\n|x^H z| \\leq \\norm{\\bf{x}^H}_2 \\norm{\\bf{z}}_2\n\\]\nNow, \\(\\bf{x}^H \\in \\C^{1 \\times n}\\) and \\(\\bf{z} \\in \\C^{n \\times 1}\\). So, \\(\\bf{x}^H \\bf{z} \\in \\C^{1 \\times 1}\\), and it is a scalar.\n\\[\n\\begin{align*}\n\\norm{\\bf{y}\\bf{x}^H}_2 &= \\max_{\\norm{\\bf{z}}_2 = 1} \\norm{\\bf{y}\\bf{x}^H \\bf{z}}_2 \\\\\n&= \\max_{\\norm{\\bf{z}}_2 = 1} |\\bf{x}^H \\bf{z}| \\norm{\\bf{y}}_2 \\{ \\bf{x}^H\\bf{z}\\text{ is scalar }\\}\\\\\n&\\leq \\max_{\\norm{\\bf{z}}_2 = 1} \\norm{\\bf{x}^H}_2 \\norm{\\bf{z}}_2 \\norm{\\bf{y}}_2 \\\\\n&= \\norm{\\bf{x}}_2 \\norm{\\bf{y}}_2\n\\end{align*}\n\\]\nOn the other hand,\n\\[\n\\begin{align*}\n\\norm{\\bf{y}\\bf{x}^H}_2 &= \\max_{\\bf{z}\\neq \\bf{0}} \\frac{\\norm{\\bf{y}\\bf{x}^H \\bf{z}}_2}{\\norm{\\bf{z}}_2}\\\\\n&\\geq \\frac{\\norm{\\bf{y}\\bf{x}^H \\bf{x}}_2}{\\norm{\\bf{x}}_2} & \\{ \\text{ Specific }\\bf{z} \\}\\\\\n&= \\frac{\\norm{\\bf{y}\\norm{\\bf{x}}_2^2}_2}{\\norm{\\bf{x}}_2} & \\{ \\bf{x}^H \\bf{x} = \\norm{\\bf{x}}_2^2\\}\\\\\n&= \\norm{\\bf{y}}_2 \\norm{\\bf{x}}_2\n\\end{align*}\n\\]\nThis closes the proof. \\(\\blacksquare\\)\n\nExercise 3 Let \\(A \\in \\C^{m \\times n}\\) and \\(a_j\\) be its column indexed with \\(j\\). Prove that:\n\\[\n\\norm{a_j}_2 \\leq \\norm{A}_2\n\\]\n\nProof.\nWe have:\n\\[\n\\begin{align*}\n\\norm{A}_2 &= \\max_{\\norm{\\bf{z}}_2 = 1} \\norm{A\\bf{z}}_2 \\\\\n&\\geq  \\norm{A\\bf{e}_j}_2\\\\\n&= \\norm{a_j}_2\n\\end{align*}\n\\]\nThis closes the proof. \\(\\blacksquare\\)\n\nExercise 4 Let \\(A \\in \\C^{m \\times n}\\). Prove that:\n\n\\[\n\\norm{A}_2 = \\max_{\\norm{\\bf{x}}_2 = \\norm{\\bf{y}}_2 = 1} |\\bf{y}^H A \\bf{x}|\n\\]\n\\[\n\\norm{A^H}_2 = \\norm{A}_2\n\\]\n\\[\n\\norm{A^H A}_2 = \\norm{A}_2^2\n\\]\n\n\nClaim.\n\\[\n\\norm{A}_2 = \\max_{\\norm{\\bf{x}}_2 = \\norm{\\bf{y}}_2 = 1} |\\bf{y}^H A \\bf{x}|\n\\]\nProof.\nWe have:\n\\[\n\\begin{align*}\n\\max_{\\norm{\\bf{x}}_2 = \\norm{\\bf{y}}_2 = 1} |\\bf{y}^H A \\bf{x}| &\\leq \\max_{\\norm{\\bf{x}}_2 = \\norm{\\bf{y}}_2 = 1} \\norm{\\bf{y}^H}_2 \\norm{A\\bf{x}}_2 & \\{ \\text{ Cauchy-Schwarz }\\} \\\\\n&= \\max_{\\norm{\\bf{x}}_2 } \\norm{A\\bf{x}}_2\\\\\n&= \\norm{A}_2\n\\end{align*}\n\\]\nOn the other hand:\n\\[\n\\begin{align*}\n\\max_{\\norm{\\bf{x}}_2 = \\norm{\\bf{y}}_2 = 1} |\\bf{y}^H A \\bf{x}| &\\geq \\max_{\\norm{\\bf{x}}_2 = 1} |\\left(\\frac{A\\bf{x}}{\\norm{A\\bf{x}}_2}\\right)^H A \\bf{x}| & \\{\\text{ Specific vector }\\}\\\\\n&= \\max_{\\norm{\\bf{x}}_2 = 1} \\frac{\\norm{A\\bf{x}}_2^2}{\\norm{A\\bf{x}}_2}\\\\\n&=\\max_{\\norm{\\bf{x}}_2 = 1} \\norm{A\\bf{x}}_2\\\\\n&= \\norm{A}_2\n\\end{align*}\n\\]\nWe have the desired result.\nClaim.\n\\[\n\\norm{A^H}_2 = \\norm{A}_2\n\\]\nProof.\nWe have:\n\\[\n\\begin{align*}\n\\norm{A^H}_2^2 &= \\max_{\\norm{\\bf{x}}_2 = 1} \\norm{A^H\\bf{x}}_2^2 \\\\\n&= \\max_{\\norm{\\bf{x}}_2 = 1} |(A^H \\bf{x})^H (A^H \\bf{x})|\n\\end{align*}\n\\]\nClaim.\n\\[\n\\norm{A^H}_2 = \\norm{A}_2\n\\]\nProof.\nWe have:\n\\[\n\\begin{align*}\n\\norm{A^H}_2 &= \\max_{\\norm{\\bf{x}}_2 = \\norm{\\bf{y}}_2 = 1} |\\bf{y}^H A^H \\bf{x}| \\\\\n&= \\max_{\\norm{\\bf{x}}_2 = \\norm{\\bf{y}}_2 = 1} |\\bf{x}^H A \\bf{y}| & \\{ |\\overline \\alpha| = |\\alpha| \\}\\\\\n&= \\max_{\\norm{\\bf{y}}_2 = 1} \\norm{A \\bf{y}}_2 \\\\\n&= \\norm{A}_2\n\\end{align*}\n\\]\nClaim\n\\[\n\\norm{A^H A}_2 = \\norm{A}_2^2\n\\]\nProof.\nWe have:\n\\[\n\\begin{align*}\n\\norm{A^H A}_2 &= \\max_{\\norm{\\bf{x}}_2 = \\norm{\\bf{y}}_2 = 1} |\\bf{y}^H A^H A \\bf{x}|\\\\\n&\\leq \\max_{\\norm{\\bf{x}}_2 = \\norm{\\bf{y}}_2 = 1} \\norm{\\bf{y}^H A^H}_2 \\norm{A\\bf{x}}_2 & \\{ \\text{ Cauchy-Schwarz }\\}\\\\\n&= \\max_{\\norm{\\bf{y}}_2 = 1} \\norm{A\\bf{y}}_2 \\max_{\\norm{\\bf{x}}_2 = 1} \\norm{A\\bf{x}}_2  & \\{ \\norm{A^H}_2 = \\norm{A}_2 \\}\\\\\n&= \\norm{A}_2^2\n\\end{align*}\n\\]\nMoreover:\n\\[\n\\begin{align*}\n\\norm{A^H A}_2 &= \\max_{\\norm{\\bf{x}}_2 = \\norm{\\bf{y}}_2 = 1} |\\bf{y}^H A^H A \\bf{x}|\\\\\n&\\geq \\max_{\\norm{\\bf{x}}_2 = 1}  |\\bf{x}^H A^H A \\bf{x}| \\{ \\text{ Restrict the choices of }\\bf{y}\\}\\\\\n&=  \\max_{\\norm{\\bf{x}}_2 = 1}  |(A\\bf{x})^H (A \\bf{x})| \\\\\n&=  \\max_{\\norm{\\bf{x}}_2 = 1}  \\norm{A\\bf{x}}_2^2\\\\\n&= \\norm{A}_2^2\n\\end{align*}\n\\]\n\nExercise 5 Partition\n\\[\nA = \\left[\n    \\begin{array}{c|c|c}\n        A_{1,1} & \\ldots & A_{1,N}\\\\\n        \\hline\n        \\vdots & & \\vdots\\\\\n        \\hline\n        A_{M,1} & \\ldots & A_{M,N}\n    \\end{array}\n\\right]\n\\]\nProve that \\(\\norm{A_{i,j}}_2 \\leq \\norm{A}_2\\).\n\nProof.\nBy definition,\n\\[\n\\begin{align*}\n\\norm{A_{i,j}}_2 = \\max_{\\norm{\\bf{x}}_2 = \\norm{\\bf{y}}_2 = 1} |\\bf{y}^H A_{i,j} \\bf{x}|\n\\end{align*}\n\\]\nSince \\(\\norm{\\bf{x}}_2 = \\norm{\\bf{y}}_2 = 1\\) is a compact set, the above maximum exists. There exists \\(\\bf{w}_i\\) and \\(\\bf{v}_j\\), satisfying \\(\\norm{\\bf{w}_i}_2 = \\norm{\\bf{v}_j}_2 = 1\\) such that:\n\\[\n\\begin{align*}\n\\norm{A_{i,j}}_2 = |\\bf{w}_i^H A_{i,j} \\bf{v}_j|\n\\end{align*}\n\\]\nNext, we choose\n\\[\n\\bf{w} = \\left[\n    \\begin{array}{c}\n    0 \\\\\n    \\hline\n    0 \\\\\n    \\hline\n    \\vdots \\\\\n    \\hline\n    \\bf{w}_i\\\\\n    \\hline\n    0 \\\\\n    \\hline\n    \\vdots\\\\\n    0\n    \\end{array}\n\\right] \\quad\n\\bf{v} = \\left[\n    \\begin{array}{c}\n    0 \\\\\n    \\hline\n    0 \\\\\n    \\hline\n    \\vdots \\\\\n    \\hline\n    \\bf{v}_j\\\\\n    \\hline\n    0 \\\\\n    \\hline\n    \\vdots\\\\\n    0\n    \\end{array}\n\\right]\n\\]\nConsider:\n\\[\n\\begin{align*}\n\\norm{A}_2 &= \\max_{\\norm{\\bf{x}}_2 = \\norm{\\bf{y}}_2 = 1} |\\bf{y}^H A \\bf{x}|\\\\\n& \\geq |\\bf{w}^H A \\bf{v}|\\\\\n&= |\\bf{w}_j^H A_{i,j} \\bf{v}_i|\\\\\n&= \\norm{A_{i,j}}_2\n\\end{align*}\n\\]\nThis closes the proof. \\(\\blacksquare\\)\n\n\nComputing the matrix \\(1\\)-norm and \\(\\infty\\)-norm\nThe matrix \\(1\\)-norm and the matrix \\(\\infty\\)-norm are of great importance, because, unlike the matrix \\(2\\)-norm, they are easy and relatively cheap to compute. The following exercises show how to practically compute the matrix \\(1\\)-norm and \\(\\infty\\)-norm.\n\nExercise 6 Let \\(A = \\C^{m \\times n}\\) and partition \\(A = [a_1 | a_2 | \\ldots | a_n]\\). Prove that\n\\[\n\\norm{A}_1 = \\max_{1 \\leq j \\leq n}\\norm{a_j}_1\n\\]\n\nProof\nWe have:\n\\[\n\\begin{align*}\n\\norm{A}_1 &= \\max_{\\norm{\\bf{x}}_1 = 1} \\norm{A\\bf{x}}_1 & \\{ \\text{ Definition }\\}\\\\\n&= \\max_{\\norm{\\bf{x}}_1 = 1} \\norm{a_1 x_1 + a_2 x_2 + \\ldots + a_n x_n}_1 & \\{ \\text{ Algebra }\\}\\\\\n&\\leq \\max_{\\norm{\\bf{x}}_1 = 1} \\norm{a_1 x_1}_1 + \\norm{a_2 x_2}_1 + \\ldots + \\norm{a_n x_n}_1 & \\{ \\text{ Triangle Inequality }\\}\\\\\n&= \\max_{\\norm{\\bf{x}}_1 = 1} |x_1| \\norm{a_1}_1 + |x_2| \\norm{a_2}_1 + \\ldots + |x_n| \\norm{a_n}_1  & \\{ \\text{ Homogeneity }\\}\\\\\n&= \\max_{\\norm{\\bf{x}}_1 = 1}  |x_1| (\\max_{1 \\leq j \\leq n} \\norm{a_j}_1) + |x_2| (\\max_{1 \\leq j \\leq n} \\norm{a_j}_1)+ \\ldots + |x_n| (\\max_{1 \\leq j \\leq n} \\norm{a_j}_1)\\\\\n&= \\max_{1 \\leq j \\leq n} \\norm{a_j}_1 \\max_{\\norm{\\bf{x}}_1 = 1} \\sum_{j=1}^n |x_j|\\\\\n&= \\max_{1 \\leq j \\leq n} \\norm{a_j}_1\n\\end{align*}\n\\]\nOn the other hand,\n\\[\n\\begin{align*}\n\\norm{A}_1  &= \\max_{\\norm{\\bf{x}}_1 = 1} \\norm{A\\bf{x}}_1 & \\{ \\text{ Definition }\\}\\\\\n&\\geq \\norm{A\\bf{e}_j}_1 & \\{ \\text{ Specific vector }\\}\\\\\n&= \\norm{a_j}_1\n\\end{align*}\n\\]\nThis concludes the proof. \\(\\blacksquare\\)\n\nExercise 7 Let \\(A = \\C^{m \\times n}\\) and partition\n\\[\nA = \\left[\n    \\begin{array}{c}\n        \\tilde{a}_0^T\\\\\n        \\hline\n        \\tilde{a}_1^T\\\\\n        \\hline\n        \\vdots\\\\\n        \\hline\n        \\tilde{a}_{m-1}^T\\\\\n    \\end{array}\n\\right]\n\\]\nProve that\n\\[\n\\norm{A}_\\infty = \\max_{0\\leq i &lt; m} \\norm{\\tilde{a}_i}_1 = \\max_{0 \\leq i &lt; m} (|\\alpha_{i,0}| + |\\alpha_{i,1}| + \\ldots + |\\alpha_{i,n-1}|)\n\\]\n\n*Notice that in this exercise, \\(\\tilde{a}_i\\) is really \\((\\tilde{a}_i^T)^T\\), since \\(\\tilde{a}_i^T\\) is the label for the \\(i\\)-th row of the matrix.\nProof.\nWe have:\n\\[\n\\begin{align*}\n\\norm{A}_\\infty &= \\max_{\\norm{\\bf{x}}_\\infty = 1} \\norm{A\\bf{x}}_\\infty & \\{ \\text{ Definition }\\} \\\\\n&= \\max_{\\norm{\\bf{x}}_\\infty = 1} \\norm{\\left[\n    \\begin{array}{c}\n        \\tilde{a}_0^T \\bf{x}\\\\\n        \\hline\n        \\tilde{a}_1^T \\bf{x}\\\\\n        \\hline\n        \\vdots\\\\\n        \\hline\n        \\tilde{a}_{m-1}^T \\bf{x}\\\\\n    \\end{array}\n\\right]}_\\infty & \\{ \\text{ Algebra }\\}\\\\\n&=  \\max_{\\norm{\\bf{x}}_\\infty = 1} \\max_{0 \\leq i &lt; m} |\\tilde{a}_i^T \\bf{x}|\\\\\n&=  \\max_{\\norm{\\bf{x}}_\\infty = 1} \\max_{0 \\leq i &lt; m} |\\alpha_{i,0}x_0 + \\ldots + \\alpha_{i,n-1}x_{n-1}|\\\\\n&\\leq  \\max_{\\norm{\\bf{x}}_\\infty = 1} \\max_{0 \\leq i &lt; m} \\left( |\\alpha_{i,0}x_0 | + \\ldots + |\\alpha_{i,n-1}x_{n-1}| \\right) & \\{ \\text{ Triangle Inequality }\\}\\\\\n&=  \\max_{\\norm{\\bf{x}}_\\infty = 1} \\max_{0 \\leq i &lt; m} \\left( |\\alpha_{i,0}||x_0 | + \\ldots + |\\alpha_{i,n-1}||x_{n-1}| \\right) & \\{ \\text{ Algebra }\\}\\\\\n&\\leq \\max_{\\norm{\\bf{x}}_\\infty = 1} \\max_{0 \\leq i &lt; m}\\left( |\\alpha_{i,0}|\\norm{\\bf{x}}_\\infty + \\ldots + |\\alpha_{i,n-1}|\\norm{\\bf{x}}_\\infty \\right) & \\{ |x_i| \\leq \\norm{\\bf{x}}_\\infty \\}\\\\\n&= \\max_{0 \\leq i &lt; m} ( |\\alpha_{i,0}| + \\ldots + |\\alpha_{i,n-1}|) \\max_{\\norm{\\bf{x}}_\\infty = 1} \\norm{\\bf{x}}_\\infty\\\\\n&= \\max_{0 \\leq i &lt; m} ( |\\alpha_{i,0}| + \\ldots + |\\alpha_{i,n-1}|)\\\\\n&= \\max_{0 \\leq i &lt; m}\n\\norm{\\tilde{a}_i}_1\n\\end{align*}\n\\]\nWe also want to show that \\(\\norm{A}_\\infty \\geq \\max_{0 \\leq i &lt; m} \\norm{\\tilde{a}_i}_1\\). Let \\(k\\) be such that \\(\\max_{0 \\leq i &lt; m}\\norm{\\tilde{a}_i}_1 = \\norm{\\tilde{a}_k}_1\\) and pick \\(\\bf{y} = \\left(\\begin{array}{c}\\psi_0\\\\ \\vdots\\\\ \\psi_{n-1}\\end{array}\\right)\\) so that \\(\\tilde{a}_k^T \\bf{y} = |\\alpha_{k,0}| + |\\alpha_{k,1}| + \\ldots + |\\alpha_{k,n-1}|=\\norm{\\tilde{a}_k}_1\\). This is a matter of picking \\(\\psi_j = |\\alpha_{k,j}|/\\alpha_{k,j}\\). Then, \\(|\\psi_j| = 1\\) and hence, \\(\\norm{\\bf{y}}_\\infty = 1\\) and \\(\\psi_j \\alpha_{k,j} = |\\alpha_{k,j}|\\). Then:\n\\[\n\\begin{align*}\n\\norm{A}_\\infty &= \\max_{\\norm{\\bf{x}}_\\infty = 1} \\norm{A\\bf{x}}_\\infty & \\{ \\text{ Definition }\\} \\\\\n&= \\max_{\\norm{\\bf{x}}_\\infty = 1} \\norm{\\left[\n    \\begin{array}{c}\n        \\tilde{a}_0^T \\bf{x}\\\\\n        \\hline\n        \\tilde{a}_1^T \\bf{x}\\\\\n        \\hline\n        \\vdots\\\\\n        \\hline\n        \\tilde{a}_{m-1}^T \\bf{x}\\\\\n    \\end{array}\n\\right]}_\\infty & \\{ \\text{ Expose rows }\\}\\\\\n&\\geq  \\norm{\\left[\n    \\begin{array}{c}\n        \\tilde{a}_0^T \\bf{y}\\\\\n        \\hline\n        \\tilde{a}_1^T \\bf{y}\\\\\n        \\hline\n        \\vdots\\\\\n        \\hline\n        \\tilde{a}_{m-1}^T \\bf{y}\\\\\n    \\end{array}\n\\right]}_\\infty & \\{ \\text{ Specific vector }\\}\\\\\n&\\geq |\\tilde{a}_k^T \\bf{y}|\\\\\n&= \\norm{\\tilde{a}_k}_1 \\\\\n&= \\max_{0 \\leq i &lt; m} \\norm{\\tilde{a}_i}_1\n\\end{align*}\n\\]\nThis closes the proof. \\(\\blacksquare\\)\n\nExercise 8 Fill out the following table:\n\\[\n\\begin{array}{|c|c|c|c|}\n\\hline\nA & \\norm{A}_1 & \\norm{A}_\\infty & \\norm{A}_F & \\norm{A}_2\\\\\n\\hline\n\\begin{bmatrix}\n1 & 0 & 0 \\\\\n0 & 1 & 0 \\\\\n0 & 0 & 1\n\\end{bmatrix}\\\\\n\\hline\n\\begin{bmatrix}\n1 & 1 & 1\\\\\n1 & 1 & 1\\\\\n1 & 1 & 1\\\\\n1 & 1 & 1\n\\end{bmatrix}\\\\\n\\hline\n\\begin{bmatrix}\n0 & 1 & 0\\\\\n0 & 1 & 0\\\\\n0 & 1 & 0\n\\end{bmatrix}\\\\\n\\hline\n\\end{array}\n\\]\n\nSolution.\nLet\n\\[\nA = \\begin{bmatrix}\n1 & 0 & 0 \\\\\n0 & 1 & 0 \\\\\n0 & 0 & 1\n\\end{bmatrix}\n\\]\nWe have, \\(\\norm{A}_1 = 1\\), \\(\\norm{A}_\\infty = 1\\), \\(\\norm{A}_F = \\sqrt{3}\\). Since this is a diagonal matrix, \\(\\norm{A}_2 = \\max_{0 \\leq i \\leq 2} |d_{i}|\\) = 1.\nNext, consider:\n\\[\n\\begin{bmatrix}\n1 & 1 & 1\\\\\n1 & 1 & 1\\\\\n1 & 1 & 1\\\\\n1 & 1 & 1\n\\end{bmatrix}\n\\]\nWe have, \\(\\norm{A}_1 = 4\\), \\(\\norm{A}_\\infty = 3\\), \\(\\norm{A}_F = \\sqrt{12}\\).\nNote that, we can write\n\\[\nA = \\begin{bmatrix}\n1 \\\\\n1 \\\\\n1 \\\\\n1 \\\\\n\\end{bmatrix} [1, 1, 1, 1] = \\bf{x}\\bf{y}^H\n\\]\nwhere \\(\\bf{x} = \\bf{y} = \\begin{bmatrix} 1 \\\\ 1 \\\\ 1 \\\\ 1 \\\\ \\end{bmatrix}\\). Using the property that, \\(\\norm{\\bf{x}\\bf{y}^H}_2 = \\norm{\\bf{x}}_2 \\norm{\\bf{y}}_2\\), we have that, \\(\\norm{A}_2 = 4\\).\nFinally, if\n\\[\nA = \\begin{bmatrix}\n0 & 1 & 0\\\\\n0 & 1 & 0\\\\\n0 & 1 & 0\n\\end{bmatrix}\n\\]\nwe find that \\(\\norm{A}_1 = 3\\), \\(\\norm{A}_\\infty = 1\\), \\(\\norm{A}_F = \\sqrt{3}\\). Finally, let \\(\\bf{x} = \\begin{bmatrix}1 \\\\ 1 \\\\ 1\\end{bmatrix}\\) and \\(\\bf{y} = \\begin{bmatrix}0 \\\\ 1 \\\\ 0\\end{bmatrix}\\). Then, \\(A = \\bf{x}\\bf{y}^H\\). So, \\(\\norm{A}_2 = \\norm{\\bf{x}}_2 \\norm{\\bf{y}}_2 = \\sqrt{3}\\).\n\n\nEquivalence of matrix norms\nWe saw that vector norms are equivalent in the sense that if a vector is small in one norm, it is small in all other norms and if it is large in one norm, it is large in all other norms. The same is true for matrix norms.\n\nTheorem 12 (Equivalence of matrix norms) Let \\(\\norm{\\cdot} : \\C^{m \\times n} \\to \\R\\) and \\(|||\\cdot|||:\\C^{m \\times n} \\to \\R\\) both be matrix norms. Then, there exist positive scalars \\(\\sigma\\) and \\(\\tau\\) such that for all \\(A \\in \\C^{m \\times n}\\)\n\\[\n\\sigma \\norm{A} \\leq |||A||| \\leq \\tau \\norm{A}\n\\]\n\nProof.\nThe proof again builds on the fact that the supremum over a compact set is achieved and can be replaced by the maximum. We will prove that there exists \\(\\tau\\) such that for all \\(A \\in \\C^{m \\times n}\\)\n\\[\n|||A||| \\leq \\tau \\norm{A}\n\\]\nLet \\(A \\in \\C^{m \\times n}\\) be an arbitrary matrix. Assume that \\(A \\neq 0\\) (the zero matrix). Then:\n\\[\n\\begin{align*}\n|||A||| &= \\frac{|||A|||}{\\norm{A}} \\cdot \\norm{A} & \\{\\text{Algebra}\\}\\\\\n&\\leq \\sup_{Z \\neq 0} \\left(\\frac{|||Z|||}{\\norm{Z}}\\right) \\norm{A} & \\{\\text{Definition of supremum}\\}\\\\\n&= \\sup_{Z \\neq 0} \\left(\\Biggl|\\Biggl|\\Biggl|\\frac{Z}{\\norm{Z}}\\Biggr|\\Biggr|\\Biggr|\\right) \\norm{A} & \\{\\text{Homogeneity}\\}\\\\\n&= \\left(\\sup_{\\norm{B} = 1} |||B||| \\right) \\norm{A} &\\{ \\text{change of variables }B=Z/\\norm{Z}\\}\\\\\n&= \\left(\\max_{\\norm{B}=1}|||B|||\\right) \\norm{A} & \\{\\text{the set }\\norm{B} = 1\\text{ is compact}\\}\n\\end{align*}\n\\]\nSo, we can choose \\(\\tau = \\max_{\\norm{B}=1} |||B|||\\).\nAlso, from the above proof, we deduce that, there exists \\(\\sigma\\) given by:\n\\[\n\\sigma = \\frac{1}{\\max_{|||B|||=1}||B||}\n\\]\nsuch that:\n\\[\n\\sigma \\norm{A} \\leq |||A|||\n\\]\nThis closes the proof. \\(\\blacksquare\\)\n\nExercise 9 Given \\(A \\in \\C^{m \\times n}\\), show that \\(\\norm{A}_2 \\leq \\norm{A}_F\\). For what matrix, is the equality attained?\n\nSolution.\nWe have:\n\\[\n\\begin{align*}\n\\norm{A}_2^2 &= \\max_{\\norm{x}_2 = 1} \\norm{Ax}_2^2  & \\{\\text{Definition}\\}\\\\\n&= \\max_{\\norm{x}_2 = 1} \\norm{\\begin{bmatrix}\n\\sum_{j=0}^{n-1} a_{0,j} x_j \\\\\n\\sum_{j=0}^{n-1} a_{1,j} x_j \\\\\n\\vdots\\\\\n\\sum_{j=0}^{n-1} a_{m-1,j} x_j\n\\end{bmatrix}\n}_2^2\\\\\n&= \\max_{\\norm{x}_2 = 1} \\sum_{i=0}^{m-1} \\Biggl|\\sum_{j=0}^{n-1} a_{i,j} x_j\\Biggr|^2\\\\\n&\\leq \\max_{\\norm{x}_2 = 1} \\sum_{i=0}^{m-1} \\left(\\sum_{j=0}^{n-1} |a_{i,j} x_j|\\right)^2 & \\{\\text{Triangle Inequality}\\}\\\\\n&\\leq \\max_{\\norm{x}_2 = 1} \\sum_{i=0}^{m-1} \\left\\{\\left(\\sum_{j=0}^{n-1} |a_{i,j}|^2\\right)^{1/2} \\left(\\sum_{j=0}^{n-1}|x_j|^2\\right)^{1/2}\\right\\}^2 & \\{\\text{Cauchy-Schwarz}\\}\\\\\n&=\\max_{\\norm{x}_2 = 1} \\sum_{i=0}^{m-1} \\left(\\sum_{j=0}^{n-1} |a_{i,j}|^2\\right) \\left(\\sum_{j=0}^{n-1}|x_j|^2\\right) & \\{\\text{Simplify}\\}\\\\\n&=\\sum_{i=0}^{m-1} \\left(\\sum_{j=0}^{n-1} |a_{i,j}|^2\\right) & \\{\\norm{x}_2 = 1\\}\\\\\n&= \\norm{A}_F\n\\end{align*}\n\\]\nAlso, consider\n\\[A = \\begin{bmatrix}1 & 0 \\\\ 0 & 0\\end{bmatrix}\\]\nThen, \\(\\norm{A}_2 = \\norm{A}_F = 1\\). So, the inequality \\(\\norm{A}_2 \\leq \\norm{A}_F\\) is tight. This closes the proof. \\(\\blacksquare\\)\n\nExercise 10 Let \\(A \\in \\C^{m \\times n}\\). The following table summarizes the equivalences of various matrix norms:\n\\[\n\\begin{array}{c|c|c|c}\n& \\norm{A}_1 \\leq \\sqrt{m}\\norm{A}_2 & \\norm{A}_1 \\leq m \\norm{A}_\\infty & \\norm{A}_1 \\leq \\sqrt{m}\\norm{A}_F \\\\\n\\hline\n\\norm{A}_2 \\leq \\sqrt{n}\\norm{A}_1 & & \\norm{A}_2 \\leq \\sqrt{m}\\norm{A}_\\infty & \\norm{A}_2 \\leq \\norm{A}_F \\\\\n\\hline\n\\norm{A}_\\infty \\leq n \\norm{A}_1 & \\norm{A}_\\infty \\leq \\sqrt{n} \\norm{A}_2 & & \\norm{A}_\\infty \\leq \\sqrt{n}\\norm{A}_F\\\\\n\\hline\n\\norm{A}_F \\leq \\sqrt{n} \\norm{A}_1 & \\norm{A}_F \\leq \\tau \\norm{A}_2 & \\norm{A}_F \\leq \\sqrt{m}\\norm{A}_\\infty\n\\end{array}\n\\]\nFor each, prove the inequality, including that it is a tight inequality for some nonzero \\(A\\). (Skip \\(\\norm{A}_F \\leq \\tau \\norm{A}_2\\), we revisit it in a later post)\n\nSolution.\nClaim. Our claim is that \\(\\norm{A}_1 \\leq \\sqrt{m} \\norm{A}_2\\).\nPartition \\(A = [a_0 | a_1 | \\ldots | a_{n-1}]\\).\nWe have:\n\\[\n\\begin{align*}\n\\norm{A}_1 &= \\max_{0 \\leq j &lt; n} \\norm{a_j}_1 & \\{\\text{Definition}\\}\\\\\n&= \\max_{0 \\leq j &lt; n} \\norm{\n    \\begin{bmatrix}\n    \\alpha_{0,j}\\\\\n    \\alpha_{1,j}\\\\\n    \\vdots\\\\\n    \\alpha_{m-1,j}\n    \\end{bmatrix}\n}_1\\\\\n&= \\max_{0 \\leq j &lt; n} \\sum_{i=0}^{m-1}|\\alpha_{i,j}| \\cdot |1|\\\\\n&= \\max_{0 \\leq j &lt; n} \\left(\\sum_{i=0}^{m-1}|\\alpha_{i,j}|^2\\right)^{1/2} \\left(\\sum_{i=0}^{m-1}|1|^2\\right)^{1/2} & \\{\\text{Cauchy-Schwarz}\\}\\\\\n&= \\max_{0 \\leq j &lt; n} \\norm{a_j}_2 \\sqrt{m}\\\\\n&= \\max_{0 \\leq j &lt; n} \\norm{A}_2 \\sqrt{m} & \\{\\norm{A_{i,j}}_2 \\leq \\norm{A}_2\\}\\\\\n&= \\sqrt{m} \\norm{A}_2\n\\end{align*}\n\\]\nMoreover, consider the matrix\n\\[\nA = \\begin{bmatrix}\n1 & 0 \\\\\n1 & 0\n\\end{bmatrix} =\n\\begin{bmatrix}\n1 \\\\\n1\n\\end{bmatrix}\n\\begin{bmatrix}\n1 & 0\n\\end{bmatrix}\n\\]\nWe have, \\(\\norm{A}_2 = \\sqrt{2}\\) and \\(\\norm{A}_1 = 2\\), so \\(\\norm{A}_1 = \\sqrt{2}\\norm{A}_2\\). Thus, the inequality is tight. This closes the proof.\nClaim. Our claim is that \\(\\norm{A}_1 \\leq m \\norm{A}_\\infty\\).\nSolution.\nWe have:\n\\[\n\\begin{align}\n\\norm{A}_1 &= \\max_{0 \\leq j &lt; n} \\norm{a_j}_1 & \\{\\text{Definition}\\}\\\\\n&= \\max_{0 \\leq j &lt; n} \\sum_{i=0}^{m-1}|\\alpha_{i,j}|\\\\\n&\\leq \\sum_{j=0}^{n-1} \\sum_{i=0}^{m-1} |\\alpha_{i,j}| = \\sum_{i=0}^{m-1} \\sum_{j=0}^{n-1} |\\alpha_{i,j}| \\\\\n&=\\sum_{i=0}^{m-1} \\norm{\\tilde{a}_i^T}_1\\\\\n&= m \\max_{0 \\leq i &lt; m} \\norm{\\tilde{a}_i^T}_1\\\\\n&= m \\norm{A}_\\infty\n\\end{align}\n\\]\nAgain, consider the matrix\n\\[\nA = \\begin{bmatrix}\n1 & 0\\\\\n1 & 0\n\\end{bmatrix}\n\\]\n\\(\\norm{A}_1 = 2\\) and \\(\\norm{A}_\\infty = 1\\), so \\(\\norm{A}_1 = 2 \\norm{A}_\\infty\\). Hence, the inequality is tight. This closes the proof.\nClaim. Our claim is that \\(\\norm{A}_1 \\leq \\sqrt{m}\\norm{A}_F\\).\nSolution.\nWe have shown that:\n\\[\n\\begin{align}\n\\norm{A}_1 &\\leq \\sqrt{m}\\norm{A}_2 \\\\\n\\norm{A}_2 &\\leq \\norm{A}_F\n\\end{align}\n\\]\nSo, we deduce that \\(\\norm{A}_1 \\leq \\sqrt{m}\\norm{A}_F\\). Moreover, consider\n\\[\nA = \\sqrt{2}I\n\\]\nThen, \\(\\norm{A}_1 = \\sqrt{2}\\) and \\(\\norm{A}_F = 2\\), so \\(\\norm{A}_1 = \\sqrt{2}\\norm{A}_F\\). Hence, the inequality is tight.\nClaim. Our claim is that \\(\\norm{A}_2 \\leq \\sqrt{n}\\norm{A}_1\\).\nSolution.\nWe have:\n\\[\n\\begin{align}\n\\norm{A}_2 &= \\max_{x \\neq 0} \\frac{\\norm{Ax}_2}{\\norm{x}_2} & \\{\\text{Definition}\\}\\\\\n&= \\max_{x \\neq 0} \\frac{\\norm{Ax}_1}{\\norm{x}_2}  & \\{\\norm{z}_2 \\leq \\norm{z}_1\\} \\\\\n&= \\max_{x \\neq 0} \\frac{\\norm{Ax}_1}{\\frac{1}{\\sqrt{n}}\\norm{x}_1}  & \\{\\norm{z}_1 \\leq \\sqrt{n}\\norm{z}_2\\} \\\\\n&= \\sqrt{n}\\norm{A}_1\n\\end{align}\n\\]\nAgain, consider the matrix \\(A = [1 | 1| \\ldots | 1]\\). Then, \\(\\norm{A}_2 = \\sqrt{n}\\) and \\(\\norm{A}_1 = 1\\). So, \\(\\norm{A}_2 = \\sqrt{n}\\norm{A}_1\\).\nClaim. Our claim is that \\(\\norm{A}_2 \\leq \\sqrt{m} \\norm{A}_\\infty\\).\nSolution.\n\\[\n\\begin{align*}\n\\norm{A}_2 &= \\max_{x \\neq 0} \\frac{\\norm{Ax}_2}{\\norm{x}_2} &\\{\\text{Definition}\\}\\\\\n&=\\max_{x \\neq 0} \\frac{\\norm{\\begin{bmatrix}\\tilde{a}_0^T \\\\ \\tilde{a}_1^T \\\\ \\vdots \\\\ \\tilde{a}_{m-1}^T\\end{bmatrix}x}_2}{\\norm{x}_2} &\\{\\text{Expose rows}\\}\\\\\n&=\\max_{x \\neq 0} \\frac{\\norm{\\begin{bmatrix}\\tilde{a}_0^T x \\\\ \\tilde{a}_1^T x\\\\ \\vdots \\\\ \\tilde{a}_{m-1}^T x\\end{bmatrix}}_2}{\\norm{x}_2} &\\{\\text{Algebra}\\}\\\\\n&\\leq \\max_{x \\neq 0} \\frac{\\sqrt{m}\\norm{Ax}_\\infty}{\\norm{x}_2} &\\{\\norm{z}_2 \\leq \\sqrt{n}\\norm{z}_\\infty\\}\\\\\n& \\leq \\max_{x \\neq 0} \\frac{\\sqrt{m}\\norm{Ax}_\\infty}{\\norm{x}_\\infty} &\\{\\norm{z}_\\infty \\leq \\norm{z}_2\\}\\\\\n&= \\sqrt{m} \\norm{A}_\\infty\n\\end{align*}\n\\]\nMoreover, consider the matrix\n\\[\nA = \\begin{bmatrix}\n1 \\\\\n1 \\\\\n\\vdots \\\\\n1\n\\end{bmatrix}\n\\]\nWe have \\(\\norm{A}_2 = \\sqrt{m}\\), \\(\\norm{A}_\\infty = 1\\), so \\(\\norm{A}_2 = \\sqrt{m}\\norm{A}_\\infty\\). Hence, the inequality is tight.\nClaim. Our claim is that \\(\\norm{A}_\\infty \\leq n \\norm{A}_1\\).\nSolution.\nWe have:\n\\[\n\\begin{align*}\n\\norm{A}_\\infty &= \\max_{x \\neq 0} \\frac{\\norm{Ax}_\\infty}{\\norm{x}_\\infty} & \\{\\text{Definition}\\}\\\\\n&\\leq  \\max_{x \\neq 0} \\frac{\\norm{Ax}_1}{\\norm{x}_\\infty} & \\{\\norm{x}_\\infty \\leq \\norm{x}_1\\}\\\\\n&\\leq  \\max_{x \\neq 0} \\frac{\\norm{Ax}_1}{\\frac{1}{n}\\norm{x}_1} & \\{\\norm{x}_1 \\leq n \\norm{x}_\\infty\\}\\\\\n&= n \\norm{A}_1\n\\end{align*}\n\\]\nMoreover, let \\(A = [1 | 1 | \\ldots | 1]\\). Then, \\(\\norm{A}_\\infty = n\\) and \\(\\norm{A}_1 = 1\\), so \\(\\norm{A}_\\infty = n \\norm{A}_1\\). Hence, the inequality is tight.\nClaim. Our claim is that \\(\\norm{A}_\\infty \\leq \\sqrt{n} \\norm{A}_2\\).\nSolution.\nWe have:\n\\[\n\\begin{align*}\n\\norm{A}_\\infty &= \\max_{x \\neq 0} \\frac{\\norm{Ax}_\\infty}{\\norm{x}_\\infty} & \\{\\text{Definition}\\}\\\\\n&\\leq  \\max_{x \\neq 0} \\frac{\\norm{Ax}_2}{\\norm{x}_\\infty} & \\{\\norm{x}_\\infty \\leq \\norm{x}_2\\}\\\\\n&\\leq  \\max_{x \\neq 0} \\frac{\\norm{Ax}_2}{\\frac{1}{\\sqrt{n}}\\norm{x}_2} & \\{\\norm{x}_2 \\leq \\sqrt{n} \\norm{x}_\\infty\\}\\\\\n&= \\sqrt{n} \\norm{A}_2\n\\end{align*}\n\\]\nMoreover, let \\(A = [1|1|\\ldots|1]\\)\nThen, \\(\\norm{A}_\\infty = n\\), \\(\\norm{A}_2 = \\sqrt{n}\\) and \\(\\norm{A}_\\infty = \\sqrt{n} \\norm{A}_2\\). So, the bound is tight.\nClaim. Our claim is that \\(\\norm{A}_\\infty \\leq \\sqrt{n}\\norm{A}_F\\).\nSolution. This is true since \\(\\norm{A}_\\infty \\leq \\sqrt{n}\\norm{A}_2\\) and \\(\\norm{A}_2 \\leq \\norm{A}_F\\).\nLet \\(A = [1 | 1 | \\ldots | 1]\\). Then, \\(\\norm{A}_\\infty = n\\) and \\(\\norm{A}_F = \\sqrt{n}\\). So, \\(\\norm{A}_\\infty = \\sqrt{n}\\norm{A}_F\\). The bound is tight.\nClaim. Our claim is that \\(\\norm{A}_F \\leq \\sqrt{n} \\norm{A}_1\\).\nSolution.\nWe have:\n\\[\n\\begin{align}\n\\norm{A}_F^2 &= \\sum_{i=0}^{m-1} \\sum_{j=0}^{n-1} |\\alpha_{i,j}|^2 & \\{\\text{Definition}\\}\\\\\n&= \\sum_{j=0}^{n-1} \\sum_{i=0}^{m-1} |\\alpha_{i,j}|^2 \\\\\n&\\leq \\sum_{j=0}^{n-1} \\left(\\sum_{i=0}^{m-1} |\\alpha_{i,j}| \\right)^2 \\\\\n&= \\sum_{j=0}^{n-1} \\norm{a_j}_1^2 \\\\\n&\\leq \\sum_{j=0}^{n-1} \\max_{j=0}^{n-1} \\norm{a_j}_1^2 \\\\\n&= n \\norm{A}_1^2\n\\end{align}\n\\]\nConsequently, \\(\\norm{A}_F \\leq \\sqrt{n}\\norm{A}_1\\). Let \\(A = [1 |1 | \\ldots| 1]\\). Then, \\(\\norm{A}_F = \\sqrt{n}\\) and \\(\\norm{A}_1 = 1\\), so \\(\\norm{A}_F = \\sqrt{n}\\norm{A}_1\\). Hence, the bound is tight.\nClaim. Our claim is that \\(\\norm{A}_F \\leq \\sqrt{m} \\norm{A}_\\infty\\).\nSolution.\nWe have:\n\\[\n\\begin{align}\n\\norm{A}_F^2 &= \\sum_{i=0}^{m-1} \\sum_{j=0}^{n-1} |\\alpha_{i,j}|^2 & \\{\\text{Definition}\\}\\\\\n&\\leq \\sum_{i=0}^{m-1} \\left(\\sum_{j=0}^{n-1} |\\alpha_{i,j}| \\right)^2 \\\\\n&= \\sum_{i=0}^{m-1} \\norm{\\tilde{a}_i^T}_1^2 \\\\\n&\\leq \\sum_{j=0}^{n-1} \\max_{i=0}^{m-1} \\norm{\\tilde{a}_i^T}_1^2 \\\\\n&= m \\norm{A}_\\infty^2\n\\end{align}\n\\]\nConsequently, \\(\\norm{A}_F \\leq \\sqrt{m}\\norm{A}_\\infty\\). Let \\(A = [1, 1, \\ldots, 1]^T\\). Then, \\(\\norm{A}_F = \\sqrt{m}\\) and \\(\\norm{A}_\\infty = 1\\), so \\(\\norm{A}_F = \\sqrt{m}\\norm{A}_1\\). Hence, the bound is tight.\n\n\nSub-multiplicative norms\nThere are a number of properties that we would like a matrix norm to have(but not all matrix norms do). Given a matrix norm \\(\\norm{\\cdot} : \\C^{m \\times n} \\to \\R\\), we may ask the following question. Do there exist vector norms \\(\\norm{\\cdot}_\\mu : C^m \\to \\R\\) and \\(\\norm{\\cdot}:\\C^n \\to R\\), such that the matrix norm is an upper bound on how much the non-zero vector \\(x\\) is stretched? That is, the following inequality is satisfied:\n\\[\n\\frac{\\norm{Ax}_\\mu}{\\norm{x}_\\nu} \\leq \\norm{A}\n\\]\nor equivalently\n\\[\n\\norm{Ax}_\\mu \\leq \\norm{A} \\norm{x}_\\nu\n\\]\nwhere this second formulation has the benefit that it also holds if \\(x = 0\\).\n\nDefinition 12 (Subordinate matrix norm) A matrix norm \\(\\norm{\\cdot}:\\C^{m \\times n} \\to \\R\\) is said to be subordinate to vector norms \\(\\norm{\\cdot}_\\mu :\\C^m \\to \\R\\) and \\(\\norm{\\cdot}_\\nu : \\C^n \\to \\R\\), if for all, \\(x \\in \\C^n\\),\n\\[\n\\norm{Ax}_\\mu \\leq \\norm{A} \\norm{x}_\\nu\n\\]\nIf \\(\\norm{\\cdot}_\\mu\\) and \\(\\norm{\\cdot}_\\nu\\) are the same norm (but perhaps for different \\(m\\) and \\(n\\)), then \\(\\norm{\\cdot}\\) is said to be subordinate to the given vector norm.\n\n\nExercise 11 Prove that the matrix \\(2\\)-norm is subordinate to the vector \\(2\\)-norm.\n\nProof.\nLet \\(A \\in C^{m \\times n}\\) and let \\(x \\in \\C^n\\). Assume that \\(x \\neq 0\\), for if \\(x = 0\\), then the inequality \\(\\norm{Ax}_2 \\leq \\norm{A}_2 \\norm{x}_2\\) is vacuously true.\nWe have:\n\\[\n\\begin{align}\n\\norm{Ax}_2&= \\left(\\frac{\\norm{Ax}_2}{\\norm{x}_2}\\right) \\norm{x}_2 & \\{x \\neq 0\\} \\\\\n&\\leq \\left(\\max_{y \\neq 0} \\frac{\\norm{Ay}_2}{\\norm{y}_2}\\right)\\norm{x}_2\\\\\n&= \\norm{A}_2 \\norm{x}_2\n\\end{align}\n\\]\nThis closes the proof. \\(\\blacksquare\\)\n\nExercise 12 Prove that the Frobenius norm is subordinate to the vector \\(2\\)-norm.\n\nProof.\nWe are interested to prove the claim that, \\((\\forall A \\in \\C^{m\\times n})(\\forall x \\in \\C^n)\\):\n\\[ \\norm{Ax}_2 \\leq \\norm{A}_F \\norm{x}_2 \\]\nAgain, without loss of generality, we have:\n\\[\n\\begin{align}\n\\norm{Ax}_2^2 &= \\norm{\n    \\begin{bmatrix}\n        \\sum_{j=0}^{n-1}\\alpha_{0,j} x_j \\\\\n        \\sum_{j=0}^{n-1}\\alpha_{1,j} x_j \\\\\n        \\vdots\n        \\sum_{j=0}^{n-1}\\alpha_{m-1,j} x_j\n    \\end{bmatrix}\n}_2^2 & \\{\\text{Definition}\\}\\\\\n&= \\sum_{i=0}^{m-1} \\Biggl| \\sum_{j=0}^{n-1}\\alpha_{i,j} x_j \\Biggr|^2\\\\\n&= \\sum_{i=0}^{m-1} \\left(\\sum_{j=0}^{n-1}|\\alpha_{i,j} x_j| \\right)^2 & \\{\\text{Triangle Inequality}\\}\\\\\n&\\leq \\sum_{i=0}^{m-1} \\left[\\left(\\sum_{j=0}^{n-1}|\\alpha_{i,j}|^2 \\right)  \\left(\\sum_{j=0}^{n-1} |x_j|^2\\right)\\right] & \\{\\text{Cauchy-Schwarz}\\}\\\\\n&= \\left(\\sum_{j=0}^{n-1} |x_j|^2\\right) \\left(\\sum_{i=0}^{m-1} \\sum_{j=0}^{n-1}|\\alpha_{i,j}|^2 \\right)   & \\{\\text{Algebra}\\}\\\\\n&= \\norm{A}_F^2 \\norm{x}_2^2\n\\end{align}\n\\]\nThis closes the proof. \\(\\blacksquare\\)\n\nTheorem 13 Induced matrix norms, \\(\\norm{\\cdot}_{\\mu,\\nu} : \\C^{m \\times n} \\to \\R\\) are subordinate to the norms, \\(\\norm{\\cdot}_\\mu\\) and \\(\\norm{\\cdot}_\\nu\\) that induce them.\n\nProof.\nWithout loss of generality, assume that \\(x \\neq 0\\), otherwise the proposition is vacuously true.\nWe have:\n\\[\n\\begin{align}\n\\norm{Ax}_\\mu &= \\frac{\\norm{Ax}_\\mu}{\\norm{x}_\\nu} \\norm{x}_\\nu \\\\\n&\\leq \\left(\\max_{x \\neq 0} \\frac{\\norm{Ax}_\\mu}{\\norm{x}_\\nu} \\right) \\norm{x}_\\nu \\\\\n&= \\left(\\max_{y \\neq 0} \\frac{\\norm{Ay}_\\mu}{\\norm{y}_\\nu} \\right) \\norm{x}_\\nu \\\\\n&= \\norm{A} \\norm{x}_\\nu\n\\end{align}\n\\]\nThis closes the proof. \\(\\blacksquare\\)\n\nCorollary 1 Any matrix \\(p\\)-norm is subordinate to the corresponding vector norm.\n\nProof.\nWithout the loss of generality, assume that \\(x \\neq 0\\). If \\(x = 0\\), the proposition is vacuously true.\nWe have:\n\\[\n\\begin{align}\n\\norm{Ax}_p &= \\left(\\frac{\\norm{Ax}_p}{\\norm{x}_p} \\right) \\norm{x}_p & \\{ x \\neq 0\\}\\\\\n&\\leq  \\left(\\max_{x \\neq 0} \\frac{\\norm{Ax}_p}{\\norm{x}_p} \\right) \\norm{x}_p\\\\\n&=  \\left(\\max_{y \\neq 0}\\frac{\\norm{Ay}_p}{\\norm{y}_p} \\right) \\norm{x}_p\\\\\n&= \\norm{A}_p \\norm{x}_p\n\\end{align}\n\\]\nThis closes the proof. \\(\\blacksquare\\)\nAnother desirable property that not all norms have is that:\n\\[\n\\norm{AB} \\leq \\norm{A} \\norm{B}\n\\]\nThis requires the given norm to be defined for all matrix sizes.\n\nDefinition 13 (Consistent matrix norm) A matrix norm \\(\\norm{\\cdot} : \\C^{m \\times n} \\to \\R\\) is said to be consistent matrix norm if it is defined for all \\(m\\) and \\(n\\), using the same formula for all \\(m\\) and \\(n\\).\n\n\nDefinition 14 (Submultiplicative matrix norm) A consistent matrix norm \\(\\norm{\\cdot} : \\C^{m \\times n} \\to \\R\\) is said to be submultiplicative if it satisfies:\n\\[\n\\norm{AB} \\leq \\norm{A} \\norm{B}\n\\]\n\n\nTheorem 14 Let \\(\\norm{\\cdot} : \\C^n \\to \\R\\) be a vector norm defined for all \\(n\\). Define the corresponding induced matrix norm as:\n\\[\n\\norm{A} = \\max_{x \\neq 0} \\frac{\\norm{Ax}}{\\norm{x}} = \\max_{\\norm{x} = 1} \\norm{Ax}\n\\]\nThen, for any \\(A \\in \\C^{m \\times k}\\) and \\(B^{k \\times n}\\), the inequality \\(\\norm{AB} \\leq \\norm{A} \\norm{B}\\) holds.\n\nIn other words, induced matrix norms are submultiplicative.\nProof.\nWe have:\n\\[\n\\begin{align}\n\\norm{AB} &= \\max_{\\norm{x}=1} \\norm{ABx} & \\{\\text{Definition}\\}\\\\\n&= \\max_{\\norm{x}=1} \\norm{A(Bx)} & \\{\\text{Associativity}\\}\\\\\n&\\leq \\max_{\\norm{x}=1} \\norm{A} \\norm{Bx} & \\{\\text{Subordinate property}\\}\\\\\n&\\leq \\max_{\\norm{x}=1} \\norm{A} \\norm{B} \\norm{x} & \\{\\text{Subordinate property}\\}\\\\\n&= \\norm{A} \\norm{B} & \\{\\norm{x}=1\\}\n\\end{align}\n\\]"
  },
  {
    "objectID": "posts/move-semantics/index.html",
    "href": "posts/move-semantics/index.html",
    "title": "A hitchhiker’s guide to move semantics and perfect forwarding",
    "section": "",
    "text": "To understand the basic principles of move semantics, let’s look at the execution of a small piece of code. I’ve written a toy Vector class. I choose the manage the memory myself, so I will follow the rule of three. I will supply a copy-constructor, copy-assignment operator and a destructor. I have also overloaded operator+() to support element-wise addition of two vectors.\n\n\nAssume that we have the following program:\n//basics/copy_semantics.cpp\n#include &lt;iostream&gt;\n#include &lt;stdexcept&gt;\n#include &lt;initializer_list&gt;\n\n\ntemplate &lt;typename T&gt;\nclass Vector {\nprivate:\n    int capacity_;\n    int size_;\n    T* ptr_;\n\npublic:\n    Vector() :capacity_{ 0 }, size_{ 0 }, ptr_{ nullptr } {}\n    Vector(int size) : capacity_{ size }, ptr_{ new T[size] }, size_{ size } {}\n    Vector(int size, T data) : Vector(size) {\n        for (int i{ 0 }; i &lt; size; ++i)\n            ptr_[i] = data;\n    }\n\n    Vector(std::initializer_list&lt;T&gt; list) {\n        clear();\n        for (const T& elem : list)\n            push_back(elem);\n    }\n\n    //Destructor\n    ~Vector()\n    {\n        clear();\n    }\n\n    //Copy constructor\n    Vector(const Vector& v)\n    {\n        if (this == &v)\n            return;\n\n        capacity_ = v.capacity_;\n        size_ = v.size_;\n        ptr_ = new T[v.size_];\n\n        for (int i{ 0 }; i &lt; v.size_; ++i)\n            ptr_[i] = v.ptr_[i];\n    }\n\n    //Copy assignment operator\n    Vector&lt;T&gt;& operator=(const Vector&lt;T&gt;& v)\n    {\n        if (this != &v)\n        {\n            delete[] ptr_;\n            ptr_ = nullptr;\n\n            capacity_ = v.capacity_;\n            size_ = v.size_;\n            ptr_ = new T[capacity_];\n\n            for (int i{ 0 }; i &lt; v.size_; ++i)\n                ptr_[i] = v.ptr_[i];\n        }\n\n        return *this;\n    }\n\n    T& operator[](int i)\n    {\n        if (i &gt;= 0 && i &lt; size_)\n            return ptr_[i];\n        else\n            throw std::out_of_range(\"Index out of bounds.\");\n    }\n\n    T& operator[](int i) const\n    {\n        if (i &gt;= 0 && i &lt; size_)\n            return ptr_[i];\n        else\n            throw std::out_of_range(\"Index out of bounds.\");\n    }\n\n    void reserve(int size)\n    {\n        if (size_ &lt; capacity_) return;\n\n        if (ptr_ == nullptr)\n        {\n            size_ = 0;\n            capacity_ = 0;\n        }\n\n        T* bufferNew = new T[size];\n        unsigned int l_size = std::min(capacity_, size);\n        for (int i{ 0 }; i &lt; l_size; ++i)\n        {\n            bufferNew[i] = ptr_[i];\n        }\n\n        if (ptr_ != nullptr)\n            delete[] ptr_;\n\n        ptr_ = bufferNew;\n        capacity_ = size;\n    }\n\n    void clear()\n    {\n        if (ptr_ != nullptr)\n            delete[] ptr_;\n        ptr_ = nullptr;\n        size_ = 0;\n        capacity_ = 0;\n    }\n\n    int size() const\n    {\n        return size_;\n    }\n\n    int capacity()\n    {\n        return capacity_;\n    }\n\n    void push_back(const T& elem)\n    {\n        if (size_ &gt;= capacity_) {\n            reserve(capacity_ + 5); // Double the capacity\n        }\n\n        ptr_[size_++] = elem;\n    }\n\n    void pop_back()\n    {\n        --size_;\n    }\n\n    T front()\n    {\n        if (size_ &gt; 0)\n            return ptr_[0];\n        else\n            throw std::out_of_range(\"Index out of bounds.\");\n    }\n\n    T back()\n    {\n        if (size_ &gt; 0)\n            return ptr_[size_ - 1];\n        else\n            throw std::out_of_range(\"Index out of bounds.\");\n    }\n\n    T* getRawPointer()\n    {\n        return ptr_;\n    }\n};\n\ntemplate &lt;typename T&gt;\nVector&lt;T&gt; operator+(const Vector&lt;T&gt;& v1, const Vector&lt;T&gt;& v2)\n{\n    if (v1.size() != v2.size())\n        throw std::logic_error(\"Vector lengths must be equal.\");\n    Vector&lt;T&gt; result;\n    for (int i{ 0 }; i &lt; v1.size(); ++i)\n        result.push_back(v1[i] + v2[i]);\n\n    return result;\n}\n\nVector&lt;Vector&lt;double&gt;&gt; createAndInsert()\n{\n    Vector&lt;Vector&lt;double&gt;&gt; pts;\n    pts.reserve(3);\n    Vector&lt;double&gt; x{ 1.0, 1.0 };\n    pts.push_back(x);\n    pts.push_back(x + x);\n    pts.push_back(x);\n    return pts;\n}\n\nint main()\n{\n    Vector&lt;Vector&lt;double&gt;&gt; result = createAndInsert();\n    return 0;\n}\nCompiler Explorer\nLet us look at the individual steps of the program (inspecting both stack and the heap) when we compile this program with a C++ compiler.\nFirst in main, we create the empty vector pts which will be used to store points in the euclidean space \\(\\mathbf{R}^2\\):\nVector&lt;Vector&lt;double&gt;&gt; pts;\nwhich is placed on the stack as an object that has size_ = 0, capacity_ = 0 and no memory allocated for elements.\nThen, we call\npts.reserve(3);\nThis allocates memory for 3 elements on the heap. The member pts_-&gt;capacity_ equals 3, pts-&gt;size_ equals 0 and pts_-&gt;ptr_ contains the address to heap block. The allocated memory is not initialized, because the number of elements is still 0.\nThen, we create a \\(2\\)-tuple to hold the cartesian coordinates of a point \\((1.0,1.0)\\). We create a Vector&lt;double&gt; initialized to {1.0,1.0}. Essentially, we create an object x on the stack with its members x-&gt;size_ = 2, x-&gt;capacity_ = 5 and a pointer x-&gt;ptr_ containing the address of newly allocated memory on the heap for 5 elements. Further, x-&gt;ptr_[0]=1.0, x-&gt;ptr_[1]=1.0.\nVector&lt;double&gt; x{1.0, 1.0};\nAfter this statement, the program has the following state: we have two objects on the stack : pts and x. Both of them have memory allocated on the heap.\n\n\n\nCheckpoint #1\n\n\nThe next step is the command to insert x into the pts vector.\npts.push_back(x);\nMy toy Vector class is said to have value semantics, which means it creates copies of the values passed to it. As a result, we get a first element in the vector, which is a full(deep) copy of the passed value/object x:\n\n\n\nCheckpoint #2\n\n\nThe current state is that we have a vector pts and two copies of x={1.0,1.0}, one of which is the first element in pts.\nLet’s now look at the next statement, which creates a new temporary vector and again inserts it into the pts vector:\npts.push_back(x + x);\nThis statement is performed in three steps:\nStep 1. We create a temporary Vector&lt;double&gt; object x + x.\n\n\n\nStep #1\n\n\nStep 2. x+x is a temporary. The Vector&lt;T&gt;::push_back(const T&) function accepts a reference-to-const as an argument. Since x+x is a temporary, it cannot be modified and binds to a reference-to-const. Moreover, being a temporary object, it is likely to die soon. Referencing it extends the lifetime of the temporary x + x={2.0,2.0}.\nNow, the statement pts_[size++] = elem will invoke the copy-assignment operator on the yet uninitialized second element pts[1] which is of type Vector&lt;double&gt;. This will force a full (deep) copy of x + x={2.0,2.0}. At this time, two copies of {2.0,2.0} exist on the heap. One of these is assigned to pts[1].\n\n\n\nStep #2\n\n\nStep 3. When push_back(const T&) returns, the temporary x + x will die and its destructor is called and the memory allocated on the heap is freed. You can see this on cppinsights.\nOur code is clearly not performing well: we create a copy of the temporary x + x and destroy the source of the copy immediately afterwards, which means we unnecessarily allocate and free memory that we could have just moved from source to the copy.\n\n\n\nStep #3\n\n\nWith the next statement, again we insert x into pts:\npts.push_back(x)\nAgain, pts copies x.\n\n\n\nCheckpoint #3\n\n\nThis is also something to improve. Because the value of x is no longer needed, some optimization could use the memory of x as the memory for the new element instead.\nAt the end of createAndInsert() we come to the return statement:\nreturn pts;\nHere, the behaviour of the program is a bit more complicated. We return by value (the return type is not a reference), which should be a copy of the value in the return statement. Creating a copy of pts means that we have create a deep copy of the whole vector with all of its elements. Thus, we have to allocate heap memory for the array of elements in the pts and heap memory for the value of each 2-tuple. Here, we would have to allocate memory 4 times.\nHowever, since at the same time pts is destroyed because we leave the scope where it is declared, the compiler is allowed to perform named return value optimization (NRVO). This means that the compiler can generate code so that pts is used as the return value.\nLet us assume that we have the named return value optimization. In that case, at the end of the return statement, pts simply becomes the return value and the destructor of x is called, which frees the memory allocated when it was declared.\n\n\n\nReturn statement\n\n\nFinally, we come to the assignment of the return value to result:\nresult = createAndInsert()\nHere, we really get behavior that can be improved: the usual assignment operator has the goal of giving result the same value as the source value that is assigned. In general, any source(assigned) value should not be modified and should independent from the object that the value was assigned to. So, the assignment operator will create a deep-copy of the whole return value:\n\n\n\nReturn statement\n\n\nHowever, right after that we no longer need the temporary return value and we destroy it:\nAgain, we create a copy of a temporary object and destroy the source of the copy immediately afterwards, which means that we again unnecessarily allocate and free memory. This time it applies to four allocations\nFor the state of the program after this assignment in main(), we allocated memory numerous times and released it. Unnecessary memory allocations were caused by:\n\nInserting a temporary object into pts.\nInserting an object into pts where we no longer need the value.\nAssigning a temporary vector with all its elements.\n\nWe can more or less avoid these performance pennalties."
  },
  {
    "objectID": "posts/move-semantics/index.html#motivation-for-move-semantics",
    "href": "posts/move-semantics/index.html#motivation-for-move-semantics",
    "title": "A hitchhiker’s guide to move semantics and perfect forwarding",
    "section": "",
    "text": "To understand the basic principles of move semantics, let’s look at the execution of a small piece of code. I’ve written a toy Vector class. I choose the manage the memory myself, so I will follow the rule of three. I will supply a copy-constructor, copy-assignment operator and a destructor. I have also overloaded operator+() to support element-wise addition of two vectors.\n\n\nAssume that we have the following program:\n//basics/copy_semantics.cpp\n#include &lt;iostream&gt;\n#include &lt;stdexcept&gt;\n#include &lt;initializer_list&gt;\n\n\ntemplate &lt;typename T&gt;\nclass Vector {\nprivate:\n    int capacity_;\n    int size_;\n    T* ptr_;\n\npublic:\n    Vector() :capacity_{ 0 }, size_{ 0 }, ptr_{ nullptr } {}\n    Vector(int size) : capacity_{ size }, ptr_{ new T[size] }, size_{ size } {}\n    Vector(int size, T data) : Vector(size) {\n        for (int i{ 0 }; i &lt; size; ++i)\n            ptr_[i] = data;\n    }\n\n    Vector(std::initializer_list&lt;T&gt; list) {\n        clear();\n        for (const T& elem : list)\n            push_back(elem);\n    }\n\n    //Destructor\n    ~Vector()\n    {\n        clear();\n    }\n\n    //Copy constructor\n    Vector(const Vector& v)\n    {\n        if (this == &v)\n            return;\n\n        capacity_ = v.capacity_;\n        size_ = v.size_;\n        ptr_ = new T[v.size_];\n\n        for (int i{ 0 }; i &lt; v.size_; ++i)\n            ptr_[i] = v.ptr_[i];\n    }\n\n    //Copy assignment operator\n    Vector&lt;T&gt;& operator=(const Vector&lt;T&gt;& v)\n    {\n        if (this != &v)\n        {\n            delete[] ptr_;\n            ptr_ = nullptr;\n\n            capacity_ = v.capacity_;\n            size_ = v.size_;\n            ptr_ = new T[capacity_];\n\n            for (int i{ 0 }; i &lt; v.size_; ++i)\n                ptr_[i] = v.ptr_[i];\n        }\n\n        return *this;\n    }\n\n    T& operator[](int i)\n    {\n        if (i &gt;= 0 && i &lt; size_)\n            return ptr_[i];\n        else\n            throw std::out_of_range(\"Index out of bounds.\");\n    }\n\n    T& operator[](int i) const\n    {\n        if (i &gt;= 0 && i &lt; size_)\n            return ptr_[i];\n        else\n            throw std::out_of_range(\"Index out of bounds.\");\n    }\n\n    void reserve(int size)\n    {\n        if (size_ &lt; capacity_) return;\n\n        if (ptr_ == nullptr)\n        {\n            size_ = 0;\n            capacity_ = 0;\n        }\n\n        T* bufferNew = new T[size];\n        unsigned int l_size = std::min(capacity_, size);\n        for (int i{ 0 }; i &lt; l_size; ++i)\n        {\n            bufferNew[i] = ptr_[i];\n        }\n\n        if (ptr_ != nullptr)\n            delete[] ptr_;\n\n        ptr_ = bufferNew;\n        capacity_ = size;\n    }\n\n    void clear()\n    {\n        if (ptr_ != nullptr)\n            delete[] ptr_;\n        ptr_ = nullptr;\n        size_ = 0;\n        capacity_ = 0;\n    }\n\n    int size() const\n    {\n        return size_;\n    }\n\n    int capacity()\n    {\n        return capacity_;\n    }\n\n    void push_back(const T& elem)\n    {\n        if (size_ &gt;= capacity_) {\n            reserve(capacity_ + 5); // Double the capacity\n        }\n\n        ptr_[size_++] = elem;\n    }\n\n    void pop_back()\n    {\n        --size_;\n    }\n\n    T front()\n    {\n        if (size_ &gt; 0)\n            return ptr_[0];\n        else\n            throw std::out_of_range(\"Index out of bounds.\");\n    }\n\n    T back()\n    {\n        if (size_ &gt; 0)\n            return ptr_[size_ - 1];\n        else\n            throw std::out_of_range(\"Index out of bounds.\");\n    }\n\n    T* getRawPointer()\n    {\n        return ptr_;\n    }\n};\n\ntemplate &lt;typename T&gt;\nVector&lt;T&gt; operator+(const Vector&lt;T&gt;& v1, const Vector&lt;T&gt;& v2)\n{\n    if (v1.size() != v2.size())\n        throw std::logic_error(\"Vector lengths must be equal.\");\n    Vector&lt;T&gt; result;\n    for (int i{ 0 }; i &lt; v1.size(); ++i)\n        result.push_back(v1[i] + v2[i]);\n\n    return result;\n}\n\nVector&lt;Vector&lt;double&gt;&gt; createAndInsert()\n{\n    Vector&lt;Vector&lt;double&gt;&gt; pts;\n    pts.reserve(3);\n    Vector&lt;double&gt; x{ 1.0, 1.0 };\n    pts.push_back(x);\n    pts.push_back(x + x);\n    pts.push_back(x);\n    return pts;\n}\n\nint main()\n{\n    Vector&lt;Vector&lt;double&gt;&gt; result = createAndInsert();\n    return 0;\n}\nCompiler Explorer\nLet us look at the individual steps of the program (inspecting both stack and the heap) when we compile this program with a C++ compiler.\nFirst in main, we create the empty vector pts which will be used to store points in the euclidean space \\(\\mathbf{R}^2\\):\nVector&lt;Vector&lt;double&gt;&gt; pts;\nwhich is placed on the stack as an object that has size_ = 0, capacity_ = 0 and no memory allocated for elements.\nThen, we call\npts.reserve(3);\nThis allocates memory for 3 elements on the heap. The member pts_-&gt;capacity_ equals 3, pts-&gt;size_ equals 0 and pts_-&gt;ptr_ contains the address to heap block. The allocated memory is not initialized, because the number of elements is still 0.\nThen, we create a \\(2\\)-tuple to hold the cartesian coordinates of a point \\((1.0,1.0)\\). We create a Vector&lt;double&gt; initialized to {1.0,1.0}. Essentially, we create an object x on the stack with its members x-&gt;size_ = 2, x-&gt;capacity_ = 5 and a pointer x-&gt;ptr_ containing the address of newly allocated memory on the heap for 5 elements. Further, x-&gt;ptr_[0]=1.0, x-&gt;ptr_[1]=1.0.\nVector&lt;double&gt; x{1.0, 1.0};\nAfter this statement, the program has the following state: we have two objects on the stack : pts and x. Both of them have memory allocated on the heap.\n\n\n\nCheckpoint #1\n\n\nThe next step is the command to insert x into the pts vector.\npts.push_back(x);\nMy toy Vector class is said to have value semantics, which means it creates copies of the values passed to it. As a result, we get a first element in the vector, which is a full(deep) copy of the passed value/object x:\n\n\n\nCheckpoint #2\n\n\nThe current state is that we have a vector pts and two copies of x={1.0,1.0}, one of which is the first element in pts.\nLet’s now look at the next statement, which creates a new temporary vector and again inserts it into the pts vector:\npts.push_back(x + x);\nThis statement is performed in three steps:\nStep 1. We create a temporary Vector&lt;double&gt; object x + x.\n\n\n\nStep #1\n\n\nStep 2. x+x is a temporary. The Vector&lt;T&gt;::push_back(const T&) function accepts a reference-to-const as an argument. Since x+x is a temporary, it cannot be modified and binds to a reference-to-const. Moreover, being a temporary object, it is likely to die soon. Referencing it extends the lifetime of the temporary x + x={2.0,2.0}.\nNow, the statement pts_[size++] = elem will invoke the copy-assignment operator on the yet uninitialized second element pts[1] which is of type Vector&lt;double&gt;. This will force a full (deep) copy of x + x={2.0,2.0}. At this time, two copies of {2.0,2.0} exist on the heap. One of these is assigned to pts[1].\n\n\n\nStep #2\n\n\nStep 3. When push_back(const T&) returns, the temporary x + x will die and its destructor is called and the memory allocated on the heap is freed. You can see this on cppinsights.\nOur code is clearly not performing well: we create a copy of the temporary x + x and destroy the source of the copy immediately afterwards, which means we unnecessarily allocate and free memory that we could have just moved from source to the copy.\n\n\n\nStep #3\n\n\nWith the next statement, again we insert x into pts:\npts.push_back(x)\nAgain, pts copies x.\n\n\n\nCheckpoint #3\n\n\nThis is also something to improve. Because the value of x is no longer needed, some optimization could use the memory of x as the memory for the new element instead.\nAt the end of createAndInsert() we come to the return statement:\nreturn pts;\nHere, the behaviour of the program is a bit more complicated. We return by value (the return type is not a reference), which should be a copy of the value in the return statement. Creating a copy of pts means that we have create a deep copy of the whole vector with all of its elements. Thus, we have to allocate heap memory for the array of elements in the pts and heap memory for the value of each 2-tuple. Here, we would have to allocate memory 4 times.\nHowever, since at the same time pts is destroyed because we leave the scope where it is declared, the compiler is allowed to perform named return value optimization (NRVO). This means that the compiler can generate code so that pts is used as the return value.\nLet us assume that we have the named return value optimization. In that case, at the end of the return statement, pts simply becomes the return value and the destructor of x is called, which frees the memory allocated when it was declared.\n\n\n\nReturn statement\n\n\nFinally, we come to the assignment of the return value to result:\nresult = createAndInsert()\nHere, we really get behavior that can be improved: the usual assignment operator has the goal of giving result the same value as the source value that is assigned. In general, any source(assigned) value should not be modified and should independent from the object that the value was assigned to. So, the assignment operator will create a deep-copy of the whole return value:\n\n\n\nReturn statement\n\n\nHowever, right after that we no longer need the temporary return value and we destroy it:\nAgain, we create a copy of a temporary object and destroy the source of the copy immediately afterwards, which means that we again unnecessarily allocate and free memory. This time it applies to four allocations\nFor the state of the program after this assignment in main(), we allocated memory numerous times and released it. Unnecessary memory allocations were caused by:\n\nInserting a temporary object into pts.\nInserting an object into pts where we no longer need the value.\nAssigning a temporary vector with all its elements.\n\nWe can more or less avoid these performance pennalties."
  },
  {
    "objectID": "posts/move-semantics/index.html#copy-elison",
    "href": "posts/move-semantics/index.html#copy-elison",
    "title": "A hitchhiker’s guide to move semantics and perfect forwarding",
    "section": "Copy elison",
    "text": "Copy elison\nCopy-elison is based on the fact that the compiler is allowed to follow the as-if rule. The compiler is allowed to generate any code which has the same effect as the code you told it to add. The standard actually says, that if the compiler is told to copy something, but the copy is not really necessary, because the original is not going to be used again, then the compiler is allowed to elide(omit) the copy. The compiler is allowed to elide copies, where the results are as-if copies were made.\nConsider the function below:\n\n#include &lt;cmath&gt;\ndouble discountFactor(double r, double t){\n    double result = exp(-r * t);\n    return result;\n}\n\nint main()\n{\n    double df {discountFactor(0.05, 1.00)};\n    return 0;\n}\nHow many parameters are passed to the function discountFactor(double, double)? C++ programmers answer \\(2\\), assembly-language programmers answer \\(3\\). Why? At a low-level, when we have a return-value, we have to tell the generated code, where to put the return value. The function is passed the address where the results should be written.\nAlright, so this is what’s going on. Our function main() is going to call discountFactor(double, double) in order to populate a local df. The stack frame for the function main() looks like this:\n\n\n\nStack frame for main()\n\n\nNow, we are going to call the function discountFactor(double, double). When we call discountFactor(double, double), we have to create the stack-frame for discountFactor(double, double).\n\n\n\nCall to discountFactor()\n\n\nOkay, now we execute the function discountFactor(double, double) and now the return value is now stored directly at the address given by &df.\n\n\n\nReturn statement\n\n\nSo, this is going to elide the copy. This form of copy elison is called Return Value Optimization(RVO). The calling function allocates space for the return value on the stack, and passes the address of that memory to the callee. The callee can then construct a return value directly into that space, which eliminates the need to copy from the inside to the outside.\nAlso, although the compiler is normally required to make a copy when a function parameter is passed by value (so modifications to the parameter inside the function can’t affect the caller), it is allowed to elide the copy, when the source is a temporary.\nvoid f(std::string a)\n{\n    int b{123};\n    //some code\n    return;\n}\n\nvoid g()\n{\n    f(std::string(\"A\"));\n    std::vector&lt;int&gt; y;\n}\nThis is how it actually works. We are going to create our temporary - the string \"A\" in the place, where we would have actually copied it, that is, in the local variable a in the stack frame of f(std::string)."
  },
  {
    "objectID": "posts/move-semantics/index.html#value-categories",
    "href": "posts/move-semantics/index.html#value-categories",
    "title": "A hitchhiker’s guide to move semantics and perfect forwarding",
    "section": "Value Categories",
    "text": "Value Categories\nIn C++, every expression is either an lvalue or an rvalue. Consider an object that owns some resources(file-descriptors, sockets, memory buffer).\n\nAn lvalue denotes an object whose resources cannot be reused. The object is an lvalue, if you can’t take the guts(resources) out of this object and donate it to someone else. lvalues include expressions that designate objects by their name. For example, in the expression double y = f(x), y is an lvalue. Moreover, lvalues have persistent storage and an identifiable memory address. For instance, if I declare std::vector&lt;double&gt; v{1.0,2.0,3.0,4.0,5.0};, then v[0] is an lvalue.\nAn rvalue denotes an object whose resources can be reused. The object is an rvalue, if you can take the guts(resources) out of it and donate it to another object. rvalues typically include temporary objects as they can’t manipulated at the place they are created and are likely to be destroyed soon. For instance, if declare int x = 5;, 5 is an rvalue. Moreover, in the statement double y = f(x);, the expression f(x) is an rvalue."
  },
  {
    "objectID": "posts/move-semantics/index.html#moving-data",
    "href": "posts/move-semantics/index.html#moving-data",
    "title": "A hitchhiker’s guide to move semantics and perfect forwarding",
    "section": "Moving data",
    "text": "Moving data\nAs seen earlier, C++ sometimes performs unnecessary copying.\nVector&lt;double&gt; x;\nx = Vector&lt;double&gt;({\n        1.0, 2.0, 3.0, 4.0, 5.0, \n        6.0, 7.0, 8.0, 9.0, 10.0\n    });\ncppinsights produces the following annotations:\nVector&lt;double&gt; x = Vector&lt;double&gt;();\nconst double __temporary179_5[10] = {\n    1.0, 2.0, 3.0, 4.0, 5.0, \n    6.0, 7.0, 8.0, 9.0, 10.0\n};\nconst Vector&lt;double&gt; __temporary179_6 = Vector&lt;double&gt;(Vector&lt;double&gt;(std::initializer_list&lt;double&gt;{__temporary179_5, 10}));\nx.operator=(__temporary179_6);\n__temporary179_6.~Vector();\n/* __temporary179_5 // lifetime ends here */\nIn the above code snippet, the temporary vector of reals \\(\\{1.0,2.0,3.0,\\ldots,10.0\\}\\) is copied element-wise to x and then destroyed immediately after. We’ve wasted a lot of energy in deep-copying.\nSimilarly, appending to a full vector causes much copying before the append. That is not what we want to do.\nWhat we really want to do is, transfer the contents of __temporary19_6 vector to x in a very simple way. Firstly, we copy the pointers; we cannot stop there, because at this point there are two Vector&lt;T&gt; objects owning the same memory resource.\n\n\n\nStep 1. Copy the pointers\n\n\nThe second step is, of course to set the pointers of the temporary vector to nullptr.\n\n\n\nStep 2. Zero out the members of __temp\n\n\nThat looks great and this is cheap! We are doing the minimum amount of work to transfer the contents of the temporary into x.\nAt the end of the assignment operation, the temporary goes out of scope and the vector \\(\\{1,2,3,\\ldots,10\\}\\) is in x. How do we implement this logic programmatically?\nIn addition to the copy-constructor, we write a move constructor. A move constuctor simply moves the data by taking ownership of the pointer that refers to the data, leaving the data itself where it resides.\n// move constructor\nVector(Vector&& src) noexcept\n{\n    // Just swap the memory pointers\n    std::swap(src, *this);\n}\n\nrvalue references in detail\nThe constructor takes an argument of the type rvalue reference. rvalue references are declared two ampersands. lvalues bind to lvalue references. When taking a reference to a temporary object, an rvalue, you have two choices. rvalues can bind to:\n\nA const lvalue reference.\nA mutable rvalue reference.\n\nconst std::string& r1 {\"hello\"};    \nstd::string& r2 {\"world\"};\n\nconst Vector&lt;int&gt;& r3 {1,2,3,4,5};\nVector&lt;int&gt;&& r4{6,7,8,9,10};\nAll these references have the semantics of - we can steal/modify the resources of the object we refer to, provided the state of the object remains a valid state. Technically, these semantics are not checked by compilers, so we can modify an rvalue reference as we can do with any non-const object of the type. We might also decide not to modify the value.\nstd::string&& r1 = \"hello\";    \nr1 += \"world\"; \n\nVector&lt;int&gt;&& r2 {1,2,3,4,5};\nr2.push_back(6);\nAnd it’s a logic error to take a mutable lvalue reference to a temporary, so this is disallowed in the language:\n// std::string& r1 = \"hello\";    //error: this is not possible\n// r1 += \"world\"; \n// Vector&lt;int&gt;& r2 {1,2,3,4,5};\n// r2.push_back(6);\nAssigning a temporary to a reference extends the lifetime of the temporary so that it matches the lifetime of the reference. So, this is legal:\nint main()\n{\n    {\n        const std::string& s = foo();\n        std::cout &lt;&lt; s &lt;&lt; std::endl;    //the temporary to which s refers is still alive\n    }\n    //but now it's destroyed\n    return 0;    \n}\nAnd so is this:\nstd::string foo(){ return \"foo\";};      //function that returns a string\n\nvoid bar(std::string&& s){              // extends the lifetime as before\n    std::cout &lt;&lt; s; \n}    \n\nint main()\n{\n    bar(foo());     \n    return 0;\n}\n\n\nrvalue references as parameters\nWhen we declare a parameter to be an rvalue reference, it has exactly the behavior and semantics as introduced above:\n\nThe parameter can only bind to a temporary object or an rvalue.\nAccording to the semantics of rvalue references:\n\nThe caller claims that it is no longer interested in the object. Therefore, you can steal the guts of object, take ownership of its resources.\nHowever, the caller might still be interested in using the object. Therefore, any modification should keep the referenced object in a valid state."
  },
  {
    "objectID": "posts/move-semantics/index.html#stdmove",
    "href": "posts/move-semantics/index.html#stdmove",
    "title": "A hitchhiker’s guide to move semantics and perfect forwarding",
    "section": "std::move()",
    "text": "std::move()\nHey, this is cool! Why don’t we apply these ideas to the below example?\nVector&lt;int&gt; v1 {1, 2, 3, 4, 5};\nVector&lt;int&gt; v2 {v1};\nWell, in this case, we would have a problem. v1 has a name, it has a persistent storage location and a memory address, it is an lvalue. You can’t steal the contents of v1.\nBut, we can do something about this. If indeed you are interested to transfer the contents of v1 into v2, then all we need to do is use std::move.\nVector&lt;int&gt; v1 {1, 2, 3, 4, 5};\nVector&lt;int&gt; v2 {std::move(v1)};\nstd::move() is a function that you can think of as performing an unconditional cast of its argument to an rvalue reference. std::move(v1) marks v1 to be movable. It does not physically move anything. It signals, that the object v1 may be moved from.\nIf you have an lvalue, an object for which the lifetime does not end when you use it, you can mark it with std::move() to express I no longer need this object here. std::move does not move; it only sets a temporary marker in the context where the expression is used:\nvoid foo1(const std::string& lr);    //binds to the passed object without modifying it\nvoid foo1(std::string&& rv);         //binds to the passed object and might steal/modify its contents\n\nstd::string s{\"hello\"};\n\nfoo1(s);                             //calls the first foo(), s keeps its value\nfoo1(std::move(s));                  //calls the second foo(), s might lose its value\n                                     //semantically s no longer legal to access\nObjects marked with std::move() can still be passed to a function that takes an ordinary const lvalue reference. Consider another code snippet:\nvoid foo2(const std::string& lr);   //binds to the passed object without modifying it\n                                    //no other overload of foo2()\nfoo2(s);                            // calls foo2(), s keeps its value\nfoos(std::move(s))                  // calls foo2(), s keeps its value because we know that\n                                    // foo2() can't modify or take ownership of the contents of s.\nSemantically, s is still legal to access after the execution of the last line. Because there’s overload of foo2(const std::string&&), there is no ways its contents can be modified or transferred.\nNote that, an object marked with std::move() cannot be passed to a non-const lvalue reference.\n\nHeader file for std::move()\nstd::move() is defined as a function in the C++ standard library. To use it, you have to include the header file &lt;utility&gt; where it is defined:\n\n\nImplementation of std::move()\nstd::move() is nothing but a static_cast to an rvalue reference. You can achieve the same effect by calling static_cast manually as follows:\nfoo(static_cast&lt;decltype(obj)&&&gt;(obj));     //same effect foo(std::move(obj))\nTherefore, we could also write:\nstd::string s{\"hello\"};\nfoo(static_cast&lt;std::string&&&gt;(s));"
  },
  {
    "objectID": "posts/move-semantics/index.html#moved-from-objects",
    "href": "posts/move-semantics/index.html#moved-from-objects",
    "title": "A hitchhiker’s guide to move semantics and perfect forwarding",
    "section": "Moved-from objects",
    "text": "Moved-from objects\nAfter a std::move(), moved-from objects are not (partially) destroyed. They are still valid objects for which at least the destructor will be called. However, they should also be valid in the sense that they have a consistent state and all operations work as expected. The only thing you do not know is their contents.\n\nValid but unspecified state\nThe C++ standard library guarantees that moved-from objects are in a valid but unspecified state. Consider the following code:\nstd::string s{\"hello\"};\nstd::vector&lt;std::string&gt; coll{};\ncoll.push_back(std::move(s));\nAfter passing s with std::move() you can ask for the number of characters, print out the value, or even assign a new value. However, you cannot print the first character or any other character without checking the number of characters first:\n#include &lt;iostream&gt;\n#include &lt;vector&gt;\n#include &lt;string&gt;\n#include &lt;utility&gt;\n\nint main()\n{\n    std::string s{\"hello\"};\n    std::vector&lt;std::string&gt; coll{};\n    coll.push_back(std::move(s));   //keeps in a valid but unclear state\n    std::cout &lt;&lt; \"Contents of s : \" &lt;&lt; s &lt;&lt; \"\\n\";     //ok (don't know which value is written)\n    std::cout &lt;&lt; \"size : \" &lt;&lt; s.size() &lt;&lt; \"\\n\"; //ok (rites the number of characters)\n    // std::cout &lt;&lt; \"[0] = \" &lt;&lt; s[0] &lt;&lt; \"\\n\"; //error (potentially undefined behavior)\n    s = \"new value\";    // ok\n    return 0;\n}\nCompiler Explorer\nstdout\nContents of s : \nsize : 0\n\n\nReusing moved-from objects\nWe might wonder why moved-from objects are still valid objects and are not (partially) destroyed. The reason is that there are useful applications of move semantics, where it makes sense to use moved-from objects again.\nFor example, consider code where we read chunks of data from a network socket or read strings line-by-line from a file stream and move them into a vector:\nstd::vector&lt;std::string&gt; allRows;\nstd::string row;\n\nwhile(std::getline(myStream, row)){ //read next line into row\n    allRows.push_back(std::move(row));  //and move it to somewhere\n}\nEach time after we read a line into row, we use std::move() to move the value of row into the vector of all rows. Then, std::getline() uses the moved-from object row again to read the next line into it.\nAs a second example, consider a generic function that swaps two values:\ntemplate &lt;typename T&gt;\nvoid swap(T& a, T& b)\n{\n    T tmp{std::move(a)};\n    a = std::move(b);       //assign new value to moved-from a\n    b = std::move(temp);    //assign new value to moved-from b\n}\nHere, we move the value of a into a temporary object to be able t move-assign the value of b afterwards. The moved-from object b then receives the value of tmp, which is the former value of a.\nCode like this is used in sorting algorithms for example, sorting a vector of buy/sell orders in the order book by the bid/ask prices.\n\n\nMove assignments of objects to themselves\nThe rule that moved-from objects are in a valid but unspecified state usually also applies to objects after a direct or indirect self-move.\nFor example, after the following statement, the object x is usually valid without its value being known:\nx = std::move(x);   //afterwards x is valid but has an unclear value"
  },
  {
    "objectID": "posts/move-semantics/index.html#the-canonical-move-constructor-and-move-assignment-operator",
    "href": "posts/move-semantics/index.html#the-canonical-move-constructor-and-move-assignment-operator",
    "title": "A hitchhiker’s guide to move semantics and perfect forwarding",
    "section": "The canonical move constructor and move assignment operator",
    "text": "The canonical move constructor and move assignment operator\nConsider the below Widget class as an example. The canonical move constructor and move assignment operators are written as follows:\nclass Widget{\n    private:\n        int i;\n        std::string s{};\n        int* resource;            // Owning pointer\n\n    public:\n    // Move constructor\n    Widget(Widget&& rhs) noexcept //Phase 1: member-wise swap\n        : i {std::move(rhs.i)}\n        , s {std::move(rhs.s)}\n        , resource{std::move(rhs.resource)}\n    {\n        rhs.resource = nullptr; // Phase 2: reset the move-from object\n    }\n\n    // Move assignment operator\n    Widget& operator=(Widget&& src)\n    {\n        delete resource;            //Phase 1: Cleanup\n        std::swap(src, *this);      //Phase 2: Member-wise move\n        src-&gt;resource = nullptr;    //Phase 3: Reset\n        return *this;\n    }\n\n    Widget::Widget& operator=(Widget src);\n}\nAn owning-pointer such int* is special, and it has to be dealt with separately.\nRaw pointers are bad (especially owning raw pointers). In this case, the declaration doesn’t indicate whether it points to an element or an array.\nIf instead, we have a smart-pointer, then what I can do is omit is phase 2.\nclass Widget{\n    private:\n        int i;\n        std::string s{};\n        int* resource;      \n\n    public:\n    // Move constructor\n    Widget(Widget&& rhs) noexcept //Phase 1: member-wise swap\n        : i {std::move(rhs.i)}\n        , s {std::move(rhs.s)}\n        , resource{std::move(rhs.resource)}\n    {}\n\n    // Move assignment operator\n    Widget& operator=(Widget&& src)\n    {\n        std::swap(src, *this); \n        return *this;\n    }\n\n    Widget::Widget& operator=(Widget src);\n}\nI would like to show you one more thing. The canonical copy assignment operator also doubles up as a move-assignment operator.\n// Copy/Move assignment operator\nWidget::Widget& operator=(Widget src)  //Copy/move constructor called \n{\n    std::swap(src, *this); \n    return *this;\n}\n\nint main()\n{\n    Widget w1(5,\"hello\", new int(10)),\n    Widget w2 = w1;     //copy/move assignment operator called\n    Widget w3 = std::move(w1);  //copy/move assignment operator called\n}\nIn the assignment statement Widget w2 = w1;, first the copy constructor is called and the contents of w1 are copied to src, before the control enters the body of operator=(Widget). Whereas the assignment statement Widget w3 = std::move(w1) results in the invocation of the move constructor and the contents of w1 are transferred to w3 before we execute the body of the assignment operator."
  },
  {
    "objectID": "posts/move-semantics/index.html#avoiding-unnecessary-stdmove",
    "href": "posts/move-semantics/index.html#avoiding-unnecessary-stdmove",
    "title": "A hitchhiker’s guide to move semantics and perfect forwarding",
    "section": "Avoiding unnecessary std::move()",
    "text": "Avoiding unnecessary std::move()\nAs we saw, returning a local object by value automatically uses move semantics if supported. However, to be safe, programmers might try to force this with an explicit std::move():\nstd::string foo()\n{\n    std::string s;\n    // do something\n    // ...\n    return std::move(s);    //Bad, don't do this\n}\nRemember that std::move() is just a static_cast to an rvalue reference. Therefore, std::move is an expression that yields the type std::string&&. However, this no longer matches the return type and therefore disables return value optimization, which usually allows the returned object to be used as a return value. For types where move semantics is not implemented, this might even force the copying of the return value instead of just using the returned object as the return value."
  },
  {
    "objectID": "posts/move-semantics/index.html#value-categories-in-detail",
    "href": "posts/move-semantics/index.html#value-categories-in-detail",
    "title": "A hitchhiker’s guide to move semantics and perfect forwarding",
    "section": "Value categories in detail",
    "text": "Value categories in detail\nTo compile an expression or statement it does not only matter whether the involved types fit. For example, you cannot assign an int to an int, when on the left hand side of the assignment, an int literal is used.\nint i{};\ni = 88;     //Ok\n//88 = i;   //Error\nFor this reason, each expression in C++ has a value category. Besides the type, the value category is essential to decide what you can do with an expression.\n\nValue categories since C++11\n\n\n\nValue Categories\n\n\nWe have the following primary categories:\n\nlvalue (Locator Value)\nprvalue (Pure Readable Value)\nxvalue (Expiring Value)\n\nThe composite categories are: - glvalue (generalized lvalue) as a common term for lvalue or xvalue - rvalue as a common term for xvalue or prvalue\nIntuitively, it’s easy to understand the primary value categories, if you look at the following diagram:\n\n\n\nValue Categories\n\n\nFor example,\nclass X{\n};\n\nX v;\nconst X c;\n\nf(v);   //passes a modifiable lvalue\nf(c);   //passes a non-modifiable lvalue\nf(X()); //passes a prvalue (old syntax of creating a temporary)\nf(X{}); //passes a prvalue (new syntax of creating a temporary)\nf(std::move(v));  //passes an xvalue\nRoughly speaking, as a rule of thumb:\n\nAll names used as expressions are lvalues.\nAll string literals used as expressions are lvalues.\nAll non-string literals used as expressions are prvalues.\nAll temporaries without a name (especially objects returned by value) are prvalues.\nAll objects marked with a std::move are xvalues.\n\n\n\nCopy Elison since C++17\nC++17 added mandates to the standard, formally known as :\n\nGuaranteed copy elison\nGuraranteed return value optimization\nCopy evasion\n\nIf, in an initialization of an object, when the initializer expression is prvalue of the same class type as the variable type, copy elison is guaranteed.\n#include &lt;iostream&gt;\n\nclass T{\n    public:\n    T(){ std::cout &lt;&lt; \"c'tor T()\\n\";}\n    T(const T& t){ std::cout &lt;&lt; \"c'tor T(const T& t)\\n\";}\n    T(T&& t){ std::cout &lt;&lt; \"c'tor T(T&& t)\\n\";}\n};\nT x{T{}};\nIn C++17, this is equivalent to T x{};. The default constructor is invoked only once.\nSimilarly, if, in a return statement the operand is a prvalue of the same class type as the function return type, copy elison is guaranteed.\nT func()\n{\n    return T{};\n}\n\nT x{func()}; //Only one default construction of T allowed here\nUnder the rules of C++17, under the hood, a prvalue will be used only as unmaterialized recipe of an object, until actual materialization is required.\nA prvalue is an expression whose evaluation initializes/materializes an object. This is called as temporary materialization conversion.\nclass  T{\n    public:\n    T(){\n        std::cout &lt;&lt; \"c'tor T()\\n\";\n    }\n    //delete move and copy constructors\n    T(const T& other) = delete;\n    T(T&& other) = delete;\n}\n\nT make(){\n    //Creates the first temporary (pre C++17)\n    return T{};\n}\n\nint main(){\n    // Construct the second temporary (pre C++17)\n    // Copy/move temporary into N using the = operator (pre C++17)\n    T t = make();\n    return 0;\n}\nPre C++17, the function make() would construct a temporary within its scope. This temporary would then be copied/moved into another temporary within the main scope. Finally, the operator= would build t via copy/move construction. All of this temporary business would be elided by (RVO) by any decent compiler resulting in make() constructing a single object within t. However, this elison is somewhat optional, so the compiler must also demand that copy and move constructors exist, just in case. The above code does not compile with any pre C++17 compiler.\nPost C++17, make() creates an object of type T within t. Avoiding excessive use of temporary objects is now a language feature and the reliance on compiler optimization is removed. The above code does compiler with a post C++17 compiler.\n\n\nValue Categories since C++17\nC++17 has the same value categories but clarified the semantic meaning of the value categories as described in the figure above.\nThe key approach for explaining value categories now is that in general, we have two major kinds of expressions:\n\nglvalues: expressions for locations of long-living objects or functions.\nprvalues: expressions for short-living values for initializations.\n\nAn xvalue is then considered a special location, representing a (long-living) object, whose resources/values are no longer needed.\nLoosely speaking, prvalues themselves do not exist somewhere in memory, they do not denote objects. They are used for initialization. In C++17, prvalues are not moved from. It doesn’t make sense to talk about whether you can steal it’s resources."
  },
  {
    "objectID": "posts/move-semantics/index.html#perfect-forwarding",
    "href": "posts/move-semantics/index.html#perfect-forwarding",
    "title": "A hitchhiker’s guide to move semantics and perfect forwarding",
    "section": "Perfect Forwarding",
    "text": "Perfect Forwarding\n\nMotivation for perfect forwarding\nConsider a function that declares the parameter as rvalue reference:\nvoid f(std::string&& s)\n{\n    // Do something\n    std::cout &lt;&lt; \"string s : \" &lt;&lt; s &lt;&lt; \"\\n\";\n}\nAs we’ve learned, we can only pass rvalues to this function:\nstd::string s{\"hello\"};\n// f(s);                // Error : passing an lvalue to an rvalue ref\nf(std::move(s));        // okay, passing an xvalue\nf(std::string(\"world\"));// okay, passing a prvalue\nHowever, when we use the parameter s inside the function f(std::string&&), we are dealing with an object that has a name. This means that we use s as an lvalue. We can do only what we are allowed to do with an lvalue. This means that we cannot call our function recursively.\nvoid f(std::string&& s)\n{\n    // Do something\n    std::cout &lt;&lt; \"string s : \" &lt;&lt; s &lt;&lt; \"\\n\";\n    // f(s);    // Error: passing an lvalue to an rvalue reference\n}\nWe have to mark s with std::move() again:\nvoid f(std::string&& s)\n{\n    // Do something\n    std::cout &lt;&lt; \"string s : \" &lt;&lt; s &lt;&lt; \"\\n\";\n    f(std::move(s));    // Ok, passing an xvalue\n}\nThis is the formal specification of the rule that move semantics is not passed through.\nTo forward an object that is passed with move semantics to a function, it not only has to be bound to an rvalue reference; you have to use std::move() again to forward its move semantics to another function.\nFor example:\nclass X{\n    // ...\n};\n\n//forward declarations\nvoid foo(const X&);     //for constant values (read-only access)\nvoid foo(X&);           //for variable values (out parameters)\nvoid foo(X&&);          //for values that are no longer used(move semantics)\nWe have the following rules when calling these functions:\nX v;\nconst X c;\n\nfoo(v);     //calls foo(X&)\nfoo(c);     //calls foo(const X&)\nfoo(X{});   //calls foo(X&&)\nfoo(std::move(v))   //calls foo(X&&)\nfoo(std::move(c))   //calls foo(const X&)\nNow, assume that we want to call foo() for the same arguments indirectly via a helper function callFoo(). That helper function would also need the three overloads.\nvoid callFoo(const X& arg){     //arg binds to all const objects\n    foo(arg);                   //calls foo(const X&)\n}\n\nvoid callFoo(X& arg)            //arg binds to lvalues\n{\n    foo(arg);                   //calls foo(&)\n}\n\nvoid callFoo(X&& arg){          //arg binds to rvalues\n    foo(std::move(arg));        //needs std::move() to call foo(X&&)\n}\nIn all cases, arg is used as an lvalue (being an object with a name). The first version forwards it as a const object, but the other two cases implement two different ways to forward the non-const argument.\n\nArguments declared as lvalue references (that bind to objects that do not have move semantics) are passed as they are.\nArguments declared as rvalue references (that bind to objects that have move semantics) are passed with std::move.\n\nThis allows us to forward move semantics perfectly: for any argument that is passed with move semantics, we keep the move semantics; but we do not add move semantics when we get an argument that does not have it.\nOnly with this implementation is the use of callFoo to call foo transparent.\nX v;\nconst X c;\n\ncallFoo(v);     //calls foo(X&)\ncallFoo(c);     //calls foo(const X&)\ncallFoo(X{});   //calls foo(X&&)\ncallFoo(std::move(v))   //calls foo(X&&)\ncallFoo(std::move(c))   //calls foo(const X&)\nRemember that an rvalue passed to an rvalue reference becomes an lvalue when used, which means that we need std::move() to pass it as an rvalue again. However, we cannot use std::move() everywhere. For the other overloads, using std::move() would call the overload of foo() for rvalue references when an lvalue is passed.\nFor perfect forwarding in generic code, we would always need all these overloads for each parameter. To support all combinations, this means having \\(3^2 = 9\\) overloads for \\(2\\) generic arguments and \\(3^3 = 27\\) overloads for \\(3\\) generic arguments.\nTherefore, C++11 introduced a special way to perfectly forward without any overloads but still keeping the type and the value category.\n\n\nImplementing perfect forwarding\nTo avoid overloading functions for parameters with different value categories, C++ introduced the mechanism of perfect forwarding. You need three things:\n\nTake the call parameter as a pure rvalue reference (delcared with && but without const or volatile)\nThe type of the parameter has to be a template parameter of the function.\nWhen forwarding the parameter to another function, use a helper function called std::forward&lt;&gt;() which is declared in &lt;utility&gt;.\n\nYou have to implement a function that perfectly forwards an argument as follows:\ntemplate&lt;typename T&gt;\nvoid callFoo(T&& arg)\n{\n    foo(std::forward&lt;T&gt;(arg));\n}\nstd::forward&lt;&gt;() is defined as a conditional std::move(), so that we get the same behavior as the three (or four) overloads of callFoo() above:\n\nIf we pass an rvalue to arg, we have the same effect as calling foo(std::move(arg)).\nIf we pass an lvalue to arg, we have the same effect as calling foo(arg).\n\nWhat exactly is happening here, is pretty tricky and needs a careful explanation.\n\n\nUniversal and Forwarding references\nFirst note that we declare arg as an rvalue reference parameter:\ntemplate&lt;typename T&gt;\nvoid callFoo(T&& arg)\nThis might give the impression that the rules of rvalue references apply. However, that is not the case. An rvalue reference (not qualified with const or volatile) of a function template parameter does not follow the rules of ordinary rvalue references. It is a different thing.\n\nTwo terms : Universal and Forwarding Reference\nSuch a reference is called a universal reference. Unfortunately, there is also another term for it that is mainly used in the C++ standard: forwarding reference. There is no difference between these two terms, it is just that we have a historical mess here with two established terms that mean the same thing. Both terms describe basic aspects of universal/forwarding references:\n\nThey can universally bind to objects of all types(const and non-const) and value categories.\nThey are usually used to forward arguments; but note that this is not the only use (one reason for me to prefer the term universal reference)\n\n\n\nUniversal references bind to all value categories\nThe important feature of universal references is that they can bind to objects and expressions of any value category:\ntemplate&lt;typename T&gt;\nvoid callFoo(T&& arg);  //arg is universal/forwarding reference\n\nX v;\nconst X c;\ncallFoo(v);             //ok\ncallFoo(c);             //ok\ncallFoo(X{});           //ok\ncallFoo(std::move(v));  //ok\ncallFoo(std::move(c));  //ok\nIn addition, they preserve the const-ness and value category (whether we have an rvalue or an lvalue) of the object they are bound to:\n#include &lt;iostream&gt;\n#include &lt;type_traits&gt;\nclass Widget{};\n\ntemplate &lt;typename T&gt;\nvoid f(T&& arg){\n    std::cout &lt;&lt; std::boolalpha;\n\n    if (std::is_same&lt;T&&, Widget&&gt;::value)\n    {\n        std::cout &lt;&lt; \"T&& = Widget&\\n\";\n    }\n    else if (std::is_same&lt;T&&, const Widget&&gt;::value)\n    {\n        std::cout &lt;&lt; \"T&& = const Widget&\\n\";\n    }\n    else if(std::is_same&lt;T&&, Widget&&&gt;::value)\n    {\n        std::cout &lt;&lt; \"T&& = Widget&&\\n\";\n    }\n    else if(std::is_same&lt;T&&,const Widget&&&gt;::value)\n    {\n        std::cout &lt;&lt; \"T&& = const Widget&&\\n\";\n    }\n}\n\nint main()\n{\n    Widget w;\n    const Widget cw;\n\n    std::cout &lt;&lt; \"Calling f(w)\\n\"; \n    f(w);\n    std::cout &lt;&lt; \"Calling f(cw)\\n\"; \n    f(cw);\n    std::cout &lt;&lt; \"Calling f(std::move(w))\\n\"; \n    f(std::move(w));\n    std::cout &lt;&lt; \"Calling f(std::move(cw))\\n\"; \n    f(std::move(cw));\n    return 0;\n}\nCompiler Explorer\nstdout:\nCalling f(w)\nT&& = Widget&\nCalling f(cw)\nT&& = const Widget&\nCalling f(std::move(w))\nT&& = Widget&&\nCalling f(std::move(cw))\nT&& = const Widget&&\nBy rule, the template parameter type T, is deduced to be:\n\nAn lvalue reference if we pass an lvalue.\nAn rvalue reference if we pass to an rvalue.\n\nNote that, a generic rvalue reference that is qualified with const (or volatile) is not a universal reference.\nThe rules of reference collapsing are now applied:\n\nWidget& && becomes Widget&\nWidget&& & becomes Widget&\nWidget& && becomes Widget &\nWidget&& && becomes Widget&&\n\nIn the function call f( w ), we are passing an lvalue, so the template parameter T is deduced to be an lvalue reference, Widget&. Therefore, T&& is Widget& && and by the rules of reference collapsing, this collapses to Widget&.\nSimilarly, in the function call f( Widget{} ), we are passing an rvalue, so the template parameter T is deduced to be an rvalue reference, Widget&&. Therefore, T&& is Widget&& && which collapses to Widget&&.\n\n\nstd::forward&lt;&gt;()\nstd::forward&lt;&gt;() conditionally casts its input into an rvalue reference.\n\nIf the given input expression is an lvalue, it is cast to an lvalue reference.\nIf the given input expression is an rvalue, it is cast to an rvalue reference.\n\nstd::forward does not forward anything.\nA really cool use-case of perfect forwarding is the std::make_unique() function. std::make_unique&lt;T&gt;() must invoke the underlying constructor. However, whilst doing so, it must preserve the const-ness and the value category of the arguments passed to the constructor.\nHere is a quick code snippet:\n// Let's say that we would like to implement the make_unique()\n// function that invokes the underlying constructor - either move\n// or copy based on the arguments\n#include &lt;memory&gt;\n#include &lt;iostream&gt;\n\nclass X{\n    public:\n        X(){}\n        X(const X& x){ std::cout &lt;&lt; \"copy c'tor\\n\";}\n        X(X&& x) { std::cout &lt;&lt; \"move c'tor\\n\"; }\n};\n\n\ntemplate&lt;typename T, typename... Args&gt;\nstd::unique_ptr&lt;T&gt; make_unique(Args&&... args){\n    T* ptr_t = new T(std::forward&lt;Args&gt;(args)...);\n    return std::unique_ptr&lt;T&gt;(ptr_t);\n}\n\nint main()\n{\n    X x1{};\n    std::unique_ptr&lt;X&gt; x2{make_unique&lt;X&gt;(x1)};  //calls X(const X&)\n    std::unique_ptr&lt;X&gt; x3{make_unique&lt;X&gt;(X{})}; //calls X(X&&)\n    return 0;\n}"
  },
  {
    "objectID": "posts/levenberg-marquardt/index.html",
    "href": "posts/levenberg-marquardt/index.html",
    "title": "Levenberg-Marquardt Algorithm",
    "section": "",
    "text": "The Levenberg-Marquardt(LM) method consists of an iterative least-squares minimization of a function based on a modification of the Newton method. It’s a super-intuitive algorithm and a generic implementation can be very quickly coded up. I state the problem formally before defining the algorithm. We’ll use finite differences to approximate the first and second-order derivatives of the function.\nLet \\(\\mathbf{x}\\in\\mathbf{R}^n\\) be the parameter vector to be optimized. We want to find the optimal \\(\\mathbf{x}^*\\) that minimizes the scalar error function:\n\\[\n\\begin{align*}\nF(\\mathbf{x}) = \\frac{1}{2}||\\mathbf{r}(\\mathbf{x})||^2 = \\frac{1}{2}\\mathbf{r}(\\mathbf{x})^T \\mathbf{r}(\\mathbf{x})\n\\end{align*}\n\\]\nThe residual error function \\(\\mathbf{r}:\\mathbf{R}^n \\to \\mathbf{R}^m\\) may sometimes include a comparison to reference or observed data. A very simple linear example would \\(\\mathbf{r}(\\mathbf{x}) = \\mathbf{b} - \\mathbf{Ax}\\). However, in the following, I assume that \\(\\mathbf{r}(\\cdot)\\) is any vector-valued function:\n\\[\n\\begin{align*}\n\\mathbf{r}(\\mathbf{x}) = (r_1(\\mathbf{x}),f_2(\\mathbf{x}),\\ldots,r_m(\\mathbf{x}))\n\\end{align*}\n\\]\nWe can define the Jacobian of the residual error functions as \\(m \\times n\\) matrix with entries :\n\\[\n\\mathbf{J}_{ij}(\\mathbf{x}) = \\frac{\\partial r_i}{\\partial x_j}(\\mathbf{x})\n\\]\nWe can also define the Hessian of the residual error functions as the \\(n \\times n\\) matrix with entries :\n\\[\n\\begin{align*}\n\\mathbf{H}_{ij}(\\mathbf{x}) = \\frac{\\partial^2 r_i}{\\partial x_i \\partial x_j} (\\mathbf{x})\n\\end{align*}\n\\]\nThe gradient of the scalar-valued function \\(F\\), by the \\(uv\\) product rule is:\n\\[\n\\begin{align*}\n\\nabla F(\\mathbf{x}) = D\\mathbf{r}(\\mathbf{x}) \\mathbf{r}(\\mathbf{x}) = \\mathbf{J}(\\mathbf{x})\\cdot \\mathbf{r}(\\mathbf{x})\n\\end{align*}\n\\]\nThe Hessian of the function \\(F\\) is:\n\\[\n\\begin{align*}\n\\nabla^2 F(\\mathbf{x}) &= D\\left\\{\\sum_{j=1}^{m} \\nabla r_j(\\mathbf{x}) \\cdot r_j(\\mathbf{x})\\right\\}\\\\\n&= \\sum_{j=1}^m \\nabla^2 r_j(\\mathbf{x}) r_j(\\mathbf{x}) + (\\nabla r_j(\\mathbf{x}))^2\n\\end{align*}\n\\]\nIf the derivatives \\(\\nabla^2 r_j(\\mathbf{x})\\) are small, they can be dropped and the Hessian in this case simply becomes:\n\\[\n\\nabla^2 F(\\mathbf{x}) = \\nabla r(\\mathbf{x})^T \\nabla(r(\\mathbf{x})) = \\mathbf{J}(\\mathbf{x})^T \\cdot \\mathbf{J}(\\mathbf{x})\n\\]\nThen, the LM method minimizes the following \\(2\\)nd-order Taylor’s expansion of the actual error function:\n\\[\nF(\\mathbf{x}^{(k)} + \\mathbf{h}) - F(\\mathbf{x}^{(k)}) = \\mathbf{h} \\nabla F(\\mathbf{x}^{(k)}) + \\frac{1}{2}\\mathbf{h}^T \\nabla^2 F(\\mathbf{x}^{(k)}) \\mathbf{h}\n\\tag{1}\\]\nDescent methods like gradient descent can place too much trust in their first- or second- order information, which can result in excessively large steps or premature convergence.\nSo, in LM, we add a penalty term\n\\[ \\frac{1}{2} \\lambda^{(k)} \\mathbf{h}^T \\mathbf{h} = \\frac{1}{2} \\lambda^{(k)} ||\\mathbf{x} - \\mathbf{x}^{(k)}||^2 \\tag{2}\\]\nto the above Equation 1, that we want to minimize. That’s because, we don’t want to go too far away from \\(\\mathbf{x}^{(k)}\\). It’s not because, we think the solution is not too far away. The actual solution could be far away. But, that’s a question of trust. And \\(\\lambda^{(k)}\\) essentially gives you your level of distrust. If \\(\\lambda^{(k)}\\) is super-big, it means that you don’t trust the model very much, or you trust it, but only if you are very close to \\(\\mathbf{x}^{(k)}\\). When \\(\\lambda^{(k)}\\) gets really small, it means you really trust your model. And you’re gonna find that \\(\\mathbf{x}\\) is going to very far from \\(\\mathbf{x}^{(k)}\\). So, that’s the gist. Putting together,\n\\[\nE(\\mathbf{h}) = \\mathbf{h} \\nabla F(\\mathbf{x}^{(k)}) + \\frac{1}{2}\\mathbf{h}^T \\nabla^2 ( F(\\mathbf{x}^{(k)}) + \\lambda^{(k)} I )\\mathbf{h}\n\\tag{3}\\]\nWe can just solve for the optimal step-size \\(\\mathbf{h}_{lm}\\) analytically. Taking the first derivative with respect to the step-size \\(\\mathbf{h}\\) and setting it equal to zero:\n\\[\n\\nabla E(\\mathbf{h}) = \\nabla F(\\mathbf{x}^{(k)}) + \\mathbf{h}_{lm}( \\nabla^2 F(\\mathbf{x}^{(k)}) + \\lambda^{(k)}I) = 0\n\\tag{4}\\]\nConsequently,\n\\[\n\\begin{align*}\n\\mathbf{h}_{lm} &= -(\\nabla^2 F(\\mathbf{x}^{(k)}) + \\lambda^{(k)}I)^{-1} \\nabla F(\\mathbf{x}^{(k)})\\\\\n&=-(\\mathbf{J}(\\mathbf{x}^{(k)})^T \\mathbf{J}(\\mathbf{x})^{(k)} + \\lambda^{(k)}I)^{-1} \\mathbf{J}(\\mathbf{x}^{(k)}) \\mathbf{r}(\\mathbf{x}^{(k)})\n\\end{align*}\n\\tag{5}\\]\nOur best estimate of the minima, is consequently:\n\\[\n\\begin{align*}\n\\mathbf{x}^{(k+1)} &= \\mathbf{x}^{(k)} + \\mathbf{h}_{lm}\\\\\n&= \\mathbf{x}^{(k)} -(\\mathbf{J}(\\mathbf{x}^{(k)})^T \\mathbf{J}(\\mathbf{x})^{(k)} + \\lambda^{(k)}I)^{-1} \\mathbf{J}(\\mathbf{x}^{(k)}) \\mathbf{r}(\\mathbf{x}^{(k)})\n\\end{align*}\n\\tag{6}\\]\n\n\n\nA trust-region method, or restricted step method maintains a local model of the trust region. It depends on the success of the previous step. If the step \\(\\mathbf{h}_{lm}\\) results in a decrease in \\(||F(\\mathbf{x})||^2\\), then we reduce \\(\\lambda^{(k)}\\), otherwise we increase the value of this parameter.\nSo, we can use the following update mechanism:\n\nIf \\(||F(\\mathbf{x}^{(k+1)})||^2\\) &lt; \\(||F(\\mathbf{x}^{(k)})||^2\\), accept the new \\(x\\) and reduce \\(\\lambda\\)\n\n\\[ \\lambda^{(k+1)} = 0.8 \\lambda^{(k)}\\]\n\notherwise, we increase the \\(\\lambda\\) and do not update \\(\\mathbf{x}\\):\n\n\\[ \\lambda^{(k+1)} = 2 \\lambda^{k}, \\quad \\mathbf{x}^{(k+1)} = \\mathbf{x}^{(k)}\\]\n\n\n\n\nusing Pkg"
  },
  {
    "objectID": "posts/levenberg-marquardt/index.html#algorithm-description",
    "href": "posts/levenberg-marquardt/index.html#algorithm-description",
    "title": "Levenberg-Marquardt Algorithm",
    "section": "",
    "text": "The Levenberg-Marquardt(LM) method consists of an iterative least-squares minimization of a function based on a modification of the Newton method. It’s a super-intuitive algorithm and a generic implementation can be very quickly coded up. I state the problem formally before defining the algorithm. We’ll use finite differences to approximate the first and second-order derivatives of the function.\nLet \\(\\mathbf{x}\\in\\mathbf{R}^n\\) be the parameter vector to be optimized. We want to find the optimal \\(\\mathbf{x}^*\\) that minimizes the scalar error function:\n\\[\n\\begin{align*}\nF(\\mathbf{x}) = \\frac{1}{2}||\\mathbf{r}(\\mathbf{x})||^2 = \\frac{1}{2}\\mathbf{r}(\\mathbf{x})^T \\mathbf{r}(\\mathbf{x})\n\\end{align*}\n\\]\nThe residual error function \\(\\mathbf{r}:\\mathbf{R}^n \\to \\mathbf{R}^m\\) may sometimes include a comparison to reference or observed data. A very simple linear example would \\(\\mathbf{r}(\\mathbf{x}) = \\mathbf{b} - \\mathbf{Ax}\\). However, in the following, I assume that \\(\\mathbf{r}(\\cdot)\\) is any vector-valued function:\n\\[\n\\begin{align*}\n\\mathbf{r}(\\mathbf{x}) = (r_1(\\mathbf{x}),f_2(\\mathbf{x}),\\ldots,r_m(\\mathbf{x}))\n\\end{align*}\n\\]\nWe can define the Jacobian of the residual error functions as \\(m \\times n\\) matrix with entries :\n\\[\n\\mathbf{J}_{ij}(\\mathbf{x}) = \\frac{\\partial r_i}{\\partial x_j}(\\mathbf{x})\n\\]\nWe can also define the Hessian of the residual error functions as the \\(n \\times n\\) matrix with entries :\n\\[\n\\begin{align*}\n\\mathbf{H}_{ij}(\\mathbf{x}) = \\frac{\\partial^2 r_i}{\\partial x_i \\partial x_j} (\\mathbf{x})\n\\end{align*}\n\\]\nThe gradient of the scalar-valued function \\(F\\), by the \\(uv\\) product rule is:\n\\[\n\\begin{align*}\n\\nabla F(\\mathbf{x}) = D\\mathbf{r}(\\mathbf{x}) \\mathbf{r}(\\mathbf{x}) = \\mathbf{J}(\\mathbf{x})\\cdot \\mathbf{r}(\\mathbf{x})\n\\end{align*}\n\\]\nThe Hessian of the function \\(F\\) is:\n\\[\n\\begin{align*}\n\\nabla^2 F(\\mathbf{x}) &= D\\left\\{\\sum_{j=1}^{m} \\nabla r_j(\\mathbf{x}) \\cdot r_j(\\mathbf{x})\\right\\}\\\\\n&= \\sum_{j=1}^m \\nabla^2 r_j(\\mathbf{x}) r_j(\\mathbf{x}) + (\\nabla r_j(\\mathbf{x}))^2\n\\end{align*}\n\\]\nIf the derivatives \\(\\nabla^2 r_j(\\mathbf{x})\\) are small, they can be dropped and the Hessian in this case simply becomes:\n\\[\n\\nabla^2 F(\\mathbf{x}) = \\nabla r(\\mathbf{x})^T \\nabla(r(\\mathbf{x})) = \\mathbf{J}(\\mathbf{x})^T \\cdot \\mathbf{J}(\\mathbf{x})\n\\]\nThen, the LM method minimizes the following \\(2\\)nd-order Taylor’s expansion of the actual error function:\n\\[\nF(\\mathbf{x}^{(k)} + \\mathbf{h}) - F(\\mathbf{x}^{(k)}) = \\mathbf{h} \\nabla F(\\mathbf{x}^{(k)}) + \\frac{1}{2}\\mathbf{h}^T \\nabla^2 F(\\mathbf{x}^{(k)}) \\mathbf{h}\n\\tag{1}\\]\nDescent methods like gradient descent can place too much trust in their first- or second- order information, which can result in excessively large steps or premature convergence.\nSo, in LM, we add a penalty term\n\\[ \\frac{1}{2} \\lambda^{(k)} \\mathbf{h}^T \\mathbf{h} = \\frac{1}{2} \\lambda^{(k)} ||\\mathbf{x} - \\mathbf{x}^{(k)}||^2 \\tag{2}\\]\nto the above Equation 1, that we want to minimize. That’s because, we don’t want to go too far away from \\(\\mathbf{x}^{(k)}\\). It’s not because, we think the solution is not too far away. The actual solution could be far away. But, that’s a question of trust. And \\(\\lambda^{(k)}\\) essentially gives you your level of distrust. If \\(\\lambda^{(k)}\\) is super-big, it means that you don’t trust the model very much, or you trust it, but only if you are very close to \\(\\mathbf{x}^{(k)}\\). When \\(\\lambda^{(k)}\\) gets really small, it means you really trust your model. And you’re gonna find that \\(\\mathbf{x}\\) is going to very far from \\(\\mathbf{x}^{(k)}\\). So, that’s the gist. Putting together,\n\\[\nE(\\mathbf{h}) = \\mathbf{h} \\nabla F(\\mathbf{x}^{(k)}) + \\frac{1}{2}\\mathbf{h}^T \\nabla^2 ( F(\\mathbf{x}^{(k)}) + \\lambda^{(k)} I )\\mathbf{h}\n\\tag{3}\\]\nWe can just solve for the optimal step-size \\(\\mathbf{h}_{lm}\\) analytically. Taking the first derivative with respect to the step-size \\(\\mathbf{h}\\) and setting it equal to zero:\n\\[\n\\nabla E(\\mathbf{h}) = \\nabla F(\\mathbf{x}^{(k)}) + \\mathbf{h}_{lm}( \\nabla^2 F(\\mathbf{x}^{(k)}) + \\lambda^{(k)}I) = 0\n\\tag{4}\\]\nConsequently,\n\\[\n\\begin{align*}\n\\mathbf{h}_{lm} &= -(\\nabla^2 F(\\mathbf{x}^{(k)}) + \\lambda^{(k)}I)^{-1} \\nabla F(\\mathbf{x}^{(k)})\\\\\n&=-(\\mathbf{J}(\\mathbf{x}^{(k)})^T \\mathbf{J}(\\mathbf{x})^{(k)} + \\lambda^{(k)}I)^{-1} \\mathbf{J}(\\mathbf{x}^{(k)}) \\mathbf{r}(\\mathbf{x}^{(k)})\n\\end{align*}\n\\tag{5}\\]\nOur best estimate of the minima, is consequently:\n\\[\n\\begin{align*}\n\\mathbf{x}^{(k+1)} &= \\mathbf{x}^{(k)} + \\mathbf{h}_{lm}\\\\\n&= \\mathbf{x}^{(k)} -(\\mathbf{J}(\\mathbf{x}^{(k)})^T \\mathbf{J}(\\mathbf{x})^{(k)} + \\lambda^{(k)}I)^{-1} \\mathbf{J}(\\mathbf{x}^{(k)}) \\mathbf{r}(\\mathbf{x}^{(k)})\n\\end{align*}\n\\tag{6}\\]"
  },
  {
    "objectID": "posts/levenberg-marquardt/index.html#updating-lambdak",
    "href": "posts/levenberg-marquardt/index.html#updating-lambdak",
    "title": "Levenberg-Marquardt Algorithm",
    "section": "",
    "text": "A trust-region method, or restricted step method maintains a local model of the trust region. It depends on the success of the previous step. If the step \\(\\mathbf{h}_{lm}\\) results in a decrease in \\(||F(\\mathbf{x})||^2\\), then we reduce \\(\\lambda^{(k)}\\), otherwise we increase the value of this parameter.\nSo, we can use the following update mechanism:\n\nIf \\(||F(\\mathbf{x}^{(k+1)})||^2\\) &lt; \\(||F(\\mathbf{x}^{(k)})||^2\\), accept the new \\(x\\) and reduce \\(\\lambda\\)\n\n\\[ \\lambda^{(k+1)} = 0.8 \\lambda^{(k)}\\]\n\notherwise, we increase the \\(\\lambda\\) and do not update \\(\\mathbf{x}\\):\n\n\\[ \\lambda^{(k+1)} = 2 \\lambda^{k}, \\quad \\mathbf{x}^{(k+1)} = \\mathbf{x}^{(k)}\\]"
  },
  {
    "objectID": "posts/levenberg-marquardt/index.html#generic-implementation-in-julia",
    "href": "posts/levenberg-marquardt/index.html#generic-implementation-in-julia",
    "title": "Levenberg-Marquardt Algorithm",
    "section": "",
    "text": "using Pkg"
  },
  {
    "objectID": "posts/ito_calculus/index.html",
    "href": "posts/ito_calculus/index.html",
    "title": "Ito Calculus",
    "section": "",
    "text": "Exercise 1 (A strange martingale) Let \\((B_t,t\\geq 0)\\) be a standard Brownian motion. Consider the process:\n\\[\nM_t = \\frac{1}{\\sqrt{1-t}}\\exp\\left(\\frac{-B_t^2}{2(1-t)}\\right), \\quad \\text{ for }0 \\leq t &lt; 1\n\\]\n\nShow that \\(M_t\\) can be represented by:\n\n\\[\nM_t = 1 + \\int_0^t \\frac{-B_s M_s}{1-s}dB_s, \\quad \\text{ for } 0 \\leq t \\leq 1\n\\]\n\nDeduce from the previous question that \\((M_s,s \\leq t)\\) is a martingale for \\(t &lt; 1\\) and for the Brownian filtration.\nShow that \\(\\mathbb{E}[M_t] = 1\\) for all \\(t &lt; 1\\).\nProve that \\(\\lim_{t \\to 1^-} M_t = 0\\) almost surely.\n\n\nSolution.\nLet \\(f(t,x) = \\frac{1}{\\sqrt{1-t}}e^{-\\frac{x^2}{2(1-t)}}\\). We have:\n\\[\n\\begin{align*}\n\\frac{\\partial f}{\\partial t} &= \\frac{\\sqrt{1-t}\\cdot e^{-\\frac{x^2}{2(1-t)}}\\cdot \\frac{x^2}{2(1-t)^2}\\cdot (-1) - e^{-\\frac{x^2}{2(1-t)}}\\cdot \\frac{1}{2\\sqrt{1-t}}\\cdot(-1)}{(1-t)}\\\\\n&=\\frac{e^{-\\frac{x^2}{2(1-t)}}}{(1-t)}\\left( -\\frac{x^2}{2(1-t)^{3/2}}+\\frac{1-t}{2(1-t)^{3/2}}\\right)\\\\\n&= \\frac{e^{-\\frac{x^2}{2(1-t)}}((1-t) - x^2)}{2(1-t)^{5/2}}\n\\end{align*}\n\\]\nAlso, the first and second derivatives with respect to the space variable \\(x\\) are:\n\\[\n\\begin{align*}\n\\frac{\\partial f}{\\partial x} &= \\frac{1}{\\sqrt{1-t}}\\exp\\left(-\\frac{x^2}{2(1-t)}\\right)\\left(-\\frac{x}{(1-t)}\\right)\\\\\n&= -\\frac{x}{(1-t)^{3/2}} \\exp\\left(-\\frac{x^2}{2(1-t)}\\right)\n\\end{align*}\n\\]\n\\[\n\\begin{align*}\n\\frac{\\partial^2 f}{\\partial x^2} &= - \\frac{1}{(1-t)^{3/2}}\\left\\{\\exp\\left(-\\frac{x^2}{2(1-t)}\\right) + x\\exp\\left(-\\frac{x^2}{2(1-t)}\\right)\\left(-\\frac{x}{(1-t)}\\right)\\right\\}\\\\\n&= - \\frac{1}{(1-t)^{3/2}}\\exp\\left(-\\frac{x^2}{2(1-t)}\\right) \\left\\{1 - \\frac{x^2}{(1-t)}\\right\\}\\\\\n&= \\frac{(x^2 - (1-t))}{(1-t)^{5/2}}\\exp\\left(-\\frac{x^2}{2(1-t)}\\right)\n\\end{align*}\n\\]\nBy Ito’s formula:\n\\[\n\\begin{align*}\ndf(t,B_t) &= (f_t + \\frac{1}{2}f_{xx})dt + f_x dB_t\\\\\ndM_t &= -\\frac{B_t}{(1-t)} \\frac{e^{-\\frac{B_t^2}{2(1-t)}}}{\\sqrt{1-t}}\\\\\n&= -\\frac{B_t M_t}{(1-t)}\n\\end{align*}\n\\]\nwhere in the second step, we used the fact that \\(f_t + \\frac{1}{2}f_{xx} = 0\\), so the \\(dt\\) term is zero.\nIn the integral form:\n\\[\n\\begin{align*}\nM_t - M_0 &= \\int \\frac{- B_s M_s}{1 - s}dB_s\\\\\nM_t &= 1 + \\int \\frac{- B_s M_s}{1 - s}dB_s\n\\end{align*}\n\\]\n\nThe Ito integral \\(\\int_0^t \\frac{-B_s M_s}{1-s}dB_s\\) is a continuous martingale with respect to the brownian filtration. Hence \\((M_t,t \\geq 0)\\) is a martingale.\nThe expectation of an Ito integral is zero. Hence, \\(\\mathbb{E}[M_t] = 1\\) for all \\(t &lt; 1\\).\nUsing Markov’s inequality followed by (concave) Jensen’s inequality, because we know that \\(\\mathbb{E}[B_t^2]=t\\), \\(\\mathbb{E}[B_t^4]=3t^2\\) and \\(Var(B_t^2) = 2t^2\\) for any \\(\\epsilon &gt; 0\\):"
  },
  {
    "objectID": "posts/ito_calculus/index.html#exercises",
    "href": "posts/ito_calculus/index.html#exercises",
    "title": "Ito Calculus",
    "section": "",
    "text": "Exercise 1 (A strange martingale) Let \\((B_t,t\\geq 0)\\) be a standard Brownian motion. Consider the process:\n\\[\nM_t = \\frac{1}{\\sqrt{1-t}}\\exp\\left(\\frac{-B_t^2}{2(1-t)}\\right), \\quad \\text{ for }0 \\leq t &lt; 1\n\\]\n\nShow that \\(M_t\\) can be represented by:\n\n\\[\nM_t = 1 + \\int_0^t \\frac{-B_s M_s}{1-s}dB_s, \\quad \\text{ for } 0 \\leq t \\leq 1\n\\]\n\nDeduce from the previous question that \\((M_s,s \\leq t)\\) is a martingale for \\(t &lt; 1\\) and for the Brownian filtration.\nShow that \\(\\mathbb{E}[M_t] = 1\\) for all \\(t &lt; 1\\).\nProve that \\(\\lim_{t \\to 1^-} M_t = 0\\) almost surely.\n\n\nSolution.\nLet \\(f(t,x) = \\frac{1}{\\sqrt{1-t}}e^{-\\frac{x^2}{2(1-t)}}\\). We have:\n\\[\n\\begin{align*}\n\\frac{\\partial f}{\\partial t} &= \\frac{\\sqrt{1-t}\\cdot e^{-\\frac{x^2}{2(1-t)}}\\cdot \\frac{x^2}{2(1-t)^2}\\cdot (-1) - e^{-\\frac{x^2}{2(1-t)}}\\cdot \\frac{1}{2\\sqrt{1-t}}\\cdot(-1)}{(1-t)}\\\\\n&=\\frac{e^{-\\frac{x^2}{2(1-t)}}}{(1-t)}\\left( -\\frac{x^2}{2(1-t)^{3/2}}+\\frac{1-t}{2(1-t)^{3/2}}\\right)\\\\\n&= \\frac{e^{-\\frac{x^2}{2(1-t)}}((1-t) - x^2)}{2(1-t)^{5/2}}\n\\end{align*}\n\\]\nAlso, the first and second derivatives with respect to the space variable \\(x\\) are:\n\\[\n\\begin{align*}\n\\frac{\\partial f}{\\partial x} &= \\frac{1}{\\sqrt{1-t}}\\exp\\left(-\\frac{x^2}{2(1-t)}\\right)\\left(-\\frac{x}{(1-t)}\\right)\\\\\n&= -\\frac{x}{(1-t)^{3/2}} \\exp\\left(-\\frac{x^2}{2(1-t)}\\right)\n\\end{align*}\n\\]\n\\[\n\\begin{align*}\n\\frac{\\partial^2 f}{\\partial x^2} &= - \\frac{1}{(1-t)^{3/2}}\\left\\{\\exp\\left(-\\frac{x^2}{2(1-t)}\\right) + x\\exp\\left(-\\frac{x^2}{2(1-t)}\\right)\\left(-\\frac{x}{(1-t)}\\right)\\right\\}\\\\\n&= - \\frac{1}{(1-t)^{3/2}}\\exp\\left(-\\frac{x^2}{2(1-t)}\\right) \\left\\{1 - \\frac{x^2}{(1-t)}\\right\\}\\\\\n&= \\frac{(x^2 - (1-t))}{(1-t)^{5/2}}\\exp\\left(-\\frac{x^2}{2(1-t)}\\right)\n\\end{align*}\n\\]\nBy Ito’s formula:\n\\[\n\\begin{align*}\ndf(t,B_t) &= (f_t + \\frac{1}{2}f_{xx})dt + f_x dB_t\\\\\ndM_t &= -\\frac{B_t}{(1-t)} \\frac{e^{-\\frac{B_t^2}{2(1-t)}}}{\\sqrt{1-t}}\\\\\n&= -\\frac{B_t M_t}{(1-t)}\n\\end{align*}\n\\]\nwhere in the second step, we used the fact that \\(f_t + \\frac{1}{2}f_{xx} = 0\\), so the \\(dt\\) term is zero.\nIn the integral form:\n\\[\n\\begin{align*}\nM_t - M_0 &= \\int \\frac{- B_s M_s}{1 - s}dB_s\\\\\nM_t &= 1 + \\int \\frac{- B_s M_s}{1 - s}dB_s\n\\end{align*}\n\\]\n\nThe Ito integral \\(\\int_0^t \\frac{-B_s M_s}{1-s}dB_s\\) is a continuous martingale with respect to the brownian filtration. Hence \\((M_t,t \\geq 0)\\) is a martingale.\nThe expectation of an Ito integral is zero. Hence, \\(\\mathbb{E}[M_t] = 1\\) for all \\(t &lt; 1\\).\nUsing Markov’s inequality followed by (concave) Jensen’s inequality, because we know that \\(\\mathbb{E}[B_t^2]=t\\), \\(\\mathbb{E}[B_t^4]=3t^2\\) and \\(Var(B_t^2) = 2t^2\\) for any \\(\\epsilon &gt; 0\\):"
  },
  {
    "objectID": "posts/irs_caps_floors_and_swaptions/index.html",
    "href": "posts/irs_caps_floors_and_swaptions/index.html",
    "title": "IRS, Caps, Floors and Swaptions",
    "section": "",
    "text": "I review here a few basic definitions relevant to the interest-rate world.\n\nDefinition 1 (Zero-coupon bond.) A \\(T\\)-maturity zero-coupon bond (pure discount bond) is a contract that guarantees its holder the payment of \\(1\\$\\) at time \\(T\\), with no intermediate payments. The contract value at time \\(t &lt; T\\) is denoted by \\(P(t,T)\\). Clearly, \\(P(T,T) = 1\\) \\(\\forall T\\in[0,\\infty)\\).\n\n\nDefinition 2 (Continuously-compounded spot interest rate.) The continuously-compounded spot interest rate prevailing at time \\(t\\) for the maturity \\(T\\) is denoted by \\(R(t,T)\\) and is the constant rate at which an investment of \\(P(t,T)\\) units of currency at time \\(t\\) accrues continuously to yield a unit amount of currency at maturity \\(T\\).\n\\[\n\\begin{align*}\nR(t,T) := - \\frac{\\ln P(t,T)}{\\tau(t,T)}\n\\end{align*}\n\\tag{1}\\]\nThe continuously-compounded interest rate is therefore a constant rate that is consistent with the zero-coupon-bond prices such that:\n\\[\n\\begin{align*}\ne^{R(t,T)\\tau(t,T)}P(t,T) = 1\n\\end{align*}\n\\tag{2}\\]\nfrom which we can express the bond price in terms of the continuously compounded rate \\(R\\):\n\\[\n\\begin{align*}\nP(t,T) = e^{-R(t,T)\\tau(t,T)}\n\\end{align*}\n\\tag{3}\\]\n\n\nDefinition 3 (Simply-compounded spot interest rate.) The simply-compounded spot interest rate prevailing at time \\(t\\) for the maturity \\(T\\) is denoted \\(L(t,T)\\) and is the constant rate at which an investment has to be made to produce an amount of one unit of currency at maturity, starting from \\(P(t,T)\\) units of currency at time \\(t\\), when accruing occurs proportionally to the investment time.\n\\[\n\\begin{align*}\nP(t,T)(1 + L(t,T)\\tau(t,T)) = 1\n\\end{align*}\n\\tag{4}\\]\nSo, the bond price can be expressed in terms of \\(L\\) as:\n\\[\n\\begin{align*}\nP(t,T) = \\frac{1}{1 + L(t,T)\\tau(t,T)}\n\\end{align*}\n\\tag{5}\\]\n\n\nDefinition 4 (Annually-compounded spot interest rate.) The annually-compounded spot interest rate prevailing at time \\(t\\) for the maturity \\(T\\) is denoted by \\(Y(t,T)\\) and is the constant (annualized) rate at which an investment has to be made to produce an amount of one unit of currency at maturity, starting from \\(P(t,T)\\) units of currency at time \\(t\\), reinvesting the obtained amounts once a year. We have:\n\\[\nP(t,T)(1+Y(t,T))^{\\tau(t,T)} = 1\n\\tag{6}\\]\n\nEquivalently,\n\\[\nY(t,T) = \\left[\\frac{1}{P(t,T)}\\right]^{\\frac{1}{\\tau(t,T)}} - 1\n\\tag{7}\\]\n\nDefinition 5 (Zero-coupon curve.) The zero-coupon curve(sometimes also referred to as the yield curve) at time \\(t\\) is the graph of the function\n\\[\nT \\mapsto \\begin{cases}\nL(t,T) & t &lt; T \\leq t + 1 \\text{ years }\\\\\nY(t,T) & T \\geq t + 1\\text{ years }\n\\end{cases}\n\\tag{8}\\]\n\n\nDefinition 6 (Discounting Curve.) The discounting curve at time \\(t\\) is the plot of the function:\n\\[\nT \\mapsto P(t,T), \\quad T &gt; t\n\\tag{9}\\]\nSuch a curve is also referred to as the term structure of discount factors.\n\n\nDefinition 7 (Simply-compounded forward interest rate.) The simply compounded forward interest rate prevailing at time \\(t\\) for the expiry \\(T &gt; t\\), maturity \\(S &gt; T\\) and is defined by:\n\\[\n\\begin{align*}\nF(t;T,S) := \\frac{1}{\\tau(T,S)}\\left(\\frac{P(t,T)}{P(t,S)} - 1\\right)\n\\end{align*}\n\\tag{10}\\]\n\n\nDefinition 8 (Instantaneous forward rate.) The instantaneous forward interest rate prevailing at time \\(t\\) for the maturity \\(T &gt; t\\) is denoted by \\(f(t,T)\\) and is defined by:\n\\[\n\\begin{align*}\nf(t,T) &= \\lim_{S \\to T^+} F(t;T,S) \\\\\n&= \\lim_{S \\to T^+} \\frac{1}{\\tau(T,S)}\\frac{P(t,T) - P(t,S)}{P(t,T)} \\\\\n&= -\\frac{1}{P(t,T)}\\lim_{S \\to T^+} \\frac{P(t,S) - P(t,T)}{\\tau(T,S)}\\\\\n&= -\\frac{1}{P(t,T)}\\lim_{h\\to 0} \\frac{P(t,T+h) - P(t,T)}{h}\\\\\n&= -\\frac{1}{P(t,T)} \\frac{\\partial}{T}(P(t,T))\\\\\n&= - \\frac{\\partial}{\\partial T}(\\ln P(t,T))\n\\end{align*}\n\\tag{11}\\]\nso we also have:\n\\[\nP(t,T) = \\exp\\left(-\\int_{t}^T f(t,u)du\\right)\n\\tag{12}\\]\n\n\n\n\nLet’s start with the classical LIBOR rate model. Suppose that bank B enters into a contract at time \\(t\\) with bank A, to borrow 1 EUR at time \\(T_0\\) and return 1 EUR plus the interest cost at time \\(T_1\\). What’s the fair interest rate, that bank A and bank B can agree on? The MTM value to bank A is:\n\\[\n\\begin{align*}\nV(t) &= P(t,T_0) \\mathbb{E}^{T_0}[-1|\\mathcal{F}_t] + P(t,T_1)\\mathbb{E}^{T_1}[1+\\tau K|\\mathcal{F}_t]\\\\\n0 &= -P(t,T_0) + P(t,T_1)(1+\\tau K)\n\\end{align*}\n\\]\nwhere \\(\\tau=\\tau(T_0,T_1)\\) is the day-count fraction between \\([T_0,T_1]\\)\n\n\n\nThe fair rate for an interbank lending deal with trade date \\(t\\), starting date \\(T_0\\) (typically 0d or 2d after \\(T\\)) and maturity date \\(T_1\\) is:\n\\[\n\\begin{align*}\nL(t;T_0,T_1) = \\frac{1}{\\tau}\\left[\\frac{P(t,T_0)}{P(t,T_1) - 1}\\right]\n\\end{align*}\n\\]\nPanel banks submit daily estimates for interbank lending rates to the calculation agent. The relevant periods \\([T_0,T_1]\\) considered are \\(1m\\), \\(3m\\), \\(6m\\) and \\(12m\\). LIBOR rate fixings used to be the most important reference rates for interest rate derivatives. Nowadays, overnight rates have become the key reference rates."
  },
  {
    "objectID": "posts/irs_caps_floors_and_swaptions/index.html#fundamentals",
    "href": "posts/irs_caps_floors_and_swaptions/index.html#fundamentals",
    "title": "IRS, Caps, Floors and Swaptions",
    "section": "",
    "text": "I review here a few basic definitions relevant to the interest-rate world.\n\nDefinition 1 (Zero-coupon bond.) A \\(T\\)-maturity zero-coupon bond (pure discount bond) is a contract that guarantees its holder the payment of \\(1\\$\\) at time \\(T\\), with no intermediate payments. The contract value at time \\(t &lt; T\\) is denoted by \\(P(t,T)\\). Clearly, \\(P(T,T) = 1\\) \\(\\forall T\\in[0,\\infty)\\).\n\n\nDefinition 2 (Continuously-compounded spot interest rate.) The continuously-compounded spot interest rate prevailing at time \\(t\\) for the maturity \\(T\\) is denoted by \\(R(t,T)\\) and is the constant rate at which an investment of \\(P(t,T)\\) units of currency at time \\(t\\) accrues continuously to yield a unit amount of currency at maturity \\(T\\).\n\\[\n\\begin{align*}\nR(t,T) := - \\frac{\\ln P(t,T)}{\\tau(t,T)}\n\\end{align*}\n\\tag{1}\\]\nThe continuously-compounded interest rate is therefore a constant rate that is consistent with the zero-coupon-bond prices such that:\n\\[\n\\begin{align*}\ne^{R(t,T)\\tau(t,T)}P(t,T) = 1\n\\end{align*}\n\\tag{2}\\]\nfrom which we can express the bond price in terms of the continuously compounded rate \\(R\\):\n\\[\n\\begin{align*}\nP(t,T) = e^{-R(t,T)\\tau(t,T)}\n\\end{align*}\n\\tag{3}\\]\n\n\nDefinition 3 (Simply-compounded spot interest rate.) The simply-compounded spot interest rate prevailing at time \\(t\\) for the maturity \\(T\\) is denoted \\(L(t,T)\\) and is the constant rate at which an investment has to be made to produce an amount of one unit of currency at maturity, starting from \\(P(t,T)\\) units of currency at time \\(t\\), when accruing occurs proportionally to the investment time.\n\\[\n\\begin{align*}\nP(t,T)(1 + L(t,T)\\tau(t,T)) = 1\n\\end{align*}\n\\tag{4}\\]\nSo, the bond price can be expressed in terms of \\(L\\) as:\n\\[\n\\begin{align*}\nP(t,T) = \\frac{1}{1 + L(t,T)\\tau(t,T)}\n\\end{align*}\n\\tag{5}\\]\n\n\nDefinition 4 (Annually-compounded spot interest rate.) The annually-compounded spot interest rate prevailing at time \\(t\\) for the maturity \\(T\\) is denoted by \\(Y(t,T)\\) and is the constant (annualized) rate at which an investment has to be made to produce an amount of one unit of currency at maturity, starting from \\(P(t,T)\\) units of currency at time \\(t\\), reinvesting the obtained amounts once a year. We have:\n\\[\nP(t,T)(1+Y(t,T))^{\\tau(t,T)} = 1\n\\tag{6}\\]\n\nEquivalently,\n\\[\nY(t,T) = \\left[\\frac{1}{P(t,T)}\\right]^{\\frac{1}{\\tau(t,T)}} - 1\n\\tag{7}\\]\n\nDefinition 5 (Zero-coupon curve.) The zero-coupon curve(sometimes also referred to as the yield curve) at time \\(t\\) is the graph of the function\n\\[\nT \\mapsto \\begin{cases}\nL(t,T) & t &lt; T \\leq t + 1 \\text{ years }\\\\\nY(t,T) & T \\geq t + 1\\text{ years }\n\\end{cases}\n\\tag{8}\\]\n\n\nDefinition 6 (Discounting Curve.) The discounting curve at time \\(t\\) is the plot of the function:\n\\[\nT \\mapsto P(t,T), \\quad T &gt; t\n\\tag{9}\\]\nSuch a curve is also referred to as the term structure of discount factors.\n\n\nDefinition 7 (Simply-compounded forward interest rate.) The simply compounded forward interest rate prevailing at time \\(t\\) for the expiry \\(T &gt; t\\), maturity \\(S &gt; T\\) and is defined by:\n\\[\n\\begin{align*}\nF(t;T,S) := \\frac{1}{\\tau(T,S)}\\left(\\frac{P(t,T)}{P(t,S)} - 1\\right)\n\\end{align*}\n\\tag{10}\\]\n\n\nDefinition 8 (Instantaneous forward rate.) The instantaneous forward interest rate prevailing at time \\(t\\) for the maturity \\(T &gt; t\\) is denoted by \\(f(t,T)\\) and is defined by:\n\\[\n\\begin{align*}\nf(t,T) &= \\lim_{S \\to T^+} F(t;T,S) \\\\\n&= \\lim_{S \\to T^+} \\frac{1}{\\tau(T,S)}\\frac{P(t,T) - P(t,S)}{P(t,T)} \\\\\n&= -\\frac{1}{P(t,T)}\\lim_{S \\to T^+} \\frac{P(t,S) - P(t,T)}{\\tau(T,S)}\\\\\n&= -\\frac{1}{P(t,T)}\\lim_{h\\to 0} \\frac{P(t,T+h) - P(t,T)}{h}\\\\\n&= -\\frac{1}{P(t,T)} \\frac{\\partial}{T}(P(t,T))\\\\\n&= - \\frac{\\partial}{\\partial T}(\\ln P(t,T))\n\\end{align*}\n\\tag{11}\\]\nso we also have:\n\\[\nP(t,T) = \\exp\\left(-\\int_{t}^T f(t,u)du\\right)\n\\tag{12}\\]"
  },
  {
    "objectID": "posts/irs_caps_floors_and_swaptions/index.html#classical-libor-rate-model",
    "href": "posts/irs_caps_floors_and_swaptions/index.html#classical-libor-rate-model",
    "title": "IRS, Caps, Floors and Swaptions",
    "section": "",
    "text": "Let’s start with the classical LIBOR rate model. Suppose that bank B enters into a contract at time \\(t\\) with bank A, to borrow 1 EUR at time \\(T_0\\) and return 1 EUR plus the interest cost at time \\(T_1\\). What’s the fair interest rate, that bank A and bank B can agree on? The MTM value to bank A is:\n\\[\n\\begin{align*}\nV(t) &= P(t,T_0) \\mathbb{E}^{T_0}[-1|\\mathcal{F}_t] + P(t,T_1)\\mathbb{E}^{T_1}[1+\\tau K|\\mathcal{F}_t]\\\\\n0 &= -P(t,T_0) + P(t,T_1)(1+\\tau K)\n\\end{align*}\n\\]\nwhere \\(\\tau=\\tau(T_0,T_1)\\) is the day-count fraction between \\([T_0,T_1]\\)"
  },
  {
    "objectID": "posts/irs_caps_floors_and_swaptions/index.html#spot-libor-rate",
    "href": "posts/irs_caps_floors_and_swaptions/index.html#spot-libor-rate",
    "title": "IRS, Caps, Floors and Swaptions",
    "section": "",
    "text": "The fair rate for an interbank lending deal with trade date \\(t\\), starting date \\(T_0\\) (typically 0d or 2d after \\(T\\)) and maturity date \\(T_1\\) is:\n\\[\n\\begin{align*}\nL(t;T_0,T_1) = \\frac{1}{\\tau}\\left[\\frac{P(t,T_0)}{P(t,T_1) - 1}\\right]\n\\end{align*}\n\\]\nPanel banks submit daily estimates for interbank lending rates to the calculation agent. The relevant periods \\([T_0,T_1]\\) considered are \\(1m\\), \\(3m\\), \\(6m\\) and \\(12m\\). LIBOR rate fixings used to be the most important reference rates for interest rate derivatives. Nowadays, overnight rates have become the key reference rates."
  },
  {
    "objectID": "posts/implementing-vanna-volga/index.html",
    "href": "posts/implementing-vanna-volga/index.html",
    "title": "Implementing Vanna Volga",
    "section": "",
    "text": "It is possible to calculate analytically the values of vanillas or barrier options using the Black-Scholes model, however, they are far from quoted prices. This is because the BS-model is based on the assumption that the volatility \\(\\sigma\\) of the stock price process remains constant throughout the lifetime of the option.\nThe vanna-volga method also known as the trader’s rule of thumb is based on adding an analytical correction to the Black-Scholes price of the instrument. In this note, I derive and implement the original paper The vanna-volga method for implied volatilities, by Castagna and Mercurio."
  },
  {
    "objectID": "posts/implementing-vanna-volga/index.html#background.",
    "href": "posts/implementing-vanna-volga/index.html#background.",
    "title": "Implementing Vanna Volga",
    "section": "",
    "text": "It is possible to calculate analytically the values of vanillas or barrier options using the Black-Scholes model, however, they are far from quoted prices. This is because the BS-model is based on the assumption that the volatility \\(\\sigma\\) of the stock price process remains constant throughout the lifetime of the option.\nThe vanna-volga method also known as the trader’s rule of thumb is based on adding an analytical correction to the Black-Scholes price of the instrument. In this note, I derive and implement the original paper The vanna-volga method for implied volatilities, by Castagna and Mercurio."
  },
  {
    "objectID": "posts/implementing-vanna-volga/index.html#replicating-portfolio.",
    "href": "posts/implementing-vanna-volga/index.html#replicating-portfolio.",
    "title": "Implementing Vanna Volga",
    "section": "Replicating Portfolio.",
    "text": "Replicating Portfolio.\nConsider a Black-Scholes world with two assets : a locally risk free domestic bank account \\(B(t)\\) and a stock \\(S(t)\\). We assume that the volatility of the stock is stochastic, but strike-independent(flat). We have the asset dynamics:\n\\[\n\\begin{align*}\ndB_t &= r_{DOM}B_t dt \\\\\\\\\ndS_t &= \\mu S_t dt + \\sigma_t S_t dW_t\n\\end{align*}\n\\]\nOur aim is to value an arbitrary option contract \\(O=f(t,S_t,\\sigma_t;K)\\) with a strike \\(K\\). We price \\(O\\) using a standard hedging argument. We build a hedge aka replicating portfolio such that it zeroes out the greeks of our net position upto the second order.\nConsider a self-financing portfolio \\(\\Pi_t\\) consisting of:\n\nA long position in \\(1\\) unit of the option \\(O(t;K)\\).\nA short position in \\(\\Delta_t\\) units of the stock \\(S_t\\).\nShort positions in three European vanilla pivot options \\(C_i\\), \\(i \\in \\{1,2,3\\}\\). We short \\(x_i\\) units of \\(C_i\\). It is standard practice, to take \\(C_1,C_2,C_3\\) as a 25-delta put, an ATM call and a 25-delta call option respectively.\n\nThe pivot options have strikes \\(K_1 = K_{25P}\\), \\(K_2 = K_{ATM}\\) and \\(K_3 = K_{25C}\\) and implied volatility quotes (market prices) \\(\\sigma_1\\), \\(\\sigma_2\\) and \\(\\sigma_3\\) which are known to us.\nThe value of the portfolio at time \\(t\\) is:\n\\[\\Pi_t = O_t - \\Delta_t S_t - \\sum_{i=1}^{3} x_i C_t^i \\tag{1}\\]\nBy self-financing, I mean, there is no exogenous infusion or withdrawal of cash, once the portfolio has been setup at time zero. Therefore, the changes in the portfolio are solely due to gains/losses on the constituents. The self-financing condition is:\n\\[d\\Pi_t = dO_t - \\Delta_t dS_t - \\sum_{i=1}^{3} x_i dC_t^i \\tag{2}\\]\nBy Ito’s lemma, the differential of the option price \\(O_t\\) can be written as:\n\\[\n\\begin{align*}\ndO_t &= \\frac{\\partial O}{\\partial t} dt + \\frac{\\partial O}{\\partial S_t} dS_t + \\frac{\\partial O}{\\partial \\sigma_t} d\\sigma_t \\\\\\\\\n&+ \\frac{1}{2}\\frac{\\partial^2 O}{\\partial t^2} (dt)^2 \\\\\\\\\n&+ \\frac{1}{2}\\frac{\\partial^2 O}{\\partial S_t^2} (dS_t)^2 \\\\\\\\\n&+ \\frac{1}{2}\\frac{\\partial^2 O}{\\partial \\sigma_t^2} (d\\sigma_t)^2 \\\\\\\\\n&+ \\frac{\\partial^2 O}{\\partial t \\partial S_t} dt \\cdot dS_t \\\\\\\\\n&+ \\frac{\\partial^2 O}{\\partial S_t \\partial \\sigma_t} dS_t \\cdot d\\sigma_t \\\\\\\\\n&+ \\frac{\\partial^2 O}{\\partial t \\partial \\sigma_t} dt \\cdot d\\sigma_t \\tag{3}\n\\end{align*}\n\\]\nSince \\((dt)^2\\), \\(dt \\cdot dS_t\\), \\(dt \\cdot d\\sigma_t\\) are equal to zero, we can write:\n\\[\n\\begin{align*}\ndO_t &= \\frac{\\partial O}{\\partial t} dt + \\frac{\\partial O}{\\partial S_t} dS_t + \\frac{\\partial O}{\\partial \\sigma_t} d\\sigma_t \\\\\\\\\n&+ \\frac{1}{2}\\frac{\\partial^2 O}{\\partial S_t^2} (dS_t)^2 \\\\\\\\\n&+ \\frac{1}{2}\\frac{\\partial^2 O}{\\partial \\sigma_t^2} (d\\sigma_t)^2 \\\\\\\\\n&+ \\frac{\\partial^2 O}{\\partial S_t \\partial \\sigma_t} dS_t \\cdot d\\sigma_t  \\tag{4}\n\\end{align*}\n\\]\nSimilarly, we can apply Ito’s lemma to the European vanilla pivot options to find the differential \\(dC^i_t\\). Putting it together we have:\n\\[\n\\begin{align*}\nd\\Pi_t &= \\left(\\frac{\\partial O(t;K)}{\\partial t} - \\sum_{i=1}^{3}x_i\\frac{\\partial C^i(t;K_i)}{\\partial t} \\right) dt  \\\\\\\\\n&+ \\left(\\frac{\\partial O(t;K)}{\\partial S_t}  - \\Delta_t - \\sum_{i=1}^{3}x_i\\frac{\\partial C^i(t;K_i)}{\\partial S_t}\\right) dS_t \\\\\\\\\n&+ \\left(\\frac{\\partial O(t;K)}{\\partial \\sigma_t} - \\sum_{i=1}^{3}x_i\\frac{\\partial C^i(t;K_i)}{\\partial \\sigma_t} \\right)d\\sigma_t\\\\\\\\\n&+ \\frac{1}{2}\\left(\\frac{\\partial^2 O(t;K)}{\\partial S_t^2} - \\sum_{i=1}^{3}x_i\\frac{\\partial^2 C^i(t;K_i)}{\\partial S_t^2}\\right)(dS_t)^2 \\\\\\\\\n&+ \\frac{1}{2}\\left(\\frac{\\partial^2 O(t;K)}{\\partial \\sigma_t^2}  - \\sum_{i=1}^{3}x_i\\frac{\\partial^2 C^i(t;K_i)}{\\partial \\sigma_t^2} \\right)(d\\sigma_t)^2 \\\\\\\\\n&+ \\left(\\frac{\\partial^2 O(t;K)}{\\partial S_t \\partial \\sigma_t} - \\sum_{i=1}^{3}x_i\\frac{\\partial^2 C^i(t;K_i)}{\\partial S_t \\partial \\sigma_t}\\right)  dS_t \\cdot d\\sigma_t  \\tag{5}\n\\end{align*}\n\\]\nWe claim that we can choose the weights \\(\\Delta_t\\) and \\(\\mathbf{x}=(x_1,x_2,x_3)\\) of the replicating portfolio, such that the coefficient of the terms \\(dS_t\\), \\(d\\sigma_t\\), \\((d\\sigma_t)^2\\) and \\(dS_t \\cdot d\\sigma_t\\) are zeroed out.\nWe are therefore left with:\n\\[\n\\begin{align*}\nd\\Pi_t &= \\left(\\frac{\\partial O}{\\partial t} - \\sum_{i=1}^{3}x_i\\frac{\\partial C^i_t}{\\partial t} \\right) dt \\\\\\\\\n&+ \\frac{1}{2}\\left(\\frac{\\partial^2 O}{\\partial S_t^2} - \\sum_{i=1}^{3}x_i\\frac{\\partial^2 C^i_t}{\\partial S_t^2}\\right)\\sigma_t^2 S_t^2 dt \\tag{6}\n\\end{align*}\n\\]\nThe portfolio value process has no driving Brownian motion \\(dW_t\\) term, and hence the source of randomness has been eliminated. Therefore, \\(\\Pi_t\\) must be a locally risk-free portfolio. That is, it satisfies:\n\\[d\\Pi_t = r_{DOM}\\Pi_t dt \\tag{7}\\]"
  },
  {
    "objectID": "posts/implementing-vanna-volga/index.html#calculating-the-vv-weights",
    "href": "posts/implementing-vanna-volga/index.html#calculating-the-vv-weights",
    "title": "Implementing Vanna Volga",
    "section": "Calculating the VV weights",
    "text": "Calculating the VV weights\nWe assume hereafter, that the constant BS volatility is the at-the-money one; \\(\\sigma = \\sigma_2 = \\sigma_{ATM}\\). We assume \\(t=0\\), so we can drop the argument \\(t\\) in the call prices \\(C_i(t;K)\\) in equation (5). The weights \\(\\mathbf{x}=(x_1,x_2,x_3)\\) are determined by solving the system of equations \\(A\\mathbf{x}=\\mathbf{b}\\) where:\n\\[\nA = \\begin{bmatrix}\n\\frac{\\partial C_1(K_1)}{\\partial \\sigma_t} & \\frac{\\partial C_1(K_2)}{\\partial \\sigma_t} &  \\frac{\\partial C_3(K_3)}{\\partial \\sigma_t} \\\\\\\\\n\\frac{\\partial^2 C_1(K_1)}{\\partial S_t \\partial \\sigma_t} & \\frac{\\partial^2 C_2(K_2)}{\\partial S_t \\partial \\sigma_t} & \\frac{\\partial^2 C_3(K_3)}{\\partial S_t \\partial \\sigma_t}\\\\\\\\\n\\frac{\\partial^2 C_1(K_1)}{\\partial \\sigma_t^2} & \\frac{\\partial^2 C_2(K_2)}{\\partial \\sigma_t^2} & \\frac{\\partial^2 C_3(K_3)}{\\partial \\sigma_t^2}\n\\end{bmatrix}, \\quad\n\\mathbf{b} = \\begin{bmatrix}\n\\frac{\\partial O(K)}{\\partial \\sigma_t} \\\\\\\\\n\\frac{\\partial^2 O(K)}{\\partial S_t \\partial \\sigma_t} \\\\\\\\\n\\frac{\\partial^2 O(K)}{\\partial \\sigma_t^2}\n\\end{bmatrix}\n\\]\nThe entries in the first, second and third rows of \\(A\\) and \\(\\mathbf{b}\\) are the option vega, the option vanna and the option volga.\nI derived the expressions for option vega, vanna and volga here. They are:\n\\[\n\\begin{align*}\n\\text{Vega} &= S_0 e^{-r_{FOR}T} \\phi(d_{+}) \\sqrt{T} \\\\\\\\\n\\text{Vanna} &= -e^{-r_{FOR}T} \\phi(d_{+})\\frac{d_{-}}{\\sigma}\\\\\\\\\n\\text{Volga} &= S_0 e^{-r_{FOR}T}\\sqrt{T}\\phi(d_{+}) \\frac{d_{+}d_{-}}{\\sigma}\n\\end{align*}\n\\]\nWe can re-phrase the other greeks in terms of vega \\(\\mathcal{V}\\). Recall, that \\(d_{+}\\) varies with the option strike \\(K\\), so all other things equal, we can write \\(\\mathcal{V} = \\mathcal{V}(K)\\).\n\\[\n\\begin{align*}\n\\text{Vanna} &= -\\frac{d_{-}}{\\sigma S_0 \\sqrt{T}} \\mathcal{V}(K)\\\\\\\\\n\\text{Volga} &= \\frac{d_{+}d_{-}}{\\sigma} \\mathcal{V}(K)\n\\end{align*}\n\\]\nThe augmented matrix \\([A | b]\\), therefore is:\n\\[\n\\begin{bmatrix}\n\\mathcal{V}(K_1) & \\mathcal{V}(K_2) &  \\mathcal{V}(K_3) & | & \\mathcal{V}(K)\\\\\\\\\n-\\frac{d_{-}(K_1)}{\\sigma S_0 \\sqrt{T}}\\mathcal{V}(K_1) & -\\frac{d_{-}(K_2)}{\\sigma S_0 \\sqrt{T}}\\mathcal{V}(K_2) & -\\frac{d_{-}(K_3)}{\\sigma S_0 \\sqrt{T}}\\mathcal{V}(K_3) & | &\\frac{d_{-}(K)}{\\sigma S_0 \\sqrt{T}}\\mathcal{V}(K)\\\\\\\\\n\\frac{d_{+}(K_1) d_{-}(K_1)}{\\sigma}\\mathcal{V}(K_1) & \\frac{d_{+}(K_2) d_{-}(K_2)}{\\sigma}\\mathcal{V}(K_2) & \\frac{d_{+}(K_3) d_{-}(K_3)}{\\sigma}\\mathcal{V}(K_3) & | & \\frac{d_{+}(K) d_{-}(K)}{\\sigma}\\mathcal{V}(K)\n\\end{bmatrix}\n\\]\nCancelling out the constant terms, we get:\n\\[\n\\begin{bmatrix}\n\\mathcal{V}(K_1) & \\mathcal{V}(K_2) &  \\mathcal{V}(K_3) & | & \\mathcal{V}(K)\\\\\\\\\nd_{-}(K_1)\\mathcal{V}(K_1) & d_{-}(K_2)\\mathcal{V}(K_2) & d_{-}(K_3)\\mathcal{V}(K_3) & | & d_{-}(K)\\mathcal{V}(K)\\\\\\\\\nd_{+}(K_1) d_{-}(K_1)\\mathcal{V}(K_1) & d_{+}(K_2) d_{-}(K_2)\\mathcal{V}(K_2) & d_{+}(K_3) d_{-}(K_3)\\mathcal{V}(K_3) & | & d_{+}(K) d_{-}(K)\\mathcal{V}(K)\n\\end{bmatrix}\n\\]\nPerforming the elementary row operation \\(R_3 \\leftarrow R_3 - d_{+}(K_1) R_2\\), we get:\n\\[\n\\begin{bmatrix}\n\\mathcal{V}(K_1) & \\mathcal{V}(K_2) &  \\mathcal{V}(K_3) & | & \\mathcal{V}(K)\\\\\\\\\nd_{-}(K_1)\\mathcal{V}(K_1) & d_{-}(K_2)\\mathcal{V}(K_2) & d_{-}(K_3)\\mathcal{V}(K_3) & | & d_{-}(K)\\mathcal{V}(K)\\\\\\\\\n0 & \\log\\frac{K_2}{K_1} d_{-}(K_2)\\mathcal{V}(K_2) & \\log \\frac{K_3}{K_1} d_{-}(K_3)\\mathcal{V}(K_3) & | & \\log \\frac{K}{K_1} d_{-}(K)\\mathcal{V}(K)\n\\end{bmatrix}\n\\]\nPerforming the elementary row operation \\(R_2 \\leftarrow R_2 - d_{-}(K_1)R_1\\), we get:\n\\[\n\\begin{bmatrix}\n\\mathcal{V}(K_1) & \\mathcal{V}(K_2) &  \\mathcal{V}(K_3) & | & \\mathcal{V}(K)\\\\\\\\\n0 & \\log\\frac{K_2}{K_1}\\mathcal{V}(K_2) & \\log \\frac{K_3}{K_1}\\mathcal{V}(K_3) & | & \\log \\frac{K}{K_1}\\mathcal{V}(K)\\\\\\\\\n0 & \\log\\frac{K_2}{K_1} d_{-}(K_2)\\mathcal{V}(K_2) & \\log \\frac{K_3}{K_1} d_{-}(K_3)\\mathcal{V}(K_3) & | & \\log \\frac{K}{K_1} d_{-}(K)\\mathcal{V}(K)\n\\end{bmatrix}\n\\]\nPerforming the elementary row operation \\(R_3 \\leftarrow R_3 - d_{-}(K_2) R_2\\), we get:\n\\[\n\\begin{bmatrix}\n\\mathcal{V}(K_1) & \\mathcal{V}(K_2) &  \\mathcal{V}(K_3) & | & \\mathcal{V}(K)\\\\\\\\\n0 & \\log\\frac{K_2}{K_1}\\mathcal{V}(K_2) & \\log \\frac{K_3}{K_1}\\mathcal{V}(K_3) & | & \\log \\frac{K}{K_1}\\mathcal{V}(K)\\\\\\\\\n0 & 0 & \\log \\frac{K_3}{K_1} \\frac{K_3}{K_2}\\mathcal{V}(K_3) & | & \\log \\frac{K}{K_1} \\log \\frac{K}{K_2}\\mathcal{V}(K)\n\\end{bmatrix}\n\\]\nPerforming the elementary row operation \\(R_1 \\leftarrow \\log(K_2/K_1) R_1 - R_2\\), we get:\n\\[\n\\begin{bmatrix}\n\\log \\frac{K_2}{K_1}\\mathcal{V}(K_1) & 0 & - \\log \\frac{K_3}{K_2}\\mathcal{V}(K_3) & | & -\\log \\frac{K}{K_2}\\mathcal{V}(K)\\\\\\\\\n0 & \\log\\frac{K_2}{K_1}\\mathcal{V}(K_2) & \\log \\frac{K_3}{K_1}\\mathcal{V}(K_3) & | & \\log \\frac{K}{K_1}\\mathcal{V}(K)\\\\\\\\\n0 & 0 & \\log \\frac{K_3}{K_1} \\log \\frac{K_3}{K_2}\\mathcal{V}(K_3) & | & \\log \\frac{K}{K_1} \\log \\frac{K}{K_2}\\mathcal{V}(K)\n\\end{bmatrix}\n\\]\nPerforming the elementary row operation \\(R_1 \\leftarrow \\log(K_3/K_1)R_1 + R_3\\), we get:\n\\[\n\\begin{bmatrix}\n\\log \\frac{K_3}{K_1}\\log \\frac{K_2}{K_1}\\mathcal{V}(K_1) & 0 & 0 & | & \\log \\frac{K}{K_3}\\log \\frac{K}{K_2}\\mathcal{V}(K)\\\\\\\\\n0 & \\log\\frac{K_2}{K_1}\\mathcal{V}(K_2) & \\log \\frac{K_3}{K_1}\\mathcal{V}(K_3) & | & \\log \\frac{K}{K_1}\\mathcal{V}(K)\\\\\\\\\n0 & 0 & \\log \\frac{K_3}{K_1} \\log \\frac{K_3}{K_2}\\mathcal{V}(K_3) & | & \\log \\frac{K}{K_1} \\log \\frac{K}{K_2}\\mathcal{V}(K)\n\\end{bmatrix}\n\\]\nPerforming the elementary row operation \\(R_2 \\leftarrow \\log(K_3/K_2) R_2 - R_3\\), we get:\n\\[\n\\begin{bmatrix}\n\\log \\frac{K_3}{K_1}\\log \\frac{K_2}{K_1}\\mathcal{V}(K_1) & 0 & 0 & | & \\log \\frac{K}{K_3}\\log \\frac{K}{K_2}\\mathcal{V}(K)\\\\\\\\\n0 & \\log\\frac{K_2}{K_1} \\log \\frac{K_3}{K_2}\\mathcal{V}(K_2) & 0 & | & \\log \\frac{K}{K_1} \\log \\frac{K_3}{K}\\mathcal{V}(K)\\\\\\\\\n0 & 0 & \\log \\frac{K_3}{K_1} \\log \\frac{K_3}{K_2}\\mathcal{V}(K_3) & | & \\log \\frac{K}{K_1} \\log \\frac{K}{K_2}\\mathcal{V}(K)\n\\end{bmatrix}\n\\]\nThus, the solution vector \\(\\mathbf{x}\\) is:\n\\[\n\\begin{align*}\nx_1(K) &= \\frac{\\log \\frac{K_3}{K}\\log \\frac{K_2}{K}\\mathcal{V}(K)}{\\log \\frac{K_3}{K_1}\\log \\frac{K_2}{K_1}\\mathcal{V}(K_1)}\\\\\\\\\nx_2(K) &= \\frac{\\log \\frac{K}{K_1} \\log \\frac{K_3}{K}\\mathcal{V}(K)}{\\log\\frac{K_2}{K_1} \\log \\frac{K_3}{K_2}\\mathcal{V}(K_2)}\\\\\\\\\nx_3(K) &= \\frac{\\log \\frac{K}{K_1} \\log \\frac{K}{K_2}\\mathcal{V}(K)}{\\log \\frac{K_3}{K_1} \\log \\frac{K_3}{K_2}\\mathcal{V}(K_3)} \\tag{9}\n\\end{align*}\n\\]"
  },
  {
    "objectID": "posts/implementing-vanna-volga/index.html#the-vv-option-price.",
    "href": "posts/implementing-vanna-volga/index.html#the-vv-option-price.",
    "title": "Implementing Vanna Volga",
    "section": "The VV Option price.",
    "text": "The VV Option price.\nWe can now proceed to the definition of an option price that is consistent with the market prices of the basic options. The above replication argument shows that a portfolio comprising of \\(x_i(K)\\) units of the option with strike \\(K_i\\) and \\(\\Delta_0\\) units of the underlying gives a local perfect hedge in a Black-Scholes world. The hedging strategy has to be implemented at prevailing market prices, which generates an extra cost with respect to the Black-Scholes value of the options portfolio. Such a cost has to be added to the Black-Scholes price \\(O^{BS}(K)\\), with \\(t=0\\), to produce an arbitrage free price which is consistent with the quoted option prices \\(C_1^{MKT}(K_1)\\), \\(C_2^{MKT}(K_2)\\) and \\(C_3^{MKT}(K_3)\\).\nIn fact, in the case of a short-maturity \\(T\\), the equation (7) can be written as:\n\\[\n\\begin{align*}\n&((S\\_T - K)^{+} - O^{BS}(K)) - \\Delta\\_0(S\\_T - S\\_0)\\\\\\\\\n-& \\sum_{i=1}^{3} x_i(K) (C_i^{MKT}(K_i) - C_i^{BS}(K_i))\\\\\\\\\n&= r_{DOM} (O^{BS}(K) - \\Delta_0 S_0 - \\sum_{i=1}^{3} x_i(K_i)C_i^{BS}(K_i))T \\tag{10}\n\\end{align*}\\]\nTherefore, setting\n\\[O_{VV}^{MKT}(K) = O^{BS}(K) + \\sum_{i=1}^{3}x_i(K)(C_i^{MKT}(K_i) - C_i^{BS}(K_i))\\tag{11}\\]\nWe get:\n\\[\n\\begin{align*}\n(S_T - K)^{+} &= O^{MKT}_{VV}(K) + \\Delta_0(S_T - S_0) \\\\\\\\\n&+ r_{DOM} (O^{BS}(K) - \\Delta_0 S_0 - \\sum_{i=1}^{3} x_i(K)C_i^{BS}(K_i))T \\tag{12}\n\\end{align*}\\]\nThus, when actual market prices are considered, the option payout \\((S_T-K)^{+}\\) can still be replicated by starting with an initial capital of \\(O_{VV}^{MKT}(K)\\), buying \\(\\Delta_0\\) units of the stock and \\(x_i(K)\\) units of the pivot options with strike \\(K_i\\), and investing the rest at the cash rate \\(r_{DOM}\\).\nHence, implicitly ignoring the replication error over longer maturities, the price of the option must the initial capital required to setup the hedge portfolio \\(O_{VV}^{MKT}(K)\\).\nThe option premium \\(O_{VV}^{MKT}(K)\\) equals the Black-Scholes price of the option \\(O^{BS}(K)\\) plus a vanna-volga correction term, or overhedge \\(O_{VV}\\), which is the difference between the market quoted prices of the pivot options and the Black-Scholes prices of the pivot options under the constant BS volatility \\(\\sigma = \\sigma_{ATM}\\)."
  },
  {
    "objectID": "posts/implementing-vanna-volga/index.html#deriving-the-implied-volatility-smile.",
    "href": "posts/implementing-vanna-volga/index.html#deriving-the-implied-volatility-smile.",
    "title": "Implementing Vanna Volga",
    "section": "Deriving the implied volatility smile.",
    "text": "Deriving the implied volatility smile.\nWe can now derive an easy approximation for the vanna-volga implied volatility smile curve \\(\\xi(K)\\).\nIn formula (11), we Taylor expand the market quotes \\(C_1^{MKT}(K_1)\\), \\(C_2^{MKT}(K_2)\\), \\(C_3^{MKT}(K_3)\\) and \\(O^{MKT}_{VV}(K)\\), about \\(\\sigma = \\sigma_{2}\\). We have:\n\\[\n\\begin{align*}\nC_i^{MKT}(\\sigma_i,K_i) &= C_i^{BS}(\\sigma,K_i)+ \\frac{\\partial C_i^{BS}(\\sigma,K_i)}{\\partial \\sigma}(\\sigma_i - \\sigma)\\\\\\\\\nO_{VV}^{MKT}(\\xi(K),K) &= O^{BS}(\\sigma,K)+ \\frac{\\partial O^{BS}(\\sigma,K)}{\\partial \\sigma}(\\xi(K) - \\sigma) \\tag{13}\n\\end{align*}\n\\]\nEquivalently,\n\\[\n\\begin{align*}\nC_i^{MKT}(\\sigma_i,K_i) - C_i^{BS}(\\sigma,K_i) &= \\mathcal{V}(K_i)(\\sigma_i - \\sigma)\\\\\\\\\nO_{VV}^{MKT}(\\xi(K),K) - O^{BS}(\\sigma,K) &= \\mathcal{V}(K)(\\xi(K) - \\sigma) \\tag{14}\n\\end{align*}\n\\]\nSubstituting (13) and (14) in formula (11), we get:\n\\[\n\\begin{align*}\n\\mathcal{V}(K)(\\xi(K) - \\sigma) &= \\sum_{i=1}^{3} x_i(K) \\mathcal{V}(K_i)(\\sigma_i - \\sigma)\n\\end{align*}\n\\]\nSince \\(\\sigma_2 = \\sigma\\), the second term in the summation vanishes. Simplifying, we have:\n\\[\n\\begin{align*}\n\\mathcal{V}(K)(\\xi(K) - \\sigma_2) &= x_1(K)\\mathcal{V}(K_1)(\\sigma_1 - \\sigma_2) + x_3(K)\\mathcal{V}(K_3)(\\sigma_3 - \\sigma_2)\\\\\\\\\n\\xi(K) - \\sigma_2 &=  x_1(K)\\frac{\\mathcal{V}(K_1)}{\\mathcal{V}(K)}(\\sigma_1 - \\sigma_2) +  x_3(K)\\frac{\\mathcal{V}(K_3)}{\\mathcal{V}(K)}(\\sigma_3 - \\sigma_2)\\\\\\\\\n\\xi(K) &= \\frac{\\log \\frac{K_3}{K}\\log \\frac{K_2}{K}}{\\log \\frac{K_3}{K_1}\\log \\frac{K_2}{K_1}} \\sigma_1 + \\frac{\\log \\frac{K}{K_1} \\log \\frac{K}{K_2}}{\\log \\frac{K_3}{K_1} \\log \\frac{K_3}{K_2}}\\sigma_3 \\\\\\\\\n&+ \\left(1 - x_1(K)\\frac{\\mathcal{V}(K_1)}{\\mathcal{V}(K)} - x_3(K)\\frac{\\mathcal{V}(K_3)}{\\mathcal{V}(K)} \\right)\\sigma_2 \\tag{15}\n\\end{align*}\n\\]\nBut, we know from the matrix system \\(A\\mathbf{x}=b\\), that the weights \\(\\mathbf{x}=(x_1,x_2,x_3)\\) satisfy:\n\\[x_1(K) \\mathcal{V}(K_1) + x_2(K) \\mathcal{V}(K_2) + x_3(K) \\mathcal{V}(K_3) = \\mathcal{V}(K) \\tag{16}\\]\nSo,\n\\[\n\\begin{align*}\n\\left(1 - x_1(K)\\frac{\\mathcal{V}(K_1)}{\\mathcal{V}(K)} - x_3(K)\\frac{\\mathcal{V}(K_3)}{\\mathcal{V}(K)} \\right) &= x_2(K) \\frac{\\mathcal{V}(K_2)}{\\mathcal{V}(K)}\\\\\\\\\n&=\\frac{\\log \\frac{K}{K_1} \\log \\frac{K_3}{K}}{\\log\\frac{K_2}{K_1} \\log \\frac{K_3}{K_2}} \\tag{17}\n\\end{align*}\n\\]\nSubstituting (17) in the expression (15), we have the result:\n\\[\n\\xi^{1}(K) := \\xi(K) = \\frac{\\log \\frac{K_3}{K}\\log \\frac{K_2}{K}}{\\log \\frac{K_3}{K_1}\\log \\frac{K_2}{K_1}} \\sigma_1 + \\frac{\\log \\frac{K}{K_1} \\log \\frac{K}{K_2}}{\\log \\frac{K_3}{K_1} \\log \\frac{K_3}{K_2}}\\sigma_3 + \\frac{\\log \\frac{K}{K_1} \\log \\frac{K_2}{K_1}}{\\log \\frac{K_2}{K_1} \\log \\frac{K_3}{K_2}} \\tag{18}\n\\]\nThe VV-implied volatility smile \\(\\xi(K)\\) is thus approximated by a linear combination of the implied vol quotes \\(\\sigma_1\\), \\(\\sigma_2\\) and \\(\\sigma_3\\) of the vanilla pivot options with coefficients that add up to \\(1\\). This approximation is extremely accurate in the interval \\(\\[K_1,K_3\\]\\). The wings, however, tend to be overvalued."
  },
  {
    "objectID": "posts/implementing-vanna-volga/index.html#a-second-order-approximation-for-vv-smile.",
    "href": "posts/implementing-vanna-volga/index.html#a-second-order-approximation-for-vv-smile.",
    "title": "Implementing Vanna Volga",
    "section": "A second order approximation for VV-smile.",
    "text": "A second order approximation for VV-smile.\nLet’s Taylor expand the market quotes \\(C_i^{MKT}(\\sigma_i,K_i)\\) and \\(O_{VV}^{MKT}(\\xi(K),K)\\) upto the second order.\n\\[\n\\begin{align*}\nC_i^{MKT}(\\sigma_i,K_i) - C_i^{BS}(\\sigma,K_i) &= \\frac{\\partial C_i^{BS}(\\sigma,K_i)}{\\partial \\sigma}(\\sigma_i - \\sigma) + \\frac{1}{2}\\frac{\\partial^2 C_i^{BS}(\\sigma,K_i)}{\\partial \\sigma^2}(\\sigma_i - \\sigma)^2 \\\\\\\\\nO^{MKT}_{VV}(\\xi(K),K) - O^{BS}(\\sigma,K) &= \\frac{\\partial O^{BS}(\\sigma,K)}{\\partial \\sigma}(\\xi(K) - \\sigma) + \\frac{1}{2}\\frac{\\partial^2 O^{BS}(\\sigma,K)}{\\partial \\sigma^2}(\\xi(K) - \\sigma)^2 \\tag{19}\n\\end{align*}\n\\]\nEquivalently,\n\\[\n\\begin{align*}\nC_i^{MKT}(\\sigma_i,K_i) - C_i^{BS}(\\sigma,K_i) &= \\mathcal{V}(K_i)(\\sigma_i - \\sigma) + \\frac{1}{2}\\frac{d_{+}(K_i)d_{-}(K_i)}{\\sigma}\\mathcal{V}(K_i)(\\sigma_i - \\sigma)^2 \\\\\\\\\nO^{MKT}_{VV}(\\xi(K),K) - O^{BS}(\\sigma,K) &= \\mathcal{V}(K)(\\xi(K) - \\sigma) + \\frac{1}{2}\\frac{d\\_{+}(K) d\\_{-}(K)}{\\sigma}\\mathcal{V}(K)(\\xi(K) - \\sigma)^2 \\tag{20}\n\\end{align*}\n\\]\nSubstituting (20) in formula (11):\n\\[\n\\mathcal{V}(K)(\\xi(K) - \\sigma) + \\frac{1}{2}\\frac{d\\_{+}(K)d\\_{-}(K)}{\\sigma}\\mathcal{V}(K)(\\xi(K) - \\sigma)^2 \\\\\\\\\n= x\\_1\\mathcal{V}(K\\_1)(\\sigma\\_1 - \\sigma) + \\frac{1}{2}x\\_1\\frac{d\\_{+}(K\\_1)d\\_{-}(K\\_1)}{\\sigma}\\mathcal{V}(K\\_1)(\\sigma\\_1 - \\sigma)^2\\\\\\\\\n+(\\sigma\\_3 - \\sigma) + \\frac{1}{2}x\\_3\\frac{d\\_{+}(K\\_3)d\\_{-}(K\\_3)}{\\sigma}\\mathcal{V}(K\\_3)(\\sigma\\_3 - \\sigma)^2 \\tag{21}\n\\]\nSimplifying we have:\n\\[\n\\begin{align*}\n&(\\xi(K) - \\sigma_2) + \\frac{1}{2}\\frac{d_{+}(K)d_{-}(K)}{\\sigma}(\\xi(K) - \\sigma_2)^2 \\\\\\\\\n=& \\frac{\\log \\frac{K_3}{K}\\log \\frac{K_2}{K}}{\\log \\frac{K_3}{K_1}\\log \\frac{K_2}{K_1}}(\\sigma_1 - \\sigma_2) + \\frac{1}{2}\\frac{d_{+}(K_1)d_{-}(K_1)}{\\sigma}\\frac{\\log \\frac{K_3}{K}\\log \\frac{K_2}{K}}{\\log \\frac{K_3}{K_1}\\log \\frac{K_2}{K_1}}(\\sigma_1 - \\sigma_2)^2\\\\\\\\\n+& \\frac{\\log \\frac{K}{K_1} \\log \\frac{K}{K_2}}{\\log \\frac{K_3}{K_1} \\log \\frac{K_3}{K_2}}(\\sigma_3 - \\sigma_2) + \\frac{1}{2}\\frac{d_{+}(K_3)d_{-}(K_3)}{\\sigma}\\frac{\\log \\frac{K}{K_1} \\log \\frac{K}{K_2}}{\\log \\frac{K_3}{K_1} \\log \\frac{K_3}{K_2}}(\\sigma_3 - \\sigma_2)^2\n\\end{align*}\\tag{22}\n\\]\nLet\n\\[\n\\begin{align*}\nD_1(K) &:= \\frac{\\log \\frac{K_3}{K}\\log \\frac{K_2}{K}}{\\log \\frac{K_3}{K_1}\\log \\frac{K_2}{K_1}}(\\sigma_1 - \\sigma_2) + \\frac{\\log \\frac{K}{K_1} \\log \\frac{K}{K_2}}{\\log \\frac{K_3}{K_1} \\log \\frac{K_3}{K_2}}(\\sigma_3 - \\sigma_2)\\\\\\\\\n&= \\xi^1(K) - \\sigma_2 \\tag{23}\n\\end{align*}\n\\]\nand\n\\[\n\\begin{align*}\nD_2(K) &:= d_{+}(K_1)d_{-}(K_1)\\frac{\\log \\frac{K_3}{K}\\log \\frac{K_2}{K}}{\\log \\frac{K_3}{K_1}\\log \\frac{K_2}{K_1}}(\\sigma_1 - \\sigma_2)^2 \\\\\\\\\n&+ d_{+}(K_3)d_{-}(K_3)\\frac{\\log \\frac{K}{K_1} \\log \\frac{K}{K_2}}{\\log \\frac{K_3}{K_1} \\log \\frac{K_3}{K_2}}(\\sigma_3 - \\sigma_2)^2 \\tag{24}\n\\end{align*}\n\\]\nSubstituting (23) and (24) in equation (22), we get:\n\\[(\\xi(K) - \\sigma_2) + \\frac{d_{+}(K)d_{-}(K)}{2\\sigma_2}(\\xi(K) - \\sigma_2)^2 = D_1(K) + \\frac{D_2(K)}{2\\sigma_2}\\tag{25}\\]\nMultiplying throughout by \\(2\\sigma_2\\), we get:\n\\[2\\sigma_2(\\xi(K) - \\sigma_2) + d_{+}(K)d_{-}(K)(\\xi(K) - \\sigma_2)^2 = 2\\sigma_2 D_1(K) + D_2(K)\\tag{26}\\]\nSolving for \\(\\xi(K) - \\sigma_2\\), we have:\n\\[\n\\begin{align*}\n\\xi(K) - \\sigma_2 &= \\frac{-2\\sigma_2 \\pm \\sqrt{4\\sigma_2^2-4d_{+}(K)d_{-}(K)(2\\sigma_2 D_1(K) + D_2(K))}}{2d_{+}(K)d_{-}(K)}\\\\\\\\\n\\xi^2(K) := \\xi(K) &=\\sigma_2 + \\frac{-\\sigma_2 \\pm \\sqrt{\\sigma_2^2-d_{+}(K)d_{-}(K)(2\\sigma_2 D_1(K) + D_2(K))}}{d_{+}(K)d_{-}(K)} \\tag{27}\n\\end{align*}\n\\]"
  },
  {
    "objectID": "posts/gaussian-discriminant-analysis/index.html",
    "href": "posts/gaussian-discriminant-analysis/index.html",
    "title": "Classification Algorithms",
    "section": "",
    "text": "Let’s say that you have input data \\(\\mathcal{D}=\\{(\\mathbf{x}_i,y_i): i=1,2,\\ldots,N\\}\\), and suppose that \\(y_i \\in \\{0,1\\}\\). Each input has \\(D\\)-features, so \\(\\mathbf{x}_i \\in \\mathbf{R}^D\\). You want to classify an arbitrary feature vector \\(\\mathbf{x}\\) into \\(y=0\\) or \\(y=1\\).\nOne way to build a classifier is to learn the joint probability distribution \\(p(\\mathbf{x},y)\\) and then to condition on \\(\\mathbf{x}\\), thereby deriving \\(p(y=c|\\mathbf{x})\\). This is called the generative approach. An alternative approach is to fit a model of the form \\(p(y|\\mathbf{x})\\) directly. This is called the discriminative approach."
  },
  {
    "objectID": "posts/gaussian-discriminant-analysis/index.html#discriminative-versus-generative-models",
    "href": "posts/gaussian-discriminant-analysis/index.html#discriminative-versus-generative-models",
    "title": "Classification Algorithms",
    "section": "",
    "text": "Let’s say that you have input data \\(\\mathcal{D}=\\{(\\mathbf{x}_i,y_i): i=1,2,\\ldots,N\\}\\), and suppose that \\(y_i \\in \\{0,1\\}\\). Each input has \\(D\\)-features, so \\(\\mathbf{x}_i \\in \\mathbf{R}^D\\). You want to classify an arbitrary feature vector \\(\\mathbf{x}\\) into \\(y=0\\) or \\(y=1\\).\nOne way to build a classifier is to learn the joint probability distribution \\(p(\\mathbf{x},y)\\) and then to condition on \\(\\mathbf{x}\\), thereby deriving \\(p(y=c|\\mathbf{x})\\). This is called the generative approach. An alternative approach is to fit a model of the form \\(p(y|\\mathbf{x})\\) directly. This is called the discriminative approach."
  },
  {
    "objectID": "posts/gaussian-discriminant-analysis/index.html#logistic-regression",
    "href": "posts/gaussian-discriminant-analysis/index.html#logistic-regression",
    "title": "Classification Algorithms",
    "section": "Logistic Regression",
    "text": "Logistic Regression\nThe sigmoid function \\(sigm(x)\\) is defined as:\n\\[\\begin{align*}\nsigm(x) = \\frac{e^x}{1+e^x} \\tag{1}\n\\end{align*}\\]\nThe logistic regression models the class posterior probability as:\n\\[\\begin{align*}\np(y=1|\\mathbf{x}) =sigm(\\mathbf{w}^T \\mathbf{x}) = \\frac{e^{\\mathbf{w}^T \\mathbf{x}}}{1 + e^{\\mathbf{w}^T \\mathbf{x}}} \\tag{2}\n\\end{align*}\\]\nRe-arranging, we can write:\n\\[\\begin{align*}\n\\frac{p(y=1|\\mathbf{x})}{1 - p(y=1|\\mathbf{x})} &= e^{\\mathbf{w}^T \\mathbf{x}}\\\\\n\\log \\left(\\frac{p(y=1|\\mathbf{x})}{1 - p(y=1|\\mathbf{x})}\\right) &= \\mathbf{w}^T \\mathbf{x} \\tag{3}\n\\end{align*}\\]\nThe quantity \\(\\frac{p(y=1|\\mathbf{x})}{1 - p(y=1|\\mathbf{x})}\\) is called the odds and can take on any value between \\(0\\) and \\(\\infty\\). Odds are traditionally used instead of probabilities to express chances of winning in horse-racing and casino games such as roulette.\nThe left-hand side is called log odds or logit. In the simplest case of \\(D=1\\) predictor, the equation (3) becomes:\n\\[\\begin{align*}\n\\log \\left(\\frac{p(y_i = 1|x_i,\\mathbf{w})}{1 - p(y_i = 1|x_i,\\mathbf{w})}\\right) &= w_0 + w_1 x_i \\tag{4}\n\\end{align*}\\]\n\nLikelihood\nThe likelihood of all the data is:\n\\[\\begin{align*}\nL(w_0,w_1) &= \\prod_{i=1}^{N} p(y_i|\\mathbf{x}_i) \\\\\n&= \\prod_{i=1}^{N} p(y_i=1|\\mathbf{x}_i)^{I(y_i=1)} p(y_i=0|\\mathbf{x}_i)^{I(y_i=0)} \\\\\n&= \\prod_{i=1}^{N} p(y_i=1|\\mathbf{x}_i)^{I(y_i=1)} \\cdot [1 - p(y_i=1|\\mathbf{x}_i)]^{I(y_i=0)} \\tag{5}\n\\end{align*}\\]\nWe seek estimates for \\(w_0\\) and \\(w_1\\), such that the predicted class probabilities \\(\\hat{p}(y_i = 1|x_i)\\) and \\(\\hat{p}(y_i = 0|x_i)\\) are as close as possible to the observed class labels. So, we try to maximize the likelihood function \\(L\\)."
  },
  {
    "objectID": "posts/gaussian-discriminant-analysis/index.html#linear-discriminant-analysis",
    "href": "posts/gaussian-discriminant-analysis/index.html#linear-discriminant-analysis",
    "title": "Classification Algorithms",
    "section": "Linear Discriminant Analysis",
    "text": "Linear Discriminant Analysis\nLet \\(c\\) be an arbitrary class label. By the Bayes formula,\n\\[\\begin{align*}\np(y=c|\\mathbf{x}) &= \\frac{p(\\mathbf{x},y=c)}{p(\\mathbf{x})} \\\\\n&= \\frac{p(\\mathbf{x}|y=c) \\cdot p(y=c)}{\\sum_{c=1}^{C} p(\\mathbf{x}|y=c) \\cdot p(y=c)} \\tag{6}\n\\end{align*}\\]\nThe LDA is a generative classifier that models the class conditional distribution \\(p(\\mathbf{x}|y=c)\\) and the class prior \\(p(y=c)\\) and applies the Bayes rule to derive \\(p(y=c|\\mathbf{x})\\).\nLDA makes the following assumptions:\n\nThe prior follows a Bernoulli distribution.\n\n\\[\\begin{align*}\np(y=y_i) = \\phi^{y_i} (1 - \\phi)^{(1-y_i)}\n\\end{align*}\\]\n\nThe data from class \\(c\\) is a \\(D\\)-dimensional multivariate gaussian distribution. We have:\n\n\\[\\begin{align*}\np(\\mathbf{x}|y=c) = \\mathcal{N}(\\mathbf{\\mu}_c,\\mathbf{\\Sigma}) \\tag{8}\n\\end{align*}\\]\nThus,\n\\[\\begin{align*}\np(\\mathbf{x}|y=c) &= \\frac{1}{(2\\pi)^{D/2} |\\det \\mathbf{\\Sigma}|^{1/2}} \\exp \\left[-\\frac{1}{2}(\\mathbf{x} - \\mathbf{\\mu}_c)^T \\mathbf{\\Sigma}^{-1}(\\mathbf{x} - \\mathbf{\\mu}_c) \\right] \\tag{9}\n\\end{align*}\\]\n\nLikelihood\nThe likelihood of all the data is:\n\\[\\begin{align*}\nL(\\phi,\\mathbf{\\mu}_1,\\ldots,\\mathbf{\\mu}_C,\\mathbf{\\Sigma}) &= \\prod_{i=1}^{N} p(\\mathbf{x}_i,y_i)\\\\\n&=\\prod_{i=1}^{N} p(\\mathbf{x}_i|y_i)\\cdot p(y=y_i) \\tag{10}\n\\end{align*}\\]\n\n\nLog-Likelihood\nThe log-likelihood function \\(l\\) is:\n\\[\\begin{align*}\nl(\\phi,\\mathbf{\\mu}_1,\\ldots,\\mathbf{\\mu}_C,\\mathbf{\\Sigma}) = \\log L &= \\sum_{i=1}^{N} \\log p(\\mathbf{x}_i|y_i) + \\sum_{i=1}^{N} \\log p(y=y_i) \\tag{11}\n\\end{align*}\\]\nFor simplicity let’s assume we have \\(C=2\\) classes. Then, the above sum can be written as:\n\\[\\begin{align*}\nl(\\phi,\\mathbf{\\mu}_0,\\mathbf{\\mu}_1,\\mathbf{\\Sigma}) &= \\sum_{i=1}^{N} I(y_i=1)\\log p(\\mathbf{x}_i|y=1) + \\sum_{i=1}^{N} I(y_i = 0)\\log p(\\mathbf{x}_i|y=0) \\\\ &+ \\sum_{i=1}^{N} I(y_i=1) \\log p(y=y_i) + \\sum_{i=1}^{N} I(y_i=0) \\log p(y=y_i) \\tag{12}\n\\end{align*}\\]\n\n\nMLE Estimate for \\(\\phi\\)\nThe first two terms of the log-likelihood function \\(l\\) are not a function of \\(\\phi\\). Taking the partial derivative of \\(l\\) with respect to \\(\\phi\\) on both sides, we are left with:\n\\[\\begin{align*}\n\\frac{\\partial l}{\\partial \\phi} &= \\frac{\\partial}{\\partial \\phi}\\left[\\sum_{i=1}^{N}I(y_i = 1) y_i\\log \\phi + \\sum_{i=1}^{N} I(y_i=0)(1-y_i)\\log(1-\\phi)\\right]\\\\\n&= \\sum_{i=1}^{N} I(y_i = 1) \\frac{y_i}{\\phi} + \\sum_{i=1}^{N} I(y_i=0) (1-y_i)\\frac{-1}{1-\\phi}\\\\\n&= \\sum_{i=1}^{N} I(y_i = 1) \\frac{1}{\\phi} - \\sum_{i=1}^{N} I(y_i=0) \\frac{1}{1-\\phi} \\tag{13}\n\\end{align*}\\]\nEquating \\(\\frac{\\partial l}{\\partial \\phi}\\) to zero:\n\\[\\begin{align*}\n\\sum_{i=1}^{N} I(y_i = 1) \\frac{1}{\\phi} &= \\sum_{i=1}^{N} I(y_i=0) \\frac{1}{1-\\phi}\\\\\n(1-\\phi)\\sum_{i=1}^{N} I(y_i = 1) &= \\phi\\sum_{i=1}^{N} I(y_i=0)\\\\\n\\sum_{i=1}^{N} I(y_i = 1) &= \\phi\\sum_{i=1}^{N} I(y_i=0) + \\phi\\sum_{i=1}^{N} I(y_i=1)\\\\\n\\sum_{i=1}^{N} I(y_i = 1) &= \\phi \\cdot N \\\\\n\\hat{\\phi} &= \\frac{\\sum_{i=1}^{N} I(y_i = 1)}{N} \\tag{14}\n\\end{align*}\\]\n\n\nMLE Estimate for \\(\\mu_c\\)\nFirst, note that:\n\\[\\begin{align*}\n\\log p(\\mathbf{x}_i|y=1) = -\\frac{D}{2}\\log(2\\pi) - \\frac{1}{2} \\log(|\\det \\mathbf{\\Sigma}|) - \\frac{1}{2}(\\mathbf{x}_i - \\mathbf{\\mu}_1)^T \\mathbf{\\Sigma}^{-1}(\\mathbf{x}_i - \\mathbf{\\mu}_1) \\tag{15}\n\\end{align*}\\]\nThus,\n\\[\\begin{align*}\n\\frac{\\partial l}{\\partial \\mu_1} &= -\\frac{1}{2}\\sum_{i=1}^{N} I(y_i = 1)\\frac{\\partial}{\\partial \\mu_1}[(\\mathbf{x}_i - \\mu_1)^T \\mathbf{\\Sigma}^{-1} (\\mathbf{x}_i - \\mu_1)] \\tag{16}\n\\end{align*}\\]\nWe know that, \\(\\frac{\\partial}{\\partial \\mathbf{x}}(\\mathbf{x}^T A \\mathbf{x}) = 2A \\mathbf{x}\\).\nConsequently,\n\\[\\begin{align*}\n\\frac{\\partial l}{\\partial \\mu_1} &= -\\mathbf{\\Sigma}^{-1}\\sum_{i=1}^{N} I(y_i = 1) (\\mathbf{x}_i - \\mu_1) \\tag{17}\n\\end{align*}\\]\nEquating \\(\\frac{\\partial l}{\\partial \\mu_1} = 0\\), we have:\n\\[\\begin{align*}\n\\hat{\\mu}_1 &= \\frac{\\sum_{i=1}^{N}I(y_i = 1) \\mathbf{x}_i}{\\sum_{i=1}^{N}I(y_i = 1)} \\tag{18}\n\\end{align*}\\]\nIn general, for a class \\(c\\), we have:\n\\[\\begin{align*}\n\\hat{\\mu}_c &= \\frac{\\sum_{i=1}^{N}I(y_i = c) \\mathbf{x}_i}{\\sum_{i=1}^{N}I(y_i = c)} \\tag{19}\n\\end{align*}\\]\n\n\nTraces and Determinants\nDefinition. The trace of a square matrix \\(A\\) is defined to the sum of the diagonal elements \\(a_{ii}\\) of \\(A\\)\n\\[\\begin{align*}\ntr(A) = \\sum_i a_{ii} \\tag{20}\n\\end{align*}\\]\nClaim. (Cyclic property) Let \\(A,B,C\\) be arbitrary matrices whose dimensions are conformal and are such that the product \\(ABC\\) (and therefore the other two products) is a square matrix. Then, the trace is invariant under cyclic permutations of matrix products:\n\\[\\begin{align*}\ntr(ABC) = tr(BCA) = tr(CAB) \\tag{21}\n\\end{align*}\\]\nProof.\nWe have:\n\\[\\begin{align*}\ntr(ABC) &= \\sum_{i} (ABC)_{ii} \\tag{22}\n\\end{align*}\\]\nThe \\((i,i)\\) element of \\(ABC\\) must be the inner product of the \\(i\\)-th row of \\(A\\) and the \\(i\\)-th column of \\(BC\\). So:\n\\[\\begin{align*}\ntr(ABC) &= \\sum_{i} \\sum_j A_{ij} (BC)_{ji} \\tag{23}\n\\end{align*}\\]\nThe \\((j,i)\\) element of \\(BC\\) must be the inner product of the \\(j\\)-th row of \\(B\\) and the \\(i\\)-th column of \\(C\\). So:\n\\[\\begin{align*}\ntr(ABC) &= \\sum_{i} \\sum_j A_{ij} \\sum_{k} B_{jk} C_{ki} \\\\\n&= \\sum_{i} \\sum_j \\sum_{k} A_{ij}  B_{jk} C_{ki} \\tag{24}\n\\end{align*}\\]\nBut, this can be re-written as\n\\[\\begin{align*}\ntr(ABC) &= \\sum_{i} \\sum_j \\sum_{k} A_{ij}  B_{jk} C_{ki} \\\\\n&= \\sum_j \\sum_k B_{jk} \\sum_i C_{ki} A_{ij} \\\\\n&= \\sum_j \\sum_k B_{jk} (CA)_{kj} \\\\\n&= \\sum_j (BCA)_{jj} \\\\\n&= tr(BCA) \\tag{25}\n\\end{align*}\\]\nSimilarly, it can be shown that \\(tr(BCA) = tr(CAB)\\). This closes the proof.\nClaim. Let \\(A\\) and \\(B\\) be matrices. Then,\n\\[\\begin{align*}\n\\frac{\\partial}{\\partial A} tr(BA) = B^T \\tag{26}\n\\end{align*}\\]\nProof.\nWe have:\n\\[\\begin{align*}\ntr(BA) &= \\sum_i (BA)_{ii} \\\\\n&= \\sum_i \\sum_j B_{ij} A_{ji}\n\\end{align*}\\]\nConsequently,\n\\[\\begin{align*}\n\\left[\\frac{\\partial}{\\partial A} tr(BA)\\right]_{(i,j)} = \\frac{\\partial}{\\partial a_{ij}} tr(BA) = B_{ji}\n\\end{align*}\\]\nThis closes the proof.\nClaim. Let \\(A\\) be a square matrix. Then:\n\\[\\begin{align*}\n\\frac{\\partial}{\\partial A} \\log (\\det A) = (A^{-1})^T \\tag{27}\n\\end{align*}\\]\nProof.\nRecall that:\n\\[\\begin{align*}\n\\det A = \\sum_{j} a_{ij} C_{ij}\n\\end{align*}\\]\nwhere \\(C_{ij}\\) is the cofactor obtained after removing the \\(i\\)-th row and \\(j\\)-th column of \\(A\\). Thus,\n\\[\\begin{align*}\n\\frac{\\partial}{\\partial a_{ij}}\\det A = C_{ij}\n\\end{align*}\\]\nConsequently,\n\\[\\begin{align*}\n\\frac{\\partial}{\\partial A}\\det A = C\n\\end{align*}\\]\nwhere \\(C\\) is the cofactor matrix of \\(A\\). We know that \\(C = (adj A)^T\\), where \\(adj A\\) is the adjugate of \\(A\\). Moreover, \\(A^{-1} = \\frac{1}{|\\det A|} adj (A)\\). Therefore,\n\\[\\begin{align*}\n\\frac{\\partial}{\\partial A} \\log (\\det A) &= \\frac{1}{|\\det A|} \\frac{\\partial}{\\partial A}\\det A \\\\\n&= \\frac{1}{|\\det A|} C \\\\\n&= \\frac{1}{|\\det A|} (adj A)^T \\\\\n&= \\left(\\frac{1}{|\\det A|} adj A\\right)^T \\\\\n&= (A^{-1})^T\n\\end{align*}\\]\n\n\nMLE Estimate for the covariance matrix \\(\\mathbf{\\Sigma}\\)\nSince \\(\\mathbf{x}^T A \\mathbf{x}\\) is a scalar, \\(\\mathbf{x}^T A \\mathbf{x} = tr(\\mathbf{x}^T A \\mathbf{x})\\). We have:\n\\[\\begin{align*}\n\\mathbf{x}^T A \\mathbf{x} &= tr(\\mathbf{x}^T A \\mathbf{x}) = tr(A \\mathbf{x} \\mathbf{x}^T) = tr(\\mathbf{x} \\mathbf{x}^T A)\n\\end{align*}\\]\nWe have:\n\\[\\begin{align*}\nl(\\phi,\\mu_c,\\mathbf{\\Sigma}) &= \\sum_{i=1}^{N} \\log p(\\mathbf{x}_i|y_i) + \\sum_{i=1}^{N} \\log p(y=y_i) \\\\\n&= -\\frac{ND}{2} \\log(2\\pi) - \\frac{N}{2} \\log(|\\det \\mathbf{\\Sigma}|) \\\\\n&- \\frac{1}{2}\\sum_{i=1}^{N} (\\mathbf{x}_i - \\mu_{y_i})^T \\mathbf{\\Sigma}^{-1} (\\mathbf{x}_i - \\mu_{y_i}) \\\\\n&+ \\sum_{i=1}^{N} \\log p(y=y_i)\\\\\n&= -\\frac{ND}{2} \\log(2\\pi) + \\frac{N}{2} \\log(|\\det \\mathbf{\\Sigma}^{-1}|) \\\\\n&- \\frac{1}{2}\\sum_{i=1}^{N} tr[(\\mathbf{x}_i - \\mu_{y_i}) (\\mathbf{x}_i - \\mu_{y_i})^T \\mathbf{\\Sigma}^{-1}]  \\\\\n&+ \\sum_{i=1}^{N} \\log p(y=y_i)\n\\end{align*}\\]\nDifferentiating both sides with respect to \\(\\mathbf{\\Sigma}^{-1}\\), get:\n\\[\\begin{align*}\n\\frac{\\partial l}{\\partial \\mathbf{\\Sigma}^{-1}} &= \\frac{N}{2} \\mathbf{\\Sigma} - \\frac{1}{2}\\sum_{i=1}^{N} (\\mathbf{x}_i - \\mu_{y_i}) (\\mathbf{x}_i - \\mu_{y_i})^T\n\\end{align*}\\]\nConsequently, we have:\n\\[\\begin{align*}\n\\hat{\\mathbf{\\Sigma}}_{mle} &= \\frac{1}{N} \\sum_{i=1}^{N} (\\mathbf{x}_i - \\mu_{y_i}) (\\mathbf{x}_i - \\mu_{y_i})^T \\tag{28}\n\\end{align*}\\]\n\n\nDecision boundary\nLet’s again consider the binary classification problem with \\(C=2\\) classes. The decision boundary is the line or the hyperplane that separates the part of the space where the probability that the point belongs to class \\(1\\) is larger than \\(50\\) percent from the part where the probability that the point belongs to class \\(2\\) is larger than \\(50\\) percent.\nThe decision boundary is given by \\(p(y=1|\\mathbf{x}) = p(y=0|\\mathbf{x})\\). Since these probabilities involve an exponent, it’s convenient to take logarithms on both sides. This results in:\n\\[\\begin{align*}\n\\cancel{-\\frac{D}{2}\\log(2\\pi)} - \\cancel{\\frac{1}{2} \\log(|\\det \\mathbf{\\Sigma}|)} - \\frac{1}{2}(\\mathbf{x} - \\mathbf{\\mu}_1)^T \\mathbf{\\Sigma}^{-1}(\\mathbf{x} - \\mathbf{\\mu}_1) = \\\\\n\\cancel{-\\frac{D}{2}\\log(2\\pi)} - \\cancel{\\frac{1}{2} \\log(|\\det \\mathbf{\\Sigma}|)} - \\frac{1}{2}(\\mathbf{x} - \\mathbf{\\mu}_0)^T \\mathbf{\\Sigma}^{-1}(\\mathbf{x} - \\mathbf{\\mu}_0) \\tag{29}\n\\end{align*}\\]\nSimplifying, we have:\n\\[\\begin{align*}\n(\\mathbf{x} - \\mathbf{\\mu}_1)^T \\mathbf{\\Sigma}^{-1}(\\mathbf{x} - \\mathbf{\\mu}_1) &= (\\mathbf{x} - \\mathbf{\\mu}_0)^T \\mathbf{\\Sigma}^{-1}(\\mathbf{x} - \\mathbf{\\mu}_0) \\tag{30}\n\\end{align*}\\]\n\\[\\begin{align*}\n(\\mathbf{x}^T - \\mathbf{\\mu}_1^T) \\mathbf{\\Sigma}^{-1}(\\mathbf{x} - \\mathbf{\\mu}_1) &= (\\mathbf{x}^T - \\mathbf{\\mu}_0^T) \\mathbf{\\Sigma}^{-1}(\\mathbf{x} - \\mathbf{\\mu}_0)\\\\\n\\cancel{\\mathbf{x}^T \\mathbf{\\Sigma}^{-1} \\mathbf{x}} - \\mathbf{x}^T \\mathbf{\\Sigma}^{-1}\\mathbf{\\mu}_1 - \\mathbf{\\mu}_1^T \\mathbf{\\Sigma}^{-1} \\mathbf{x} + \\mathbf{\\mu}_1^T \\mathbf{\\Sigma}^{-1} \\mathbf{\\mu}_1 &= \\cancel{\\mathbf{x}^T \\mathbf{\\Sigma}^{-1} \\mathbf{x}} - \\mathbf{x}^T \\mathbf{\\Sigma}^{-1}\\mathbf{\\mu}_0 - \\mathbf{\\mu}_0^T \\mathbf{\\Sigma}^{-1} \\mathbf{x} + \\mathbf{\\mu}_0^T \\mathbf{\\Sigma}^{-1} \\mathbf{\\mu}_0\n\\end{align*}\\]\nNote that, \\(\\mathbf{x}^T \\mathbf{\\Sigma}^{-1} (\\mu_1 - \\mu_0)\\) is a scalar, so \\(\\mathbf{x}^T \\mathbf{\\Sigma}^{-1} (\\mu_1 - \\mu_0) = (\\mathbf{x}^T \\mathbf{\\Sigma}^{-1} (\\mu_1 - \\mu_0))^T\\). So, we get:\n\\[\\begin{align*}\n2\\mathbf{x}^T \\mathbf{\\Sigma}^{-1} (\\mu_1 - \\mu_0) = \\underbrace{\\mu_1^T \\mathbf{\\Sigma}^{-1} \\mu_1 - \\mu_0^T \\mathbf{\\Sigma}^{-1} \\mu_0}_{\\text{constant}} \\tag{31}\n\\end{align*}\\]\nThis is the equation of the decision boundary. This is a linear projection of the vector \\(\\mathbf{x}\\) onto the \\(\\mathbf{\\Sigma}^{-1} (\\mu_1 - \\mu_0)\\) direction. Whenever this projection equals to this constant, we are on the decision boundary; when it’s larger than this threshold, it’s class \\(1\\) and when it’s smaller it’s class \\(2\\). So, the decision boundary is just a line perpendicular to this vector and crossing it in the point that corresponds to this threshold.\nTo make it clear, the fact that the decision boundary is linear follows from our assumption that the covariances are the same."
  },
  {
    "objectID": "posts/gaussian-discriminant-analysis/index.html#quadratic-discriminant-analysis-qda",
    "href": "posts/gaussian-discriminant-analysis/index.html#quadratic-discriminant-analysis-qda",
    "title": "Classification Algorithms",
    "section": "Quadratic Discriminant Analysis (QDA)",
    "text": "Quadratic Discriminant Analysis (QDA)\nLDA assumes that the data within each class \\(c\\) are drawn from a multivariate Gaussian distribution with a class-specific mean vector \\(\\mathbf{\\mu}_c\\) and a covariance matrix that common to all \\(C\\) classes. Quadratic Discriminant Analysis (QDA) classifier assumes that the observations from each class are drawn from a Gaussian distribution and each class has its own mean vector \\(\\mathbf{\\mu}_c\\) and covariance matrix \\(\\mathbf{\\Sigma}_c\\).\n\\[\\begin{align*}\np(y=c|\\mathbf{x}) = \\frac{1}{(2\\pi)^{D/2} |\\det \\mathbf{\\Sigma_c}|^{1/2}}\\exp\\left[-\\frac{1}{2}(\\mathbf{x} - \\mu_c)^T \\mathbf{\\Sigma}_c^{-1}(\\mathbf{x} - \\mu_c)\\right]\n\\end{align*}\\]"
  },
  {
    "objectID": "posts/fun-with-numeraires/index.html",
    "href": "posts/fun-with-numeraires/index.html",
    "title": "Fun with numeraires!",
    "section": "",
    "text": "A proficiency in the change-of-measure technique is useful to the working quant. An excellent summary of the important results is the note Girsanov, Numeraires and all that, by Andrew Lesniewski. In this post, I would like to derive relevant results and then we can enjoy pricing some payoffs together!"
  },
  {
    "objectID": "posts/fun-with-numeraires/index.html#introduction",
    "href": "posts/fun-with-numeraires/index.html#introduction",
    "title": "Fun with numeraires!",
    "section": "",
    "text": "A proficiency in the change-of-measure technique is useful to the working quant. An excellent summary of the important results is the note Girsanov, Numeraires and all that, by Andrew Lesniewski. In this post, I would like to derive relevant results and then we can enjoy pricing some payoffs together!"
  },
  {
    "objectID": "posts/fun-with-numeraires/index.html#girsanov-theorem",
    "href": "posts/fun-with-numeraires/index.html#girsanov-theorem",
    "title": "Fun with numeraires!",
    "section": "Girsanov Theorem",
    "text": "Girsanov Theorem\n\nTheorem 1 (Girsanov Theorem) Let \\((W^{\\mathbb{P}},t\\geq 0)\\) be a \\(\\mathbb{P}\\) standard brownian motion on \\((\\Omega,\\mathcal{F},\\mathbb{P})\\) and let \\(\\phi\\) be any adapted process. Choose fixed \\(T\\) and defined the process \\(L\\) on \\([0,T]\\) by:\n\\[\n\\begin{align*}\ndL_t = \\phi_t L_t dW^{\\mathbb{P}}_t\n\\end{align*}\n\\tag{1}\\]\n\\[\n\\begin{align*}\nL_0 = 1\n\\end{align*}\n\\tag{2}\\]\nthat is:\n\\[\n\\begin{align*}\nL_t = \\exp\\left(\\int_0^t \\phi_s dW^{\\mathbb{P}}_s - \\int_0^t \\phi^2_s ds\\right)\n\\end{align*}\n\\tag{3}\\]\nAssume that:\n\\[\n\\begin{align*}\n\\mathbb{E}^{\\mathbb{P}}[L_T] = 1\n\\end{align*}\n\\tag{4}\\]\nand define the new probability measure \\(\\mathbb{Q}\\) on \\(\\mathcal{F}_t\\) by:\n\\[\nL_T = \\frac{d\\mathbb{Q}}{d\\mathbb{P}}\n\\tag{5}\\]\nThen,\n\\[\ndW^{\\mathbb{P}}_t = dW^{\\mathbb{Q}}_t + \\phi_t dt\n\\tag{6}\\]\nwhere \\(dW^{\\mathbb{Q}}_t\\) is a \\(\\mathbb{Q}\\)-standard brownian motion.\n\nProof.\nOur claim is that, under the \\(\\mathbb{Q}\\) measure, the increments \\((W^{\\mathbb{Q}}_t - W^{\\mathbb{Q}}_s)\\) are normally distributed with mean \\(0\\) and variance \\((t-s)\\). We start with the special case \\(s=0\\). Using moment generating functions, it is enough to show that:\nIt is straightforward to derive Equation 3 using Ito’s lemma. Let \\(f(x) = \\ln x\\). Then, \\(f_x = \\frac{1}{x}\\), \\(f_{xx} = -\\frac{1}{x^2}\\).\n\\[\n\\begin{align*}\nd(\\ln L_t) &= \\frac{1}{L_t}dL_t -\\frac{1}{2} \\frac{1}{L_t^2}(dL_t)^2 \\\\\n&= \\frac{1}{L_t}{\\phi_t L_t dW^{\\mathbb{P}}_t} - \\frac{1}{2L_t^2}\\phi_t^2 L_t^2 dt\\\\\n&= \\phi_t dW^{\\mathbb{P}}_t -\\frac{1}{2} \\phi_t^2 dt \\\\\nL_t &= \\exp\\left(\\int_0^t \\phi_s dW^{\\mathbb{P}}_s - \\frac{1}{2}\\int_0^t \\phi_s^2 ds \\right)\n\\end{align*}\n\\]\nTo prove our main result, we will now use the MGF of the increments. For \\(n \\in \\mathbb{N}\\) and \\((t_j,j\\leq n)\\) a partition of \\([0,T]\\), with \\(t_n = T\\), I will show that :\n\\[\n\\begin{align*}\n\\mathbb{E}^{\\mathbb{Q}}\\left[\\exp\\left(\\sum_{j=0}^{n-1}\\lambda_j (W^{\\mathbb{Q}}_{t_{j+1}} - W^{\\mathbb{Q}}_{t_{j}})\\right)\\right] = \\exp\\left[\\sum_{j=0}^{n-1}\\lambda_j^2(t_{j+1}-t_j)\\right]\n\\end{align*}\n\\tag{7}\\]\nThis proves that the increments are the ones of standard brownian motion.\nLet \\((\\mathcal{F}_{t_j},j\\leq n)\\) be the filtrations of the Brownian motion at the time of the partition. The proof is by successively conditioning from \\(t_{n-1}\\) to \\(t_1\\). We have:\n\\[\n\\begin{aligned}\n\\mathbb{E}^{\\mathbb{Q}}\\left[\\exp\\left(\\sum _{j=0}^{n-1} \\lambda _{j} (W_{t_{j+1}}^{\\mathbb{Q}} -W_{t_{j}}^{\\mathbb{Q}} )\\right)\\right] & =\\mathbb{E}^{\\mathbb{P}}\\left[\\mathbb{E}^{\\mathbb{P}}\\left[ L_{t_{n}}\\exp\\left(\\sum _{j=0}^{n-1} \\lambda _{j} (W_{t_{j+1}}^{\\mathbb{Q}} -W_{t_{j}}^{\\mathbb{Q}} )\\right) |\\mathcal{F}_{t_{n-1}}\\right]\\right]\\\\\n& =\\mathbb{E}^{\\mathbb{P}}\\left[\\sum _{j=0}^{n-2} \\lambda _{j} (W_{t_{j+1}}^{\\mathbb{Q}} -W_{t_{j}}^{\\mathbb{Q}} )\\mathbb{E}^{\\mathbb{P}}\\left[ L_{t_{n}}\\exp\\left( \\lambda _{n-1} (W_{t_{n}}^{\\mathbb{Q}} -W_{t_{n-1}}^{\\mathbb{Q}} )\\right) |\\mathcal{F}_{t_{n-1}}\\right]\\right]\\\\\n& =\\mathbb{E}^{\\mathbb{P}}\\left[\\sum _{j=0}^{n-2} \\lambda _{j} (W_{t_{j+1}}^{\\mathbb{Q}} -W_{t_{j}}^{\\mathbb{Q}} )\\mathbb{E}^{\\mathbb{P}}\\left[\\exp\\left(\\int _{t_{n-1}}^{t_{n}} \\phi _{s} dW_{s}^{\\mathbb{Q}} +\\frac{1}{2}\\int _{t_{n-1}}^{t_{n}} \\phi _{s}^{2} ds\\right)\\exp\\left( \\lambda _{n-1}\\int _{t_{n-1}}^{t_{n}} dW_{s}^{\\mathbb{Q}}\\right) |\\mathcal{F}_{t_{n-1}}\\right]\\right]\\\\\n& =\\mathbb{E}^{\\mathbb{P}}\\left[\\sum _{j=0}^{n-2} \\lambda _{j} (W_{t_{j+1}}^{\\mathbb{Q}} -W_{t_{j}}^{\\mathbb{Q}} )\\mathbb{E}^{\\mathbb{P}}\\left[\\exp\\left(\\int _{t_{n-1}}^{t_{n}}( \\phi _{s} +\\lambda _{n-1}) dW_{s}^{\\mathbb{Q}} +\\frac{1}{2}\\int _{t_{n-1}}^{t_{n}} \\phi _{s}^{2} ds\\right) |\\mathcal{F}_{t_{n-1}}\\right]\\right]\\\\\n& =\\mathbb{E}^{\\mathbb{P}}\\left[\\sum _{j=0}^{n-2} \\lambda _{j} (W_{t_{j+1}}^{\\mathbb{Q}} -W_{t_{j}}^{\\mathbb{Q}} )\\mathbb{E}^{\\mathbb{P}}\\left[\\exp\\left(\\int _{t_{n-1}}^{t_{n}}( \\phi _{s} +\\lambda _{n-1})\\left( dW_{s}^{\\mathbb{P}} -\\theta ds\\right) +\\frac{1}{2}\\int _{t_{n-1}}^{t_{n}} \\phi _{s}^{2} ds\\right) |\\mathcal{F}_{t_{n-1}}\\right]\\right]\\\\\n& =\\mathbb{E}^{\\mathbb{P}}\\left[\\sum _{j=0}^{n-2} \\lambda _{j} (W_{t_{j+1}}^{\\mathbb{Q}} -W_{t_{j}}^{\\mathbb{Q}} )\\exp\\left(\\frac{1}{2}\\int _{t_{n-1}}^{t_{n}} \\phi _{s}^{2} +\\int _{t_{n-1}}^{t_{n}} -\\phi _{s}( \\phi _{s} +\\lambda _{n-1}) ds\\right) \\ \\exp\\left(\\frac{1}{2}\\int _{t_{n-1}}^{t_{n}}( \\phi _{s} +\\lambda _{n-1})^{2} ds\\right)\\right]\\\\\n& \\left\\{\\ \\int XdW_{s}^{\\mathbb{P}} \\ \\text{ is a }\\mathcal{N}^{\\mathbb{P}}\\left( 0,\\int \\mathbb{E}\\left[ X^{2}\\right] ds\\right) \\ \\text{gaussian random variable.}\\right\\} \\ \\\\\n& =\\mathbb{E}^{\\mathbb{P}}\\left[\\sum _{j=0}^{n-2} \\lambda _{j} (W_{t_{j+1}}^{\\mathbb{Q}} -W_{t_{j}}^{\\mathbb{Q}} )\\exp\\left(\\int _{t_{n-1}}^{t_{n}}\\left( -\\frac{1}{2} \\phi _{s}^{2} -\\lambda _{n-1} \\phi _{s} +\\frac{1}{2} \\phi _{s}^{2} +\\lambda _{n-1} \\phi _{s} +\\lambda _{n-1}^{2}\\right) ds\\right)\\right]\\\\\n& =\\mathbb{E}^{\\mathbb{P}}\\left[\\sum _{j=0}^{n-2} \\lambda _{j} (W_{t_{j+1}}^{\\mathbb{Q}} -W_{t_{j}}^{\\mathbb{Q}} )\\exp\\left( \\lambda _{n-1}\\int _{t_{n-1}}^{t_{n}} ds\\right)\\right]\\\\\n& =\\exp( \\lambda _{n-1}( t_{n} -t_{n-1}) \\cdot \\mathbb{E}^{\\mathbb{P}}\\left[\\sum _{j=0}^{n-2} \\lambda _{j} (W_{t_{j+1}}^{\\mathbb{Q}} -W_{t_{j}}^{\\mathbb{Q}} )\\right]\n\\end{aligned}\n\\]\nHere, I used the fact that \\(L_{t_{n-1}}\\) is \\(\\mathcal{F}_{t_{n-1}}\\) measurable. I can now condition on \\(\\mathcal{F}_{t_{n-2}}\\) down to \\(\\mathcal{F}_{t_1}\\) and proceed as above to obtain the desired result.\nThe process \\(\\phi_t\\) is called the Girsanov kernel."
  },
  {
    "objectID": "posts/fun-with-numeraires/index.html#what-is-a-numeraire",
    "href": "posts/fun-with-numeraires/index.html#what-is-a-numeraire",
    "title": "Fun with numeraires!",
    "section": "What is a numeraire?",
    "text": "What is a numeraire?\nAs Shreve puts it, a numeraire is the unit of account in which other assets are denominated. In practice, we tend to choose numeraires that simply the payoff expression.\nAny strictly positive (non-dividend paying) price process can be chosen as a numeraire. A numeraire must be a tradable asset.\nConsider a unit of stock worth \\(S_t\\). It can be used as numeraire, because the price process \\(e^{-rt}S_t\\) (assume a constant short rate) is a martingale under risk-neutral measure \\(\\mathbb{Q}^M\\). Powers of the stock price \\(S_t^\\alpha\\) cannot be used as numeraires, because their discounted values are not martingales under the risk-neutral measure. Clearly, set the short rate \\(r = 0\\), then \\(\\mathbb{E}^{\\mathbb{Q}^M}[S_T^2] \\geq (\\mathbb{E}^{\\mathbb{Q}^M}[S_T])^2 =S_0^2\\) by the Jensen’s inequality.\nThe price-process \\(V_t\\) of a derivative contract that pays \\(V_T=S_T^2\\) is a martingale under \\(\\mathbb{Q}\\) and can be used as a numeraire.\nConsider the price of a contract that pays a unit sum \\(1\\) at maturity \\(T\\). This instrument is the zero-coupon bond. Its an observable and tradable asset. Its price process \\(P(t,T) = \\mathbb{E}^{\\mathbb{Q}^M}[1/M_T]\\) can be used as a numeraire. \\(\\mathbb{Q}^T\\) is called the \\(T\\)-forward measure."
  },
  {
    "objectID": "posts/fun-with-numeraires/index.html#abstract-bayes-formula",
    "href": "posts/fun-with-numeraires/index.html#abstract-bayes-formula",
    "title": "Fun with numeraires!",
    "section": "Abstract Bayes Formula",
    "text": "Abstract Bayes Formula\n\nTheorem 2 (Abstract Bayes Formula) Let \\((\\Omega,\\mathcal{F},\\mathbb{P})\\) be a probability space and let \\(\\mathbb{Q}\\) be any other probability measure on it. By the Radon-Nikodym theorem, \\(\\exists L = \\frac{d\\mathbb{Q}}{d\\mathbb{P}}\\), \\(L \\geq 0\\) with \\(\\mathbb{E}^{\\mathbb{P}}[L]=1\\). Then we have:\n\\[\n\\begin{align*}\n\\mathbb{E}^{\\mathbb{Q}}[X|\\mathcal{G}] = \\frac{\\mathbb{E}^{\\mathbb{P}}[LX|\\mathcal{G}]}{\\mathbb{E}^{\\mathbb{P}}[L|\\mathcal{G}]}\n\\end{align*}\n\\tag{8}\\]\n\nProof.\nBy the definition of conditional expectations, recall that if \\(W\\) is any \\(\\mathcal{G}\\)-measurable random variable, then the conditional expectation must satisfy the relationship:\n\\[\n\\mathbb{E}[WX] = \\mathbb{E}[W\\mathbb{E}[X|\\mathcal{G}]]\n\\]\nIt is sufficient to prove that:\n\\[\n\\mathbb{E}^{\\mathbb{P}}[X|\\mathcal{G}]\\mathbb{E}^{\\mathbb{Q}}[L|\\mathcal{G}] = \\mathbb{E}^{\\mathbb{P}}[LX|\\mathcal{G}]\n\\]\nLet \\(G\\) be an arbitrary set in \\(\\mathcal{G}\\). We have:\n\\[\n\\begin{align*}\n& \\int_G \\mathbb{E}^{\\mathbb{Q}}[X|\\mathcal{G}]\\mathbb{E}^{\\mathbb{P}}[L|\\mathcal{G}] d\\mathbb{P} \\\\\n&= \\int_G \\mathbb{E}^{\\mathbb{P}}[L\\cdot \\mathbb{E}^{\\mathbb{Q}}[X|\\mathcal{G}]|\\mathcal{G}] d\\mathbb{P} \\\\\n& \\quad \\{ \\mathbb{E}^{\\mathbb{Q}}[X|\\mathcal{G}] \\text{ is }\\mathcal{G}\\text{-measurable } \\}\\\\\n&= \\int_G  L\\cdot \\mathbb{E}^{\\mathbb{Q}}[X|\\mathcal{G}] d\\mathbb{P}\\\\\n&= \\int_G  \\frac{d\\mathbb{Q}}{d\\mathbb{P}}\\cdot \\mathbb{E}^{\\mathbb{Q}}[X|\\mathcal{G}] d\\mathbb{P}\\\\\n&= \\int_G \\mathbb{E}^{\\mathbb{Q}}[X|\\mathcal{G}] d\\mathbb{Q}\\\\\n&= \\int_G X d\\mathbb{Q}\n\\end{align*}\n\\]\nAlso, we have:\n\\[\n\\begin{align*}\n\\int_{G} \\mathbb{E}^{\\mathbb{P}}[LX|\\mathcal{G}]d\\mathbb{P} &= \\int_G LX d\\mathbb{P}\\\\\n&= \\int_G \\frac{d\\mathbb{Q}}{d\\mathbb{P}} X d\\mathbb{P}\\\\\n&= \\int_G X d\\mathbb{Q}\n\\end{align*}\n\\]\nHence, proved.\nNote that, the filtration \\(\\mathcal{G}\\) is the same irrespective of what probability measure we construct on \\(\\Omega\\)."
  },
  {
    "objectID": "posts/fun-with-numeraires/index.html#martingale-property",
    "href": "posts/fun-with-numeraires/index.html#martingale-property",
    "title": "Fun with numeraires!",
    "section": "Martingale property",
    "text": "Martingale property\n\nProposition 1 Assume that there exists a numeraire \\(M\\) and a probability measure \\(\\mathbb{Q}^M\\), such that the price of any traded asset \\(X\\) (without intermediate payments) relative to \\(M\\) is a martingale under \\(\\mathbb{Q}^M\\).That is:\n\\[\n\\frac{X_t}{M_t} = \\mathbb{E}^{\\mathbb{Q}^M} \\left\\{\\frac{X_T}{M_T}|\\mathcal{F}_t\\right\\}\n\\]\nLet \\(N_t\\) be an arbitrary numeraire. Then, there exists a probability measure \\(\\mathbb{Q}^N\\) such that the price of \\(X\\) normalized by \\(N\\) is a martingale under \\(\\mathbb{Q}^N\\).\n\\[\n\\frac{X_t}{N_t} = \\mathbb{E}^{\\mathbb{Q}^N} \\left\\{\\frac{X_T}{N_T}|\\mathcal{F}_t\\right\\}\n\\]\nMoreover, the Radon-Nikodym derivative defining the measure \\(\\mathbb{Q}^N\\) is given by:\n\\[\n\\frac{d\\mathbb{Q}^N}{d\\mathbb{Q}^M} = \\frac{N_T/N_0}{M_T/M_0}\n\\]\n\nProof.\nWe have:\n\\[\nX_0 = M_0 \\mathbb{E}^{\\mathbb{Q}^M}\\left[\\frac{X_T}{M_T}\\right]\n\\]\nImposing the simple fact that, the price of the derivative contract should be the same, even if we switch numeraires from \\(M\\) to \\(N\\), we should have:\n\\[\nX_0 = N_0 \\mathbb{E}^{\\mathbb{Q}^N}\\left[\\frac{X_T}{N_T}\\right]\n\\]\nThus,\n\\[\n\\begin{aligned}\nN_{0}\\mathbb{E}^{\\mathbb{Q}^{N}}\\left[\\frac{X_{T}}{N_{T}}\\right] & =M_{0}\\mathbb{E}^{\\mathbb{Q}^{M}}\\left[\\frac{X_{T}}{M_{T}}\\right]\\\\\n\\frac{N_{T}}{N_{0}} \\times N_{0}\\mathbb{E}^{\\mathbb{Q}^{N}}\\left[\\frac{X_{T}}{N_{T}}\\right] & =\\frac{N_{T}}{N_{0}} \\times M_{0} \\ \\mathbb{E}^{\\mathbb{Q}^{M}}\\left[\\frac{X_{T}}{M_{T}}\\right] \\quad \\left\\{\\text{Multiplying both sides by }\\frac{N_{T}}{N_{0}}\\right\\}\\\\\n\\Longrightarrow \\mathbb{E}^{\\mathbb{Q}^{N}}[ X_{T}] & =\\mathbb{E}^{\\mathbb{Q}^{M}}\\left[\\frac{N_{T} /N_{0}}{M_{T} /M_{0}} X_{T}\\right]\n\\end{aligned}\n\\]\nBut, we know that:\n\\[\n\\mathbb{E}^{\\mathbb{Q}^N}[X_T] = \\mathbb{E}^{\\mathbb{Q}^M}\\left[\\frac{d\\mathbb{Q}^N}{d\\mathbb{Q}^M}X_T\\right]\n\\]\nConsequently, our candidate for the Radon-Nikodym derivative should be:\n\\[\nL_T = \\frac{d\\mathbb{Q}^N}{d\\mathbb{Q}^M} = \\frac{N_T/N_0}{M_T/M_0}\n\\]\nFurther \\((X_t/N_t)\\) is a martingale under \\(\\mathbb{Q}^N\\). Its easy to see that:\n\\[\n\\begin{aligned}\n\\mathbb{E}^{\\mathbb{Q}^{N}}\\left[\\frac{X_{T}}{N_{T}} |\\mathcal{F}_{t}\\right] & =\\frac{\\mathbb{E}^{\\mathbb{Q}^{M}}\\left[ L_{T} \\cdot \\frac{X_{T}}{N_{T}} |\\mathcal{F}_{t}\\right]}{\\mathbb{E}^{\\mathbb{Q}^{M}}[ L_{T} |\\mathcal{F}_{t}]} \\quad \\left\\{\\text{ Abstract bayes formula }\\right\\}\\\\\n& =\\frac{\\mathbb{E}^{\\mathbb{Q}^{M}}\\left[ L_{T} \\cdot \\frac{X_{T}}{N_{T}} |\\mathcal{F}_{t}\\right]}{L_{t}}\\\\\n& =\\frac{\\mathbb{E}^{\\mathbb{Q}^{M}}\\left[\\frac{N_{T}}{N_{0}} \\cdot \\frac{M_{0}}{M_{T}} \\cdot \\frac{X_{T}}{N_{T}} |\\mathcal{F}_{t}\\right]}{\\frac{N_{t}}{N_{0}} \\cdot \\frac{M_{0}}{M_{t}}}\\\\\n& =\\frac{\\mathbb{E}^{\\mathbb{Q}^{M}}\\left[\\frac{N_{T}}{N_{0}} \\cdot \\frac{M_{0}}{M_{T}} \\cdot \\frac{X_{T}}{N_{T}} |\\mathcal{F}_{t}\\right]}{\\frac{N_{t}}{N_{0}} \\cdot \\frac{M_{0}}{M_{t}}}\\\\\n& =\\frac{M_{t}}{N_{t}} \\cdot \\mathbb{E}^{\\mathbb{Q}^{M}}\\left[\\frac{X_{T}}{M_{T}}\\right]\\\\\n& =\\frac{M_{t}}{N_{t}} \\cdot \\frac{X_{t}}{M_{t}}\\\\\n& =\\frac{X_{t}}{N_{t}}\n\\end{aligned}\n\\]\nSince we determined the relevant likelihood process, it is easy to find the Girsanov Kernel."
  },
  {
    "objectID": "posts/fun-with-numeraires/index.html#drift-transformation-under-change-of-numeraire",
    "href": "posts/fun-with-numeraires/index.html#drift-transformation-under-change-of-numeraire",
    "title": "Fun with numeraires!",
    "section": "Drift transformation under change of numeraire",
    "text": "Drift transformation under change of numeraire\nSuppose we are interested in the dynamics of the stochastic process \\((X_t,t\\geq 0)\\). Under \\(\\mathbb{Q}^M\\) measure, its dynamics reads:\n\\[\n\\begin{aligned}\ndX(t) = \\mu_X^{\\mathbb{Q}^M}(t) dt + c_X(t)dW^{\\mathbb{Q}^M}_t\n\\end{aligned}\n\\tag{9}\\]\nI supressed \\(\\mu_X^{\\mathbb{Q}^M}(t,X_t)\\) as \\(\\mu_X^{\\mathbb{Q}^M}(t)\\) for brevity.\nUnder the \\(\\mathbb{Q}^N\\) measure, its dynamics reads:\n\\[\n\\begin{aligned}\ndX(t) = \\mu_X^{\\mathbb{Q}^N}(t) dt + c_X(t)dW^{\\mathbb{Q}^N}_t\n\\end{aligned}\n\\tag{10}\\]\nRemember that the diffusion coefficients in these equations are unaffected by the change of measure! We assume that \\(\\mathbb{Q}^M\\) is associated with the numeraire \\(M(t)\\) whose dynamics is given by:\n\\[\ndM(t) = \\mu_M(t)dt + c_M(t)dW^{\\mathbb{Q}^M}\n\\]\nand that the numeraire \\(N\\) has \\(\\mathbb{Q}^M\\) dynamics:\n\\[\ndN(t) = \\mu_N(t)dt + c_N(t)dW^{\\mathbb{Q}^N}\n\\]\nAccording to the Girsanov theorem, the likelihood process \\(L(t)\\) accompanying this change of measure is a martingale under the measure \\(\\mathbb{Q}^M\\) measure and satisfies the stochastic differential equation:\n\\[\ndL_t = L(t)\\theta(t)dW^{\\mathbb{Q}^M}_t\n\\]\nExplicitly, the likelihood process \\(L(t)\\) is given by the stochastic exponential of the martingale \\(\\int_0^t \\theta_s dW^{\\mathbb{Q}^M}_s\\):\n\\[\nL(t) = \\exp\\left(\\int_0^t \\theta_s dW^{\\mathbb{Q}^M}_s - \\frac{1}{2}\\int_0^t \\theta^2_s ds \\right)\n\\]\nOn the other hand, from Proposition 1, we have:\n\\[\nL_t = \\frac{N_t / N_0}{M_t / M_0}\n\\]\nDifferentiating using Ito’s lemma, we have:\n\\[\n\\begin{aligned}\ndL_{t} & =\\frac{M_{0}}{N_{0}} d\\left(\\frac{N_{t}}{M_{t}}\\right)\\\\\n& =\\frac{M_{0}}{N_{0}}\\left( -\\frac{N_{t}}{M_{t}^{2}} dM_{t} +\\frac{1}{M_{t}} dN_{t} +\\frac{1}{2} \\cdot \\frac{2N_{t}}{M_{t}^{3}}( dM_{t})^{2} -\\frac{1}{M_{t}^{2}}( dM_{t} \\cdot dN_{t})\\right)\\\\\n&  \\begin{array}{l}\n=\\frac{M_{0}}{N_{0}}( -\\frac{N_{t}}{M_{t}^{2}}\\left( \\mu _{M}( t) dt+c_{M}( t) dW_{t}^{\\mathbb{Q}^{M}}\\right) +\\frac{1}{M_{t}}\\left( \\mu _{N}( t) dt+c_{N}( t) dW_{t}^{\\mathbb{Q}^{M}}\\right)\\\\\n+\\frac{N_{t}}{M_{t}^{3}} c_{M}^{2}( t) dt-\\frac{1}{M_{t}^{2}} c_{M}( t) c_{N}( t) dt\n\\end{array}\n\\end{aligned}\n\\]\nBut since \\(L_t\\) is driftless, we can ignore the \\(dt\\) terms (whatever they are, they are bound to cancel out) and only look at the diffusion coefficient. So, we can write:\n\\[\n\\begin{aligned}\ndL_{t} & =\\frac{M_{0}}{N_{0}}\\left( -\\frac{N_{t}}{M_{t}^{2}} c_{M}( t) +\\frac{1}{M_{t}} c_{N}( t)\\right) dW{_{t}^{\\mathbb{Q}}}^{M}\\\\\n& =\\frac{N_{t} /N_{0}}{M_{t} /M_{0}}\\left(\\frac{c_{N}( t)}{N_{t}} -\\frac{c_{M}( t)}{M_{t}}\\right) dW{_{t}^{\\mathbb{Q}}}^{M}\\\\\n& =L_{t}\\left(\\frac{c_{N}( t)}{N_{t}} -\\frac{c_{M}( t)}{M_{t}}\\right) dW{_{t}^{\\mathbb{Q}}}^{M}\n\\end{aligned}\n\\]\nComparing this, we can infer that:\n\\[\n\\theta_t = \\frac{c_N(t)}{N_t} - \\frac{c_M(t)}{M_t}\n\\]\nSince we can write:\n\\[\n\\begin{align*}\ndX_t = \\mu^{\\mathbb{P}}_X(t) dt + c_X(t)dW^{\\mathbb{P}}(t) &= \\mu^{\\mathbb{Q}}_X(t) + c_X(t)dW^{\\mathbb{Q}}(t)\\\\\ndW^{\\mathbb{P}}(t) &= \\frac{\\mu^{\\mathbb{Q}}_X(t) - \\mu^{\\mathbb{P}}_X(t)}{c_X(t)} + dW^{\\mathbb{Q}}(t)\n\\end{align*}\n\\tag{11}\\]\nUsing Equation 11, we conclude that the change of drift accompanying a change of numeraire is given by:\n\\[\n\\begin{align*}\n\\mu_X^{\\mathbb{Q}}(t) - \\mu_X^{\\mathbb{P}}(t) = c_X(t)\\left(\\frac{c_M(t)}{M(t)} - \\frac{c_N(t)}{N(t)}\\right)\n\\end{align*}\n\\tag{12}\\]"
  },
  {
    "objectID": "posts/fun-with-numeraires/index.html#examples-of-numeraires",
    "href": "posts/fun-with-numeraires/index.html#examples-of-numeraires",
    "title": "Fun with numeraires!",
    "section": "Examples of numeraires",
    "text": "Examples of numeraires\nThe basic component of an interest rate model is an instantaneous forward rate process \\(f(t,s)\\). Its value is the future instantaneous interest rate at a future time \\(s\\), that is the rate for the infinitesimally short term \\([s,s+ds]\\) observed at time \\(t \\leq s\\).\nA zero-coupon bond settling at time \\(T_0\\) and maturing at time \\(T &gt; T_0\\) is the process:\n\\[\nP(t,T_0,T) = \\exp\\left(-\\int_{T_0}^Tf(t,s)ds\\right)\n\\]\nfor \\(t \\leq T_0\\). In other words, it is the time \\(T_0\\) value of 1\\(\\$\\) (without the risk of default) at \\(T\\), as observed at time \\(t \\leq T_0\\). Its current value is given by:\n\nBank-account numeraire\nThe bank-account(money-market account) numeraire is simply the value of \\(1\\$\\) deposited in a bank and accruing the (credit-riskless) instantaneous interest rate. In reality, the bank credits interest to the account daily, but this can very well be approximated to a continous process. The associated stochastic price process \\(M(t)\\) is given by:\n\\[\n\\begin{align*}\nM(t) = \\exp(\\int_0^t r(s)ds)\n\\end{align*}\n\\]\nHere, the spot rate \\(r(t)\\) is the instantaneous forward observed at the time it settles. That is,\n\\[\nr(t) = f(t,t)\n\\]\n\n\nForward numeraire\nA zero-coupon bond(ZCB) is a simple contract with unit payoff \\(1\\$\\) at maturity \\(T\\). By the risk-neutral valuation formula:\n\\[\nP(t,t,T) = V(t) = M(t) \\mathbb{E}^{\\mathbb{Q}^M}\\left[\\frac{1}{M(T)}\\right]\n\\]\nSo, a \\(T\\)-maturity ZCB is a tradable asset and its price \\(P(t,T)\\) can be used as a numeraire. The associated measure is called the \\(T\\)-foward measure \\(\\mathbb{Q}^T\\).\nThe term(e.g. 3 months) forward rates for settlement at \\(T_0\\) and maturity at \\(T\\) are defined by the equation:\n\\[\n\\begin{align*}\nP(t,T_0,T) = \\frac{1}{1 + \\delta F(t,T_0,T)}\n\\end{align*}\n\\]\nwhere \\(\\delta\\) is the day-count fraction for the period \\([T_0,T]\\). Re-arranging, we have:\n\\[\n\\begin{align*}\nF(t,T_0,T) &= \\frac{1}{\\delta}\\frac{P(t,T,T) - P(t,T_0, T)}{P(t,T_0,T)}\nF(t,T_0,T)P(t,T_0,T) &= \\frac{1}{\\delta}(P(t,T,T) - P(t,T_0,T))\n\\end{align*}\n\\]\nClearly, it is a multiple of a difference \\(P(t,T,T)\\) and \\(P(t,T_0,T)\\) normalized by \\(T\\)-maturity zero coupon bond price \\(P(t,T_0,T)\\). So, the forward iBOR-rate must be a martingale under the \\(T\\)-forward measure \\(Q^T\\).\n\nProposition 2 (Forward rates are \\(\\mathbb{Q}^T\\) expectations of future spot rates.) Any simply compounded forward rate spanning a time interval ending in \\(T\\) is a martingale under the \\(T\\)-forward measure.\n\\[\n\\mathbb{E}^{\\mathbb{Q}^T}[F(t;S,T)|\\mathcal{F}_u] = F(u;S,T)\n\\]\nfor each \\(0 \\leq u \\leq t \\leq S &lt; T\\). In particular, the forward rate spanning the interval \\([S,T]\\) is the \\(\\mathbb{Q}^T\\) expectation of the future simply-compounded spot rate at time \\(S\\) for the maturity T.\n\\[\n\\mathbb{E}^{\\mathbb{Q}^T}[L(S,T)|\\mathcal{F}_t] = F(t;S,T)\n\\tag{13}\\]\n\n\nThe expected value of any future instantaneous spot interest rate, under the corresponding forward measure, is equal to the related instantaneuous forward rate. That is, \\[\n\\begin{align*}\n\\mathbb{E}^T{r_T|\\mathcal{F}_t} = f(t,T)\n\\end{align*}\n\\]\nfor each \\(0 \\leq t \\leq T\\).\n\nProof.\nWe have:\n\\[\n\\begin{align*}\n\\mathbb{E}^{\\mathbb{Q}^T} [r_T|\\mathcal{F}_t] &= \\frac{1}{P(t,T)}\\mathbb{E}\\left[r_TP(t,T)|\\mathcal{F}_t\\right]\\\\\n&= - \\frac{1}{P(t,T)}\\mathbb{E}\\left[r_Te^{-\\int_t^T r(s)ds}|\\mathcal{F}_t\\right]\\\\\n&= - \\frac{1}{P(t,T)}\\mathbb{E}\\left[\\frac{\\partial}{\\partial T}e^{-\\int_t^T r(s)ds}|\\mathcal{F}_t\\right]\\\\\n&= - \\frac{1}{P(t,T)}\\frac{\\partial}{\\partial T}\\mathbb{E}\\left[e^{-\\int_t^T r(s)ds}|\\mathcal{F}_t\\right]\\\\\n&= - \\frac{1}{P(t,T)}\\frac{\\partial}{\\partial T}P(t,T)\\\\\n&= f(t,T)\n\\end{align*}\n\\]\n\n\nPricing an IRS\nConsider a forward starting interest rate swap(IRS) which settles in \\(T_0\\) and matures in \\(T_N\\) years from now. An IRS is a transaction between two counterparties who exchange interest rate payments on an agreed notional principal.\nOn a vanilla swap, a fixed-coupon interest payments are exchanged for floating rate payments. For the sake of simplicity, we assume that the payment dates on the fixed and floating leg of the swap are the same, and that the floating rate is the same as the discounting rate. The former of these assumptions is a minor simplification, made to lighten up the notation only. The latter is an important simplification, as the basis between the floating rate and the discounting rate may exhibit a complex dynamics.\nLet \\(S\\) be the fixed-rate on the swap. By the risk-neutral valuation formula, the fixed leg value at time \\(t\\) can be expressed as:\n\\[\n\\begin{align*}\nV_{fixed}(t) &=   N \\cdot \\sum_{i=1}^N \\mathbb{E}^{\\mathbb{Q^M}}[e^{-r(T_i-t)}S \\tau(T_{i-1},T_i)|\\mathcal{F}_t]\\\\\n&=S \\cdot N \\cdot \\sum_{i=1}^N \\mathbb{E}^{\\mathbb{Q}}[e^{-r(T_i-t)}\\tau(T_{i-1},T_i)|\\mathcal{F}_t]\\\\\n&=S \\cdot N \\cdot \\left(\\sum_{i=1}^N P(t,T_i)\\tau(T_{i-1},T_i)\\right)\n\\end{align*}\n\\]\nThe floating leg can be written as:\n\\[\n\\begin{align*}\nV_{float}(t) & = N \\cdot \\sum_{i=1}^N P(t,T_i)\\mathbb{E}^{T_i}\\left[L(T,T_{i-1}, T_i)|\\mathcal{F}_t\\right]\\tau(T_{i-1},T_i)\\\\\n&=  N \\cdot \\sum_{i=1}^N P(t,T_i)L(t,T_{i-1}, T_i)\\tau(T_{i-1},T_i)\\\\\n&= N \\cdot \\sum_{i=1}^N P(t,T_i)\\frac{1}{\\tau(T_{i-1},T_i)}\\cdot\\left(\\frac{P(t,T_{i-1})}{P(t,T_{i})}-1\\right)\\tau(T_{i-1},T_i)\\\\\n&= N \\cdot \\sum_{i=1}^N (P(t,T_i) - P(t,T_{i-1}))\\\\\n&= -N P(t,T_0) + NP(t,T_N)\n\\end{align*}\n\\]\nwhere the expectations are under the \\(T_i\\)-forward measure. Note that, I used the fact that the iBOR-rates are martingales under the forward measure.\nThe par-swap rate \\(S\\) is the fixed-rate which renders the value of the swap zero at the contract start date \\(t\\).\n\\[\n\\begin{align*}\n-V_{fix} + V_{floating} &= 0\\\\\nS \\cdot N \\cdot \\left(\\sum_{i=1}^N P(t,T_i)\\tau(T_{i-1},T_i)\\right) &= -N P(t,T_0) + NP(t,T_N) \\\\\nS(t,T_{0:N}) &= \\frac{- P(t,T_0) + P(t,T_N)}{\\left(\\sum_{i=1}^N P(t,T_i)\\tau(T_{i-1},T_i)\\right)}\n\\end{align*}\n\\]\n\n\nThe Annuity Measure\nThe annuity is an asset that pays \\(1\\$\\) on each coupon payment day of the swap, accrued according to the swap’s day count convention.\n\\[\nA(t,T_{0:N}) = \\left( \\sum_{i=1}^N P(t,T_i)\\tau(T_{i-1},T_i) \\right)\n\\]\nSince, it is a portfolio of zero coupon bonds, it is a tradable asset and its price \\(A(t,T_{0:N})\\) can be used as numeraire. This is called the Annuity numeraire and the measure \\(\\mathbb{Q}^{T_{0:N}}\\) associated with this numeraire is called the (forward) swap measure. The annuity numeraire arises as the natural numeraire when valuing swaptions. It is the mechanism that allows us to link the swaption as an option on a swap to the option on the corresponding swap rate.\nThe forward swap rate \\(S(t,T_{0:N})\\) is a martingale in the annuity measure \\(\\mathbb{Q}^{T_{0:N}}\\)."
  },
  {
    "objectID": "posts/fun-with-numeraires/index.html#pricing-the-payoff-vt-s_ts_t---k",
    "href": "posts/fun-with-numeraires/index.html#pricing-the-payoff-vt-s_ts_t---k",
    "title": "Fun with numeraires!",
    "section": "Pricing the payoff \\(V(T) = [S_T(S_T - K)]^{+}\\)",
    "text": "Pricing the payoff \\(V(T) = [S_T(S_T - K)]^{+}\\)\nSell-side quant interviews are known to ask puzzles to price tricky payoffs like the power option \\(V_T=(S_T^2 - K)1_{S_T &gt; K}\\), exchange options \\(V_T = (S_2(T) - S_1(T))^{+}\\) and quantos.\nChange of numeraire and measure transformation provide an elegant way to price these payoffs quickly.\nSuppose, we want to price the following payoff:\n\\[\nV(T) = \\max( S(T)(S(T) - K), 0 )\n\\]\nBy the risk-neutral pricing formula,\n\\[\nV(t) = M(t) \\mathbf{E}^{Q}\\left[\\frac{S(T)}{M(T)}(S(T) - K)1_{S_T &gt; K}|\\mathcal{F}_t\\right]\n\\]\nThe Radon-Nikodym derivative \\(\\frac{dQ}{dQ^S}\\) is given by:\n\\[\nL(t) = \\frac{dQ}{dQ^S} = \\frac{M(T)/M(t)}{S(T)/S(t)} = \\frac{M(T)}{S(T)}\\cdot \\frac{S(t)}{M(t)}\n\\]\nConsequently, we can write:\n\\[\n\\begin{align*}\nV(t) &= M(t) \\mathbf{E}^{Q^S}\\left[\\frac{dQ}{dQ^S}\\cdot\\frac{S(T)}{M(T)}(S(T) - K)1_{S_T &gt; K}|\\mathcal{F}_t\\right]\\\\\n&= M(t) \\mathbf{E}^{Q^S}\\left[\\frac{M(T)}{S(T)}\\cdot \\frac{S(t)}{M(t)}\\cdot\\frac{S(T)}{M(T)}(S(T) - K)1_{S_T &gt; K}|\\mathcal{F}_t\\right]\\\\\n&= \\mathbf{E}^{Q^S}\\left[S(t)(S(T) - K)1_{S_T &gt; K}|\\mathcal{F}_t\\right]\\\\\n&= S(t)\\mathbf{E}^{Q^S}\\left[(S(T) - K)1_{S_T &gt; K}|\\mathcal{F}_t\\right]\n\\end{align*}\n\\tag{14}\\]\nThis looks much like the familiar European vanilla call option payoff, except that, the conditional expectation needs to be taken under the probability measure induced by the stock numeraire \\((S,Q^S)\\).\nTo find the dynamics of the stock price \\(S(t)\\) under the probability measure \\(Q^S\\), we use the intuitive fact, that, all normalized asset prices - the asset price \\(X(t)\\) deflated by the numeraire price \\(S(t)\\), \\(\\frac{X(t)}{S(t)}\\) must be martingales under \\(Q^S\\). Thus, the price process \\(M(t)/S(t)\\) must be a martingale.\nLet’s find the dynamics of the process \\(\\left(\\frac{M(t)}{S(t)}\\right)\\).\nConsider \\(f(x,y) = \\frac{x}{y}\\). We have:\n\\[\n\\begin{align*}\nf_x = \\frac{1}{y}, \\quad f_y = -\\frac{x}{y^2}\\\\\nf_{xx} = 0, \\quad f_{xy} = -\\frac{1}{y^2}, f_{yy} = \\frac{2x}{y^3}\n\\end{align*}\n\\]\nWe have:\n\\[\n\\begin{aligned}\nd\\left(\\frac{M_{t}}{S_{t}}\\right) & =\\frac{1}{S_{t}} dM( t) -\\frac{M_{t}}{S_{t}^{2}} dS( t)\\\\\n& -\\frac{1}{S_{t}^{2}} dM( t) \\cdotp dS( t) +\\frac{1}{2} \\cdot \\frac{2M_{t}}{S_{t}^{3}}( dS_{t})^{2}\\\\\n& =\\frac{1}{S_{t}} rM( t) dt-\\frac{M_{t}}{S_{t}^{2}}\\left( rdt+\\sigma dW^{\\boxed{Q}}( t)\\right)\\\\\n& +\\frac{M_{t}}{S_{t}^{3}} \\sigma ^{2} S_{t}^{2} dt\\\\\n& =\\left(\\frac{M_{t}}{S_{t}}\\right)\\left( rdt-rdt-\\sigma dW^{\\boxed{Q}}( t) +\\sigma ^{2} dt\\right)\\\\\n& =-\\sigma \\left(\\frac{M_{t}}{S_{t}}\\right)\\left( -\\sigma dt+dW^{\\boxed{Q}}( t)\\right)\n\\end{aligned}\n\\]\nBut, we know that the process \\((M_t/S_t)\\) is a \\(Q^S\\)-martingale and should be driftless. Thus, we should have:\n\\[\nd\\left(\\frac{M_t}{S_t}\\right) = -\\sigma \\left(\\frac{M_{t}}{S_{t}}\\right)(0 \\cdot dt + dW^{\\boxed{Q^S}}( t))\n\\]\nSo, we perform the measure transformation:\n\\[\ndW^{\\boxed{Q^S}}(t) = -\\sigma dt+dW^{\\boxed{Q}}(t)\n\\tag{15}\\]\nConsequently, \\(Q^S\\)-dynamics of the asset \\(S(t)\\) can be expressed as:\n\\[\n\\begin{align*}\ndS(t) &= rSdt + \\sigma S dW^{\\boxed{Q}}(t)\\\\\n&=rSdt + \\sigma S (dW^{\\boxed{Q^S}}(t) + \\sigma dt)\\\\\n&=(r+\\sigma^2)Sdt + \\sigma S dW^{\\boxed{Q^S}}(t)\n\\end{align*}\n\\]\nSo, \\(S(t)\\) is still a lognormal random variable and evolves according to:\n\\[\nS(T) = S(t)\\exp\\left[\\left(r+\\frac{\\sigma^2}{2}\\right)(T-t) + \\sigma (W^{\\boxed{Q^S}}(T) - W^{\\boxed{Q^S}}(t))\\right]\n\\tag{16}\\]\nThe price of the option would be given by:\n\\[\nV(t) = S(t)[S(t)\\Phi(d_{+}) - K\\Phi(d_{-})]\n\\]\nwhere\n\\[\n\\begin{align*}\nd_{+} &= \\frac{\\ln\\left(\\frac{S(t)}{K}\\right) + (r + \\frac{3\\sigma^2}{2})(T-t)}{\\sigma\\sqrt{T - t}}\\\\\nd_{-} &= \\frac{\\ln\\left(\\frac{S(t)}{K}\\right) + (r + \\frac{\\sigma^2}{2})(T-t)}{\\sigma\\sqrt{T - t}}\n\\end{align*}\n\\]"
  },
  {
    "objectID": "posts/fun-with-numeraires/index.html#pricing-the-payoff-vt-s_1t1_s_2t-k",
    "href": "posts/fun-with-numeraires/index.html#pricing-the-payoff-vt-s_1t1_s_2t-k",
    "title": "Fun with numeraires!",
    "section": "Pricing the payoff \\(V(T) = S_1(T)1_{S_2(T) > K}\\)",
    "text": "Pricing the payoff \\(V(T) = S_1(T)1_{S_2(T) &gt; K}\\)\nSuppose the dynamics of two assets \\(S_1(t)\\) and \\(S_2(t)\\) are given by:\n\\[\n\\begin{align*}\ndS_1(t) &= rS_1(t)dt + \\sigma_1 S_1 W_1^{Q}(t) \\\\\ndS_2(t) &= rS_2(t)dt + \\sigma_2 S_2 W_2^{Q}(t)\n\\end{align*}\n\\]\nAssume that the two driving brownian motions are correlated and their instantaneous correlation is given by:\n\\[\ndW_1^{Q}(t) dW_2^{Q}(t) = \\rho dt\n\\]\nBy the risk-neutral pricing formula, we have:\n\\[\nV(t) = M(t)\\mathbb{E}^{\\boxed{Q}}\\left[\\frac{S_1(T)}{M(T)}1_{S_2(T) &gt; K}\\right]\n\\]\nBy change of numeraire, we have:\n\\[\n\\begin{align*}\nV(t) &= M(t)\\mathbb{E}^{\\boxed{Q}}\\left[\\frac{S_1(T)}{M(T)}1_{S_2(T) &gt; K}\\right]\\\\\n&= M(t) \\mathbb{E}^{\\boxed{Q^{S_1}}}\\left[\\frac{dQ}{dQ^{S_1}}\\cdot \\frac{S_1(T)}{M(T)}1_{S_2(T) &gt; K}\\right]\\\\\n&= M(t) \\mathbb{E}^{\\boxed{Q^{S_1}}}\\left[\\frac{M(T)}{S_1(T)}\\cdot \\frac{S_1(t)}{M(t)}\\cdot \\frac{S_1(T)}{M(T)}1_{S_2(T) &gt; K}\\right]\\\\\n&= M(t) \\mathbb{E}^{\\boxed{Q^{S_1}}}\\left[\\frac{M(T)}{S_1(T)}\\cdot \\frac{S_1(t)}{M(t)}\\cdot \\frac{S_1(T)}{M(T)}1_{S_2(T) &gt; K}\\right]\\\\\n&=S_1(t)\\mathbb{E}^{\\boxed{Q^{S_1}}}[1_{S_2(T) &gt; K}]\\\\\n&=S_1(t)Q^{S_1}(S_2(T) &gt; K)\n\\end{align*}\n\\]\nThus, we need to derive the \\(Q^{S_1}\\)-dynamics of the asset \\(S_2\\). Under the \\(Q^{S_1}\\)-measure, \\(\\left(\\frac{S_2(t)}{S_1(t)}\\right)\\) must be a martingale.\nLet \\(f(x,y) = \\frac{y}{x}\\). We have:\n\\[\n\\begin{align*}\nf_x = -\\frac{y}{x^2}, \\quad f_y = \\frac{1}{x} \\\\\nf_{xx} = \\frac{2y}{x^3}, \\quad f_{xy} = -\\frac{1}{x^2}, \\quad f_{yy} = 0\n\\end{align*}\n\\]\nWe have:\n\\[\n\\begin{aligned}\nd\\left(\\frac{S_{2}( t)}{S_{1}( t)}\\right) & =-\\frac{S_{2}}{S_{1}^{2}} dS_{1}( t) +\\frac{1}{S_{1}} dS_{2}( t) +\\frac{1}{2}\\left(\\frac{2S_{2}}{S_{1}^{3}}\\right)( dS_{1}( t))^{2} -\\frac{1}{S_{1}^{2}} dS_{1}( t) \\cdot dS_{2}( t)\\\\\n& =-\\frac{S_{2}}{S_{1}^{2}}\\left( rS_{1}( t) dt+\\sigma _{1} S_{1} dW_{1}^{\\boxed{Q}}( t)\\right) +\\frac{1}{S_{1}}\\left( rS_{2}( t) dt+\\sigma _{2} S_{2} dW_{2}^{\\boxed{Q}}( t)\\right)\\\\\n& +\\frac{S_{2}}{S_{1}^{3}} \\sigma _{1}^{2} S_{1}^{2} dt-\\frac{1}{S_{1}^{2}} S_{1} S_{2} \\sigma _{1} \\sigma _{2} \\rho dt\\\\\n& =\\left(\\frac{S_{2}}{S_{1}}\\right)\\left( -rdt-\\sigma _{1} dW_{1}^{\\boxed{Q}}( t) +rdt+\\sigma _{2} dW_{2}^{\\boxed{Q}}( t) +\\sigma _{1}^{2} dt-\\rho \\sigma _{1} \\sigma _{2} dt\\right)\\\\\n& =\\left(\\frac{S_{2}}{S_{1}}\\right)\\left( \\sigma _{1}^{2} dt-\\rho \\sigma _{1} \\sigma _{2} dt-\\sigma _{1} dW_{1}^{\\boxed{Q}}( t) +\\sigma _{2} dW_{2}^{\\boxed{Q}}( t)\\right)\\\\\n& \\quad \\left\\{\\text{ Applying the measure transformation } dW_{1}^{\\boxed{Q}}( t) =dW_{1}^{\\boxed{Q^{S_{1}}}}( t) +\\sigma _{1} dt\\right\\}\\\\\n& =\\left(\\frac{S_{2}}{S_{1}}\\right)\\left( \\sigma _{1}^{2} dt-\\rho \\sigma _{1} \\sigma _{2} dt-\\sigma _{1}\\left( dW_{1}^{\\boxed{Q^{S_{1}}}}( t) +\\sigma _{1} dt\\right) +\\sigma _{2} dW_{2}^{\\boxed{Q}}( t)\\right)\\\\\n& =\\left(\\frac{S_{2}}{S_{1}}\\right)\\left( -\\rho \\sigma _{1} \\sigma _{2} dt-\\sigma _{1} dW_{1}^{\\boxed{Q^{S_{1}}}}( t) +\\sigma _{2} dW_{2}^{\\boxed{Q}}( t)\\right)\\\\\n& =\\left(\\frac{S_{2}}{S_{1}}\\right)\\left[\\left( -\\rho \\sigma _{1} \\sigma _{2} dt+\\sigma _{2} dW_{2}^{\\boxed{Q}}( t)\\right) -\\sigma _{1} dW_{1}^{\\boxed{Q^{S_{1}}}}( t)\\right]\\\\\n& =\\sigma _{2}\\left(\\frac{S_{2}}{S_{1}}\\right)\\left[\\left( -\\rho \\sigma _{1} dt+dW_{2}^{\\boxed{Q}}( t)\\right) -\\frac{\\sigma _{1}}{\\sigma _{2}} dW_{1}^{\\boxed{Q^{S_{1}}}}( t)\\right]\n\\end{aligned}\n\\]\nBut, we must have:\n\\[\nd\\left(\\frac{S_2}{S_1}\\right) = \\sigma_2 \\left(\\frac{S_2}{S_1}\\right) \\left[0 \\cdot dt  + dW_{2}^{\\boxed{Q^{S_1}}}(t) -\\frac{\\sigma_{1}}{\\sigma _{2}} dW_{1}^{\\boxed{Q^{S_{1}}}}( t)\\right]\n\\]\nThis suggests the measure transformation:\n\\[\ndW_2^{\\boxed{Q^{S_1}}}(t) =  -\\rho \\sigma _{1} dt + dW_{2}^{\\boxed{Q}}( t)\n\\]\nSo, finally, the model under the stock measure \\(Q^{S_1}\\) is given by:\n\\[\n\\begin{aligned}\ndS_1(t) &= (r + \\sigma_1^2) S_1 dt + \\sigma_1 S_1 dW_1^{\\boxed{Q^{S_1}}}(t)\\\\\ndS_2(t) &= (r +\\rho \\sigma_1) S_2 dt + \\sigma_2 S_2 dW_2^{\\boxed{Q^{S_1}}}(t)\\\\\ndM(t) &= r M(t) dt\n\\end{aligned}\n\\]\nThe evolution of the second asset can be expressed as:\n\\[\n\\begin{aligned}\nS_2(T) &= S_2(t) \\exp\\left[\\left(r + \\rho \\sigma_1 - \\frac{\\sigma_2^2}{2}\\right)(T-t) + \\sigma_2 (W_2^{\\boxed{Q^{S_1}}}(T) - W_2^{\\boxed{Q^{S_1}}}(t))\\right]\n\\end{aligned}\n\\]\nThe option payoff can be simplified as:\n\\[\n\\begin{aligned}\nV( t) & =S_{1}( t) Q^{\\boxed{S_{1}}}[ S_{2}( T)  &gt;K]\\\\\n& =S_{1}( t) Q^{\\boxed{S_{1}}}\\left[ S_{2}( t)\\exp\\left\\{\\left( r+\\rho \\sigma _{1} -\\frac{\\sigma _{2}^{2}}{2}\\right)( T-t) +\\sigma _{2}( W_{2}( T) -W_{2}( t))\\right\\}  &gt;K\\right]\\\\\n& =S_{1}( t) Q^{\\boxed{S_{1}}}\\left[ S_{2}( t)\\exp\\left\\{\\left( r+\\rho \\sigma _{1} -\\frac{\\sigma _{2}^{2}}{2}\\right)( T-t) -\\sigma _{2}\\sqrt{T-t} \\cdot Z\\right\\}  &gt;K\\right]\\\\\n& =S_{1}( t) Q^{\\boxed{S_{1}}}\\left[\\ln\\frac{S_{2}( t)}{K} +\\left( r+\\rho \\sigma _{1} -\\frac{\\sigma _{2}^{2}}{2}\\right)( T-t)  &gt;\\sigma _{2}\\sqrt{T-t} \\cdot Z\\right]\\\\\n& =S_{1}( t) Q^{\\boxed{S_{1}}}\\left[ Z&lt; \\frac{\\ln\\frac{S_{2}( t)}{K} +\\left( r+\\rho \\sigma _{1} -\\frac{\\sigma _{2}^{2}}{2}\\right)( T-t)}{\\sigma _{2}\\sqrt{T-t}}\\right]\\\\\n& =S_{1}( t) \\Phi \\left[\\frac{\\ln\\frac{S_{2}( t)}{K} +\\left( r+\\rho \\sigma _{1} -\\frac{\\sigma _{2}^{2}}{2}\\right)( T-t)}{\\sigma _{2}\\sqrt{T-t}}\\right]\n\\end{aligned}\n\\]"
  },
  {
    "objectID": "posts/fun-with-numeraires/index.html#pricing-an-assymetric-power-option-v_t-frac1k2k3---s_t3",
    "href": "posts/fun-with-numeraires/index.html#pricing-an-assymetric-power-option-v_t-frac1k2k3---s_t3",
    "title": "Fun with numeraires!",
    "section": "Pricing an assymetric power option \\(V_T = \\frac{1}{K^2}(K^3 - S_T^3)^{+}\\)",
    "text": "Pricing an assymetric power option \\(V_T = \\frac{1}{K^2}(K^3 - S_T^3)^{+}\\)"
  },
  {
    "objectID": "posts/fun-with-numeraires/index.html#references",
    "href": "posts/fun-with-numeraires/index.html#references",
    "title": "Fun with numeraires!",
    "section": "References",
    "text": "References\n\n\nGirsanov, Numeraires and all that, Andrew Lesniewski.\nInterest-rate Models - Theory and Practice, Damiano Brigo and Fabio Mercurio."
  },
  {
    "objectID": "posts/exploring-option-greeks/index.html",
    "href": "posts/exploring-option-greeks/index.html",
    "title": "Exploring Option Greeks",
    "section": "",
    "text": "I derived the Black-Scholes formula for European style vanilla FX options in a previous post here. The Black-Scholes model \\(Bl(S_0,K,T,r_{DOM},r_{FOR},\\sigma)\\) equipped with a single flat volatility parameter \\(\\sigma\\) produces option prices which are NOT consistent with the observed market prices of FX options across different strikes and maturities.\nAlthough, the BS model suffers many flaws, it is still often used, at least for quoting purposes. Since all of the other inputs into the model - market data variables such as the stock price \\(S_0\\), the domestic depo rate \\(r_{DOM}\\), the foreign depo rate \\(r_{FOR}\\), and the parameters such as option strike \\(K\\), the time-to-maturity \\(T\\), can be either seen in the market or are known constants, we can easily solve for the value \\(\\sigma_{\\text{imp}}\\) of the parameter \\(\\sigma\\) such that:\n\\[Bl(S_0,K,T,r_{DOM},r_{FOR},\\sigma_{\\text{imp}}) = V_{\\text{market}}\\]\nThis value \\(\\sigma_{\\text{imp}}\\) implied from the market price of the option is called the implied volatility.\nThus, although the BS model suffers from flaws, it is mainly used as a quote converter. In the FX options market, option prices are quoted in terms of implied volatilities. The BS formula is used to convert implied vols \\(\\sigma_{\\text{imp}}\\) to prices and vice versa. The delta hedge to be exchanged between counterparties is calculated according to the BS formula, and this is also true for the Vega hedge of various exotic options. In many cases, the model is also used to run trading books.\nIn this note, I explore various delta conventions and derive the greeks. Check out FX Vol smile by Wyestup! The entire concept of the FX volatility smile is based on the parametrization with respect to delta."
  },
  {
    "objectID": "posts/exploring-option-greeks/index.html#introduction.",
    "href": "posts/exploring-option-greeks/index.html#introduction.",
    "title": "Exploring Option Greeks",
    "section": "",
    "text": "I derived the Black-Scholes formula for European style vanilla FX options in a previous post here. The Black-Scholes model \\(Bl(S_0,K,T,r_{DOM},r_{FOR},\\sigma)\\) equipped with a single flat volatility parameter \\(\\sigma\\) produces option prices which are NOT consistent with the observed market prices of FX options across different strikes and maturities.\nAlthough, the BS model suffers many flaws, it is still often used, at least for quoting purposes. Since all of the other inputs into the model - market data variables such as the stock price \\(S_0\\), the domestic depo rate \\(r_{DOM}\\), the foreign depo rate \\(r_{FOR}\\), and the parameters such as option strike \\(K\\), the time-to-maturity \\(T\\), can be either seen in the market or are known constants, we can easily solve for the value \\(\\sigma_{\\text{imp}}\\) of the parameter \\(\\sigma\\) such that:\n\\[Bl(S_0,K,T,r_{DOM},r_{FOR},\\sigma_{\\text{imp}}) = V_{\\text{market}}\\]\nThis value \\(\\sigma_{\\text{imp}}\\) implied from the market price of the option is called the implied volatility.\nThus, although the BS model suffers from flaws, it is mainly used as a quote converter. In the FX options market, option prices are quoted in terms of implied volatilities. The BS formula is used to convert implied vols \\(\\sigma_{\\text{imp}}\\) to prices and vice versa. The delta hedge to be exchanged between counterparties is calculated according to the BS formula, and this is also true for the Vega hedge of various exotic options. In many cases, the model is also used to run trading books.\nIn this note, I explore various delta conventions and derive the greeks. Check out FX Vol smile by Wyestup! The entire concept of the FX volatility smile is based on the parametrization with respect to delta."
  },
  {
    "objectID": "posts/exploring-option-greeks/index.html#quote-style-conversions.",
    "href": "posts/exploring-option-greeks/index.html#quote-style-conversions.",
    "title": "Exploring Option Greeks",
    "section": "Quote style conversions.",
    "text": "Quote style conversions.\nIn FX markets, options are quoted in one of 4 quote styles - domestic per foreign (d/f), percentage foreign (%f), percentage domestic (%d) and foreign per domestic (f/d).\nThe standard Black-Scholes formula is:\n\\[\n\\begin{align*}\nV_{d/f} &= \\omega [S_0 e^{-r_{FOR} T} \\Phi(d_{+}) - K e^{-r_{DOM}T} \\Phi(d_{-})\\\\\n&= \\omega e^{-r_{DOM}T}[F \\Phi(d_{+}) - K  \\Phi(d_{-})]\n\\end{align*}\n\\]\n\nImplementing the Bl Calculator and Option Greeks.\nimport numpy as np\nfrom scipy.stats import norm\nfrom enum import Enum\nimport datetime as dt\n\nclass CallPut(Enum):\n    CALL_OPTION = 1\n    PUT_OPTION = -1\n\nclass BlackCalculator:\n    \"\"\"Implements the Black formula to price a vanilla option\"\"\"\n    def __init__(\n        self,\n        s_t : float,\n        strike : float,\n        today : float,\n        expiry : float,\n        r_dom : float,\n        r_for : float,\n        sigma : float            \n    )\n        self._s_t = s_t\n        self._strike = strike\n        self._today = today\n        self._expiry = expiry\n        self._r_dom = r_dom\n        self._r_for = r_for\n        self._sigma = sigma\n\n    def at_the_money_forward(\n        self,\n    ) -&gt; float :\n        \"\"\"Computes the at-the-money forward\"\"\"\n\n        foreign_df = np.exp(self._r_for * (expiry - today))\n        domestic_df = np.exp(self._r_dom * (expiry - today))\n        fwd_points = foreign_df / domestic_df\n        return self._s_t * fwd_points \n            \n    def d_plus(S_t,K,t,T,r_DOM,r_FOR,sigma):\n        F = at_the_money_forward(S_t,K,t,T,r_DOM,r_FOR,sigma)\n        return (np.log(F/K) + (T-t)*(sigma**2)/2)/(sigma * np.sqrt(T - t))\n\n    def d_minus(S_t,K,t,T,r_DOM,r_FOR,sigma):\n        F = at_the_money_forward(S_t,K,t,T,r_DOM,r_FOR,sigma)\n        return (np.log(F/K) - (T-t)*(sigma**2)/2)/(sigma * np.sqrt(T - t))\n\n    def pv(S_t,K,t,T,r_DOM,r_FOR,sigma, CCY1Notional,callPut):\n        F = at_the_money_forward(S_t,K,t,T,r_DOM,r_FOR,sigma)\n        omega = callPut.value\n        d_plus = dPlus(S_t,K,t,T,r_DOM,r_FOR,sigma)\n        d_minus = dMinus(S_t,K,t,T,r_DOM,r_FOR,sigma)\n        domesticDF = np.exp(-r_DOM*(T-t))\n        \n        undiscountedPrice = omega* (F * norm.cdf(omega * d_plus) - K * norm.cdf(omega * d_minus))\n        pv = domesticDF * undiscountedPrice * CCY1Notional\n        return pv"
  },
  {
    "objectID": "posts/diagonalization/index.html",
    "href": "posts/diagonalization/index.html",
    "title": "Eigenthingies and Diagonalizability",
    "section": "",
    "text": "Each square matrix possesses a collection of one or more complex scalars, called eigenvalues and associated vectors called eigenvectors. A matrix is a concrete realization of a linear transformation on a vector space. The eigenvectors indicate the directions of pure stretch and the eigenvalues the extent of stretching."
  },
  {
    "objectID": "posts/diagonalization/index.html#eigenvalues-and-eigenvectors",
    "href": "posts/diagonalization/index.html#eigenvalues-and-eigenvectors",
    "title": "Eigenthingies and Diagonalizability",
    "section": "Eigenvalues and Eigenvectors",
    "text": "Eigenvalues and Eigenvectors\n\nDefinition 1 (Eigenvalue and Eigenvector) Let \\(A\\) be an \\(n \\times n\\) matrix. A scalar \\(\\lambda\\) is called an eigenvalue of \\(A\\) if there exists a non-zero vector \\(\\mathbf{v} \\neq \\mathbf{0}\\) such that\n\\[\nA\\mathbf{v} = \\lambda \\mathbf{v}\n\\tag{1}\\]\n\nIn geometric terms, the matrix \\(A\\) has the effect of stretching the eigenvector \\(\\mathbf{v}\\) by an amount specified by the eigenvalue \\(\\lambda\\).\nThe eigenvalue equation (Equation 1) is a system of linear equations is a system of linear equations for the entries of the eigenvector \\(\\mathbf{v}\\), provided that the eigenvaluen \\(\\lambda\\) is specified in advance. But, Gaussian elimination per se cannot solve the problem of determining two unknowns \\(\\lambda\\) and \\(\\mathbf{v}\\). We can rewrite the equation in the form:\n\\[\n(A- \\lambda I)\\mathbf{v} = \\mathbf{0}\n\\tag{2}\\]\nThis is a homogenous system of linear equations. It has the trivial solution \\(\\mathbf{v}=0\\). But, we are specifically seeking a non-zero solution. The homogenous system \\(R\\mathbf{x}=\\mathbf{0}\\) has a non-trivial solution, if and only if, \\(R\\) is singular, \\(rank(R) &lt; n\\) or equivalently \\(det(R) = 0\\). Consequently, we desire\n\\[\ndet(A-\\lambda I) = 0\n\\tag{3}\\]\nThis is called the characteristic equation and \\(p(\\lambda) = det(A-\\lambda I)\\) is called the characteristic polynomial.\nIn practice, one first solves the characteristic equation (Equation 3) to obtain a set of eigenvalues. Then, for each eigenvalue, we use standard linear algebra methods e.g. Gaussian elimination to solve the correponding linear system Equation 2 for the associated eigenvector \\(\\mathbf{v}\\)."
  },
  {
    "objectID": "posts/diagonalization/index.html#emhe",
    "href": "posts/diagonalization/index.html#emhe",
    "title": "Eigenthingies and Diagonalizability",
    "section": "EMHE",
    "text": "EMHE\n\nTheorem 1 Every matrix has atleast one eigenvalue, and a corresponding eigenvector.\n\nProof.\nThis is just the FTA(Fundamental Theorem of Algebra), but it’s still worth enumerating as a theorem.\nLet \\(A \\in \\mathbb{C}^{n \\times n}\\) and the scalar field \\(\\mathbb{F}= \\mathbb{R}\\).\nLet \\(\\mathbf{v}\\) be any non-zero vector in \\(\\mathbb{C}^n\\). Consider the list \\(\\{\\mathbf{v},A\\mathbf{v},\\ldots,A^n \\mathbf{v}\\}\\). These are \\(n+1\\) vectors and this must be a linearly dependent set. There exists \\(a_0, \\ldots, a_n\\) not all zero, such that:\n\\[\na_n A^n \\mathbf{v} + a_{n-1}A^{n-1}\\mathbf{v} + \\ldots + a_1 A \\mathbf{v} + a_0 I \\mathbf{v} = \\mathbf{0}\n\\]\nSince this holds for all \\(\\mathbf{v}\\neq \\mathbf{0}\\), the linear operator \\(a_n A^n + \\ldots + a_1 A + a_0 I\\) must be the zero transformation.\nBy FTA, the polynomial equation with complex coefficients of degree \\(n\\):\n\\[\np(x) = a_0 + a_1 x + a_2 x^2 + \\ldots + a_{n}x^n\n\\]\ncan be factorized as :\n\\[\np(x) = (x - \\lambda_1)(x - \\lambda_2)\\cdots(x - \\lambda_n)\n\\]\nPutting it all together,\n\\[\n\\begin{align*}\np(A)\\mathbf{v} &= (A - \\lambda_1 I)(A - \\lambda_2 I)\\cdots (A - \\lambda_n I)\\mathbf{v} = \\mathbf{0}\n\\end{align*}\n\\]\n\\(\\forall \\mathbf{v} \\neq \\mathbf{0}\\).\nSo, the composition of the factors \\((A-\\lambda_1 I)\\cdots (A - \\lambda_n I)\\) has a non-trivial null space.\n\\[\nker((A-\\lambda_1 I)(A-\\lambda_2 I)\\cdots (A - \\lambda_n I)) \\neq \\{\\mathbf{0}\\}\n\\]\nSo, atleast one of the factors must fail to be injective. There exists \\(\\lambda_i\\), such that \\((A-\\lambda_i I)\\mathbf{v}=\\mathbf{0}\\) such that \\(\\mathbf{v}\\neq \\mathbf{0}\\). Thus, \\(A\\) has atleast one eigenvalue and one eigenvector. \\(\\blacksquare\\)"
  },
  {
    "objectID": "posts/diagonalization/index.html#eigenvectors-as-the-basis-of-a-vector-space",
    "href": "posts/diagonalization/index.html#eigenvectors-as-the-basis-of-a-vector-space",
    "title": "Eigenthingies and Diagonalizability",
    "section": "Eigenvectors as the basis of a vector space",
    "text": "Eigenvectors as the basis of a vector space\n\nLemma 1 If \\(\\lambda_1 \\geq \\lambda_2 \\geq \\ldots \\geq \\lambda_n\\) are \\(n\\) distinct eigenvalues of a matrix \\(A\\), \\(\\lambda_i \\neq \\lambda_j\\), \\(\\forall i \\neq j\\), then the corresponding eigenvectors \\(\\{\\mathbf{v}_1,\\ldots,\\mathbf{v}_n\\}\\) are linearly independent.\n\nProof.\nWe use induction on the number of eigenvalues. The case \\(k=1\\) is immediate, since an eigenvector cannot be zero. Assume that we know that the result is valid for \\((k-1)\\) eigenvalues. Our claim is that \\(\\{\\mathbf{v}_1,\\ldots,\\mathbf{v}_{k-1},\\mathbf{v}_k\\}\\) are linearly independent.\nSuppose we have a vanishing linear combination:\n\\[\nc_1 \\mathbf{v}_1 + c_2 \\mathbf{v}_2 + \\ldots + c_{k} \\mathbf{v}_k = \\mathbf{0}\n\\tag{4}\\]\nLet us multiply this equation by the matrix \\(A\\):\n\\[\n\\begin{align*}\nc_1 A\\mathbf{v}_1 + c_2 A\\mathbf{v}_2 + \\ldots + c_{k} A\\mathbf{v}_k &= \\mathbf{0}\\\\\n\\Longrightarrow c_1 \\lambda_1 \\mathbf{v}_1 + c_2 \\lambda_2 \\mathbf{v}_2 + \\ldots + c_k \\lambda_k \\mathbf{v}_k &= \\mathbf{0}\n\\end{align*}\n\\]\nOn the other hand if we multiply the original Equation 4 by \\(\\lambda_k\\), we have:\n\\[\nc_1 \\lambda_k \\mathbf{v}_1 + c_2 \\lambda_k \\mathbf{v}_2 + \\ldots + c_{k} \\lambda_k \\mathbf{v}_k = \\mathbf{0}\n\\]\nUpon subtracting this from the previous equation, we obtain:\n\\[\nc_1 (\\lambda_1 - \\lambda_k) \\mathbf{v}_1 + c_2 (\\lambda_2 - \\lambda_k)\\mathbf{v}_2 + \\ldots + c_{k-1} (\\lambda_{k-1} - \\lambda_k)\\mathbf{v}_{k-1} = \\mathbf{0}\n\\]\nThis is a vanishing linear combination of the first \\((k-1)\\) eigenvectors, and so, by our induction hypothesis, it can only happen if all the coefficients are zero:\n\\[\nc_1(\\lambda_1 - \\lambda_k) = c_2(\\lambda_2 - \\lambda_k) = \\ldots = c_{k-1}(\\lambda_{k-1} - \\lambda_k) = 0\n\\]\nThe eigenvalues were assumed to be distinct, and consequently \\(c_1 = c_2 = \\ldots = c_{k-1} = 0\\). Substituting these values back into Equation 4, we find that \\(c_k \\mathbf{v}_k = 0\\), and so \\(c_k = 0\\) also, since \\(\\mathbf{v}_k \\neq \\mathbf{0}\\). Thus, we have proved that, if Equation 4 holds, then \\(c_1 = \\ldots = c_k = 0\\). Thus, \\(\\{\\mathbf{v}_1,\\ldots,\\mathbf{v}_k\\}\\) is a linearly independent set. \\(\\blacksquare\\)\n\nTheorem 2 If the \\(n \\times n\\) real matrix \\(A\\) has \\(n\\) distinct real eigenvalues \\(\\lambda_1,\\lambda_2,\\ldots,\\lambda_n\\), then the corresponding real eigenvectors \\(\\mathbf{v}_1,\\ldots,\\mathbf{v}_n\\) form a basis of \\(\\mathbb{R}^n\\). If \\(A\\) (which may be either real or complex-valued matrix) has \\(n\\) distinct complex eigenvalues, then the corresponding eigenvectors \\(\\mathbf{v}_1,\\ldots,\\mathbf{v}_n\\) form a basis of \\(\\mathbb{C}^n\\)."
  },
  {
    "objectID": "posts/diagonalization/index.html#diagonalization",
    "href": "posts/diagonalization/index.html#diagonalization",
    "title": "Eigenthingies and Diagonalizability",
    "section": "Diagonalization",
    "text": "Diagonalization\nConsider a square matrix \\(A \\in \\mathbb{R}^{n \\times n}\\) with \\(n\\) distinct eigenvalues. We can then write:\n\\[\nA\\begin{bmatrix}\\mathbf{v}_1 \\\\ \\mathbf{v}_2 \\\\ \\vdots \\\\ \\mathbf{v}_n\\end{bmatrix} =\n\\begin{bmatrix}\n\\lambda_1 \\\\\n& \\lambda_2 \\\\\n& & \\ddots \\\\\n& & & \\lambda_n\n\\end{bmatrix}\\begin{bmatrix}\\mathbf{v}_1 \\\\ \\mathbf{v}_2 \\\\ \\vdots \\\\ \\mathbf{v}_n\\end{bmatrix}\n\\]\nDefine \\(P\\) as \\((\\mathbf{v}_1,\\mathbf{v}_2,\\ldots,\\mathbf{v}_n)^T\\). So, we can write:\n\\[\n\\begin{align*}\nAP &= \\Lambda P\\\\\nA & = P^{-1}\\Lambda P\n\\end{align*}\n\\]\nor equivalently \\(A=P\\Lambda P^{-1}\\), where \\(\\Lambda = diag(\\lambda_1,\\ldots,\\lambda_n)\\) is a diagonal matrix. Consequently, if the matrix \\(A\\) has \\(n\\) distinct eigenvalues, then \\(A\\) is said to be diagonalizable.\n\nDefinition 2 A square matrix \\(A\\) is said to be diagonalizable, if and only if, there exists a non-singular matrix \\(P\\), such that \\(A\\) has a matrix factorization:\n\\[\nA = P\\Lambda P^{-1}\n\\]\nwhere \\(\\Lambda=diag(\\lambda_1,\\ldots,\\lambda_n)\\) ."
  },
  {
    "objectID": "posts/diagonalization/index.html#gershgorin-circle-theorem",
    "href": "posts/diagonalization/index.html#gershgorin-circle-theorem",
    "title": "Eigenthingies and Diagonalizability",
    "section": "Gershgorin-Circle Theorem",
    "text": "Gershgorin-Circle Theorem\nIn pratice, precisely computing the eigenvalues of a matrix is done using a numerical algorithm. In certain theoretical applications, we may not require numerical values, but only their approximate locations. The Gershgorin circle theorem, due to early 20th century Russian mathematician Semyon Gershgorin, serves to restrict the eigenvalues to a certain well-defined region in the complex plane.\n\nDefinition 3 Let \\(A \\in \\mathbb{C}^{n \\times n}\\) be a square matrix. For each \\(1 \\leq i \\leq n\\) , define the \\(i\\) th Gershgorin disk\n\\[\nD_i = \\{|z - a_{ii}|&lt;r_i:z\\in\\mathbb{C}\\}, \\quad r_i = \\sum_{j,j\\neq i} |a_{ij}|\n\\tag{5}\\]\nThe Gershgorin domain \\(D_A = \\bigcup_{i=1}^n D_i \\subset \\mathbb{C}\\) is the union of the Gershgorin disks.\n\nThus, the \\(i\\)th Gershgorin disk \\(D_i\\) is centered at the \\(i\\)-th diagonal entry of \\(A\\) and is an open ball of radius \\(r_i\\) equal to the sum of the absolute values of the off-diagonal entries that are in it’s \\(i\\)-th row.\nProof\nLet \\(\\mathbf{v}\\) be an eigenvector of \\(A\\) with eigenvalue \\(\\lambda\\). Let \\(\\mathbf{u}=\\mathbf{v}/||v||_{\\infty}\\) be the corresponding unit eigenvector with respect to the \\(\\infty\\)-norm, so that:\n\\[\n||u||_{\\infty} = \\max\\{|u|_1,|u|_2,\\ldots,|u|_n\\} = 1\n\\]\nLet \\(u_i\\) be an entry of \\(\\mathbf{u}\\) that achieves the maximum: \\(|u_i|=1\\). Writing out the \\(i\\)-th component of the eigenvalue equation \\(A\\mathbf{u}=\\lambda \\mathbf{u}\\), we obtain:\n\\[\n\\begin{align*}\n\\sum_{j=1}^{n} a_{ij}u_j &= \\lambda u_i \\\\\n\\sum_{j \\neq i} a_{ij}u_j &= (\\lambda - a_{ii}) u_i\n\\end{align*}\n\\]\nTherefore, since all \\(|u_j| \\leq 1\\), while \\(|u_i|=1\\), the distance between \\(\\lambda\\) and \\(a_{ii}\\) can be bounded from above as:\n\\[\n\\begin{align*}\n|\\lambda - a_{ii}| &= \\Bigg|\\sum_{j \\neq i} a_{ij}u_j \\Bigg|\\\\\n&\\leq \\sum_{j \\neq i} |a_{ij}||u_j| & \\{\\text{ Triangle Inequality }\\}\\\\\n&\\leq \\sum_{j \\neq i} |a_{ij}| & \\{ |u_j| \\leq 1 \\}\\\\\n&= r_i\n\\end{align*}\n\\]\nThis immediately implies that \\(\\lambda \\in D_i \\subset D_A\\) belongs to the \\(i\\)th Gershgorin disk."
  },
  {
    "objectID": "posts/custom-iterators/index.html",
    "href": "posts/custom-iterators/index.html",
    "title": "Custom iterators and Iterator concepts",
    "section": "",
    "text": "An iterator is a generalization of a pointer. C++ STL containers usually expose iterators as part of their interface. They abstract away lower-level implementation details of traversing through container types, thus freeing the container-user to focus on algorithm design/business logic."
  },
  {
    "objectID": "posts/cox-ingersoll-ross-model/index.html",
    "href": "posts/cox-ingersoll-ross-model/index.html",
    "title": "Cox-Ingersoll-Ross (CIR) model",
    "section": "",
    "text": "The short rate under the CIR model has the dynamics:\n\\[dr_t = \\kappa (\\theta - r_t)dt + \\sigma \\sqrt{r_t}dB_t\\]\nFor a moment, if we drop the stochastic term, and merely consider the first order linear ODE \\(\\frac{dr_t}{dt} + \\kappa r_t = \\kappa \\theta\\), the integrating factor for this differential equation is \\(e^{\\int \\kappa dt} = e^{\\kappa t}\\). Multiplying both sides by the integrating factor, we have:\n\\[\\begin{align*}\ne^{\\kappa t} dr_t &= \\kappa(\\theta - r_t) e^{\\kappa t}dt + \\sigma e^{\\kappa t}\\sqrt{r_t} dB_t \\\\\ne^{\\kappa t} dr_t + r_t e^{\\kappa t}dt &= \\kappa e^{\\kappa t}\\theta dt + \\sigma e^{\\kappa t}\\sqrt{r_t} dB_t \\\\\nd(e^{\\kappa t} r_t) &= \\kappa e^{\\kappa t}\\theta dt + \\sigma e^{\\kappa t}\\sqrt{r_t} dB_t \\\\\n\\int_{0}^{t} d(e^{\\kappa s} r_s) &= \\theta \\kappa\\int_{0}^{t}  e^{\\kappa s} ds + \\sigma \\int_{0}^{t}  e^{\\kappa s}\\sqrt{r_s} dB_s \\\\\n[e^{\\kappa s} r_s]_{0}^{t} &= \\kappa \\theta \\left[\\frac{e^{\\kappa s}}{\\kappa}\\right]_{0}^{t} + \\sigma \\int_{0}^{t}  e^{\\kappa s}\\sqrt{r_s} dB_s\\\\\ne^{\\kappa t}r_t - r_0 &= \\theta (e^{\\kappa t} - 1) + \\sigma \\int_{0}^{t}  e^{\\kappa s}\\sqrt{r_s} dB_s \\\\\ne^{\\kappa t} r_t &= r_0 + \\theta (e^{\\kappa t} - 1) + \\sigma \\int_{0}^{t}  e^{\\kappa s}\\sqrt{r_s} dB_s \\\\\nr_t &= r_0 e^{-\\kappa t} + \\theta (1 - e^{-\\kappa t}) + \\sigma \\int_{0}^{t}  e^{-\\kappa (t-s)}\\sqrt{r_s} dB_s\n\\end{align*}\\]\nThe mean is given by:\n\\[\\begin{align*}\n\\mathbf{E}[r_t] &= r_0 e^{-\\kappa t} + \\theta (1 - e^{-\\kappa t})\n\\end{align*}\\]\nThe random variable \\(\\sigma \\int_{0}^{t} e^{-\\kappa (t-s)}\\sqrt{r_s} dB_s\\) has mean \\(0\\) and variance:\n\\[\\begin{align*}\n\\mathbf{E}\\left[\\left(\\sigma \\int_{0}^{t}  e^{-\\kappa (t-s)}\\sqrt{r_s} dB_s\\right)^2\\right] &= \\sigma^2 \\int_{0}^{t}e^{-2\\kappa(t-s)} \\mathbf{E}[r_s] ds \\\\\n&= \\sigma^2 e^{-2\\kappa t}\\int_{0}^{t}e^{2\\kappa s} \\left(r_0 e^{-\\kappa s} + \\theta(1-e^{-\\kappa s})\\right) ds\\\\\n&= \\sigma^2 r_0 e^{-2\\kappa t} \\int_{0}^{t} e^{\\kappa s} ds + \\sigma^2 \\theta e^{-2\\kappa t} \\int_{0}^{t}(e^{2\\kappa s}-e^{\\kappa s}) ds \\\\\n&= \\sigma^2 r_0 e^{-2\\kappa t} \\left[\\frac{e^{\\kappa s}}{\\kappa} \\right]_{0}^{t} +\\sigma^2 \\theta e^{-2\\kappa t} \\left[\\frac{e^{2\\kappa s}}{2\\kappa} - \\frac{e^{\\kappa s}}{\\kappa}\\right]_{0}^{t}\\\\\n&= \\frac{\\sigma^2 r_0}{\\kappa} e^{-2\\kappa t} (e^{\\kappa t} - 1)+\\sigma^2 \\theta e^{-2\\kappa t} \\left[\\frac{e^{2\\kappa s}}{2\\kappa} - \\frac{2e^{\\kappa s}}{2\\kappa}\\right]_{0}^{t}\\\\\n&= \\frac{\\sigma^2 r_0}{\\kappa} e^{-2\\kappa t}(e^{\\kappa t} - 1)+\\frac{\\sigma^2 \\theta}{2\\kappa} e^{-2\\kappa t}(e^{2\\kappa t} - 2e^{\\kappa t} - (1 - 2))\\\\\n&= \\frac{\\sigma^2 r_0}{\\kappa} e^{-2\\kappa t}(e^{\\kappa t} - 1)+\\frac{\\sigma^2 \\theta}{2\\kappa}e^{-2\\kappa t} (1 + e^{2\\kappa t} - 2e^{\\kappa t})\\\\\n&= \\frac{\\sigma^2 r_0}{\\kappa} (e^{-\\kappa t} - e^{-2\\kappa t})+\\frac{\\sigma^2 \\theta}{2\\kappa} (1 - e^{-\\kappa t})^2\n\\end{align*}\\]"
  },
  {
    "objectID": "posts/cox-ingersoll-ross-model/index.html#short-rate-dynamics-mean-and-variance",
    "href": "posts/cox-ingersoll-ross-model/index.html#short-rate-dynamics-mean-and-variance",
    "title": "Cox-Ingersoll-Ross (CIR) model",
    "section": "",
    "text": "The short rate under the CIR model has the dynamics:\n\\[dr_t = \\kappa (\\theta - r_t)dt + \\sigma \\sqrt{r_t}dB_t\\]\nFor a moment, if we drop the stochastic term, and merely consider the first order linear ODE \\(\\frac{dr_t}{dt} + \\kappa r_t = \\kappa \\theta\\), the integrating factor for this differential equation is \\(e^{\\int \\kappa dt} = e^{\\kappa t}\\). Multiplying both sides by the integrating factor, we have:\n\\[\\begin{align*}\ne^{\\kappa t} dr_t &= \\kappa(\\theta - r_t) e^{\\kappa t}dt + \\sigma e^{\\kappa t}\\sqrt{r_t} dB_t \\\\\ne^{\\kappa t} dr_t + r_t e^{\\kappa t}dt &= \\kappa e^{\\kappa t}\\theta dt + \\sigma e^{\\kappa t}\\sqrt{r_t} dB_t \\\\\nd(e^{\\kappa t} r_t) &= \\kappa e^{\\kappa t}\\theta dt + \\sigma e^{\\kappa t}\\sqrt{r_t} dB_t \\\\\n\\int_{0}^{t} d(e^{\\kappa s} r_s) &= \\theta \\kappa\\int_{0}^{t}  e^{\\kappa s} ds + \\sigma \\int_{0}^{t}  e^{\\kappa s}\\sqrt{r_s} dB_s \\\\\n[e^{\\kappa s} r_s]_{0}^{t} &= \\kappa \\theta \\left[\\frac{e^{\\kappa s}}{\\kappa}\\right]_{0}^{t} + \\sigma \\int_{0}^{t}  e^{\\kappa s}\\sqrt{r_s} dB_s\\\\\ne^{\\kappa t}r_t - r_0 &= \\theta (e^{\\kappa t} - 1) + \\sigma \\int_{0}^{t}  e^{\\kappa s}\\sqrt{r_s} dB_s \\\\\ne^{\\kappa t} r_t &= r_0 + \\theta (e^{\\kappa t} - 1) + \\sigma \\int_{0}^{t}  e^{\\kappa s}\\sqrt{r_s} dB_s \\\\\nr_t &= r_0 e^{-\\kappa t} + \\theta (1 - e^{-\\kappa t}) + \\sigma \\int_{0}^{t}  e^{-\\kappa (t-s)}\\sqrt{r_s} dB_s\n\\end{align*}\\]\nThe mean is given by:\n\\[\\begin{align*}\n\\mathbf{E}[r_t] &= r_0 e^{-\\kappa t} + \\theta (1 - e^{-\\kappa t})\n\\end{align*}\\]\nThe random variable \\(\\sigma \\int_{0}^{t} e^{-\\kappa (t-s)}\\sqrt{r_s} dB_s\\) has mean \\(0\\) and variance:\n\\[\\begin{align*}\n\\mathbf{E}\\left[\\left(\\sigma \\int_{0}^{t}  e^{-\\kappa (t-s)}\\sqrt{r_s} dB_s\\right)^2\\right] &= \\sigma^2 \\int_{0}^{t}e^{-2\\kappa(t-s)} \\mathbf{E}[r_s] ds \\\\\n&= \\sigma^2 e^{-2\\kappa t}\\int_{0}^{t}e^{2\\kappa s} \\left(r_0 e^{-\\kappa s} + \\theta(1-e^{-\\kappa s})\\right) ds\\\\\n&= \\sigma^2 r_0 e^{-2\\kappa t} \\int_{0}^{t} e^{\\kappa s} ds + \\sigma^2 \\theta e^{-2\\kappa t} \\int_{0}^{t}(e^{2\\kappa s}-e^{\\kappa s}) ds \\\\\n&= \\sigma^2 r_0 e^{-2\\kappa t} \\left[\\frac{e^{\\kappa s}}{\\kappa} \\right]_{0}^{t} +\\sigma^2 \\theta e^{-2\\kappa t} \\left[\\frac{e^{2\\kappa s}}{2\\kappa} - \\frac{e^{\\kappa s}}{\\kappa}\\right]_{0}^{t}\\\\\n&= \\frac{\\sigma^2 r_0}{\\kappa} e^{-2\\kappa t} (e^{\\kappa t} - 1)+\\sigma^2 \\theta e^{-2\\kappa t} \\left[\\frac{e^{2\\kappa s}}{2\\kappa} - \\frac{2e^{\\kappa s}}{2\\kappa}\\right]_{0}^{t}\\\\\n&= \\frac{\\sigma^2 r_0}{\\kappa} e^{-2\\kappa t}(e^{\\kappa t} - 1)+\\frac{\\sigma^2 \\theta}{2\\kappa} e^{-2\\kappa t}(e^{2\\kappa t} - 2e^{\\kappa t} - (1 - 2))\\\\\n&= \\frac{\\sigma^2 r_0}{\\kappa} e^{-2\\kappa t}(e^{\\kappa t} - 1)+\\frac{\\sigma^2 \\theta}{2\\kappa}e^{-2\\kappa t} (1 + e^{2\\kappa t} - 2e^{\\kappa t})\\\\\n&= \\frac{\\sigma^2 r_0}{\\kappa} (e^{-\\kappa t} - e^{-2\\kappa t})+\\frac{\\sigma^2 \\theta}{2\\kappa} (1 - e^{-\\kappa t})^2\n\\end{align*}\\]"
  },
  {
    "objectID": "posts/cox-ingersoll-ross-model/index.html#naive-python-implementation",
    "href": "posts/cox-ingersoll-ross-model/index.html#naive-python-implementation",
    "title": "Cox-Ingersoll-Ross (CIR) model",
    "section": "Naive python implementation",
    "text": "Naive python implementation\n\nCIRProcess class\nThe class CIRProcess is designed as an engine to generate sample paths of the CIR process.\n\nimport math\nfrom dataclasses import dataclass\n\nimport joypy\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport pandas as pd\nfrom matplotlib import cm\nfrom tqdm import tqdm\n\n\n@dataclass\nclass CIRProcess:\n    \"\"\"An engine for generating sample paths of the Cox-Ingersoll-Ross process\"\"\"\n\n    kappa: float\n    theta: float\n    sigma: float\n    step_size: float\n    total_time: float\n    r_0: float\n\n    def generate_paths(self, paths: int):\n        \"\"\"Generate sample paths\"\"\"\n        num_steps = int(self.total_time / self.step_size)\n        dz = np.random.standard_normal((paths, num_steps))\n        r_t = np.zeros((paths, num_steps))\n        zero_vector = np.full(paths, self.r_0)\n        prev_r = zero_vector\n        for i in range(num_steps):\n            r_t[:, i] = (\n                prev_r\n                + self.kappa * np.subtract(self.theta, prev_r) * self.step_size\n                + self.sigma\n                * np.sqrt(np.abs(prev_r))\n                * math.sqrt(self.step_size)\n                * dz[:, i]\n            )\n\n            prev_r = r_t[:, i]\n\n        return r_t\n\n\n\nSample Paths\nWe generate \\(N=10\\) paths of the CIR process.\n\n\nShow the code\ncir_process = CIRProcess(\n    kappa=3,\n    r_0=9,\n    sigma=0.5,\n    step_size=10e-3,\n    theta=3,\n    total_time=1.0,\n)\n\nnum_paths = 10\n\npaths = cir_process.generate_paths(num_paths)\n\nt = np.linspace(0.01, 1.0, 100)\n\nplt.grid(True)\nplt.xlabel(r\"Time $t$\")\nplt.ylabel(r\"$R(t)$\")\nplt.title(r\"$N=10$ paths of the Cox-Ingersoll-Ross process\")\nfor path in paths:\n    plt.plot(t, path)\n\nplt.show()\n\n\n\n\n\n\n\nEvolution of the distribution.\nThe evolution of the distribution with time can be visualized.\n\n\nShow the code\n# TODO: - this is where slowness lies, generating paths is a brezze\n\n# Wrap the paths 2d-array in a dataframe\npaths_tr = paths.transpose()\n# Take 20 samples at times t=0.05, 0.10, 0.15, ..., 1.0 along each path\nsamples = paths_tr[4::5]\n# Reshape in a 1d column-vector\nsamples_arr = samples.reshape(num_paths * 20)\nsamples_df = pd.DataFrame(samples_arr, columns=[\"values\"])\nsamples_df[\"time\"] = [\n    \"t=\" + str((int(i / num_paths) + 1) / 20) for i in range(num_paths * 20)\n]\n\n# TODO: end\n\nfig, ax = joypy.joyplot(\n    samples_df,\n    by=\"time\",\n    colormap=cm.autumn_r,\n    column=\"values\",\n    grid=\"y\",\n    kind=\"kde\",\n    range_style=\"own\",\n    tails=10e-3,\n)\nplt.vlines(\n    [cir_process.theta, cir_process.r_0],\n    -0.2,\n    1,\n    color=\"k\",\n    linestyles=\"dashed\",\n)\nplt.show()"
  },
  {
    "objectID": "posts/coding-a-neural-network-layer/index.html",
    "href": "posts/coding-a-neural-network-layer/index.html",
    "title": "Coding a neural network layer",
    "section": "",
    "text": "In 1943, McCulloch and Pitts introduced artificial intelligence to the world. Their idea was to develop an algorithmic approach to mimic the functionality of the human brain. Due to the structure of the brain consisting of a net of neurons, they introduced the so-called artificial neurons as building blocks.\nIn it’s most simple form, the neuron consists of :\n\ndendrites, which receive the information from other neurons\nsoma, which processes the information\nsynapse, transmits the output of this neuron\naxon, point of connection to other neurons\n\nConsequently, a mathematical definition of an artificial neuron is as follows.\nDefinition. An artificial neuron with weights \\(w_1,\\ldots,w_n \\in \\mathbf{R}\\), bias \\(b\\in\\mathbf{R}\\) and an activation function \\(\\rho:\\mathbf{R} \\to \\mathbf{R}\\) is defined as the scalar-valued function \\(f:\\mathbf{R}^n \\to \\mathbf{R}\\) given by:\n\\[\\begin{align*}\nf(x_1,\\ldots,x_n) = \\rho \\left(\\sum_{i=1}^{n}w_i x_i + b\\right) = \\rho(\\mathbf{w}^T \\mathbf{x}+b) \\tag{1}\n\\end{align*}\\]\nwhere \\(\\mathbf{w} = (w_1,\\ldots,w_n)\\) and \\(\\mathbf{x}=(x_1,\\ldots,x_n)\\).\nA single neuron by itself is useless, but when combined with hundreds or thousands(or many more) of other neurons, the interconnectivity can approximate any complex function and frequently outperforms any other machine learning methods.\n\n%load_ext itikz\n\n\n\nShow the code\n%%itikz --temp-dir --tex-packages=tikz --tikz-libraries=arrows --implicit-standalone\n\\begin{tikzpicture}\n\\foreach \\i in {1,2}\n{\n    \\node[circle, \n        minimum size = 15mm,\n        fill=red!30\n        ] (Input-\\i) at (0,-\\i * 2) {\\large $x_\\i$};\n}\n\\foreach \\i in {1,2,...,5}\n{\n    \\node[circle, \n        minimum size = 15mm,\n        fill=blue!50,\n        yshift=30 mm\n        ] (Hidden1-\\i) at (3.0,-\\i * 2) {\\large $h_\\i^{(1)}$};\n        \n}\n\\foreach \\i in {1,2,...,5}\n{\n    \\node[circle, \n        minimum size = 15mm,\n        fill=blue!50,\n        yshift=30 mm\n        ] (Hidden2-\\i) at (6.0,-\\i * 2) {\\large $h_\\i^{(2)}$};\n}\n\\foreach \\i in {1,2}\n{\n    \\node[circle, \n        minimum size = 15mm,\n        fill=green!30] (Output-\\i) at (9.0,-\\i * 2) {\\large $\\hat{y}_\\i$};\n}\n\n% Connect neurons In-Hidden1\n\\foreach \\i in {1,...,2}\n{\n    \\foreach \\j in {1,...,5}\n    {\n        \\draw[-&gt;, shorten &gt;=1pt] (Input-\\i) -- (Hidden1-\\j);   \n    }\n}\n\\foreach \\i in {1,...,5}\n{\n    \\foreach \\j in {1,...,5}\n    {\n        \\draw[-&gt;, shorten &gt;=1pt] (Hidden1-\\i) -- (Hidden2-\\j);   \n    }\n}\n\\foreach \\i in {1,...,5}\n{\n    \\foreach \\j in {1,2}\n    {\n        \\draw[-&gt;, shorten &gt;=1pt] (Hidden2-\\i) -- (Output-\\j);   \n    }\n}\n\\end{tikzpicture}\n\n\n\n\n\nDense layers, the most common layers, consist of interconnected neurons. In a dense layer, each neuron of a given layer is connected to every neuron of the next layer, which means its output value becomes an input for the next neurons. Each connection between neurons has a weight associated with it, which is a trainable factor of how much of this input to use. Once all of the \\(\\text{inputs} \\cdot \\text{ weights}\\) flow into our neuron, they are summed and a bias, another trainable parameter is added.\nSay, we have an input \\(x_1\\) and weight \\(w_1\\), then the output \\(y_1 = w_1 x_1\\) is a straight-line with slope \\(w_1\\).\n\n\nShow the code\n%%itikz --temp-dir --tex-packages=tikz,pgfplots --tikz-libraries=arrows --implicit-standalone\n\\begin{tikzpicture}[scale=1.5]\n\\begin{axis}\n\\addplot[color=blue]{x};\n\\addlegendentry{\\(f(x)=x\\)}\n\\addplot[color=red]{2*x};\n\\addlegendentry{\\(f(x)=2x\\)}\n\\end{axis}\n\\end{tikzpicture}\n\n\n\n\n\nThe bias offsets the overall function.\n\n\nShow the code\n%%itikz --temp-dir --tex-packages=tikz,pgfplots --tikz-libraries=arrows --implicit-standalone\n\\begin{tikzpicture}[scale=1.5]\n\\begin{axis}\n\\addplot[color=black]{x+1};\n\\addlegendentry{\\(f(x)=x+1\\)}\n\\addplot[color=gray]{x-1};\n\\addlegendentry{\\(f(x)=x-1\\)}\n\\end{axis}\n\\end{tikzpicture}\n\n\n\n\n\n\n\nLet us now look at some examples of activation functions.\nThe heaviside function is defined as:\n\\[\\begin{align*}\n\\rho(x) &=\n\\begin{cases}\n1, & x &gt; 0 \\\\\n0, & x \\leq 0\n\\end{cases}\n\\end{align*}\\]\nThe sigmoid function is defined as:\n\\[\\begin{align*}\n\\rho(x) &= \\frac{1}{1+e^{-x}}\n\\end{align*}\\]\n\n\nShow the code\n%%itikz --temp-dir --tex-packages=tikz,pgfplots --tikz-libraries=arrows --implicit-standalone\n\\begin{tikzpicture}[scale=1.5]\n\\begin{axis}\n\\addplot[color=black]{1/(1+exp(-x))};\n\\end{axis}\n\\end{tikzpicture}\n\n\n\n\n\nThe Rectifiable Linear Unit (ReLU) function is defined as:\n\\[\\begin{align*}\n\\rho(x) &= \\max(0,x)\n\\end{align*}\\]\n\n\nShow the code\n%%itikz --temp-dir --tex-packages=tikz,pgfplots --tikz-libraries=arrows --implicit-standalone\n\\begin{tikzpicture}[scale=1.5]\n\\begin{axis}\n\\addplot[color=black]{max(0,x)};\n\\end{axis}\n\\end{tikzpicture}"
  },
  {
    "objectID": "posts/coding-a-neural-network-layer/index.html#introduction",
    "href": "posts/coding-a-neural-network-layer/index.html#introduction",
    "title": "Coding a neural network layer",
    "section": "",
    "text": "In 1943, McCulloch and Pitts introduced artificial intelligence to the world. Their idea was to develop an algorithmic approach to mimic the functionality of the human brain. Due to the structure of the brain consisting of a net of neurons, they introduced the so-called artificial neurons as building blocks.\nIn it’s most simple form, the neuron consists of :\n\ndendrites, which receive the information from other neurons\nsoma, which processes the information\nsynapse, transmits the output of this neuron\naxon, point of connection to other neurons\n\nConsequently, a mathematical definition of an artificial neuron is as follows.\nDefinition. An artificial neuron with weights \\(w_1,\\ldots,w_n \\in \\mathbf{R}\\), bias \\(b\\in\\mathbf{R}\\) and an activation function \\(\\rho:\\mathbf{R} \\to \\mathbf{R}\\) is defined as the scalar-valued function \\(f:\\mathbf{R}^n \\to \\mathbf{R}\\) given by:\n\\[\\begin{align*}\nf(x_1,\\ldots,x_n) = \\rho \\left(\\sum_{i=1}^{n}w_i x_i + b\\right) = \\rho(\\mathbf{w}^T \\mathbf{x}+b) \\tag{1}\n\\end{align*}\\]\nwhere \\(\\mathbf{w} = (w_1,\\ldots,w_n)\\) and \\(\\mathbf{x}=(x_1,\\ldots,x_n)\\).\nA single neuron by itself is useless, but when combined with hundreds or thousands(or many more) of other neurons, the interconnectivity can approximate any complex function and frequently outperforms any other machine learning methods.\n\n%load_ext itikz\n\n\n\nShow the code\n%%itikz --temp-dir --tex-packages=tikz --tikz-libraries=arrows --implicit-standalone\n\\begin{tikzpicture}\n\\foreach \\i in {1,2}\n{\n    \\node[circle, \n        minimum size = 15mm,\n        fill=red!30\n        ] (Input-\\i) at (0,-\\i * 2) {\\large $x_\\i$};\n}\n\\foreach \\i in {1,2,...,5}\n{\n    \\node[circle, \n        minimum size = 15mm,\n        fill=blue!50,\n        yshift=30 mm\n        ] (Hidden1-\\i) at (3.0,-\\i * 2) {\\large $h_\\i^{(1)}$};\n        \n}\n\\foreach \\i in {1,2,...,5}\n{\n    \\node[circle, \n        minimum size = 15mm,\n        fill=blue!50,\n        yshift=30 mm\n        ] (Hidden2-\\i) at (6.0,-\\i * 2) {\\large $h_\\i^{(2)}$};\n}\n\\foreach \\i in {1,2}\n{\n    \\node[circle, \n        minimum size = 15mm,\n        fill=green!30] (Output-\\i) at (9.0,-\\i * 2) {\\large $\\hat{y}_\\i$};\n}\n\n% Connect neurons In-Hidden1\n\\foreach \\i in {1,...,2}\n{\n    \\foreach \\j in {1,...,5}\n    {\n        \\draw[-&gt;, shorten &gt;=1pt] (Input-\\i) -- (Hidden1-\\j);   \n    }\n}\n\\foreach \\i in {1,...,5}\n{\n    \\foreach \\j in {1,...,5}\n    {\n        \\draw[-&gt;, shorten &gt;=1pt] (Hidden1-\\i) -- (Hidden2-\\j);   \n    }\n}\n\\foreach \\i in {1,...,5}\n{\n    \\foreach \\j in {1,2}\n    {\n        \\draw[-&gt;, shorten &gt;=1pt] (Hidden2-\\i) -- (Output-\\j);   \n    }\n}\n\\end{tikzpicture}\n\n\n\n\n\nDense layers, the most common layers, consist of interconnected neurons. In a dense layer, each neuron of a given layer is connected to every neuron of the next layer, which means its output value becomes an input for the next neurons. Each connection between neurons has a weight associated with it, which is a trainable factor of how much of this input to use. Once all of the \\(\\text{inputs} \\cdot \\text{ weights}\\) flow into our neuron, they are summed and a bias, another trainable parameter is added.\nSay, we have an input \\(x_1\\) and weight \\(w_1\\), then the output \\(y_1 = w_1 x_1\\) is a straight-line with slope \\(w_1\\).\n\n\nShow the code\n%%itikz --temp-dir --tex-packages=tikz,pgfplots --tikz-libraries=arrows --implicit-standalone\n\\begin{tikzpicture}[scale=1.5]\n\\begin{axis}\n\\addplot[color=blue]{x};\n\\addlegendentry{\\(f(x)=x\\)}\n\\addplot[color=red]{2*x};\n\\addlegendentry{\\(f(x)=2x\\)}\n\\end{axis}\n\\end{tikzpicture}\n\n\n\n\n\nThe bias offsets the overall function.\n\n\nShow the code\n%%itikz --temp-dir --tex-packages=tikz,pgfplots --tikz-libraries=arrows --implicit-standalone\n\\begin{tikzpicture}[scale=1.5]\n\\begin{axis}\n\\addplot[color=black]{x+1};\n\\addlegendentry{\\(f(x)=x+1\\)}\n\\addplot[color=gray]{x-1};\n\\addlegendentry{\\(f(x)=x-1\\)}\n\\end{axis}\n\\end{tikzpicture}\n\n\n\n\n\n\n\nLet us now look at some examples of activation functions.\nThe heaviside function is defined as:\n\\[\\begin{align*}\n\\rho(x) &=\n\\begin{cases}\n1, & x &gt; 0 \\\\\n0, & x \\leq 0\n\\end{cases}\n\\end{align*}\\]\nThe sigmoid function is defined as:\n\\[\\begin{align*}\n\\rho(x) &= \\frac{1}{1+e^{-x}}\n\\end{align*}\\]\n\n\nShow the code\n%%itikz --temp-dir --tex-packages=tikz,pgfplots --tikz-libraries=arrows --implicit-standalone\n\\begin{tikzpicture}[scale=1.5]\n\\begin{axis}\n\\addplot[color=black]{1/(1+exp(-x))};\n\\end{axis}\n\\end{tikzpicture}\n\n\n\n\n\nThe Rectifiable Linear Unit (ReLU) function is defined as:\n\\[\\begin{align*}\n\\rho(x) &= \\max(0,x)\n\\end{align*}\\]\n\n\nShow the code\n%%itikz --temp-dir --tex-packages=tikz,pgfplots --tikz-libraries=arrows --implicit-standalone\n\\begin{tikzpicture}[scale=1.5]\n\\begin{axis}\n\\addplot[color=black]{max(0,x)};\n\\end{axis}\n\\end{tikzpicture}"
  },
  {
    "objectID": "posts/coding-a-neural-network-layer/index.html#coding-a-layer-with-3-neurons",
    "href": "posts/coding-a-neural-network-layer/index.html#coding-a-layer-with-3-neurons",
    "title": "Coding a neural network layer",
    "section": "Coding a layer with 3-neurons",
    "text": "Coding a layer with 3-neurons\nLet’s code a simple layer with \\(n=3\\) neurons.\n\ninputs = [1, 2, 3, 2.5]\nweights = [[0.2, 0.8, -0.5, 1.0], [0.5, -0.91, 0.26, -0.5], [-0.26, -0.27, 0.17, 0.87]]\n\nbiases = [2, 3, 0.5]\n\n# Output of the current layer\nlayer_outputs = []\n\n# For each neuron\nfor neuron_weights, neuron_bias in zip(weights, biases):\n    # zeroed output of the neuron\n    neuron_output = 0.0\n    # for each input and weight to the neuron\n    for input, weight in zip(inputs, neuron_weights):\n        # multiply this input with the associated weight\n        # and add to the neuron's output variable\n        neuron_output += input * weight\n    # Add bias\n    neuron_output += neuron_bias\n    # Put the neuron's result to the layer's output list\n    layer_outputs.append(neuron_output)\n\nprint(layer_outputs)\n\n[4.8, 1.21, 2.385]\n\n\nWe can achieve the same results as in our pure Python implementation of multiplying each component in our input vector \\(\\mathbf{x}\\) and weights vector \\(\\mathbf{w}\\) element-wise, by taking an inner product \\(\\mathbf{w} \\cdot \\mathbf{x}\\).\n\nimport numpy as np\n\ninputs = [1, 2, 3, 2.5]\nweights = [\n    [0.2, 0.8, -0.5, 1.0], \n    [0.5, -0.91, 0.26, -0.5], \n    [-0.26, -0.27, 0.17, 0.87]\n]\n\nbiases = [2, 3, 0.5]\n\n# Output of the current layer\nlayer_outputs = np.dot(weights, inputs) + biases\n\nprint(layer_outputs)\n\n[4.8   1.21  2.385]\n\n\nTo train, neural networks tend to receive data in batches. So far, the example input data has only one sample (or observation) of various features called a feature set instance:\nsample = [1, 2, 3, 2.5]\nOften, neural networks expect to take in many samples at a time. One reason is its faster to train in batches in parallel processing. Also, if you fit on one sample at a time, you’re highly likely to keep fitting to that individual sample, rather than slowly producing general tweaks to the weights and biases that fit the entire dataset. Fitting or training in batches gives you a higher chance of making more meaningful changes to weights and biases."
  },
  {
    "objectID": "posts/coding-a-neural-network-layer/index.html#a-layer-of-neurons-and-a-batch-of-data",
    "href": "posts/coding-a-neural-network-layer/index.html#a-layer-of-neurons-and-a-batch-of-data",
    "title": "Coding a neural network layer",
    "section": "A layer of neurons and a batch of data",
    "text": "A layer of neurons and a batch of data\nCurrently, the weights matrix looks as follows:\n\\[\\begin{align*}\nW = \\begin{bmatrix}\n0.2 & 0.8 & -0.5 & 1.0 \\\\\n0.5 & -0.91 & 0.26 & -0.5 \\\\\n-0.26 & -0.27 & 0.17 & 0.87\n\\end{bmatrix}\n\\end{align*}\\]\nAnd say, that we have a batch of inputs:\n\\[\\begin{align*}\nX = \\begin{bmatrix}\n1.0 & 2.0 & 3.0 & 3.5 \\\\\n2.0 & 5.0 & -1.0 & 2.0\\\\\n-1.5 & 2.7 & 3.3 & -0.8\n\\end{bmatrix}\n\\end{align*}\\]\nWe need to take the inner products \\((1.0, 2.0, 3.0, 3.5) \\cdot (0.2, 0.8, -0.5, 1.0)\\), \\((2.0, 5.0, -1.0, 2.0) \\cdot (0.2, 0.8, -0.5, 1.0)\\) and \\((-1.5, 2.7, 3.3, -0.8) \\cdot (0.2, 0.8, -0.5, 1.0)\\) for the first neuron.\nWe need to take the inner products \\((1.0, 2.0, 3.0, 3.5) \\cdot (0.5, -0.91, 0.26, -0.5)\\), \\((2.0, 5.0, -1.0, 2.0) \\cdot (0.5, -0.91, 0.26, -0.5)\\) and \\((-1.5, 2.7, 3.3, -0.8) \\cdot (0.5, -0.91, 0.26, -0.5)\\) for the second neuron.\nAnd so forth.\nConsider the matrix product \\(XW^T\\):\n\\[\\begin{align*}\nXW^T &= \\begin{bmatrix}\n1.0 & 2.0 & 3.0 & 2.5 \\\\\n2.0 & 5.0 & -1.0 & 2.0\\\\\n-1.5 & 2.7 & 3.3 & -0.8\n\\end{bmatrix}\n\\begin{bmatrix}\n0.2 & 0.5 & -0.26 \\\\\n0.8 & -0.91 & -0.27 \\\\\n-0.5 & 0.26 & 0.17 \\\\\n1.0 & -0.5 & 0.87\n\\end{bmatrix}\\\\\n&= \\begin{bmatrix}\n2.8 & -1.79 & 1.885 \\\\\n6.9 & -4.81 & -0.3 \\\\\n-0.59 & -1.949 & -0.474\n\\end{bmatrix}\n\\end{align*}\\]\n\nimport numpy as np\n\nX = [\n    [1.0, 2.0, 3.0, 2.5],\n    [2.0, 5.0, -1.0, 2.0],\n    [-1.5, 2.7, 3.3, -0.8]\n]\n\nW = [\n    [0.2, 0.8, -0.5, 1.0],\n    [0.5, -0.91, 0.26, -0.5],\n    [-0.26, -0.27, 0.17, 0.87]\n]\n\nnp.dot(X,np.array(W).T)\n\narray([[ 2.8  , -1.79 ,  1.885],\n       [ 6.9  , -4.81 , -0.3  ],\n       [-0.59 , -1.949, -0.474]])\n\n\nSo, we can process a batch of inputs as:\n\nlayer_outputs = np.dot(X,np.array(W).T) + biases\nprint(layer_outputs)\n\n[[ 4.8    1.21   2.385]\n [ 8.9   -1.81   0.2  ]\n [ 1.41   1.051  0.026]]\n\n\nThe second argument for np.dot() is going to be our transposed weights. Before, we were computing the neuron output using a single sample of data, but now we’ve taken a step forward where we model the layer behavior on a batch of data."
  },
  {
    "objectID": "posts/coding-a-neural-network-layer/index.html#adding-layers",
    "href": "posts/coding-a-neural-network-layer/index.html#adding-layers",
    "title": "Coding a neural network layer",
    "section": "Adding Layers",
    "text": "Adding Layers\nThe neural network we have built is becoming more respectable, but at the moment, we have only one layer. Neural networks become deep when they have \\(2\\) or more hidden layers. At the moment, we have just one layer, which is effectively an output layer. Why we want two or more hidden layers will become apparent later on. Currently, we have no hidden layers. A hidden layer isn’t an input or output layer; as the scientist, you see the data as they are handed to the input layer and the resulting data from the output layer. Layers between these endpoints have values that we don’t necessarily deal with, and hence the name “hidden”. Don’t let this name convince you that you can’t access these values, though. You will often use them to diagnose issues or improve your neural network. To explore this concept, let’s add another layer to this neural network, and for now, let’s assume that these two layers that we’re going to have will be hidden layers, and we just coded our output layer yet.\nBefore we add another layer, let’s think about what’s coming. In the case of the first layer, we can see that we have an input with \\(4\\) features.\n\n\nShow the code\n%%itikz --temp-dir --tex-packages=tikz --tikz-libraries=arrows --implicit-standalone\n\\begin{tikzpicture}\n\\foreach \\i in {1,2,...,4}\n{\n    \\node[circle, \n        minimum size = 15mm,\n        fill=red!30\n        ] (Input-\\i) at (0,-\\i * 2) {\\large $x_\\i$};\n}\n\\foreach \\i in {1,2,...,3}\n{\n    \\node[circle, \n        minimum size = 15mm,\n        fill=blue!50,\n        yshift=-10 mm\n        ] (Hidden1-\\i) at (3.0,-\\i * 2) {\\large $h_\\i^{(1)}$};\n        \n}\n\n% Connect neurons In-Hidden1\n\\foreach \\i in {1,...,4}\n{\n    \\foreach \\j in {1,...,3}\n    {\n        \\draw[-&gt;, shorten &gt;=1pt] (Input-\\i) -- (Hidden1-\\j);   \n    }\n}\n\\end{tikzpicture}\n\n\n\n\n\nSamples(feature set data) get fed through the input, which does not change it in any way, to our first hidden layer, which we can see has \\(3\\) sets of weights with \\(4\\) values each.\nEach of those \\(3\\) unique weight sets is associated with its distinct neuron. Thus, since we have \\(3\\) weight sets, we have \\(3\\) neurons in the first hidden layer. Each neuron has a unique set of weights, of which we have \\(4\\) (as there are \\(4\\) inputs to this layer), which is why our initial weights have a shape of \\((3,4)\\).\nNow we wish to add another layer. To do that, we must make sure that the expected input to that layer matches the previous layer’s output. We have set the number of neurons in a layer by setting how many weights and biases we have. The previous layer’s influence on weight sets for the current layer is that each weight set needs to have a separate weight per input. This means a distinct weight per neuron from the previous layer (or feature if we’re talking the input). The previous layer has \\(3\\) weight sets and \\(3\\) biases, so we know it has \\(3\\) neurons. This then means, for the next layer, we can have as many weight sets as we want (because this is how many neurons this new layer will have), but each of those weight sets must have \\(3\\) discrete weights.\nTo create this new layer, we are going to copy and paste our weights and biases to weights2 and biases2, and change their values to new made up sets. Here’s an example:\n\ninputs = [\n    [1, 2, 3, 2.5],\n    [2.0, 5.0, -1.0, 2],\n    [-1.5, 2.7, 3.3, -0.8]\n]\n\nweights = [\n    [0.2, 0.8, -0.5, 1],\n    [0.5, -0.91, 0.26, -0.5],\n    [-0.26, -0.27, 0.17, 0.87]\n]\n\nbiases = [2, 3, 0.5]\n\nweights2 = [\n    [0.1, -0.14, 0.5],\n    [-0.5, 0.12, -0.33],\n    [-0.44, 0.73, -0.13]\n]\n\nbiases2 = [-1, 2, -0.5]\n\nNext, we will now call the outputs layer1_outputs.\n\nlayer1_outputs = np.dot(inputs, np.array(weights).T) + biases\n\nAs previously stated, inputs to the layers are either inputs from the actual dataset you’re training with, or outputs from a previous layer. That’s why we defined \\(2\\) versions of weights and biases, but only one of inputs.\n\nlayer2_outputs = np.dot(layer1_outputs, np.array(weights2).T) + biases2\n\nAt this point, our neural network could be visually represented as:\n\n\nShow the code\n%%itikz --temp-dir --tex-packages=tikz --tikz-libraries=arrows --implicit-standalone\n\\begin{tikzpicture}\n\\foreach \\i in {1,2,...,4}\n{\n    \\node[circle, \n        minimum size = 15mm,\n        fill=red!30\n        ] (Input-\\i) at (0,-\\i * 2) {\\large $x_\\i$};\n}\n\\foreach \\i in {1,2,...,3}\n{\n    \\node[circle, \n        minimum size = 15mm,\n        fill=blue!50,\n        yshift=-10 mm\n        ] (Hidden1-\\i) at (3.0,-\\i * 2) {\\large $h_\\i^{(1)}$};\n        \n}\n\\foreach \\i in {1,2,...,3}\n{\n    \\node[circle, \n        minimum size = 15mm,\n        fill=blue!50,\n        yshift=-10 mm\n        ] (Hidden2-\\i) at (6.0,-\\i * 2) {\\large $h_\\i^{(2)}$};\n        \n}\n\n% Connect neurons In-Hidden1\n\\foreach \\i in {1,...,4}\n{\n    \\foreach \\j in {1,...,3}\n    {\n        \\draw[-&gt;, shorten &gt;=1pt] (Input-\\i) -- (Hidden1-\\j);   \n    }\n}\n% Connect neurons Hidden1-Hidden2\n\\foreach \\i in {1,...,3}\n{\n    \\foreach \\j in {1,...,3}\n    {\n        \\draw[-&gt;, shorten &gt;=1pt] (Hidden1-\\i) -- (Hidden2-\\j);   \n    }\n}\n\\end{tikzpicture}"
  },
  {
    "objectID": "posts/coding-a-neural-network-layer/index.html#training-data",
    "href": "posts/coding-a-neural-network-layer/index.html#training-data",
    "title": "Coding a neural network layer",
    "section": "Training Data",
    "text": "Training Data\nNext, rather than hand-typing in random data, we’ll use a function that can create non-linear data. What do we mean by non-linear? Linear data can be fit or represented by a straight line. Non-linear data cannot be represented well by a straight line.\nWe shall use the python package nnfs to create data. You can install it with\npip install nnfs\nYou typically don’t generate training data from a package like nnfs for your neural networks. Generating a dataset this way is purely for convenience at this stage. I shall also use this package to ensure repeatability.\n\nimport numpy as np\nimport nnfs\n\nnnfs.init()\n\nThe nnfs.init() does three things: it sets the random seed to \\(0\\) by default, creates a float32 dtype default and overrides the original dot product from numpy. All of these are meant to ensure repeatable results for following along.\n\nfrom nnfs.datasets import spiral_data\nimport matplotlib.pyplot as plt\n\nX, y = spiral_data(samples=100, classes=3)\n\nplt.scatter(X[:,0], X[:,1])\nplt.show()\n\n\n\n\nThe spiral_data function allows us to create a dataset with as many classes as we want. The function has parameters to choose the number of classes and the number of points/observations per class in the resulting non-linear dataset.\nIf you trace from the center, you can determine all \\(3\\) classes separately, but this is a very challenging problem for a machine learning classifier to solve. Adding color to the chart makes this more clear:\n\nplt.scatter(X[:,0],X[:,1],c=y,cmap='brg')\nplt.show()\n\n\n\n\nKeep in mind that the neural network will not be aware of the color differences as the data have no class encodings. This is only made as an instruction for you. In the data above, each dot is an observation, that is, it’s coordinates are the samples that form the dataset. The classification for the dot has to do with which spiral it is a part of, depicted by red, blue or green color."
  },
  {
    "objectID": "posts/coding-a-neural-network-layer/index.html#dense-layer-class",
    "href": "posts/coding-a-neural-network-layer/index.html#dense-layer-class",
    "title": "Coding a neural network layer",
    "section": "Dense Layer Class",
    "text": "Dense Layer Class\nNow that we no longer need to hand-type our data, we should create something similar for our various types of neural network layers. So far, we’ve only used what’s called a dense or fully-connected layer. These layers are commonly referred to as dense layers in papers, literature and code, but you will see them called fully-connected or fc for short in the code I write. Our dense layer class begins with two methods:\n\nclass DenseLayer:\n    def __init__(self, n_inputs, n_neurons):\n        # Initialize weights and biases\n        pass # using pass statement as a placeholder\n\n    # Forward pass\n    def forward(self, inputs):\n        # Calculate output values from inputs, weights and biases\n        pass # using pass statement as a placeholder\n\nWeights are often initialized randomly for a model, but not always. If you wish to load a pre-trained model, you will initialize the parameters to whatever that pretrained model finished with. It’s also possible that, even for a new model, you have some other initialization rules besides random. From now, we’ll stick with random initialization. Next, we have the forward method. When we pass data through a model from beginning to end, this is called a forward pass. Just like everything else, this is not the only way to do things. You can have the data loop back around and do other interesting things. We’ll keep it usual and perform a regular forward pass.\nTo continue the LayerDense class code, let’s add the random initialization of weights and biases:\n#Layer initialization\ndef __init__(self,n_inputs, n_neurons):\n    self.weights = 0.01 * np.random.randn(n_inputs,n_neurons)\n    self.biases = np.zeros((1,n_neurons))\nHere, we are setting the weights to be random and the biases to be \\(0\\). Note that, we are initializing weights to be a matrix of dimensions \\(n_{inputs} \\times n_{neurons}\\), rather than \\(n_{neurons} \\times n_{inputs}\\). We’re doing this ahead instead of transposing everytime we perform a forward pass, as explained in the previous chapter.\nWe initialize the biases to zero, because with many samples containing values of \\(0\\), it will ensure that a neuron fires initially. The most common initialization for biases is zero. This will vary depending on our use-case and is just one of the many things we can tweak when trying to improve results. One situation where we might want to try something else is with what’s called dead neurons.\nImagine our step function again:\n\\[\\begin{align*}\ny = \\begin{cases}\n1, & x &gt; 0\\\\\n0, & x \\leq 0\n\\end{cases}\n\\end{align*}\\]\nIt’s possible for \\(\\text{weights} \\cdot \\text{inputs} + \\text{biases}\\) not to meet the threshold of the step function, which means the neuron will output a zero. On its own, this is not a big issue, but it becomes a problem if this happens to this neuron for every one of the input samples (it’ll become clear why once we learn about backpropogation). So, then this neuron’s \\(0\\) output is the input to another neuron. Any weight multiplied by zero will be zero. With an increasing number of neurons outputting \\(0\\), more inputs to the next neurons will be zeros, rendering the network essentially non-trainable or dead.\nOn to our forward method now.\n\nclass DenseLayer:\n    def __init__(self, n_inputs, n_neurons):\n        self.weights = 0.01 * np.random.randn(n_inputs,n_neurons)\n        self.biases = np.zeros((1,n_neurons))\n\n    def forward(self,inputs):\n        self.output = np.dot(inputs,self.weights) + self.biases\n\nWe are now ready to make use of this new class instead of hardcoded calculations, so let’s generate some data using the discussed dataset creation method and use our new layer to perform a forward pass:\n\n# Create dataset\nX, y = spiral_data(samples=100, classes=3)\n\n# Create a dense layer with 2 input features and 3 output values\ndense1 = DenseLayer(2, 3)\n\n# Perform a forward pass of our training data through this layer\ndense1.forward(X)\n\n# Let's see the output of the first few samples\nprint(dense1.output[:5])\n\n[[ 0.00000000e+00  0.00000000e+00  0.00000000e+00]\n [-1.11171044e-04 -5.11007493e-05 -1.12099799e-04]\n [ 2.99257295e-06 -2.69126613e-04 -1.45165104e-04]\n [ 8.95101766e-05 -4.30442247e-04 -1.68079801e-04]\n [-3.49893759e-04 -3.07208364e-04 -4.33002861e-04]]"
  },
  {
    "objectID": "posts/coding-a-neural-network-layer/index.html#activation-functions-1",
    "href": "posts/coding-a-neural-network-layer/index.html#activation-functions-1",
    "title": "Coding a neural network layer",
    "section": "Activation Functions",
    "text": "Activation Functions\nWe use activation functions because if the activation function itself is non-linear, it allows for neural networks with two or more layers to map non-linear functions. We’ll see how this works. In general, your neural network will have \\(2\\) types of activation functions. The first will be the activation function used in hidden layers, and the second will be used in the output layer. Usually, the activation function used for hidden neurons will be all the same for all of them, but it doesn’t have to.\n\nWhy use activation functions?\nLet’s discuss why we use activation functions in the first place? In most cases, for a neural network to fit a non-linear function, we need it to contain two or more hidden layers and we need those hidden layers to use a non-linear activation function.\nWhile there are certainly problems in life that are linear in nature, for example, trying to figure out the cost of some number of shirts, and we know the cost of an individual shirt, then the equation to calculate the price of any number of those products is a linear equation; other problems in life are not so simple.\nMany interesting and hard problems are non-linear. The main attraction of neural networks has to do with their ability to solve non-linear problems. If we allow only linear activation functions in a neural network, the output will just be a linear transformation of the input, which is not enough to form a universal function approximator.\nFor simplicity, suppose a neural network has \\(2\\) hidden layers with \\(1\\) neuron each.\n\n\nShow the code\n%%itikz --temp-dir --tex-packages=tikz --tikz-libraries=arrows --implicit-standalone\n\\begin{tikzpicture}[scale=1.5]\n    \\node[circle, \n        minimum size = 15mm,\n        fill=red!30\n        ] (Input) at (0,0) {\\large $x_1$};\n\n    \\node[circle, \n        minimum size = 15mm,\n        fill=blue!50\n        ] (Hidden1) at (3.0,0) {\\large $h_1^{(1)}$};\n        \n\n    \\node[circle, \n        minimum size = 15mm,\n        fill=blue!50\n        ] (Hidden2) at (6.0,0) {\\large $h_1^{(2)}$};\n\n    \\node[circle, \n        minimum size = 15mm,\n        fill=red!30\n        ] (Output) at (9.0,0) {\\large $\\hat{y}_1$};        \n        \n\n    \\draw[-&gt;, shorten &gt;=1pt] (Input) -- (Hidden1) node [midway,above] {\\large $w_1$};\n    \\draw[-&gt;, shorten &gt;=1pt] (Hidden1) -- (Hidden2) node [midway,above]  {\\large $w_2$};\n    \\draw[-&gt;, shorten &gt;=1pt] (Hidden2) -- (Output);\n    \\draw[-&gt;, shorten &gt;=1pt] (3.0, -2.0) node [below] {\\large $b_1$} -- (Hidden1);\n    \\draw[-&gt;, shorten &gt;=1pt] (6.0, -2.0) node [below] {\\large $b_2$} -- (Hidden2);\n\\end{tikzpicture}\n\n\n\n\n\n\\[\\begin{align*}\n\\hat{y}_1 &= h_1^{(2)} \\\\\n&= w_2 h_1^{(1)} + b_2 \\\\\n&= w_2 (w_1 x_1 + b_1) + b_2 \\\\\n&= w_2 w_1 x_1 + (w_2 b_1 + b_2)\n\\end{align*}\\]\nSo, \\(\\hat{y}_1\\) is a linear function of the inputs, no matter, what values we choose for weights and biases.\nThe composition of linear functions is linear. No matter what we do, however many layers we have, or neurons we have in each layer, this network can only model linear functions."
  },
  {
    "objectID": "posts/coding-a-neural-network-layer/index.html#relu-activation-in-a-pair-of-neurons",
    "href": "posts/coding-a-neural-network-layer/index.html#relu-activation-in-a-pair-of-neurons",
    "title": "Coding a neural network layer",
    "section": "ReLU Activation in a pair of Neurons",
    "text": "ReLU Activation in a pair of Neurons\nIt is less obvious how, with a barely non-linear activation function, like the rectified linear activation function, we can suddenly model non-linear relationships and functions. Let’s start with a single neuron. We’ll begin with both a weight of zero and a bias of zero:\n\n\nShow the code\n%%itikz --temp-dir --tex-packages=tikz --tikz-libraries=arrows --implicit-standalone\n\\begin{tikzpicture}[scale=1.5]\n    \\node[circle, \n        minimum size = 15mm,\n        draw=blue\n        ] (Input) at (0,0) {};\n    \n    \\node[] (w) at (-3,0) {};\n    \\node[] (b) at (0,-2) {};\n\n    \\draw[-&gt;, shorten &gt;=1pt] (w) -- (Input) node [midway,above] {\\large $0.00$};\n    \\draw[-&gt;, shorten &gt;=1pt] (b) node [below] {\\large $0.00$} -- (Input);\n\\end{tikzpicture}\n\n\n\n\n\nIn this case, no matter what input we pass, the output of this neuron will always be \\(0\\), because the weight is \\(0\\) and the bias is \\(0\\).\n\n\nShow the code\n%%itikz --temp-dir --tex-packages=tikz,pgfplots --tikz-libraries=arrows --implicit-standalone\n\\begin{tikzpicture}[scale=1.5]\n\\begin{axis}[grid]\n\\addplot[color=blue,thick]{0};\n\\end{axis}\n\\end{tikzpicture}\n\n\n\n\n\nLet’s set the weight to be \\(1.00\\).\n\n\nShow the code\n%%itikz --temp-dir --tex-packages=tikz --tikz-libraries=arrows --implicit-standalone\n\\begin{tikzpicture}[scale=1.5]\n    \\node[circle, \n        minimum size = 15mm,\n        draw=blue\n        ] (Input) at (0,0) {};\n    \n    \\node[] (w) at (-3,0) {};\n    \\node[] (b) at (0,-2) {};\n\n    \\draw[-&gt;, shorten &gt;=1pt] (w) -- (Input) node [midway,above] {\\large $1.00$};\n    \\draw[-&gt;, shorten &gt;=1pt] (b) node [below] {\\large $0.00$} -- (Input);\n\\end{tikzpicture}\n\n\n\n\n\nNow, it just looks like the basic rectified linear function. No surprises yet!\n\n\nShow the code\n%%itikz --temp-dir --tex-packages=tikz,pgfplots --tikz-libraries=arrows --implicit-standalone\n\\begin{tikzpicture}[scale=1.5]\n\\begin{axis}[grid,ymin=-2.0,ymax=2.0,xmin=-2.0,xmax=2.0]\n\\addplot[color=blue,thick]{max(x,0)};\n\\end{axis}\n\\end{tikzpicture}\n\n\n\n\n\nNow, let’s set the bias to \\(0.50\\):\n\n\nShow the code\n%%itikz --temp-dir --tex-packages=tikz --tikz-libraries=arrows --implicit-standalone\n\\begin{tikzpicture}[scale=1.5]\n    \\node[circle, \n        minimum size = 15mm,\n        draw=blue\n        ] (Input) at (0,0) {};\n    \n    \\node[] (w) at (-3,0) {};\n    \\node[] (b) at (0,-2) {};\n\n    \\draw[-&gt;, shorten &gt;=1pt] (w) -- (Input) node [midway,above] {\\large $1.00$};\n    \\draw[-&gt;, shorten &gt;=1pt] (b) node [below] {\\large $0.50$} -- (Input);\n\\end{tikzpicture}\n\n\n\n\n\nWe can see that in this case, with a single neuron, the bias offsets the overall function’s activation point horizontally.\n\n\nShow the code\n%%itikz --temp-dir --tex-packages=tikz,pgfplots --tikz-libraries=arrows --implicit-standalone\n\\begin{tikzpicture}[scale=1.5]\n\\begin{axis}[grid,ymin=-2.0,ymax=2.0,xmin=-2.0,xmax=2.0]\n\\addplot[color=blue,thick,samples=100]{max(x+0.50,0)};\n\\end{axis}\n\\end{tikzpicture}\n\n\n\n\n\nBy increasing bias, we’re making this neuron activate earlier. What happens when we negate the weight to \\(-1.0\\)?\n\n\nShow the code\n%%itikz --temp-dir --tex-packages=tikz --tikz-libraries=arrows --implicit-standalone\n\\begin{tikzpicture}[scale=1.5]\n    \\node[circle, \n        minimum size = 15mm,\n        draw=blue\n        ] (Input) at (0,0) {};\n    \n    \\node[] (w) at (-3,0) {};\n    \\node[] (b) at (0,-2) {};\n\n    \\draw[-&gt;, shorten &gt;=1pt] (w) -- (Input) node [midway,above] {\\large $-1.00$};\n    \\draw[-&gt;, shorten &gt;=1pt] (b) node [below] {\\large $0.50$} -- (Input);\n\\end{tikzpicture}\n\n\n\n\n\nWith a negative weight and this single neuron, the function has become a question of when this neuron deactivates.\n\n\nShow the code\n%%itikz --temp-dir --tex-packages=tikz,pgfplots --tikz-libraries=arrows --implicit-standalone\n\\begin{tikzpicture}[scale=1.5]\n\\begin{axis}[grid,ymin=-2.0,ymax=2.0,xmin=-2.0,xmax=2.0]\n\\addplot[color=blue,thick,samples=100]{max(-x+0.50,0)};\n\\end{axis}\n\\end{tikzpicture}\n\n\n\n\n\nWhat happens if modify the weight to \\(-2.00\\)?\n\n\nShow the code\n%%itikz --temp-dir --tex-packages=tikz --tikz-libraries=arrows --implicit-standalone\n\\begin{tikzpicture}[scale=1.5]\n    \\node[circle, \n        minimum size = 15mm,\n        draw=blue\n        ] (Input) at (0,0) {};\n    \n    \\node[] (w) at (-3,0) {};\n    \\node[] (b) at (0,-2) {};\n\n    \\draw[-&gt;, shorten &gt;=1pt] (w) -- (Input) node [midway,above] {\\large $-2.00$};\n    \\draw[-&gt;, shorten &gt;=1pt] (b) node [below] {\\large $0.50$} -- (Input);\n\\end{tikzpicture}\n\n\n\n\n\nThe neuron now deactivates at \\(0.25\\).\n\n\nShow the code\n%%itikz --temp-dir --tex-packages=tikz,pgfplots --tikz-libraries=arrows --implicit-standalone\n\\begin{tikzpicture}[scale=1.5]\n\\begin{axis}[grid,ymin=-2.0,ymax=2.0,xmin=-2.0,xmax=2.0]\n\\addplot[color=blue,thick,samples=100]{max(-2*x+0.50,0)};\n\\end{axis}\n\\end{tikzpicture}\n\n\n\n\n\nUpto this point, we’ve seen how we can use the bias to offset the function horizontally, and the weight to influence the slope of the activation. Moreover, we’re also able to control whether the function is one for determining where the neuron activates or deactivates. What happens when we have, rather than just one neuron, a pair of neurons? For example, let’s pretend that we have two hidden layers of \\(1\\) neuron each. Thinking back to the \\(y=x\\) activation function, we unsurprisingly discovered that a linear activation function produced linear results no matter what chain of neurons we made. Let’s see what happens with the rectified linear function for the activation.\nWe’ll begin with the last values for the first neuron and a weight of \\(1.00\\) and a bias of \\(0.00\\) for the second neuron.\n\n\nShow the code\n%%itikz --temp-dir --tex-packages=tikz --tikz-libraries=arrows --implicit-standalone\n\\begin{tikzpicture}[scale=1.5]\n    \\node[circle, \n        minimum size = 15mm,\n        draw=blue\n        ] (Input) at (0,0) {};\n\n    \\node[circle, \n        minimum size = 15mm,\n        draw=blue\n        ] (Hidden1) at (3,0) {};\n    \n    \\node[] (w1) at (-3,0) {};\n    \\node[] (b1) at (0,-2) {};\n    \\node[] (b2) at (3,-2) {};\n\n    \\draw[-&gt;, shorten &gt;=1pt] (w1) -- (Input) node [midway,above] {\\large $-1.00$};\n    \\draw[-&gt;, shorten &gt;=1pt] (b1) node [below] {\\large $0.50$} -- (Input);\n    \\draw[-&gt;, shorten &gt;=1pt] (Input) -- (Hidden1) node [midway,above] {\\large $1.00$};\n    \\draw[-&gt;, shorten &gt;=1pt] (b2) node [below] {\\large $0.00$} -- (Hidden1);\n\\end{tikzpicture}\n\n\n\n\n\nAs we can see so far, there’s no change. This is because the second neuron’s bias is doing no offsetting, and the second neuron’s weight is just multiplying the output by \\(1\\), so there’s no change. Let’s try to adjust the second neuron’s bias now:\n\n\nShow the code\n%%itikz --temp-dir --tex-packages=tikz,pgfplots --tikz-libraries=arrows --implicit-standalone\n\\begin{tikzpicture}[scale=1.5]\n\\begin{axis}[grid,ymin=-1,ymax=6,ytick={-1,0,...,6}]\n\\addplot[color=blue,thick,samples=100]{max(max(-x+0.50,0),0)};\n\\end{axis}\n\\end{tikzpicture}\n\n\n\n\n\nLet’s try to adjust the second neuron’s bias now:\n\n\nShow the code\n%%itikz --temp-dir --tex-packages=tikz --tikz-libraries=arrows --implicit-standalone\n\\begin{tikzpicture}[scale=1.5]\n    \\node[circle, \n        minimum size = 15mm,\n        draw=blue\n        ] (Input) at (0,0) {};\n\n    \\node[circle, \n        minimum size = 15mm,\n        draw=blue\n        ] (Hidden1) at (3,0) {};\n    \n    \\node[] (w1) at (-3,0) {};\n    \\node[] (b1) at (0,-2) {};\n    \\node[] (b2) at (3,-2) {};\n\n    \\draw[-&gt;, shorten &gt;=1pt] (w1) -- (Input) node [midway,above] {\\large $-1.00$};\n    \\draw[-&gt;, shorten &gt;=1pt] (b1) node [below] {\\large $0.50$} -- (Input);\n    \\draw[-&gt;, shorten &gt;=1pt] (Input) -- (Hidden1) node [midway,above] {\\large $1.00$};\n    \\draw[-&gt;, shorten &gt;=1pt] (b2) node [below] {\\large $1.00$} -- (Hidden1);\n\\end{tikzpicture}\n\n\n\n\n\nNow, we see some fairly interesting behavior. The bias of the second neuron indeed shifted the overall function but, rather than shifting it horizontally, it shifted vertically.\n\n\nShow the code\n%%itikz --temp-dir --tex-packages=tikz,pgfplots --tikz-libraries=arrows --implicit-standalone\n\\begin{tikzpicture}[scale=1.5]\n\\begin{axis}[grid,ymin=-1,ymax=6,ytick={-1,0,...,6}]\n\\addplot[color=blue,thick,samples=100]{max(max(-x+0.50,0)+1.00,0)};\n\\end{axis}\n\\end{tikzpicture}\n\n\n\n\n\nWhat then might happen, if we make the \\(2\\)nd neuron’s weight \\(-2\\) rather than \\(1\\)?\n\n\nShow the code\n%%itikz --temp-dir --tex-packages=tikz --tikz-libraries=arrows --implicit-standalone\n\\begin{tikzpicture}[scale=1.5]\n    \\node[circle, \n        minimum size = 15mm,\n        draw=blue\n        ] (Input) at (0,0) {};\n\n    \\node[circle, \n        minimum size = 15mm,\n        draw=blue\n        ] (Hidden1) at (3,0) {};\n    \n    \\node[] (w1) at (-3,0) {};\n    \\node[] (b1) at (0,-2) {};\n    \\node[] (b2) at (3,-2) {};\n\n    \\draw[-&gt;, shorten &gt;=1pt] (w1) -- (Input) node [midway,above] {\\large $-1.00$};\n    \\draw[-&gt;, shorten &gt;=1pt] (b1) node [below] {\\large $0.50$} -- (Input);\n    \\draw[-&gt;, shorten &gt;=1pt] (Input) -- (Hidden1) node [midway,above] {\\large $-2.00$};\n    \\draw[-&gt;, shorten &gt;=1pt] (b2) node [below] {\\large $1.00$} -- (Hidden1);\n\\end{tikzpicture}\n\n\n\n\n\nSomething exciting has occurred! What we have here is a neuron that has both an activation and a deactivation point. Now, the output after these two neurons will be variable, so long as it is inside of some specific range. So, basically if both neurons are activated then we actually sort of see this influence on the value. Otherwise, if both neurons aren’t activated, then the output is just a static value.\n\n\nShow the code\n%%itikz --temp-dir --tex-packages=tikz,pgfplots --tikz-libraries=arrows --implicit-standalone\n\\begin{tikzpicture}[scale=1.5]\n\\begin{axis}[grid,ymin=-1,ymax=2,ytick={-1,0,...,2},xmin=-2,xmax=2]\n\\addplot[color=blue,thick,samples=500]{max(-2.0*max(-x+0.50,0)+1.00,0)};\n\\end{axis}\n\\end{tikzpicture}\n\n\n\n\n\nSo, when we are below the activation of the first neuron, the output will be the bias of the second neuron \\(1.00\\).\n\n\nShow the code\n%%itikz --temp-dir --tex-packages=tikz --tikz-libraries=arrows --implicit-standalone\n\\begin{tikzpicture}[scale=1.5]\n    \\node[circle, \n        minimum size = 15mm,\n        draw=blue\n        ] (Input) at (0,0) {};\n\n    \\node[circle, \n        minimum size = 15mm,\n        draw=blue,\n        fill=green\n        ] (Hidden1) at (3,0) {};\n    \n    \\node[] (w1) at (-3,0) {};\n    \\node[] (b1) at (0,-2) {};\n    \\node[] (b2) at (3,-2) {};\n\n    \\draw[-&gt;, shorten &gt;=1pt] (w1) node [left] {\\large $0.50$} -- (Input) node [midway,above] {\\large $-1.00$};\n    \\draw[-&gt;, shorten &gt;=1pt] (b1) node [below] {\\large $0.50$} -- (Input);\n    \\draw[-&gt;, shorten &gt;=1pt] (Input) -- (Hidden1) node [midway,above] {\\large $-2.00$};\n    \\draw[-&gt;, shorten &gt;=1pt] (b2) node [below] {\\large $1.00$} -- (Hidden1);\n    \\draw[-&gt;, shorten &gt;=1pt] (Hidden1) -- (6,0) node [right] {$1.00$};\n\\end{tikzpicture}\n\n\n\n\n\nThe second neuron is activated if it’s input is smaller than \\(0.50\\).\nConsider what happens when the input to the first neuron is \\(0.00, -0.10, \\ldots\\). The output of the first neuron is \\(0.50, 0.60, \\ldots\\) which implies that the second neuron is deactivated, so the output of the second neuron is simply zero.\n\n\nShow the code\n%%itikz --temp-dir --tex-packages=tikz --tikz-libraries=arrows --implicit-standalone\n\\begin{tikzpicture}[scale=1.5]\n    \\node[circle, \n        minimum size = 15mm,\n        draw=blue,\n        fill=green\n        ] (Input) at (0,0) {};\n\n    \\node[circle, \n        minimum size = 15mm,\n        draw=blue\n        ] (Hidden1) at (3,0) {};\n    \n    \\node[] (w1) at (-3,0) {};\n    \\node[] (b1) at (0,-2) {};\n    \\node[] (b2) at (3,-2) {};\n\n    \\draw[-&gt;, shorten &gt;=1pt] (w1) node [left] {\\large $0.50$} -- (Input) node [midway,above] {\\large $-1.00$};\n    \\draw[-&gt;, shorten &gt;=1pt] (b1) node [below] {\\large $0.50$} -- (Input);\n    \\draw[-&gt;, shorten &gt;=1pt] (Input) -- (Hidden1) node [midway,above] {\\large $-2.00$};\n    \\draw[-&gt;, shorten &gt;=1pt] (b2) node [below] {\\large $1.00$} -- (Hidden1);\n    \\draw[-&gt;, shorten &gt;=1pt] (Hidden1) -- (6,0) node [right] {$0.00$};\n\\end{tikzpicture}"
  },
  {
    "objectID": "posts/coding-a-neural-network-layer/index.html#relu-activation-in-hidden-layers",
    "href": "posts/coding-a-neural-network-layer/index.html#relu-activation-in-hidden-layers",
    "title": "Coding a neural network layer",
    "section": "ReLU Activation in hidden layers",
    "text": "ReLU Activation in hidden layers\nLet’s now take this concept and use it to fit to a sine wave-like function using two hidden layers of \\(8\\) neurons each and we can hand-tune the values to fit the curve. We’ll do this by working with \\(1\\) pair of neurons at a time, which means \\(1\\) neuron from each layer individually. For simplicity, we are also going to assume that the layers are not densely connected, and each neuron from the first hidden layer connects to only one neuron from the second hidden layer. That’s usually not the case with the real models, but we want this simplification for the purpose of this demo. Additionally, this example model takes a single value as an input, the input to the sine function, and outputs a single value like the sine function. The output layer uses the linear activation function and the hidden layers will use the rectified linear activation function.\nTo start, we’ll set all weights to \\(0\\) and work with the first pair of neurons:\n\n\nShow the code\n%%itikz --temp-dir --tex-packages=tikz --tikz-libraries=arrows --implicit-standalone\n\\begin{tikzpicture}\n\n\\node[circle, \n    minimum size = 15mm,\n    fill=red!30\n    ] (Input) at (0,0) {\\large $x_1$};\n\n\\foreach \\i in {1,2,...,8}\n{\n    \\node[circle, \n        minimum size = 15mm,\n        fill=blue!50,\n        yshift=90 mm\n        ] (Hidden1-\\i) at (3.0,-\\i * 2) {\\large $h_\\i^{(1)}$};\n        \n}\n\\foreach \\i in {1,2,...,8}\n{\n    \\node[circle, \n        minimum size = 15mm,\n        fill=blue!50,\n        yshift=90 mm\n        ] (Hidden2-\\i) at (6.0,-\\i * 2) {\\large $h_\\i^{(2)}$};\n        \n}\n\n\\node[circle, \n    minimum size = 15mm,\n    fill=red!30\n    ] (Output) at (9,0) {\\large $\\hat{y}_1$};\n\n% Connect neurons In-Hidden1\n\\foreach \\j in {2,...,8}\n{\n    \\draw[-&gt;, shorten &gt;=1pt] (Input) -- (Hidden1-\\j);   \n}\n% Connect neurons Hidden1-Hidden2\n\\foreach \\i in {2,...,8}\n{\n    \n        \\draw[-&gt;, shorten &gt;=1pt] (Hidden1-\\i) -- (Hidden2-\\i);   \n    \n}\n\n\\foreach \\i in {2,...,8}\n{\n    \n        \\draw[-&gt;, shorten &gt;=1pt] (Hidden2-\\i) -- (Output);   \n}\n\\draw[-&gt;, shorten &gt;=1pt] (Input) -- node [midway] {$0.00$} (Hidden1-1);   \n\\draw[-&gt;, shorten &gt;=1pt] (Hidden1-1) -- node [midway] {$0.00$} (Hidden2-1); \n\\draw[-&gt;, shorten &gt;=1pt] (Hidden2-1) -- node [midway] {$0.00$} (Output); \n\\draw[-&gt;, shorten &gt;=1pt] (6,6) node [below] {$0.00$} --  (Hidden2-1); \n\\draw[-&gt;, shorten &gt;=1pt] (3,6) node [below] {$0.00$} --  (Hidden1-1); \n\\end{tikzpicture}\n\n\n\n\n\nNext, we can set the weight for the hidden layer neurons and the output neuron to \\(1.00\\), and we can see how this impacts the output:\n\n\nShow the code\n%%itikz --temp-dir --tex-packages=tikz --tikz-libraries=arrows --implicit-standalone\n\\begin{tikzpicture}\n\n\\node[circle, \n    minimum size = 15mm,\n    fill=red!30\n    ] (Input) at (0,0) {\\large $x_1$};\n\n\\foreach \\i in {1,2,...,8}\n{\n    \\node[circle, \n        minimum size = 15mm,\n        fill=blue!50,\n        yshift=90 mm\n        ] (Hidden1-\\i) at (3.0,-\\i * 2) {\\large $h_\\i^{(1)}$};\n        \n}\n\\foreach \\i in {1,2,...,8}\n{\n    \\node[circle, \n        minimum size = 15mm,\n        fill=blue!50,\n        yshift=90 mm\n        ] (Hidden2-\\i) at (6.0,-\\i * 2) {\\large $h_\\i^{(2)}$};\n        \n}\n\n\\node[circle, \n    minimum size = 15mm,\n    fill=red!30\n    ] (Output) at (9,0) {\\large $\\hat{y}_1$};\n\n% Connect neurons In-Hidden1\n\\foreach \\j in {2,...,8}\n{\n    \\draw[-&gt;, shorten &gt;=1pt] (Input) -- (Hidden1-\\j);   \n}\n% Connect neurons Hidden1-Hidden2\n\\foreach \\i in {2,...,8}\n{\n    \n        \\draw[-&gt;, shorten &gt;=1pt] (Hidden1-\\i) -- (Hidden2-\\i);   \n    \n}\n\n\\foreach \\i in {2,...,8}\n{\n    \n        \\draw[-&gt;, shorten &gt;=1pt] (Hidden2-\\i) -- (Output);   \n}\n\\draw[-&gt;, shorten &gt;=1pt] (Input) -- node [midway] {$1.00$} (Hidden1-1);   \n\\draw[-&gt;, shorten &gt;=1pt] (Hidden1-1) -- node [midway,above] {$1.00$} (Hidden2-1); \n\\draw[-&gt;, shorten &gt;=1pt] (Hidden2-1) -- node [midway] {$1.00$} (Output); \n\\draw[-&gt;, shorten &gt;=1pt] (6,6) node [below] {$0.00$} --  (Hidden2-1); \n\\draw[-&gt;, shorten &gt;=1pt] (3,6) node [below] {$0.00$} --  (Hidden1-1); \n\\end{tikzpicture}\n\n\n\n\n\nThe output is:\n\n\nShow the code\n%%itikz --temp-dir --tex-packages=tikz,pgfplots --tikz-libraries=arrows --implicit-standalone\n\\begin{tikzpicture}[scale=1.5]\n\\begin{axis}[grid,ymin=-2,ymax=2,ytick={-2,-1,...,2},xmin=0,xmax=1]\n\\addplot[color=blue,thick,samples=1000]{max(max(x,0),0)};\n\\addplot[color=green,samples=1000,domain=0:1]{sin(deg(2*3.14*x))};\n\\end{axis}\n\\end{tikzpicture}\n\n\n\n\n\nWe can increase the slope of the output by adjusting the weight of the first neuron of the first layer to \\(6.00\\).\n\n\nShow the code\n%%itikz --temp-dir --tex-packages=tikz --tikz-libraries=arrows --implicit-standalone\n\\begin{tikzpicture}\n\n\\node[circle, \n    minimum size = 15mm,\n    fill=red!30\n    ] (Input) at (0,0) {\\large $x_1$};\n\n\\foreach \\i in {1,2,...,8}\n{\n    \\node[circle, \n        minimum size = 15mm,\n        fill=blue!50,\n        yshift=90 mm\n        ] (Hidden1-\\i) at (3.0,-\\i * 2) {\\large $h_\\i^{(1)}$};\n        \n}\n\\foreach \\i in {1,2,...,8}\n{\n    \\node[circle, \n        minimum size = 15mm,\n        fill=blue!50,\n        yshift=90 mm\n        ] (Hidden2-\\i) at (6.0,-\\i * 2) {\\large $h_\\i^{(2)}$};\n        \n}\n\n\\node[circle, \n    minimum size = 15mm,\n    fill=red!30\n    ] (Output) at (9,0) {\\large $\\hat{y}_1$};\n\n% Connect neurons In-Hidden1\n\\foreach \\j in {2,...,8}\n{\n    \\draw[-&gt;, shorten &gt;=1pt] (Input) -- (Hidden1-\\j);   \n}\n% Connect neurons Hidden1-Hidden2\n\\foreach \\i in {2,...,8}\n{\n    \n        \\draw[-&gt;, shorten &gt;=1pt] (Hidden1-\\i) -- (Hidden2-\\i);   \n    \n}\n\n\\foreach \\i in {2,...,8}\n{\n    \n        \\draw[-&gt;, shorten &gt;=1pt] (Hidden2-\\i) -- (Output);   \n}\n\\draw[-&gt;, shorten &gt;=1pt] (Input) -- node [midway] {$6.00$} (Hidden1-1);   \n\\draw[-&gt;, shorten &gt;=1pt] (Hidden1-1) -- node [midway,above] {$1.00$} (Hidden2-1); \n\\draw[-&gt;, shorten &gt;=1pt] (Hidden2-1) -- node [midway] {$1.00$} (Output); \n\\draw[-&gt;, shorten &gt;=1pt] (6,6) node [below] {$0.00$} --  (Hidden2-1); \n\\draw[-&gt;, shorten &gt;=1pt] (3,6) node [below] {$0.00$} --  (Hidden1-1); \n\\end{tikzpicture}\n\n\n\n\n\nWe can now see, for example, that the initial slope of this function is what we’d like, but we have a problem.\n\n\nShow the code\n%%itikz --temp-dir --tex-packages=tikz,pgfplots --tikz-libraries=arrows --implicit-standalone\n\\begin{tikzpicture}[scale=1.5]\n\\begin{axis}[grid,ymin=-2,ymax=2,ytick={-2,-1,...,2},xmin=0,xmax=1]\n\\addplot[color=blue,thick,samples=1000]{max(max(6*x,0),0)};\n\\addplot[color=green,samples=1000,domain=0:1]{sin(deg(2*3.14*x))};\n\\end{axis}\n\\end{tikzpicture}\n\n\n\n\n\nCurrently, this function never ends because this neuron pair never deactivates. We can visually see where we’d like the deactivation to occur. It’s where the red fitment line diverges from our green sine wave. So now, while we have the correct slope, we need to set this spot as our deactivation point. To do that, we start by increasing the bias for the second neuron of the hidden layer to \\(0.70\\).\n\n\nShow the code\n%%itikz --temp-dir --tex-packages=tikz --tikz-libraries=arrows --implicit-standalone\n\\begin{tikzpicture}\n\n\\node[circle, \n    minimum size = 15mm,\n    fill=red!30\n    ] (Input) at (0,0) {\\large $x_1$};\n\n\\foreach \\i in {1,2,...,8}\n{\n    \\node[circle, \n        minimum size = 15mm,\n        fill=blue!50,\n        yshift=90 mm\n        ] (Hidden1-\\i) at (3.0,-\\i * 2) {\\large $h_\\i^{(1)}$};\n        \n}\n\\foreach \\i in {1,2,...,8}\n{\n    \\node[circle, \n        minimum size = 15mm,\n        fill=blue!50,\n        yshift=90 mm\n        ] (Hidden2-\\i) at (6.0,-\\i * 2) {\\large $h_\\i^{(2)}$};\n        \n}\n\n\\node[circle, \n    minimum size = 15mm,\n    fill=red!30\n    ] (Output) at (9,0) {\\large $\\hat{y}_1$};\n\n% Connect neurons In-Hidden1\n\\foreach \\j in {2,...,8}\n{\n    \\draw[-&gt;, shorten &gt;=1pt] (Input) -- (Hidden1-\\j);   \n}\n% Connect neurons Hidden1-Hidden2\n\\foreach \\i in {2,...,8}\n{\n    \n        \\draw[-&gt;, shorten &gt;=1pt] (Hidden1-\\i) -- (Hidden2-\\i);   \n    \n}\n\n\\foreach \\i in {2,...,8}\n{\n    \n        \\draw[-&gt;, shorten &gt;=1pt] (Hidden2-\\i) -- (Output);   \n}\n\\draw[-&gt;, shorten &gt;=1pt] (Input) -- node [midway] {$6.00$} (Hidden1-1);   \n\\draw[-&gt;, shorten &gt;=1pt] (Hidden1-1) -- node [midway,above] {$1.00$} (Hidden2-1); \n\\draw[-&gt;, shorten &gt;=1pt] (Hidden2-1) -- node [midway] {$1.00$} (Output); \n\\draw[-&gt;, shorten &gt;=1pt] (6,6) node [below] {$0.70$} --  (Hidden2-1); \n\\draw[-&gt;, shorten &gt;=1pt] (3,6) node [below] {$0.00$} --  (Hidden1-1); \n\\end{tikzpicture}\n\n\n\n\n\nRecall, that this offsets the overall function vertically:\n\n\nShow the code\n%%itikz --temp-dir --tex-packages=tikz,pgfplots --tikz-libraries=arrows --implicit-standalone\n\\begin{tikzpicture}[scale=1.5]\n\\begin{axis}[grid,ymin=-2,ymax=2,ytick={-2,-1,...,2},xmin=0,xmax=1]\n\\addplot[color=blue,thick,samples=1000]{max(max(6*x,0)+0.70,0)};\n\\addplot[color=green,samples=1000,domain=0:1]{sin(deg(2*3.14*x))};\n\\end{axis}\n\\end{tikzpicture}\n\n\n\n\n\nNow, we can set the weight for the second neuron to \\(-1\\), causing a deactivation point to occur, atleast horizontally, where we want it.\n\n\nShow the code\n%%itikz --temp-dir --tex-packages=tikz --tikz-libraries=arrows --implicit-standalone\n\\begin{tikzpicture}\n\n\\node[circle, \n    minimum size = 15mm,\n    fill=red!30\n    ] (Input) at (0,0) {\\large $x_1$};\n\n\\foreach \\i in {1,2,...,8}\n{\n    \\node[circle, \n        minimum size = 15mm,\n        fill=blue!50,\n        yshift=90 mm\n        ] (Hidden1-\\i) at (3.0,-\\i * 2) {\\large $h_\\i^{(1)}$};\n        \n}\n\\foreach \\i in {1,2,...,8}\n{\n    \\node[circle, \n        minimum size = 15mm,\n        fill=blue!50,\n        yshift=90 mm\n        ] (Hidden2-\\i) at (6.0,-\\i * 2) {\\large $h_\\i^{(2)}$};\n        \n}\n\n\\node[circle, \n    minimum size = 15mm,\n    fill=red!30\n    ] (Output) at (9,0) {\\large $\\hat{y}_1$};\n\n% Connect neurons In-Hidden1\n\\foreach \\j in {2,...,8}\n{\n    \\draw[-&gt;, shorten &gt;=1pt] (Input) -- (Hidden1-\\j);   \n}\n% Connect neurons Hidden1-Hidden2\n\\foreach \\i in {2,...,8}\n{\n    \n        \\draw[-&gt;, shorten &gt;=1pt] (Hidden1-\\i) -- (Hidden2-\\i);   \n    \n}\n\n\\foreach \\i in {2,...,8}\n{\n    \n        \\draw[-&gt;, shorten &gt;=1pt] (Hidden2-\\i) -- (Output);   \n}\n\\draw[-&gt;, shorten &gt;=1pt] (Input) -- node [midway] {$6.00$} (Hidden1-1);   \n\\draw[-&gt;, shorten &gt;=1pt] (Hidden1-1) -- node [midway,above] {$-1.00$} (Hidden2-1); \n\\draw[-&gt;, shorten &gt;=1pt] (Hidden2-1) -- node [midway] {$1.00$} (Output); \n\\draw[-&gt;, shorten &gt;=1pt] (6,6) node [below] {$0.70$} --  (Hidden2-1); \n\\draw[-&gt;, shorten &gt;=1pt] (3,6) node [below] {$0.00$} --  (Hidden1-1); \n\\end{tikzpicture}\n\n\n\n\n\nWe get:\n\n\nShow the code\n%%itikz --temp-dir --tex-packages=tikz,pgfplots --tikz-libraries=arrows --implicit-standalone\n\\begin{tikzpicture}[scale=1.5]\n\\begin{axis}[grid,ymin=-2,ymax=2,ytick={-2,-1,...,2},xmin=0,xmax=1]\n\\addplot[color=blue,thick,samples=1000]{max(-max(6*x,0)+0.70,0)};\n\\addplot[color=green,samples=1000,domain=0:1]{sin(deg(2*3.14*x))};\n\\end{axis}\n\\end{tikzpicture}\n\n\n\n\n\nNow, we’d like to flip this slope back. How might we flip the output of these two neurons?\n\n\nShow the code\n%%itikz --temp-dir --tex-packages=tikz --tikz-libraries=arrows --implicit-standalone\n\\begin{tikzpicture}\n\n\\node[circle, \n    minimum size = 15mm,\n    fill=red!30\n    ] (Input) at (0,0) {\\large $x_1$};\n\n\\foreach \\i in {1,2,...,8}\n{\n    \\node[circle, \n        minimum size = 15mm,\n        fill=blue!50,\n        yshift=90 mm\n        ] (Hidden1-\\i) at (3.0,-\\i * 2) {\\large $h_\\i^{(1)}$};\n        \n}\n\\foreach \\i in {1,2,...,8}\n{\n    \\node[circle, \n        minimum size = 15mm,\n        fill=blue!50,\n        yshift=90 mm\n        ] (Hidden2-\\i) at (6.0,-\\i * 2) {\\large $h_\\i^{(2)}$};\n        \n}\n\n\\node[circle, \n    minimum size = 15mm,\n    fill=red!30\n    ] (Output) at (9,0) {\\large $\\hat{y}_1$};\n\n% Connect neurons In-Hidden1\n\\foreach \\j in {2,...,8}\n{\n    \\draw[-&gt;, shorten &gt;=1pt] (Input) -- (Hidden1-\\j);   \n}\n% Connect neurons Hidden1-Hidden2\n\\foreach \\i in {2,...,8}\n{\n    \n        \\draw[-&gt;, shorten &gt;=1pt] (Hidden1-\\i) -- (Hidden2-\\i);   \n    \n}\n\n\\foreach \\i in {2,...,8}\n{\n    \n        \\draw[-&gt;, shorten &gt;=1pt] (Hidden2-\\i) -- (Output);   \n}\n\\draw[-&gt;, shorten &gt;=1pt] (Input) -- node [midway] {$6.00$} (Hidden1-1);   \n\\draw[-&gt;, shorten &gt;=1pt] (Hidden1-1) -- node [midway,above] {$-1.00$} (Hidden2-1); \n\\draw[-&gt;, shorten &gt;=1pt] (Hidden2-1) -- node [midway] {$-1.00$} (Output); \n\\draw[-&gt;, shorten &gt;=1pt] (6,6) node [below] {$0.70$} --  (Hidden2-1); \n\\draw[-&gt;, shorten &gt;=1pt] (3,6) node [below] {$0.00$} --  (Hidden1-1); \n\\end{tikzpicture}\n\n\n\n\n\nIt seems like we can take the weights of the connection to the output neuron, which is currently \\(1.0\\) and just flip it to a \\(-1\\), and that flips the function:\n\n\nShow the code\n%%itikz --temp-dir --tex-packages=tikz,pgfplots --tikz-libraries=arrows --implicit-standalone\n\\begin{tikzpicture}[scale=1.5]\n\\begin{axis}[grid,ymin=-2,ymax=2,ytick={-2,-1,...,2},xmin=0,xmax=1]\n\\addplot[color=blue,thick,samples=1000]{-max(-max(6*x,0)+0.70,0)};\n\\addplot[color=green,samples=1000,domain=0:1]{sin(deg(2*3.14*x))};\n\\end{axis}\n\\end{tikzpicture}\n\n\n\n\n\nWe’re certainly getting closer to making this first section fit how we want. Now, all we need to do is offset this up a bit. For this hand-optimized example, we’re going to use the first \\(7\\) pairs of neurons in the hidden layers to create the sine wave’s shape.\n\n\nShow the code\n%%itikz --temp-dir --tex-packages=tikz --tikz-libraries=arrows --implicit-standalone\n\\begin{tikzpicture}\n\n\\node[circle, \n    minimum size = 15mm,\n    fill=red!30\n    ] (Input) at (0,0) {\\large $x_1$};\n\n\\foreach \\i in {1,2,...,8}\n{\n    \\node[circle, \n        minimum size = 15mm,\n        fill=blue!50,\n        yshift=90 mm\n        ] (Hidden1-\\i) at (3.0,-\\i * 2) {\\large $h_\\i^{(1)}$};\n        \n}\n\\foreach \\i in {1,2,...,8}\n{\n    \\node[circle, \n        minimum size = 15mm,\n        fill=blue!50,\n        yshift=90 mm\n        ] (Hidden2-\\i) at (6.0,-\\i * 2) {\\large $h_\\i^{(2)}$};\n        \n}\n\n\\node[circle, \n    minimum size = 15mm,\n    fill=red!30\n    ] (Output) at (9,0) {\\large $\\hat{y}_1$};\n\n% Connect neurons In-Hidden1\n\\foreach \\j in {2,...,7}\n{\n    \\draw[-&gt;, shorten &gt;=1pt] (Input) -- (Hidden1-\\j);   \n}\n% Connect neurons Hidden1-Hidden2\n\\foreach \\i in {2,...,7}\n{\n    \n        \\draw[-&gt;, shorten &gt;=1pt] (Hidden1-\\i) -- (Hidden2-\\i);   \n    \n}\n\n\\foreach \\i in {2,...,7}\n{\n    \n        \\draw[-&gt;, shorten &gt;=1pt] (Hidden2-\\i) -- (Output);   \n}\n\\draw[-&gt;, shorten &gt;=1pt] (Input) -- node [midway] {$6.00$} (Hidden1-1);   \n\\draw[-&gt;, shorten &gt;=1pt] (Hidden1-1) -- node [midway,above] {$-1.00$} (Hidden2-1); \n\\draw[-&gt;, shorten &gt;=1pt] (Hidden2-1) -- node [midway] {$-1.00$} (Output); \n\\draw[-&gt;, shorten &gt;=1pt] (6,6) node [below] {$0.70$} --  (Hidden2-1); \n\\draw[-&gt;, shorten &gt;=1pt] (3,6) node [below] {$0.00$} --  (Hidden1-1); \n\n\\draw[-&gt;, shorten &gt;=1pt] (Input) -- node [midway] {$0.00$} (Hidden1-8); \n\\draw[-&gt;, shorten &gt;=1pt] (3,-9) node [below] {$0.00$} --  (Hidden1-8); \n\\draw[-&gt;, shorten &gt;=1pt] (Hidden1-8) -- node [midway,above] {$0.00$} (Hidden2-8); \n\\draw[-&gt;, shorten &gt;=1pt] (6,-9) node [below] {$1.00$} --  (Hidden2-8); \n\\draw[-&gt;, shorten &gt;=1pt] (Hidden2-8) -- node [midway] {$0.70$} (Output); \n\\end{tikzpicture}\n\n\n\n\n\nIf we set the bias of the second neuron in the bottom pair to \\(1.0\\) and the weight to the output neuron to \\(0.70\\), we can vertically shift the line like so:\n\n\nShow the code\n%%itikz --temp-dir --tex-packages=tikz,pgfplots --tikz-libraries=arrows --implicit-standalone\n\\begin{tikzpicture}[scale=1.5]\n\\begin{axis}[grid,ymin=-2,ymax=2,ytick={-2,-1,...,2},xmin=0,xmax=1]\n\\addplot[color=blue,thick,samples=1000]{-max(-max(6*x,0)+0.70,0))+0.70};\n\\addplot[color=green,samples=1000,domain=0:1]{sin(deg(2*3.14*x))};\n\\end{axis}\n\\end{tikzpicture}\n\n\n\n\n\nAt this point, we have completed the first section with an “area of effect” being the first upward section of the sine wave. We can start on the next section that we wish to do. We can start on the next section that we wish to do. We can start by setting all weights for this second pair of neurons to \\(1\\) including the output neuron.\n\n\nShow the code\n%%itikz --temp-dir --tex-packages=tikz --tikz-libraries=arrows --implicit-standalone\n\\begin{tikzpicture}\n\n\\node[circle, \n    minimum size = 15mm,\n    fill=red!30\n    ] (Input) at (0,0) {\\large $x_1$};\n\n\\foreach \\i in {1,2,...,8}\n{\n    \\node[circle, \n        minimum size = 15mm,\n        fill=blue!50,\n        yshift=90 mm\n        ] (Hidden1-\\i) at (3.0,-\\i * 2) {\\large $h_\\i^{(1)}$};\n        \n}\n\\foreach \\i in {1,2,...,8}\n{\n    \\node[circle, \n        minimum size = 15mm,\n        fill=blue!50,\n        yshift=90 mm\n        ] (Hidden2-\\i) at (6.0,-\\i * 2) {\\large $h_\\i^{(2)}$};\n        \n}\n\n\\node[circle, \n    minimum size = 15mm,\n    fill=red!30\n    ] (Output) at (9,0) {\\large $\\hat{y}_1$};\n\n% Connect neurons In-Hidden1\n\\foreach \\j in {3,...,7}\n{\n    \\draw[-&gt;, shorten &gt;=1pt] (Input) -- (Hidden1-\\j);   \n}\n% Connect neurons Hidden1-Hidden2\n\\foreach \\i in {3,...,7}\n{\n    \n        \\draw[-&gt;, shorten &gt;=1pt] (Hidden1-\\i) -- (Hidden2-\\i);   \n    \n}\n\n\\foreach \\i in {3,...,7}\n{\n    \n        \\draw[-&gt;, shorten &gt;=1pt] (Hidden2-\\i) -- (Output);   \n}\n\\draw[-&gt;, shorten &gt;=1pt] (Input) -- node [midway] {$6.00$} (Hidden1-1);   \n\\draw[-&gt;, shorten &gt;=1pt] (Hidden1-1) -- node [midway,above] {$-1.00$} (Hidden2-1); \n\\draw[-&gt;, shorten &gt;=1pt] (Hidden2-1) -- node [midway] {$-1.00$} (Output); \n\\draw[-&gt;, shorten &gt;=1pt] (6,6) node [below] {$0.70$} --  (Hidden2-1); \n\\draw[-&gt;, shorten &gt;=1pt] (3,6) node [below] {$0.00$} --  (Hidden1-1); \n\n\\draw[-&gt;, shorten &gt;=1pt] (Input) -- node [midway] {$0.00$} (Hidden1-8); \n\\draw[-&gt;, shorten &gt;=1pt] (3,-9) node [below] {$0.00$} --  (Hidden1-8); \n\\draw[-&gt;, shorten &gt;=1pt] (Hidden1-8) -- node [midway,above] {$0.00$} (Hidden2-8); \n\\draw[-&gt;, shorten &gt;=1pt] (6,-9) node [below] {$1.00$} --  (Hidden2-8); \n\\draw[-&gt;, shorten &gt;=1pt] (Hidden2-8) -- node [midway] {$0.70$} (Output); \n\n\\draw[-&gt;, shorten &gt;=1pt] (Input) -- node [midway] {$1.00$} (Hidden1-2); \n\\draw[-&gt;, shorten &gt;=1pt] (3,4) node [below] {$0.00$} --  (Hidden1-2); \n\\draw[-&gt;, shorten &gt;=1pt] (Hidden1-2) -- node [midway,above] {$1.00$} (Hidden2-2); \n\\draw[-&gt;, shorten &gt;=1pt] (6,4) node [below] {$0.00$} --  (Hidden2-2); \n\\draw[-&gt;, shorten &gt;=1pt] (Hidden2-2) -- node [midway] {$1.00$} (Output); \n\\end{tikzpicture}\n\n\n\n\n\nAt this point, this second pair of neurons activation is beginning too soon, which is impacting the area of effect of the top pair we already aligned.\n\n\nShow the code\n%%itikz --temp-dir --tex-packages=tikz,pgfplots --tikz-libraries=arrows --implicit-standalone\n\\begin{tikzpicture}[scale=1.5]\n\\begin{axis}[grid,ymin=-2,ymax=2,ytick={-2,-1,...,2},xmin=0,xmax=1]\n\\addplot[color=blue,thick,samples=1000]{-max(-max(6*x,0)+0.70,0))+0.70+max(max(x,0),0)};\n\\addplot[color=green,samples=1000,domain=0:1]{sin(deg(2*3.14*x))};\n\\end{axis}\n\\end{tikzpicture}\n\n\n\n\n\nTo fix this, we want this second pair to start influencing the output where the first pair deactivates, so we want to adjust the function horizontally. As you can recall from earlier, we adjust the first neuron’s bias in this neuron pair to achieve this. Also, to modify the slope, we’ll set the weight coming into that first neuron for the second pair, setting it to \\(3.50\\).\n\n\nShow the code\n%%itikz --temp-dir --tex-packages=tikz --tikz-libraries=arrows --implicit-standalone\n\\begin{tikzpicture}\n\n\\node[circle, \n    minimum size = 15mm,\n    fill=red!30\n    ] (Input) at (0,0) {\\large $x_1$};\n\n\\foreach \\i in {1,2,...,8}\n{\n    \\node[circle, \n        minimum size = 15mm,\n        fill=blue!50,\n        yshift=90 mm\n        ] (Hidden1-\\i) at (3.0,-\\i * 2) {\\large $h_\\i^{(1)}$};\n        \n}\n\\foreach \\i in {1,2,...,8}\n{\n    \\node[circle, \n        minimum size = 15mm,\n        fill=blue!50,\n        yshift=90 mm\n        ] (Hidden2-\\i) at (6.0,-\\i * 2) {\\large $h_\\i^{(2)}$};\n        \n}\n\n\\node[circle, \n    minimum size = 15mm,\n    fill=red!30\n    ] (Output) at (9,0) {\\large $\\hat{y}_1$};\n\n% Connect neurons In-Hidden1\n\\foreach \\j in {3,...,7}\n{\n    \\draw[-&gt;, shorten &gt;=1pt] (Input) -- (Hidden1-\\j);   \n}\n% Connect neurons Hidden1-Hidden2\n\\foreach \\i in {3,...,7}\n{\n    \n        \\draw[-&gt;, shorten &gt;=1pt] (Hidden1-\\i) -- (Hidden2-\\i);   \n    \n}\n\n\\foreach \\i in {3,...,7}\n{\n    \n        \\draw[-&gt;, shorten &gt;=1pt] (Hidden2-\\i) -- (Output);   \n}\n\\draw[-&gt;, shorten &gt;=1pt] (Input) -- node [midway] {$6.00$} (Hidden1-1);   \n\\draw[-&gt;, shorten &gt;=1pt] (Hidden1-1) -- node [midway,above] {$-1.00$} (Hidden2-1); \n\\draw[-&gt;, shorten &gt;=1pt] (Hidden2-1) -- node [midway] {$-1.00$} (Output); \n\\draw[-&gt;, shorten &gt;=1pt] (6,6) node [below] {$0.70$} --  (Hidden2-1); \n\\draw[-&gt;, shorten &gt;=1pt] (3,6) node [below] {$0.00$} --  (Hidden1-1); \n\n\\draw[-&gt;, shorten &gt;=1pt] (Input) -- node [midway] {$0.00$} (Hidden1-8); \n\\draw[-&gt;, shorten &gt;=1pt] (3,-9) node [below] {$0.00$} --  (Hidden1-8); \n\\draw[-&gt;, shorten &gt;=1pt] (Hidden1-8) -- node [midway,above] {$0.00$} (Hidden2-8); \n\\draw[-&gt;, shorten &gt;=1pt] (6,-9) node [below] {$1.00$} --  (Hidden2-8); \n\\draw[-&gt;, shorten &gt;=1pt] (Hidden2-8) -- node [midway] {$0.70$} (Output); \n\n\\draw[-&gt;, shorten &gt;=1pt] (Input) -- node [midway] {$3.50$} (Hidden1-2); \n\\draw[-&gt;, shorten &gt;=1pt] (3,4) node [below] {$-0.42$} --  (Hidden1-2); \n\\draw[-&gt;, shorten &gt;=1pt] (Hidden1-2) -- node [midway,above] {$1.00$} (Hidden2-2); \n\\draw[-&gt;, shorten &gt;=1pt] (6,4) node [below] {$0.00$} --  (Hidden2-2); \n\\draw[-&gt;, shorten &gt;=1pt] (Hidden2-2) -- node [midway] {$1.00$} (Output); \n\\end{tikzpicture}\n\n\n\n\n\nAfter these adjustments:\n\n\nShow the code\n%%itikz --temp-dir --tex-packages=tikz,pgfplots --tikz-libraries=arrows --implicit-standalone\n\\begin{tikzpicture}[scale=1.5]\n\\begin{axis}[grid,ymin=-2,ymax=2,ytick={-2,-1,...,2},xmin=0,xmax=1]\n\\addplot[color=blue,thick,samples=1000]{-max(-max(6*x,0)+0.70,0))+0.70+max(max(3.50*x - 0.42,0),0)};\n\\addplot[color=green,samples=1000,domain=0:1]{sin(deg(2*3.14*x))};\n\\end{axis}\n\\end{tikzpicture}\n\n\n\n\n\nWe will now use the same methodology as we did with the first pair of neurons to set the deactivation point. We set the weight for the second neuron in the hidden layer pair to \\(-1.00\\) and the bias to \\(0.27\\).\n\n\nShow the code\n%%itikz --temp-dir --tex-packages=tikz --tikz-libraries=arrows --implicit-standalone\n\\begin{tikzpicture}\n\n\\node[circle, \n    minimum size = 15mm,\n    fill=red!30\n    ] (Input) at (0,0) {\\large $x_1$};\n\n\\foreach \\i in {1,2,...,8}\n{\n    \\node[circle, \n        minimum size = 15mm,\n        fill=blue!50,\n        yshift=90 mm\n        ] (Hidden1-\\i) at (3.0,-\\i * 2) {\\large $h_\\i^{(1)}$};\n        \n}\n\\foreach \\i in {1,2,...,8}\n{\n    \\node[circle, \n        minimum size = 15mm,\n        fill=blue!50,\n        yshift=90 mm\n        ] (Hidden2-\\i) at (6.0,-\\i * 2) {\\large $h_\\i^{(2)}$};\n        \n}\n\n\\node[circle, \n    minimum size = 15mm,\n    fill=red!30\n    ] (Output) at (9,0) {\\large $\\hat{y}_1$};\n\n% Connect neurons In-Hidden1\n\\foreach \\j in {3,...,7}\n{\n    \\draw[-&gt;, shorten &gt;=1pt] (Input) -- (Hidden1-\\j);   \n}\n% Connect neurons Hidden1-Hidden2\n\\foreach \\i in {3,...,7}\n{\n    \n        \\draw[-&gt;, shorten &gt;=1pt] (Hidden1-\\i) -- (Hidden2-\\i);   \n    \n}\n\n\\foreach \\i in {3,...,7}\n{\n    \n        \\draw[-&gt;, shorten &gt;=1pt] (Hidden2-\\i) -- (Output);   \n}\n\\draw[-&gt;, shorten &gt;=1pt] (Input) -- node [midway] {$6.00$} (Hidden1-1);   \n\\draw[-&gt;, shorten &gt;=1pt] (Hidden1-1) -- node [midway,above] {$-1.00$} (Hidden2-1); \n\\draw[-&gt;, shorten &gt;=1pt] (Hidden2-1) -- node [midway] {$-1.00$} (Output); \n\\draw[-&gt;, shorten &gt;=1pt] (6,6) node [below] {$0.70$} --  (Hidden2-1); \n\\draw[-&gt;, shorten &gt;=1pt] (3,6) node [below] {$0.00$} --  (Hidden1-1); \n\n\\draw[-&gt;, shorten &gt;=1pt] (Input) -- node [midway] {$0.00$} (Hidden1-8); \n\\draw[-&gt;, shorten &gt;=1pt] (3,-9) node [below] {$0.00$} --  (Hidden1-8); \n\\draw[-&gt;, shorten &gt;=1pt] (Hidden1-8) -- node [midway,above] {$0.00$} (Hidden2-8); \n\\draw[-&gt;, shorten &gt;=1pt] (6,-9) node [below] {$1.00$} --  (Hidden2-8); \n\\draw[-&gt;, shorten &gt;=1pt] (Hidden2-8) -- node [midway] {$0.70$} (Output); \n\n\\draw[-&gt;, shorten &gt;=1pt] (Input) -- node [midway] {$3.50$} (Hidden1-2); \n\\draw[-&gt;, shorten &gt;=1pt] (3,4) node [below] {$-0.42$} --  (Hidden1-2); \n\\draw[-&gt;, shorten &gt;=1pt] (Hidden1-2) -- node [midway,above] {$-1.00$} (Hidden2-2); \n\\draw[-&gt;, shorten &gt;=1pt] (6,4) node [below] {$0.27$} --  (Hidden2-2); \n\\draw[-&gt;, shorten &gt;=1pt] (Hidden2-2) -- node [midway] {$1.00$} (Output); \n\\end{tikzpicture}\n\n\n\n\n\nThis results in:\n\n\nShow the code\n%%itikz --temp-dir --tex-packages=tikz,pgfplots --tikz-libraries=arrows --implicit-standalone\n\\begin{tikzpicture}[scale=1.5]\n\\begin{axis}[grid,ymin=-2,ymax=2,ytick={-2,-1,...,2},xmin=0,xmax=1]\n\\addplot[color=blue,thick,samples=1000]{-max(-max(6*x,0)+0.70,0))+0.70+max(-max(3.50*x - 0.42,0)+0.27,0)};\n\\addplot[color=green,samples=1000,domain=0:1]{sin(deg(2*3.14*x))};\n\\end{axis}\n\\end{tikzpicture}\n\n\n\n\n\nThen, we can flip this section’s function again the same way we did with the first one, by setting the weight to the output neuron from \\(1.0\\) to \\(-1.0\\).\n\n\nShow the code\n%%itikz --temp-dir --tex-packages=tikz --tikz-libraries=arrows --implicit-standalone\n\\begin{tikzpicture}\n\n\\node[circle, \n    minimum size = 15mm,\n    fill=red!30\n    ] (Input) at (0,0) {\\large $x_1$};\n\n\\foreach \\i in {1,2,...,8}\n{\n    \\node[circle, \n        minimum size = 15mm,\n        fill=blue!50,\n        yshift=90 mm\n        ] (Hidden1-\\i) at (3.0,-\\i * 2) {\\large $h_\\i^{(1)}$};\n        \n}\n\\foreach \\i in {1,2,...,8}\n{\n    \\node[circle, \n        minimum size = 15mm,\n        fill=blue!50,\n        yshift=90 mm\n        ] (Hidden2-\\i) at (6.0,-\\i * 2) {\\large $h_\\i^{(2)}$};\n        \n}\n\n\\node[circle, \n    minimum size = 15mm,\n    fill=red!30\n    ] (Output) at (9,0) {\\large $\\hat{y}_1$};\n\n% Connect neurons In-Hidden1\n\\foreach \\j in {3,...,7}\n{\n    \\draw[-&gt;, shorten &gt;=1pt] (Input) -- (Hidden1-\\j);   \n}\n% Connect neurons Hidden1-Hidden2\n\\foreach \\i in {3,...,7}\n{\n    \n        \\draw[-&gt;, shorten &gt;=1pt] (Hidden1-\\i) -- (Hidden2-\\i);   \n    \n}\n\n\\foreach \\i in {3,...,7}\n{\n    \n        \\draw[-&gt;, shorten &gt;=1pt] (Hidden2-\\i) -- (Output);   \n}\n\\draw[-&gt;, shorten &gt;=1pt] (Input) -- node [midway] {$6.00$} (Hidden1-1);   \n\\draw[-&gt;, shorten &gt;=1pt] (Hidden1-1) -- node [midway,above] {$-1.00$} (Hidden2-1); \n\\draw[-&gt;, shorten &gt;=1pt] (Hidden2-1) -- node [midway] {$-1.00$} (Output); \n\\draw[-&gt;, shorten &gt;=1pt] (6,6) node [below] {$0.70$} --  (Hidden2-1); \n\\draw[-&gt;, shorten &gt;=1pt] (3,6) node [below] {$0.00$} --  (Hidden1-1); \n\n\\draw[-&gt;, shorten &gt;=1pt] (Input) -- node [midway] {$0.00$} (Hidden1-8); \n\\draw[-&gt;, shorten &gt;=1pt] (3,-9) node [below] {$0.00$} --  (Hidden1-8); \n\\draw[-&gt;, shorten &gt;=1pt] (Hidden1-8) -- node [midway,above] {$0.00$} (Hidden2-8); \n\\draw[-&gt;, shorten &gt;=1pt] (6,-9) node [below] {$1.00$} --  (Hidden2-8); \n\\draw[-&gt;, shorten &gt;=1pt] (Hidden2-8) -- node [midway] {$0.70$} (Output); \n\n\\draw[-&gt;, shorten &gt;=1pt] (Input) -- node [midway] {$3.50$} (Hidden1-2); \n\\draw[-&gt;, shorten &gt;=1pt] (3,4) node [below] {$-0.42$} --  (Hidden1-2); \n\\draw[-&gt;, shorten &gt;=1pt] (Hidden1-2) -- node [midway,above] {$-1.00$} (Hidden2-2); \n\\draw[-&gt;, shorten &gt;=1pt] (6,4) node [below] {$0.27$} --  (Hidden2-2); \n\\draw[-&gt;, shorten &gt;=1pt] (Hidden2-2) -- node [midway] {$-1.00$} (Output); \n\\end{tikzpicture}\n\n\n\n\n\nConsequently, we have:\n\n\nShow the code\n%%itikz --temp-dir --tex-packages=tikz,pgfplots --tikz-libraries=arrows --implicit-standalone\n\\begin{tikzpicture}[scale=1.5]\n\\begin{axis}[grid,ymin=-2,ymax=2,ytick={-2,-1,...,2},xmin=0,xmax=1]\n\\addplot[color=blue,thick,samples=1000]{-max(-max(6*x,0)+0.70,0))+0.70-max(-max(3.50*x - 0.42,0)+0.27,0)};\n\\addplot[color=green,samples=1000,domain=0:1]{sin(deg(2*3.14*x))};\n\\end{axis}\n\\end{tikzpicture}\n\n\n\n\n\nAnd again, just like the first pair, we use the bottom pair to fix the vertical offset.\n\n\nShow the code\n%%itikz --temp-dir --tex-packages=tikz --tikz-libraries=arrows --implicit-standalone\n\\begin{tikzpicture}\n\n\\node[circle, \n    minimum size = 15mm,\n    fill=red!30\n    ] (Input) at (0,0) {\\large $x_1$};\n\n\\foreach \\i in {1,2,...,8}\n{\n    \\node[circle, \n        minimum size = 15mm,\n        fill=blue!50,\n        yshift=90 mm\n        ] (Hidden1-\\i) at (3.0,-\\i * 2) {\\large $h_\\i^{(1)}$};\n        \n}\n\\foreach \\i in {1,2,...,8}\n{\n    \\node[circle, \n        minimum size = 15mm,\n        fill=blue!50,\n        yshift=90 mm\n        ] (Hidden2-\\i) at (6.0,-\\i * 2) {\\large $h_\\i^{(2)}$};\n        \n}\n\n\\node[circle, \n    minimum size = 15mm,\n    fill=red!30\n    ] (Output) at (9,0) {\\large $\\hat{y}_1$};\n\n% Connect neurons In-Hidden1\n\\foreach \\j in {3,...,7}\n{\n    \\draw[-&gt;, shorten &gt;=1pt] (Input) -- (Hidden1-\\j);   \n}\n% Connect neurons Hidden1-Hidden2\n\\foreach \\i in {3,...,7}\n{\n    \n        \\draw[-&gt;, shorten &gt;=1pt] (Hidden1-\\i) -- (Hidden2-\\i);   \n    \n}\n\n\\foreach \\i in {3,...,7}\n{\n    \n        \\draw[-&gt;, shorten &gt;=1pt] (Hidden2-\\i) -- (Output);   \n}\n\\draw[-&gt;, shorten &gt;=1pt] (Input) -- node [midway] {$6.00$} (Hidden1-1);   \n\\draw[-&gt;, shorten &gt;=1pt] (Hidden1-1) -- node [midway,above] {$-1.00$} (Hidden2-1); \n\\draw[-&gt;, shorten &gt;=1pt] (Hidden2-1) -- node [midway] {$-1.00$} (Output); \n\\draw[-&gt;, shorten &gt;=1pt] (6,6) node [below] {$0.70$} --  (Hidden2-1); \n\\draw[-&gt;, shorten &gt;=1pt] (3,6) node [below] {$0.00$} --  (Hidden1-1); \n\n\\draw[-&gt;, shorten &gt;=1pt] (Input) -- node [midway] {$0.00$} (Hidden1-8); \n\\draw[-&gt;, shorten &gt;=1pt] (3,-9) node [below] {$0.00$} --  (Hidden1-8); \n\\draw[-&gt;, shorten &gt;=1pt] (Hidden1-8) -- node [midway,above] {$0.00$} (Hidden2-8); \n\\draw[-&gt;, shorten &gt;=1pt] (6,-9) node [below] {$1.00$} --  (Hidden2-8); \n\\draw[-&gt;, shorten &gt;=1pt] (Hidden2-8) -- node [midway] {$0.97$} (Output); \n\n\\draw[-&gt;, shorten &gt;=1pt] (Input) -- node [midway] {$3.50$} (Hidden1-2); \n\\draw[-&gt;, shorten &gt;=1pt] (3,4) node [below] {$-0.42$} --  (Hidden1-2); \n\\draw[-&gt;, shorten &gt;=1pt] (Hidden1-2) -- node [midway,above] {$-1.00$} (Hidden2-2); \n\\draw[-&gt;, shorten &gt;=1pt] (6,4) node [below] {$0.27$} --  (Hidden2-2); \n\\draw[-&gt;, shorten &gt;=1pt] (Hidden2-2) -- node [midway] {$-1.00$} (Output); \n\\end{tikzpicture}\n\n\n\n\n\nWe get:\n\n\nShow the code\n%%itikz --temp-dir --tex-packages=tikz,pgfplots --tikz-libraries=arrows --implicit-standalone\n\\begin{tikzpicture}[scale=1.5]\n\\begin{axis}[grid,ymin=-2,ymax=2,ytick={-2,-1,...,2},xmin=0,xmax=1]\n\\addplot[color=blue,thick,samples=1000]{-max(-max(6*x,0)+0.70,0))+0.97-max(-max(3.50*x - 0.42,0)+0.27,0)};\n\\addplot[color=green,samples=1000,domain=0:1]{sin(deg(2*3.14*x))};\n\\end{axis}\n\\end{tikzpicture}\n\n\n\n\n\nWe then just continue this methodology. It should begin to make more sense to you now, how more neurons can enable more unique areas of effect, why we need two or more hidden layers, and why we need nonlinear activation functions to map nonlinear problems.\nWe can write a ReLUActivation class to represent the ReLU activation function:\n\nclass ReLUActivation:\n\n    # Forward pass\n    def forward(self, inputs):\n        # Calculate output values from the inputs\n        self.output = np.maximum(0, inputs)\n\nLet’s apply this activation function to the DenseLayer’s outputs in our code:\n\nfrom nnfs.datasets import spiral_data\nimport numpy as np\n\n# Create dataset\nX, y = spiral_data(samples=100, classes=3)\n\n# Create Dense layer with 2 input features and 3 output values\ndense1 = DenseLayer(2, 3)\n\n# Create ReLU activation function (to be used with the DenseLayer)\nactivation1 = ReLUActivation()\n\n# Make a forward pass of our training data through this layer\ndense1.forward(X)\n\n# Forward pass through our activation function\n# Takes in output from the previous layer\nactivation1.forward(dense1.output)\n\n# Let's see output of the first few samples\nprint(activation1.output[:5])\n\n[[0.0000000e+00 0.0000000e+00 0.0000000e+00]\n [1.3520580e-04 1.8173116e-05 0.0000000e+00]\n [2.3245417e-04 0.0000000e+00 0.0000000e+00]\n [3.8226307e-04 0.0000000e+00 0.0000000e+00]\n [5.7436468e-04 0.0000000e+00 0.0000000e+00]]\n\n\nAs we can see, negative values have been clipped (modified to zero). That’s all there is to the rectified linear activation function used in the hidden layer. Let’s talk about the activation function that we are going to use on the output of the last layer."
  },
  {
    "objectID": "posts/coding-a-neural-network-layer/index.html#the-softmax-activation-function",
    "href": "posts/coding-a-neural-network-layer/index.html#the-softmax-activation-function",
    "title": "Coding a neural network layer",
    "section": "The Softmax Activation function",
    "text": "The Softmax Activation function\nIn our case, we’re looking to get this model to be a classifier, so we want an activation function meant for classification. One of these is the softmax activation function. First, why are we bothering with another activation function? It just depends on what our overall goals are.\nThe rectified linear unit is unbounded, not normalized with other units and exclusive. “Not normalized” implies the values can be anything, an output of [12,99,318] is without context, and exclusive means each output is independent of others. To address this lack of context, the softmax activation function on the output data can take in non-normalized, or uncalibrated, inputs and produce a normalized distribution of probabilities for our classes. In the case of classification, what we want to see is a prediction of which class the network thinks the input represents. This distribution returned by the softmax activation function represents confidence scores in our overarching algorithm/program that uses this network. For example, if our network has a confidence distirbution for two classes \\([0.45,0.55]\\), the prediction is the \\(2\\)nd class, but the confidence in this prediction isn’t very high.\nMaybe our program wouldn’t act in this case, since it’s not very confident.\nThe softmax function takes as input a vector of \\(L\\) real numbers and normalizes it into a probability distribution consisting of \\(L\\) probabilities proportional to the exponentials of the input numbers.\nDefinition. The standard(unit) softmax function \\(\\sigma:\\mathbf{R}^L \\to (0,1)^L\\) takes a vector \\(\\mathbf{z}=(z_1,\\ldots,z_l)\\in\\mathbf{R}^L\\) and computes each component of the vector \\(\\sigma(\\mathbf{z})\\in(0,1)^L\\) with:\n\\[\\begin{align*}\n\\sigma(\\mathbf{z})_i = \\frac{e^{z_{i}}}{\\sum_{l=1}^{L}e^{z_{l}}}\n\\end{align*}\\]\nThat might look daunting, but it’s easy to follow. Suppose the example outputs from a neural network layer are:\n\nlayer_outputs = [4.80, 1.21, 2.385]\n\nThen, the normalized values are:\n\nimport numpy as np\n\nnorm_values = np.exp(layer_outputs)/np.sum(np.exp(layer_outputs))\nprint(norm_values)\n\n[0.89528266 0.02470831 0.08000903]\n\n\nTo train in batches, we need to convert this functionality to accept layer outputs in batches. Do this is easy:\n\nlayer_outputs = np.random.randn(100,3)\nnorm_values = np.exp(layer_outputs)/np.sum(np.exp(layer_outputs),axis=1,keepdims=True)\n\nWe can now write a SoftmaxActivation class as:\n\n# Softmax activation\nclass SoftmaxActivation:\n\n    # Forward pass\n    def forward(self, inputs):\n        exp_values = np.exp(inputs - np.max(inputs, axis=1, keepdims=True))\n        probabilities = exp_values / np.sum(exp_values, axis=1, keepdims=True)\n        self.output = probabilities\n\nWe also included a subtraction of the largest of the inputs before we do the exponentiation. This does not affect the output of the softmax function, since:\n\\[\\begin{align*}\n\\frac{e^{z_{i}-||\\mathbf{z}||}}{\\sum_{l=1}^{L}e^{z_{l}-||\\mathbf{z}||}} = \\frac{e^{-||\\mathbf{z}||}\\cdot e^{z_{i}}}{e^{-||\\mathbf{z}||}\\cdot \\sum_{l=1}^{L}e^{z_{l}}} = \\sigma(\\mathbf{z})_i\n\\end{align*}\\]\nThere are two main pervasive challenges with neural networks : dead neurons and very large numbers (referred to as exploding values). Dead neurons and enormous numbers can wreak havoc down the line and render a network useless over time."
  },
  {
    "objectID": "posts/coding-a-neural-network-layer/index.html#the-output-layer",
    "href": "posts/coding-a-neural-network-layer/index.html#the-output-layer",
    "title": "Coding a neural network layer",
    "section": "The output layer",
    "text": "The output layer\nNow, we can add another DenseLayer as the output layer, setting it to contain as many inputs as the previous layer outputs and as many outputs as our data includes classes. Then, we can apply the softmax function to the output of this new layer.\n\nFull code upto this point\n\nimport numpy as np\nimport nnfs\nfrom nnfs.datasets import spiral_data\n\nclass DenseLayer:\n\n    def __init__(self, n_inputs, n_neurons):\n        # Initialize all weights and biases\n        self.weights = 0.01 * np.random.randn(n_inputs,n_neurons)\n        self.biases = np.zeros((1,n_neurons))\n    \n    def forward(self, inputs):\n        self.output = np.dot(inputs,self.weights) + self.biases\n\nclass ReLUActivation:\n\n    # Forward pass\n    def forward(self, inputs):\n        self.output = np.maximum(inputs, 0)\n\nclass SoftmaxActivation:\n\n    # Forward pass\n    def forward(self,inputs):\n        exp_values = np.exp(inputs - np.max(inputs, axis=1, keepdims=True))\n        probabilities = exp_values / np.sum(exp_values, axis=1, keepdims=True)\n        self.output = probabilities\n\n# Create dataset\nX, y = spiral_data(samples=100, classes=3)\n\n# Create a DenseLayer with 2 input features and 3 neurons\ndense1 = DenseLayer(2, 3)\n\n# Create ReLU Activation (to be used with DenseLayer)\nactivation1 = ReLUActivation()\n\n# Create a second DenseLayer with 3 input features and 3 output values\ndense2 = DenseLayer(3, 3)\n\n# Create Softmax activation to be used with the output layer\nactivation2 = SoftmaxActivation()\n\n# Make a forward pass of our training data through this layer\ndense1.forward(X)\n\n# Make a forward pass through the activation function \n# It takes the output of the first dense layer\nactivation1.forward(dense1.output)\n\n# Make a forward pass through the second DenseLayer\n# It takes outputs of the activation function of the first layer\n# as inputs\ndense2.forward(activation1.output)\n\n# Make a forward pass through activation function\n# It takes outputs of the second dense layer\nactivation2.forward(dense2.output)\n\n# Let's see output of the first few examples\nprint(activation2.output[:5])\n\n[[0.33333334 0.33333334 0.33333334]\n [0.33333322 0.3333335  0.33333322]\n [0.3333332  0.3333332  0.3333336 ]\n [0.3333332  0.3333336  0.3333332 ]\n [0.33333287 0.33333436 0.33333275]]\n\n\nWe’ve completed what we need for forward-passing data through the model.\nOur example model is currently random. To remedy this, we need a way to calculate how wrong the neural network is at current predictions and begin adjusting weights and biases to decrease error over time. Thus, our next step is to quantify how wrong the model is through what’s defined as a loss function."
  },
  {
    "objectID": "posts/cd-swaptions/index.html",
    "href": "posts/cd-swaptions/index.html",
    "title": "Standard CDS Pricing Theory",
    "section": "",
    "text": "I summarize below standard CDS pricing formulas.\n\n\n\nIn CDS pricing, credit default events are modelled using a Poisson process, with an intensity (or hazard rate) \\(\\lambda(t)\\). If the default time is \\(\\tau\\), then the probability of default over an infinitesimal time period \\(dt\\), given no default to \\(t\\) is:\n\\[\n\\begin{align*}\n\\mathbb{P}(t &lt; \\tau &lt; t + dt | \\tau &gt; t) = \\lambda(t)dt\n\\end{align*}\n\\] {#eq-instantaneous probability of default}\nThe probability of surviving to at least time \\(T &gt; t\\) (assuming no default has occurred until time \\(t\\)) is given by:\n\\[\n\\begin{align*}\nQ(t,T) = \\mathbb{P}(\\tau &gt; T | \\tau &gt; t) = \\mathbb{E}[1_{\\tau &gt; T}|\\mathcal{F}_t] = \\exp\\left(-\\lambda(s)ds\\right)\n\\end{align*}\n\\tag{1}\\]\nUp until this point, we have assumed that the intensity is deterministic - if it is extended to be a stochastic process, then the survival probability is given by:\n\\[\n\\begin{align*}\nQ(t,T) = \\mathbb{E}\\left[e^{-\\int_{t}^T \\lambda(s)ds}|\\mathcal{F}_t\\right]\n\\end{align*}\n\\tag{2}\\]\nIt is quite clear that the survival probability \\(Q(t,T)\\) plays the same role as the discounting factor (risk-free zero-coupon bond) \\(P(t,T)\\), as is the intensity \\(\\lambda(t)\\) and the instantaneous short rate \\(r(t)\\). We may extend this analogy and define the forward hazard rate \\(h(t,T)\\) as:\n\\[\n\\begin{align*}\nQ(t,T) = e^{-\\int_{t}^T h(t,s) ds} \\implies h(t,s) = -\\frac{\\partial}{\\partial s}(\\ln Q(t,s)) = -\\frac{1}{Q(t,s)} \\frac{\\partial Q(t,s)}{\\partial s}\n\\end{align*}\n\\tag{3}\\]\nand the zero hazard rates \\(\\Lambda(t,T)\\) as:\n\\[\n\\begin{align*}\nQ(t,T) = e^{-(T-t)\\Lambda(t,T)}, \\quad \\Lambda(t,T) = -\\frac{1}{T-t}\\ln[Q(t,T)]\n\\end{align*}\n\\tag{4}\\]\nThe survival probability curve \\(Q(t,T)\\), the forward hazard rate curve \\(h(t,T)\\) and the zero hazard rate curve \\(\\Lambda(t,T)\\) are equivalent and we refer to them generically as credit curves.\nThe forward hazard rate represents the (infinitesimal) probability of default between times \\(T\\) and \\(T+dt\\), conditional on survival to time \\(T\\) as seen from time \\(t &lt; T\\). The unconditional probability of default between times \\(T\\) and \\(T+dT\\) (as seen from time \\(t\\)) is given by:\n\\[\n\\mathbb{P}(T &lt; \\tau \\leq T + dT | \\tau &gt; t ) = Q(t,T)h(t)\n\\]\n\n\n\n\n\nTHe protection leg of a CDS consists of a (random) payment of \\(N(1 - RR(\\tau))\\) at default time \\(\\tau\\) if this is before expiry of the CDS (time \\(T\\)) and nothing otherwise. The present value of this leg can be written as:\n\\[\n\\begin{align*}\nPV_{prot} = N \\mathbb{E}[e^{-\\int_0^\\tau r(s) ds} (1 - RR(\\tau))1_{\\tau &lt; T}]\n\\end{align*}\n\\tag{5}\\]\nUnder the assumption of a flat recovery curve, this can be rewritten as:\n\\[\n\\begin{align*}\nPV_{prot} = N(1-RR)\\mathbb{E}[e^{-\\int_0^\\tau r(s) ds} 1_{\\tau &lt; T}]\n\\end{align*}\n\\tag{6}\\]\nConsider first a contract that pays \\(N(1-RR)\\), if the default takes place in the small time interval \\([u,u+du]\\). The value of this cash-flow at time \\(0\\):\n\\[\nN(1-RR)\\mathbb{E}[e^{-\\int_0^u r(s)ds } 1_{\\tau\\in[u,u+du]}]\n\\]\nWe can rewrite it as:\n\\[\nN(1-RR)\\mathbb{E}[e^{-\\int_0^u r(s)ds } 1_{\\tau\\in[u,u+du]}] = N(1-RR)\\mathbb{E}[ \\lambda(u) e^{-\\int_0^u (r(s) + \\lambda(s))ds }]\n\\]\nIntegrating over \\(u\\) from \\(0\\) to \\(T\\), we find that:\n\\[\nV_{prot}(0,T) = N(1-RR)\\mathbb{E}\\left[\\int_0^T \\lambda(s) e^{-\\int_0^s (r(u) + \\lambda(u))du} ds \\right]\n\\]\nIf the short rate process and the credit default intensity processes are independent, we can write this expression as:\n\\[\nV_{prot}(0,T) = N(1-RR) \\int_0^T  P(0,s) Q(0,s)\\lambda(s) ds\n\\]\nThe last integral can be easily approximated numerically.\n\n\n\nConsider now the premium leg of a CDS maturing at \\(T\\) with the premium consisting of the periodic coupon payments only (no upfront fee).\nThe premium leg consists of two parts : Regular premium (or coupon) payments (e.g. every three months) up to the expiry of the CDS, which cease if a default occurs, and a single payment of the accrued premium in the event of a default.\nIf there are \\(M\\) remaining payments, with payment times \\(t_1,t_2,\\ldots,t_i,\\ldots,t_M\\), period end times \\(e_1,e_2,\\ldots,e_M\\) and year fractions \\(\\Delta_1, \\Delta_2,\\ldots,\\Delta_M\\), then the present value of the premiums only is:\n\\[\nV_{\\text{premiums-only}}(0,T) = NC\\mathbb{E}\\left[\\sum_{i=1}^M \\Delta_i e^{-\\int_0^{t_i} r(s) ds 1_{e_i &lt; \\tau}}\\right] = NC\\sum_{i=1}^M \\Delta_i P(0,t_i) Q(0,e_i)\n\\tag{7}\\]\n\n\n\n\nA forward starting CDS entered into at time \\(t\\) will give protection against the default of an obligor for the period \\(T_e &gt; t\\) to \\(T_m\\), in return for premium payments in that period. If the obligor defaults before the start of the protection \\(\\tau &lt; T_e\\), the contract cancels worthless. This can easily be replicated by entering a long protection CDS with maturity \\(T_m\\), and a short protection position with maturity \\(T_e\\), leaving only the coupons between \\(T_e\\) and \\(T_m\\) to pay. Furthermore, if a default occurs before \\(T_e\\), the protection payments will exactly cancel.\n\\[\nV(t,T_e, T_m) = V(t, T_m) - V(t,T_e)\n\\]"
  },
  {
    "objectID": "posts/cd-swaptions/index.html#credit-curves",
    "href": "posts/cd-swaptions/index.html#credit-curves",
    "title": "Standard CDS Pricing Theory",
    "section": "",
    "text": "In CDS pricing, credit default events are modelled using a Poisson process, with an intensity (or hazard rate) \\(\\lambda(t)\\). If the default time is \\(\\tau\\), then the probability of default over an infinitesimal time period \\(dt\\), given no default to \\(t\\) is:\n\\[\n\\begin{align*}\n\\mathbb{P}(t &lt; \\tau &lt; t + dt | \\tau &gt; t) = \\lambda(t)dt\n\\end{align*}\n\\] {#eq-instantaneous probability of default}\nThe probability of surviving to at least time \\(T &gt; t\\) (assuming no default has occurred until time \\(t\\)) is given by:\n\\[\n\\begin{align*}\nQ(t,T) = \\mathbb{P}(\\tau &gt; T | \\tau &gt; t) = \\mathbb{E}[1_{\\tau &gt; T}|\\mathcal{F}_t] = \\exp\\left(-\\lambda(s)ds\\right)\n\\end{align*}\n\\tag{1}\\]\nUp until this point, we have assumed that the intensity is deterministic - if it is extended to be a stochastic process, then the survival probability is given by:\n\\[\n\\begin{align*}\nQ(t,T) = \\mathbb{E}\\left[e^{-\\int_{t}^T \\lambda(s)ds}|\\mathcal{F}_t\\right]\n\\end{align*}\n\\tag{2}\\]\nIt is quite clear that the survival probability \\(Q(t,T)\\) plays the same role as the discounting factor (risk-free zero-coupon bond) \\(P(t,T)\\), as is the intensity \\(\\lambda(t)\\) and the instantaneous short rate \\(r(t)\\). We may extend this analogy and define the forward hazard rate \\(h(t,T)\\) as:\n\\[\n\\begin{align*}\nQ(t,T) = e^{-\\int_{t}^T h(t,s) ds} \\implies h(t,s) = -\\frac{\\partial}{\\partial s}(\\ln Q(t,s)) = -\\frac{1}{Q(t,s)} \\frac{\\partial Q(t,s)}{\\partial s}\n\\end{align*}\n\\tag{3}\\]\nand the zero hazard rates \\(\\Lambda(t,T)\\) as:\n\\[\n\\begin{align*}\nQ(t,T) = e^{-(T-t)\\Lambda(t,T)}, \\quad \\Lambda(t,T) = -\\frac{1}{T-t}\\ln[Q(t,T)]\n\\end{align*}\n\\tag{4}\\]\nThe survival probability curve \\(Q(t,T)\\), the forward hazard rate curve \\(h(t,T)\\) and the zero hazard rate curve \\(\\Lambda(t,T)\\) are equivalent and we refer to them generically as credit curves.\nThe forward hazard rate represents the (infinitesimal) probability of default between times \\(T\\) and \\(T+dt\\), conditional on survival to time \\(T\\) as seen from time \\(t &lt; T\\). The unconditional probability of default between times \\(T\\) and \\(T+dT\\) (as seen from time \\(t\\)) is given by:\n\\[\n\\mathbb{P}(T &lt; \\tau \\leq T + dT | \\tau &gt; t ) = Q(t,T)h(t)\n\\]"
  },
  {
    "objectID": "posts/cd-swaptions/index.html#pricing-a-cds",
    "href": "posts/cd-swaptions/index.html#pricing-a-cds",
    "title": "Standard CDS Pricing Theory",
    "section": "",
    "text": "THe protection leg of a CDS consists of a (random) payment of \\(N(1 - RR(\\tau))\\) at default time \\(\\tau\\) if this is before expiry of the CDS (time \\(T\\)) and nothing otherwise. The present value of this leg can be written as:\n\\[\n\\begin{align*}\nPV_{prot} = N \\mathbb{E}[e^{-\\int_0^\\tau r(s) ds} (1 - RR(\\tau))1_{\\tau &lt; T}]\n\\end{align*}\n\\tag{5}\\]\nUnder the assumption of a flat recovery curve, this can be rewritten as:\n\\[\n\\begin{align*}\nPV_{prot} = N(1-RR)\\mathbb{E}[e^{-\\int_0^\\tau r(s) ds} 1_{\\tau &lt; T}]\n\\end{align*}\n\\tag{6}\\]\nConsider first a contract that pays \\(N(1-RR)\\), if the default takes place in the small time interval \\([u,u+du]\\). The value of this cash-flow at time \\(0\\):\n\\[\nN(1-RR)\\mathbb{E}[e^{-\\int_0^u r(s)ds } 1_{\\tau\\in[u,u+du]}]\n\\]\nWe can rewrite it as:\n\\[\nN(1-RR)\\mathbb{E}[e^{-\\int_0^u r(s)ds } 1_{\\tau\\in[u,u+du]}] = N(1-RR)\\mathbb{E}[ \\lambda(u) e^{-\\int_0^u (r(s) + \\lambda(s))ds }]\n\\]\nIntegrating over \\(u\\) from \\(0\\) to \\(T\\), we find that:\n\\[\nV_{prot}(0,T) = N(1-RR)\\mathbb{E}\\left[\\int_0^T \\lambda(s) e^{-\\int_0^s (r(u) + \\lambda(u))du} ds \\right]\n\\]\nIf the short rate process and the credit default intensity processes are independent, we can write this expression as:\n\\[\nV_{prot}(0,T) = N(1-RR) \\int_0^T  P(0,s) Q(0,s)\\lambda(s) ds\n\\]\nThe last integral can be easily approximated numerically.\n\n\n\nConsider now the premium leg of a CDS maturing at \\(T\\) with the premium consisting of the periodic coupon payments only (no upfront fee).\nThe premium leg consists of two parts : Regular premium (or coupon) payments (e.g. every three months) up to the expiry of the CDS, which cease if a default occurs, and a single payment of the accrued premium in the event of a default.\nIf there are \\(M\\) remaining payments, with payment times \\(t_1,t_2,\\ldots,t_i,\\ldots,t_M\\), period end times \\(e_1,e_2,\\ldots,e_M\\) and year fractions \\(\\Delta_1, \\Delta_2,\\ldots,\\Delta_M\\), then the present value of the premiums only is:\n\\[\nV_{\\text{premiums-only}}(0,T) = NC\\mathbb{E}\\left[\\sum_{i=1}^M \\Delta_i e^{-\\int_0^{t_i} r(s) ds 1_{e_i &lt; \\tau}}\\right] = NC\\sum_{i=1}^M \\Delta_i P(0,t_i) Q(0,e_i)\n\\tag{7}\\]"
  },
  {
    "objectID": "posts/cd-swaptions/index.html#forward-starting-cds",
    "href": "posts/cd-swaptions/index.html#forward-starting-cds",
    "title": "Standard CDS Pricing Theory",
    "section": "",
    "text": "A forward starting CDS entered into at time \\(t\\) will give protection against the default of an obligor for the period \\(T_e &gt; t\\) to \\(T_m\\), in return for premium payments in that period. If the obligor defaults before the start of the protection \\(\\tau &lt; T_e\\), the contract cancels worthless. This can easily be replicated by entering a long protection CDS with maturity \\(T_m\\), and a short protection position with maturity \\(T_e\\), leaving only the coupons between \\(T_e\\) and \\(T_m\\) to pay. Furthermore, if a default occurs before \\(T_e\\), the protection payments will exactly cancel.\n\\[\nV(t,T_e, T_m) = V(t, T_m) - V(t,T_e)\n\\]"
  },
  {
    "objectID": "posts/cd-swaptions/index.html#references",
    "href": "posts/cd-swaptions/index.html#references",
    "title": "Standard CDS Pricing Theory",
    "section": "References",
    "text": "References\n\nPricing Single-name and Multi-name credit derivatives, Dominic O’ Kane"
  },
  {
    "objectID": "posts/c++-ranges/index.html",
    "href": "posts/c++-ranges/index.html",
    "title": "C++ Ranges",
    "section": "",
    "text": "C++ ranges are a programmatic abstraction for any container/type T that allows iteration over its elements by providing begin and end iterators. A std::ranges::range is defined as a concept that requires a container type T satisfy 2 constraints: it has a begin and an end.\ntemplate&lt; class T &gt;\nconcept range = requires( T& t ) {\n    ranges::begin(t); // equality-preserving for forward iterators\n    ranges::end (t);\n};\nThe C++ ranges library also includes rangified algorithms which are applied to ranges eagerly, and range adaptors that are applied to views lazily.\nThere are three kind of ranges : they can be an abstraction on\n\na pair of iterators\nan iterator and a count\nan iterator and a predicate\n\nHere’s a quick code example:\n#include&lt;iostream&gt;\n#include&lt;vector&gt;\n#include&lt;ranges&gt;\n#include&lt;type_traits&gt;\n\ntemplate&lt;std::ranges::input_range Rng&gt;\nauto sum(Rng&& rng){\n    Rng result{};\n    for(auto&e : rng){\n        result += e;\n    }\n    return result;\n}\n\nint main()\n{\n    std::vector v{1, 2, 3, 4, 5};\n    auto result = sum(v);\n}\nPlay on Compiler Explorer\n\n\n\nYou always accept ranges using universal references. The motivation for this is as follows. Consider the function find_second_occurrence that finds the second occurrence of a character in the string.\nThe function call find_second_occurrence( \"Hello World\", 'l') invokes find_second_occurrence with a string literal. The string literal is copied to a temporary std::string instance. We can bind this to the const lvalue reference str. All good so far. In this instance, we even find the second occurrence of the character l at the index 3. We return str[3]. Except, that once we return, the temporary goes out of scope and is destroyed. So, we have a dangling reference.\n#include&lt;string&gt;\nconst char& find_second_occurrence(const std::string& str, char c){\n    static char not_found = '\\0';\n\n    std::size_t idx = str.find(c);\n    if(idx == std::string::npos) return not_found;\n\n    idx = str.find(c, idx+1);\n    if(idx == std::string::npos) return not_found;\n\n    return str[idx];\n}\nSomething very interesting happens if we change the signature of the function to take a string_view. This function is no longer broken. We are kind of doing the same thing. We call the function with the string literal Hello World. We construct the temporary instance of the string_view. We bind the temporary instance of a string to a const reference. Then, we find the second instance of l. We return reference to that. We destroy the string_view. But, the important difference is that string_view doesn’t hold it’s own data. It just points to some place else. That some place else in this case is a global object - a string literal. Recall, string literals are lvalues. So, we have a reference into a string literal.\n#include&lt;string&gt;\nconst char& find_second_occurrence(const std::string_view& str, char c){\n    static char not_found = '\\0';\n\n    std::size_t idx = str.find(c);\n    if(idx == std::string::npos) return not_found;\n\n    idx = str.find(c, idx+1);\n    if(idx == std::string::npos) return not_found;\n\n    return str[idx];\n}\nThis difference is something that is captured under the name borrowed_range. You probably know std::string_view and std::span. These are ranges that don’t hold their own data, but simply point to some place else. They are called borrowed ranges.\nIf you use range algorithms, they actually take this into account.\nIf you call ranges_find() with a std::string_view, it will work absolutely fine. You will get an iterator back.\nauto it1 = std::ranges::find(std::string_view(\"Hello World!\"), 'o');\n\n// decltype(it1) == std::string_view::iterator\nIf you call ranges_find() with a temporary std::string instance, you will get std::ranges::dangling, which is a special type and this is just a empty type, meaning if you try to do anything with it, you will get a compilation error, because it doesn’t support any operations.\nBut, importantly, if you call ranges_find with an lvalue, meaning that the lifetime of the argument is outside of the function call, well, then the type of the range in the function signature actually doesn’t matter; it would not lead to a dangling reference. It would be considered that the function is borrowing from the outside.\nstd::string str1(\"Hello World\");\nauto it3 = std::ranges::find(str1, 'o');\n// decltype(it3) == std::string::iterator\n\nstd::string_view str2(\"Hello World!\");\nauto it4 = std::ranges::find(str2, 'o');\n// decltype(it4) == std::string_view::iterator\nThis is precisely when const references break down, because we cannot actually distinguish which of these two situations we are actually in:\nvoid fun(const std::string& rng) {}\n\nfun(std::string(\"\"));   // passing a temporary - we are taking ownership\n\nstd::string str;\nfun(str);               // passing an lvalue - we are borrowing\nIf we switch to universal references, we can actually interrogate our argument inside of the function, to see if we are actually borrowing the data, and therefore it’s safe to return references and iterators from it without the danger of dangling or if you are actually taking ownership of the data, in which case, you better not.\ntemplate&lt;typename Rng&gt;\nvoid fun(Rng&& rng) {\n    if constexpr(std::ranges::borrowed_range&lt;decltype(rng)&gt;)\n    {\n        //borrowed range\n    }\n    else{\n        //taking ownership\n    }\n}\n\nfun(std::string(\"\"));       // taking ownership\n\nstd::string str;\nfun(str);                   // borrowing\nfun(\"\");                    // borrowing\nfun(std::string_view(\"\"));  // borrowing\nUniversal references are also necessary, because of views.\n\n\n\nA view is a light-weight object. A view is a range that is:\n\nCheap to move\nCheap to destroy when moved-from\nCheap to copy if copyable\n\nLet’s imagine that, we wish to code up a generic print function:\n#include&lt;ranges&gt;\n#include&lt;iostream&gt;\n#include&lt;concepts&gt;\n#include&lt;vector&gt;\n#include&lt;list&gt;\n\ntemplate&lt;std::ranges::input_range Rng&gt;\nvoid print(Rng&& rng){\n    std::cout &lt;&lt; \"\\n\";\n    for(int i{0}; auto elem : rng){\n        std::cout &lt;&lt; \"\\n\" &lt;&lt; \"[\" &lt;&lt; i++ &lt;&lt; \"] = \" &lt;&lt; elem;\n    }\n}\n\nint main(){\n    std::vector vec{0, 8, 15, 47, 11, 42};\n    std::list lst{0, 8, 15, 47, 11, 42};\n\n    print(vec);\n    print(lst);\n\n    print(std::views::take(vec, 3));    //print first 3 elements\n    print(std::views::take(lst, 3));    //print first 3 elements\n\n    print(vec | std::views::take(3));   //print first 3 elements\n    print(lst | std::views::take(3));   //print first 3 elements\n\n    return 0;\n}\nPlay of Compiler Explorer\nWhat you can do since C++ 20 is, you can say, I can take this print function and instead of printing the entire collection as a whole, we can say, well print a view on this collection.\nSo, I can, for example take the first 3 elements of the vector vec and pass them to the print function. And I can do the same for a list.\nThere is some nice syntax for this. You can pipe the vector or list into the view using the pipe symbol |.\nWe can have real pipelines doing consecutive specifications of what to do with the elements, which elements to use. In C++23, we have a zip_view which can zip the elements of two views.\nA std::views::iota(1) view generates a sequence of values \\(\\{1,2,3,4,5,\\ldots\\}\\), its an infinite sequence and then we have a second collection, a vector \\(\\{0, 8, 15, 47, 11, 42\\}\\). We can zip the elements of these two views together. The elements are then tuples where the first member is the index, the next one is the vector element.\nfor(auto [idx, elem] : std::views::zip(std::views::iota(1), vec))\n    std::cout &lt;&lt; \"\\n\" &lt;&lt;  idx &lt;&lt; \" : \" &lt;&lt; elem;\n\n\n\nViews do not provide expensive member functions.\n#include&lt;ranges&gt;\n#include&lt;iostream&gt;\n#include&lt;concepts&gt;\n#include&lt;vector&gt;\n#include&lt;list&gt;\n\nint main(){\n    std::vector vec{1, 2, 3, 4, 5};\n    std::list lst{1, 2, 3, 4, 5};\n\n    auto vVec = vec | std::views::drop(3);      \n    vVec.begin();                               // fast: vec.begin() + n\n    vVec.empty();                               // fast: vec.size() &lt;= n\n    vVec.size();                                // fast: n &gt;= vec.size() ? 0 : vec.size() - n\n    vVec[2];                                    // vec[n + idx]\n\n    auto vLst = lst | std::views::drop(3);\n    vLst.begin();                               // slow: lst.begin() and n times ++\n    vLst.empty();                               // fast\n    vLst.size();                                // fast\n    //vLst[2];                                  // Very slow, n + idx times ++\n\n    auto vFlt = vec | std::views::filter([](int x){ return x &gt;= 3; });\n    vFlt.begin();                               // slow: pred for all elements until first is true\n    vFlt.empty();                               // slow: pred for all elements until first is true\n    //vFlt.size();                                // Not supported. \n                                                // slow: pred for all elements until first is true\n    //vFlt[2];                                    // Not supported. Slow.\n    return 0;\n}\n\n\nLet’s say, we have a map of composers of classic music. We want to deal with that collection, but only those composers who were born after 1700.\n#include&lt;map&gt;\n#include&lt;ranges&gt;\n#include&lt;concepts&gt;\n#include&lt;iostream&gt;\n\nint main(){\n    std::map&lt;std::string, int&gt; composers{\n        {\"Bach\", 1685},\n        {\"Mozart\", 1756},\n        {\"Beethoven\",1770},\n        {\"Tchaikovsky\",1840},\n        {\"Chopin\",1810},\n        {\"Vivaldi\",1678},\n    };\n\n    for(const auto& elem : composers \n                            | std::views::filter([](std::pair&lt;std::string,int&gt; composer){\n                                return std::get&lt;1&gt;(composer) &gt; 1700;\n                            })\n                            | std::views::take(3)\n                            | std::views::keys\n    )\n        std::cout &lt;&lt; \" - \" &lt;&lt; elem &lt;&lt; \"\\n\";\n    return 0;\n}\nPlay on Compiler Explorer\nLet’s only take the first 3 of those composers and we only need their keys, which are the names. And, let’s use that as the right hand side collection we iterate over in a range-based for loop. So, that’s the output of the program.\n\n\n\n\nIn numerical algorithms, one needs often sequences of numerical values. We can use ranges to implement numerical sequences, dynamical systems and numerical algorithms. The range becomes a proxy for the algorithm.\n#include&lt;iostream&gt;\n#include&lt;type_traits&gt;\n#include&lt;concepts&gt;\n#include&lt;vector&gt;\n#include&lt;ranges&gt;\n#include&lt;cmath&gt;\n#include&lt;numbers&gt;\n#include&lt;functional&gt;\n\nvoid printSequence(auto seq) {\n    std::cout &lt;&lt; \"\\n\";\n    for (auto x : seq)\n        std::cout &lt;&lt; x &lt;&lt; \" \";\n}\nint main()\n{\n    /* Generating numerical sequences */\n    int n{ 1024 };\n    \n    // 0, 1, 2, 3, ...\n    auto seq = std::ranges::iota_view(0, n);\n    printSequence(seq | std::views::take(5));\n\n    // Let's say we are interested to sample a continuous function F\n    // at x_0 = 0.0, x_1 = 0.1, x_2 = 0.2, x_3 = 0.3, ....\n    // We can generate the sampling domain as:\n    double sampling = 0.1;\n    auto seq2 = seq | std::views::transform([sampling](double i) {\n        return sampling * i;\n        });\n\n    printSequence(seq2 | std::views::take(5));\n\n    // f_n = sin(2x_n) + 0.1\n    auto seq3 = seq2 | std::views::transform([](double x_n) {\n        return sin(2 * x_n) + 0.1;\n        });\n\n    printSequence(seq3 | std::views::take(5));\n\n    // We can wrap this logic into a lambda that accepts a sampling (frequency),\n    // an arbitrary function F and generates the sequence F(x[0]), F(x[1]), ...\n    auto sequence = [](int n, double sampling, auto&& F) {\n        auto seq = std::ranges::iota_view(0, n);\n        return seq | std::views::transform([sampling, F](double i) {\n            return F(sampling * i);\n            });\n    };\n\n    /* Great for scientific computing! */\n    printSequence(sequence(1024, 0.1, [](double x) {return sin(2 * x) + 0.1;})\n        | std::views::take(5));\n\n    /* Custom break conditions */\n    auto identity = [](double x) { return x;};\n    auto seq4 = std::views::take_while(sequence(1024, 0.1, identity),\n        [](double x) { return x &lt; 0.5;}\n    );\n\n    printSequence(seq4);\n\n    /* Combine sequences : You get a sequence of tuples */\n    auto result = std::ranges::zip_view(sequence(1024, 0.1, identity), sequence(1024, 0.1, identity));\n\n    return 0;\n}\nPlay on Compiler Explorer\n0 1 2 3 4 \n0 0.1 0.2 0.3 0.4 \n0.1 0.298669 0.489418 0.664642 0.817356 \n0.1 0.298669 0.489418 0.664642 0.817356 \n0 0.1 0.2 0.3 0.4 \n\n\n\nConsider the Newton’s root-finding algorithm. The Newton’s algorithm is:\n\nChoose \\(x_0\\).\nIterate \\(x_{n+1} = x_n - \\frac{f(x_n)}{f'(x_n)}\\)\n\nTo implement numerical schemes like Newton’s, we can hand roll-out a custom range called map_range. A map_range represents the fixed-point iteration algorithm. Given an initial-value \\(x_0\\) and a function \\(f\\), map_range represents the recursive sequence\n\\[x_{n+1} = f(x_n)\\]\nthat is\n\\[\n\\{x_0, f(x_0), f(f(x_0)), \\ldots, \\}\n\\]\nFrom basic analysis, it is a well-known fact, that if \\(f\\) is a contraction, then the sequence \\((y_n)_{n=0}^{\\infty}\\), where \\(y_{n+1} = f(x_n)\\) converges to a finite value.\nmap_range holds three member-variables : the current state m_x, the function m_f and the break condition m_break_condition. map_range must satisfy the std::ranges::range concept.\n#include&lt;iostream&gt;\n#include&lt;type_traits&gt;\n#include&lt;concepts&gt;\n#include&lt;vector&gt;\n#include&lt;ranges&gt;\n#include&lt;cmath&gt;\n#include&lt;numbers&gt;\n#include&lt;functional&gt;\n/* \nWe write a new type map_range that will be used to implement fixed-point iteration in C++.\nBeginning with the initial value x[0], map_range represents the recursive sequence\n\nx[n+1] = F(x[n])\n\nthat is {x[0], F(x[0]), F(F(x[0])), F(F(F(x[0]))), ...\n*/\ntemplate&lt;typename T, typename Func, typename Cond&gt;\nclass map_range{\nprivate:\n    T m_x;\n    Func m_f;\n    Cond m_break_condition;\n\n    struct iterator {\n        map_range* r;\n\n        iterator(map_range * r_) : r{r_} {}\n\n        /* Compute the next iterate x[n+1] = f(x[n]) */\n        iterator& operator++() {\n            r-&gt;m_x = r-&gt;m_f(r-&gt;m_x);\n            if (r-&gt;m_break_condition(r-&gt;m_x))\n                r = nullptr;\n            return (*this);\n        }\n\n        /* Dereference the iterator and return the current state x[n]*/\n        T operator*() {\n            return r-&gt;m_x;\n        }\n\n        bool operator==(iterator & o) {\n            return (o.r == r);\n        }\n\n        bool operator!=(iterator & o)  {\n            return !(o == *this);\n        }\n    };\npublic:\n    map_range(T x, Func func, Cond cond )\n    : m_x {x}\n    , m_f {func}\n    , m_break_condition{cond}\n    { }\n\n    // begin() and end() methods which return iterators\n    iterator begin() { return iterator{ this }; }\n    iterator end()  { return iterator{ nullptr }; }\n    T value() { return m_x; }\n};\n\ntemplate&lt;typename T, typename Func, typename Cond&gt;\nauto make_range_map(T value, Func func, Cond cond) {\n    return map_range(value, func, cond);\n}\n\nint main(){\n    /* Let's solve exp(-x^2 / 2 ) = 0 */\n    std::function&lt;double(double)&gt; f = [](auto x) { return exp(-0.5 * x * x); };\n    std::function&lt;double(double)&gt; df = [](auto x) { return -x * exp(-0.5 * x * x); };\n    auto cond = [f](double x) { return std::abs(f(x)) &lt; 1.0e-12; };\n    auto range = newton_range( 1.0, f, df, cond );\n\n    std::cout &lt;&lt; \"\\n\" &lt;&lt; \"Solving f(x) = exp(-0.5 * x * x) = 0\" &lt;&lt; \"\\n\";\n    for(auto r : range)\n        std::cout &lt;&lt; r &lt;&lt; \" \";\n    return 0;\n}\nPlay on Compiler Explorer"
  },
  {
    "objectID": "posts/c++-ranges/index.html#what-is-a-range",
    "href": "posts/c++-ranges/index.html#what-is-a-range",
    "title": "C++ Ranges",
    "section": "",
    "text": "C++ ranges are a programmatic abstraction for any container/type T that allows iteration over its elements by providing begin and end iterators. A std::ranges::range is defined as a concept that requires a container type T satisfy 2 constraints: it has a begin and an end.\ntemplate&lt; class T &gt;\nconcept range = requires( T& t ) {\n    ranges::begin(t); // equality-preserving for forward iterators\n    ranges::end (t);\n};\nThe C++ ranges library also includes rangified algorithms which are applied to ranges eagerly, and range adaptors that are applied to views lazily.\nThere are three kind of ranges : they can be an abstraction on\n\na pair of iterators\nan iterator and a count\nan iterator and a predicate\n\nHere’s a quick code example:\n#include&lt;iostream&gt;\n#include&lt;vector&gt;\n#include&lt;ranges&gt;\n#include&lt;type_traits&gt;\n\ntemplate&lt;std::ranges::input_range Rng&gt;\nauto sum(Rng&& rng){\n    Rng result{};\n    for(auto&e : rng){\n        result += e;\n    }\n    return result;\n}\n\nint main()\n{\n    std::vector v{1, 2, 3, 4, 5};\n    auto result = sum(v);\n}\nPlay on Compiler Explorer"
  },
  {
    "objectID": "posts/c++-ranges/index.html#using-universal-references-to-accept-ranges",
    "href": "posts/c++-ranges/index.html#using-universal-references-to-accept-ranges",
    "title": "C++ Ranges",
    "section": "",
    "text": "You always accept ranges using universal references. The motivation for this is as follows. Consider the function find_second_occurrence that finds the second occurrence of a character in the string.\nThe function call find_second_occurrence( \"Hello World\", 'l') invokes find_second_occurrence with a string literal. The string literal is copied to a temporary std::string instance. We can bind this to the const lvalue reference str. All good so far. In this instance, we even find the second occurrence of the character l at the index 3. We return str[3]. Except, that once we return, the temporary goes out of scope and is destroyed. So, we have a dangling reference.\n#include&lt;string&gt;\nconst char& find_second_occurrence(const std::string& str, char c){\n    static char not_found = '\\0';\n\n    std::size_t idx = str.find(c);\n    if(idx == std::string::npos) return not_found;\n\n    idx = str.find(c, idx+1);\n    if(idx == std::string::npos) return not_found;\n\n    return str[idx];\n}\nSomething very interesting happens if we change the signature of the function to take a string_view. This function is no longer broken. We are kind of doing the same thing. We call the function with the string literal Hello World. We construct the temporary instance of the string_view. We bind the temporary instance of a string to a const reference. Then, we find the second instance of l. We return reference to that. We destroy the string_view. But, the important difference is that string_view doesn’t hold it’s own data. It just points to some place else. That some place else in this case is a global object - a string literal. Recall, string literals are lvalues. So, we have a reference into a string literal.\n#include&lt;string&gt;\nconst char& find_second_occurrence(const std::string_view& str, char c){\n    static char not_found = '\\0';\n\n    std::size_t idx = str.find(c);\n    if(idx == std::string::npos) return not_found;\n\n    idx = str.find(c, idx+1);\n    if(idx == std::string::npos) return not_found;\n\n    return str[idx];\n}\nThis difference is something that is captured under the name borrowed_range. You probably know std::string_view and std::span. These are ranges that don’t hold their own data, but simply point to some place else. They are called borrowed ranges.\nIf you use range algorithms, they actually take this into account.\nIf you call ranges_find() with a std::string_view, it will work absolutely fine. You will get an iterator back.\nauto it1 = std::ranges::find(std::string_view(\"Hello World!\"), 'o');\n\n// decltype(it1) == std::string_view::iterator\nIf you call ranges_find() with a temporary std::string instance, you will get std::ranges::dangling, which is a special type and this is just a empty type, meaning if you try to do anything with it, you will get a compilation error, because it doesn’t support any operations.\nBut, importantly, if you call ranges_find with an lvalue, meaning that the lifetime of the argument is outside of the function call, well, then the type of the range in the function signature actually doesn’t matter; it would not lead to a dangling reference. It would be considered that the function is borrowing from the outside.\nstd::string str1(\"Hello World\");\nauto it3 = std::ranges::find(str1, 'o');\n// decltype(it3) == std::string::iterator\n\nstd::string_view str2(\"Hello World!\");\nauto it4 = std::ranges::find(str2, 'o');\n// decltype(it4) == std::string_view::iterator\nThis is precisely when const references break down, because we cannot actually distinguish which of these two situations we are actually in:\nvoid fun(const std::string& rng) {}\n\nfun(std::string(\"\"));   // passing a temporary - we are taking ownership\n\nstd::string str;\nfun(str);               // passing an lvalue - we are borrowing\nIf we switch to universal references, we can actually interrogate our argument inside of the function, to see if we are actually borrowing the data, and therefore it’s safe to return references and iterators from it without the danger of dangling or if you are actually taking ownership of the data, in which case, you better not.\ntemplate&lt;typename Rng&gt;\nvoid fun(Rng&& rng) {\n    if constexpr(std::ranges::borrowed_range&lt;decltype(rng)&gt;)\n    {\n        //borrowed range\n    }\n    else{\n        //taking ownership\n    }\n}\n\nfun(std::string(\"\"));       // taking ownership\n\nstd::string str;\nfun(str);                   // borrowing\nfun(\"\");                    // borrowing\nfun(std::string_view(\"\"));  // borrowing\nUniversal references are also necessary, because of views."
  },
  {
    "objectID": "posts/c++-ranges/index.html#c-20-views",
    "href": "posts/c++-ranges/index.html#c-20-views",
    "title": "C++ Ranges",
    "section": "",
    "text": "A view is a light-weight object. A view is a range that is:\n\nCheap to move\nCheap to destroy when moved-from\nCheap to copy if copyable\n\nLet’s imagine that, we wish to code up a generic print function:\n#include&lt;ranges&gt;\n#include&lt;iostream&gt;\n#include&lt;concepts&gt;\n#include&lt;vector&gt;\n#include&lt;list&gt;\n\ntemplate&lt;std::ranges::input_range Rng&gt;\nvoid print(Rng&& rng){\n    std::cout &lt;&lt; \"\\n\";\n    for(int i{0}; auto elem : rng){\n        std::cout &lt;&lt; \"\\n\" &lt;&lt; \"[\" &lt;&lt; i++ &lt;&lt; \"] = \" &lt;&lt; elem;\n    }\n}\n\nint main(){\n    std::vector vec{0, 8, 15, 47, 11, 42};\n    std::list lst{0, 8, 15, 47, 11, 42};\n\n    print(vec);\n    print(lst);\n\n    print(std::views::take(vec, 3));    //print first 3 elements\n    print(std::views::take(lst, 3));    //print first 3 elements\n\n    print(vec | std::views::take(3));   //print first 3 elements\n    print(lst | std::views::take(3));   //print first 3 elements\n\n    return 0;\n}\nPlay of Compiler Explorer\nWhat you can do since C++ 20 is, you can say, I can take this print function and instead of printing the entire collection as a whole, we can say, well print a view on this collection.\nSo, I can, for example take the first 3 elements of the vector vec and pass them to the print function. And I can do the same for a list.\nThere is some nice syntax for this. You can pipe the vector or list into the view using the pipe symbol |.\nWe can have real pipelines doing consecutive specifications of what to do with the elements, which elements to use. In C++23, we have a zip_view which can zip the elements of two views.\nA std::views::iota(1) view generates a sequence of values \\(\\{1,2,3,4,5,\\ldots\\}\\), its an infinite sequence and then we have a second collection, a vector \\(\\{0, 8, 15, 47, 11, 42\\}\\). We can zip the elements of these two views together. The elements are then tuples where the first member is the index, the next one is the vector element.\nfor(auto [idx, elem] : std::views::zip(std::views::iota(1), vec))\n    std::cout &lt;&lt; \"\\n\" &lt;&lt;  idx &lt;&lt; \" : \" &lt;&lt; elem;"
  },
  {
    "objectID": "posts/c++-ranges/index.html#member-functions-of-views",
    "href": "posts/c++-ranges/index.html#member-functions-of-views",
    "title": "C++ Ranges",
    "section": "",
    "text": "Views do not provide expensive member functions.\n#include&lt;ranges&gt;\n#include&lt;iostream&gt;\n#include&lt;concepts&gt;\n#include&lt;vector&gt;\n#include&lt;list&gt;\n\nint main(){\n    std::vector vec{1, 2, 3, 4, 5};\n    std::list lst{1, 2, 3, 4, 5};\n\n    auto vVec = vec | std::views::drop(3);      \n    vVec.begin();                               // fast: vec.begin() + n\n    vVec.empty();                               // fast: vec.size() &lt;= n\n    vVec.size();                                // fast: n &gt;= vec.size() ? 0 : vec.size() - n\n    vVec[2];                                    // vec[n + idx]\n\n    auto vLst = lst | std::views::drop(3);\n    vLst.begin();                               // slow: lst.begin() and n times ++\n    vLst.empty();                               // fast\n    vLst.size();                                // fast\n    //vLst[2];                                  // Very slow, n + idx times ++\n\n    auto vFlt = vec | std::views::filter([](int x){ return x &gt;= 3; });\n    vFlt.begin();                               // slow: pred for all elements until first is true\n    vFlt.empty();                               // slow: pred for all elements until first is true\n    //vFlt.size();                                // Not supported. \n                                                // slow: pred for all elements until first is true\n    //vFlt[2];                                    // Not supported. Slow.\n    return 0;\n}\n\n\nLet’s say, we have a map of composers of classic music. We want to deal with that collection, but only those composers who were born after 1700.\n#include&lt;map&gt;\n#include&lt;ranges&gt;\n#include&lt;concepts&gt;\n#include&lt;iostream&gt;\n\nint main(){\n    std::map&lt;std::string, int&gt; composers{\n        {\"Bach\", 1685},\n        {\"Mozart\", 1756},\n        {\"Beethoven\",1770},\n        {\"Tchaikovsky\",1840},\n        {\"Chopin\",1810},\n        {\"Vivaldi\",1678},\n    };\n\n    for(const auto& elem : composers \n                            | std::views::filter([](std::pair&lt;std::string,int&gt; composer){\n                                return std::get&lt;1&gt;(composer) &gt; 1700;\n                            })\n                            | std::views::take(3)\n                            | std::views::keys\n    )\n        std::cout &lt;&lt; \" - \" &lt;&lt; elem &lt;&lt; \"\\n\";\n    return 0;\n}\nPlay on Compiler Explorer\nLet’s only take the first 3 of those composers and we only need their keys, which are the names. And, let’s use that as the right hand side collection we iterate over in a range-based for loop. So, that’s the output of the program."
  },
  {
    "objectID": "posts/c++-ranges/index.html#numerical-sequences",
    "href": "posts/c++-ranges/index.html#numerical-sequences",
    "title": "C++ Ranges",
    "section": "",
    "text": "In numerical algorithms, one needs often sequences of numerical values. We can use ranges to implement numerical sequences, dynamical systems and numerical algorithms. The range becomes a proxy for the algorithm.\n#include&lt;iostream&gt;\n#include&lt;type_traits&gt;\n#include&lt;concepts&gt;\n#include&lt;vector&gt;\n#include&lt;ranges&gt;\n#include&lt;cmath&gt;\n#include&lt;numbers&gt;\n#include&lt;functional&gt;\n\nvoid printSequence(auto seq) {\n    std::cout &lt;&lt; \"\\n\";\n    for (auto x : seq)\n        std::cout &lt;&lt; x &lt;&lt; \" \";\n}\nint main()\n{\n    /* Generating numerical sequences */\n    int n{ 1024 };\n    \n    // 0, 1, 2, 3, ...\n    auto seq = std::ranges::iota_view(0, n);\n    printSequence(seq | std::views::take(5));\n\n    // Let's say we are interested to sample a continuous function F\n    // at x_0 = 0.0, x_1 = 0.1, x_2 = 0.2, x_3 = 0.3, ....\n    // We can generate the sampling domain as:\n    double sampling = 0.1;\n    auto seq2 = seq | std::views::transform([sampling](double i) {\n        return sampling * i;\n        });\n\n    printSequence(seq2 | std::views::take(5));\n\n    // f_n = sin(2x_n) + 0.1\n    auto seq3 = seq2 | std::views::transform([](double x_n) {\n        return sin(2 * x_n) + 0.1;\n        });\n\n    printSequence(seq3 | std::views::take(5));\n\n    // We can wrap this logic into a lambda that accepts a sampling (frequency),\n    // an arbitrary function F and generates the sequence F(x[0]), F(x[1]), ...\n    auto sequence = [](int n, double sampling, auto&& F) {\n        auto seq = std::ranges::iota_view(0, n);\n        return seq | std::views::transform([sampling, F](double i) {\n            return F(sampling * i);\n            });\n    };\n\n    /* Great for scientific computing! */\n    printSequence(sequence(1024, 0.1, [](double x) {return sin(2 * x) + 0.1;})\n        | std::views::take(5));\n\n    /* Custom break conditions */\n    auto identity = [](double x) { return x;};\n    auto seq4 = std::views::take_while(sequence(1024, 0.1, identity),\n        [](double x) { return x &lt; 0.5;}\n    );\n\n    printSequence(seq4);\n\n    /* Combine sequences : You get a sequence of tuples */\n    auto result = std::ranges::zip_view(sequence(1024, 0.1, identity), sequence(1024, 0.1, identity));\n\n    return 0;\n}\nPlay on Compiler Explorer\n0 1 2 3 4 \n0 0.1 0.2 0.3 0.4 \n0.1 0.298669 0.489418 0.664642 0.817356 \n0.1 0.298669 0.489418 0.664642 0.817356 \n0 0.1 0.2 0.3 0.4"
  },
  {
    "objectID": "posts/c++-ranges/index.html#custom-ranges",
    "href": "posts/c++-ranges/index.html#custom-ranges",
    "title": "C++ Ranges",
    "section": "",
    "text": "Consider the Newton’s root-finding algorithm. The Newton’s algorithm is:\n\nChoose \\(x_0\\).\nIterate \\(x_{n+1} = x_n - \\frac{f(x_n)}{f'(x_n)}\\)\n\nTo implement numerical schemes like Newton’s, we can hand roll-out a custom range called map_range. A map_range represents the fixed-point iteration algorithm. Given an initial-value \\(x_0\\) and a function \\(f\\), map_range represents the recursive sequence\n\\[x_{n+1} = f(x_n)\\]\nthat is\n\\[\n\\{x_0, f(x_0), f(f(x_0)), \\ldots, \\}\n\\]\nFrom basic analysis, it is a well-known fact, that if \\(f\\) is a contraction, then the sequence \\((y_n)_{n=0}^{\\infty}\\), where \\(y_{n+1} = f(x_n)\\) converges to a finite value.\nmap_range holds three member-variables : the current state m_x, the function m_f and the break condition m_break_condition. map_range must satisfy the std::ranges::range concept.\n#include&lt;iostream&gt;\n#include&lt;type_traits&gt;\n#include&lt;concepts&gt;\n#include&lt;vector&gt;\n#include&lt;ranges&gt;\n#include&lt;cmath&gt;\n#include&lt;numbers&gt;\n#include&lt;functional&gt;\n/* \nWe write a new type map_range that will be used to implement fixed-point iteration in C++.\nBeginning with the initial value x[0], map_range represents the recursive sequence\n\nx[n+1] = F(x[n])\n\nthat is {x[0], F(x[0]), F(F(x[0])), F(F(F(x[0]))), ...\n*/\ntemplate&lt;typename T, typename Func, typename Cond&gt;\nclass map_range{\nprivate:\n    T m_x;\n    Func m_f;\n    Cond m_break_condition;\n\n    struct iterator {\n        map_range* r;\n\n        iterator(map_range * r_) : r{r_} {}\n\n        /* Compute the next iterate x[n+1] = f(x[n]) */\n        iterator& operator++() {\n            r-&gt;m_x = r-&gt;m_f(r-&gt;m_x);\n            if (r-&gt;m_break_condition(r-&gt;m_x))\n                r = nullptr;\n            return (*this);\n        }\n\n        /* Dereference the iterator and return the current state x[n]*/\n        T operator*() {\n            return r-&gt;m_x;\n        }\n\n        bool operator==(iterator & o) {\n            return (o.r == r);\n        }\n\n        bool operator!=(iterator & o)  {\n            return !(o == *this);\n        }\n    };\npublic:\n    map_range(T x, Func func, Cond cond )\n    : m_x {x}\n    , m_f {func}\n    , m_break_condition{cond}\n    { }\n\n    // begin() and end() methods which return iterators\n    iterator begin() { return iterator{ this }; }\n    iterator end()  { return iterator{ nullptr }; }\n    T value() { return m_x; }\n};\n\ntemplate&lt;typename T, typename Func, typename Cond&gt;\nauto make_range_map(T value, Func func, Cond cond) {\n    return map_range(value, func, cond);\n}\n\nint main(){\n    /* Let's solve exp(-x^2 / 2 ) = 0 */\n    std::function&lt;double(double)&gt; f = [](auto x) { return exp(-0.5 * x * x); };\n    std::function&lt;double(double)&gt; df = [](auto x) { return -x * exp(-0.5 * x * x); };\n    auto cond = [f](double x) { return std::abs(f(x)) &lt; 1.0e-12; };\n    auto range = newton_range( 1.0, f, df, cond );\n\n    std::cout &lt;&lt; \"\\n\" &lt;&lt; \"Solving f(x) = exp(-0.5 * x * x) = 0\" &lt;&lt; \"\\n\";\n    for(auto r : range)\n        std::cout &lt;&lt; r &lt;&lt; \" \";\n    return 0;\n}\nPlay on Compiler Explorer"
  },
  {
    "objectID": "posts/black-scholes-formula-for-a-european-call/index.html",
    "href": "posts/black-scholes-formula-for-a-european-call/index.html",
    "title": "Black Scholes Formula for a European Call",
    "section": "",
    "text": "The mean rate of growth of all assets under the risk-neutral measure \\(\\mathbb{Q}\\) is risk-free rate \\(r\\).\nThe stock price process has the \\(\\mathbb{Q}\\)-dynamics:\n\\[dS_t = r S_t dt + \\sigma S_t dW^{\\mathbb{Q}}(t) \\tag{1}\\]\nThe solution to this SDE is:\n\\[S(t) = S(0)\\exp \\left[ \\left(r - \\frac{\\sigma^2}{2}\\right)t + \\sigma W^{\\mathbb{Q}}(t)\\right]\\tag{2}\\]\nConsider a call option with maturity time \\(T\\). Then, the stock price at \\(T\\) is:\n\\[S(T) = S(0)\\exp \\left[ \\left(r - \\frac{\\sigma^2}{2}\\right)T + \\sigma W^{\\mathbb{Q}}(T)\\right]\\tag{3}\\]\nDenoting \\(\\tau = T - t\\), we have:\n\\[S(T) = S(t)\\exp \\left[ \\left(r - \\frac{\\sigma^2}{2}\\right)\\tau + \\sigma (W^{\\mathbb{Q}}(T)-W^{\\mathbb{Q}}(t))\\right]\\tag{4}\\]\nSince, \\(W^{\\mathbb{Q}}(T)-W^{\\mathbb{Q}}(t)\\) is a gaussian random variable with mean \\(0\\) and variance \\(\\tau = T-t\\), we can write \\(-(W^{\\mathbb{Q}}(T)-W^{\\mathbb{Q}}(t)) = \\sqrt{\\tau}Z\\), where \\(Z\\) is a standard normal random variable. Thus,\n\\[S(T) = S(t)\\exp \\left[ \\left(r - \\frac{\\sigma^2}{2}\\right)\\tau - \\sigma \\sqrt{\\tau}Z\\right]\\tag{5}\\]\nBy the risk-neutral pricing formula, the time-\\(t\\) price of the European call option is:\n\\[\n\\begin{align*}\nV(t) &= \\mathbb{E}^{\\mathbb{Q}}\\left[e^{-r(T-t)}\\max(S(T) - K,0)|\\mathcal{F}_t\\right] \\\\\n&= e^{-r(T-t)}\\mathbb{E}^{\\mathbb{Q}}\\left[\\left(S(t)\\exp \\left\\{ \\left(r - \\frac{\\sigma^2}{2}\\right)\\tau - \\sigma \\sqrt{\\tau}Z\\right\\} - K\\right)\\cdot 1_{S(T)&gt;K}|\\mathcal{F}_t\\right]\\\\\n&= e^{-r(T-t)}\\mathbb{E}^{\\mathbb{Q}}\\left[\\left(S(t)\\exp \\left\\{ \\left(r - \\frac{\\sigma^2}{2}\\right)\\tau - \\sigma \\sqrt{\\tau}Z\\right\\} - K\\right)\\cdot 1_{S_t e^{(r-\\sigma^2/2) - \\sigma\\tau Z}&gt;K}\\right]\n\\end{align*}\n\\]\nIn the last-but-one step, everything is \\(\\mathcal{F}_t\\)-measurable.\nThe domain of integration is all \\(z\\) satisfying:\n\\[\n\\begin{align*}\nS(t)\\exp \\left[ \\left(r - \\frac{\\sigma^2}{2}\\right)\\tau - \\sigma \\sqrt{\\tau}Z\\right] &&gt;  K\\\\\n\\log \\frac{S(t)}{K} + \\left(r - \\frac{\\sigma^2}{2}\\right)\\tau  &&gt; \\sigma \\sqrt{\\tau}Z\n\\end{align*}\n\\]\nDefine \\(d_{-} = \\frac{\\log \\frac{S(t)}{K} +(r-\\sigma^2/2)\\tau}{\\sigma\\sqrt{\\tau}}\\).\nThen, the region \\(D\\) is:\n\\[Z &lt; d_{-}\\]\nSo, we can expand the expectation in (6) as:\n\\[\n\\begin{align*}\nV(t) &=  \\int_{-\\infty}^{d_{-}} e^{-r\\tau}\\left(S(t)\\exp \\left\\{\\left(r - \\frac{\\sigma^2}{2}\\right)\\tau - \\sigma \\sqrt{\\tau}z \\right\\} - K\\right)d\\mathbb{Q} \\\\\n&=\\int_{-\\infty}^{d_{-}} e^{-r\\tau}\\left(S(t)\\exp \\left\\{ \\left(r - \\frac{\\sigma^2}{2}\\right)\\tau - \\sigma \\sqrt{\\tau}z\\right\\} - K\\right) f_Z^{\\mathbb{Q}}(z) dz \\\\\n&=\\frac{1}{\\sqrt{2\\pi}}\\int_{-\\infty}^{d_{-}}e^{-r\\tau} \\left(S(t)\\exp \\left\\{ \\left(r - \\frac{\\sigma^2}{2}\\right)\\tau - \\sigma \\sqrt{\\tau}z\\right\\} - K\\right) e^{-\\frac{z^2}{2}} dz\n\\\\\n&=\\frac{1}{\\sqrt{2\\pi}}\\int_{-\\infty}^{d_{-}} e^{-r\\tau}S(t)\\exp \\left\\{ \\left(r - \\frac{\\sigma^2}{2}\\right)\\tau - \\sigma \\sqrt{\\tau}z\\right\\}e^{-\\frac{z^2}{2}} dz \\\\\n&- Ke^{-r\\tau}\\cdot \\frac{1}{\\sqrt{2\\pi}}\\int_{-\\infty}^{d_{-}} e^{-\\frac{z^2}{2}} dz \\\\\n&=\\frac{1}{\\sqrt{2\\pi}}\\int_{-\\infty}^{d_{-}} e^{-r\\tau}S(t)\\exp \\left\\{ \\left(r - \\frac{\\sigma^2}{2}\\right)\\tau - \\sigma \\sqrt{\\tau}z\\right\\}e^{-\\frac{z^2}{2}} dz - Ke^{-r\\tau}\\Phi(d_{-})\\tag{7}\n\\end{align*}\n\\]\nWe have:\n\\[\n\\begin{align*}\n&\\exp \\left[-\\frac{\\sigma^2}{2}\\tau - \\sigma\\sqrt{\\tau} z - \\frac{z^2}{2}\\right]\\\\\n=&\\exp\\left[-\\frac{\\sigma^2 \\tau + 2\\sigma \\sqrt{\\tau}z + z^2}{2}\\right]\\\\\n=&\\exp\\left[-\\frac{(z+\\sigma\\sqrt{\\tau})^2}{2}\\right] \\tag{8}\n\\end{align*}\n\\]\nSubstituting (8) into (7), we get:\n\\[\n\\begin{align*}\nV(t) &=\\frac{1}{\\sqrt{2\\pi}}\\int_{-\\infty}^{d_{-}} S(t)\\exp\\left[-\\frac{(z+\\sigma\\sqrt{\\tau})^2}{2}\\right] dz - Ke^{-r\\tau}\\Phi(d_{-}) \\tag{9}\n\\end{align*}\n\\]\nPut \\(u = z + \\sigma \\sqrt{\\tau}\\). Then, \\(dz = du\\). The upper limit of integration is \\(d_{+} = d_{-} + \\sigma \\sqrt{\\tau}\\), which is:\n\\[\n\\begin{align*}\nd_{+} &=\\frac{\\log \\frac{S(t)}{K} + (r-\\sigma^2/2)\\tau}{\\sigma \\sqrt{\\tau}} + \\sigma \\sqrt{\\tau}\\\\\n&= \\frac{\\log \\frac{S(t)}{K} + (r+\\sigma^2/2)\\tau}{\\sigma \\sqrt{\\tau}}\n\\end{align*}\n\\]\nSo, the equation (9) can be written as:\n\\[\n\\begin{align*}\nV(t) &=\\frac{1}{\\sqrt{2\\pi}}\\int_{-\\infty}^{d_{+}} S(t)e^{-\\frac{u^2}{2}} du - Ke^{-r\\tau}\\Phi(d_{-}) \\\\\n&= S(t)\\Phi(d_{+}) - Ke^{-r\\tau} \\Phi(d_{-})\n\\end{align*}\n\\]"
  },
  {
    "objectID": "posts/black-scholes-formula-for-a-european-call/index.html#the-black-scholes-formula-for-a-european-call",
    "href": "posts/black-scholes-formula-for-a-european-call/index.html#the-black-scholes-formula-for-a-european-call",
    "title": "Black Scholes Formula for a European Call",
    "section": "",
    "text": "The mean rate of growth of all assets under the risk-neutral measure \\(\\mathbb{Q}\\) is risk-free rate \\(r\\).\nThe stock price process has the \\(\\mathbb{Q}\\)-dynamics:\n\\[dS_t = r S_t dt + \\sigma S_t dW^{\\mathbb{Q}}(t) \\tag{1}\\]\nThe solution to this SDE is:\n\\[S(t) = S(0)\\exp \\left[ \\left(r - \\frac{\\sigma^2}{2}\\right)t + \\sigma W^{\\mathbb{Q}}(t)\\right]\\tag{2}\\]\nConsider a call option with maturity time \\(T\\). Then, the stock price at \\(T\\) is:\n\\[S(T) = S(0)\\exp \\left[ \\left(r - \\frac{\\sigma^2}{2}\\right)T + \\sigma W^{\\mathbb{Q}}(T)\\right]\\tag{3}\\]\nDenoting \\(\\tau = T - t\\), we have:\n\\[S(T) = S(t)\\exp \\left[ \\left(r - \\frac{\\sigma^2}{2}\\right)\\tau + \\sigma (W^{\\mathbb{Q}}(T)-W^{\\mathbb{Q}}(t))\\right]\\tag{4}\\]\nSince, \\(W^{\\mathbb{Q}}(T)-W^{\\mathbb{Q}}(t)\\) is a gaussian random variable with mean \\(0\\) and variance \\(\\tau = T-t\\), we can write \\(-(W^{\\mathbb{Q}}(T)-W^{\\mathbb{Q}}(t)) = \\sqrt{\\tau}Z\\), where \\(Z\\) is a standard normal random variable. Thus,\n\\[S(T) = S(t)\\exp \\left[ \\left(r - \\frac{\\sigma^2}{2}\\right)\\tau - \\sigma \\sqrt{\\tau}Z\\right]\\tag{5}\\]\nBy the risk-neutral pricing formula, the time-\\(t\\) price of the European call option is:\n\\[\n\\begin{align*}\nV(t) &= \\mathbb{E}^{\\mathbb{Q}}\\left[e^{-r(T-t)}\\max(S(T) - K,0)|\\mathcal{F}_t\\right] \\\\\n&= e^{-r(T-t)}\\mathbb{E}^{\\mathbb{Q}}\\left[\\left(S(t)\\exp \\left\\{ \\left(r - \\frac{\\sigma^2}{2}\\right)\\tau - \\sigma \\sqrt{\\tau}Z\\right\\} - K\\right)\\cdot 1_{S(T)&gt;K}|\\mathcal{F}_t\\right]\\\\\n&= e^{-r(T-t)}\\mathbb{E}^{\\mathbb{Q}}\\left[\\left(S(t)\\exp \\left\\{ \\left(r - \\frac{\\sigma^2}{2}\\right)\\tau - \\sigma \\sqrt{\\tau}Z\\right\\} - K\\right)\\cdot 1_{S_t e^{(r-\\sigma^2/2) - \\sigma\\tau Z}&gt;K}\\right]\n\\end{align*}\n\\]\nIn the last-but-one step, everything is \\(\\mathcal{F}_t\\)-measurable.\nThe domain of integration is all \\(z\\) satisfying:\n\\[\n\\begin{align*}\nS(t)\\exp \\left[ \\left(r - \\frac{\\sigma^2}{2}\\right)\\tau - \\sigma \\sqrt{\\tau}Z\\right] &&gt;  K\\\\\n\\log \\frac{S(t)}{K} + \\left(r - \\frac{\\sigma^2}{2}\\right)\\tau  &&gt; \\sigma \\sqrt{\\tau}Z\n\\end{align*}\n\\]\nDefine \\(d_{-} = \\frac{\\log \\frac{S(t)}{K} +(r-\\sigma^2/2)\\tau}{\\sigma\\sqrt{\\tau}}\\).\nThen, the region \\(D\\) is:\n\\[Z &lt; d_{-}\\]\nSo, we can expand the expectation in (6) as:\n\\[\n\\begin{align*}\nV(t) &=  \\int_{-\\infty}^{d_{-}} e^{-r\\tau}\\left(S(t)\\exp \\left\\{\\left(r - \\frac{\\sigma^2}{2}\\right)\\tau - \\sigma \\sqrt{\\tau}z \\right\\} - K\\right)d\\mathbb{Q} \\\\\n&=\\int_{-\\infty}^{d_{-}} e^{-r\\tau}\\left(S(t)\\exp \\left\\{ \\left(r - \\frac{\\sigma^2}{2}\\right)\\tau - \\sigma \\sqrt{\\tau}z\\right\\} - K\\right) f_Z^{\\mathbb{Q}}(z) dz \\\\\n&=\\frac{1}{\\sqrt{2\\pi}}\\int_{-\\infty}^{d_{-}}e^{-r\\tau} \\left(S(t)\\exp \\left\\{ \\left(r - \\frac{\\sigma^2}{2}\\right)\\tau - \\sigma \\sqrt{\\tau}z\\right\\} - K\\right) e^{-\\frac{z^2}{2}} dz\n\\\\\n&=\\frac{1}{\\sqrt{2\\pi}}\\int_{-\\infty}^{d_{-}} e^{-r\\tau}S(t)\\exp \\left\\{ \\left(r - \\frac{\\sigma^2}{2}\\right)\\tau - \\sigma \\sqrt{\\tau}z\\right\\}e^{-\\frac{z^2}{2}} dz \\\\\n&- Ke^{-r\\tau}\\cdot \\frac{1}{\\sqrt{2\\pi}}\\int_{-\\infty}^{d_{-}} e^{-\\frac{z^2}{2}} dz \\\\\n&=\\frac{1}{\\sqrt{2\\pi}}\\int_{-\\infty}^{d_{-}} e^{-r\\tau}S(t)\\exp \\left\\{ \\left(r - \\frac{\\sigma^2}{2}\\right)\\tau - \\sigma \\sqrt{\\tau}z\\right\\}e^{-\\frac{z^2}{2}} dz - Ke^{-r\\tau}\\Phi(d_{-})\\tag{7}\n\\end{align*}\n\\]\nWe have:\n\\[\n\\begin{align*}\n&\\exp \\left[-\\frac{\\sigma^2}{2}\\tau - \\sigma\\sqrt{\\tau} z - \\frac{z^2}{2}\\right]\\\\\n=&\\exp\\left[-\\frac{\\sigma^2 \\tau + 2\\sigma \\sqrt{\\tau}z + z^2}{2}\\right]\\\\\n=&\\exp\\left[-\\frac{(z+\\sigma\\sqrt{\\tau})^2}{2}\\right] \\tag{8}\n\\end{align*}\n\\]\nSubstituting (8) into (7), we get:\n\\[\n\\begin{align*}\nV(t) &=\\frac{1}{\\sqrt{2\\pi}}\\int_{-\\infty}^{d_{-}} S(t)\\exp\\left[-\\frac{(z+\\sigma\\sqrt{\\tau})^2}{2}\\right] dz - Ke^{-r\\tau}\\Phi(d_{-}) \\tag{9}\n\\end{align*}\n\\]\nPut \\(u = z + \\sigma \\sqrt{\\tau}\\). Then, \\(dz = du\\). The upper limit of integration is \\(d_{+} = d_{-} + \\sigma \\sqrt{\\tau}\\), which is:\n\\[\n\\begin{align*}\nd_{+} &=\\frac{\\log \\frac{S(t)}{K} + (r-\\sigma^2/2)\\tau}{\\sigma \\sqrt{\\tau}} + \\sigma \\sqrt{\\tau}\\\\\n&= \\frac{\\log \\frac{S(t)}{K} + (r+\\sigma^2/2)\\tau}{\\sigma \\sqrt{\\tau}}\n\\end{align*}\n\\]\nSo, the equation (9) can be written as:\n\\[\n\\begin{align*}\nV(t) &=\\frac{1}{\\sqrt{2\\pi}}\\int_{-\\infty}^{d_{+}} S(t)e^{-\\frac{u^2}{2}} du - Ke^{-r\\tau}\\Phi(d_{-}) \\\\\n&= S(t)\\Phi(d_{+}) - Ke^{-r\\tau} \\Phi(d_{-})\n\\end{align*}\n\\]"
  },
  {
    "objectID": "posts/black-scholes-formula-for-a-european-call/index.html#appendix",
    "href": "posts/black-scholes-formula-for-a-european-call/index.html#appendix",
    "title": "Black Scholes Formula for a European Call",
    "section": "Appendix",
    "text": "Appendix\nLemma. The discounted stock-price process \\((D(t)S(t),t\\geq 0)\\) is a \\(\\mathbb{Q}\\)-martingale.\nSuppose we have a risk-free money-market account with the dynamics:\n\\[dM(t) = rM(t)dt\\]\nand the dynamics of the stock-price process is:\n\\[dS(t) = \\mu S(t) dt + \\sigma S(t) dW^\\mathbb{P}(t)\\]\nThus, the discounting process is:\n\\[dD(t) = -rD(t)dt\\]\nwhere the instantaneous interest rate \\(r\\) is a constant.\nBy Ito’s product rule:\n\\[\n\\begin{align*}\nd(D(t)S(t)) &= dD(t) S(t) + D(t)dS(t)\\\\\n&= -rD(t)S(t)dt + D(t)(\\mu S(t) dt + \\sigma S(t)dW^\\mathbb{P}(t))\\\\\n&= D(t)S(t)((\\mu - r)dt + \\sigma dW^\\mathbb{P}(t))\\\\\n\\end{align*}\n\\]\nWe are interested to write:\n\\[\n\\begin{align*}\nd(D(t)S(t)) &= D(t)S(t)\\sigma dW^\\mathbb{Q}(t)\n\\end{align*}\n\\]\nComparing the right hand sides, we have: \\[\n\\begin{align*}\n\\sigma dW^\\mathbb{Q}(t) &= (\\mu - r)dt + \\sigma dW^\\mathbb{P}(t)\n\\end{align*}\n\\]\nLet’s define:\n\\[dW^\\mathbb{Q}(t) = \\theta dt + dW^\\mathbb{P}(t)\\]\nwhere \\(\\theta = (\\mu - r)/\\sigma\\) and the Radon-Nikodym derivative \\(Z\\) as:\n\\[Z = \\exp\\left[-\\int_0^T \\theta dW^\\mathbb{P}(u) - \\frac{1}{2}\\int_0^T \\theta^2 du \\right]\\]\nBy the Girsanov theorem, \\(W^\\mathbb{Q}(t)\\) is a \\(\\mathbb{Q}\\)-standard brownian motion. Hence, we can write:\n\\[\n\\begin{align*}\nd(D(t)S(t)) &= D(t)S(t)\\sigma dW^\\mathbb{Q}(t)\n\\end{align*}\n\\]\nSince the Ito integral is a martingale, \\(D(t)S(t)\\) is a \\(\\mathbb{Q}\\)-martingale. This closes the proof.\nClaim. The \\(\\mathbb{Q}\\)-dynamics of \\(S_t\\) satisfy :\n\\[dS(t) = rS(t) dt + \\sigma S(t) dW^{\\mathbb{Q}}(t)\\]\nProof.\nWe have:\n\\[\n\\begin{align*}dS(t) &= d(S(t)D(t)M(t))\\\\\n&= d(S(t)D(t))M(t) + S(t)D(t)dM(t)\\\\\n&= D(t)M(t) S(t)\\sigma dW^\\mathbb{Q}(t) + S(t)D(t)r M(t)dt\\\\\n&= S(t)(rdt + \\sigma dW^\\mathbb{Q}(t))\n\\end{align*}\n\\]\nWe can easily solve this linear SDE; its solution is:\n\\[S(t) = S(0)\\exp\\left[\\left(\\mu - \\frac{\\sigma^2}{2}\\right)dt + \\sigma W^\\mathbb{Q}(t)\\right]\\]"
  },
  {
    "objectID": "posts/atomic-operations/index.html",
    "href": "posts/atomic-operations/index.html",
    "title": "C++ Atomics",
    "section": "",
    "text": "Atomic operations are indivisible. Consider, for instance a shared variable counter that is initialized to 0. Consider the assembly instructions corresponding to the increment operation count++.\nint counter {0};\n\nint main(){\n    counter++;\n\n    return 0;\n}\nPlay on Compiler Explorer\nLook at the assembler code generated by the compiler and the instructions the CPU executes.\ncounter:\n        .zero   4\nmain:\n        push    rbp\n        mov     rbp, rsp\n        mov     eax, DWORD PTR counter[rip]\n        add     eax, 1\n        mov     DWORD PTR counter[rip], eax\n        mov     eax, 0\n        pop     rbp\n        ret\nThe code increments a global counter. The statement on line 6, copies the value stored in the counter to the eax register, line 7 adds 1 to the value stored in eax, and finally line 8 copies back the contents of the eax register to the counter variable. So, a thread could execute line 6 and then be scheduled out, and another thread execute all threee instructions after that. When the first thread finishes increment the result, the counter will be increment just once and thus the result will incorrect.\nThe following code does the same: it increments a global counter. This time, though, we use an atomic type and operations.\n#include &lt;atomic&gt;\nstd::atomic&lt;int&gt; counter {0};\n\nint main(){\n    counter++;\n    return 0;\n}\nPlay on Compiler Explorer\nI will explain the std::atomic&lt;int&gt; type and the atomic increment operation later. The generated assembly code is the following:\nlock add        DWORD PTR counter[rip], 1\nJust one instruction has been generated to add 1 to the value stored in the counter variable. The lock prefix here means that the following instruction (in this case add) is going to be executed atomically. Hence, a thread cannot be interrupted in the middle of incrementing the counter.\nAtomic operations allow threads to read, modify and write indivisibly and can also be used as synchronization primitives. Atomic operations must be provided by the CPU (as in the lock add instruction)."
  },
  {
    "objectID": "posts/atomic-operations/index.html#introduction",
    "href": "posts/atomic-operations/index.html#introduction",
    "title": "C++ Atomics",
    "section": "",
    "text": "Atomic operations are indivisible. Consider, for instance a shared variable counter that is initialized to 0. Consider the assembly instructions corresponding to the increment operation count++.\nint counter {0};\n\nint main(){\n    counter++;\n\n    return 0;\n}\nPlay on Compiler Explorer\nLook at the assembler code generated by the compiler and the instructions the CPU executes.\ncounter:\n        .zero   4\nmain:\n        push    rbp\n        mov     rbp, rsp\n        mov     eax, DWORD PTR counter[rip]\n        add     eax, 1\n        mov     DWORD PTR counter[rip], eax\n        mov     eax, 0\n        pop     rbp\n        ret\nThe code increments a global counter. The statement on line 6, copies the value stored in the counter to the eax register, line 7 adds 1 to the value stored in eax, and finally line 8 copies back the contents of the eax register to the counter variable. So, a thread could execute line 6 and then be scheduled out, and another thread execute all threee instructions after that. When the first thread finishes increment the result, the counter will be increment just once and thus the result will incorrect.\nThe following code does the same: it increments a global counter. This time, though, we use an atomic type and operations.\n#include &lt;atomic&gt;\nstd::atomic&lt;int&gt; counter {0};\n\nint main(){\n    counter++;\n    return 0;\n}\nPlay on Compiler Explorer\nI will explain the std::atomic&lt;int&gt; type and the atomic increment operation later. The generated assembly code is the following:\nlock add        DWORD PTR counter[rip], 1\nJust one instruction has been generated to add 1 to the value stored in the counter variable. The lock prefix here means that the following instruction (in this case add) is going to be executed atomically. Hence, a thread cannot be interrupted in the middle of incrementing the counter.\nAtomic operations allow threads to read, modify and write indivisibly and can also be used as synchronization primitives. Atomic operations must be provided by the CPU (as in the lock add instruction)."
  },
  {
    "objectID": "posts/atomic-operations/index.html#non-blocking-data-structures",
    "href": "posts/atomic-operations/index.html#non-blocking-data-structures",
    "title": "C++ Atomics",
    "section": "Non-Blocking Data-Structures",
    "text": "Non-Blocking Data-Structures\nData-structures synchronized with locks are called blocking data-structures because threads are blocked (by the operating system), waiting until the locks become available.\nData-structures that don’t use locks are called non-blocking data structures. Most (but not all) of them are lock-free.\nA data-structure or algorithm is considered lock-free if each synchronized action completes in a finite number of steps, not allowing indefinite waiting for a condition to become true or false.\nThe types of lock-free data structures are the following:\n\nObstruction-free: A thread will complete its operation in a bounded number of steps if all other threads are suspended.\nLock-free: Atleast one thread will complete its operation in a bounded number of steps while multiple threads are working on the data-structure.\nWait-free: All threads will complete their operations in a bounded number of steps while multiple threads are working on the data-structure."
  },
  {
    "objectID": "posts/atomic-operations/index.html#memory-access",
    "href": "posts/atomic-operations/index.html#memory-access",
    "title": "C++ Atomics",
    "section": "Memory Access",
    "text": "Memory Access\nMemory order refers to the order in which memory(that is, the variables in a program) are accessed. Memory can be either read or write(load and store). But, what is the actual order in which the variables of a program are accessed? For the following code, there are \\(3\\) points of view: the written code order, the compiler-generated instructions order, and finally, the order in which the instructions are executed by the CPU. These \\(3\\) orderings can all be the same or (more likely) different.\nThe first and obvious ordering is the one in the code.\nvoid func_1(int& a, int& b){\n    a += 1;\n    b += 10;\n    a += 2;\n}\nThe func_1 function first adds \\(1\\) to the variable a, then adds \\(10\\) to the variable b and finally adds \\(2\\) to the variable a. This is our intention and the order in which we define the statements to be executed.\nWhen compiling the code to assembly, the compiler may change the order of the statements to make the generate code more efficient provided the outcome of the code execution is unchanged. For example, with the preceding code, the compiler could either do the two additions with variable a first and then the addition with variable b, or it could simply add 3 to a and 10 to b.\nfunc_1(int&, int&):\n        add     DWORD PTR [rdi], 1\n        add     DWORD PTR [rsi], 10\n        add     DWORD PTR [rdi], 2\n        ret\nIf we define func_2 as:\nvoid func_2(int& a, int& b){\n    a += 1;\n    a += 2;\n    b += 10;\n}\nthe compiler generates:\nfunc_2(int&, int&):\n        add     DWORD PTR [rdi], 3\n        add     DWORD PTR [rsi], 10\n        ret\nIn this case, the CPU could execute the instructions out of order, as there is no dependency among the operations.\nConsider func_3(int&, int&) defined as:\nvoid func_3(int& a, int &b){\n    a += 1;\n    b += 10 + a;\n    a += 2;\n}\nIn this case, the operation on b depends on the previous operation on a, so the compiler cannot reorder the statements, and the generated code will be like the code we write (same order of operations).\nfunc_3(int&, int&):\n        mov     eax, DWORD PTR [rdi]\n        lea     edx, [rax+1]\n        add     eax, 11\n        mov     DWORD PTR [rdi], edx\n        add     DWORD PTR [rsi], eax\n        add     DWORD PTR [rdi], 2\n        ret\nTo conclude, the source code order, the compiler generated object-code order and the actual exection order on a multi-core CPU will differ."
  },
  {
    "objectID": "posts/atomic-operations/index.html#modification-order",
    "href": "posts/atomic-operations/index.html#modification-order",
    "title": "C++ Atomics",
    "section": "Modification Order",
    "text": "Modification Order\nAny entity with a type T that has a lifetime and occupies storage in memory is an object. Every object in a C++ program has a modification order, consisting of all writes to that object from all the threads in the program, starting with the object’s initialization. In multi-threaded code, the modification order may vary between runs, but in a given execution of the program, all threads must agree on the order.\nIf distinct threads see distinct sequences of values for a single variable, we have a data-race and UB.\nCertain kinds of speculative execution aren’t permitted. Once a thread has seen a particular entry in the modification order, subsequent reads from the same thread must return later values and subsequent writes to that object must occur later in the modification order. A read of an object that follows a write to that object in the same thread must either return the same value or another value that occurs later in the modification order. Although all threads must agree on the modification orders of each individual object, they may not necessarily agree on the relative ordering of operations on separate objects."
  },
  {
    "objectID": "posts/atomic-operations/index.html#memory-model",
    "href": "posts/atomic-operations/index.html#memory-model",
    "title": "C++ Atomics",
    "section": "Memory Model",
    "text": "Memory Model\nTypically, each core in a multi-core processor has dedicated store buffers, its own L3 cache. A pair of cores often share the L2 cache. All cores share the L1 cache and the global main memory. So, the below picture is a more accurate mental model of a modern microprocessor.\n\n\n\nMemory Model\n\n\nConsider 2 globally declared atomic flags flag1 and flag2. Assume that thread_1 executes on processor-1 and thread_2 executes on processor-2 and all reads and writes are atomic.\nEssentially, thread_1 declares its intent to enter a critical section by setting flag1 = 1. A flag1.store(1) operation writes flag1 = 1 to the store buffer. Concurrently, thread_2 declares its intent to enter the critical section by setting flag2 = 1. A flag2.store(1) operation writes flag2 = 1 the processor’s store buffer.\nthread_1 reads the value of flag2 from the global main memory, which is 0 (since processor-2’s buffer has not been flushed). Hence, the predicate !flag2 is satisfied and the thread_1 enters the critical section. Similarly, thread_2 reads the value of flag1 from the global main memory, which is also 0 and enters the critical section at the same time.\n\\(1\\) nanosecond later, the contents of the store buffers on processor-1 and process-2 are flushed to main memory.\nThus, we need synchronization and some form of ordering to prevent undefined behavior.\n\nSequential consistency\nstd::memory_order_seq_cst has two implications. The operations of a program(thread) will always be executed in source code order.\nIn a given execution, there is a single global ordering of all operations tagged memory_order_seq, and all threads observe the same global order.\n#include &lt;iostream&gt;\n#include &lt;atomic&gt;\n#include &lt;thread&gt;\n\nstd::atomic&lt;int&gt; x = ATOMIC_INT_LOCK_FREE;\nstd::atomic&lt;int&gt; y = ATOMIC_INT_LOCK_FREE;\n\nint main() {\n    std::thread t1(\n        [&]() {\n            x.store(42);\n            int result1 = y.load();\n        }\n    );\n\n    std::thread t2(\n        [&]() {\n            y.store(17);\n            int result2 = x.load();\n        }\n    );\n}\nSequential ordering is also the default memory ordering.\nx.store(42) will always be performed before y.load(). y.store(17) will always be performed before x.load(). That is the guarantee of the sequential consistency. And each thread sees operations of the other thread in the same order. This respects our intuition.\nHow many ways exist to perform these 4 operations? Extremely easy! There are 6 possibilities.\n\n\n\nSequential Memory Order\n\n\nTo further elaborate, consider the below snippet:\n// Ref: Asynchronous programming with C++\n// Javier Reguera Salgado\n#include &lt;iostream&gt;\n#include &lt;atomic&gt;\n#include &lt;thread&gt;\n#include &lt;vector&gt;\n\nstd::atomic&lt;bool&gt; x{ false };\nstd::atomic&lt;bool&gt; y{ false };\nstd::atomic&lt;int&gt; z{ 0 };\n\nvoid write_x() {\n    x.store(true, std::memory_order_seq_cst);\n}\n\nvoid write_y() {\n    y.store(true, std::memory_order_seq_cst);\n}\n\nvoid read_x_then_y() {\n    while (!x.load(std::memory_order_seq_cst));\n\n    if (y.load(std::memory_order_seq_cst))\n        ++z;\n}\n\nvoid read_y_then_x() {\n    while (!y.load(std::memory_order_seq_cst));\n\n    if (x.load(std::memory_order_seq_cst))\n        ++z;\n}\n\nint main() {\n    std::thread t1(write_x);\n    std::thread t2(write_y);\n    std::thread t3(read_x_then_y);\n    std::thread t4(read_y_then_x);\n\n    t1.join();\n    t2.join();\n    t3.join();\n    t4.join();\n\n    std::cout &lt;&lt; \"\\n\" &lt;&lt; \"x = \" &lt;&lt; x;\n    std::cout &lt;&lt; \"\\n\" &lt;&lt; \"y = \" &lt;&lt; y;\n    std::cout &lt;&lt; \"\\n\" &lt;&lt; \"z = \" &lt;&lt; z;\n}\nUnder no circumstances, the value of z will be equal to 0. Either the write_x goes before write_y or write_y goes before write_x. All threads observe the same global order of events."
  },
  {
    "objectID": "posts/atomic-operations/index.html#non-sequential-memory-ordering",
    "href": "posts/atomic-operations/index.html#non-sequential-memory-ordering",
    "title": "C++ Atomics",
    "section": "Non-sequential memory ordering",
    "text": "Non-sequential memory ordering\nOn the opposite end of the spectrum is relaxed ordering. In the absence of other ordering constraints, the only requirement is that threads agree on the modification order of each variable. Operations on distinct variables can appear in different orders on different threads.\n// Ref: Concurrency in Action, Anthony Williams\n#include&lt;atomic&gt;\n#include&lt;thread&gt;\n#include&lt;assert.h&gt;\n\nstd::atomic&lt;bool&gt; x,y;\nstd::atomic&lt;int&gt; z;\n\nvoid write_x_then_y()\n{\n    x.store(true, std::memory_order_relaxed);   // [1]\n    y.store(true, std::memory_order_relaxed);   // [2]\n}\n\nvoid read_y_then_x()\n{\n    while(!y.load(std::memory_order_relaxed));  //[3]\n    if(x.load(std::memory_order_relaxed))\n        ++z;                                    //[4]\n}\n\nint main(){\n    x = false;\n    y = false;\n    z = 0;\n    std::thread a(write_x_then_y);\n    std::thread b(read_y_then_x);\n    a.join();\n    b.join();\n    assert(z.load()!=0);                        //[5]\n}\nThis time the assert at [5] can be false, because the x.load() can read false, even though the load of y reads true and the store of x happens before the store of y.\nx and y are different variables so there are no ordering guarantees relating to the visbility of variables. Relaxed operations on different variables can be freely reordered (provided they obey any happens before relationships in the same thread). They don’t introduce synchronizes-with relationships.\nEven though there is a happens-before relationship between the stores and between the loads, the store of y does not synchronize with the load of y. So, the reader thread can see the stores out of order.\nThere’s another cool example I played around with, from Anthony William’s book, Concurrency in Action.\n// Relaxed operations on multiple threads\n// Ref: Concurrency in action, Anthony Williams\n#include&lt;thread&gt;\n#include&lt;atomic&gt;\n#include&lt;iostream&gt;\n\nstd::atomic&lt;int&gt; x{0}, y{0}, z{0};\nstd::atomic&lt;bool&gt; go{false};\nconst uint loop_count{10};\n\nstruct Snapshot{\n    int x;\n    int y;\n    int z;\n};\n\nSnapshot snapshots[5][loop_count];\n\nvoid increment(std::atomic&lt;int&gt;* var_to_inc, Snapshot* snapshots){\n    while(!go)\n        std::this_thread::yield();      // Spin, waiting for the signal\n\n    for(unsigned i=0;i&lt;loop_count;++i){\n        snapshots[i].x = x.load(std::memory_order_relaxed);\n        snapshots[i].y = y.load(std::memory_order_relaxed);\n        snapshots[i].z = z.load(std::memory_order_relaxed);\n        var_to_inc-&gt;store(i+1, std::memory_order_relaxed);\n        std::this_thread::yield();\n    }\n}\n\nvoid record_values(Snapshot* snapshots){\n    while(!go)\n        std::this_thread::yield();\n\n    for(unsigned i{0};i&lt;loop_count;++i){\n        snapshots[i].x = x.load(std::memory_order_relaxed);\n        snapshots[i].y = y.load(std::memory_order_relaxed);\n        snapshots[i].z = z.load(std::memory_order_relaxed);\n        std::this_thread::yield();\n    }\n}\n\nvoid print(Snapshot* v){\n    for(unsigned i={0};i&lt;loop_count;++i){\n        if(i)\n            std::cout &lt;&lt; \",\";\n        std::cout&lt;&lt; \"(\" &lt;&lt; v[i].x &lt;&lt; \",\" &lt;&lt; v[i].y &lt;&lt; \",\" &lt;&lt; v[i].z &lt;&lt; \")\";\n    }\n\n    std::cout&lt;&lt;\"\\n\";\n}\n\nint main(){\n    std::thread t1(increment, &x, snapshots[0]);\n    std::thread t2(increment, &y, snapshots[1]);\n    std::thread t3(increment, &z, snapshots[2]);\n    std::thread t4(record_values, snapshots[3]);\n    std::thread t5(record_values, snapshots[4]);\n    go=true;\n    t5.join();\n    t4.join();\n    t3.join();\n    t2.join();\n    t1.join();\n\n    for(unsigned i{0};i&lt;5;++i)\n        print(snapshots[i]);\n}\nOutput:\n(0,1,0),(1,5,0),(2,6,0),(3,8,0),(4,8,0),(5,10,0),(6,10,0),(7,10,0),(8,10,0),(9,10,0)\n(0,0,0),(1,1,0),(1,2,0),(1,3,0),(1,4,0),(1,5,0),(2,6,0),(3,7,0),(4,8,0),(5,9,0)\n(10,10,0),(10,10,1),(10,10,2),(10,10,3),(10,10,4),(10,10,5),(10,10,6),(10,10,7),(10,10,8),(10,10,9)\n(10,10,10),(10,10,10),(10,10,10),(10,10,10),(10,10,10),(10,10,10),(10,10,10),(10,10,10),(10,10,10),(10,10,10)\n(0,1,0),(1,3,0),(1,4,0),(1,5,0),(2,6,0),(3,7,0),(4,8,0),(5,9,0),(5,10,0),(6,10,0)\nThis simple code-snippet shows that each thread sees a distinct sequence of values for the distinct variables x, y, and z when incremented 10 times each. Only the modification order of each variable is consistent amongst the threads."
  },
  {
    "objectID": "posts/atomic-operations/index.html#acquire-release-semantic",
    "href": "posts/atomic-operations/index.html#acquire-release-semantic",
    "title": "C++ Atomics",
    "section": "Acquire-Release Semantic",
    "text": "Acquire-Release Semantic\nA release operation on an atomic synchronizes with an acquire operation on the same atomic and additionally establishes an ordering constraint. So, we have a synchronizationation and a partial ordering in the acquire-release semantic.\nSo, what are typically acquire and release operations?\n\nAny write operation such as store or clear must specify std::memory_order_release. This flushes the core cache and publishes all updates before the release operation. So, any writes intra-thread prior to the release operation are visible to other susbcriber threads.\nAny read operation such as load or test_and_set must specify std::memory_order_acquire. This captures any all updates upto this point.\n\nAdditionally,\n\nRead and write operations cannot be reordered to before an acquire operation.\nRead and write operations cannot be reordered to after a release operation.\n\n#include &lt;iostream&gt;\n#include &lt;atomic&gt;\n#include &lt;thread&gt;\n#include &lt;vector&gt;\n\nstd::vector&lt;int&gt; mySharedItems;\nstd::atomic_bool dataProduced;\nstd::atomic_bool dataReadyToBeConsumed;\n\nvoid dataProducer() {\n    mySharedItems = { 1, 0, 3 };\n    std::cout &lt;&lt; \"\\n\" &lt;&lt; \"dataProduced.store(true)\";\n    dataProduced.store(true, std::memory_order_release);\n}\n\nvoid deliveryBoy() {\n    while (!dataProduced.load(std::memory_order_acquire));\n    std::cout &lt;&lt; \"\\n\" &lt;&lt; \"After dataProduced.load()\";\n    std::cout &lt;&lt; \"\\n\" &lt;&lt; \"Before dataReadyToBeConsumed.store(true)\";\n    dataReadyToBeConsumed.store(true, std::memory_order_release);\n}\n\nvoid dataConsumer() {\n    while (!dataReadyToBeConsumed.load(std::memory_order_acquire));\n    std::cout &lt;&lt; \"\\n\" &lt;&lt; \"After dataReadyToBeConsumed.load()\";\n    mySharedItems[1] = 2;\n}\n\nint main() {\n    std::thread t1(dataProducer);\n    std::thread t2(deliveryBoy);\n    std::thread t3(dataConsumer);\n\n    t1.join();\n    t2.join();\n    t3.join();\n    return 0;\n}\nOutput:\ndataProduced.store(true)\nAfter dataProduced.load()\nBefore dataReadyToBeConsumed.store(true)\nAfter dataReadyToBeConsumed.load()\nThe store on line 13 synchronizes with the load on line 17. That’s the acquire-release semantic. It also establishes a partial ordering. Read or write operations prior to the release on line 13 cannot be moved to after line 13. And release operation on line 20 cannot be moved before acquire operation on line 13.\nThe same for the deliveryBoy and dataConsumer.\n\n\n\nAcquire-release semantics\n\n\nIf you think about mutexes, a mutex lock() is an acquire-operation. A mutex unlock() is a release operation. Things inside the critical region cannot be moved to outside it. An unlock() synchronizes with the next lock(). Similarly, wait and notify are acquire and release operations. The starting of a thread and join call on a thread are acquire and release operations.\nConsider the same code as in the previous section for sequential consistency, but in this case, I use acquire-release semantics.\n// Ref: Asynchronous programming with C++, Javier Reguera Salgado\n#include &lt;iostream&gt;\n#include &lt;atomic&gt;\n#include &lt;thread&gt;\n#include &lt;vector&gt;\n\nstd::atomic&lt;bool&gt; x{ false };\nstd::atomic&lt;bool&gt; y{ false };\nstd::atomic&lt;int&gt; z{ 0 };\n\nvoid write_x() {\n    x.store(true, std::memory_order_release);\n}\n\nvoid write_y() {\n    y.store(true, std::memory_order_release);\n}\n\nvoid read_x_then_y() {\n    while (!x.load(std::memory_order_acquire));\n\n    if (y.load(std::memory_order_acquire))\n        ++z;\n}\n\nvoid read_y_then_x() {\n    while (!y.load(std::memory_order_acquire));\n\n    if (x.load(std::memory_order_acquire))\n        ++z;\n}\n\nint main() {\n    std::thread t1(write_x);\n    std::thread t2(write_y);\n    std::thread t3(read_x_then_y);\n    std::thread t4(read_y_then_x);\n\n    t1.join();\n    t2.join();\n    t3.join();\n    t4.join();\n\n    std::cout &lt;&lt; \"\\n\" &lt;&lt; \"x = \" &lt;&lt; x;\n    std::cout &lt;&lt; \"\\n\" &lt;&lt; \"y = \" &lt;&lt; y;\n    std::cout &lt;&lt; \"\\n\" &lt;&lt; \"z = \" &lt;&lt; z;\n}\nThe release operation on x in t1 synchronizes with the acquire operation on x in t3. Similarly, the release operation on y in t2 synchonizes with acquire operation in thread t4. However, writes to x and y happen in different threads.\nSo, t3 may find x = true and y=false. At the same time t4 may find y=true and x=false. Different threads have different views of the memory. So, it may happen that z=0 at the end of this code."
  },
  {
    "objectID": "posts/atomic-operations/index.html#references",
    "href": "posts/atomic-operations/index.html#references",
    "title": "C++ Atomics",
    "section": "References",
    "text": "References\n\n\nThe memory model in C++ - Rainier Grimm, Meeting C++ 2016."
  },
  {
    "objectID": "notebooks/ho_lee.html",
    "href": "notebooks/ho_lee.html",
    "title": "quantdev.blog",
    "section": "",
    "text": "import numpy as np\nimport matplotlib.pyplot as plt\n\"\"\"\nHo-Lee Model - Ensuring that model price of the ZCBs matches the market price\n\"\"\"\n\n# Discounting curve\ndef P(t,T):\n    r = 0.05\n    return np.exp(-r * (T-t))\n\nclass HoLee:\n    def __init__( self\n                 ,discountingCurve : np.array\n                 ,numOfSteps : int\n                 ,numOfPaths : int\n                 ,simulationCutoffDate : float\n                 ,sigma: float\n                 ):\n        self.discountingCurve = discountingCurve\n        self.numOfSteps = numOfSteps\n        self.numOfPaths = numOfPaths\n        self.T = simulationCutoffDate\n        self.sigma = sigma\n    \n    def F0T(self, T : float):\n        dt = 0.0001\n        return -(np.log(P(0,T+dt)) - np.log(P(0,T-dt)))/(2 * dt)\n        \n    def generatePaths(self):\n        dt = self.T / self.numOfSteps\n        timeGrid = np.linspace(dt, self.T, self.numOfSteps)\n\n        # Initial interest rate is a forward rate at time t -&gt; 0\n        r0 = self.F0T(0.0) * np.ones([self.numOfPaths, 1])\n        theta = lambda t : (self.F0T(t + dt) - self.F0T(t - dt))/(2 * dt) + self.sigma**2 * t\n        theta = np.array([theta(t) for t in timeGrid])\n        theta = np.tile(theta, [self.numOfPaths,1])\n        \n        dZt = np.random.standard_normal([self.numOfPaths, self.numOfSteps])\n        dWt = np.sqrt(dt) * dZt\n        dr_t = dt * theta + self.sigma * dWt\n        dr_t = np.concat([r0, dr_t], axis=1)\n        r_t = np.cumsum(dr_t, axis=1)\n        return r_t\n\n    # Price a ZCB in the Ho-Lee model, by computing expectations \n    # under the risk-neutral valuation formula\n    def ZCB(self, t1, t2, r_t : np.matrix):\n        idx_t1 = int(t1 * 365)\n        idx_t2 = int(t2 * 365)\n        dt = self.T / self.numOfSteps\n        return np.average(np.exp(np.sum([-(r_t[:,t] * dt) for t in range(idx_t1, idx_t2)], axis=0)))\n\n\n\nT = 10.0                # Simulation cutoff time T in years\nnumOfSteps = int(365 * T)    # Number of steps\nnumOfPaths = 100\n\ntimeGrid = np.linspace(0.0, T, numOfSteps + 1)\ndiscountingCurve = np.array([P(0,t) for t in timeGrid])\n\n# In this experiment we compare the ZCB from the market and Monte Carlo\nengine = HoLee(\n    discountingCurve=discountingCurve,\n    numOfSteps = numOfSteps,\n    numOfPaths = numOfPaths,\n    simulationCutoffDate = T,\n    sigma = 0.001\n)\n\npaths = engine.generatePaths()\n\nplt.xlabel(r'$t$')\nplt.ylabel(r'$r(t)$')\nplt.title(r'Simulating short rate in the Ho-Lee model')\nplt.grid(True)\nfor path in paths:\n    plt.plot(timeGrid, path)\n\nplt.show()\n\n\n\n\n\n\n\n# Computing ZCB Model prices\nZCBPriceVector = np.array([engine.ZCB(0,T, paths) for T in timeGrid])\n\n# Plot Discount curve and Model ZCB Prices\nplt.close()\n\nplt.xlabel(r'$t$')\nplt.ylabel(r'$P(0,T)$')\nplt.grid(True)\n\nplt.plot(timeGrid, discountingCurve)\nplt.plot(timeGrid, ZCBPriceVector)\nplt.legend([r'$P(0,t)$ market', r'$P(0,t)$ model'])\nplt.show()"
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "About this blog"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "quantdev.blog",
    "section": "",
    "text": "Hi there! Welcome to my blog. I’m Quasar. I am a software engineer turned quantitative analyst.\nHere, I’ll document my coding conquests, exploring practical modern C++ and financial math, building practical and impractical tools, to playing around with numerics!\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCustom iterators and Iterator concepts\n\n\n\nC++\n\n\n\n\n\n\n\nQuasar\n\n\nMay 5, 2025\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nA note on make_shared&lt;T&gt;(Args&&...) and make_unique&lt;T&gt;(Args&&...)\n\n\n\nC++\n\n\n\n\n\n\n\nQuasar\n\n\nMay 4, 2025\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nunique_ptr - A custom implementation\n\n\n\nC++\n\n\n\n\n\n\n\nQuasar\n\n\nApr 21, 2025\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nshared_ptr - A custom implementation\n\n\n\nC++\n\n\n\n\n\n\n\nQuasar\n\n\nApr 21, 2025\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nC++ Atomics\n\n\n\nC++\n\n\n\n\n\n\n\nQuasar\n\n\nMar 8, 2025\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nnumpy and pandas CheatSheet\n\n\n\nPython\n\n\n\n\n\n\n\nQuasar\n\n\nMar 6, 2025\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nPython lists, dicts, tuples\n\n\n\nPython\n\n\n\n\n\n\n\nQuasar\n\n\nMar 5, 2025\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nDIY asyncio\n\n\n\nPython\n\n\n\n\n\n\n\nQuasar\n\n\nFeb 28, 2025\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nA thread-safe queue implementation\n\n\n\nC++\n\n\n\n\n\n\n\nQuasar\n\n\nFeb 23, 2025\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nThread-Safe Stack Implementation\n\n\n\nC++\n\n\n\n\n\n\n\nQuasar\n\n\nFeb 23, 2025\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nMargrabe’s formula\n\n\n\nBack to the basics\n\n\n\n\n\n\n\nQuasar\n\n\nFeb 22, 2025\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nLevenberg-Marquardt Algorithm\n\n\n\nNumerical Methods\n\n\n\n\n\n\n\nQuasar\n\n\nFeb 1, 2025\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nC++ Ranges\n\n\n\nC++\n\n\n\n\n\n\n\nQuasar\n\n\nJan 31, 2025\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCollateralized Discounting\n\n\n\nBack to the basics\n\n\n\n\n\n\n\nQuasar\n\n\nJan 27, 2025\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nIRS, Caps, Floors and Swaptions\n\n\n\nRates Modelling\n\n\n\n\n\n\n\nQuasar\n\n\nJan 24, 2025\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCRTP(Curiously recurring template pattern)\n\n\n\nC++\n\n\n\n\n\n\n\nQuasar\n\n\nDec 28, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nRule of Five\n\n\n\nC++\n\n\n\n\n\n\n\nQuasar\n\n\nDec 27, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCurrying and partial function application\n\n\n\nC++\n\n\n\n\n\n\n\nQuasar\n\n\nDec 11, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCopy-and-swap idiom\n\n\n\nC++\n\n\n\n\n\n\n\nQuasar\n\n\nDec 10, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nSFINAE\n\n\n\nC++\n\n\n\n\n\n\n\nQuasar\n\n\nDec 7, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nC++20 concepts\n\n\n\nC++\n\n\n\n\n\n\n\nQuasar\n\n\nDec 7, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nA gentle introduction to the Girsanov Theorem - Back to the basics\n\n\n\nStochastic Calculus\n\n\n\n\n\n\n\nQuasar\n\n\nDec 1, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nFun with numeraires!\n\n\n\nStochastic Calculus\n\n\n\n\n\n\n\nQuasar\n\n\nNov 28, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nClass Template Argument Deduction(CTAD)\n\n\n\nC++\n\n\n\n\n\n\n\nQuasar\n\n\nNov 25, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nType Traits 101\n\n\n\nC++\n\n\n\n\n\n\n\nQuasar\n\n\nNov 25, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nTridiagonal Systems\n\n\n\nNumerical Methods\n\n\n\n\n\n\n\nQuasar\n\n\nNov 15, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nInterpolation and Approximation\n\n\n\nNumerical Methods\n\n\n\n\n\n\n\nQuasar\n\n\nNov 13, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nNumerical Integration\n\n\n\nNumerical Methods\n\n\n\n\n\n\n\nQuasar\n\n\nNov 11, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nTemplate programming\n\n\n\nC++\n\n\n\n\n\n\n\nQuasar\n\n\nNov 10, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nA hitchhiker’s guide to move semantics and perfect forwarding\n\n\n\nC++\n\n\n\n\n\n\n\nQuasar\n\n\nOct 26, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nNorms\n\n\n\nNumerical Methods\n\n\n\n\n\n\n\nQuasar\n\n\nJul 25, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nSingular Value Decomposition(SVD)\n\n\n\nLinear Algebra\n\n\n\n\n\n\n\nQuasar\n\n\nJul 24, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nEigenthingies and Diagonalizability\n\n\n\nLinear Algebra\n\n\n\n\n\n\n\nQuasar\n\n\nJul 23, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nThe Spectral Theorem\n\n\n\nLinear Algebra\n\n\n\n\n\n\n\nQuasar\n\n\nJul 23, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nIto Calculus\n\n\n\nStochastic Calculus\n\n\n\n\n\n\n\nQuasar\n\n\nJul 12, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nMartingales\n\n\n\nStochastic Calculus\n\n\n\n\n\n\n\nQuasar\n\n\nJul 12, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nThe Markov Property\n\n\n\nStochastic Calculus\n\n\n\n\n\n\n\nQuasar\n\n\nJul 12, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nIto Processes and Stochastic Differential Equations\n\n\n\nStochastic Calculus\n\n\n\n\n\n\n\nQuasar\n\n\nJul 8, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nMultivariate Ito Calculus\n\n\n\nStochastic Calculus\n\n\n\n\n\n\n\nQuasar\n\n\nJul 4, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nThe distribution of the first passage time of Brownian Motion\n\n\n\nStochastic Calculus\n\n\n\n\n\n\n\nQuasar\n\n\nJul 2, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nBorel-Cantelli Lemmas\n\n\n\nProbability Theory\n\n\n\n\n\n\n\nQuasar\n\n\nJun 28, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nPositive Definiteness\n\n\n\nLinear Algebra\n\n\n\n\n\n\n\nQuasar\n\n\nJun 20, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nOptimization Algorithms\n\n\n\nMachine Learning\n\n\n\n\n\n\n\nQuasar\n\n\nJun 10, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nBackpropogation\n\n\n\nMachine Learning\n\n\n\n\n\n\n\nQuasar\n\n\nJun 5, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCoding a neural network layer\n\n\n\nMachine Learning\n\n\n\n\n\n\n\nQuasar\n\n\nMay 28, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nClassification Algorithms\n\n\n\nMachine Learning\n\n\n\n\n\n\n\nQuasar\n\n\nMay 28, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nDerivation of the Least Squares Estimate Beta in Linear Regression\n\n\n\nMachine Learning\n\n\n\n\n\n\n\nQuasar\n\n\nMay 16, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nStandard CDS Pricing Theory\n\n\n\nCredit Derivatives\n\n\n\n\n\n\n\nQuasar\n\n\nMay 8, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCox-Ingersoll-Ross (CIR) model\n\n\n\nRates Modelling\n\n\n\n\n\n\n\nQuasar\n\n\nMay 8, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nBlack Scholes Formula for a European Call\n\n\n\nStochastic Calculus\n\n\n\n\n\n\n\nQuasar\n\n\nMay 3, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nExploring Option Greeks\n\n\n\nVanilla Options\n\n\n\n\n\n\n\nQuasar\n\n\nMay 3, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nProperties of Brownian Motion\n\n\n\nStochastic Calculus\n\n\n\n\n\n\n\nQuasar\n\n\nApr 27, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nImplementing Vanna Volga\n\n\n\nVolatility modelling\n\n\n\n\n\n\n\nQuasar\n\n\nNov 26, 2023\n\n\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "posts/SFINAE/index.html",
    "href": "posts/SFINAE/index.html",
    "title": "SFINAE",
    "section": "",
    "text": "When we write templates, we sometimes need to restrict the template arguments. For instance, we have a function that should work for any numeric type, therefore integral and floating point, but should not work with anything else. Or we may have a class template that should only accept trivial types for an argument.\nThere are also cases where we have overloaded function templates that should work with some types only. For instance, one overload should work with integral types and the other for floating-point types only. There are different ways to achieve that goal.\nType traits are, however, involved in one way or the other. The first one that will be discussed in this chapter is called SFINAE. C++20 concepts are an approach superior to SFINAE, that I am going to blog about in another post.\nSFINAE stands for Substitution Failure Is Not An Error. When the compiler encounters the use of a function template, it substitutes the arguments in order to instantiate the template. If an error occurs at this point, it is not regarded as ill-informed code, only as a deduction failure. The function is removed from the overload set instead of causing an error. Only if there is no match in the overload set does an error occur.\n\n\nIn C++11, there are free-standing functions std::begin() and std::end() that return iterators to the first and the one-past-last elements of the container. These functions also work with arrays. How might we implement begin() to work both with STL containers and arrays?\nWe need two overloads of the function template:\n#include &lt;array&gt;\n#include &lt;iterator&gt;\n#include &lt;iostream&gt;\n\ntemplate&lt;typename T&gt;\nauto beginIter(T& c) { return c.begin(); }      //[1]\n\ntemplate&lt;typename T, std::size_t N&gt;\nT* beginIter(T(&arr)[N]){ return arr; }         //[2]\nThe first overload calls the member function begin() and returns the value. Therefore, this overload is restricted to types that have a member function begin(), otherwise a compiler error would occur. The second overload simply returns a pointer to the first element of the array. This is restricted to array types; anything else would produce a compiler error.\nWe can use these overloads as follows:\nint main()\n{\n    std::array&lt;int, 5&gt; arr1{1, 2, 3, 4, 5};     \n    std::cout &lt;&lt; *beginIter(arr1) &lt;&lt; \"\\n\";          //[3] prints 1\n\n    int arr2[] {5, 4, 3, 2, 1};\n    std::cout &lt;&lt; *beginIter(arr2) &lt;&lt; \"\\n\";          //[5] prints 5\n}\nCompiler Explorer\nIf you compile this piece of code, no error, not even a warning occurs! The reason for that is SFINAE. When resolving the call to beginIter(arr1), substituting std::array&lt;int,5&gt; to the first overload at [1] succeeds, but the substitution for the second (at [2]) fails. Instead of issuing an error at this point, the compiler just ignores it, so it builds an overload set with a single instantiation, and therefore it can find a match for the invocation. Similarly, when resolving the call to beginIter(arr2), the substitution of int[5] for the first overload fails and is ignored, but it succeeds for the second and is added to the overload set, eventually finding a good match for the invocation. Therefore, both calls can be successfully made. Should one of the two overloads not be present, either beginIter(arr1) or beginIter(arr2) would fail to match the function template and a compiler error would occur.\n\n\n\nThere are two categories of type traits in C++:\n\nType traits that enable us to query properties of the type at compile-time.\nType traits that enable us to perform type transformations at compile-time(such as adding or removing the const qualifier, or adding or removing pointer or reference from a type). These type traits are also called meta-functions.\n\nOne important type trait is std::enable_if. This is used to enable SFINAE and remove candidates from a function’s overload set. Recall that, enable_if&lt;B,T&gt; is a type metafunction. If B is true, it returns T.\ntemplate&lt;bool B, typename T=void&gt;\nstruct enable_if{};\n\ntemplate&lt;typename t&gt;\nstruct enable_if&lt;true,T&gt;{\n    using type = T;\n};\nRecall, the example in my blog post on type traits on the creating a serializer that exposes a uniform API to prirint an object to the output stream. To achieve that, we coded up a uses_write type trait.\nWith std::enable_if, we can implement that idea in a simple way:\ntemplate&lt;typename T,\n            typename std::enable_if&lt;\n                uses_write&lt;T&gt;::value&gt;::type* = nullptr&gt;\n\nvoid serialize(std::ostream& os, T const & value){\n    value.write(os);\n}\n\ntemplate&lt;typename T,\n            typename std::enable_if&lt;\n                !uses_write&lt;T&gt;::value&gt;::type* = nullptr&gt;\n\nvoid serialize(std::ostream& os, T const & value){\n    os &lt;&lt; value;\n}\nThere are two overloaded function templates in this implementation. They both have two template parameters. The first parameter is the usual template type parameter T. The second is an anonymous non-type template parameter of a pointer type that also has the default value nullptr. We use std::enable_if to define the member called type only if the uses_write metafunction evaluates to true. Therefore, for classes that have the member function write, the substitution succeeds for the first overload but fails for the second overload, because typename* = nullptr is not a valid parameter. For classses for which the output stream operator &lt;&lt; is overload, we have the opposite situation.\nThe std::enable_if metafunction can be used in several scenarios:\n\nTo define a template parameter that has a default argument.\nTo define a function parameter that has a default argument.\nTo specify the return type of a function.\n\nLet’s use std::enable_if to define a function parameter with a default argument. For instance, we can write:\ntemplate&lt;typename T&gt;\nvoid serialize(\n    std::ostream& os, \n    T const & value,\n    typename std::enable_if&lt;use_write&lt;T&gt;::value&gt;::type* value == nullptr\n){\n    value.write(os);\n}\n\ntemplate&lt;typename T&gt;\nvoid serialize(\n    std::ostream& os, \n    T const & value,\n    typename std::enable_if&lt;!use_write&lt;T&gt;::value&gt;::type* value == nullptr\n){\n    os &lt;&lt; value;\n}\nWe basically moved the parameter from the template parameter list to the function parameter list. The third alternative is to use std::enable_if&lt;T&gt; to wrap the return type of the function. This implementation is only slightly different(the default argument does not make sense for a return type.) Here is how it looks:\ntemplate&lt;typename T&gt;\ntypename std::enable_if&lt;use_write&lt;T&gt;::value&gt;::type serialize(\n    std::ostream& os,\n    T const & value\n){\n    value.write(os);\n}\n\ntemplate&lt;typename T&gt;\ntypename std::enable_if&lt;!use_write&lt;T&gt;::value&gt;::type serialize(\n    std::ostream& os,\n    T const & value\n){\n    os &lt;&lt; value;\n}\nIn all these examples, the enable_if type trait was used to enable SFINAE during the overload resolution for the function templates. This type metafunction can also be used to restrict instantiations of class templates. In the following example, we have a class called integral_wrapper that is supposed to be instantiated only with integral types, and a class called floating_wrapper that is supposed to be instantiated only with only with floating point types:\n#include &lt;type_traits&gt;\n\ntemplate&lt;\n    typename T,\n    typename=std::enable_if&lt;std::is_integral_v&lt;T&gt;&gt;::type&gt;\nstruct integral_wrapper{\n    T value;\n};\n\ntemplate&lt;\n    typename T,\n    typename=std::enable_if&lt;std::is_floating_point_v&lt;T&gt;&gt;::type&gt;\nstruct floating_point_wrapper{\n    T value;\n};\nBoth these templates have two type template parameters. The first one is called T, but the second one is anonymous and has a default argument. The value of this argument is defined or not with the help of the std::enable_if&lt;B,T&gt; type metafunction, based on the value of a boolean expression.\nWe can use the wrapper class templates as follows:\nint main()\n{\n    integral_wrapper w1{ 42 };          //OK\n    //integral_wrapper w2{ 42.0 };      //error\n    //integral_wrapper w3{ \"42\" };      //error\n\n    //floating_point_wrapper w4{ 42 };  //error\n    floating_point_wrapper w5{ 42.0 };  //OK\n    //floating_point_wrapper w6{ \"42\" };//error\n    return 0;\n}\nCompiler Explorer\n\n\n\nThe C++17 feature if constexpr is a compile-time version of the if statement and makes SFINAE much easier. It helps replace complex template code with simpler versions. Let’s look at a C++17 implementation of the serialize function that can uniformly serialize both widgets and gadgets:\ntemplate&lt;typename T&gt;\nvoid serialize(std::ostream& os, T const & value){\n    if constexpr (uses_write&lt;T&gt;::value){\n        value.write(os);\n    }else{\n        os &lt;&lt; value;\n    }\n}\nconstexpr if enables us to discard a branch, at compile-time, based on the value of the expression. In our example, when the uses_write_v variable is true, the else branch is discarded, and the body of the first branch is retained. Otherwise, the opposite occurs. We end up with following specializations for the widget and gadget classes:\ntemplate&lt;&gt;\nvoid serialize&lt;widget&gt;(std::ostream&& os, widget const & value){\n    if constexpr(true)\n    {\n        value.write(os);\n    }\n}\n\nvoid serialize&lt;widget&gt;(std::ostream&& os, widget const & value){\n    if constexpr(false)\n    {\n        os &lt;&lt; write;\n    }\n}"
  },
  {
    "objectID": "posts/SFINAE/index.html#an-example-of-implementing-the-begin-method",
    "href": "posts/SFINAE/index.html#an-example-of-implementing-the-begin-method",
    "title": "SFINAE",
    "section": "",
    "text": "In C++11, there are free-standing functions std::begin() and std::end() that return iterators to the first and the one-past-last elements of the container. These functions also work with arrays. How might we implement begin() to work both with STL containers and arrays?\nWe need two overloads of the function template:\n#include &lt;array&gt;\n#include &lt;iterator&gt;\n#include &lt;iostream&gt;\n\ntemplate&lt;typename T&gt;\nauto beginIter(T& c) { return c.begin(); }      //[1]\n\ntemplate&lt;typename T, std::size_t N&gt;\nT* beginIter(T(&arr)[N]){ return arr; }         //[2]\nThe first overload calls the member function begin() and returns the value. Therefore, this overload is restricted to types that have a member function begin(), otherwise a compiler error would occur. The second overload simply returns a pointer to the first element of the array. This is restricted to array types; anything else would produce a compiler error.\nWe can use these overloads as follows:\nint main()\n{\n    std::array&lt;int, 5&gt; arr1{1, 2, 3, 4, 5};     \n    std::cout &lt;&lt; *beginIter(arr1) &lt;&lt; \"\\n\";          //[3] prints 1\n\n    int arr2[] {5, 4, 3, 2, 1};\n    std::cout &lt;&lt; *beginIter(arr2) &lt;&lt; \"\\n\";          //[5] prints 5\n}\nCompiler Explorer\nIf you compile this piece of code, no error, not even a warning occurs! The reason for that is SFINAE. When resolving the call to beginIter(arr1), substituting std::array&lt;int,5&gt; to the first overload at [1] succeeds, but the substitution for the second (at [2]) fails. Instead of issuing an error at this point, the compiler just ignores it, so it builds an overload set with a single instantiation, and therefore it can find a match for the invocation. Similarly, when resolving the call to beginIter(arr2), the substitution of int[5] for the first overload fails and is ignored, but it succeeds for the second and is added to the overload set, eventually finding a good match for the invocation. Therefore, both calls can be successfully made. Should one of the two overloads not be present, either beginIter(arr1) or beginIter(arr2) would fail to match the function template and a compiler error would occur."
  },
  {
    "objectID": "posts/SFINAE/index.html#enabling-sfinae-with-the-enable_if-type-trait",
    "href": "posts/SFINAE/index.html#enabling-sfinae-with-the-enable_if-type-trait",
    "title": "SFINAE",
    "section": "",
    "text": "There are two categories of type traits in C++:\n\nType traits that enable us to query properties of the type at compile-time.\nType traits that enable us to perform type transformations at compile-time(such as adding or removing the const qualifier, or adding or removing pointer or reference from a type). These type traits are also called meta-functions.\n\nOne important type trait is std::enable_if. This is used to enable SFINAE and remove candidates from a function’s overload set. Recall that, enable_if&lt;B,T&gt; is a type metafunction. If B is true, it returns T.\ntemplate&lt;bool B, typename T=void&gt;\nstruct enable_if{};\n\ntemplate&lt;typename t&gt;\nstruct enable_if&lt;true,T&gt;{\n    using type = T;\n};\nRecall, the example in my blog post on type traits on the creating a serializer that exposes a uniform API to prirint an object to the output stream. To achieve that, we coded up a uses_write type trait.\nWith std::enable_if, we can implement that idea in a simple way:\ntemplate&lt;typename T,\n            typename std::enable_if&lt;\n                uses_write&lt;T&gt;::value&gt;::type* = nullptr&gt;\n\nvoid serialize(std::ostream& os, T const & value){\n    value.write(os);\n}\n\ntemplate&lt;typename T,\n            typename std::enable_if&lt;\n                !uses_write&lt;T&gt;::value&gt;::type* = nullptr&gt;\n\nvoid serialize(std::ostream& os, T const & value){\n    os &lt;&lt; value;\n}\nThere are two overloaded function templates in this implementation. They both have two template parameters. The first parameter is the usual template type parameter T. The second is an anonymous non-type template parameter of a pointer type that also has the default value nullptr. We use std::enable_if to define the member called type only if the uses_write metafunction evaluates to true. Therefore, for classes that have the member function write, the substitution succeeds for the first overload but fails for the second overload, because typename* = nullptr is not a valid parameter. For classses for which the output stream operator &lt;&lt; is overload, we have the opposite situation.\nThe std::enable_if metafunction can be used in several scenarios:\n\nTo define a template parameter that has a default argument.\nTo define a function parameter that has a default argument.\nTo specify the return type of a function.\n\nLet’s use std::enable_if to define a function parameter with a default argument. For instance, we can write:\ntemplate&lt;typename T&gt;\nvoid serialize(\n    std::ostream& os, \n    T const & value,\n    typename std::enable_if&lt;use_write&lt;T&gt;::value&gt;::type* value == nullptr\n){\n    value.write(os);\n}\n\ntemplate&lt;typename T&gt;\nvoid serialize(\n    std::ostream& os, \n    T const & value,\n    typename std::enable_if&lt;!use_write&lt;T&gt;::value&gt;::type* value == nullptr\n){\n    os &lt;&lt; value;\n}\nWe basically moved the parameter from the template parameter list to the function parameter list. The third alternative is to use std::enable_if&lt;T&gt; to wrap the return type of the function. This implementation is only slightly different(the default argument does not make sense for a return type.) Here is how it looks:\ntemplate&lt;typename T&gt;\ntypename std::enable_if&lt;use_write&lt;T&gt;::value&gt;::type serialize(\n    std::ostream& os,\n    T const & value\n){\n    value.write(os);\n}\n\ntemplate&lt;typename T&gt;\ntypename std::enable_if&lt;!use_write&lt;T&gt;::value&gt;::type serialize(\n    std::ostream& os,\n    T const & value\n){\n    os &lt;&lt; value;\n}\nIn all these examples, the enable_if type trait was used to enable SFINAE during the overload resolution for the function templates. This type metafunction can also be used to restrict instantiations of class templates. In the following example, we have a class called integral_wrapper that is supposed to be instantiated only with integral types, and a class called floating_wrapper that is supposed to be instantiated only with only with floating point types:\n#include &lt;type_traits&gt;\n\ntemplate&lt;\n    typename T,\n    typename=std::enable_if&lt;std::is_integral_v&lt;T&gt;&gt;::type&gt;\nstruct integral_wrapper{\n    T value;\n};\n\ntemplate&lt;\n    typename T,\n    typename=std::enable_if&lt;std::is_floating_point_v&lt;T&gt;&gt;::type&gt;\nstruct floating_point_wrapper{\n    T value;\n};\nBoth these templates have two type template parameters. The first one is called T, but the second one is anonymous and has a default argument. The value of this argument is defined or not with the help of the std::enable_if&lt;B,T&gt; type metafunction, based on the value of a boolean expression.\nWe can use the wrapper class templates as follows:\nint main()\n{\n    integral_wrapper w1{ 42 };          //OK\n    //integral_wrapper w2{ 42.0 };      //error\n    //integral_wrapper w3{ \"42\" };      //error\n\n    //floating_point_wrapper w4{ 42 };  //error\n    floating_point_wrapper w5{ 42.0 };  //OK\n    //floating_point_wrapper w6{ \"42\" };//error\n    return 0;\n}\nCompiler Explorer"
  },
  {
    "objectID": "posts/SFINAE/index.html#c17-constexpr-if",
    "href": "posts/SFINAE/index.html#c17-constexpr-if",
    "title": "SFINAE",
    "section": "",
    "text": "The C++17 feature if constexpr is a compile-time version of the if statement and makes SFINAE much easier. It helps replace complex template code with simpler versions. Let’s look at a C++17 implementation of the serialize function that can uniformly serialize both widgets and gadgets:\ntemplate&lt;typename T&gt;\nvoid serialize(std::ostream& os, T const & value){\n    if constexpr (uses_write&lt;T&gt;::value){\n        value.write(os);\n    }else{\n        os &lt;&lt; value;\n    }\n}\nconstexpr if enables us to discard a branch, at compile-time, based on the value of the expression. In our example, when the uses_write_v variable is true, the else branch is discarded, and the body of the first branch is retained. Otherwise, the opposite occurs. We end up with following specializations for the widget and gadget classes:\ntemplate&lt;&gt;\nvoid serialize&lt;widget&gt;(std::ostream&& os, widget const & value){\n    if constexpr(true)\n    {\n        value.write(os);\n    }\n}\n\nvoid serialize&lt;widget&gt;(std::ostream&& os, widget const & value){\n    if constexpr(false)\n    {\n        os &lt;&lt; write;\n    }\n}"
  },
  {
    "objectID": "posts/backpropogation/index.html",
    "href": "posts/backpropogation/index.html",
    "title": "Backpropogation",
    "section": "",
    "text": "With a randomly initialized model, or even a model initialized with more sophisticated approaches, our goal is to train, or teach a model over time. To train a model, we tweak the weights and biases to improve the model’s accuracy and confidence. To do this, we calculate the error in our model. The loss function also referred to as the cost function quantifies the error.\n\n\nLet \\(\\vec{l} = \\mathbf{w}\\cdot \\mathbf{x} + \\mathbf{b}\\) be the result of the last dense layer of a neural network (the inner product between an input feature vector and the weights vector of the layer, added to the bias factor). This is commonly referred to as the logit vector in machine learning literature.\n\n\n\nLet \\(X\\) be a random variable with possible outcomes \\(\\mathcal{X}\\). Let \\(P\\) be the true probability distribution of \\(X\\) with probability mass function \\(p(x)\\). Let \\(Q\\) be an approximating distribution with probability mass function \\(q(x)\\).\nDefinition. The entropy of \\(P\\) is defined as:\n\\[\\begin{align*}\nH(P) = -\\sum_{x\\in\\mathcal{X}} p(x) \\cdot \\log p(x)\n\\end{align*}\\]\nIn information theory, entropy is the measure of uncertainty, surprise of a system. By taking the logarithm \\(\\log p(x)\\), we concentrate on the order of the surprise. Entropy, then, is an expectation over the uncertainties or the expected surprise.\nDefinition. The cross-entropy of \\(Q\\) relative to \\(P\\) is defined as:\n\\[\\begin{align*}\nH(P,Q) = -\\sum_{x\\in\\mathcal{X}} p(x) \\cdot \\log q(x)\n\\end{align*}\\]\nDefinition. For discrete distributions \\(P\\) and \\(Q\\) defined on the sample space \\(\\mathcal{X}\\), the Kullback-Leibler(KL) divergence (or relative entropy) from \\(Q\\) to \\(P\\) is defined as:\n\\[\\begin{align*}\nD_{KL}(P||Q) = -\\sum_{x\\in\\mathcal{X}} p(x) \\cdot \\log \\frac{p(x)}{q(x)}\n\\end{align*}\\]\nIntuitively, it is the expected excess surprise from using \\(Q\\) as a model instead of \\(P\\), when the actual distribution is \\(P\\). Note that, \\(D_{KL}(P||Q) \\neq D_{KL}(Q||P)\\), so it is not symmetric and hence it is not a norm.\n\n\n\nWe are going to work on a multi-class classification problem.\nFor any input \\(\\mathbf{x}_i\\), the target vector \\(\\mathbf{y}_i\\) could be specified using one-hot encoding or an integer in the range [0,numClasses).\nLet’s say, we have numClasses = 3.\nIn one-hot encoding, the target vector y_true is an array like [1, 0, 0], [0, 1, 0], or [0, 0, 1]. The category/class is determined by the index which is hot. For example, if y_true equals [0, 1, 0], then the sample belongs to class \\(1\\), whilst if y_true equals [0, 0, 1], the sample belongs to class \\(2\\).\nIn integer encoding, the target vector y_true is an integer. For example, if y_true equals \\(1\\), the sample belongs to class \\(1\\), whilst if y_true equals \\(2\\), the sample belongs to class \\(2\\).\nThe categorical_crossentropy is defined as:\n\\[\\begin{align*}\nL_i = -\\sum_{j} y_{i,j} \\log(\\hat{y}_{i,j})\n\\end{align*}\\]\nAssume that we have a softmax output \\(\\hat{\\mathbf{y}}_i\\), [0.7, 0.1, 0.2] and target vector \\(\\mathbf{y}_i\\) [1, 0, 0]. Then, we can compute the categorical cross entropy loss as:\n\\[\\begin{align*}\n-\\left(1\\cdot \\log (0.7) + 0 \\cdot \\log (0.1) + 0 \\cdot \\log(0.2)\\right) = 0.35667494\n\\end{align*}\\]\nLet’s that we have a batch of \\(3\\) samples. Additionally, suppose the target y_true is integer encoded. After running through the softmax activation function, the network’s output layer yields:\n\n%load_ext itikz\n\n\nimport numpy as np\n\ny_pred = np.array(\n    [\n        [0.7, 0.1, 0.2],\n        [0.1, 0.5, 0.4],\n        [0.02, 0.9, 0.08]\n    ]\n)\n\ny_true = [0, 1, 2]\n\nWith a collection of softmax outputs and their intended targets, we can map these indices to retrieve the predicted probabilities of the true class labels:\n\nfor targ_index, distribution in zip(y_true,y_pred):\n    print(distribution[targ_index])\n\n0.7\n0.5\n0.08\n\n\nThis can be simplified.\n\nprint(y_pred[[0,1,2],y_true])\n\n[0.7  0.5  0.08]\n\n\nnumpy lets us index an 2D-array in multiple ways. One of them is to use a list filled with row indices and a list with column indices. We could, thus, write:\n\nprint(y_pred[range(len(y_pred)),y_true])\n\n[0.7  0.5  0.08]\n\n\nThe categorical cross-entropy loss for each of the samples is:\n\nprint(-np.log(y_pred[range(len(y_pred)),y_true]))\n\n[0.35667494 0.69314718 2.52572864]\n\n\nFinally, we want an average loss for the entire batch, to have an idea about how our model is doing during the training phase. Therefore, we have:\n\nneg_log = -np.log(y_pred[range(len(y_pred)),y_true])\naverage_loss = np.mean(neg_log)\nprint(average_loss)\n\n1.191850256268978\n\n\nIn the case, that the targets are one-hot encoded, we need to handle this case a bit differently. If y_true.shape has \\(2\\) dimensions, then it implies, we have a set of one-hot encoded vectors. On the other hand, if y_true is a list, that is y_true.shape has \\(1\\) dimension, then it means, we have sparse labels/integer encoding.\n\nimport numpy as np\n\ny_pred = np.array(\n    [\n        [0.7, 0.1, 0.2],\n        [0.1, 0.5, 0.4],\n        [0.02, 0.9, 0.08]\n    ]\n)\n\ny_true = np.array(\n    [\n        [1, 0, 0],\n        [0, 1, 0],\n        [0, 0, 1]\n    ]\n)\n\ncorrect_confidences = np.array([])\n\n# If categorical labels\nif(len(y_pred.shape) == 1):\n    correct_confidences = y_pred[range(len(y_pred)), y_true]\nelif(len(y_pred.shape)==2):\n    correct_confidences = np.sum(y_pred * y_true, axis=1)\n\nneg_log = -np.log(correct_confidences)\naverage_loss = np.mean(neg_log)\nprint(average_loss)\n\n1.191850256268978\n\n\nIf the neural network output y_pred for some reason is the vector [1, 0, 0], this would result in numpy.log function returning a negative infinity. To avoid such situations, it’s safer to apply a ceil and floor to y_pred.\n\nepsilon = 1e-7\ny_pred_clipped = np.clip(y_pred, epsilon, 1-epsilon)"
  },
  {
    "objectID": "posts/backpropogation/index.html#calculating-the-network-error-with-loss",
    "href": "posts/backpropogation/index.html#calculating-the-network-error-with-loss",
    "title": "Backpropogation",
    "section": "",
    "text": "With a randomly initialized model, or even a model initialized with more sophisticated approaches, our goal is to train, or teach a model over time. To train a model, we tweak the weights and biases to improve the model’s accuracy and confidence. To do this, we calculate the error in our model. The loss function also referred to as the cost function quantifies the error.\n\n\nLet \\(\\vec{l} = \\mathbf{w}\\cdot \\mathbf{x} + \\mathbf{b}\\) be the result of the last dense layer of a neural network (the inner product between an input feature vector and the weights vector of the layer, added to the bias factor). This is commonly referred to as the logit vector in machine learning literature.\n\n\n\nLet \\(X\\) be a random variable with possible outcomes \\(\\mathcal{X}\\). Let \\(P\\) be the true probability distribution of \\(X\\) with probability mass function \\(p(x)\\). Let \\(Q\\) be an approximating distribution with probability mass function \\(q(x)\\).\nDefinition. The entropy of \\(P\\) is defined as:\n\\[\\begin{align*}\nH(P) = -\\sum_{x\\in\\mathcal{X}} p(x) \\cdot \\log p(x)\n\\end{align*}\\]\nIn information theory, entropy is the measure of uncertainty, surprise of a system. By taking the logarithm \\(\\log p(x)\\), we concentrate on the order of the surprise. Entropy, then, is an expectation over the uncertainties or the expected surprise.\nDefinition. The cross-entropy of \\(Q\\) relative to \\(P\\) is defined as:\n\\[\\begin{align*}\nH(P,Q) = -\\sum_{x\\in\\mathcal{X}} p(x) \\cdot \\log q(x)\n\\end{align*}\\]\nDefinition. For discrete distributions \\(P\\) and \\(Q\\) defined on the sample space \\(\\mathcal{X}\\), the Kullback-Leibler(KL) divergence (or relative entropy) from \\(Q\\) to \\(P\\) is defined as:\n\\[\\begin{align*}\nD_{KL}(P||Q) = -\\sum_{x\\in\\mathcal{X}} p(x) \\cdot \\log \\frac{p(x)}{q(x)}\n\\end{align*}\\]\nIntuitively, it is the expected excess surprise from using \\(Q\\) as a model instead of \\(P\\), when the actual distribution is \\(P\\). Note that, \\(D_{KL}(P||Q) \\neq D_{KL}(Q||P)\\), so it is not symmetric and hence it is not a norm.\n\n\n\nWe are going to work on a multi-class classification problem.\nFor any input \\(\\mathbf{x}_i\\), the target vector \\(\\mathbf{y}_i\\) could be specified using one-hot encoding or an integer in the range [0,numClasses).\nLet’s say, we have numClasses = 3.\nIn one-hot encoding, the target vector y_true is an array like [1, 0, 0], [0, 1, 0], or [0, 0, 1]. The category/class is determined by the index which is hot. For example, if y_true equals [0, 1, 0], then the sample belongs to class \\(1\\), whilst if y_true equals [0, 0, 1], the sample belongs to class \\(2\\).\nIn integer encoding, the target vector y_true is an integer. For example, if y_true equals \\(1\\), the sample belongs to class \\(1\\), whilst if y_true equals \\(2\\), the sample belongs to class \\(2\\).\nThe categorical_crossentropy is defined as:\n\\[\\begin{align*}\nL_i = -\\sum_{j} y_{i,j} \\log(\\hat{y}_{i,j})\n\\end{align*}\\]\nAssume that we have a softmax output \\(\\hat{\\mathbf{y}}_i\\), [0.7, 0.1, 0.2] and target vector \\(\\mathbf{y}_i\\) [1, 0, 0]. Then, we can compute the categorical cross entropy loss as:\n\\[\\begin{align*}\n-\\left(1\\cdot \\log (0.7) + 0 \\cdot \\log (0.1) + 0 \\cdot \\log(0.2)\\right) = 0.35667494\n\\end{align*}\\]\nLet’s that we have a batch of \\(3\\) samples. Additionally, suppose the target y_true is integer encoded. After running through the softmax activation function, the network’s output layer yields:\n\n%load_ext itikz\n\n\nimport numpy as np\n\ny_pred = np.array(\n    [\n        [0.7, 0.1, 0.2],\n        [0.1, 0.5, 0.4],\n        [0.02, 0.9, 0.08]\n    ]\n)\n\ny_true = [0, 1, 2]\n\nWith a collection of softmax outputs and their intended targets, we can map these indices to retrieve the predicted probabilities of the true class labels:\n\nfor targ_index, distribution in zip(y_true,y_pred):\n    print(distribution[targ_index])\n\n0.7\n0.5\n0.08\n\n\nThis can be simplified.\n\nprint(y_pred[[0,1,2],y_true])\n\n[0.7  0.5  0.08]\n\n\nnumpy lets us index an 2D-array in multiple ways. One of them is to use a list filled with row indices and a list with column indices. We could, thus, write:\n\nprint(y_pred[range(len(y_pred)),y_true])\n\n[0.7  0.5  0.08]\n\n\nThe categorical cross-entropy loss for each of the samples is:\n\nprint(-np.log(y_pred[range(len(y_pred)),y_true]))\n\n[0.35667494 0.69314718 2.52572864]\n\n\nFinally, we want an average loss for the entire batch, to have an idea about how our model is doing during the training phase. Therefore, we have:\n\nneg_log = -np.log(y_pred[range(len(y_pred)),y_true])\naverage_loss = np.mean(neg_log)\nprint(average_loss)\n\n1.191850256268978\n\n\nIn the case, that the targets are one-hot encoded, we need to handle this case a bit differently. If y_true.shape has \\(2\\) dimensions, then it implies, we have a set of one-hot encoded vectors. On the other hand, if y_true is a list, that is y_true.shape has \\(1\\) dimension, then it means, we have sparse labels/integer encoding.\n\nimport numpy as np\n\ny_pred = np.array(\n    [\n        [0.7, 0.1, 0.2],\n        [0.1, 0.5, 0.4],\n        [0.02, 0.9, 0.08]\n    ]\n)\n\ny_true = np.array(\n    [\n        [1, 0, 0],\n        [0, 1, 0],\n        [0, 0, 1]\n    ]\n)\n\ncorrect_confidences = np.array([])\n\n# If categorical labels\nif(len(y_pred.shape) == 1):\n    correct_confidences = y_pred[range(len(y_pred)), y_true]\nelif(len(y_pred.shape)==2):\n    correct_confidences = np.sum(y_pred * y_true, axis=1)\n\nneg_log = -np.log(correct_confidences)\naverage_loss = np.mean(neg_log)\nprint(average_loss)\n\n1.191850256268978\n\n\nIf the neural network output y_pred for some reason is the vector [1, 0, 0], this would result in numpy.log function returning a negative infinity. To avoid such situations, it’s safer to apply a ceil and floor to y_pred.\n\nepsilon = 1e-7\ny_pred_clipped = np.clip(y_pred, epsilon, 1-epsilon)"
  },
  {
    "objectID": "posts/backpropogation/index.html#categorical-cross-entropy-loss-class",
    "href": "posts/backpropogation/index.html#categorical-cross-entropy-loss-class",
    "title": "Backpropogation",
    "section": "Categorical Cross-Entropy Loss Class",
    "text": "Categorical Cross-Entropy Loss Class\nI first create an abstract base class Loss. Every Loss object exposes the calculate method which in turn calls Loss object’s forward method to compute the log-loss for each sample and then takes an average of the sample losses.\nCategoricalCrossEntropyLoss class is a child class of Loss and provides an implementation of the forward method.\n\nimport numpy as np\nimport nnfs\nfrom nnfs.datasets import spiral_data\nfrom abc import abstractmethod\n\n\n# Abstract base class for losses\nclass Loss:\n    @abstractmethod\n    def forward(self, y_pred, y_true):\n        pass\n\n    @abstractmethod\n    def backward(self, y_pred, y_true):\n        pass\n\n    # Calculates the data and regularization losses\n    # given model output and ground truth values\n    def calculate(self, output, y):\n\n        # Calculate the sample losses\n        sample_losses = self.forward(output, y)\n\n        # Calculate the mean loss\n        data_loss = np.mean(sample_losses)\n\n        # Return loss\n        return data_loss\n\n\n# Cross-Entropy loss\nclass CategoricalCrossEntropyLoss(Loss):\n\n    # Forward pass\n    def forward(self, y_pred, y_true):\n        num_samples = len(y_pred)\n\n        # Clip data to prevent division by 0\n        # Clip both sides to not drag mean towards any value\n        epsilon = 1e-7\n        y_pred_clipped = np.clip(y_pred, epsilon, 1 - epsilon)\n\n        # If categorical labels\n        if len(y_pred.shape) == 1:\n            correct_confidences = y_pred[range(len(y_pred)), y_true]\n        # else if one-hot encoding\n        elif len(y_pred.shape) == 2:\n            correct_confidences = np.sum(y_pred * y_true, axis=1)\n\n        neg_log = -np.log(correct_confidences)\n        return neg_log\n\nUsing the manual created outputs and targets, we have:\n\ny_pred = np.array(\n    [\n        [0.7, 0.1, 0.2],\n        [0.1, 0.5, 0.4],\n        [0.02, 0.9, 0.08]\n    ]\n)\n\ny_true = np.array(\n    [\n        [1, 0, 0],\n        [0, 1, 0],\n        [0, 0, 1]\n    ]\n)\n\nloss_function = CategoricalCrossEntropyLoss()\nloss = loss_function.calculate(y_pred, y_true)\nprint(loss)\n\n1.191850256268978"
  },
  {
    "objectID": "posts/backpropogation/index.html#backpropogation",
    "href": "posts/backpropogation/index.html#backpropogation",
    "title": "Backpropogation",
    "section": "Backpropogation",
    "text": "Backpropogation\nBackpropogation consists going backwards along the edges and passing along gradients. We are going to chop up a neuron into it’s elementary operations and draw a computational graph. Each node in the graph receives an upstream gradient. The goal is pass on the correct downstream gradient.\nEach node has a local gradient - the gradient of it’s output with respect to it’s input. Consider a node receiving an input \\(z\\) and producing an output \\(h=f(z)\\). Then, we have:\n\n\nShow the code\n%%itikz --temp-dir --tex-packages=tikz --tikz-libraries=arrows --implicit-standalone\n\\begin{tikzpicture}\n    \\node [circle,minimum size=40mm,draw] (f) at (0,0) {\\huge $f$};\n    \\node [blue] (localgrad) at (-1,0) {\\huge $\\frac{\\partial h}{\\partial z}$};\n    \\node [blue] (lgrad) at (0.0,1) {\\large Local gradient};\n    \\draw [-&gt;, shorten &gt;=1pt] (1.80,1) -- node [above,midway] {\\huge $h$} (5,1);\n    \\draw [-&gt;, shorten &gt;=1pt] (5,-1) -- node [below,midway] {\\huge $\\frac{\\partial s}{\\partial h}$} (1.80,-1);\n    \\node [] (upgrad) at (4.0,-3) {\\huge Upstream gradient};\n    \\draw [-&gt;, shorten &gt;=1pt] (-5,1) -- node [above,midway] {\\huge $z$} (-1.80,1);\n    \\draw [-&gt;, shorten &gt;=1pt] (-1.80,-1) -- node [below,midway] {\\huge $\\frac{\\partial s}{\\partial z} = \\frac{\\partial s}{\\partial h} \\cdot \\frac{\\partial h}{\\partial z}$} (-5,-1);\n    \\node [] (downgrad) at (-4.0,-3) {\\huge Downstream gradient};\n\\end{tikzpicture}\n\n\n\n\n\nThe downstream gradient \\(\\frac{\\partial s}{\\partial z}\\) equals the upstream graient \\(\\frac{\\partial s}{\\partial h}\\) times the local gradient \\(\\frac{\\partial h}{\\partial z}\\).\nWhat about nodes with multiple inputs? Say that, \\(h=f(x,y)\\). Multiple inputs imply multiple local gradients.\n\n\nShow the code\n%%itikz --temp-dir --tex-packages=tikz --tikz-libraries=arrows --implicit-standalone\n\\begin{tikzpicture}[x=0.75pt,y=0.75pt,yscale=-1,scale=1.75]\n%uncomment if require: \\path (0,216); %set diagram left start at 0, and has height of 216\n\n%Shape: Circle [id:dp08328772161506959] \n\\draw   (302.75,83.38) .. controls (302.75,53.62) and (326.87,29.5) .. (356.63,29.5) .. controls (386.38,29.5) and (410.5,53.62) .. (410.5,83.38) .. controls (410.5,113.13) and (386.38,137.25) .. (356.63,137.25) .. controls (326.87,137.25) and (302.75,113.13) .. (302.75,83.38) -- cycle ;\n%Straight Lines [id:da2730189357413113] \n\\draw    (406,59.38) -- (513.5,59.74) ;\n\\draw [shift={(515.5,59.75)}, rotate = 180.2] [color={rgb, 255:red, 0; green, 0; blue, 0 }  ][line width=0.75]    (10.93,-3.29) .. controls (6.95,-1.4) and (3.31,-0.3) .. (0,0) .. controls (3.31,0.3) and (6.95,1.4) .. (10.93,3.29)   ;\n%Straight Lines [id:da21080101466010737] \n\\draw    (515,110.75) -- (405,110.26) ;\n\\draw [shift={(403,110.25)}, rotate = 0.26] [color={rgb, 255:red, 0; green, 0; blue, 0 }  ][line width=0.75]    (10.93,-3.29) .. controls (6.95,-1.4) and (3.31,-0.3) .. (0,0) .. controls (3.31,0.3) and (6.95,1.4) .. (10.93,3.29)   ;\n%Straight Lines [id:da05192158713361961] \n\\draw    (209,1.75) -- (309.71,51.37) ;\n\\draw [shift={(311.5,52.25)}, rotate = 206.23] [color={rgb, 255:red, 0; green, 0; blue, 0 }  ][line width=0.75]    (10.93,-3.29) .. controls (6.95,-1.4) and (3.31,-0.3) .. (0,0) .. controls (3.31,0.3) and (6.95,1.4) .. (10.93,3.29)   ;\n%Straight Lines [id:da3568530309648137] \n\\draw    (305,68.25) -- (204.31,20.61) ;\n\\draw [shift={(202.5,19.75)}, rotate = 25.32] [color={rgb, 255:red, 0; green, 0; blue, 0 }  ][line width=0.75]    (10.93,-3.29) .. controls (6.95,-1.4) and (3.31,-0.3) .. (0,0) .. controls (3.31,0.3) and (6.95,1.4) .. (10.93,3.29)   ;\n%Straight Lines [id:da4437541566257528] \n\\draw    (205,167.25) -- (311.2,116.12) ;\n\\draw [shift={(313,115.25)}, rotate = 154.29] [color={rgb, 255:red, 0; green, 0; blue, 0 }  ][line width=0.75]    (10.93,-3.29) .. controls (6.95,-1.4) and (3.31,-0.3) .. (0,0) .. controls (3.31,0.3) and (6.95,1.4) .. (10.93,3.29)   ;\n%Straight Lines [id:da2672766038605987] \n\\draw    (304.5,101.75) -- (205.82,146.92) ;\n\\draw [shift={(204,147.75)}, rotate = 335.41] [color={rgb, 255:red, 0; green, 0; blue, 0 }  ][line width=0.75]    (10.93,-3.29) .. controls (6.95,-1.4) and (3.31,-0.3) .. (0,0) .. controls (3.31,0.3) and (6.95,1.4) .. (10.93,3.29)   ;\n\n% Text Node\n\\draw (352,76.4) node [anchor=north west][inner sep=0.75pt]    {\\huge $f$};\n% Text Node\n\\draw (318.5,44.4) node [anchor=north west][inner sep=0.75pt]  [font=\\small,color={rgb, 255:red, 0; green, 28; blue, 247 }  ,opacity=1 ]  {\\huge $\\frac{\\partial h}{\\partial x}$};\n% Text Node\n\\draw (318.5,88.9) node [anchor=north west][inner sep=0.75pt]  [font=\\small,color={rgb, 255:red, 0; green, 36; blue, 255 }  ,opacity=1 ]  {\\huge $\\frac{\\partial h}{\\partial y}$};\n% Text Node\n\\draw (258.5,7.4) node [anchor=north west][inner sep=0.75pt]    {\\huge $x$};\n% Text Node\n\\draw (264,136.9) node [anchor=north west][inner sep=0.75pt]    {\\huge $y$};\n% Text Node\n\\draw (151.5,96.9) node [anchor=north west][inner sep=0.75pt]  [font=\\small,color={rgb, 255:red, 0; green, 28; blue, 247 }  ,opacity=1 ]  {\\huge $\\frac{\\partial s}{\\partial y} =\\frac{\\partial s}{\\partial h} \\cdot \\frac{\\partial h}{\\partial y}$};\n% Text Node\n\\draw (150,33.4) node [anchor=north west][inner sep=0.75pt]  [font=\\small,color={rgb, 255:red, 0; green, 28; blue, 247 }  ,opacity=1 ]  {\\huge $\\frac{\\partial s}{\\partial x} =\\frac{\\partial s}{\\partial h} \\cdot \\frac{\\partial h}{\\partial x}$};\n% Text Node\n\\draw (322.5,4.9) node [anchor=north west][inner sep=0.75pt]    {\\huge $h=f(x,y)$};\n% Text Node\n\\draw (449.5,39.9) node [anchor=north west][inner sep=0.75pt]    {\\huge $h$};\n% Text Node\n\\draw (451.5,112.9) node [anchor=north west][inner sep=0.75pt]    {\\huge $\\frac{\\partial s}{\\partial h}$};\n% Text Node\n\\draw (164.5,172.9) node [anchor=north west][inner sep=0.75pt]    {\\huge $ \\begin{array}{l}\nDownstream\\ \\\\\ngradients\n\\end{array}$};\n% Text Node\n\\draw (430.5,175.4) node [anchor=north west][inner sep=0.75pt]    {\\huge $ \\begin{array}{l}\nUpstream\\ \\\\\ngradients\n\\end{array}$};\n% Text Node\n\\draw (318.5,173.9) node [anchor=north west][inner sep=0.75pt]  [color={rgb, 255:red, 3; green, 50; blue, 255 }  ,opacity=1 ]  {\\huge $ \\begin{array}{l}\nLocal\\ \\\\\ngradients\n\\end{array}$};\n\n\n\\end{tikzpicture}\n\n\n\n\n\nLet’s start with a simple forward pass with \\(1\\) neuron. Let’s say, we have the following input vector, weights and bias:\n\nx = [1.0, -2.0, 3.0]  # input values\nw = [-3.0, -1.0, 2.0] # weights\nb = 1.0\n\n# Forward pass\nz = np.dot(x,w) + b\n\n# ReLU Activation function\ny = max(z, 0)\n\n\n\nShow the code\n%%itikz --temp-dir --tex-packages=tikz --tikz-libraries=arrows --implicit-standalone\n\\begin{tikzpicture}\n\\foreach \\i in {0,...,2}\n{\n    \\node[] (Input-\\i) at (0,-\\i * 4) {\\large $x[\\i]$};\n}\n\\foreach \\i in {0,...,2}\n{\n    \\node[] (Weight-\\i) at (0,-\\i * 4-2) {\\large $w[\\i]$};\n}\n\\foreach \\i in {0,...,2}\n{\n    \\node[circle, \n        minimum size = 15mm,\n        draw,\n        ] (Mult-\\i) at (3.0,-\\i * 4 - 1) {\\large $\\times$};\n        \n}\n\n\\node [] (bias) at (0,-12) {\\large $b$};\n\n\\node [circle,minimum size=15mm,draw] (Add) at (6,-5) {\\large +};\n\\node [circle,minimum size=15mm,draw] (ReLU) at (9,-5) {\\large $\\max(x,0)$};\n\\node [] (NextLayer) at (12,-5) {};\n\n\\draw[-&gt;, shorten &gt;=1pt] (Input-0) -- node[midway,above,blue] {\\large $1.0$} (Mult-0);   \n\\draw[-&gt;, shorten &gt;=1pt] (Weight-0) -- node[midway,above,blue] {\\large $-3.0$} (Mult-0);   \n\\draw[-&gt;, shorten &gt;=1pt] (Input-1) -- node[midway,above,blue] {\\large $-2.0$}(Mult-1);   \n\\draw[-&gt;, shorten &gt;=1pt] (Weight-1) -- node[midway,above,blue] {\\large $-1.0$}(Mult-1);   \n\\draw[-&gt;, shorten &gt;=1pt] (Input-2) -- node[midway,above,blue] {\\large $3.0$}(Mult-2);   \n\\draw[-&gt;, shorten &gt;=1pt] (Weight-2) -- node[midway,above,blue] {\\large $2.0$}(Mult-2);   \n\n\\draw (bias) -- node[midway,above,blue] {\\large $1.0$}(6,-12);\n\\draw[-&gt;, shorten &gt;=1pt] (6,-12) -- (Add);\n\n\\draw[-&gt;, shorten &gt;=1pt] (Mult-0) -- node[midway,above,blue] {\\large $-3.0$}(Add);   \n\\draw[-&gt;, shorten &gt;=1pt] (Mult-1) -- node[midway,above,blue] {\\large $2.0$}(Add);   \n\\draw[-&gt;, shorten &gt;=1pt] (Mult-2) -- node[midway,above,blue] {\\large $6.0$}(Add);   \n\n\\draw[-&gt;, shorten &gt;=1pt] (Add) -- node[midway,above,blue] {\\large $6.0$}(ReLU);   \n\\draw[-&gt;, shorten &gt;=1pt] (ReLU) -- node[midway,above,blue] {\\large $6.0$}(NextLayer);\n\\node [red] (A) at (11,-5.5) {\\large $1.00$};\n\\end{tikzpicture}\n\n\n\n\n\nThe ReLU function \\(f(x)=\\max(x,0)\\) is differentiable everywhere except at \\(x = 0\\). We define \\(f'(x)\\) as:\n\\[\\begin{align*}\nf'(x) =\n\\begin{cases}\n1 & x &gt; 0 \\\\\n0 & \\text{otherwise}\n\\end{cases}\n\\end{align*}\\]\nIn Python, we write:\n\nrelu_dz = (1. if z &gt; 0 else 0.)\n\nThe input to the ReLU function is \\(6.00\\), so the derivative equals \\(1.00\\). We multiply this local gradient by the upstream gradient to calculate the downstream gradient.\n\nimport numpy as np\n\nx = [1.0, -2.0, 3.0]  # input values\nw = [-3.0, -1.0, 2.0]  # weights\nb = 1.0\n\n# Forward pass\nz = np.dot(x, w) + b\n\n# ReLU Activation function\ny = max(z, 0)\n\n# Backward pass\n# Upstream gradient\nds_drelu = 1.0\n\n# Derivative of the ReLU and the chain rule\ndrelu_dz = 1.0 if z &gt; 0 else 0.0\nds_dz = ds_drelu * drelu_dz\nprint(ds_dz)\n\n1.0\n\n\nThe results with the derivative of the ReLU function and chain rule look as follows:\n\n\nShow the code\n%%itikz --temp-dir --tex-packages=tikz --tikz-libraries=arrows --implicit-standalone\n\\begin{tikzpicture}\n\\foreach \\i in {0,...,2}\n{\n    \\node[] (Input-\\i) at (0,-\\i * 4) {\\large $x[\\i]$};\n}\n\\foreach \\i in {0,...,2}\n{\n    \\node[] (Weight-\\i) at (0,-\\i * 4-2) {\\large $w[\\i]$};\n}\n\\foreach \\i in {0,...,2}\n{\n    \\node[circle, \n        minimum size = 15mm,\n        draw,\n        ] (Mult-\\i) at (3.0,-\\i * 4 - 1) {\\large $\\times$};\n        \n}\n\n\\node [] (bias) at (0,-12) {\\large $b$};\n\n\\node [circle,minimum size=15mm,draw] (Add) at (6,-5) {\\large +};\n\\node [circle,minimum size=15mm,draw] (ReLU) at (9,-5) {\\large $\\max(x,0)$};\n\\node [] (NextLayer) at (12,-5) {};\n\n\\draw[-&gt;, shorten &gt;=1pt] (Input-0) -- node[midway,above,blue] {\\large $1.0$} (Mult-0);   \n\\draw[-&gt;, shorten &gt;=1pt] (Weight-0) -- node[midway,above,blue] {\\large $-3.0$} (Mult-0);   \n\\draw[-&gt;, shorten &gt;=1pt] (Input-1) -- node[midway,above,blue] {\\large $-2.0$}(Mult-1);   \n\\draw[-&gt;, shorten &gt;=1pt] (Weight-1) -- node[midway,above,blue] {\\large $-1.0$}(Mult-1);   \n\\draw[-&gt;, shorten &gt;=1pt] (Input-2) -- node[midway,above,blue] {\\large $3.0$}(Mult-2);   \n\\draw[-&gt;, shorten &gt;=1pt] (Weight-2) -- node[midway,above,blue] {\\large $2.0$}(Mult-2);   \n\n\\draw (bias) -- node[midway,above,blue] {\\large $1.0$}(6,-12);\n\\draw[-&gt;, shorten &gt;=1pt] (6,-12) -- (Add);\n\n\\draw[-&gt;, shorten &gt;=1pt] (Mult-0) -- node[midway,above,blue] {\\large $-3.0$}(Add);   \n\\draw[-&gt;, shorten &gt;=1pt] (Mult-1) -- node[midway,above,blue] {\\large $2.0$}(Add);   \n\\draw[-&gt;, shorten &gt;=1pt] (Mult-2) -- node[midway,above,blue] {\\large $6.0$}(Add);   \n\n\\draw[-&gt;, shorten &gt;=1pt] (Add) -- node[midway,above,blue] {\\large $6.0$}(ReLU);   \n\\draw[-&gt;, shorten &gt;=1pt] (ReLU) -- node[midway,above,blue] {\\large $6.0$}(NextLayer);\n\\node [red] (A) at (11,-5.5) {\\large $1.00$};\n\\node [red] (B) at (7,-5.5) {\\large $1.00$};\n\\end{tikzpicture}\n\n\n\n\n\nMoving backward through our neural network, consider the add function \\(f(x,y,z)=x + y + z\\). The partial derivatives \\(\\frac{\\partial f}{\\partial x}\\), \\(\\frac{\\partial f}{\\partial y}\\) and \\(\\frac{\\partial f}{\\partial z}\\) are all equal to \\(1\\). So, the add gate always takes on the gradient on its output and distributes it equally to all of its inputs, regardless of what their values were during the forward pass.\n\n# Local gradients for the + function\ndz_dw0x0 = 1\ndz_dw1x1 = 1\ndz_dw2x2 = 1\ndz_db = 1\n\n# Calculate the downstream gradients\nds_dw0x0 = ds_dz * dz_dw0x0\nds_dw1x1 = ds_dz * dz_dw1x1\nds_dw2x2 = ds_dz * dz_dw2x2\nds_db = ds_dz * dz_db\nprint(ds_dw0x0, ds_dw1x1, ds_dw2x2, ds_db)\n\n1.0 1.0 1.0 1.0\n\n\nWe can update the computation graph as:\n\n\nShow the code\n%%itikz --temp-dir --tex-packages=tikz --tikz-libraries=arrows --implicit-standalone\n\\begin{tikzpicture}\n\\foreach \\i in {0,...,2}\n{\n    \\node[] (Input-\\i) at (0,-\\i * 4) {\\large $x[\\i]$};\n}\n\\foreach \\i in {0,...,2}\n{\n    \\node[] (Weight-\\i) at (0,-\\i * 4-2) {\\large $w[\\i]$};\n}\n\\foreach \\i in {0,...,2}\n{\n    \\node[circle, \n        minimum size = 15mm,\n        draw,\n        ] (Mult-\\i) at (3.0,-\\i * 4 - 1) {\\large $\\times$};\n        \n}\n\n\\node [] (bias) at (0,-12) {\\large $b$};\n\n\\node [circle,minimum size=15mm,draw] (Add) at (6,-5) {\\large +};\n\\node [circle,minimum size=15mm,draw] (ReLU) at (9,-5) {\\large $\\max(x,0)$};\n\\node [] (NextLayer) at (12,-5) {};\n\n\\draw[-&gt;, shorten &gt;=1pt] (Input-0) -- node[midway,above,blue] {\\large $1.0$} (Mult-0);   \n\\draw[-&gt;, shorten &gt;=1pt] (Weight-0) -- node[midway,above,blue] {\\large $-3.0$} (Mult-0);   \n\\draw[-&gt;, shorten &gt;=1pt] (Input-1) -- node[midway,above,blue] {\\large $-2.0$}(Mult-1);   \n\\draw[-&gt;, shorten &gt;=1pt] (Weight-1) -- node[midway,above,blue] {\\large $-1.0$}(Mult-1);   \n\\draw[-&gt;, shorten &gt;=1pt] (Input-2) -- node[midway,above,blue] {\\large $3.0$}(Mult-2);   \n\\draw[-&gt;, shorten &gt;=1pt] (Weight-2) -- node[midway,above,blue] {\\large $2.0$}(Mult-2);   \n\n\\draw (bias) -- node[midway,above,blue] {\\large $1.0$}(6,-12);\n\\draw[-&gt;, shorten &gt;=1pt] (6,-12) -- (Add);\n\n\\draw[-&gt;, shorten &gt;=1pt] (Mult-0) -- node[midway,above,blue] {\\large $-3.0$}(Add);   \n\\draw[-&gt;, shorten &gt;=1pt] (Mult-1) -- node[midway,above,blue] {\\large $2.0$}(Add);   \n\\draw[-&gt;, shorten &gt;=1pt] (Mult-2) -- node[midway,above,blue] {\\large $6.0$}(Add);   \n\n\\draw[-&gt;, shorten &gt;=1pt] (Add) -- node[midway,above,blue] {\\large $6.0$}(ReLU);   \n\\draw[-&gt;, shorten &gt;=1pt] (ReLU) -- node[midway,above,blue] {\\large $6.0$}(NextLayer);\n\\node [red] (A) at (11,-5.5) {\\large $1.00$};\n\\node [red] (B) at (7,-5.5) {\\large $1.00$};\n\\node [red] (C) at (5,-3.5) {\\large $1.00$};\n\\node [red] (D) at (5,-5.5) {\\large $1.00$};\n\\node [red] (E) at (5,-7.5) {\\large $1.00$};\n\\node [red] (f) at (5,-12.5) {\\large $1.00$};\n\\end{tikzpicture}\n\n\n\n\n\nNow, consider the production function \\(f(x,y) = x * y\\). The gradients of \\(f\\) are \\(\\frac{\\partial f}{\\partial x} = y\\), \\(\\frac{\\partial f}{\\partial y} = x\\). The multiply gate is therefore a little less easy to interpret. Its local gradients are the input values, except switched and this is multiplied by the upstream gradient.\n\n# Local gradients for the * function\ndw0x0_dx0 = w[0]\ndw0x0_dw0 = x[0]\ndw1x1_dx1 = w[1]\ndw1x1_dw1 = x[1]\ndw2x2_dx2 = w[2]\ndw2x2_dw2 = x[2]\n\n# Calculate the downstream gradients\nds_dx0 = ds_dw0x0 * dw0x0_dx0\nds_dw0 = ds_dw0x0 * dw0x0_dw0\nds_dx1 = ds_dw1x1 * dw1x1_dx1\nds_dw1 = ds_dw1x1 * dw1x1_dw1\nds_dx2 = ds_dw2x2 * dw2x2_dx2\nds_dw2 = ds_dw2x2 * dw2x2_dw2\n\nprint(ds_dx0, ds_dw0, ds_dx1, ds_dw1, ds_dx2, ds_dw2)\n\n-3.0 1.0 -1.0 -2.0 2.0 3.0\n\n\nWe can update the computation graph as follows:\n\n\nShow the code\n%%itikz --temp-dir --tex-packages=tikz --tikz-libraries=arrows --implicit-standalone\n\\begin{tikzpicture}\n\\foreach \\i in {0,...,2}\n{\n    \\node[] (Input-\\i) at (0,-\\i * 4) {\\large $x[\\i]$};\n}\n\\foreach \\i in {0,...,2}\n{\n    \\node[] (Weight-\\i) at (0,-\\i * 4-2) {\\large $w[\\i]$};\n}\n\\foreach \\i in {0,...,2}\n{\n    \\node[circle, \n        minimum size = 15mm,\n        draw,\n        ] (Mult-\\i) at (3.0,-\\i * 4 - 1) {\\large $\\times$};\n        \n}\n\n\\node [] (bias) at (0,-12) {\\large $b$};\n\n\\node [circle,minimum size=15mm,draw] (Add) at (6,-5) {\\large +};\n\\node [circle,minimum size=15mm,draw] (ReLU) at (9,-5) {\\large $\\max(x,0)$};\n\\node [] (NextLayer) at (12,-5) {};\n\n\\draw[-&gt;, shorten &gt;=1pt] (Input-0) -- node[midway,above,blue] {\\large $1.0$} (Mult-0);   \n\\draw[-&gt;, shorten &gt;=1pt] (Weight-0) -- node[midway,above,blue] {\\large $-3.0$} (Mult-0);   \n\\draw[-&gt;, shorten &gt;=1pt] (Input-1) -- node[midway,above,blue] {\\large $-2.0$}(Mult-1);   \n\\draw[-&gt;, shorten &gt;=1pt] (Weight-1) -- node[midway,above,blue] {\\large $-1.0$}(Mult-1);   \n\\draw[-&gt;, shorten &gt;=1pt] (Input-2) -- node[midway,above,blue] {\\large $3.0$}(Mult-2);   \n\\draw[-&gt;, shorten &gt;=1pt] (Weight-2) -- node[midway,above,blue] {\\large $2.0$}(Mult-2);   \n\n\\draw (bias) -- node[midway,above,blue] {\\large $1.0$}(6,-12);\n\\draw[-&gt;, shorten &gt;=1pt] (6,-12) -- (Add);\n\n\\draw[-&gt;, shorten &gt;=1pt] (Mult-0) -- node[midway,above,blue] {\\large $-3.0$}(Add);   \n\\draw[-&gt;, shorten &gt;=1pt] (Mult-1) -- node[midway,above,blue] {\\large $2.0$}(Add);   \n\\draw[-&gt;, shorten &gt;=1pt] (Mult-2) -- node[midway,above,blue] {\\large $6.0$}(Add);   \n\n\\draw[-&gt;, shorten &gt;=1pt] (Add) -- node[midway,above,blue] {\\large $6.0$}(ReLU);   \n\\draw[-&gt;, shorten &gt;=1pt] (ReLU) -- node[midway,above,blue] {\\large $6.0$}(NextLayer);\n\\node [red] (A) at (11,-5.5) {\\large $1.00$};\n\\node [red] (B) at (7,-5.5) {\\large $1.00$};\n\\node [red] (C) at (5,-3.5) {\\large $1.00$};\n\\node [red] (D) at (5,-5.5) {\\large $1.00$};\n\\node [red] (E) at (5,-7.5) {\\large $1.00$};\n\\node [red] (F) at (5,-12.5) {\\large $1.00$};\n\\node [red] (G) at (1,-0.75) {\\large $-3.0$};\n\\node [red] (H) at (1,-2) {\\large $1.0$};\n\\node [red] (I) at (1,-4.75) {\\large $-1.0$};\n\\node [red] (J) at (1,-6) {\\large $-2.0$};\n\\node [red] (K) at (1,-8.75) {\\large $2.0$};\n\\node [red] (L) at (1,-10) {\\large $3.0$};\n\\end{tikzpicture}\n\n\n\n\n\nGradients sum at outward branches. Consider the following computation graph:\n\n\nShow the code\n%%itikz --temp-dir --tex-packages=tikz --tikz-libraries=arrows --implicit-standalone\n\\begin{tikzpicture}[x=0.75pt,y=0.75pt,yscale=-1,xscale=1]\n%uncomment if require: \\path (0,211); %set diagram left start at 0, and has height of 211\n\n%Shape: Ellipse [id:dp4612472925724298] \n\\draw   (444.62,95) .. controls (444.62,81.19) and (455.38,70) .. (468.64,70) .. controls (481.91,70) and (492.66,81.19) .. (492.66,95) .. controls (492.66,108.81) and (481.91,120) .. (468.64,120) .. controls (455.38,120) and (444.62,108.81) .. (444.62,95) -- cycle ;\n%Shape: Ellipse [id:dp4844626229099638] \n\\draw   (299.33,31.5) .. controls (299.33,17.69) and (310.08,6.5) .. (323.35,6.5) .. controls (336.61,6.5) and (347.37,17.69) .. (347.37,31.5) .. controls (347.37,45.31) and (336.61,56.5) .. (323.35,56.5) .. controls (310.08,56.5) and (299.33,45.31) .. (299.33,31.5) -- cycle ;\n%Shape: Ellipse [id:dp2271780920027553] \n\\draw   (303.25,94.7) .. controls (303.25,80.89) and (314,69.7) .. (327.27,69.7) .. controls (340.53,69.7) and (351.29,80.89) .. (351.29,94.7) .. controls (351.29,108.51) and (340.53,119.7) .. (327.27,119.7) .. controls (314,119.7) and (303.25,108.51) .. (303.25,94.7) -- cycle ;\n%Shape: Ellipse [id:dp150108609534231] \n\\draw   (299.25,167.7) .. controls (299.25,153.89) and (310,142.7) .. (323.27,142.7) .. controls (336.53,142.7) and (347.29,153.89) .. (347.29,167.7) .. controls (347.29,181.51) and (336.53,192.7) .. (323.27,192.7) .. controls (310,192.7) and (299.25,181.51) .. (299.25,167.7) -- cycle ;\n%Straight Lines [id:da7844123205705824] \n\\draw    (347.37,31.5) -- (450.04,76.06) ;\n\\draw [shift={(452.79,77.25)}, rotate = 203.46] [fill={rgb, 255:red, 0; green, 0; blue, 0 }  ][line width=0.08]  [draw opacity=0] (6.25,-3) -- (0,0) -- (6.25,3) -- cycle    ;\n%Straight Lines [id:da814168086414518] \n\\draw    (351.29,94.7) -- (441.62,94.99) ;\n\\draw [shift={(444.62,95)}, rotate = 180.18] [fill={rgb, 255:red, 0; green, 0; blue, 0 }  ][line width=0.08]  [draw opacity=0] (6.25,-3) -- (0,0) -- (6.25,3) -- cycle    ;\n%Straight Lines [id:da7411937688169676] \n\\draw    (347.29,167.7) -- (446.35,110.75) ;\n\\draw [shift={(448.95,109.25)}, rotate = 150.1] [fill={rgb, 255:red, 0; green, 0; blue, 0 }  ][line width=0.08]  [draw opacity=0] (6.25,-3) -- (0,0) -- (6.25,3) -- cycle    ;\n%Shape: Circle [id:dp515320046458885] \n\\draw   (163,96) .. controls (163,82.19) and (174.19,71) .. (188,71) .. controls (201.81,71) and (213,82.19) .. (213,96) .. controls (213,109.81) and (201.81,121) .. (188,121) .. controls (174.19,121) and (163,109.81) .. (163,96) -- cycle ;\n%Straight Lines [id:da6219161786925074] \n\\draw    (492.66,95) -- (567,94.52) ;\n\\draw [shift={(570,94.5)}, rotate = 179.63] [fill={rgb, 255:red, 0; green, 0; blue, 0 }  ][line width=0.08]  [draw opacity=0] (6.25,-3) -- (0,0) -- (6.25,3) -- cycle    ;\n%Straight Lines [id:da5694521418691749] \n\\draw    (84.5,95.75) -- (160,95.99) ;\n\\draw [shift={(163,96)}, rotate = 180.18] [fill={rgb, 255:red, 0; green, 0; blue, 0 }  ][line width=0.08]  [draw opacity=0] (8.04,-3.86) -- (0,0) -- (8.04,3.86) -- (5.34,0) -- cycle    ;\n%Straight Lines [id:da08990804845355682] \n\\draw    (210.69,85.5) -- (296.86,31.4) ;\n\\draw [shift={(299.4,29.8)}, rotate = 147.88] [fill={rgb, 255:red, 0; green, 0; blue, 0 }  ][line width=0.08]  [draw opacity=0] (6.25,-3) -- (0,0) -- (6.25,3) -- cycle    ;\n%Straight Lines [id:da1505672958459916] \n\\draw    (212.61,96) -- (300.4,95.03) ;\n\\draw [shift={(303.4,95)}, rotate = 179.37] [fill={rgb, 255:red, 0; green, 0; blue, 0 }  ][line width=0.08]  [draw opacity=0] (6.25,-3) -- (0,0) -- (6.25,3) -- cycle    ;\n%Straight Lines [id:da23258128449735227] \n\\draw    (203,116.5) -- (296.36,167.17) ;\n\\draw [shift={(299,168.6)}, rotate = 208.49] [fill={rgb, 255:red, 0; green, 0; blue, 0 }  ][line width=0.08]  [draw opacity=0] (6.25,-3) -- (0,0) -- (6.25,3) -- cycle    ;\n\n% Text Node\n\\draw (464.08,84.4) node [anchor=north west][inner sep=0.75pt]    {\\huge $s$};\n% Text Node\n\\draw (317.25,18.9) node [anchor=north west][inner sep=0.75pt]    {\\huge $z^{1}$};\n% Text Node\n\\draw (321.65,82.6) node [anchor=north west][inner sep=0.75pt]    {\\huge $z^{2}$};\n% Text Node\n\\draw (317.65,155.6) node [anchor=north west][inner sep=0.75pt]    {\\huge $z^{3}$};\n% Text Node\n\\draw (365.04,44.2) node [anchor=north west][inner sep=0.75pt]  [color={rgb, 255:red, 0; green, 13; blue, 247 }  ,opacity=1 ]  {\\huge $\\frac{\\partial s}{\\partial z^{1}}$};\n% Text Node\n\\draw (365.52,94.3) node [anchor=north west][inner sep=0.75pt]  [color={rgb, 255:red, 0; green, 13; blue, 247 }  ,opacity=1 ]  {\\huge $\\frac{\\partial s}{\\partial z^{2}}$};\n% Text Node\n\\draw (366.72,154) node [anchor=north west][inner sep=0.75pt]  [color={rgb, 255:red, 0; green, 13; blue, 247 }  ,opacity=1 ]  {\\huge $\\frac{\\partial s}{\\partial z^{3}}$};\n% Text Node\n\\draw (183.5,85.4) node [anchor=north west][inner sep=0.75pt]    {\\huge $a$};\n% Text Node\n\\draw (304.78,21.4) node [anchor=north west][inner sep=0.75pt]  [font=\\tiny,color={rgb, 255:red, 0; green, 13; blue, 247 }  ,opacity=1 ]  {\\normalsize $\\frac{\\partial z^{1}}{\\partial a}$};\n% Text Node\n\\draw (305.82,84.6) node [anchor=north west][inner sep=0.75pt]  [font=\\tiny,color={rgb, 255:red, 0; green, 13; blue, 247 }  ,opacity=1 ]  {\\normalsize $\\frac{\\partial z^{2}}{\\partial a}$};\n% Text Node\n\\draw (303.26,156.6) node [anchor=north west][inner sep=0.75pt]  [font=\\tiny,color={rgb, 255:red, 0; green, 13; blue, 247 }  ,opacity=1 ]  {\\normalsize $\\frac{\\partial z^{3}}{\\partial a}$};\n% Text Node\n\\draw (251.38,53.4) node [anchor=north west][inner sep=0.75pt]  [font=\\tiny,color={rgb, 255:red, 0; green, 13; blue, 247 }  ,opacity=1 ]  {\\normalsize $\\frac{\\partial s}{\\partial z^{1}} \\cdot \\frac{\\partial z^{1}}{\\partial a}$};\n% Text Node\n\\draw (249.38,99.8) node [anchor=north west][inner sep=0.75pt]  [font=\\tiny,color={rgb, 255:red, 0; green, 13; blue, 247 }  ,opacity=1 ]  {\\normalsize $\\frac{\\partial s}{\\partial z^{2}} \\cdot \\frac{\\partial z^{2}}{\\partial a}$};\n% Text Node\n\\draw (245.78,165.8) node [anchor=north west][inner sep=0.75pt]  [font=\\tiny,color={rgb, 255:red, 0; green, 13; blue, 247 }  ,opacity=1 ]  {\\normalsize $\\frac{\\partial s}{\\partial z^{3}} \\cdot \\frac{\\partial z^{3}}{\\partial a}$};\n\n\n\\end{tikzpicture}\n\n\n\n\n\nThe upstream gradient for the node \\(a\\) is \\(\\frac{ds}{da}\\). By the law of total derivatives:\n\\[\\begin{align*}\n\\frac{ds}{da} = \\frac{\\partial s}{\\partial z^1} \\cdot \\frac{\\partial z^1}{\\partial a} + \\frac{\\partial s}{\\partial z^2} \\cdot \\frac{\\partial z^2}{\\partial a} + \\frac{\\partial s}{\\partial z^3} \\cdot \\frac{\\partial z^3}{\\partial a}\n\\end{align*}\\]"
  },
  {
    "objectID": "posts/backpropogation/index.html#backprop-for-a-single-neuron---a-python-implementation",
    "href": "posts/backpropogation/index.html#backprop-for-a-single-neuron---a-python-implementation",
    "title": "Backpropogation",
    "section": "Backprop for a single neuron - a python implementation",
    "text": "Backprop for a single neuron - a python implementation\nWe can write a naive implementation for the backprop algorithm for a single neuron.\n\nimport numpy as np\n\nweights = np.array([-3.0, -1.0, 2.0])\nbias = 1.0\ninputs = np.array([1.0, -2.0, 3.0])\ntarget_output = 0.0\nlearning_rate = 0.001\n\n\ndef relu(x):\n    return np.maximum(x, 0)\n\n\ndef relu_derivative(x):\n    return np.where(x &gt; 0, 1.0, 0.0)\n\n\nfor iter in range(200):\n    # Forward pass\n    z = np.dot(weights, inputs) + bias\n    a = relu(z)\n    loss = (a - target_output) ** 2\n\n    # Backward pass\n    dloss_da = 2 * (a - target_output)\n    dloss_dz = dloss_da * relu_derivative(z)\n    dz_dx = weights\n    dz_dw = inputs\n    dz_db = 1.0\n    dloss_dx = dloss_dz * dz_dx\n    dloss_dw = dloss_dz * dz_dw\n    dloss_db = dloss_dz * dz_db\n\n    # Update the weights and bias\n    weights -= learning_rate * dloss_dw\n    bias -= learning_rate * dloss_db\n\n    # print the loss for this iteration\n    if (iter + 1) % 10 == 0:\n        print(f\"Iteration {iter + 1}, loss: {loss}\")\n\nprint(\"Final weights : \", weights)\nprint(\"Final bias : \", bias)\n\nIteration 10, loss: 20.80624545154949\nIteration 20, loss: 11.314318574097976\nIteration 30, loss: 6.152662434665503\nIteration 40, loss: 3.345783025909011\nIteration 50, loss: 1.8194178821496518\nIteration 60, loss: 0.9893891517327431\nIteration 70, loss: 0.5380242236653578\nIteration 80, loss: 0.29257452918677535\nIteration 90, loss: 0.1591003738562249\nIteration 100, loss: 0.08651788326054576\nIteration 110, loss: 0.04704793547908108\nIteration 120, loss: 0.025584401159906914\nIteration 130, loss: 0.013912652617925996\nIteration 140, loss: 0.007565621788733219\nIteration 150, loss: 0.004114142329436494\nIteration 160, loss: 0.00223724732474303\nIteration 170, loss: 0.0012166024389232565\nIteration 180, loss: 0.0006615815238773228\nIteration 190, loss: 0.0003597642900693548\nIteration 200, loss: 0.00019563778572677352\nFinal weights :  [-3.3990955  -0.20180899  0.80271349]\nFinal bias :  0.6009044964039992"
  },
  {
    "objectID": "posts/backpropogation/index.html#backprop-for-a-layer-of-neurons",
    "href": "posts/backpropogation/index.html#backprop-for-a-layer-of-neurons",
    "title": "Backpropogation",
    "section": "Backprop for a layer of neurons",
    "text": "Backprop for a layer of neurons\nWe are now in a position to write a naive implementation of the backprop algorithm for a layer of neurons.\nA neural network with a single hidden layer is shown below.\n\n\n\nbackprop\n\n\nLet \\(\\mathcal{L}\\) be a loss function of a neural network to minimize. Let \\(x \\in \\mathbf{R}^{d_0}\\) be a single sample(input). Let \\(d_{l}\\) be number of neurons(inputs) in layer \\(l\\). In our example, \\(x \\in \\mathbf{R}^4\\).\nLet’s derive expressions for all the derivatives we want to compute.\n\nGradient of the loss with respect to \\(\\hat{y}\\)\nThe gradient of the loss function \\(\\mathcal{L}\\) with respect to \\(\\hat{y}\\) is:\n\\[\\begin{align*}\n\\frac{\\partial \\mathcal{L}}{\\partial \\hat{y}} &= 2*(\\hat{y} - y)\n\\end{align*}\\]\n\n\nGradient of the loss with respect to \\(a\\)\nThe gradient of \\(\\hat{y}\\) with respect to \\(a_1, a_2, a_3\\) is:\n\\[\\begin{align*}\n\\frac{\\partial \\hat{y}}{\\partial a} &= \\left[\\frac{\\partial \\hat{y}}{\\partial a_1}, \\frac{\\partial \\hat{y}}{\\partial a_2}, \\frac{\\partial \\hat{y}}{\\partial a_3}\\right] = [1, 1, 1]\n\\end{align*}\\]\nSo, by chain rule:\n\\[\\begin{align*}\n\\frac{\\partial \\mathcal{L}}{\\partial a} &= \\left[\\frac{\\partial \\mathcal{L}}{\\partial a_1}, \\frac{\\partial \\mathcal{L}}{\\partial a_2}, \\frac{\\partial \\mathcal{L}}{\\partial a_3}\\right] \\\\\n&=\\left[\\frac{\\partial \\mathcal{L}}{\\partial \\hat{y}} \\cdot \\frac{\\partial \\hat{y}}{\\partial a_1}, \\frac{\\partial \\mathcal{L}}{\\partial \\hat{y}} \\cdot \\frac{\\partial \\hat{y}}{\\partial a_2}, \\frac{\\partial \\mathcal{L}}{\\partial \\hat{y}} \\cdot \\frac{\\partial \\hat{y}}{\\partial a_3}\\right] \\\\\n&= \\frac{\\partial \\mathcal{L}}{\\partial \\hat{y}} \\cdot \\frac{\\partial \\hat{y}}{\\partial a}\n\\end{align*}\\]\nThis vector has the shape [1,layer_width]. In this example, it’s dimensions are (1,3).\n\n\nGradient of the loss with respect to \\(z\\)\nIn our example, \\(a_1 = max(z_1,0)\\), \\(a_2 = max(z_2,0)\\) and \\(a_3 = max(z_3,0)\\). Consequently, the derivative:\n\\[\\begin{align*}\n\\frac{\\partial a}{\\partial z} &= \\left[\\frac{\\partial a_1}{\\partial z_1}, \\frac{\\partial a_2}{\\partial z_2}, \\frac{\\partial a_3}{\\partial z_3}\\right]\\\\\n&= \\left[1_{(z_1 &gt; 0)}, 1_{(z_2 &gt; 0)}, 1_{(z_3 &gt; 0)}\\right]\n\\end{align*}\\]\nAgain this vector has shape [1,layer_width], which in our example equals (1,3).\nBy the chain rule:\n\\[\\begin{align*}\n\\frac{\\partial \\mathcal{L}}{\\partial z} &= \\left[\\frac{\\partial \\mathcal{L}}{\\partial a_1} \\cdot \\frac{\\partial a_1}{\\partial z_1}, \\frac{\\partial \\mathcal{L}}{\\partial a_2} \\cdot \\frac{\\partial a_2}{\\partial z_2}, \\frac{\\partial \\mathcal{L}}{\\partial a_3} \\cdot \\frac{\\partial a_3}{\\partial z_3}\\right]\\\\\n&= \\frac{\\partial \\mathcal{L}}{\\partial a} \\odot \\frac{\\partial \\mathcal{a}}{\\partial z}\n\\end{align*}\\]\nwhere \\(\\odot\\) denotes the element wise product of the two vectors. The gradient of the loss with respect to \\(z\\), is also a vector of shape [1,layer_width].\n\n\nGradient of the loss with respect to weights \\(W\\)\nSince\n\\[\\begin{align*}\nz_1 &= w_{11}x_1 + w_{12}x_2 + w_{13}x_3 + w_{14}x_4 + b_1 \\\\\nz_2 &= w_{21}x_1 + w_{22}x_2 + w_{23}x_3 + w_{24}x_4 + b_2 \\\\\nz_3 &= w_{31}x_1 + w_{32}x_2 + w_{23}x_3 + w_{24}x_4 + b_3\n\\end{align*}\\]\nit follows that: \\[\\begin{align*}\n\\frac{\\partial z_i}{\\partial w_{ij}} = x_j\n\\end{align*}\\]\nNow,\n\\[\\begin{align*}\n\\frac{\\partial \\mathcal{L}}{\\partial w_{ij}} &= \\frac{\\partial \\mathcal{L}}{\\partial z_i} \\cdot \\frac{\\partial z_i}{\\partial w_{ij}} \\\\\n&= \\frac{\\partial \\mathcal{L}}{\\partial z_i} \\cdot x_j\n\\end{align*}\\]\nIn other words:\n\\[\\begin{align*}\n\\begin{bmatrix}\n\\frac{\\partial \\mathcal{L}}{\\partial w_{11}} \\\\\n\\frac{\\partial \\mathcal{L}}{\\partial w_{12}} \\\\\n\\frac{\\partial \\mathcal{L}}{\\partial w_{13}} \\\\\n\\frac{\\partial \\mathcal{L}}{\\partial w_{14}}\n\\end{bmatrix}\n&= \\begin{bmatrix}\n\\frac{\\partial \\mathcal{L}}{\\partial z_1} \\cdot \\frac{\\partial z_1}{\\partial w_{11}}\\\\\n\\frac{\\partial \\mathcal{L}}{\\partial z_1} \\cdot \\frac{\\partial z_1}{\\partial w_{12}}\\\\\n\\frac{\\partial \\mathcal{L}}{\\partial z_1} \\cdot \\frac{\\partial z_1}{\\partial w_{13}}\\\\\n\\frac{\\partial \\mathcal{L}}{\\partial z_1} \\cdot \\frac{\\partial z_1}{\\partial w_{14}}\n\\end{bmatrix}\\\\\n&= \\begin{bmatrix}\n\\frac{\\partial \\mathcal{L}}{\\partial z_1} \\cdot x_1\\\\\n\\frac{\\partial \\mathcal{L}}{\\partial z_1} \\cdot x_2\\\\\n\\frac{\\partial \\mathcal{L}}{\\partial z_1} \\cdot x_3\\\\\n\\frac{\\partial \\mathcal{L}}{\\partial z_1} \\cdot x_4\n\\end{bmatrix}\n\\end{align*}\\]\nPutting this together, we define the jacobian matrix \\(\\frac{\\partial \\mathcal{L}}{\\partial W}\\) as:\n\\[\\begin{align*}\n\\frac{\\partial \\mathcal{L}}{\\partial W}&=\\begin{bmatrix}\n\\frac{\\partial \\mathcal{L}}{\\partial w_{11}} & \\frac{\\partial \\mathcal{L}}{\\partial w_{21}} & \\frac{\\partial \\mathcal{L}}{\\partial w_{31}} & \\frac{\\partial \\mathcal{L}}{\\partial w_{41}} \\\\\n\\frac{\\partial \\mathcal{L}}{\\partial w_{12}} & \\frac{\\partial \\mathcal{L}}{\\partial w_{22}} & \\frac{\\partial \\mathcal{L}}{\\partial w_{32}} & \\frac{\\partial \\mathcal{L}}{\\partial w_{42}} \\\\\n\\frac{\\partial \\mathcal{L}}{\\partial w_{13}} & \\frac{\\partial \\mathcal{L}}{\\partial w_{23}} & \\frac{\\partial \\mathcal{L}}{\\partial w_{33}} & \\frac{\\partial \\mathcal{L}}{\\partial w_{43}} \\\\\n\\frac{\\partial \\mathcal{L}}{\\partial w_{14}} & \\frac{\\partial \\mathcal{L}}{\\partial w_{24}} & \\frac{\\partial \\mathcal{L}}{\\partial w_{34}} & \\frac{\\partial \\mathcal{L}}{\\partial w_{44}} \\\\\n\\end{bmatrix}\\\\\n&= \\begin{bmatrix}\n\\frac{\\partial \\mathcal{L}}{\\partial z_1} \\cdot \\frac{\\partial z_1}{\\partial w_{11}} & \\frac{\\partial \\mathcal{L}}{\\partial z_2} \\cdot \\frac{\\partial z_2}{\\partial w_{21}} & \\frac{\\partial \\mathcal{L}}{\\partial z_3} \\cdot \\frac{\\partial z_3}{\\partial w_{31}}\\\\\n\\frac{\\partial \\mathcal{L}}{\\partial z_1} \\cdot \\frac{\\partial z_1}{\\partial w_{12}} & \\frac{\\partial \\mathcal{L}}{\\partial z_2} \\cdot \\frac{\\partial z_2}{\\partial w_{22}} & \\frac{\\partial \\mathcal{L}}{\\partial z_3} \\cdot \\frac{\\partial z_3}{\\partial w_{32}}\\\\\n\\frac{\\partial \\mathcal{L}}{\\partial z_1} \\cdot \\frac{\\partial z_1}{\\partial w_{13}} & \\frac{\\partial \\mathcal{L}}{\\partial z_2} \\cdot \\frac{\\partial z_2}{\\partial w_{23}} & \\frac{\\partial \\mathcal{L}}{\\partial z_3} \\cdot \\frac{\\partial z_3}{\\partial w_{33}}\\\\\n\\frac{\\partial \\mathcal{L}}{\\partial z_1} \\cdot \\frac{\\partial z_1}{\\partial w_{14}} & \\frac{\\partial \\mathcal{L}}{\\partial z_2} \\cdot \\frac{\\partial z_2}{\\partial w_{24}} & \\frac{\\partial \\mathcal{L}}{\\partial z_3} \\cdot \\frac{\\partial z_3}{\\partial w_{34}}\n\\end{bmatrix}\\\\\n&= \\begin{bmatrix}\n\\frac{\\partial \\mathcal{L}}{\\partial z_1} \\cdot x_1 & \\frac{\\partial \\mathcal{L}}{\\partial z_2} \\cdot x_1 & \\frac{\\partial \\mathcal{L}}{\\partial z_3} \\cdot x_1 \\\\\n\\frac{\\partial \\mathcal{L}}{\\partial z_1} \\cdot x_2 & \\frac{\\partial \\mathcal{L}}{\\partial z_2} \\cdot x_2 & \\frac{\\partial \\mathcal{L}}{\\partial z_3} \\cdot x_2\\\\\n\\frac{\\partial \\mathcal{L}}{\\partial z_1} \\cdot x_3 & \\frac{\\partial \\mathcal{L}}{\\partial z_2} \\cdot x_3 & \\frac{\\partial \\mathcal{L}}{\\partial z_3} \\cdot x_3\\\\\n\\frac{\\partial \\mathcal{L}}{\\partial z_1} \\cdot x_4 & \\frac{\\partial \\mathcal{L}}{\\partial z_2} \\cdot x_4 & \\frac{\\partial \\mathcal{L}}{\\partial z_3} \\cdot x_4\n\\end{bmatrix}\\\\\n&= \\begin{bmatrix}\nx_1 \\\\\nx_2 \\\\\nx_3 \\\\\nx_4\n\\end{bmatrix} \\begin{bmatrix}\n\\frac{\\partial \\mathcal{L}}{\\partial z_1} & \\frac{\\partial \\mathcal{L}}{\\partial z_2} & \\frac{\\partial \\mathcal{L}}{\\partial z_3}\n\\end{bmatrix} \\\\\n&= X^T \\cdot \\frac{\\partial \\mathcal{L}}{\\partial z}\n\\end{align*}\\]\nThe dimensions of \\(X^T\\) and \\(\\frac{\\partial \\mathcal{L}}{\\partial z}\\) are [input_size,1] and [1,layer_width] respectively. Therefore, \\(\\frac{\\partial \\mathcal{L}}{\\partial W}\\) will be of dimensions [input_size,layer_width]. In our example this equals (4,3).\nThe first column of \\(X^T \\cdot \\frac{\\partial \\mathcal{L}}{\\partial z}\\) gives the derivative with respect to the first neuron’s weights, the second column gives the derivative with respect to the second neuron’s weights and so forth.\n\n\nGradient of the loss with respect to the biases \\(b\\)\nSince\n\\[\\begin{align*}\n\\frac{\\partial z}{\\partial b} &= \\left[\\frac{\\partial z_1}{\\partial b_1}, \\frac{\\partial z_2}{\\partial b_2}, \\frac{\\partial z_3}{\\partial b_3}\\right]\\\\\n&= [1,1,1]\n\\end{align*}\\]\nIt follows that:\n\\[\\begin{align*}\n\\frac{\\partial \\mathcal{L}}{\\partial b} &= \\left[\\frac{\\partial \\mathcal{L}}{\\partial b_1}, \\frac{\\partial \\mathcal{L}}{\\partial b_2}, \\frac{\\partial \\mathcal{L}}{\\partial b_3}\\right]\\\\\n&= \\left[\\frac{\\partial \\mathcal{L}}{\\partial z_1} \\cdot \\frac{\\partial z_1}{\\partial b_1}, \\frac{\\partial \\mathcal{L}}{\\partial b_2} \\cdot \\frac{\\partial z_2}{\\partial b_21}, \\frac{\\partial \\mathcal{L}}{\\partial b_3}\\cdot \\cdot \\frac{\\partial z_3}{\\partial b_3}\\right]\\\\\n&=\\left[\\frac{\\partial \\mathcal{L}}{\\partial z_1} \\cdot 1, \\frac{\\partial \\mathcal{L}}{\\partial b_2} \\cdot 1, \\frac{\\partial \\mathcal{L}}{\\partial b_3}\\cdot \\cdot 1\\right]\\\\\n&= \\frac{\\partial \\mathcal{L}}{\\partial z}\n\\end{align*}\\]\n\n\nNaive Python implementation\n\nimport numpy as np\n\ninputs = np.array([1, 2, 3, 4])\nweights = np.array([[0.1, 0.2, 0.3, 0.4], [0.5, 0.6, 0.7, 0.8], [0.9, 1.0, 1.1, 1.2]])\n\nbiases = np.array([0.1, 0.2, 0.3])\n\n# Learning rate\nlearning_rate = 0.001\n\n\n# ReLU Activation function and its derivative\ndef relu(x):\n    return np.maximum(x, 0)\n\n\ndef relu_derivative(z):\n    return np.where(z &gt; 0.0, 1.0, 0.0)\n\n\nfor iter in range(200):\n    # Forward pass\n    z = np.dot(weights, inputs) + biases\n    a = relu(z)\n    y_pred = np.sum(a)\n    y_true = 0.0\n    loss = (y_pred - y_true) ** 2\n\n    # Backward pass\n    # Gradient of loss with respect to y_pred\n    dloss_dy = 2 * (y_pred - y_true)\n\n    # Gradient of y_pred with respect to a\n    dy_da = np.ones_like(a)\n\n    # Gradient of the activation function with respect to z\n    da_dz = relu_derivative(z)\n\n    # Gradient of z with respect to the weights\n    dz_dw = inputs\n\n    # Gradient of z with respect to inputs\n    dz_dx = weights\n\n    # Gradient of loss with respect to a\n    dloss_da = dloss_dy * dy_da\n\n    # Gradient of loss with respect to z\n    dloss_dz = dloss_da * da_dz\n\n    # Gradient of loss with respect to the weights\n    dloss_dw = np.outer(dloss_dz, dz_dw)\n\n    # Gradient of loss with respect to biases\n    dloss_db = dloss_dz\n\n    weights -= learning_rate * dloss_dw\n    biases -= learning_rate * dloss_db\n\n    if (iter + 1) % 20 == 0:\n        print(f\"Iteration {iter+1}, loss = {loss}\")\n\nprint(\"Final weights : \", weights)\nprint(\"Final bias : \", biases)\n\nIteration 20, loss = 6.057433318678514\nIteration 40, loss = 0.4681684867419663\nIteration 60, loss = 0.03618392815029436\nIteration 80, loss = 0.0027965928794077364\nIteration 100, loss = 0.00021614380010564146\nIteration 120, loss = 1.670537841532316e-05\nIteration 140, loss = 1.2911296454618448e-06\nIteration 160, loss = 9.978916489916474e-08\nIteration 180, loss = 7.712531012091791e-09\nIteration 200, loss = 5.96088109107831e-10\nFinal weights :  [[-0.00698895 -0.01397789 -0.02096684 -0.02795579]\n [ 0.25975286  0.11950572 -0.02074143 -0.16098857]\n [ 0.53548461  0.27096922  0.00645383 -0.25806156]]\nFinal bias :  [-0.00698895 -0.04024714 -0.06451539]"
  },
  {
    "objectID": "posts/backpropogation/index.html#backprop-with-a-batch-of-inputs",
    "href": "posts/backpropogation/index.html#backprop-with-a-batch-of-inputs",
    "title": "Backpropogation",
    "section": "Backprop with a batch of inputs",
    "text": "Backprop with a batch of inputs\nLet \\(x\\) be a batch of inputs of dimensions [batch_size,input_size]. Consider\n\nx = np.array(\n    [\n        [1, 2, 3, 2.5],\n        [2, 5, -1, 2],\n        [-1.5, 2.7, 3.3, -0.8]\n    ]\n)\n\nof shape (3,4). Each sample will give one loss. Hence, the total loss \\(\\mathcal{L} = L_1 + L_2 + L_3\\).\n\nGradient of the loss with respect to weights \\(w\\)\nI am going to denote use the following convention for the \\(z\\)’s:\n\\[\\begin{align*}\n\\begin{array}[c|ccc]\n\\text{} & \\text{Neuron}-1 & \\text{Neuron}-2 & \\text{Neuron}-3\\\\\n\\hline\n\\text{Sample}-1 & z_{11} & z_{12} & z_{13} \\\\\n\\text{Sample}-2 & z_{21} & z_{22} & z_{23} \\\\\n\\text{Sample}-3 & z_{31} & z_{32} & z_{33} \\\\\n\\text{Sample}-4 & z_{41} & z_{42} & z_{43}\n\\end{array}\n\\end{align*}\\]\nIn this case \\(\\frac{d\\mathcal{L}}{dz}\\) will be a matrix of partial derivatives of shape [batch_size,layer_width].\nI can write:\n\\[\\begin{align*}\n\\frac{\\partial \\mathcal{L}}{\\partial w_{11}} &= \\frac{\\partial L_1}{\\partial w_{11}} + \\frac{\\partial L_2}{\\partial w_{11}} + \\frac{\\partial L_3}{\\partial w_{11}} \\\\\n&= \\frac{\\partial L_1}{\\partial z_{11}}\\cdot \\frac{\\partial z_{11}}{\\partial w_{11}} + \\frac{\\partial L_2}{\\partial z_{21}}\\cdot\\frac{\\partial z_{21}}{\\partial w_{11}} + \\frac{\\partial L_3}{\\partial z_{31}} \\cdot \\frac{\\partial z_{31}}{\\partial w_{11}}\\\\\n&=\\frac{\\partial L_1}{\\partial z_{11}}\\cdot x_{11} + \\frac{\\partial L_2}{\\partial z_{21}}\\cdot x_{21} + \\frac{\\partial L_3}{\\partial z_{31}} \\cdot x_{31}\n\\end{align*}\\]\nIf you work out the derivatives of the loss function with respect to each of the weights, you would find:\n\\[\\begin{align*}\n\\frac{\\partial \\mathcal{L}}{\\partial W} &= X^T \\cdot \\frac{\\partial \\mathcal{L}}{\\partial z}\n\\end{align*}\\]\nX.T has shape [input_size,batch_size] and dloss_dz has shape [batch_size,layer_width], so the matrix product will have dimensions [input_size,layer_width].\n\n\nGradient of the loss with respect to the biases \\(b\\)\nConsider again:\n\\[\\begin{align*}\n\\frac{\\partial \\mathcal{L}}{\\partial b_1} &= \\frac{\\partial L}{\\partial z_{11}} \\cdot \\frac{\\partial z_{11}}{\\partial b_1} + \\frac{\\partial L}{\\partial z_{21}} \\cdot \\frac{\\partial z_{21}}{\\partial b_1} + \\frac{\\partial L}{\\partial z_{31}} \\cdot \\frac{\\partial z_{31}}{\\partial b_1} \\\\\n&= \\frac{\\partial L}{\\partial z_{11}} \\cdot 1 + \\frac{\\partial L}{\\partial z_{21}} \\cdot 1 + \\frac{\\partial L}{\\partial z_{31}} \\cdot 1\n\\end{align*}\\]\nSo, to find the partial derivative of the loss with respect to \\(b_1\\), we will just look at the partial derivatives of the loss with respect to the first neuron and then add them up.\nIn python, we would write this as\ndloss_dbiases = np.sum(dloss_dz, axis=0, keepdims=True)\n\n\nGradient of the loss with respect to the inputs\nThe gradients of the loss with respect to the weights in the layer \\(l\\), require the gradients of the loss with respect to the inputs in layer \\(l+1\\). It’s easy to see that:\n\\[\\begin{align*}\n\\frac{\\partial L}{\\partial w_{11}^{(l)}} &= \\frac{\\partial L}{\\partial x_1^{(l+1)}}\\cdot \\frac{\\partial x_1^{(l+1)}}{\\partial z_{1}^{l}} \\cdot \\frac{\\partial z_1^{(l)}}{\\partial w_{11}^{(l)}}\n\\end{align*}\\]\nWhat is \\(\\frac{\\partial \\mathcal{L}}{\\partial x_1}\\), \\(\\frac{\\partial \\mathcal{L}}{\\partial x_2}\\), \\(\\frac{\\partial \\mathcal{L}}{\\partial x_3}\\) and \\(\\frac{\\partial \\mathcal{L}}{\\partial x_4}\\)?\nBy the chain rule:\n\\[\\begin{align*}\n\\frac{\\partial \\mathcal{L}}{\\partial x_1} &= \\frac{\\partial L}{\\partial z_1}\\cdot \\frac{\\partial z_1}{\\partial x_1} +  \\frac{\\partial L}{\\partial z_2}\\cdot \\frac{\\partial z_2}{\\partial x_1} +  \\frac{\\partial L}{\\partial z_3}\\cdot \\frac{\\partial z_3}{\\partial x_1} \\\\\n&= \\frac{\\partial L}{\\partial z_1}\\cdot w_{11} +  \\frac{\\partial L}{\\partial z_2}\\cdot w_{21} +  \\frac{\\partial L}{\\partial z_3}\\cdot w_{31}\n\\end{align*}\\]\nConsequently,\n\\[\\begin{align*}\n\\begin{bmatrix}\n\\frac{\\partial \\mathcal{L}}{\\partial x_1} & \\frac{\\partial \\mathcal{L}}{\\partial x_2} & \\frac{\\partial \\mathcal{L}}{\\partial x_3} & \\frac{\\partial \\mathcal{L}}{\\partial x_4}\n\\end{bmatrix} &=\n\\begin{bmatrix}\n\\frac{\\partial L}{\\partial z_1} & \\frac{\\partial L}{\\partial z_2} & \\frac{\\partial L}{\\partial z_3}\n\\end{bmatrix}\n\\begin{bmatrix}\nw_{11} & w_{12} & w_{13} & w_{14}\\\\\nw_{21} & w_{22} & w_{23} & w_{24}\\\\\nw_{31} & w_{32} & w_{33} & w_{34}\n\\end{bmatrix}\\\\\n\\frac{\\partial \\mathcal{L}}{\\partial x} &= \\frac{\\partial L}{\\partial z} \\cdot W\n\\end{align*}\\]\nWhat if we have a batch of input data of 3 examples? In such case, \\(\\frac{\\partial \\mathcal{L}}{\\partial z}\\) will have shape (3,3) and \\(W\\) will have shape (3,4). So, we can multiply them and the result would be (3,4)."
  },
  {
    "objectID": "posts/backpropogation/index.html#adding-backward-to-denselayer",
    "href": "posts/backpropogation/index.html#adding-backward-to-denselayer",
    "title": "Backpropogation",
    "section": "Adding backward() to DenseLayer",
    "text": "Adding backward() to DenseLayer\nWe will now add backward pass code to the DenseLayer and ReLUActivation classes.\n\nfrom nnfs.datasets import spiral_data\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport nnfs\n\nnnfs.init()\n\n\nclass DenseLayer:\n    def __init__(self, n_inputs, n_neurons):\n        self.width = n_neurons\n        # Weight vectors per neuron\n        self.weights = np.array(\n            [[0.1, 0.2, 0.3, 0.4], [0.5, 0.6, 0.7, 0.8], [0.9, 1.0, 1.1, 1.2]]\n        )\n        self.biases = np.array([0.1, 0.2, 0.3])\n\n    def forward(self, inputs):\n        self.inputs = inputs\n        self.output = np.dot(inputs, self.weights.T) + self.biases\n\n    def backward(self, dloss_dz):\n        self.dloss_dz = dloss_dz\n        self.dz_dweights = self.inputs\n        self.dz_dbiases = np.ones_like(self.inputs)\n        self.dz_dinputs = self.weights\n        self.dloss_dweights = np.dot(self.inputs.T, self.dloss_dz).T\n        self.dloss_dbiases = np.sum(self.dloss_dz, axis=0, keepdims=True)\n        self.dloss_dinputs = np.dot(self.dloss_dz, self.dz_dinputs)\n\n\nclass ReLUActivation:\n\n    # Forward pass\n    def forward(self, inputs):\n        # Calculate output values from the inputs\n        self.inputs = inputs\n        self.output = np.maximum(0, inputs)\n\n    # Backward pass\n    def backward(self, dloss_da):\n        self.dloss_da = dloss_da\n        self.da_dz = np.where(self.inputs &gt; 0.0, 1.0, 0.0)\n        self.dloss_dz = self.dloss_da * self.da_dz\n\n\n# Create dataset\nX = np.array([[1, 2, 3, 2.5], [2, 5, -1, 2], [-1.5, 2.7, 3.3, -0.8]])\n\n# Create a dense layer with 4 input features and 3 output values\ndense1 = DenseLayer(4, 3)\nrelu = ReLUActivation()\n\n# Perform a forward pass of our training data through this layer\ndense1.forward(X)\nrelu.forward(dense1.output)\n\n# Calculate loss\ny_pred = np.sum(relu.output)\ny_true = 0.0\nloss = (y_pred - y_true) ** 2\n\n# Gradient of the loss with respect to y\ndloss_dy = 2 * (y_pred - y_true)\ndy_da = np.ones_like(relu.output)\ndloss_da = dloss_dy * dy_da\n\nrelu.backward(dloss_da)\ndense1.backward(relu.dloss_dz)\nprint(f\"dloss_dweights = {dense1.dloss_dweights}\")\nprint(f\"dloss_dbiases = {dense1.dloss_dbiases}\")\nprint(f\"dloss_dinputs = {dense1.dloss_dinputs}\")\n\ndloss_dweights = [[124.560005 805.48804  440.112    307.24802 ]\n [124.560005 805.48804  440.112    307.24802 ]\n [124.560005 805.48804  440.112    307.24802 ]]\ndloss_dbiases = [[249.12000303 249.12000303 249.12000303]]\ndloss_dinputs = [[124.560005 149.472    174.384    199.296   ]\n [124.560005 149.472    174.384    199.296   ]\n [124.560005 149.472    174.384    199.296   ]]"
  },
  {
    "objectID": "posts/backpropogation/index.html#categorical-cross-entropy-loss-derivative",
    "href": "posts/backpropogation/index.html#categorical-cross-entropy-loss-derivative",
    "title": "Backpropogation",
    "section": "Categorical cross-entropy loss derivative",
    "text": "Categorical cross-entropy loss derivative\nThe cross-entropy loss of the \\(i\\)-th sample is given by:\n\\[\\begin{align*}\nL_i = -\\sum_k y_{ik}log(\\hat{y}_ik)\n\\end{align*}\\]\nDifferentiating with respect to \\(\\hat{y}_{ij}\\), we have:\n\\[\\begin{align*}\n\\frac{\\partial L_i}{\\partial \\hat{y}_{ij}} &= -\\frac{\\partial}{\\partial \\hat{y}_{ik}} \\left[\\sum_k y_{ik}\\log (\\hat{y}_{ik})\\right] \\\\\n&= -y_{ij} \\cdot \\frac{\\partial }{\\partial \\hat{y}_{ij}} \\log (\\hat{y}_{ij})\\\\\n&= -\\frac{y_{ij}}{\\hat{y}_{ij}}\n\\end{align*}\\]\n\nAdding backward() to CategoricalCrossEntropyLoss\n\n# Cross-Entropy loss\nclass CategoricalCrossEntropyLoss(Loss):\n\n    # Forward pass\n    def forward(self, y_pred, y_true):\n        num_samples = len(y_pred)\n\n        # Clip data to prevent division by 0\n        # Clip both sides to not drag mean towards any value\n        epsilon = 1e-7\n        y_pred_clipped = np.clip(y_pred, epsilon, 1 - epsilon)\n\n        # If categorical labels\n        if len(y_true.shape) == 1:\n            correct_confidences = y_pred_clipped[range(len(y_pred)), y_true]\n        # else if one-hot encoding\n        elif len(y_true.shape) == 2:\n            correct_confidences = np.sum(y_pred_clipped * y_true, axis=1)\n\n        neg_log = -np.log(correct_confidences)\n        return neg_log\n\n    # Backward pass\n    def backward(self, y_pred, y_true):\n\n        # number of samples\n        batch_size = len(y_pred)\n\n        # number of labels\n        num_labels = len(y_pred[0])\n\n        # If labels are sparse, turn them into a one-hot vector\n        if len(y_true.shape) == 1:\n            y_true = np.eye(num_labels)[y_true]\n\n        # Calculate gradient\n        self.dloss_da = -y_true / y_pred\n\n        # Normalize the gradient\n        self.dloss_da = self.dloss_da / batch_size"
  },
  {
    "objectID": "posts/backpropogation/index.html#softmax-activation-function-derivative",
    "href": "posts/backpropogation/index.html#softmax-activation-function-derivative",
    "title": "Backpropogation",
    "section": "Softmax Activation function derivative",
    "text": "Softmax Activation function derivative\nWe are interested to calculate the derivative of the softmax function. The softmax activation function is defined as:\n\\[\\begin{align*}\nS_{i,j} &= \\frac{e^{z_{i,j}}}{\\sum_{l=1}^{d_l} e^{z_{i,l}}}\n\\end{align*}\\]\nwhere \\(S_{i,j}\\) denotes the output of the \\(j\\)-th neuron for the \\(i\\)-th sample. Thus, \\(S_{i,j} = f(z_{i,1},\\ldots,z_{i,d_l})\\). Let’s calculate the partial derivative of \\(S_{i,j}\\) with respect to \\(z_{i,k}\\).\nBy the \\(u/v\\) rule:\n\\[\\begin{align*}\n\\frac{\\partial S_{i,j}}{\\partial z_{i,k}} &= \\frac{\\sum_{l=1}^{d_l} e^{z_{i,l}} \\cdot \\frac{\\partial e^{z_{i,j}}}{\\partial z_{i,k}}-e^{z_{i,j}} \\cdot \\frac{\\partial}{\\partial z_{i,k}} \\sum_{l=1}^{d_l} e^{z_{i,l}}}{\\left(\\sum_{l=1}^{d_l} e^{z_{i,l}}\\right)^2}\n\\end{align*}\\]\nWe have two cases. If \\(j=k\\), then \\(\\frac{\\partial e^{z_{i,j}}}{\\partial z_{i,k}} = e^{z_{i,k}}\\) and we get:\n\\[\\begin{align*}\n\\frac{\\partial S_{i,j}}{\\partial z_{i,k}} &= \\frac{e^{z_{i,k}} \\cdot \\sum_{l=1}^{d_l} e^{z_{i,l}} -e^{z_{i,k}} \\cdot e^{z_{i,k}}}{\\left(\\sum_{l=1}^{d_l} e^{z_{i,l}}\\right)^2}\\\\\n&=\\frac{e^{z_{i,k}}}{\\sum_{l=1}^{d_l} e^{z_{i,l}}} \\cdot \\frac{\\sum_{l=1}^{d_l} e^{z_{i,l}} -e^{z_{i,k}}}{\\sum_{l=1}^{d_l} e^{z_{i,l}}}\\\\\n&=S_{i,k}(1-S_{i,k})\n\\end{align*}\\]\nIn the case where \\(j \\neq k\\), \\(\\frac{\\partial e^{z_{i,j}}}{\\partial z_{i,k}} = 0\\) and we have:\n\\[\\begin{align*}\n\\frac{\\partial S_{i,j}}{\\partial z_{i,k}} &= -\\frac{e^{z_{i,j}}}{\\sum_{l=1}^{d_l}e^{z_{i,l}}}\\cdot \\frac{e^{z_{i,k}}}{\\sum_{l=1}^{d_l}e^{z_{i,l}}}\\\\\n&=-S_{i,j} S_{i,k}\n\\end{align*}\\]\nSo, the derivative of the softmax activation function can be expressed in terms of Kronecker’s delta as:\n\\[\\begin{align*}\n\\frac{\\partial S_{i,j}}{\\partial z_{i,k}} &= S_{i,j}(\\delta_{j,k} -  S_{i,k})\\\\\n&= S_{i,j} \\delta_{j,k} - S_{i,j}S_{i,k}\n\\end{align*}\\]\nNow, like before, let’s say we have neural network with a single hidden layer with \\(d_1 = 3\\) neurons. We apply the softmax activation function to the output of this layer. The jacobian matrix \\(\\frac{\\partial S_i}{\\partial z_i}\\) for the \\(i\\)-th sample can be expressed as:\n\\[\\begin{align*}\n\\frac{\\partial S_i}{\\partial z_i} &=\n\\begin{bmatrix}\n\\frac{\\partial S_{i1}}{\\partial z_{i1}} & \\frac{\\partial S_{i1}}{\\partial z_{i2}} & \\frac{\\partial S_{i1}}{\\partial z_{i3}} \\\\\n\\frac{\\partial S_{i2}}{\\partial z_{i1}} & \\frac{\\partial S_{i2}}{\\partial z_{i2}} & \\frac{\\partial S_{i2}}{\\partial z_{i3}} \\\\\n\\frac{\\partial S_{i3}}{\\partial z_{i1}} & \\frac{\\partial S_{i3}}{\\partial z_{i2}} & \\frac{\\partial S_{i3}}{\\partial z_{i3}}\n\\end{bmatrix}\\\\\n&=\\begin{bmatrix}\nS_{i1}(\\delta_{11} - S_{i1}) & S_{i1}(\\delta_{12} - S_{i2}) & S_{i1}(\\delta_{13} - S_{i3}) \\\\\nS_{i2}(\\delta_{21} - S_{i1}) & S_{i2}(\\delta_{22} - S_{i2}) & S_{i2}(\\delta_{23} - S_{i3}) \\\\\nS_{i3}(\\delta_{31} - S_{i1}) & S_{i3}(\\delta_{32} - S_{i2}) & S_{i3}(\\delta_{33} - S_{i3})\n\\end{bmatrix}\\\\\n&=\\begin{bmatrix}\nS_{i1}(1 - S_{i1}) & S_{i1}(0 - S_{i2}) & S_{i1}(0 - S_{i3}) \\\\\nS_{i2}(0 - S_{i1}) & S_{i2}(1 - S_{i2}) & S_{i2}(0 - S_{i3}) \\\\\nS_{i3}(0 - S_{i1}) & S_{i3}(0 - S_{i2}) & S_{i3}(1 - S_{i3})\n\\end{bmatrix}\\\\\n&=\\begin{bmatrix}\nS_{i1}\\\\\nS_{i2}\\\\\nS_{i3}\n\\end{bmatrix}\\odot\n\\begin{bmatrix}\n1 & 0 & 0 \\\\\n0 & 1 & 0 \\\\\n0 & 0 & 1\n\\end{bmatrix} -\n\\begin{bmatrix}\nS_{i1}\\\\\nS_{i2}\\\\\nS_{i3}\n\\end{bmatrix}\\begin{bmatrix}\nS_{i1} & S_{i2} & S_{i3}\n\\end{bmatrix}\n\\end{align*}\\]\nSay the softmax_output=[0.70, 0.10, 0.20]. Then, in python, we can find the Jacobian matrix as:\n\nimport numpy as np\n\nsoftmax_output = np.array([0.70, 0.10, 0.20])\n\n# Reshape as a column vector\nsoftmax_output = softmax_output.reshape(-1, 1)\n\nda_dz = np.diagflat(softmax_output) - np.dot(softmax_output, softmax_output.T)\n\nprint(f\"softmax_output = {softmax_output}\")\nprint(f\"da_dz = {da_dz}\")\n\nsoftmax_output = [[0.7]\n [0.1]\n [0.2]]\nda_dz = [[ 0.20999999 -0.07       -0.14      ]\n [-0.07        0.09       -0.02      ]\n [-0.14       -0.02        0.16      ]]\n\n\nWhat happens when we have a batch of inputs? By the chain rule:\n\\[\\begin{align*}\n\\frac{\\partial L}{\\partial z_{11}} &= \\frac{\\partial L}{\\partial S_{11}} \\cdot \\frac{\\partial S_{11}}{\\partial z_{11}} + \\frac{\\partial L}{\\partial S_{12}} \\cdot \\frac{\\partial S_{12}}{\\partial z_{11}} + \\frac{\\partial L}{\\partial S_{13}}\\cdot \\frac{\\partial S_{13}}{\\partial z_{11}}\n\\end{align*}\\]\nIn general,\n\\[\\begin{align*}\n\\frac{\\partial L}{\\partial z_{ij}} &= \\frac{\\partial L}{\\partial S_{i1}} \\cdot \\frac{\\partial S_{i1}}{\\partial z_{ij}} + \\frac{\\partial L}{\\partial S_{i2}} \\cdot \\frac{\\partial S_{i2}}{\\partial z_{ij}} + \\frac{\\partial L}{\\partial S_{i3}}\\cdot \\frac{\\partial S_{i3}}{\\partial z_{ij}}\\\\\n&=\\sum_{k=1}^{3} \\frac{\\partial L}{\\partial S_{ik}} \\cdot \\frac{\\partial S_{ik}}{\\partial z_{ij}}\n\\end{align*}\\]\nIt follows that:\n\\[\\begin{align*}\n\\frac{\\partial L}{\\partial z_i} &= \\begin{bmatrix}\n\\frac{\\partial L}{\\partial z_{i1}} & \\frac{\\partial L}{\\partial z_{i2}} & \\frac{\\partial L}{\\partial z_{i3}}\n\\end{bmatrix}\\\\\n&=\\begin{bmatrix}\n\\frac{\\partial L}{\\partial S_{i1}} & \\frac{\\partial L}{\\partial S_{i2}} & \\frac{\\partial L}{\\partial S_{i3}}\n\\end{bmatrix} \\begin{bmatrix}\n\\frac{\\partial S_{i1}}{\\partial z_{i1}} & \\frac{\\partial S_{i1}}{\\partial z_{i2}} & \\frac{\\partial S_{i1}}{\\partial z_{i3}} \\\\\n\\frac{\\partial S_{i2}}{\\partial z_{i1}} & \\frac{\\partial S_{i2}}{\\partial z_{i2}} & \\frac{\\partial S_{i2}}{\\partial z_{i3}} \\\\\n\\frac{\\partial S_{i3}}{\\partial z_{i1}} & \\frac{\\partial S_{i3}}{\\partial z_{i2}} & \\frac{\\partial S_{i3}}{\\partial z_{i3}}\n\\end{bmatrix}\\\\\n&=\\frac{\\partial L}{\\partial S_i} \\cdot \\frac{\\partial S_i}{\\partial z_i}\n\\end{align*}\\]\nNow, \\(\\partial L/\\partial S_i\\) has shape [1,3] and \\(\\partial S_i/\\partial z_i\\) is a matrix of size [3,3]. So, \\(\\partial L/\\partial z_i\\) will have dimensions [1,3]."
  },
  {
    "objectID": "posts/backpropogation/index.html#softmax-backward-implementation",
    "href": "posts/backpropogation/index.html#softmax-backward-implementation",
    "title": "Backpropogation",
    "section": "Softmax backward() implementation",
    "text": "Softmax backward() implementation\nWe are now in a position to add backward() pass to the SoftmaxActivation layer.\n\nclass SoftmaxActivation:\n\n    # Forward pass\n    def forward(self, inputs):\n        self.inputs = inputs\n        exp_values = np.exp(inputs - np.max(inputs, axis=1, keepdims=True))\n        probabilities = exp_values / np.sum(exp_values, axis=1, keepdims=True)\n        self.output = probabilities\n\n    # Backward pass\n    def backward(self, dloss_da):\n        dloss_dz = []\n        n = len(self.output)\n        for i in range(n):\n            softmax_output = self.output[i]\n\n            # Reshape as a column vector\n            softmax_output = softmax_output.reshape(-1, 1)\n\n            dsoftmax_dz = np.diagflat(softmax_output) - np.dot(\n                softmax_output, softmax_output.T\n            )\n            dloss_dz.append(np.dot(dloss_da[i], dsoftmax_dz))\n\n        self.dloss_dz = np.array(dloss_dz)"
  },
  {
    "objectID": "posts/backpropogation/index.html#categorical-cross-entropy-loss-and-softmax-activation-function-derivative",
    "href": "posts/backpropogation/index.html#categorical-cross-entropy-loss-and-softmax-activation-function-derivative",
    "title": "Backpropogation",
    "section": "Categorical cross-entropy loss and softmax activation function derivative",
    "text": "Categorical cross-entropy loss and softmax activation function derivative\nThe derivative of the categorical cross entropy loss and softmax activation function can be combined and results in a faster and simple implementation. The current implementation of the backward function in SoftMaxActivation is not vectorized and has a loop.\nLet’s focus again on \\(\\frac{\\partial L_{i}}{\\partial z_{ij}}\\). We have:\n\\[\\begin{align*}\n\\frac{\\partial L_i}{\\partial z_{ij}} &= \\sum_{k} \\frac{\\partial L_i}{\\partial S_{ik}} \\frac{\\partial S_{ik}}{\\partial z_{ij}} \\\\\n&= \\frac{\\partial L_i}{S_{ij}} \\cdot \\frac{\\partial S_{ij}}{\\partial z_{ij}} + \\sum_{k\\neq j}\\frac{\\partial L_i}{\\partial S_{ik}} \\frac{\\partial S_{ik}}{\\partial z_{ij}} \\\\\n&= -\\frac{y_{ij}}{\\hat{y}_{ij}}\\hat{y}_{ij}(1-\\hat{y}_{ij}) + \\sum_{k \\neq j}-\\frac{y_{ik}}{\\hat{y}_{ik}}\\cdot \\hat{y}_{ik}(0 - \\hat{y}_{ij})\\\\\n&= -\\frac{y_{ij}}{\\cancel{\\hat{y}_{ij}}}\\cancel{\\hat{y}_{ij}}(1-\\hat{y}_{ij}) + \\sum_{k \\neq j}-\\frac{y_{ik}}{\\cancel{\\hat{y}_{ik}}}\\cdot \\cancel{\\hat{y}_{ik}}(0 - \\hat{y}_{ij})\\\\\n&= -y_{ij} + y_{ij}\\hat{y}_{ij} + \\sum_{k\\neq j}y_{ik} \\hat{y}_{ij}\\\\\n&= -y_{ij} + \\hat{y}_{ij}(\\sum_{k}y_{ik})\\\\\n&= \\hat{y}_{ij} - y_{ij}\n\\end{align*}\\]\n\nclass CategoricalCrossEntropySoftmax:\n\n    # create activation and loss function objects\n    def __init__(self):\n        self.activation = SoftmaxActivation()\n        self.loss = CategoricalCrossEntropyLoss()\n\n    # forward pass\n    def forward(self, inputs, y_true):\n\n        self.inputs = inputs\n        self.activation.forward(inputs)\n\n        self.output = self.activation.output\n\n        return self.loss.calculate(self.output, y_true)\n\n    # Backward pass\n    def backward(self, y_pred, y_true):\n        # number of samples\n        batch_size = len(y_pred)\n\n        # number of labels\n        num_labels = len(y_pred[0])\n\n        # If labels are sparse, turn them into a one-hot vector\n        if len(y_true.shape) == 1:\n            y_true = np.eye(num_labels)[y_true]\n\n        # Calculate the gradient\n        self.dloss_dz = y_pred - y_true\n\n        # Normalize the gradient\n        self.dloss_dz = self.dloss_dz / batch_size\n\nWe can now test if the combined backward step returns the same values compared to when we backpropogate gradients through both of the functions separately.\n\nimport numpy as np\nimport nnfs\n\nnnfs.init()\n\nsoftmax_outputs = np.array([[0.7, 0.1, 0.2], [0.1, 0.5, 0.4], [0.02, 0.9, 0.08]])\n\nclass_targets = np.array([0, 1, 1])\n\n\nactivation = SoftmaxActivation()\nactivation.output = softmax_outputs\n\nloss = CategoricalCrossEntropyLoss()\nloss.backward(softmax_outputs, class_targets)\nprint(\"Gradients : separate loss and activation\")\nprint(f\"dloss_da = {loss.dloss_da}\")\n\nactivation.backward(loss.dloss_da)\nprint(f\"dloss_dz = {activation.dloss_dz}\")\n\nsoftmax_cce = CategoricalCrossEntropySoftmax()\nsoftmax_cce.backward(softmax_outputs, class_targets)\nprint(\"Gradients : combined loss and activation\")\nprint(f\"dloss_dz = {softmax_cce.dloss_dz}\")\n\nGradients : separate loss and activation\ndloss_da = [[-0.47619048 -0.         -0.        ]\n [-0.         -0.66666667 -0.        ]\n [-0.         -0.37037037 -0.        ]]\ndloss_dz = [[-0.09999999  0.03333334  0.06666667]\n [ 0.03333334 -0.16666667  0.13333334]\n [ 0.00666667 -0.03333333  0.02666667]]\nGradients : combined loss and activation\ndloss_dz = [[-0.1         0.03333333  0.06666667]\n [ 0.03333333 -0.16666667  0.13333333]\n [ 0.00666667 -0.03333333  0.02666667]]"
  },
  {
    "objectID": "posts/borel_cantelli_lemmas/index.html",
    "href": "posts/borel_cantelli_lemmas/index.html",
    "title": "Borel-Cantelli Lemmas",
    "section": "",
    "text": "Borel-Cantelli Lemmas.\n\n(First Borel-Cantelli Lemma) Let \\((A_n)\\) be a sequence of events such that the series \\(\\sum_n \\mathbb{P}(A_n)\\) converges to a finite value \\(L\\). Then, almost surely finitely many \\(A_n\\)’s will occur.\n(Second Borel-Cantelli Lemma) Let \\((A_n)\\) be a sequence of independent events, such that the infinite series \\(\\sum_n \\mathbb{P}(A_n)\\) diverges to \\(\\infty\\). Then, almost surely, infinitely many \\(A_n\\)’s will occur.\n\nFix a probability space \\((\\Omega,\\mathcal{F},\\mathbb{P})\\). Let \\(A_1, A_2, A_3, \\ldots\\) be an infinite sequence of events belonging to \\(\\mathcal{F}\\). We shall often be interested in finding out how many of the \\(A_n\\)’s occur.\nThe event \\(A_n\\) occurs infinitely often (\\(A_n\\hspace{2mm}i.o\\)) is the set of all \\(\\omega\\) that belong to infinitely many \\(A_n\\)’s.\nImagine that an infinite number of \\(A_n\\)’s occur. That is, \\((\\forall n)(\\exists m \\geq n)(\\text{s.t. }A_m \\text{ occurs})\\). In other words:\n\\[\\begin{align*}\n\\{A_n \\text{ infinitely often}\\} = \\bigcap_{n=1}^{\\infty} \\underbrace{\\bigcup_{m\\geq n} A_m}_{B_n} \\tag{1}\n\\end{align*}\\]\nHere, \\(B_n\\) is the event that atleast one of \\(A_n,A_{n+1},\\ldots\\) occur. For that reason, \\(B_n\\) is referred to as the \\(n\\)-th tail event. \\(\\{A_n \\hspace{2mm} i.o.\\}\\) is the intersection of all \\(B_n\\)’s, so it is the event that all the \\(B_n\\)’s occur. Therefore, no matter how far I go, no matter how big \\(n_0\\) is, atleast one of \\(A_{n_0}, A_{n_0}+1,\\ldots\\) occurs.\nTaking the complement of both sides in (1), we get the expression for the event that \\(A_n\\) occurs finitely many times.\n\\[\\begin{align*}\n\\{A_n \\text{ occurs finitely often}\\} = \\bigcup_{n_0=1}^{\\infty} \\bigcap_{n \\geq n_0} A_n^C\n\\end{align*}\\]\nIt means that, there exists an \\(n_0\\), such that each of the further \\(A_i\\)’s fail to occur.\nIn order to prove the Borel-Cantelli lemmas, we require the following lemma."
  },
  {
    "objectID": "posts/borel_cantelli_lemmas/index.html#borel-cantelli-lemmas",
    "href": "posts/borel_cantelli_lemmas/index.html#borel-cantelli-lemmas",
    "title": "Borel-Cantelli Lemmas",
    "section": "",
    "text": "Borel-Cantelli Lemmas.\n\n(First Borel-Cantelli Lemma) Let \\((A_n)\\) be a sequence of events such that the series \\(\\sum_n \\mathbb{P}(A_n)\\) converges to a finite value \\(L\\). Then, almost surely finitely many \\(A_n\\)’s will occur.\n(Second Borel-Cantelli Lemma) Let \\((A_n)\\) be a sequence of independent events, such that the infinite series \\(\\sum_n \\mathbb{P}(A_n)\\) diverges to \\(\\infty\\). Then, almost surely, infinitely many \\(A_n\\)’s will occur.\n\nFix a probability space \\((\\Omega,\\mathcal{F},\\mathbb{P})\\). Let \\(A_1, A_2, A_3, \\ldots\\) be an infinite sequence of events belonging to \\(\\mathcal{F}\\). We shall often be interested in finding out how many of the \\(A_n\\)’s occur.\nThe event \\(A_n\\) occurs infinitely often (\\(A_n\\hspace{2mm}i.o\\)) is the set of all \\(\\omega\\) that belong to infinitely many \\(A_n\\)’s.\nImagine that an infinite number of \\(A_n\\)’s occur. That is, \\((\\forall n)(\\exists m \\geq n)(\\text{s.t. }A_m \\text{ occurs})\\). In other words:\n\\[\\begin{align*}\n\\{A_n \\text{ infinitely often}\\} = \\bigcap_{n=1}^{\\infty} \\underbrace{\\bigcup_{m\\geq n} A_m}_{B_n} \\tag{1}\n\\end{align*}\\]\nHere, \\(B_n\\) is the event that atleast one of \\(A_n,A_{n+1},\\ldots\\) occur. For that reason, \\(B_n\\) is referred to as the \\(n\\)-th tail event. \\(\\{A_n \\hspace{2mm} i.o.\\}\\) is the intersection of all \\(B_n\\)’s, so it is the event that all the \\(B_n\\)’s occur. Therefore, no matter how far I go, no matter how big \\(n_0\\) is, atleast one of \\(A_{n_0}, A_{n_0}+1,\\ldots\\) occurs.\nTaking the complement of both sides in (1), we get the expression for the event that \\(A_n\\) occurs finitely many times.\n\\[\\begin{align*}\n\\{A_n \\text{ occurs finitely often}\\} = \\bigcup_{n_0=1}^{\\infty} \\bigcap_{n \\geq n_0} A_n^C\n\\end{align*}\\]\nIt means that, there exists an \\(n_0\\), such that each of the further \\(A_i\\)’s fail to occur.\nIn order to prove the Borel-Cantelli lemmas, we require the following lemma."
  },
  {
    "objectID": "posts/borel_cantelli_lemmas/index.html#limit-of-product-series",
    "href": "posts/borel_cantelli_lemmas/index.html#limit-of-product-series",
    "title": "Borel-Cantelli Lemmas",
    "section": "Limit of product series",
    "text": "Limit of product series\nLemma. If \\(\\sum_{i=1}^\\infty p_i = \\infty\\), then \\(\\lim \\prod_{i=1}^{n}(1-p_i) = 0\\).\nProof.\nWe know that:\nUsing Taylor’s series expansion of \\(\\ln(1+x)\\) about \\(a=0\\), we have:\n\\[\\begin{align*}\n\\ln(1+x) &= x - \\frac{f''(c)}{2!}x^2\\\\\n&= x - \\frac{1}{(1+c)^2} \\cdot \\frac{x^2}{2}\\\\\n&\\leq x\\\\\n&\\quad \\{\\text{since } \\left(\\frac{x}{1+c}\\right)^2 \\geq 0\\}\n\\end{align*}\\]\nSo,\n\\[\\begin{align*}\n\\ln(1 - p_i) &\\leq -p_i\\\\\n\\sum_{i=1}^{n} \\ln(1 - p_i) &\\leq \\sum_{i=1}^{n} (-p_i)\\\\\n\\ln\\left(\\prod_{i=1}^{n}(1-p_i)\\right) &\\leq \\sum_{i=1}^{n} (-p_i)\\\\\n\\prod_{i=1}^{n}(1-p_i) &\\leq e^{-\\sum_{i=1}^{n} p_i}\n\\end{align*}\\]\nSo,\n\\[\\begin{align*}\n0 \\leq \\prod_{i=1}^{n}(1-p_i) \\leq e^{-\\lim \\sum_{i=1}^{n} p_i}\n\\end{align*}\\]\nNow, \\(e^{-\\lim \\sum_{i=1}^{n} p_i} = 0\\), so by the squeeze theorem, \\(\\lim \\prod_{i=1}^{n}(1-p_i) = 0\\)."
  },
  {
    "objectID": "posts/borel_cantelli_lemmas/index.html#proof-of-the-first-borel-cantelli-lemma",
    "href": "posts/borel_cantelli_lemmas/index.html#proof-of-the-first-borel-cantelli-lemma",
    "title": "Borel-Cantelli Lemmas",
    "section": "Proof of the First Borel-Cantelli Lemma",
    "text": "Proof of the First Borel-Cantelli Lemma\nOur claim is that \\(\\mathbb{P}\\left(\\bigcap_{n=1}^{\\infty} B_n\\right) = 0\\). Observe that, \\(B_1 \\supseteq B_2 \\supseteq B_3 \\supseteq \\ldots\\). So, \\((B_n)\\) is a decreasing sequence of events.\n\\[\\begin{align*}\n\\mathbb{P}\\left(\\bigcap_{n=1}^{\\infty} B_n\\right) &= \\lim_{n \\to \\infty }\\mathbb{P}(B_n) \\\\\n& \\quad \\{ \\text{Continuity of probability measure} \\}\\\\\n&= \\lim_{n\\to\\infty} \\mathbb{P}\\left(\\bigcup_{n=1}^{\\infty}A_n\\right)\\\\\n&\\leq \\lim_{n\\to\\infty} \\sum_{n=1}^{\\infty} \\mathbb{P}\\left(A_n\\right)\\\\\n& \\quad \\{ \\text{Union bound} \\}\n\\end{align*}\\]\nThe infinite series \\(\\sum_{n=1}^{\\infty} \\mathbb{P}\\left(A_n\\right)\\) is convergent. The tail sum \\(\\lim_{k \\to \\infty} \\sum a_k\\) of a convergent series \\(\\sum a_k\\) is zero. Hence,\n\\[\\begin{align*}\n0 \\leq \\mathbb{P}\\left(\\bigcap_{n=1}^{\\infty} B_n\\right) \\leq 0\n\\end{align*}\\]\nConsequently,\n\\[\\begin{align*}\n\\mathbb{P}\\left(\\bigcap_{n=1}^{\\infty} B_n\\right) = 0\n\\end{align*}\\]\nHence, \\(A_n\\) occurs only finitely many times."
  },
  {
    "objectID": "posts/borel_cantelli_lemmas/index.html#proof-of-the-second-borel-cantelli-lemma",
    "href": "posts/borel_cantelli_lemmas/index.html#proof-of-the-second-borel-cantelli-lemma",
    "title": "Borel-Cantelli Lemmas",
    "section": "Proof of the second Borel-Cantelli Lemma",
    "text": "Proof of the second Borel-Cantelli Lemma\nOur claim is that \\(\\mathbb{P}\\left(A_n \\hspace{2mm} i.o.\\right) = 1\\). We must therefore prove that:\n\\[\\begin{align*}\n\\mathbb{P} \\left(\\bigcap_{m=1}^{\\infty} \\bigcup_{n=m}^{\\infty}A_n \\right) = \\mathbb{P} \\left(\\bigcap_{m=1}^{\\infty} B_m \\right) = 1\n\\end{align*}\\]\nOr:\n\\[\\begin{align*}\n\\mathbb{P} \\left(\\bigcup_{n=1}^{\\infty} B_n^C \\right) = 0\n\\end{align*}\\]\nSince \\((B_n^C)\\) is an increasing sequence of events, we have:\n\\[\\begin{align*}\n\\mathbb{P} \\left(\\bigcup_{n=1}^{\\infty} B_n^C\\right) &= \\lim \\mathbb{P}(B_n^C)\\\\\n&= \\lim \\mathbb{P}\\left\\{ \\left(\\bigcup_{m \\geq n} A_m\\right)^C \\right\\} \\\\\n&= \\lim \\mathbb{P} \\left\\{\\bigcap_{m \\geq n} A_m^C \\right\\}\\\\\n&= \\lim \\prod_{m=n}^{\\infty} \\mathbb{P} (A_m^C)\\\\\n&= \\lim \\prod_{m=n}^{\\infty} (1-P(A_m))\n\\end{align*}\\]\nSince \\(\\sum_i P(A_i)\\) diverges to \\(\\infty\\), \\(\\prod_i (1-P(A_i))\\) converges to zero. Consequently,\n\\[\\begin{align*}\n\\mathbb{P} \\left(\\bigcup_{n=1}^{\\infty} B_n^C \\right) = 0\n\\end{align*}\\]"
  },
  {
    "objectID": "posts/c++20-concepts/index.html",
    "href": "posts/c++20-concepts/index.html",
    "title": "C++20 concepts",
    "section": "",
    "text": "A class template, function template (including lambdas) may be associated with a constraint, which specifies requirements on the template arguments. This can be used to select the most appropriate function overload or template specialization.\nA concept is a named set of such constraints. A concept is ultimately a logical predicate \\(P(x)\\), evaluated at compile-time, where \\(x\\) represents template parameters. A function or class template constrained by the concept \\(P\\), will work only for template arguments that satisfy \\(P\\).\nConsider the templated function:\n#include &lt;iostream&gt;\n#include &lt;complex&gt;\n\ntemplate&lt;typename T&gt;\nT sum(T const a, T const b){\n    return (a + b);\n}\n\nint main()\n{\n    using namespace std::literals::complex_literals;\n\n    int x{2}, y{3};\n\n    sum(x, y);\n    sum(2.71828, 3.14159);\n    sum(std::complex{1.0 + 1.0i}, std::complex{1.0 - 1.0i});\n    //sum(\"42\", \"1\");       //Error cannot add two strings\n\n    return 0;\n}\nCompiler Explorer\nThe sum function returns the result of applying the binary operator+(T,T) on its arguments. The sum function only makes sense when we discuss mathematical types such as integers, floating-point numbers, std::complex&lt;double&gt;, vectors and matrices. For most types, overloading the operator + makes no sense at all.\nTherefore, just by looking at the declaration of this function, without inspecting its body, we cannot really say what this function may accept as input and what it does.\nThe intention for our sum function template is to allow passing only types that support arithmetic operations. One way is to use std::enable_if:\n#include &lt;iostream&gt;\n#include &lt;complex&gt;\n#include &lt;type_traits&gt;\n\ntemplate&lt;typename T, \n        typename = typename std::enable_if&lt;std::is_arithmetic_v&lt;T&gt;,T&gt;&gt;\nT sum(T const a, T const b){\n    return (a + b);\n}\n\nint main()\n{\n    using namespace std::literals::complex_literals;\n\n    int x{2}, y{3};\n\n    sum(x, y);\n    sum(2.71828, 3.14159);\n    sum(std::complex{1.0 + 1.0i}, std::complex{1.0 - 1.0i});\n    sum(\"42\", \"1\");    \n\n    return 0;\n}\nCompiler Explorer\nWe added an anonymous template parameter which calls the type metafunction std::enable_if&lt;C,T&gt; from the type_traits library. If the condition C evaluates to std::true_type, then std::enable_if&lt;C,T&gt; returns T. Since std::is_arithmetic_v&lt;const char*&gt; returns false_type, enable_if meta-function doesn’t return anything and the code will not build.\nWith this implementation, the code readability has decreased. The second type template parameter is difficult to read and certainly requires good TMP knowledge. The compiler error messages could also be cryptic.\nWe can improve these two aspects (code readability and compiler error messages) in C++ 20 by using constraints. These are introduced with the requires keyword as follows:\n#include &lt;iostream&gt;\n#include &lt;complex&gt;\n#include &lt;type_traits&gt;\n#include &lt;concepts&gt;\n\ntemplate&lt;typename T&gt;\nrequires std::is_arithmetic_v&lt;T&gt;\nT sum(T const a, T const b){\n    return (a + b);\n}\n\nint main()\n{\n    int x{2}, y{3};\n\n    sum(x, y);\n    sum(2.71828, 3.14159);\n    sum(\"42\", \"1\");    \n\n    return 0;\n}\nCompiler Explorer\nThe compiler error message is more meaningful and states that the constraint is_arithmetic_v&lt;const char*&gt; evaluates to false.\nThe requires keyword introduces a clause, called the requires clasuse, that defines constraints on the template parameters. A constraint is a predicate that evaluates to true or false at compile-time. The expression used in the previous example, std::is_arithmetic_v&lt;T&gt; is simply using a standard type-trait."
  },
  {
    "objectID": "posts/c++20-concepts/index.html#simple-requirements",
    "href": "posts/c++20-concepts/index.html#simple-requirements",
    "title": "C++20 concepts",
    "section": "Simple requirements",
    "text": "Simple requirements\nA simple requirement is an expression that is not evaluated but only checked for correctness. The expression must be valid for the requirement to be evaluated to true.\ntemplate&lt;typename T&gt;\nconcept arithmetic requires(T a){\n  std::is_arithmetic_v&lt;T&gt;;\n};"
  },
  {
    "objectID": "posts/c++20-concepts/index.html#type-requirements",
    "href": "posts/c++20-concepts/index.html#type-requirements",
    "title": "C++20 concepts",
    "section": "Type requirements",
    "text": "Type requirements\nType requirements are introduced with the typename keyword followed by the name of a type. We can use it verify if :\n\nA nested type exists(such as in typename T::value_type).\nA class template specialization names a type.\nAn alias template specialization names a type.\n\nLet’s code up a few examples.\ntemplate&lt;typename T&gt;\nconcept KeyValuePair = requires{\n  typename T::key_type;\n  typename T::value_type;\n}\n\ntemplate&lt;typename T, typename U&gt;\nstruct Pair{\n\n  using key_type = T;\n  using value_type = U;\n\n  key_type key;\n  value_type value;\n};\nPair satisfies the concept KeyValuePair, as it has inner types key_type and value_type. To verify this is indeed the case, we can use KeyValuePair as a compile-time metafunction.\nstatic_assert(KeyValuePair&lt;Pair&gt;);\nstatic_assert(!KeyValuePair&lt;std::pair&gt;);\nstd::pair&lt;T,U&gt; does have inner types, but they are called first_type and second_type.\n#include&lt;iostream&gt;\n#include&lt;type_traits&gt;\n#include&lt;concepts&gt;\n\ntemplate&lt;typename T&gt;\nconcept arithmetic = std::is_arithmetic_v&lt;T&gt;;\n\ntemplate&lt;arithmetic T&gt;\nstruct Point2D{\n    T x;\n    T y;\n};\n\ntemplate&lt;typename T&gt;\nusing Ref = T&;\n\ntemplate&lt;typename T&gt;\nconcept C = requires(T t){\n    typename T::inner; // required nested member name\n    typename Point2D&lt;T&gt;; // required class template specialization\n    typename Ref&lt;T&gt;;     // required alias template specialization\n};"
  },
  {
    "objectID": "posts/c++20-concepts/index.html#compound-requirements",
    "href": "posts/c++20-concepts/index.html#compound-requirements",
    "title": "C++20 concepts",
    "section": "Compound requirements",
    "text": "Compound requirements\nA compound requirement has the form:\n{expression} noexcept -&gt; return_type_requirement\nand asserts the properties of the named expression. Both the noexcept and the return_type_requirement are optional.\nLet’s code up a couple of examples.\nIn the below example, we define a NonThrowing to check if a function is marked with the noexcept specifier.\n#include&lt;iostream&gt;\n#include&lt;type_traits&gt;\n#include&lt;concepts&gt;\n\n/* \nTemplate Metaprogramming \nMariusz Bancila  \n*/\ntemplate&lt;typename T&gt;\nvoid f(T) noexcept {}\n\ntemplate&lt;typename T&gt;\nvoid g(T) {}\n\ntemplate &lt;typename F, typename... T&gt;\nconcept NonThrowing = requires(F&& func, T... t){\n  {func(t...)} noexcept;\n};\n\ntemplate&lt;typename F, typename... T&gt;\nrequires NonThrowing&lt;F,T...&gt;\nvoid invoke(F&& func, T... t)\n{\n  func(t...);\n}\n\nint main()\n{\n    invoke(f&lt;double&gt;, 100.0);\n    // invoke(g&lt;double&gt;, 100.0); //Error\n    return 0;\n}\nCompiler Explorer\nThe call invoke(g&lt;double&gt;,100.0) is not valid, because g&lt;double&gt; may throw an exception, which results in NonThrowing&lt;F,T...&gt; to evaluating as false."
  },
  {
    "objectID": "posts/c++20-concepts/index.html#nested-requirements",
    "href": "posts/c++20-concepts/index.html#nested-requirements",
    "title": "C++20 concepts",
    "section": "Nested requirements",
    "text": "Nested requirements\nA nested requirement has the form:\nrequires constraint_expression;\nIt is introduced by the requires keyword. Suppose we want to define a function that performs addition on a variable number of arguments. However, we want to impose some conditions:\n\nThere is more than one argument.\nAll arguments have the same type.\nThe expression arg1 + arg2 + ... + argn is valid.\n\nWe define a concept called HomogenousRange as follows:\n/* \nTemplate Metaprogramming \nMariusz Bancila  \n*/\ntemplate&lt;typename T, typename... Ts&gt;\ninline constexpr bool are_same_v = \n  std::conjunction_v&lt;std::is_same&lt;T,Ts&gt;...&gt;;\n\ntemplate &lt;typename... T&gt;\nconcept HomogenousRange = requires(T... t)\n{\n  (... + t);\n  requires are_same_v&lt;T...&gt;;\n  requires sizeof...(T) &gt; 1;\n}\nThis concept contains one simple requirement and two nested requirements. std::conjunction_v&lt;B1,...,BN&gt; is a type metafunction that forms the logical conjunction of conditions B1,…,BN, effectively performing a logical AND on the sequence. It works as follows:\n\nIf sizeof...(B)==0, std::true_type otherwise\nThe first type Bi in B1,...,BN for which Bi is false or BN if there is no such type.\n\nThe pattern std::is_same&lt;T,Ts&gt;... is expanded as\nstd::is_same&lt;T,T1&gt;,std::is_same&lt;T,T2&gt;,...,std::is_same&lt;T,Tn&gt;\nAkin to the logical AND operation, if all of them evaluate to std::true_type, the type metafunction std::conjunction_v&lt;B1,...,Bn returns std::true_type.\nThe simple requirement (... + t) specifies that left fold expression (adding all the arguments) is a valid operation.\nUsing this concept, we can define the variadic function template:\n#include&lt;iostream&gt;\n#include&lt;type_traits&gt;\n#include&lt;concepts&gt;\n\n/* \nTemplate Metaprogramming \nMariusz Bancila  \n*/\ntemplate&lt;typename T, typename... Ts&gt;\ninline constexpr bool are_same_v = \n  std::conjunction_v&lt;std::is_same&lt;T,Ts&gt;...&gt;;\n\ntemplate &lt;typename... T&gt;\nconcept HomogenousRange = requires(T... t)\n{\n  (... + t);\n  requires are_same_v&lt;T...&gt;;\n  requires sizeof...(T) &gt; 1;\n};\n\ntemplate&lt;typename... T&gt;\nrequires HomogenousRange&lt;T...&gt;\nstd::common_type_t&lt;T...&gt; sum(T&&... args){\n    return (... + args);\n}\n\nint main()\n{\n    auto result = sum(1, 2, 3, 4, 5);\n    return 0;\n}\nCompiler Explorer"
  },
  {
    "objectID": "posts/class-template-argument-deduction/index.html",
    "href": "posts/class-template-argument-deduction/index.html",
    "title": "Class Template Argument Deduction(CTAD)",
    "section": "",
    "text": "Its super-helpful to have a good low-level hang of the template argument deduction rules (more on deduction guides in another post). Essentially, since C++17, you can just declare, std::vector{1.0, 2.0, 3.0, 4.0, 5.0} - clean and nice instead of std::vector&lt;double&gt;{1.0, 2.0, 3.0, 4.0, 5.0}.\nWhen the compiler tries to deduce the template arguments, it performs matching of the type template parameters with the types of arguments used to invoke the function.\nVery succinctly, the compiler can match: - Types of the form T, T const, T volatile - Pointers T*, lvalue references T& and universal references T&& - Arrays such as T[5] and C[5][n] - Pointers to functions - Pointers to member-functions and data-members.\n#include &lt;iostream&gt;\n#include &lt;vector&gt;\n#include &lt;chrono&gt;\n#include &lt;tuple&gt;\n\nusing namespace std::chrono;\n\ntemplate&lt;typename T&gt;\nstd::ostream& operator&lt;&lt;(std::ostream& out, const std::vector&lt;T&gt; vec){\n    for(int i{0}; i &lt; vec.size(); ++ i){\n        out &lt;&lt; \"\\n[\" &lt;&lt; i &lt;&lt; \"] = \" &lt;&lt; vec[i];\n    }\n    return out;\n}\n\nstruct BondDiscountingCurve{\n    std::vector&lt;std::pair&lt;year_month_day,double&gt;&gt; discountFactorCurve;\n};\n\nstruct CustomBond{\n    std::vector&lt;double&gt; cashflows;\n    std::vector&lt;std::chrono::year_month_day&gt; cashflow_dates;\n\n    double pv(BondDiscountingCurve disc){\n        double result{0.0};\n        for(int i{0};i &lt; cashflows.size(); ++i)\n        {\n            double df = std::get&lt;1&gt;(disc.discountFactorCurve[i]);\n            result += cashflows[i] * df;\n        }\n        return result;\n    }\n};\n\nstruct Leg{\n    // A cashflow is a 4-tuple (Cashflow date, Cashflow amount, Cap, Floor)\n    using flow = std::tuple&lt;year_month_day, double, double, double&gt;;\n    std::vector&lt;flow&gt; flows;\n};\n\nstruct AssetSwap{\n    Leg bondLeg;\n    Leg fundingLeg;\n\n    Leg getBondLeg() { return bondLeg; }\n    Leg getFundingLeg() { return fundingLeg; }\n};\n\ntemplate&lt;typename T&gt;\nvoid process01(T bond){ std::cout &lt;&lt; \"T\\n\"; }\n\ntemplate&lt;typename T&gt;\nvoid process02(T const){ std::cout &lt;&lt; \"T const\\n\"; }\n\ntemplate&lt;typename T&gt;\nvoid process03(T volatile) { std::cout &lt;&lt; \"T volatile\\n\"; }\n\ntemplate&lt;typename T&gt;\nvoid process04(T*) { std::cout &lt;&lt; \"T*\\n\"; }\n\ntemplate&lt;typename T&gt;\nvoid process04(T&) { std::cout &lt;&lt; \"T&\\n\"; }\n\n// Universal reference\ntemplate&lt;typename T&gt;\nvoid process05(T&&) { std::cout &lt;&lt; \"T&&\\n\"; }\n\ntemplate&lt;typename T&gt;\nvoid process06(T[5]) { std::cout &lt;&lt; \"T[5]\\n\"; }\n\ntemplate&lt;typename T&gt;\nvoid process07(T[3][5]) { std::cout &lt;&lt; \"T[3][5]\\n\"; }\n\ntemplate&lt;typename T&gt;\nvoid process08(T(*)()) { std::cout &lt;&lt; \"T (*)()\\n\"; }\n\ntemplate&lt;typename T&gt;\nvoid process08(CustomBond (*)(T)) { std::cout &lt;&lt; \"C (*)(T)\\n\"; }\n\ntemplate&lt;typename T, typename U&gt;\nvoid process08(T(*)(U)) { std::cout &lt;&lt; \"T (*)(U)\\n\"; }\n\ntemplate&lt;typename T&gt;\nvoid process09(T(CustomBond::*)()) { std::cout &lt;&lt; \"T (C::*)()\\n\"; }\n\ntemplate&lt;typename T, typename U&gt;\nvoid process09(T(CustomBond::*)(U)) { std::cout &lt;&lt; \"T (C::*)(U)\\n\"; }\n\ntemplate&lt;typename T, typename U&gt;\nvoid process09(T(U::*)()) { std::cout &lt;&lt; \"T (U::*)()\\n\"; }\n\ntemplate&lt;typename T, typename U, typename V&gt;\nvoid process09(T(U::*)(V)) { std::cout &lt;&lt; \"T (U::*)(V)\\n\"; }\n\ntemplate&lt;typename T&gt;\nvoid process09(Leg(T::*)()) { std::cout &lt;&lt; \"C (T::*)()\\n\"; }\n\ntemplate&lt;typename T, typename U&gt;\nvoid process09(Leg(T::*)(U)) { std::cout &lt;&lt; \"C (T::*)(U)\\n\"; }\n\ntemplate&lt;typename T&gt;\nvoid process09(Leg(AssetSwap::*)(T)) { std::cout &lt;&lt; \"D (C::*)(T)\\n\"; }\n\ntemplate&lt;typename T&gt;\nvoid process10(T CustomBond::*) { std::cout &lt;&lt; \"T C::*\\n\"; }\n\ntemplate&lt;typename T&gt;\nvoid process10(Leg T::*) { std::cout &lt;&lt; \"C T::*\\n\"; }\n\ntemplate&lt;typename T, typename U&gt;\nvoid process10(T U::*) { std::cout &lt;&lt; \"T U::*\\n\"; }\n\nint main()\n{\n    CustomBond bond(\n        {0.05, 0.05, 0.05, 1.05},\n        {2024y/June/20d, 2024y/December/20d, 2025y/June/20d, 2025y/December/20d}\n    );\n\n    AssetSwap assetSwap;\n\n    process01(bond);    // T\n    process02(bond);    // T const\n    process03(bond);    // T volatile\n    process04(&bond);   // T*\n    process04(bond);    // T&\n    process05(bond);    // T&&; deduced as CustomBond& \n\n    CustomBond bondsArray[5] {};  //Create an array of custom bonds\n    process06(bondsArray);  // T[5]\n    process06(&bond);       // T[5]\n\n    CustomBond bondsByMaturityAndRating[3][5] {}; \n    process07(bondsByMaturityAndRating);    //C[5][n]\n\n    CustomBond (*funcptr1)() = nullptr;\n    CustomBond (*funcptr2)(int) = nullptr;\n    double     (*funcptr3)(int) = nullptr;\n\n    process08(funcptr1);    //T(*)()\n    process08(funcptr2);    //C(*)(T)\n    process08(funcptr3);    //T(*)(U)\n\n    double (CustomBond::*ptrmemfunc1) () = nullptr;\n    double (CustomBond::*ptrmemfunc2)(BondDiscountingCurve) = &CustomBond::pv;\n    std::vector&lt;double&gt; (Leg::*ptrmemfunc3)() = nullptr;\n    double(AssetSwap::*getLegPv)(Leg) = nullptr;\n    Leg(AssetSwap::*ptrmemfunc4)() = &AssetSwap::getFundingLeg;\n    Leg(Leg::*applyScaleToAllCoupons)(double) = nullptr;\n    Leg(AssetSwap::*applyFixedSpreadToAllCoupons)(double) = nullptr;\n    //Leg(AssetSwap::*)()\n\n    process09(ptrmemfunc1);     // T(C::*)()\n    process09(ptrmemfunc2);     // T(C::*)(U)\n    process09(ptrmemfunc3);     // T(U::*)()\n    process09(getLegPv);        // T(U::*)(V)\n    process09(ptrmemfunc4);     // C(T::*)()\n    process09(applyScaleToAllCoupons);          //C(T::*)(U)\n    process09(applyFixedSpreadToAllCoupons);    //D(C::*)(T)\n\n    process10(&CustomBond::cashflows);\n    process10(&AssetSwap::bondLeg);\n    process10(&Leg::flows);\n    return 0;\n}\nCompiler Explorer"
  },
  {
    "objectID": "posts/class-template-argument-deduction/index.html#function-template-argument-deduction.",
    "href": "posts/class-template-argument-deduction/index.html#function-template-argument-deduction.",
    "title": "Class Template Argument Deduction(CTAD)",
    "section": "",
    "text": "Its super-helpful to have a good low-level hang of the template argument deduction rules (more on deduction guides in another post). Essentially, since C++17, you can just declare, std::vector{1.0, 2.0, 3.0, 4.0, 5.0} - clean and nice instead of std::vector&lt;double&gt;{1.0, 2.0, 3.0, 4.0, 5.0}.\nWhen the compiler tries to deduce the template arguments, it performs matching of the type template parameters with the types of arguments used to invoke the function.\nVery succinctly, the compiler can match: - Types of the form T, T const, T volatile - Pointers T*, lvalue references T& and universal references T&& - Arrays such as T[5] and C[5][n] - Pointers to functions - Pointers to member-functions and data-members.\n#include &lt;iostream&gt;\n#include &lt;vector&gt;\n#include &lt;chrono&gt;\n#include &lt;tuple&gt;\n\nusing namespace std::chrono;\n\ntemplate&lt;typename T&gt;\nstd::ostream& operator&lt;&lt;(std::ostream& out, const std::vector&lt;T&gt; vec){\n    for(int i{0}; i &lt; vec.size(); ++ i){\n        out &lt;&lt; \"\\n[\" &lt;&lt; i &lt;&lt; \"] = \" &lt;&lt; vec[i];\n    }\n    return out;\n}\n\nstruct BondDiscountingCurve{\n    std::vector&lt;std::pair&lt;year_month_day,double&gt;&gt; discountFactorCurve;\n};\n\nstruct CustomBond{\n    std::vector&lt;double&gt; cashflows;\n    std::vector&lt;std::chrono::year_month_day&gt; cashflow_dates;\n\n    double pv(BondDiscountingCurve disc){\n        double result{0.0};\n        for(int i{0};i &lt; cashflows.size(); ++i)\n        {\n            double df = std::get&lt;1&gt;(disc.discountFactorCurve[i]);\n            result += cashflows[i] * df;\n        }\n        return result;\n    }\n};\n\nstruct Leg{\n    // A cashflow is a 4-tuple (Cashflow date, Cashflow amount, Cap, Floor)\n    using flow = std::tuple&lt;year_month_day, double, double, double&gt;;\n    std::vector&lt;flow&gt; flows;\n};\n\nstruct AssetSwap{\n    Leg bondLeg;\n    Leg fundingLeg;\n\n    Leg getBondLeg() { return bondLeg; }\n    Leg getFundingLeg() { return fundingLeg; }\n};\n\ntemplate&lt;typename T&gt;\nvoid process01(T bond){ std::cout &lt;&lt; \"T\\n\"; }\n\ntemplate&lt;typename T&gt;\nvoid process02(T const){ std::cout &lt;&lt; \"T const\\n\"; }\n\ntemplate&lt;typename T&gt;\nvoid process03(T volatile) { std::cout &lt;&lt; \"T volatile\\n\"; }\n\ntemplate&lt;typename T&gt;\nvoid process04(T*) { std::cout &lt;&lt; \"T*\\n\"; }\n\ntemplate&lt;typename T&gt;\nvoid process04(T&) { std::cout &lt;&lt; \"T&\\n\"; }\n\n// Universal reference\ntemplate&lt;typename T&gt;\nvoid process05(T&&) { std::cout &lt;&lt; \"T&&\\n\"; }\n\ntemplate&lt;typename T&gt;\nvoid process06(T[5]) { std::cout &lt;&lt; \"T[5]\\n\"; }\n\ntemplate&lt;typename T&gt;\nvoid process07(T[3][5]) { std::cout &lt;&lt; \"T[3][5]\\n\"; }\n\ntemplate&lt;typename T&gt;\nvoid process08(T(*)()) { std::cout &lt;&lt; \"T (*)()\\n\"; }\n\ntemplate&lt;typename T&gt;\nvoid process08(CustomBond (*)(T)) { std::cout &lt;&lt; \"C (*)(T)\\n\"; }\n\ntemplate&lt;typename T, typename U&gt;\nvoid process08(T(*)(U)) { std::cout &lt;&lt; \"T (*)(U)\\n\"; }\n\ntemplate&lt;typename T&gt;\nvoid process09(T(CustomBond::*)()) { std::cout &lt;&lt; \"T (C::*)()\\n\"; }\n\ntemplate&lt;typename T, typename U&gt;\nvoid process09(T(CustomBond::*)(U)) { std::cout &lt;&lt; \"T (C::*)(U)\\n\"; }\n\ntemplate&lt;typename T, typename U&gt;\nvoid process09(T(U::*)()) { std::cout &lt;&lt; \"T (U::*)()\\n\"; }\n\ntemplate&lt;typename T, typename U, typename V&gt;\nvoid process09(T(U::*)(V)) { std::cout &lt;&lt; \"T (U::*)(V)\\n\"; }\n\ntemplate&lt;typename T&gt;\nvoid process09(Leg(T::*)()) { std::cout &lt;&lt; \"C (T::*)()\\n\"; }\n\ntemplate&lt;typename T, typename U&gt;\nvoid process09(Leg(T::*)(U)) { std::cout &lt;&lt; \"C (T::*)(U)\\n\"; }\n\ntemplate&lt;typename T&gt;\nvoid process09(Leg(AssetSwap::*)(T)) { std::cout &lt;&lt; \"D (C::*)(T)\\n\"; }\n\ntemplate&lt;typename T&gt;\nvoid process10(T CustomBond::*) { std::cout &lt;&lt; \"T C::*\\n\"; }\n\ntemplate&lt;typename T&gt;\nvoid process10(Leg T::*) { std::cout &lt;&lt; \"C T::*\\n\"; }\n\ntemplate&lt;typename T, typename U&gt;\nvoid process10(T U::*) { std::cout &lt;&lt; \"T U::*\\n\"; }\n\nint main()\n{\n    CustomBond bond(\n        {0.05, 0.05, 0.05, 1.05},\n        {2024y/June/20d, 2024y/December/20d, 2025y/June/20d, 2025y/December/20d}\n    );\n\n    AssetSwap assetSwap;\n\n    process01(bond);    // T\n    process02(bond);    // T const\n    process03(bond);    // T volatile\n    process04(&bond);   // T*\n    process04(bond);    // T&\n    process05(bond);    // T&&; deduced as CustomBond& \n\n    CustomBond bondsArray[5] {};  //Create an array of custom bonds\n    process06(bondsArray);  // T[5]\n    process06(&bond);       // T[5]\n\n    CustomBond bondsByMaturityAndRating[3][5] {}; \n    process07(bondsByMaturityAndRating);    //C[5][n]\n\n    CustomBond (*funcptr1)() = nullptr;\n    CustomBond (*funcptr2)(int) = nullptr;\n    double     (*funcptr3)(int) = nullptr;\n\n    process08(funcptr1);    //T(*)()\n    process08(funcptr2);    //C(*)(T)\n    process08(funcptr3);    //T(*)(U)\n\n    double (CustomBond::*ptrmemfunc1) () = nullptr;\n    double (CustomBond::*ptrmemfunc2)(BondDiscountingCurve) = &CustomBond::pv;\n    std::vector&lt;double&gt; (Leg::*ptrmemfunc3)() = nullptr;\n    double(AssetSwap::*getLegPv)(Leg) = nullptr;\n    Leg(AssetSwap::*ptrmemfunc4)() = &AssetSwap::getFundingLeg;\n    Leg(Leg::*applyScaleToAllCoupons)(double) = nullptr;\n    Leg(AssetSwap::*applyFixedSpreadToAllCoupons)(double) = nullptr;\n    //Leg(AssetSwap::*)()\n\n    process09(ptrmemfunc1);     // T(C::*)()\n    process09(ptrmemfunc2);     // T(C::*)(U)\n    process09(ptrmemfunc3);     // T(U::*)()\n    process09(getLegPv);        // T(U::*)(V)\n    process09(ptrmemfunc4);     // C(T::*)()\n    process09(applyScaleToAllCoupons);          //C(T::*)(U)\n    process09(applyFixedSpreadToAllCoupons);    //D(C::*)(T)\n\n    process10(&CustomBond::cashflows);\n    process10(&AssetSwap::bondLeg);\n    process10(&Leg::flows);\n    return 0;\n}\nCompiler Explorer"
  },
  {
    "objectID": "posts/class-template-argument-deduction/index.html#ctad-class-template-argument-deduction.",
    "href": "posts/class-template-argument-deduction/index.html#ctad-class-template-argument-deduction.",
    "title": "Class Template Argument Deduction(CTAD)",
    "section": "CTAD (Class Template Argument Deduction).",
    "text": "CTAD (Class Template Argument Deduction).\n\nThe basic mechanics.\nCTAD(Class Template Argument Deduction) has \\(2\\) phases:\n\nDeduction (CTAD) - The first step is, the compiler is going to deduce the types that you didn’t write.\nInitialization - The second step is, it’s going to initialize the object.\n\nLet’s take a templated class pair, this is just a fictional class, it is not actually how std::pair&lt;&gt; looks like:\n\ntemplate&lt;typename T, typename U&gt;\nstruct pair{\n    T first;\n    U second;\n\n    pair(const T& _first, const U& _second) \n    : first(_first)\n    , second(_second)\n    {}\n\n    pair(T&& _first, U&& _second) \n    : first(std::move&lt;T&gt;(_first))\n    , second(std::move&lt;U&gt;(_second))\n    {}\n\n    //other stuff\n};\n\nThis is an oversimplification that is enough for our purposes. So, you have a templated class with two template parameters T and U and then you have a bunch of constructors. Now, we want to instantiate one of these things:\npair p1{\"OptionVolQuote\"s, 0.50};\nYou want to construct an object of type pair. The next thing the compiler sees is, pair is a template. And we didn’t specify any template arguments. Probably, you wanna do class template argument deduction.\nThe next thing happens. pair has a bunch of constructors. Probably, you wanna call one of those constructors. And this where step 1 kicks in, which is the actual Class Template Argument Deduction(CTAD).\nSo, how does the compiler figure out, what you actually want to instantiate? So, it’s going to look at those constructors. Let’s pretend for a minute, that those constructors are ordinary functions - just free-standing functions. Now, these functions use class template parameters. Let’s pretend for a moment, that those template parameters are template parameters for the function.\n\ntemplate&lt;typename T, typename U&gt;\nstruct pair{\n    T first;\n    U second;\n\n    // Imagine this to be a function template\n    template&lt;typename T, typename U&gt;  \n    pair(const T& _first, const T& _second) \n    : first(_first)\n    , second(_second)\n    {}\n\n    // Imagine this to be a function template\n    template&lt;typename T, typename U&gt;\n    pair(T&& _first, U&& _second) \n    : first(std::move&lt;T&gt;(_first))\n    , second(std::move&lt;U&gt;(_second))\n    {}\n\n    //other stuff\n};\n\nSo, this code doesn’t exist. It’s just what the compiler temporarily does for you. And it generates these template functions from the constructors and they are called the deduction candidates.\nAnd now, if we have a call like this:\n\npair p1{\"OptionVolQuote\"s, 0.50};\n\nwe know, how to deal with functions right. So, it’s going to look at these functions and apply the usual template arguments deduction and the usual overload resolution.\n\"OptionVolQuote\"s is a lvalue that gets converted to an xvalue (by the std::string() constructor) and 0.50 is a prvalue. these arguments bind to universal references. So, the pair(T&&, U&&) version is chosen by the compiler from the overload set, during overload resolution. Further, T is deduced as std::string and U is deduced as double. The compiler literally inserts them as:\n\npair&lt;std::string,double&gt; p1{\"OptionVolQuote\"s, 0.50};\n\nThen, its going to do, what it would have done, if you would have written pair&lt;std::string,double&gt;. So, now we know, that this pair is actually pair&lt;std::string,int&gt;. So, the step 1 is done.\nNow, what we can do is, we can actually instantiate the function template! That’s step 2. So, you have an actual constructor and it will be called by the run-time to create an object of pair&lt;std::string,int&gt;. And we are done.\nIf we write:\n\nconst auto s{\"5YSwapRate\"s};\nconst auto rate{0.0125};\npair p2{s,rate};\n\nHere, s and rate are identifiers, so these are glvalues and can bind to const T&. So, the compiler instantiates the first overload of the constructor as pair(const std::string&, const double&).\nThere’s no need to use std::make_pair anymore. This make_pair thing is a basically a work-around for the fact that up until C++14, you could only do this with functions. So, you had to use a function to deduce the class template arguments. So, it was kind of hacky. And now we don’t need to use that anymore.\nThe same goes for std::tuple, you can instantiate a std::tuple with a bunch of arguments and it’s going to deduce the correct types for you, so you don’t need to use std::make_tuple anymore.\n\nstd::tuple point{1.00, -1.00}\n\nLet’s look at std::vector. So, for example, if you just give it an std::initializer_list of ints, its gonna correctly deduce back to std::vector&lt;int&gt;.\n\nstd::vector v{3, 5, 7, 11, 13};\n// deduces std::vector&lt;int&gt;\n\nOf course, with std::vector, there’s a trap. std::vector has this other constructor which takes a std::size_t, and it initializes a vector with that many elements in it.\n\nstd::vector&lt;int&gt; v1{3};\n// content is {3}\n\nstd::vector&lt;int&gt; v2(3);\n// content is {0,0,0}\n\nSo, in C++14, if you write std::vector&lt;int&gt; v{3} with curly braces, it’s going to be an initializer list, so its going to initialize the vector with one int, which is 3. If you std::vector&lt;int&gt; v(3) with parenthesis, it’s going to call the size_t constructor, and you’re gonna have 3 ints, which are initialized to 0.0.\nNow, what happens if you omit the int and use class-template argument deduction? Then if you write the curlies, its going to do the deduction. But if you use round parenthesis, it says, well you’re calling the constructor that takes a size_t, so you are going to have 3 elements, but 3 elements of what type? You didn’t specify! So, you get a compiler error.\n\nstd::vector v1{3};\n// Ok- deduces std::vector&lt;int&gt;, content is {3}\n\n// std::vector v2(3);\n// Error : 3 elements of what?\n\nstd::vector has another constructor, which is really cool! Now, some real magic happens here! So, if you have a range of ints, any range, then there’s this constructor that takes a pair of iterators like begin() and end() and if you don’t specify the int, it is still going to figure out, that those iterators are iterators to int range and it is going correctly deduce std::vector&lt;int&gt; for you.\n\nstd::vector range{2, 3, 5, 7, 11};\nstd::vector v(range.begin(), range.end());\n// deduces std::vector&lt;int&gt;\n\nHow does that work? It has this constructor which looks like the below. It takes two iterators.\n\ntemplate&lt;typename T&gt;\nstruct vector\n{\n    // range c'tor\n    template&lt;typename Iter&gt;\n    vector&lt;Iter begin, Iter end&gt; { /* ... */ }\n\n    // other stuff\n};\n\nIf you have a constructor that also has template arguments, the compiler is going to pretend that this is a function and it’s going to take the template argument of the class and concatenate it with the constructor’s template argument. It’s going to put them one after the other.\n\n// This is magic code, generated by the compiler\ntemplate&lt;typename T&gt;\nstruct vector\n{\n    // range c'tor\n    template&lt;typename T, typename Iter&gt;\n    vector&lt;Iter begin, Iter end&gt; { /* ... */ }\n\n    // other stuff\n};\n\nNow, if you call it like this:\n\nstd::vector range{2, 3, 5, 7, 11};\nstd::vector v(range.begin(), range.end());\n\nit’s going to say, well okay, you are giving me two iterators, so I can deduce the type of iterators as std::vector&lt;&gt;::iterator. But, you didn’t specify T, so I still don’t know what T is. So, how is it able to figure this out?"
  },
  {
    "objectID": "posts/class-template-argument-deduction/index.html#list-initialization-has-priority",
    "href": "posts/class-template-argument-deduction/index.html#list-initialization-has-priority",
    "title": "Class Template Argument Deduction(CTAD)",
    "section": "List initialization has priority",
    "text": "List initialization has priority\nYou really have to be careful with the parenthesis and the curlies.\n\nstd::vector range{2, 3, 5, 7, 11};\nstd::vector v(range.begin(), range.end());\n// deduces std::vector&lt;int&gt;\n\nstd::vector v{range.begin(), range.end()};\n// list initialization has a priority, so the compiler deduces it\n// as std::vector&lt;std::vector&lt;int&gt;::iterator&gt;, which is \n// probably not what we want"
  },
  {
    "objectID": "posts/copy-and-swap-idiom/index.html",
    "href": "posts/copy-and-swap-idiom/index.html",
    "title": "Copy-and-swap idiom",
    "section": "",
    "text": "The canonical way to write the copy assignment operator is the following:\nstruct Point3D{\n    double x;\n    double y;\n    double z;\n\n    /* Rule of five */\n    Point3D() = default;\n    Point3D(const Point3D&) = default;\n    \n    Point3D& operator=(const Point3d& p){\n        if(this != &p){\n            // Copy member variables\n            x = p.x;\n            y = p.y;\n            z = p.z;\n        }\n\n        return (*this);\n    }\n\n    Point3D(Point3D&& ) = default;\n    Point3D& operator=(Point3D&& ) = default;\n};\nThe problem is, what if the member-wise copy assignment fails? If constructing any of the members x, y or z fails, the object we want to assign-to remains in an inconsistent state."
  },
  {
    "objectID": "posts/copy-and-swap-idiom/index.html#introduction.",
    "href": "posts/copy-and-swap-idiom/index.html#introduction.",
    "title": "Copy-and-swap idiom",
    "section": "",
    "text": "The canonical way to write the copy assignment operator is the following:\nstruct Point3D{\n    double x;\n    double y;\n    double z;\n\n    /* Rule of five */\n    Point3D() = default;\n    Point3D(const Point3D&) = default;\n    \n    Point3D& operator=(const Point3d& p){\n        if(this != &p){\n            // Copy member variables\n            x = p.x;\n            y = p.y;\n            z = p.z;\n        }\n\n        return (*this);\n    }\n\n    Point3D(Point3D&& ) = default;\n    Point3D& operator=(Point3D&& ) = default;\n};\nThe problem is, what if the member-wise copy assignment fails? If constructing any of the members x, y or z fails, the object we want to assign-to remains in an inconsistent state."
  },
  {
    "objectID": "posts/copy-and-swap-idiom/index.html#exception-safety-in-c",
    "href": "posts/copy-and-swap-idiom/index.html#exception-safety-in-c",
    "title": "Copy-and-swap idiom",
    "section": "Exception Safety in C++",
    "text": "Exception Safety in C++\nThe C++ standard library provides several levels of exception safety (in decreasing order of exception safety):\n\nNo-throw guarantee, also known as failure transparency: Operations are guaranteed to succeed and satisfy all requirements even in exceptional situations. If an exception occurs, it will be handled internally and not observed by clients.\nStrong exception safety, also known as commit or rollback semantics: Operations can fail, but failed operations are guaranteed to have no side effects, leaving the original values intact.\nBasic exception safety: Partial execution of failed operations can result in side-effects, but all invariants are preserved.\nNo exception safety: No guarantees are made."
  },
  {
    "objectID": "posts/copy-and-swap-idiom/index.html#achieving-strong-exception-safety",
    "href": "posts/copy-and-swap-idiom/index.html#achieving-strong-exception-safety",
    "title": "Copy-and-swap idiom",
    "section": "Achieving strong exception safety",
    "text": "Achieving strong exception safety\nOur copy-assignment operator provides basic exception safety at best. If we want strong-exception safety, the copy-and-swap idiom will help us achieve that.\nThe constructions might fail, but the destruction must not. Therefore, first, we should create a new object on its own and then swap it with old one. If the construction fails, the original object is not modified at all. We are on the safe-side. Then, we should switch the handles and we know that the destruction of the temporary object with the old data will not fail.\nWe need 3 things to implement the copy-and-swap idiom. We need\n\nA copy constructor.\nA swap function that swaps two objects member-by-member, without throwing an exception.\nA destructor.\n\nWe want the copy-assignment operator to look like this:\nPoint3D& Point3D::operator=(const Point3D& other){\n    Point3D temp{other};\n    swap(*this, temp);\n    return (*this);\n} // temp goes out of scope, its destructor is called\n  // any memory held by it is automatically released.\nThe swap function should swap, or in other words, exchange the content of two objects member by member. For that, we cannot use std::swap, because std::swap requires an implementation of a the copy-constructor and a copy-assignment operator. Instead, we write it by hand:\nfriend void swap(const Point3D& lhs, const Point3D& rhs){\n    using std::swap;\n    swap(lhs.x, rhs.x);\n    swap(lhs.y, rhs.y);\n    swap(lhs.z, rhs.z);\n}"
  },
  {
    "objectID": "posts/crtp/index.html",
    "href": "posts/crtp/index.html",
    "title": "CRTP(Curiously recurring template pattern)",
    "section": "",
    "text": "Introduction\nImagine you have an inheritance hierarchy to implement mathematical interpolation.\n#include &lt;concepts&gt;\n#include &lt;exception&gt;\n#include &lt;vector&gt;\n#include &lt;cmath&gt;\n#include &lt;string&gt;\n#include &lt;algorithm&gt;\n#include &lt;stdexcept&gt;\n#include &lt;iostream&gt;\n\ntemplate&lt;typename I1, typename I2&gt;\nclass LinearInterpolatorBase{\n    public:\n    std::vector&lt;double&gt; xValues(){\n        return std::vector&lt;double&gt;(m_xBegin, m_xEnd);\n    }\n    std::vector&lt;double&gt; yValues(){\n        return std::vector&lt;double&gt;(m_yBegin, m_yEnd);\n    }\n\n    void safetyCheck(){\n        if(!(static_cast&lt;int&gt;(m_xEnd - m_xBegin) &gt;= 2)){\n            std::string errorMessage = \"not enough points to interpolate : at least \";\n            errorMessage += m_requiredPoints + \" required, \";\n            throw std::logic_error(errorMessage);\n        }\n        \n        for(I1 i{m_xBegin}, j{m_xBegin + 1}; j!=m_xEnd; ++i, ++j){\n            if(*i &gt; *j){\n                throw std::logic_error(\"unsorted x values\");\n            }\n        }\n    }\n    \n    int locate(double x){\n        safetyCheck();\n        return std::distance(m_xBegin, std::upper_bound(m_xBegin, m_xEnd, x));\n    }\n\n    virtual double value(double) = 0;\n    \n    void determineBracket(double& x1, double& x2, double &y1, double& y2, double x){\n        int N = static_cast&lt;int&gt;(this-&gt;m_xEnd - this-&gt;m_xBegin);\n        int j = this-&gt;locate(x);\n\n        if(j == 0)\n        {\n            x1 = *(this-&gt;m_xBegin);\n            y1 = *(this-&gt;m_yBegin);\n            x2 = *(this-&gt;m_xBegin + 1);\n            y2 = *(this-&gt;m_yBegin + 1);\n        }else if(j == N){\n            x1 = *(this-&gt;m_xEnd - 2);\n            y1 = *(this-&gt;m_yEnd - 2);\n            x2 = *(this-&gt;m_xEnd - 1);\n            y2 = *(this-&gt;m_yEnd - 1);\n        }else{\n            x1 = *(this-&gt;m_xBegin + j - 1);\n            y1 = *(this-&gt;m_yBegin + j - 1);\n            x2 = *(this-&gt;m_xBegin + j);\n            y2 = *(this-&gt;m_yBegin + j);\n        }\n    }\n    \n    LinearInterpolatorBase(I1 xBegin, I1 xEnd, I2 yBegin, I2 yEnd)\n    : m_xBegin(xBegin)\n    , m_xEnd(xEnd)\n    , m_yBegin(yBegin)\n    , m_yEnd(yEnd)\n    {}\n    \n    protected:\n    I1 m_xBegin;\n    I1 m_xEnd;\n    I2 m_yBegin;\n    I2 m_yEnd;\n    const int m_requiredPoints {2};\n};\n\ntemplate&lt;typename I1, typename I2&gt;\nclass LinearInterpolator : public LinearInterpolatorBase&lt;I1, I2&gt;{\npublic:\n    double value(double x) override{\n        double x1{0.0}, x2{0.0}, y1{0.0}, y2{0.0}, y{0.0};\n        this-&gt;determineBracket(x1, x2, y1, y2, x);\n        \n        double t {(x - x1)/(x2 - x1)};\n        \n        return (1 - t) * y1 + t * y2;\n    }\n\n    LinearInterpolator(I1 xBegin, I1 xEnd, I2 yBegin, I2 yEnd)\n    : LinearInterpolatorBase&lt;I1,I2&gt;(xBegin, xEnd, yBegin, yEnd) {}\n};\n\ntemplate&lt;typename I1, typename I2&gt;\nclass LogLinearInterpolator : public LinearInterpolatorBase&lt;I1, I2&gt;{\npublic:\n    double value(double x) override{\n        double x1{0.0}, x2{0.0}, y1{0.0}, y2{0.0}, y{0.0};\n        this-&gt;determineBracket(x1, x2, y1, y2, x);\n        \n        double t {(x - x1)/(x2 - x1)};\n        \n        return exp((1 - t) * log(y1) + t * log(y2));\n    }\n    \n    LogLinearInterpolator(I1 xBegin, I1 xEnd, I2 yBegin, I2 yEnd)\n    : LinearInterpolatorBase&lt;I1,I2&gt;(xBegin, xEnd, yBegin, yEnd) {}\n};\n\n\n\nint main(int argc, const char * argv[]) {\n    std::vector&lt;double&gt; discountFactors{\n        1, 0.9523, 0.9070, 0.8683, 0.8227,0.7835,\n        0.7462, 0.7106, 0.6768, 0.6446, 0.6139\n    };\n    \n    std::vector&lt;double&gt; times{\n        0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10\n    };\n    \n    double result{0.0};\n\n    using I = std::vector&lt;double&gt;::iterator;\n\n    LinearInterpolatorBase&lt;I,I&gt;* p;\n    \n    LinearInterpolator linearInterp(\n        times.begin(),\n        times.end(),\n        discountFactors.begin(),\n        discountFactors.end()\n    );\n\n    p = &linearInterp;\n\n    result = p-&gt;value(2.5);\n    std::cout &lt;&lt; \"\\nResult of linear interpolation y-value = \" &lt;&lt; result;\n\n    LogLinearInterpolator logLinearInterp(\n        times.begin(),\n        times.end(),\n        discountFactors.begin(),\n        discountFactors.end()\n    );\n\n    p = &logLinearInterp;\n    result = p-&gt;value(2.5);\n    std::cout &lt;&lt; \"\\nResult of log-linear interpolation y-value = \" &lt;&lt; result;\n    return 0;\n}\nCompiler Explorer\nThe base class LinearInterpolationBase has a pure virtual function value and the child classes LinearInterpolation and LogLinearInterpolation will override this virtual function doing different things. This is called dynamic polymorphism.\nThe implementation of double value(double) chosen at run-time is determined by the object bound to the base class pointer/reference.\nYou can also overload free-standing functions or class member functions, provided they have different type/number of arguments. For example, you can over the + operator to support addition of two std::vectors component-wise. And this is the compile-time version of polymorphism, called static polymorphism.\nDynamic polymorphism incurs a performance cost because in order to know what functions to call, the compiler needs to build a table of pointers to virtual functions. So, there is some level of indirection when calling virtual functions polymorphically.\nCan we get the benefits of dynamic polymorphism at compile time? One way to achieve that is the Curiously Recurring Template Patter(CRTP).\n\n\nThe Curiously Recurring Template Pattern\nWhile diving into the internals of some libraries, James Coplien observed a commonly recurring pattern, and for the lack of a better word, wrote a paper titled the Curiously Recurring Template Pattern(CRTP). The name stuck.\nIn practice, a minimalistic example of this idiom is as follows:\n#include &lt;iostream&gt;\n#include &lt;memory&gt;\n#include &lt;vector&gt;\n\ntemplate&lt;typename Derived&gt;\nstruct B{\n    void do_work(){\n        static_cast&lt;Derived*&gt;(this)-&gt;work();\n    }\n};\n\nstruct X : public B&lt;X&gt;{\n    void work(){\n        std::cout &lt;&lt; \"\\nimpl of X::work\";\n    }\n};\n\nstruct Y : public B&lt;Y&gt;{\n    void work(){\n        std::cout &lt;&lt; \"\\nimpl of Y::work\";\n    }\n};\n\ntemplate&lt;typename T&gt;\nvoid perform_work(T* obj){\n    obj-&gt;do_work();\n}\n\nint main(){\n    X x;\n    Y y;\n    perform_work(&x);\n    perform_work(&y);\n    return 0;\n}\nThe do_work method in the base class performs an upcast of the this pointer to the derived class pointer T*.\nCompiler Explorer\nWe have move the runtime polymorphism to compile-time. Therefore, the perform_work function cannot treat X and Y objects polymorphically. Instead, we get two different overloads, one that can handle X objects and one that can handle Y objeccts. This is static polymorphism.\nWe could do this for our numerical routines as well:\n#include &lt;concepts&gt;\n#include &lt;exception&gt;\n#include &lt;vector&gt;\n#include &lt;cmath&gt;\n#include &lt;string&gt;\n#include &lt;algorithm&gt;\n#include &lt;stdexcept&gt;\n#include &lt;iostream&gt;\n#include &lt;memory&gt;\n\ntemplate&lt;typename I1, typename I2, typename Derived&gt;\nclass LinearInterpolatorBase{\n    /* \n        ...\n    */\n\n    double computeValue(double x){\n        return static_cast&lt;Derived*&gt;(this)-&gt;value(x);\n    }\n    \n    /*\n        ...\n    */\n};\n\ntemplate&lt;typename I1, typename I2&gt;\nclass LinearInterpolator : public LinearInterpolatorBase&lt;I1, I2, LinearInterpolator&lt;I1,I2&gt;&gt;{\npublic:\n    double value(double x){\n        /*\n            ...\n        */\n    }\n\n    LinearInterpolator(I1 xBegin, I1 xEnd, I2 yBegin, I2 yEnd)\n    : LinearInterpolatorBase&lt;I1,I2,LinearInterpolator&gt;(xBegin, xEnd, yBegin, yEnd) {}\n};\n\ntemplate&lt;typename I1, typename I2&gt;\nclass LogLinearInterpolator : public LinearInterpolatorBase&lt;I1, I2, LogLinearInterpolator&lt;I1,I2&gt;&gt;{\npublic:\n    double value(double x){\n        /*\n            ...\n        */\n    }\n    \n    LogLinearInterpolator(I1 xBegin, I1 xEnd, I2 yBegin, I2 yEnd)\n    : LinearInterpolatorBase&lt;I1,I2,LogLinearInterpolator&gt;(xBegin, xEnd, yBegin, yEnd) {}\n};\n\ntemplate&lt;typename I1, typename I2, typename T&gt;\ndouble computeValueHelper(LinearInterpolatorBase&lt;I1,I2,T&gt;* interpolator, double x){\n    return interpolator-&gt;computeValue(x);\n}\n\nint main(int argc, const char * argv[]) {\n    std::vector&lt;double&gt; discountFactors{\n        1, 0.9523, 0.9070, 0.8683, 0.8227,0.7835,\n        0.7462, 0.7106, 0.6768, 0.6446, 0.6139\n    };\n    \n    std::vector&lt;double&gt; times{\n        0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10\n    };\n    \n    double result{0.0};\n\n\n    LinearInterpolator linearInterp(\n        times.begin(),\n        times.end(),\n        discountFactors.begin(),\n        discountFactors.end()\n    );\n\n    result = computeValueHelper(&linearInterp, 2.5);\n    std::cout &lt;&lt; \"\\nResult of linear interpolation y-value = \" &lt;&lt; result;\n\n    LogLinearInterpolator logLinearInterp(\n        times.begin(),\n        times.end(),\n        discountFactors.begin(),\n        discountFactors.end()\n    );\n\n    result = computeValueHelper(&logLinearInterp, 2.5);\n\n    std::cout &lt;&lt; \"\\nResult of log-linear interpolation y-value = \" &lt;&lt; result;\n    return 0;\n}\nCompiler Explorer\n\n\nCRTP in QuantLib\nIt’s always interesting to learn design patterns not in some theoretical project or a textbook or something, but actually find them working in a real-life library and QuantLib is certainly a big enough and an interesting enough library to give us a few examples of design patterns for our pleasure.\nnamespace QuantLib {\n \n    //! Support for the curiously recurring template pattern\n    /*! See James O. Coplien. A Curiously Recurring Template Pattern.\n        In Stanley B. Lippman, editor, C++ Gems, 135-144.\n        Cambridge University Press, New York, New York, 1996.\n \n        \\ingroup patterns\n    */\n    template &lt;class Impl&gt;\n    class CuriouslyRecurringTemplate {\n      protected:\n        // not meant to be instantiated as such\n        CuriouslyRecurringTemplate() = default;\n        ~CuriouslyRecurringTemplate() = default;\n        // support for the curiously recurring template pattern\n        Impl& impl() {\n            return static_cast&lt;Impl&&gt;(*this);\n        }\n        const Impl& impl() const {\n            return static_cast&lt;const Impl&&gt;(*this);\n        }\n    };\n \n}\n#endif\nEssentially, all that this pattern does is, it takes the template argument Impl and then it performs a cast of the current object *this to whatever type is implemented.\nThe impl() methods are actually protected, so they are not meant to be used within client code, but are internal to the framework.\nLet’s look at the derived classes Solver1D and Bisection.\nSolver1D is a general-purpose one-dimension numerical solver and the class header has the signature:\ntemplate&lt;typename Impl&gt;\nclass Solver1D : CuriouslyRecurringTemplate&lt;Impl&gt;\n{\n    public:\n    template &lt;class F&gt;\n        Real solve(const F& f,\n                   Real accuracy,\n                   Real guess,\n                   Real xMin,\n                   Real xMax) const {\n \n            /*\n                ...\n            */\n \n            root_ = guess;\n \n            return this-&gt;impl().solveImpl(f, accuracy);\n        }\n};\nThe class header for Bisection is typically saying that I am a one-dimensional solver Solver1D and I am going to feed by own type Bisection as a template argument to Solver1D&lt;Impl&gt;.\nnamespace QuantLib {\n \n    //! %Bisection 1-D solver\n    class Bisection : public Solver1D&lt;Bisection&gt; {\n      public:\n        template &lt;class F&gt;\n        Real solveImpl(const F& f,\n                       Real xAccuracy) const {\n \n            /* \n                ...\n            */\n        }\n    };\n}\nThis results in the compiler instantiating the class templates and defining CuriousRecurringTemplate&lt;Bisection&gt; and Solver1D&lt;Bisection&gt; classes.\nSo, if you go back to Solver1D, it doesn’t know the actual implementation. It says, whatever the implementation(Impl template parameter) is, I want to call solveImpl() on it.\n\n\nLimiting the object count with CRTP\nOne scenario in which the CRTP idiom could be applied is to limit the object count. We code up a limit_instances class template and have our user-declared classes specialize from it. The limit_instances class has a class(static) member variable called count that keeps track of the number instances of the user-objects. Each time the user-object constructor(and thus limit_instances base class constructor) is invoked, we are to increment count and every destructor call decrements the count.\n#include &lt;iostream&gt;\n#include &lt;exception&gt;\n#include &lt;atomic&gt;\n\ntemplate&lt;typename T, int N&gt;\nstruct limit_instances{\n    static int count;\n\n    limit_instances(){\n        if(count &gt;= N)\n            throw std::logic_error(\"Too many instances.\");\n        ++count;\n    }\n\n    ~limit_instances(){\n        --count;\n    }\n};\n\ntemplate&lt;typename T, int N&gt;\nint limit_instances&lt;T,N&gt;::count = 0;\n\nstruct X : public limit_instances&lt;X,3&gt;{\n    /*\n        User-defined private member fields\n        and public methods.\n    */\n};\n\nstruct Y : public limit_instances&lt;Y,5&gt;{\n    /*\n        ...\n    */\n};\n\nint main()\n{\n    X x1,x2,x3;   // okay\n    try{\n        X x4;         \n    }\n    catch(std::exception& e){\n        std::cout &lt;&lt; e.what() &lt;&lt; \"\\n\";\n    }\n    \n    Y y[5];       // okay\n     try{\n        Y anotherInstance;         \n    }\n    catch(std::exception& e){\n        std::cout &lt;&lt; e.what() &lt;&lt; \"\\n\";\n    } \n    return 0;\n}\nCompiler Explorer\nThe class template limit_instances takes the user-class T and the maximum number of allowable instances N as template parameters. So, the user-class when inheriting from limit_instances and while invoking the base-class constructor should supply appropriate template arguments.\n\n\nImplementing the Composite design pattern\nThe composite design pattern lets you compose objects into tree structures.\nCRTP can be used to implement the composite design pattern. We can quickly code it up:\n#include &lt;vector&gt;\n#include &lt;iostream&gt;\n#include &lt;string&gt;\n\ntemplate&lt;typename T&gt;\nstruct Component{\n    template&lt;typename U&gt;\n    void connect(U& other);\n\n    std::string name;\n    Component(){}\n    Component(std::string name_) : name(name_) {}\n\n};\n\nstruct Node : Component&lt;Node&gt;{\n    Node* begin(){\n        return this;\n    }    \n\n    Node* end(){\n        return (this + 1);\n    }\n\n    Node(std::string name_) : Component&lt;Node&gt;(name_) {}\n    std::vector&lt;Node*&gt; connections;\n};\n\nstruct Composite : std::vector&lt;Node&gt;, Component&lt;Composite&gt;{\n    Composite() : Component&lt;Composite&gt;(){}\n    Composite(std::string name_) : Component&lt;Composite&gt;(name_){}\n};\n\ntemplate&lt;typename T&gt;\ntemplate&lt;typename U&gt;\nvoid Component&lt;T&gt;::connect(U& other){\n    for(Node& from : *static_cast&lt;T*&gt;(this)){\n        for(Node& to : other){\n            from.connections.push_back(&to);\n            to.connections.push_back(&from);\n        }\n    }\n}\n\nint main(){\n    \n    Node a(\"Gregory Peck\");\n    \n    Node b(\"Marlon Brando\");\n    Node c(\"Audrey Hepburn\");\n    Node d(\"Charles Chaplin\");\n\n    Node guitarist(\"Jimmy Hendrix\");\n    Node artistParExcellence(\"Elvis Presley\");\n    \n    Composite actorsTroupe;\n    actorsTroupe.push_back(a);\n    actorsTroupe.push_back(b);\n    actorsTroupe.push_back(c);\n    actorsTroupe.push_back(d);\n\n    guitarist.connect(actorsTroupe);\n    actorsTroupe.connect(artistParExcellence);\n    \n    return 0;\n}\nThis helps avoid the explosion of state-space and writing methods such as Node::connect(Node&), Node::connect(Composite&), Composite::connect(Node&) and Node::connect(Node&)."
  },
  {
    "objectID": "posts/derivation-for-the-least-squares-estimate-of-beta-/index.html",
    "href": "posts/derivation-for-the-least-squares-estimate-of-beta-/index.html",
    "title": "Derivation of the Least Squares Estimate Beta in Linear Regression",
    "section": "",
    "text": "The following post is going to derive the least squares estimate of the coefficients of linear regression. Our data consists of \\(p\\) predictors or features \\(X_1,\\ldots,X_p\\) and a response \\(Y\\), and there are \\(n\\) observations in our dataset. Assume that the data arises from the real world model:\n\\[\\begin{align}\n\\begin{bmatrix}\ny_1 \\\\\ny_2 \\\\\n\\ldots \\\\\ny_n\n\\end{bmatrix} =\n\\begin{bmatrix}\nx_{11} & x_{12} & \\ldots & x_{1p} \\\\\nx_{21} & x_{22} & \\ldots & x_{2p} \\\\\n\\vdots \\\\\nx_{n1} & x_{n2} & \\ldots & x_{np}\n\\end{bmatrix}\n\\begin{bmatrix}\n\\beta_1 \\\\\n\\beta_2 \\\\\n\\vdots \\\\\n\\beta_p\n\\end{bmatrix} +\n\\begin{bmatrix}\n\\epsilon_1 \\\\\n\\epsilon_2 \\\\\n\\ldots \\\\\n\\epsilon_n\n\\end{bmatrix} \\tag{1}\n\\end{align}\\]\nor in matrix notation,\n\\[Y = X \\beta + \\epsilon \\tag{2}\\]\n\n\nThe real world model in equation (1) is called the population regression line.\nIn statistics, we quite often do not know the population mean \\(\\mu\\), but we try to estimate it using the sample mean \\(\\hat{\\mu}\\).\nIn a similar vein, we do not know the true values of the regression coefficients \\(\\beta_1,\\beta_2,\\ldots,\\beta_p\\). Instead, we estimate them from the data as \\(\\hat{\\beta_1},\\hat{\\beta_2},\\ldots,\\hat{\\beta_p}\\).\nSo, our linear regression model would predict an outcome:\n\\[\\hat{Y} = \\hat{\\beta_1}X_1 + \\hat{\\beta_2} X_2 + \\ldots +\\hat{\\beta_p} X_p \\tag{3}\\]"
  },
  {
    "objectID": "posts/derivation-for-the-least-squares-estimate-of-beta-/index.html#introduction",
    "href": "posts/derivation-for-the-least-squares-estimate-of-beta-/index.html#introduction",
    "title": "Derivation of the Least Squares Estimate Beta in Linear Regression",
    "section": "",
    "text": "The following post is going to derive the least squares estimate of the coefficients of linear regression. Our data consists of \\(p\\) predictors or features \\(X_1,\\ldots,X_p\\) and a response \\(Y\\), and there are \\(n\\) observations in our dataset. Assume that the data arises from the real world model:\n\\[\\begin{align}\n\\begin{bmatrix}\ny_1 \\\\\ny_2 \\\\\n\\ldots \\\\\ny_n\n\\end{bmatrix} =\n\\begin{bmatrix}\nx_{11} & x_{12} & \\ldots & x_{1p} \\\\\nx_{21} & x_{22} & \\ldots & x_{2p} \\\\\n\\vdots \\\\\nx_{n1} & x_{n2} & \\ldots & x_{np}\n\\end{bmatrix}\n\\begin{bmatrix}\n\\beta_1 \\\\\n\\beta_2 \\\\\n\\vdots \\\\\n\\beta_p\n\\end{bmatrix} +\n\\begin{bmatrix}\n\\epsilon_1 \\\\\n\\epsilon_2 \\\\\n\\ldots \\\\\n\\epsilon_n\n\\end{bmatrix} \\tag{1}\n\\end{align}\\]\nor in matrix notation,\n\\[Y = X \\beta + \\epsilon \\tag{2}\\]\n\n\nThe real world model in equation (1) is called the population regression line.\nIn statistics, we quite often do not know the population mean \\(\\mu\\), but we try to estimate it using the sample mean \\(\\hat{\\mu}\\).\nIn a similar vein, we do not know the true values of the regression coefficients \\(\\beta_1,\\beta_2,\\ldots,\\beta_p\\). Instead, we estimate them from the data as \\(\\hat{\\beta_1},\\hat{\\beta_2},\\ldots,\\hat{\\beta_p}\\).\nSo, our linear regression model would predict an outcome:\n\\[\\hat{Y} = \\hat{\\beta_1}X_1 + \\hat{\\beta_2} X_2 + \\ldots +\\hat{\\beta_p} X_p \\tag{3}\\]"
  },
  {
    "objectID": "posts/derivation-for-the-least-squares-estimate-of-beta-/index.html#residual-sum-of-squares",
    "href": "posts/derivation-for-the-least-squares-estimate-of-beta-/index.html#residual-sum-of-squares",
    "title": "Derivation of the Least Squares Estimate Beta in Linear Regression",
    "section": "Residual sum of squares",
    "text": "Residual sum of squares\nThe difference between the observed response value and the predicted response value is called as the residual.\nWe define the residual sum of squares as:\n\\[\\begin{align*}\n(Y - X\\hat{\\beta})'(Y - X\\hat{\\beta})&= (Y' - \\hat{\\beta}' X')(Y - X\\hat{\\beta})\\\\\n&= Y'Y - Y'X \\hat{\\beta} - \\hat{\\beta}' X' Y + \\hat{\\beta}'X'X\\hat{\\beta}\n\\end{align*}\\]\nThe \\(j\\)-th column of \\(Y'X\\) is \\(\\sum_{i=1}^{n}y_i x_{ij}\\) and therefore the product \\(Y'X\\hat{\\beta}\\) equals \\(\\sum_{j=1}^{p}\\sum_{i=1}^{n}y_i x_{ij}\\hat{\\beta_j}\\). But, \\((x_{ij}) = (x_{ji})^T\\). The same sum can be re-written \\(\\sum_{i=1}^{n}\\sum_{j=1}^{p}\\hat{\\beta_j} x_{ji}^T y_i\\). Thus, \\(\\hat{\\beta}' X' Y = Y' X \\hat{\\beta}\\).\nConsequently,\n\\[\\begin{align*}\n(Y - X\\hat{\\beta})'(Y - X\\hat{\\beta})&= Y'Y - 2Y'X \\hat{\\beta} + \\hat{\\beta}'X'X\\hat{\\beta} \\tag{4}\n\\end{align*}\\]"
  },
  {
    "objectID": "posts/derivation-for-the-least-squares-estimate-of-beta-/index.html#aside-proof-i",
    "href": "posts/derivation-for-the-least-squares-estimate-of-beta-/index.html#aside-proof-i",
    "title": "Derivation of the Least Squares Estimate Beta in Linear Regression",
    "section": "Aside proof I",
    "text": "Aside proof I\nClaim. Let \\(A \\in \\mathbf{R}^{m \\times n}\\) be a rectangular matrix and \\(\\vec{x}\\) be a vector of \\(n\\) elements and let \\(\\vec{y}\\) be the matrix-vector product:\n\\[\\vec{y} = A \\vec{x}\\]\nThen,\n\\[\\frac{\\partial \\vec{y}}{\\partial \\vec{x}} = A\\]\nProof.\nLet \\(A_1,\\ldots,A_n\\) be the columns of \\(A\\). Then,\n\\[\\begin{align*}\n\\vec{y} &= [A_1, A_2, \\ldots, A_n] \\begin{bmatrix}\nx_1 \\\\\nx_2 \\\\\n\\vdots \\\\\nx_n\n\\end{bmatrix} \\\\\n&= A_1 x_1 + A_2 x_2 + \\ldots + A_n x_n\n\\end{align*}\\]\nThus,\n\\[\\frac{\\partial \\vec{y}}{\\partial x_i} = A_i\\]\nConsequently,\n\\[\\frac{\\partial \\vec{y}}{\\partial \\vec{x}} = A\\]"
  },
  {
    "objectID": "posts/derivation-for-the-least-squares-estimate-of-beta-/index.html#aside-proof-ii",
    "href": "posts/derivation-for-the-least-squares-estimate-of-beta-/index.html#aside-proof-ii",
    "title": "Derivation of the Least Squares Estimate Beta in Linear Regression",
    "section": "Aside proof II",
    "text": "Aside proof II\nClaim. Consider the quadratic form \\(Q(\\vec{x}) = \\vec{x}^T A^T A \\vec{x}\\). Then, we have:\n\\[\\frac{\\partial Q}{\\partial \\vec{x}} = 2A^T A\\vec{x}\\]\nProof.\nThe matrix \\(K = A^T A\\) is symmetric, since \\((A^T A)^T = A^T (A^T)^T = A^T A\\). So, \\(Q = \\vec{x}^T K \\vec{x}\\). Now, let \\(A = (A_1, A_2, \\ldots, A_n)\\) in the block form, \\(A_j\\) denotes the \\(j\\)-th column of \\(A\\). Thus, \\(A \\vec{x} =\\sum_j A_j x_j\\). and \\(\\vec{x}^T A^T = \\sum_j A_j x_j\\) as well. So, \\(Q = \\left(\\sum_j A_j x_j\\right)^2\\). Consequently,\n\\[\\begin{align}\n\\frac{\\partial Q}{\\partial x_j} &= 2 A_j \\left(\\sum_{j} A_j x_j\\right)\n\\end{align}\\]\nThus,\n\\[\\begin{align}\n\\frac{\\partial Q}{\\partial \\vec{x}} &= 2 \\begin{bmatrix}A_1 \\\\ A_2 \\\\ \\vdots \\\\\nA_n\\end{bmatrix} \\left(\\sum_{j} A_j x_j\\right) \\\\\n&= 2 A^T A \\vec{x}\n\\end{align}\\]"
  },
  {
    "objectID": "posts/derivation-for-the-least-squares-estimate-of-beta-/index.html#least-squares-estimate",
    "href": "posts/derivation-for-the-least-squares-estimate-of-beta-/index.html#least-squares-estimate",
    "title": "Derivation of the Least Squares Estimate Beta in Linear Regression",
    "section": "Least squares estimate",
    "text": "Least squares estimate\nWe proceed with minimizing the RSS expression in equation (4). Taking derivatives with respect to the vector \\(\\hat{\\beta}\\) on both sides, and equating to zero, we have:\n\\[\\begin{align*}\n\\frac{\\partial (RSS)}{\\hat{\\beta}}&= - 2Y'X + 2X'X\\hat{\\beta} = 0 \\\\\nX^T X \\hat{\\beta} &= Y^T X \\\\\n\\hat{\\beta} &= (X^T X)^{-1} Y^T X\n\\end{align*}\\]"
  },
  {
    "objectID": "posts/diy-asyncio/index.html",
    "href": "posts/diy-asyncio/index.html",
    "title": "DIY asyncio",
    "section": "",
    "text": "In single-core processors, the machine can only perform one task at a time, but can switch between many tasks many times per second. By doing a bit of one task and then a bit of another and so on, it appears that the tasks are happening concureently. This is called task switching. Because the task switches are so fast, it provides an illusion of concurrency to both the user and the applications.\nOn a single-core maching doing task switching, chunks from each task are interleaved. But, they are also spaced out a bit; in order to do the interleaving, the operating system has to perform a context switch every time it changes from one task to another, and this takes time. In order to perform a context switch, the OS has to save the CPU state and the instruction pointer for the currently running task, work out which task to switch to, and reload the CPU state for the task being switched to.\nMulti-core processors are genuinely capable of running more than one task in parallel. This is called hardware concurrency.\n\n\nThe rate of doing work (operations per second) is called throughput. The response time it takes for a system to process a request is called latency.\n\n\n\nSynchronous execution is sequential.\n\ndef foo():\n    print(f\"Inside foo.\")\n\ndef main():\n    print(f\"Starting work.\")\n    foo()\n    print(f\"Finishing work.\")\n\nmain()\n\nStarting work.\nInside foo.\nFinishing work.\n\n\nIn the main() code-path, the call to foo() is a blocking call, the execution jumps to foo() and main() resumes when foo() returns.\nAsynchronous(or async) execution refers to execution that doesn't block when invoking subroutines. It is a fire-and-forget technique. Any work package runs separately from the main application thread and notifies the calling thread of its completion, failure or progress.\nUsually, such methods return an entity called future or promise that is the representation of an in-progress computation. The calling thread can query for the status of the computation via the returned future or promise and retrieve the result once completed.\nAnother pattern is to pass a callback function to the asynchronous functional call, which is invoked with the results when the asynchronous function is done processing.\nAsynchronous programming is an execllent choice for applications that do extensive network or disk I/O and spend most of their time waiting.\n\n\n\n\n\nPrograms that are compute-intensive are called CPU bound programs. This could involve numerical optimizations, Monte-Carlo simulations, data-crunching etc.\n\n\n\nI/O bound programs spend most of their time doing network or main memory and file I/O operations. Since the CPU and main memory are separate, a bus exists between the two to transfer bits. Similarly, data needs to moved from the NIC to CPU/memory. Even though these physical distances are small, the time taken to transfer the data can waste a few thousand CPU cycles. This is why I/O bound programs show relatively lower CPU utilization than CPU bound programs.\n\n\n\n\nThe most common cause of bugs in concurrent code is a race-condition.\n\nimport concurrent.futures\nimport logging\nimport time\nimport concurrent\nimport threading\n\nclass Account:\n    def __init__(self):\n        self.value = 0\n\n    @property\n    def value(self):\n        return self._value\n    \n    @value.setter\n    def value(self, x):\n        self._value = x\n    \n    def credit(self, name : str, amount : float):\n        logging.info(\"Thread %s: starting update\", name)\n        \n        # ----- Critical section -----\n        local_copy = self.value     \n        local_copy += amount\n        time.sleep(0.1)\n        self.value = local_copy\n        # ----- End of critical section -----\n\n        logging.info(\"Thread %s: finishing update\", name)\n\nif __name__ == \"__main__\":\n    format = \"%(asctime)s: %(message)s\"\n    logging.basicConfig(format=format, level=logging.INFO, datefmt=\"%H:%M:%S\")\n    account = Account()\n    logging.info(\"Testing update. Starting value is %d.\", account.value)\n\n    with concurrent.futures.ThreadPoolExecutor(max_workers=2) as executor:\n        for index in range(2):\n            executor.submit(account.credit, index, 100)\n\n    logging.info(\"Testing update. Ending value is %d\", account.value)\n\n11:49:59: Testing update. Starting value is 0.\n11:49:59: Thread 0: starting update\n11:49:59: Thread 1: starting update\n11:49:59: Thread 1: finishing update\n11:49:59: Thread 0: finishing update\n11:49:59: Testing update. Ending value is 100\n\n\nThe above logic can be made thread-safe by fencing off the critical section using a mutex and enforcing that only a single thread can enter at a time.\n\n\n\nImagine that you have a toy that comes in two parts, and you need both parts to play with it - a toy drum and a drumstick, for example. Now, imagine that you ave two small children, both of whom like playing with it. If one of them gets both the drum and the drumstick, that child can merrily play the drum until titing of it. If the other child wants to play, they have wait, however sad that makes them. Now, imagine one child has the drum and other has the drumstick. They’re stuck, unless one decides to be nice and let the other play, each will hold on to whatver they have and demand that they be given the other piece, so neither gets to play. This is a deadlock.\nImagine two threads arguing over locks on mutexes: each of a pair of threads needs to lock both of a pair of mutexes to perform some operation, and each thread has one mutex and is waiting for the other. Neither thread can proceed, because each is waiting for the other to release its mutex. This scenario is called deadlock.\n\nimport threading\nimport concurrent\nimport time\n\nif __name__ == \"__main__\":\n    drum = threading.Lock()\n    drumstick = threading.Lock()\n\n    def child1_plays_drums():\n        print(f\"\\nChild-1 waiting for drums\")\n        drum.acquire()\n        print(f\"\\nChild-1 acquired drums\")\n        print(f\"\\nChild-1 waiting for drumstick\")\n        drumstick.acquire()\n        print(f\"\\nChild-1 is playing drums\")\n\n    def child2_plays_drums():\n        print(f\"\\nChild-2 waiting for drumstick\")\n        drumstick.acquire()\n        print(f\"\\nChild-2 acquired drumstick\")\n        print(f\"\\nChild-2 waiting for drums\")\n        drum.acquire()\n        print(f\"\\nChild-2 acquired drums\")\n        print(f\"\\nChild-2 is playing drums\")\n\n    t1 = threading.Thread(target=child1_plays_drums)\n    t2 = threading.Thread(target=child2_plays_drums)\n    \n    t1.start()\n    t2.start()\n\n    time.sleep(1)\n\n\nChild-1 waiting for drums\n\nChild-1 acquired drums\n\nChild-1 waiting for drumstick\n\nChild-1 is playing drums\n\nChild-2 waiting for drumstick\n\n\n\n\n\nA mutex is an programming construct that allows only a single thread to access a shared resource or critical section. Once a thread acquires a mutex, all other threads attempting to acquire the same mutex are blocked until the thread releases the mutex.\nA semaphore on the hand is used to limit access to a collection of resources. Think of semaphore as having a limited number of permits to give out. If a semaphore has given out all the permits it has, then any new thread that comes along requesting a permit will be blocked till an earlier thread with a permit returns it to the semaphore. A protoypical example is a ConnectionPool that hands out database connects to requesting threads.\nA semaphore with a single permit is called a binary semaphore. Semaphores can also be used for signaling among threads. This is an important distinction as it allows threads to cooperatively work towards completing a task. A mutex on the other hand, is strictly limted to serializing access to shared data among competing threads.\n\n\nA semaphore can potentially act as a mutex if the number of permits it can give is at most \\(1\\). However, the most important difference is that, the thread that calls acquire() on a mutex must subsequently release() the mutex. A mutex is owned by the thread acquiring it, upto the point the owning thread releases it. Whilst, in the case of a binary semaphore, different threads can call acquire() and release() on the semaphore.\n\n\n\n\nAnother distinction between a semaphore and a mutex is that semaphores can be used for signaling amongst threads. For example, in case of the classical producer-consumer problem, the producer thread can signal the consumer thread by incrementing the semaphore count to indicate to the consumer thread to read items from the queue. Threads can coordinate tasks using semaphores. A mutex, in contrast, only guards access to shared data."
  },
  {
    "objectID": "posts/diy-asyncio/index.html#basics",
    "href": "posts/diy-asyncio/index.html#basics",
    "title": "DIY asyncio",
    "section": "",
    "text": "In single-core processors, the machine can only perform one task at a time, but can switch between many tasks many times per second. By doing a bit of one task and then a bit of another and so on, it appears that the tasks are happening concureently. This is called task switching. Because the task switches are so fast, it provides an illusion of concurrency to both the user and the applications.\nOn a single-core maching doing task switching, chunks from each task are interleaved. But, they are also spaced out a bit; in order to do the interleaving, the operating system has to perform a context switch every time it changes from one task to another, and this takes time. In order to perform a context switch, the OS has to save the CPU state and the instruction pointer for the currently running task, work out which task to switch to, and reload the CPU state for the task being switched to.\nMulti-core processors are genuinely capable of running more than one task in parallel. This is called hardware concurrency.\n\n\nThe rate of doing work (operations per second) is called throughput. The response time it takes for a system to process a request is called latency.\n\n\n\nSynchronous execution is sequential.\n\ndef foo():\n    print(f\"Inside foo.\")\n\ndef main():\n    print(f\"Starting work.\")\n    foo()\n    print(f\"Finishing work.\")\n\nmain()\n\nStarting work.\nInside foo.\nFinishing work.\n\n\nIn the main() code-path, the call to foo() is a blocking call, the execution jumps to foo() and main() resumes when foo() returns.\nAsynchronous(or async) execution refers to execution that doesn't block when invoking subroutines. It is a fire-and-forget technique. Any work package runs separately from the main application thread and notifies the calling thread of its completion, failure or progress.\nUsually, such methods return an entity called future or promise that is the representation of an in-progress computation. The calling thread can query for the status of the computation via the returned future or promise and retrieve the result once completed.\nAnother pattern is to pass a callback function to the asynchronous functional call, which is invoked with the results when the asynchronous function is done processing.\nAsynchronous programming is an execllent choice for applications that do extensive network or disk I/O and spend most of their time waiting.\n\n\n\n\n\nPrograms that are compute-intensive are called CPU bound programs. This could involve numerical optimizations, Monte-Carlo simulations, data-crunching etc.\n\n\n\nI/O bound programs spend most of their time doing network or main memory and file I/O operations. Since the CPU and main memory are separate, a bus exists between the two to transfer bits. Similarly, data needs to moved from the NIC to CPU/memory. Even though these physical distances are small, the time taken to transfer the data can waste a few thousand CPU cycles. This is why I/O bound programs show relatively lower CPU utilization than CPU bound programs.\n\n\n\n\nThe most common cause of bugs in concurrent code is a race-condition.\n\nimport concurrent.futures\nimport logging\nimport time\nimport concurrent\nimport threading\n\nclass Account:\n    def __init__(self):\n        self.value = 0\n\n    @property\n    def value(self):\n        return self._value\n    \n    @value.setter\n    def value(self, x):\n        self._value = x\n    \n    def credit(self, name : str, amount : float):\n        logging.info(\"Thread %s: starting update\", name)\n        \n        # ----- Critical section -----\n        local_copy = self.value     \n        local_copy += amount\n        time.sleep(0.1)\n        self.value = local_copy\n        # ----- End of critical section -----\n\n        logging.info(\"Thread %s: finishing update\", name)\n\nif __name__ == \"__main__\":\n    format = \"%(asctime)s: %(message)s\"\n    logging.basicConfig(format=format, level=logging.INFO, datefmt=\"%H:%M:%S\")\n    account = Account()\n    logging.info(\"Testing update. Starting value is %d.\", account.value)\n\n    with concurrent.futures.ThreadPoolExecutor(max_workers=2) as executor:\n        for index in range(2):\n            executor.submit(account.credit, index, 100)\n\n    logging.info(\"Testing update. Ending value is %d\", account.value)\n\n11:49:59: Testing update. Starting value is 0.\n11:49:59: Thread 0: starting update\n11:49:59: Thread 1: starting update\n11:49:59: Thread 1: finishing update\n11:49:59: Thread 0: finishing update\n11:49:59: Testing update. Ending value is 100\n\n\nThe above logic can be made thread-safe by fencing off the critical section using a mutex and enforcing that only a single thread can enter at a time.\n\n\n\nImagine that you have a toy that comes in two parts, and you need both parts to play with it - a toy drum and a drumstick, for example. Now, imagine that you ave two small children, both of whom like playing with it. If one of them gets both the drum and the drumstick, that child can merrily play the drum until titing of it. If the other child wants to play, they have wait, however sad that makes them. Now, imagine one child has the drum and other has the drumstick. They’re stuck, unless one decides to be nice and let the other play, each will hold on to whatver they have and demand that they be given the other piece, so neither gets to play. This is a deadlock.\nImagine two threads arguing over locks on mutexes: each of a pair of threads needs to lock both of a pair of mutexes to perform some operation, and each thread has one mutex and is waiting for the other. Neither thread can proceed, because each is waiting for the other to release its mutex. This scenario is called deadlock.\n\nimport threading\nimport concurrent\nimport time\n\nif __name__ == \"__main__\":\n    drum = threading.Lock()\n    drumstick = threading.Lock()\n\n    def child1_plays_drums():\n        print(f\"\\nChild-1 waiting for drums\")\n        drum.acquire()\n        print(f\"\\nChild-1 acquired drums\")\n        print(f\"\\nChild-1 waiting for drumstick\")\n        drumstick.acquire()\n        print(f\"\\nChild-1 is playing drums\")\n\n    def child2_plays_drums():\n        print(f\"\\nChild-2 waiting for drumstick\")\n        drumstick.acquire()\n        print(f\"\\nChild-2 acquired drumstick\")\n        print(f\"\\nChild-2 waiting for drums\")\n        drum.acquire()\n        print(f\"\\nChild-2 acquired drums\")\n        print(f\"\\nChild-2 is playing drums\")\n\n    t1 = threading.Thread(target=child1_plays_drums)\n    t2 = threading.Thread(target=child2_plays_drums)\n    \n    t1.start()\n    t2.start()\n\n    time.sleep(1)\n\n\nChild-1 waiting for drums\n\nChild-1 acquired drums\n\nChild-1 waiting for drumstick\n\nChild-1 is playing drums\n\nChild-2 waiting for drumstick\n\n\n\n\n\nA mutex is an programming construct that allows only a single thread to access a shared resource or critical section. Once a thread acquires a mutex, all other threads attempting to acquire the same mutex are blocked until the thread releases the mutex.\nA semaphore on the hand is used to limit access to a collection of resources. Think of semaphore as having a limited number of permits to give out. If a semaphore has given out all the permits it has, then any new thread that comes along requesting a permit will be blocked till an earlier thread with a permit returns it to the semaphore. A protoypical example is a ConnectionPool that hands out database connects to requesting threads.\nA semaphore with a single permit is called a binary semaphore. Semaphores can also be used for signaling among threads. This is an important distinction as it allows threads to cooperatively work towards completing a task. A mutex on the other hand, is strictly limted to serializing access to shared data among competing threads.\n\n\nA semaphore can potentially act as a mutex if the number of permits it can give is at most \\(1\\). However, the most important difference is that, the thread that calls acquire() on a mutex must subsequently release() the mutex. A mutex is owned by the thread acquiring it, upto the point the owning thread releases it. Whilst, in the case of a binary semaphore, different threads can call acquire() and release() on the semaphore.\n\n\n\n\nAnother distinction between a semaphore and a mutex is that semaphores can be used for signaling amongst threads. For example, in case of the classical producer-consumer problem, the producer thread can signal the consumer thread by incrementing the semaphore count to indicate to the consumer thread to read items from the queue. Threads can coordinate tasks using semaphores. A mutex, in contrast, only guards access to shared data."
  },
  {
    "objectID": "posts/diy-asyncio/index.html#threading-module",
    "href": "posts/diy-asyncio/index.html#threading-module",
    "title": "DIY asyncio",
    "section": "threading module",
    "text": "threading module\nData-parallelism can be achieved using multi-threading.\n\nimport numpy as np\nimport threading\nimport typing\n\ndef accumulate(a : np.array, idx : int):\n    result = np.sum(a)\n    print(f\"\\nSum of the subarray {idx} = {result}\")\n\nif __name__ == \"__main__\":\n    data = np.random.rand(1000000)\n    num_chunks = 4\n    chunk_size = int(len(data) / num_chunks)\n    num_threads = num_chunks\n\n    threads = []\n    for i in range(num_threads):\n        start = i * chunk_size\n        end = start + chunk_size\n        thread = threading.Thread(target=accumulate(data[start:end], i))\n        threads.append(thread)\n\n    for t in threads:\n        t.start()\n\n    for t in threads:\n        t.join()\n\n\nSum of the subarray 0 = 124776.70127165115\n\nSum of the subarray 1 = 125051.88402552163\n\nSum of the subarray 2 = 125194.03813575335\n\nSum of the subarray 3 = 125021.25239279671\n\n\nAnother way to create threads is subclassing the threading.Thread class.\n\nfrom threading import Thread\nfrom threading import current_thread\n\nclass MyTask(Thread):\n\n    def __init__(self):\n        Thread.__init__(self, name=\"subClassThread\", args=(2,3))\n\n    def run(self):\n        print(f\"{current_thread().name} is executing\")\n\nmyTask = MyTask()\nmyTask.start()  # start the thread\nmyTask.join()   # wait for the thread to complete\n\nThe important caveats to remember when subclassing Thread class are:\n\nWe can only override the run() method and the constructor of the Thread class.\nThread.__init__() must be invoked if the subclass chooses to override the constructor.\n\n\nDaemon Thread\nDaemon threads are background threads. When the main thread is about to exit, it cycles through all regular non-daemon threads and waits for them to complete. In the implementation of the threading module, the _shutdown() method iterates through non-daemon threads and invokes join() on each of them. join() is a blocking call, which returns when a thread’s work package is complete.\n\nimport threading\nimport time\n\ndef daemon_task():\n    while(True):\n        print(f\"Executing daemon task\")\n        time.sleep(1)\n    print(f\"Completed daemon task\")\n\nif __name__ == \"__main__\":\n    daemon_thread = threading.Thread(\n        target=daemon_task,\n        name=\"daemon thread\",\n        daemon=True\n    )\n\n    daemon_thread.start()\n\nExecuting daemon task\n\n\n\n\nImplementation of a thread-safe LIFO stack\n\nimport threading\nimport time\nfrom typing import Any, Optional\n\nclass StackFull(Exception):\n    pass\n\nclass StackEmpty(Exception):\n    pass\n    \nclass Stack:\n    def __init__(self, maxsize : int = None):\n        self._mutex = threading.RLock()\n        self.maxsize = maxsize\n        self._data = list()\n\n    @property\n    def maxsize(self):\n        with self._mutex:\n            value = self._maxsize\n\n        return value\n\n    @maxsize.setter\n    def maxsize(self, value : int):\n        with self._mutex:\n            self._maxsize = value\n\n    def size(self) -&gt; int:\n        with self._mutex:\n            size = len(self._data)\n        \n        return size\n\n    def empty(self) -&gt; bool:\n        with self._mutex:\n            isEmpty = len(self._data) == 0\n        \n        return isEmpty\n\n    def full(self) -&gt; bool:\n        with self._mutex:\n            if(self.maxsize is not None):\n                isFull = len(self._data) == self.maxsize\n            else:\n                isFull = False\n        \n        return isFull\n\n    def put(\n        self,\n        item : Any, \n        block : bool = True, \n        timeout : float = -1\n    ) -&gt; None:\n        self._mutex.acquire(blocking=True,timeout=timeout)\n        print(f\"\\nPushing item {item} to the stack\")\n        if self.full():\n            print(\"Stack full!\")\n            self._mutex.release()\n            raise StackFull(\"Stack full!\")\n        \n        self._data.append(item)\n        print(f\"\\nPush complete\")\n        print(f\"stack : {self._data}\")\n        self._mutex.release()\n    \n    def put_nowait(self, item:Any):\n        self.put(item, block=False)\n\n    def get(self, block : bool = True, timeout : float = -1) -&gt; Any:\n        self._mutex.acquire(blocking=block, timeout=timeout)\n        print(f\"\\nPopping from the stack\")\n        if self.empty():\n            print(\"Stack empty!\")\n            self._mutex.release()\n            raise StackEmpty(\"Stack empty!\")\n        \n        value = self._data[self.size() - 1]\n        del self._data[self.size() - 1]\n        print(f\"\\nPopped item {value} from the stack\")\n        print(f\"stack : {self._data}\")\n        self._mutex.release()\n\n        return value\n\n    def get_no_wait(self):\n        return self.get(block=False)\n\n    def top(self) -&gt; Any:\n        self._mutex.acquire()\n        if self.empty():\n            self._mutex.release()\n            print(\"Stack empty!\")\n            raise StackEmpty(\"Stack empty!\")  \n\n        value = self._data[self.size() - 1]\n        self._mutex.release()\n        return value\n\ndef push_thread(stack : Stack):\n    \n    for i in range(10):\n        try:\n            stack.put(i)\n            time.sleep(0.1)\n        except Exception:\n            pass\n\ndef pop_thread(stack: Stack):\n    for i in range(10):\n        try:\n            item = stack.get()\n            time.sleep(0.12)\n        except Exception:\n            pass\n\nif __name__ == \"__main__\":\n    stack = Stack()\n    \n    t1 = threading.Thread(target=push_thread, args=(stack,))\n    t2 = threading.Thread(target=pop_thread, args=(stack,))\n    \n    t1.start()\n    t2.start()\n\n    t1.join()\n    t2.join()\n    \n    print(\"main() thread finished.\")\n\n\nPushing item 0 to the stack\n\nPush complete\nstack : [0]\n\nPopping from the stack\n\nPopped item 0 from the stack\nstack : []\n\nPushing item 1 to the stack\n\nPush complete\nstack : [1]\n\nPopping from the stack\n\nPopped item 1 from the stack\nstack : []\n\nPushing item 2 to the stack\n\nPush complete\nstack : [2]\n\nPopping from the stack\n\nPopped item 2 from the stack\nstack : []\n\nPushing item 3 to the stack\n\nPush complete\nstack : [3]\n\nPopping from the stack\n\nPopped item 3 from the stack\nstack : []\n\nPushing item 4 to the stack\n\nPush complete\nstack : [4]\n\nPopping from the stack\n\nPopped item 4 from the stack\nstack : []\n\nPushing item 5 to the stack\n\nPush complete\nstack : [5]\n\nPopping from the stack\n\nPopped item 5 from the stack\nstack : []\n\nPushing item 6 to the stack\n\nPush complete\nstack : [6]\n\nPushing item 7 to the stack\n\nPush complete\nstack : [6, 7]\n\nPopping from the stack\n\nPopped item 7 from the stack\nstack : [6]\n\nPushing item 8 to the stack\n\nPush complete\nstack : [6, 8]\n\nPopping from the stack\n\nPopped item 8 from the stack\nstack : [6]\n\nPushing item 9 to the stack\n\nPush complete\nstack : [6, 9]\n\nPopping from the stack\n\nPopped item 9 from the stack\nstack : [6]\n\nPopping from the stack\n\nPopped item 6 from the stack\nstack : []\nmain() thread finished.\n\n\nIn the above implementation, I used RLock - a reentrant lock. If a thread acquires a RLock object, it can choose to reacquire it as many times as possible. It is implicit to call release() as many times as lock() was called.\n\n\nCondition variables\nWe looked at various ways of protecting the data that’s shared between threads. But, sometimes we don’t just need to protect the data, we also need to synchronize actions on separate threads. One thread might need to wait for another thread to complete a task before the first thread can complete its own. In general, its common to want a thread to wait for a specific event to happen or a condition to be true. Although it would be possible to do this by periodically checking a task-complete flag or something like that, it is far from ideal. The need to synchronize operations between threads like this is a common scenario and the python standard standard library provides facilities to handle it, in the form of condition variables and futures.\nA condition variable is always associated with some kind of lock; this can be passed in, or one will be created on the fly. Passing one in is useful when several condition variables must share the same lock. The two important methods of a condition variable are:\n\nwait() - The wait() method releases the lock held, then block until another thread awakens it by calling notify() or notify_all(). Once awakened, wait() reqacquires the lock and returns.\nnotify() - The notify() method arbitrarily wakes up any one of the threads waiting on the condition variable. The notify_all() method wakes up all the threads.\n\nThe typical programming style using condition variables uses the lock to synchronize access to some shared state; threads that are interest in a particular change of state call wait() repeatedly until they see the desired state, while threads that modify the state call notify() or notify_all() when they change the state in such a way that it could possibly be a desired state for one of the waiters.\nNote: The notify() and notify_all() methods don’t release the lock; this means that the thread or threads awakened will not return from their wait() call immediately, but only when the waited-for thread finally relinquishes the ownership of the lock.\nFor example, the following code is a generic producer-consumer situation with unlimited buffer capacity:\n# consumer\nwith cond_var:\n    while item_is_not_available:\n        cond_var.wait()\n    \n    get_the_available_item()\n\n# producer\nwith cond_var:\n    produce_an_item()\n    cond_var.notify()\n\n\nImplementation of a thread-based SPSC bounded ring-buffer\n\nimport threading\nimport time\nfrom typing import Any, Optional\nfrom threading import Condition\n\nclass QueueFull(Exception):\n    pass\n\nclass QueueEmpty(Exception):\n    pass\n    \nclass Queue:\n    def __init__(self, maxsize : int = None):\n        self._lck = threading.RLock()\n        self._queue_not_empty_condition = Condition(self._lck)\n        self._queue_not_full_condition = Condition(self._lck)\n        self.maxsize = maxsize\n        self._data = list()\n\n    @property\n    def maxsize(self):\n        with self._lck:\n            value = self._maxsize\n\n        return value\n\n    @maxsize.setter\n    def maxsize(self, value : int):\n        with self._lck:\n            self._maxsize = value\n\n    def size(self) -&gt; int:\n        with self._lck:\n            size = len(self._data)\n        \n        return size\n\n    def empty(self) -&gt; bool:\n        with self._lck:\n            isEmpty = len(self._data) == 0\n        \n        return isEmpty\n\n    def full(self) -&gt; bool:\n        with self._lck:\n            if(self.maxsize is not None):\n                isFull = len(self._data) == self.maxsize\n            else:\n                isFull = False\n        \n        return isFull\n\n    def put(\n        self,\n        item : Any, \n    ) -&gt; None:\n        print(f\"\\nPushing item {item} to the queue\")\n        \n        self._queue_not_full_condition.acquire()\n        \n        while (self.full()):\n            self._queue_not_full_condition.wait()\n        \n        self._data.append(item)\n\n        print(f\"\\nPush complete\")\n        print(f\"queue : {self._data}\")\n        \n        self._queue_not_empty_condition.notify()\n\n        self._queue_not_full_condition.release()\n        return\n\n\n    def get(self) -&gt; Any:\n        \n        self._queue_not_empty_condition.acquire()\n\n        while (self.empty()):\n            self._queue_not_empty_condition.wait()\n\n        print(f\"\\nPopping from the queue\")\n        \n        value = self._data[0]\n        del self._data[0]\n        print(f\"\\nPopped item {value} from the queue\")\n        print(f\"queue : {self._data}\")\n\n        self._queue_not_full_condition.notify()\n\n        self._queue_not_empty_condition.release()\n        return value\n\n    def top(self) -&gt; Any:\n        self._lck.acquire()\n        if self.empty():\n            self._lck.release()\n            raise QueueEmpty(\"queue empty!\")  \n\n        value = self._data[self.size() - 1]\n        self._lck.release()\n        return value\n\ndef push_thread(queue : Queue):\n    \n    for i in range(10):\n        try:\n            queue.put(i)\n            time.sleep(0.07)\n        except Exception:\n            pass\n\ndef pop_thread(queue: Queue):\n    for i in range(10):\n        try:\n            item = queue.get()\n            time.sleep(0.1)\n        except Exception:\n            pass\n\nif __name__ == \"__main__\":\n    queue = Queue()\n   \n    \n    t1 = threading.Thread(target=push_thread, args=(queue,))\n    t2 = threading.Thread(target=pop_thread, args=(queue,))\n    \n    t1.start()\n    t2.start()\n\n    t1.join()\n    t2.join()\n    \n    print(\"main() thread finished.\")\n\n\nPushing item 0 to the queue\n\nPush complete\nqueue : [0]\n\nPopping from the queue\n\nPopped item 0 from the queue\nqueue : []\n\nPushing item 1 to the queue\n\nPush complete\nqueue : [1]\n\nPopping from the queue\n\nPopped item 1 from the queue\nqueue : []\n\nPushing item 2 to the queue\n\nPush complete\nqueue : [2]\n\nPopping from the queue\n\nPopped item 2 from the queue\nqueue : []\n\nPushing item 3 to the queue\n\nPush complete\nqueue : [3]\n\nPushing item 4 to the queue\n\nPush complete\nqueue : [3, 4]\n\nPopping from the queue\n\nPopped item 3 from the queue\nqueue : [4]\n\nPushing item 5 to the queue\n\nPush complete\nqueue : [4, 5]\n\nPopping from the queue\n\nPopped item 4 from the queue\nqueue : [5]\n\nPushing item 6 to the queue\n\nPush complete\nqueue : [5, 6]\n\nPushing item 7 to the queue\n\nPush complete\nqueue : [5, 6, 7]\n\nPopping from the queue\n\nPopped item 5 from the queue\nqueue : [6, 7]\n\nPushing item 8 to the queue\n\nPush complete\nqueue : [6, 7, 8]\n\nPopping from the queue\n\nPopped item 6 from the queue\nqueue : [7, 8]\n\nPushing item 9 to the queue\n\nPush complete\nqueue : [7, 8, 9]\n\nPopping from the queue\n\nPopped item 7 from the queue\nqueue : [8, 9]\n\nPopping from the queue\n\nPopped item 8 from the queue\nqueue : [9]\n\nPopping from the queue\n\nPopped item 9 from the queue\nqueue : []\nmain() thread finished.\n\n\n\n\nSemaphores\nThis is one of the oldest synchronization primitices in the history of CS, invented by the Dutch computer scientist Edsger W. Djikstra. A semaphore manages an internal counter which is decremented by each acquire() and incremented by each release() call."
  },
  {
    "objectID": "posts/diy-asyncio/index.html#events",
    "href": "posts/diy-asyncio/index.html#events",
    "title": "DIY asyncio",
    "section": "Events",
    "text": "Events\nAn Event object is one of the simplest primitives available for synchronization. Internally, the CPython implementation manages a flag that can be set to True with the set() method and reset to False using the clear() method. The wait() method blocks until the flag is True.\nWhen the internal flag is set to True, all threads waiting on the Event are awakened. Threads that call wait() once the flag is True will not block at all.\nWhen the internal flag is reset to False, threads calling wait() will block until set() is called to set the internal flag to True again."
  },
  {
    "objectID": "posts/diy-asyncio/index.html#the-global-interpreter-lockgil",
    "href": "posts/diy-asyncio/index.html#the-global-interpreter-lockgil",
    "title": "DIY asyncio",
    "section": "The Global Interpreter Lock(GIL)",
    "text": "The Global Interpreter Lock(GIL)\nThe Python interpreter maintains a reference count of each object in Python code. When references go out of scope, the reference count of the object is decremented and if the reference count equals \\(0\\), memory is deallocated(reclaimed). These reference counts are shared state and executing Python bytecode requires acquiring an exclusive lock on the interpreter (shared state). The implication is that the threading library does not offer true hardware concurrency even on multi-core CPUs."
  },
  {
    "objectID": "posts/diy-asyncio/index.html#asyncio-from-scratch",
    "href": "posts/diy-asyncio/index.html#asyncio-from-scratch",
    "title": "DIY asyncio",
    "section": "asyncio from scratch",
    "text": "asyncio from scratch\n\nGenerators\n\ndef fib(count: int):\n    a, b = 1, 0\n    for i in range(count):\n        a, b = b, a + b\n        yield b\n\ndef main():\n    gen = fib(5)\n    print(gen)\n    while True:\n        print(next(gen))\n\ntry:\n    main()        \nexcept StopIteration:\n    print(\"Stop Iteration.\")\n\n&lt;generator object fib at 0x11e043ca0&gt;\n1\n1\n2\n3\n5\nStop Iteration.\n\n\nThe fibonacci sequence is a staple of generator examples. Each time through the loop we add the previous two numbers together and yield that value resulting in the sequence \\(\\{1, 1, 2, 3, 5, \\ldots \\}\\). But, when we call this function, we don’t get any of these values directly, instead we get a compiled version of the generator object. The actual code in our function hasn’t even started executing yet.\nThe generator object can then be iterated over just like a list and the standard next() function from the standard library can be used to iterate just once at a time. Each time we call next() on our generator object, it’s re-entering the function where we left off, preserving the full state and if the function yields another value we get that value as the result value or the return value from the next call. When the generator function completes or returns, it raises a StopIteration exception, just like any other iterator would.\nIt’s quite common to see generators that yield values out, but it’s also possible to communicate or send values back into the generator from the outside. To do this, we have to replace the use of the next() function with the generator’s send() function.\n\ndef counter(start = 0, stop = 10, step = 1):\n    value = start\n    while value &lt; stop:\n        value = yield value\n        value += step\n    yield value\n\ndef main():\n    gen = counter()\n    \n    # prime the generator\n    # advance to the next yield statement\n    value = gen.send(None)\n    print(f\"sent None, got {value}\")\n\n    try:\n        while(True):\n            next_value = gen.send(value)\n            print(f\"sent {value}, got {next_value}\")\n            value = next_value\n    except StopIteration:\n        print(\"StopIteration.\")\n\nmain()\n\nsent None, got 0\nsent 0, got 1\nsent 1, got 2\nsent 2, got 3\nsent 3, got 4\nsent 4, got 5\nsent 5, got 6\nsent 6, got 7\nsent 7, got 8\nsent 8, got 9\nsent 9, got 10\nStopIteration.\n\n\nCongratulation, now you’ve just discovered coroutines. Python’s had them hiding in plain sight for years. But, how do we actually use this to run concurrent tasks?\nWe are going to write an event loop that calls send on each generator object. And rather than looking for a flag, we catch the StopIteration exception and mark those generators and tasks as completed. The StopIteration itself contains the return value from these generators. So, we save those for the final result. Lastly, we also capture intermediate yielded values and send them back on the next iteration, which enables coroutines to call other coroutines.\n\nfrom typing import Generator, Any, List, Iterable\nimport time\n\n\ndef wait(tasks: Iterable[Generator]) -&gt; List[Any]:\n    pending = list(tasks)\n    tasks = {task: None for task in pending}\n    before = time.time()\n\n    while pending:\n        for gen in pending:\n            try:\n                tasks[gen] = gen.send(tasks[gen])\n            except StopIteration as e:\n                tasks[gen] = e.args[0]\n                pending.remove(gen)\n\n    print(f\"duration = {time.time() - before:.3}\")\n    return list(tasks.values())\n\nThis means that we can now yield from another coroutine to call into it. Together, this makes our coroutines look and feel more like standard functions. But, they are still yielding control on their terms, and get to continue where they left off when its their turn again.\n\ndef sleep(duration: float):\n    now = time.time()\n    threshold = now + duration\n\n    while now &lt; threshold:\n        yield\n        now = time.time()\n\ndef bar():\n    yield from sleep(0.1)\n    return 123\n\ndef foo():\n    value = yield from bar()\n    return value\n\ndef main():\n    tasks = [foo(), foo()]\n    print(wait(tasks))\n\nmain()\n\nduration = 0.1\n[123, 123]\n\n\nWe can create a pair of coroutines from the foo() functions and pass them to the event loop. It will follow execution from foo into bar and then into the sleep coroutine. In there, it will continue yielding back into the event loop until the time duration is up. Then, on the next iteration, it will return control to bar() which returns the value back to foo() which finally completes and returns the value.\nTo be clear, at each yield(), our event loop is cycling to the next pending task, giving us the cooperative multitasking concurrency that we have been looking for."
  },
  {
    "objectID": "posts/first_passage_time_of_BM/index.html",
    "href": "posts/first_passage_time_of_BM/index.html",
    "title": "The distribution of the first passage time of Brownian Motion",
    "section": "",
    "text": "The distribution of Brownian motion enjoys many interesting symmetries. The reflection of a Brownian motion about any time \\(s\\) is also a Brownian motion.\nLemma 1. (Reflection at time \\(s\\)) Let \\(B_t\\) be a standard Brownian motion. Then, the process \\((-B_t,t \\geq 0)\\) is a Brownian motion. More generally, for any \\(s \\geq 0\\), the process \\((\\tilde{B_t},t\\geq 0)\\) defined by:\n\\[\\begin{align*}\n\\tilde{B}_t = \\begin{cases}\nB_t & \\text{ if } t\\leq s\\\\\nB_s - (B_t - B_s) & \\text{ if }t &gt; s\n\\end{cases}\n\\end{align*}\\]\nis a Brownian motion.\nClaim. \\((-B_t,t\\geq 0)\\) is a Brownian motion.\nProof.\nWe have, \\(-B(0) = 0\\).\nFor any increment \\(s &lt; t\\), the increment \\((-B_t) - (-B_s) = B_s - B_t\\) is a Gaussian random variable with mean \\(0\\) and variance \\(t - s\\).\nFor any choice of \\(n\\) times, \\(0 \\leq t_1 \\leq t_2 \\leq \\ldots \\leq t_n\\), the increments:\n\\[\\begin{align*}\n(B_{0} - B_{t_1}), (B_{t_1} - B_{t_2}), \\ldots, (B_{t_n} - B_{t_{n-1}})\n\\end{align*}\\]\nare independent\nThe paths \\(-B_t(\\omega)\\) are continuous.\nThus, \\((-B_t,t\\geq 0)\\) is a standard Brownian motion.\nClaim. \\((\\tilde{B_t},t\\geq 0)\\) is a Brownian motion.\nProof.\nLet \\(s \\geq 0\\) be any arbitrary time.\nWe have, \\(\\tilde{B}(0) = 0\\).\nConsider any increment \\(\\tilde{B}(t_2) - \\tilde{B}(t_1)\\), \\(t_2 &lt; t_1\\).\nCase I. \\(s \\leq t_1 &lt; t_2\\)\nHere\n\\[\\begin{align*}\n\\tilde{B}(t_2) - \\tilde{B}(t_1) &= B(s) - (B(t_2) - B(s)) - (B(s) - (B(t_1) - B(s))) \\\\\n&= -(B(t_2) - B(t_1))\n\\end{align*}\\]\nHence, \\(\\tilde{B}(t_2) - \\tilde{B}(t_1) \\sim \\mathcal{N}(0,t_2 - t_1)\\).\nCase II. \\(t_1 &lt; s &lt; t_2\\)\nHere\n\\[\\begin{align*}\n\\tilde{B}(t_2) - \\tilde{B}(t_1) &= B(s) - (B(t_2) - B(s)) - B(t_1)\\\\\n&= (B(s) - B(t_1)) - (B(t_2) - B(s))\n\\end{align*}\\]\n\\(B(s) - B(t_1)\\) and \\(B(t_2) - B(s)\\) are independent random variables. Moreover, \\(B(s) - B(t_1) \\sim \\mathcal{N}(0,s - t_1)\\) and \\(B(t_2) - B(s) \\sim \\mathcal{N}(0,t_2 - s)\\). Consequently, \\(\\tilde{B}(t_2) - \\tilde{B}(t_1) \\sim \\mathcal{N}(0,t_2 - t_1)\\).\nCase III. \\(t_1 &lt; t_2 \\leq s\\)\nHere\n\\[\\begin{align*}\n\\tilde{B}(t_2) - \\tilde{B}(t_1) &= B(t_2) - B(t_1)\n\\end{align*}\\]\nso \\(\\tilde{B}(t_2) - \\tilde{B}(t_1) \\sim \\mathcal{N}(0,t_2 - t_1)\\).\nFinally, the paths \\(\\tilde{B}(t,\\omega)\\) are continuous. Hence, \\((\\tilde{B}(t),t\\geq 0)\\) is a standard brownian motion."
  },
  {
    "objectID": "posts/first_passage_time_of_BM/index.html#reflection-principle",
    "href": "posts/first_passage_time_of_BM/index.html#reflection-principle",
    "title": "The distribution of the first passage time of Brownian Motion",
    "section": "Reflection Principle",
    "text": "Reflection Principle\nIt turns out that the above reflection property holds even if \\(s\\) is replaced by a stopping time. I prove this here.\nLemma 2. (Reflection Principle) Let \\((B_t,t \\geq 0)\\) be a standard Brownian motion and \\(\\tau\\) be a stopping time for its filtration. Then, the process \\((\\tilde{B}(t),t\\geq 0)\\) defined by the reflection at time \\(\\tau\\):\n\\[\\begin{align*}\n\\tilde{B}(t) &= \\begin{cases}\nB_t & \\text{ if } t\\leq \\tau\\\\\nB_\\tau - (B_t - B_\\tau) & \\text{ if }t &gt; \\tau\n\\end{cases}\n\\end{align*}\\]\nis also a standard Brownian motion."
  },
  {
    "objectID": "posts/first_passage_time_of_BM/index.html#bacheliers-formula",
    "href": "posts/first_passage_time_of_BM/index.html#bacheliers-formula",
    "title": "The distribution of the first passage time of Brownian Motion",
    "section": "Bachelier’s formula",
    "text": "Bachelier’s formula\nIt is an amazing fact, that some simple manipulations using stopping time yield the complete distribution of the first passage time \\(\\tau_a\\) of a Brownian motion as well as the distribution of the running maximum of the Brownian path on an interval of time \\([0,T]\\). This is surprising since the maximum of the Brownian path on \\([0,T]\\), denoted by \\(\\sup_{0\\leq t \\leq T} B_t\\) is a random variable that depends on the whole path on \\([0,T]\\). This beautiful result is due to Bachelier.\nProposition 3. (Bachelier’s formula) Let \\((B_t,t\\leq T)\\) be a standard Brownian motion on \\([0,T]\\). Then, the CDF of the random variable \\(\\sup_{0 \\leq t\\leq T} B_t\\) is:\n\\[\\begin{align*}\n\\mathbb{P}\\left(\\sup_{0\\leq t \\leq T} B_t \\leq a\\right) = \\mathbb{P}(|B_T| \\leq a) \\quad \\text{ for any }a\\geq 0\n\\end{align*}\\]\nIn particular, its PDF is:\n\\[\\begin{align*}\nf_{max}(a) = \\frac{2}{\\sqrt{2\\pi T}} e^{-a^2/2T}\n\\end{align*}\\]\nIn other words, the random variable \\(\\sup_{0 \\leq t \\leq T} B_t\\) (the maximum of the brownian motion at any time \\(t\\)) has the same distribution as \\(|B_T|\\) (the terminal distribution of the absolute value of the brownian motion).\nThis equality holds in distribution for a fixed \\(t\\). As a bonus corollary, we get the distribution of the first passage time at \\(a\\).\nProof. Consider \\(\\mathbb{P}(\\sup_{t \\leq T} B_t \\geq a)\\). By splitting this probability over the event of the endpoint, we have:\n\\[\\begin{align*}\n\\mathbb{P}(\\sup_{t \\leq T} B_t \\geq a) &= \\mathbb{P}(\\sup_{t \\leq T} B_t \\geq a, B_T &gt; a) + \\mathbb{P}(\\sup_{t \\leq T} B_t \\geq a, B_T \\leq a)\n\\end{align*}\\]\nNote also that \\(\\mathbb{P}(B_T = a) = 0\\). Hence, the first probability equals \\(\\mathbb{P}(B_T \\geq a)\\). As for the second, consider the time \\(\\tau_a\\). On the event considered, we have \\(\\tau_a \\leq T\\) and using the reflection principle (lemma 2), we get:\n\\[\\begin{align*}\n\\mathbb{P}(\\sup_{t \\leq T} B_t \\geq a, B_T \\leq a) &= \\mathbb{P}(\\sup_{t \\leq T} B_t \\geq a, \\tilde{B}_T \\geq a)\n\\end{align*}\\]\nObserve that, since \\(\\tau_a \\leq T\\), the event \\(\\{\\sup_{t \\leq T} B_t \\geq a\\}\\) is the same as \\(\\{\\sup_{t\\leq T} \\tilde{B}(t) \\geq a\\}\\). Therefore the above probability is:\n\\[\\begin{align*}\n\\mathbb{P}(\\sup_{t \\leq T} B_t \\geq a) &= \\mathbb{P}(B_T &gt; a) + \\mathbb{P}(\\sup_{t \\leq T} \\tilde{B}_t \\geq a, \\tilde{B}_T \\geq a)\n\\end{align*}\\]\nBut, \\(\\tilde{B}_t\\) is also a standard brownian motion and has the same distribution as \\(B_t\\). \\(\\mathbb{P}(B_t \\in S) = \\mathbb{P}(\\tilde{B}_t \\in S)\\) by the reflection principle. So, we can simply drop the tilde signs and write:\n\\[\\begin{align*}\n\\mathbb{P}(\\sup_{t \\leq T} B_t \\geq a) &= \\mathbb{P}(B_T &gt; a) + \\mathbb{P}(\\sup_{t \\leq T} {B}_t \\geq a, {B}_T \\geq a)\\\\\n&=\\mathbb{P}(B_T &gt; a) + \\mathbb{P}({B}_T \\geq a)\\\\\n&= \\mathbb{P}(B_T \\leq -a) + \\mathbb{P}(B_T \\geq a) \\\\\n& \\quad \\{\\text{ By symmetry of the Gaussian distribution }\\}\\\\\n&= \\mathbb{P}(B_T \\leq -a \\cup B_T \\geq a) \\\\\n&= \\mathbb{P}(|B_T| \\geq a)\n\\end{align*}\\]\nWe conclude that:\n\\[\\begin{align*}\n\\mathbb{P}(\\sup B_t \\leq a) = \\mathbb{P}(|B_T| \\leq a)\n\\end{align*}\\]\nas claimed.\nTo derive the PDF, we can always write:\n\\[\\begin{align*}\n\\mathbb{P}(\\sup_{t \\leq T} B_t \\geq a) &= \\mathbb{P}(B_T &gt; a) + \\mathbb{P}({B}_T \\geq a)\\\\\n&= 2\\mathbb{P}(B_T \\geq a)\\\\\n&= 2(1 - F_{B_T}(a))\n\\end{align*}\\]\nSo:\n\\[\\begin{align*}\nF_{\\sup B_t}(a) &= 1 - 2(1 - F_{B_T}(a))\\\\\n\\frac{d}{da}(F_{\\sup B_t}(a)) &= 2 \\frac{d}{da}(F_{B_T}(a))\\\\\nf_{\\sup B_t}(a) &= 2 f_{B_T}(a)\\\\\n&= \\frac{2}{\\sqrt{2\\pi T}}\\exp\\left[-\\frac{a^2}{2T}\\right]\n\\end{align*}\\]"
  },
  {
    "objectID": "posts/first_passage_time_of_BM/index.html#distribution-of-the-first-passage-time-tau_a",
    "href": "posts/first_passage_time_of_BM/index.html#distribution-of-the-first-passage-time-tau_a",
    "title": "The distribution of the first passage time of Brownian Motion",
    "section": "Distribution of the first passage time \\(\\tau_a\\)",
    "text": "Distribution of the first passage time \\(\\tau_a\\)\nCorollary 4. Let \\(a \\geq 0\\) and let \\(\\tau_a = \\min \\{t \\geq 0: B_t \\geq a\\}\\). Then:\n\\[\\begin{align*}\n\\mathbb{P}(\\tau_a \\leq T) = \\mathbb{P}\\left(\\sup_{0 \\leq t \\leq T} B_t \\geq a\\right) = \\int_{a}^{\\infty} \\frac{2}{\\sqrt{2\\pi T}}e^{-x^2/2T} dx\n\\end{align*}\\]\nIn particular, the random variable \\(\\tau_a\\) has PDF:\n\\[\\begin{align*}\nf_{\\tau_a}(t) = \\frac{a}{\\sqrt{2\\pi}} \\frac{e^{-a^2/2t}}{t^{3/2}}\n\\end{align*}\\]\nThis implies that it is heavy-tailed and \\(\\mathbb{E}[\\tau_a] = \\infty\\).\nProof.\nThe maximum on \\([0,T]\\) is larger than or equal to \\(a\\), if and only if, \\(\\tau_a \\leq T\\). Therefore, the events \\(\\{\\sup_{0 \\leq t \\leq T} B_t \\geq a\\}\\) and \\(\\{\\tau_a \\leq T\\}\\) are the same. So, the CDF \\(\\mathbb{P}(\\tau_a \\leq t)\\) of \\(\\tau_a\\) is\n\\[\\begin{align*}\nF_{\\tau_a}(t) = \\int_{a}^{\\infty} \\frac{2}{\\sqrt{2\\pi t}} e^{-\\frac{x^2}{2t}} dx\n\\end{align*}\\]\nTo get the PDF, it remains to differentiate the integral with respect to \\(t\\). This is easy to do, once we realise a change of variable \\(u = x/\\sqrt{t}\\), \\(du = dx/\\sqrt{t}\\) that:\n\\[\\begin{align*}\nF_{\\tau_a}(t) &= \\int_{a/\\sqrt{t}}^{\\infty} \\frac{2}{\\sqrt{2\\pi}} e^{-\\frac{u^2}{2}}du\\\\\n&= 2(1 - \\Phi\\left(\\frac{a}{\\sqrt{t}}\\right))\n\\end{align*}\\]\nDifferentiating on both sides with respect to \\(t\\), we get:\n\\[\\begin{align*}\nf_{\\tau_a}(t) &= - 2\\phi\\left(\\frac{a}{\\sqrt{t}}\\right) \\left(-\\frac{1}{2}\\right) \\frac{a}{t^{3/2}}\\\\\n&= \\frac{a}{t^{3/2}} \\frac{e^{-a^2/2t}}{\\sqrt{2\\pi}}\n\\end{align*}\\]\nThis closes the proof."
  },
  {
    "objectID": "posts/function-currying/index.html",
    "href": "posts/function-currying/index.html",
    "title": "Currying and partial function application",
    "section": "",
    "text": "Let \\(u=f(x_1,\\ldots,x_n)\\) be a function of \\(n\\) variables. curry&lt;n&gt;(f) is an operator form of the function \\(f\\), such that:\n\\[\n\\begin{align*}\n\\text{curry&lt;n&gt;}(f)(a_1)(a_2)\\ldots(a_n) = f(a_1,\\ldots,a_n)\n\\end{align*}\n\\]\nand\n\\[\n\\begin{align*}\n\\text{curry&lt;n&gt;}(f)(a_1) &= \\text{curry&lt;n-1&gt;}(g(x_2,\\ldots,x_n)), & \\quad g(x_2,\\ldots,x_n) &= f(a_1,x_2,\\ldots,x_n) \\\\\n\\text{curry&lt;n-1&gt;}(g)(a_2) &= \\text{curry&lt;n-2&gt;}(h(x_3,\\ldots,x_n)),  &\\quad h(x_3,\\ldots,x_n) &= g(a_2,x_3,\\ldots,x_n)\n\\end{align*}\n\\]\n\n\n#include &lt;iostream&gt;\n#include &lt;functional&gt;\n#include &lt;cmath&gt;\n#include &lt;cassert&gt;\n\n/* curry&lt;N&gt;(f) is an operator form of the function of N variables,\n   so that curry&lt;N&gt;(f)(x_1)(x_2)...(x_N) = f(x_1,...,x_N).\n\n   Also, curry&lt;N&gt;(f)(a_1) = curry&lt;N-1&gt;(f')\n\n   where f' is a function of N-1 variables obtained by partial\n   function application, that is, substituting the value x_1=a_1 in f.\n*/\n\ntemplate&lt;int N&gt;\nauto curry (auto f){\n    if constexpr(N == 1){\n        return [=](auto x){\n            return f(x);\n        };\n    }else{\n        return [=](auto x){\n            return curry&lt;N-1&gt;(\n                [=](auto... rest){\n                    return f(x, rest...);\n            });\n        };\n    }\n};\n\nint main()\n{\n    auto norm = [](double x, double y, double z) -&gt; double {\n        return sqrt(x*x + y*y + z*z);\n    };\n\n    assert(curry&lt;3&gt;(norm)(1)(2)(2) == 3.0);\n    return 0;\n}\nCompiler Explorer"
  },
  {
    "objectID": "posts/function-currying/index.html#c-implementation-using-lambda",
    "href": "posts/function-currying/index.html#c-implementation-using-lambda",
    "title": "Currying and partial function application",
    "section": "",
    "text": "#include &lt;iostream&gt;\n#include &lt;functional&gt;\n#include &lt;cmath&gt;\n#include &lt;cassert&gt;\n\n/* curry&lt;N&gt;(f) is an operator form of the function of N variables,\n   so that curry&lt;N&gt;(f)(x_1)(x_2)...(x_N) = f(x_1,...,x_N).\n\n   Also, curry&lt;N&gt;(f)(a_1) = curry&lt;N-1&gt;(f')\n\n   where f' is a function of N-1 variables obtained by partial\n   function application, that is, substituting the value x_1=a_1 in f.\n*/\n\ntemplate&lt;int N&gt;\nauto curry (auto f){\n    if constexpr(N == 1){\n        return [=](auto x){\n            return f(x);\n        };\n    }else{\n        return [=](auto x){\n            return curry&lt;N-1&gt;(\n                [=](auto... rest){\n                    return f(x, rest...);\n            });\n        };\n    }\n};\n\nint main()\n{\n    auto norm = [](double x, double y, double z) -&gt; double {\n        return sqrt(x*x + y*y + z*z);\n    };\n\n    assert(curry&lt;3&gt;(norm)(1)(2)(2) == 3.0);\n    return 0;\n}\nCompiler Explorer"
  },
  {
    "objectID": "posts/girsanov-theorem/index.html",
    "href": "posts/girsanov-theorem/index.html",
    "title": "A gentle introduction to the Girsanov Theorem - Back to the basics",
    "section": "",
    "text": "One of the most popular technical tools in financial engineering is the Girsanov theorem. In this blog-post, I intend to provide the dear reader a beginner-friendly introduction and an intuitive gut feel for these tools.\nThe change of measure technique was used by Heylette Geman, Nicole El Karoui and Jean-Charles Rochet in their seminal note Changes of Numeraire, Changes of Probability Measure and Option Pricing.\n\n%load_ext itikz"
  },
  {
    "objectID": "posts/girsanov-theorem/index.html#change-of-probability-for-a-random-variable.",
    "href": "posts/girsanov-theorem/index.html#change-of-probability-for-a-random-variable.",
    "title": "A gentle introduction to the Girsanov Theorem - Back to the basics",
    "section": "Change of Probability for a Random Variable.",
    "text": "Change of Probability for a Random Variable.\nConsider a random variable \\(X\\) defined on a sample space \\(\\Omega\\) having zero mean. We want to change the mean of \\(X\\) so that \\(\\mu\\neq 0\\). Of course, it is easy to change the mean of a random variable: If \\(X\\) has mean \\(0\\), then the random variable \\(X+\\mu\\) has mean \\(\\mu\\). However, it might be that the variable \\(X+\\mu\\) does not share the same possible values as \\(X\\). For example, take \\(X\\) to be a uniform random variable on \\([-1,1]\\). While \\(X+1\\) has mean \\(1\\), the density of \\(X+1\\) would be non-zero on \\([0,2]\\) instead of \\([-1,1]\\).\nOur goal is to find a good way to change the underlying probability \\(\\mathbb{P}\\), and thus the distribution of \\(X\\), so that the set of outcomes is unchanged. If \\(X\\) is a discrete random variable, say with \\(\\mathbb{P}(X=-1)=\\mathbb{P}(X=1)=1/2\\), we can change the probability in order to change the mean easily. It suffices to take \\(\\tilde{\\mathbb{P}}\\) so that \\(\\tilde{\\mathbb{P}}(X=1)=p\\) and \\(\\mathbb{P}(X=-1)=1-p\\) for some appropriate \\(0\\leq p\\leq1\\).\nIf \\(X\\) is a continuous random variable, with a PDF \\(f_{X}\\), the probabilities can be changed by modifying the PDF. Consider the a new PDF:\n\\[\\begin{aligned}\n\\tilde{f}_{X}(x) & =f_{X}(x)g(x)\n\\end{aligned}\\]\nfor some function \\(g(x)&gt;0\\) such that \\(\\int f(x)g(x)dx=1\\). Clearly, \\(f_{X}(x)g(x)\\) is also a PDF and \\(f_{X}(x)&gt;0\\) if and only if \\(f_{X}(x)g(x)&gt;0\\), so that the possible values of \\(X\\) are unchanged. A convenient (and important!) choice of function \\(g\\) is:\n\\[\\begin{aligned}\ng(x) & =\\frac{e^{ax}}{\\int_{\\mathbf{R}}e^{ax}f_{X}(x)dx}=\\frac{e^{ax}}{\\mathbb{E}[e^{aX}]},\\quad a\\in\\mathbf{R}\n\\end{aligned} \\tag{1}\\]\nassuming \\(X\\) has a well-defined MGF. Here \\(a\\) is a parameter that can be tuned to fit to a specific mean. The normalization factor in the denominator is the MGF of \\(X\\). It ensures that \\(f_{X}(x)g(x)\\) is a PDF. Note that if \\(a&gt;0\\), the function \\(g\\) gives a bigger weight to large values of \\(X\\). We say that \\(g\\) is biased towards the large values.\n\nExample 1 (Biasing a uniform random variable) Let \\(X\\) be a uniform random variable on \\([0,1]\\) defined on \\((\\Omega,\\mathcal{F},\\mathbb{P})\\). Clearly, \\(\\mathbb{E}[X]=1/2\\). How can we change the PDF of \\(X\\) so that the possible values are still \\([0,1]\\), but the mean is \\(1/4\\). We have that the PDF is \\(f_{X}(x)=1\\) if \\(x\\in[0,1]\\) and \\(0\\) elsewhere. Therefore, the mean with the new PDF with parameter \\(a\\) as in the Equation 1 is:\n\\[\\begin{aligned}\n\\tilde{\\mathbb{E}}[X] & =\\int_{0}^{1}x\\tilde{f}(x)dx\\\\\n& =\\int_{0}^{1}\\frac{xe^{ax}}{\\mathbb{E}[e^{aX}]}dx\\\\\n& =\\frac{a}{e^{a}-1}\\int_{0}^{1}xe^{ax}dx\\\\\n& =\\frac{a}{e^{a}-1}\\left(\\left[x\\frac{e^{ax}}{a}\\right]_{0}^{1}-\\frac{1}{a}\\int_{0}^{1}e^{ax}dx\\right)\\\\\n& =\\frac{a}{e^{a}-1}\\left(\\frac{e^{a}}{a}-\\frac{1}{a}\\frac{e^{a}-1}{a}\\right)\\\\\n& =\\frac{e^{a}}{e^{a}-1}-\\frac{1}{a}\n\\end{aligned}\\]\nFor \\(\\tilde{\\mathbb{E}[X]}\\)to be equal to \\(1/4\\), we get numerically \\(a\\approx-3.6\\). Note that the possible values of \\(X\\) remain the same under the new probability. However, the new distribution is no longer uniform! It has bias towards values closer to zero, as it should.\n\n\nExample 2 (Biasing a Gaussian random variable.) Let \\(X\\) be a Gaussian random variable with mean \\(\\mu\\) and variance \\(\\sigma^{2}\\). How can we change the PDF of \\(X\\) to have mean \\(0\\)? Going back to Equation 1, the mean \\(\\mu\\) under the new PDF with parameter \\(a\\) is:\n\\[\\begin{aligned}\n\\tilde{\\mathbb{E}}[X] & =\\int_{-\\infty}^{\\infty}x\\tilde{f}(x)dx\\\\\n& =\\int_{-\\infty}^{\\infty}xg(x)f(x)dx\\\\\n& =\\int_{-\\infty}^{\\infty}x\\cdot\\frac{e^{ax}}{\\mathbb{E}[e^{aX}]}\\frac{1}{\\sqrt{2\\pi}\\sigma}e^{-\\frac{1}{2}\\left(\\frac{x-\\mu}{\\sigma}\\right)^{2}}dx\\\\\n& =\\frac{1}{e^{\\mu a+\\frac{1}{2}a^{2}\\sigma^{2}}}\\frac{1}{\\sqrt{2\\pi}\\sigma}\\int_{-\\infty}^{\\infty}x\\cdot\\exp\\left[-\\frac{1}{2}\\left(\\frac{x^{2}-2\\mu x+\\mu^{2}-2a\\sigma^{2}x}{\\sigma^{2}}\\right)\\right]dx\\\\\n& =\\frac{1}{e^{\\mu a+\\frac{1}{2}a^{2}\\sigma^{2}}}\\frac{1}{\\sqrt{2\\pi}\\sigma}\\int_{-\\infty}^{\\infty}x\\cdot\\exp\\left[-\\frac{1}{2}\\left(\\frac{x^{2}-2(\\mu+a\\sigma^{2})x+(\\mu+a\\sigma^{2})^{2}-2\\mu a\\sigma^{2}-a^{2}\\sigma^{4}}{\\sigma^{2}}\\right)\\right]dx\\\\\n& =\\frac{e^{\\mu a+a^{2}\\sigma^{2}/2}}{e^{\\mu a+\\frac{1}{2}a^{2}\\sigma^{2}}}\\frac{1}{\\sqrt{2\\pi}\\sigma}\\int_{-\\infty}^{\\infty}x\\exp\\left[-\\frac{1}{2}\\left(\\frac{x-(\\mu+a\\sigma^{2})}{\\sigma}\\right)^{2}\\right]dx\\\\\n& =\\frac{1}{\\sqrt{2\\pi}\\sigma}\\int_{-\\infty}^{\\infty}x\\exp\\left[-\\frac{1}{2}\\left(\\frac{x-(\\mu+a\\sigma^{2})}{\\sigma}\\right)^{2}\\right]dx\n\\end{aligned}\\]\nFor the specific choice of the parameter \\(a=\\mu/\\sigma^{2}\\), we recover the PDF of a Gaussian random variable with mean \\(0\\). But, we can deduce more. The new PDF is also Gaussian. This was not the case for uniform random variables. In fact, the new PDF is exactly the same as the one of \\(X-\\mu\\). For if, \\(a=\\mu/\\sigma^{2}\\), we have:\n\\[\\begin{aligned}\n\\tilde{\\mathbb{E}}[X] & =\\frac{1}{\\sqrt{2\\pi}\\sigma}\\int_{-\\infty}^{\\infty}x\\exp\\left[-\\frac{x^{2}}{2\\sigma^{2}}\\right]dx\n\\end{aligned}\\]\nand observe that if \\(Y=X-\\mu\\), then:\n\\[\\begin{aligned}\nF_{Y}(x) & =\\mathbb{P}(X-\\mu&lt;x)\\\\\n& =\\mathbb{P}(X\\leq x+\\mu)\\\\\n& =F_{X}(x+\\mu)\\\\\n\\frac{d}{dx}(F_{Y}(x)) & =\\frac{d}{dx}(F_{X}(x+\\mu))\\\\\nf_{Y}(x) & =f_{X}(x+\\mu)\\cdot\\frac{d}{dx}(x+\\mu)\\\\\nf_{Y}(x) & =f_{X}(x+\\mu)\\\\\n& =\\frac{1}{\\sqrt{2\\pi}\\sigma}\\exp\\left[-\\frac{1}{2}\\left(\\frac{x+\\mu-\\mu}{\\sigma}\\right)^{2}\\right]\\\\\n& =\\frac{1}{\\sqrt{2\\pi}\\sigma}\\exp\\left[-\\frac{x^{2}}{2\\sigma^{2}}\\right]\n\\end{aligned}\\]\nIn other words:\nFor Gaussians, changing the mean by recentering is equivalent to changing the probability as in Equation 1.\n\nVisualization\nLet \\(X\\) be gaussian with mean \\(\\mu=1\\) and variance \\(\\sigma^2 = 1\\). The PDF of \\(X\\) is:\n\n\nShow the code\n%%itikz --temp-dir --tex-packages=tikz,pgfplots --tikz-libraries=arrows --implicit-standalone\n\\begin{tikzpicture}[scale=1.5]\n\\begin{axis}[xlabel = $x$, ylabel={$f_X(x)$}, title={The PDF of $X \\sim \\mathcal{N}^{P}(\\mu=1,\\sigma^2=1)$},domain=-3:3]\n\\addplot[color=black,samples=100]{1/(sqrt(2*3.14))*exp(-0.5*((x-1)*(x-1))};\n\\end{axis}\n\\end{tikzpicture}\n\n\n\n\n\nI choose \\(g(x) = \\frac{e^{ax}}{\\mathbb{E}[e^{aX}]} = \\frac{e^{ax}}{e^{\\mu a + \\frac{1}{2}a^2 \\sigma^2}}\\), \\(\\mu=1\\), \\(\\sigma^2 = 1\\) and set the value of the parameter \\(a = \\frac{\\mu}{\\sigma^2} = -1\\).\n\n\nShow the code\n%%itikz --temp-dir --tex-packages=tikz,pgfplots --tikz-libraries=arrows --implicit-standalone\n\\begin{tikzpicture}[scale=1.5]\n\\begin{axis}[xlabel = $x$, ylabel={$g(x)$}, title={The density scaling $g(x)=\\frac{e^{ax}}{E[e^{ax}]}$, with parameter value $a=-\\frac{\\mu}{\\sigma^2}$},domain=-3:3]\n\\addplot[color=black,samples=100]{exp(-x)/exp(-0.5)};\n\\end{axis}\n\\end{tikzpicture}\n\n\n\n\n\nThe new density \\(\\tilde{f}_X(x)\\) obtained multiplying \\(f_X(x)\\) by the weights \\(g(x)\\) is the same as a gaussian centered at \\(0\\) with variance \\(1\\) :\n\n\nShow the code\n%%itikz --temp-dir --tex-packages=tikz,pgfplots --tikz-libraries=arrows --implicit-standalone\n\\begin{tikzpicture}[scale=1.5]\n\\begin{axis}[xlabel = $x$, ylabel={$\\tilde{f}_X(x)$}, title={The new PDF of $X$, after multiplying the density ${f}_X(x)$ by weights $g(x)$.},domain=-3:3]\n\\addplot[color=black,samples=100]{1/(sqrt(2*3.14))*exp(-0.5*(x*x))};\n\\end{axis}\n\\end{tikzpicture}\n\n\n\n\n\n\n\nThis is a very special property of the Gaussian distribution. The exponential and Poisson distributions have a similar property.\nIntuitively, if we have a brownian motion with a drift \\(dX_t = \\mu dt + dB_t\\), we can apply this idea to each time-slice \\((X_t - X_s)\\) of the process, we can recenter the gaussians to have mean \\(0\\), so the paths are driftless and it has the same distribution as a standard brownian motion."
  },
  {
    "objectID": "posts/girsanov-theorem/index.html#change-of-probability-measure",
    "href": "posts/girsanov-theorem/index.html#change-of-probability-measure",
    "title": "A gentle introduction to the Girsanov Theorem - Back to the basics",
    "section": "Change of probability measure",
    "text": "Change of probability measure\nExample 2 is very important and we will state it as a theorem. Before doing so, we notice that the change of PDF (Equation 1) can be expressed more generally by changing the underlying probability measure(length, area, weights) \\(\\mathbb{P}\\) on the sample space \\(\\Omega\\) on which the random variables are defined. More precisely, let \\((\\Omega,\\mathcal{F},\\mathbb{P})\\) be a probability space, and let \\(X\\) be a random variable defined on \\(\\Omega\\). We define a new probability \\(\\tilde{\\mathbb{P}}\\) on \\(\\Omega\\) as follows:\nIf \\(\\mathcal{E}\\) is an event in \\(\\mathcal{F}\\), then:\n\\[\\begin{aligned}\n\\mathbb{\\tilde{P}}(\\mathcal{E}) & =\\mathbb{\\tilde{E}}[1_{\\mathcal{E}}]=\\int_{\\mathbf{R}}1_{\\mathcal{E}}\\cdot\\tilde{f}(x)dx\\nonumber \\\\\n& =\\int_{\\mathbf{R}}1_{\\mathcal{E}}\\cdot g(x)f_{X}(x)dx\\nonumber \\\\\n& =\\int_{\\mathbf{R}}1_{\\mathcal{E}}\\cdot\\frac{e^{ax}}{\\mathbb{E}[e^{aX}]}f_{X}(x)dx\\nonumber \\\\\n& =\\mathbb{E}\\left[1_{\\mathcal{E}}\\frac{e^{aX}}{\\mathbb{E}[e^{aX}]}\\right]\n\\end{aligned}\\]\nIntuitively, we are changing the probability of each outcome \\(\\omega\\in\\mathcal{E}\\), by the factor\n\\[\n\\begin{aligned}\n\\frac{e^{aX(\\omega)}}{\\mathbb{E}[e^{aX}]}\n\\end{aligned}\n\\tag{2}\\]\nIn other words, if \\(a&gt;0\\), the outcomes \\(\\omega\\) for which \\(X\\) has large values are favored. Note that equation (Equation 1) for the PDF is recovered, since for any function \\(h\\) of \\(X\\), we have:\n\\[\\begin{aligned}\n\\tilde{\\mathbb{E}}[h(X)] & =\\mathbb{E}\\left[\\frac{e^{aX}}{\\mathbb{E}[e^{aX}]}h(X)\\right]\\\\\n& =\\int_{\\mathbf{R}}h(x)\\frac{e^{ax}}{\\mathbb{E}[e^{aX}]}f_{X}(x)dx\n\\end{aligned}\\]\nIn this setting, the above example becomes the preliminary version of the Cameron-Martin-Girsanov theorem:\n\nTheorem 1 (Change of probability for a random variable) Let \\(X\\) be a Gaussian random variable with mean \\(\\mu\\) and variance \\(\\sigma^{2}\\) defined on \\((\\Omega,\\mathcal{F},\\mathbb{P})\\). Then, under the probability \\(\\mathbb{\\tilde{P}}\\) given by:\n\\[\\begin{aligned}\n\\mathbb{\\tilde{P}}(\\mathcal{E}) & =\\mathbb{E}\\left[1_{\\mathcal{E}}e^{-\\frac{\\mu}{\\sigma^{2}}X+\\frac{1}{2}\\frac{\\mu^{2}}{\\sigma^{2}}}\\right],\\quad\\mathcal{E}\\in\\mathcal{F}\n\\end{aligned} \\tag{3}\\]\nthe random variable \\(X\\) is Gaussian with mean \\(0\\) and variance \\(\\sigma^{2}\\).\nMoreover, since \\(X\\) can be written as \\(X=Y+\\mu\\) where \\(Y\\) is Gaussian with mean \\(0\\) and variance \\(\\sigma^{2}\\) under \\(\\mathbb{P}\\), we have that \\(\\mathbb{\\tilde{P}}\\) can be written as:\n\\[\\begin{aligned}\n\\mathbb{\\tilde{P}}(\\mathcal{E}) & =\\mathbb{E}\\left[1_{\\mathcal{E}}e^{-\\frac{\\mu}{\\sigma^{2}}Y-\\frac{1}{2}\\frac{\\mu^{2}}{\\sigma^{2}}}\\right],\\quad\\mathcal{E}\\in\\mathcal{F}\n\\end{aligned} \\tag{4}\\]\n\nIt is good to pause for a second and look at the signs in the exponential of equations (Equation 3) and (Equation 4). The signs in the exponential might be very confusing and is the source of many mistakes in the Cameron-Martin-Girsanov theorem. A good trick is to say that, if we want to remove \\(\\mu\\), then the sign in front of \\(X\\) or \\(Y\\) must be negative. Then, we add the exponential factor needed for \\(\\tilde{\\mathbb{P}}\\) to be a probability. This is given by the MGF of \\(X\\) or \\(Y\\) depending on how we want to express it.\nThe probabilities \\(\\mathbb{P}\\) and \\(\\tilde{\\mathbb{P}}\\), as defined in the equation (Equation 3) are obviously not equal since they differ by a factor in (Equation 2). However, they share some similarities. Most notably, if \\(\\mathcal{E}\\) is an event of positive \\(\\mathbb{P}\\)-probability, \\(\\mathbb{P}(\\mathcal{E})&gt;0\\), then we must have \\(\\tilde{\\mathbb{P}}(\\mathcal{E})&gt;0\\), since the factor in () is always strictly positive. The converse is also true: if \\(\\mathcal{E}\\) is an event of positive \\(\\tilde{\\mathbb{P}}\\)-probability, \\(\\tilde{\\mathbb{P}}(\\mathcal{E})&gt;0\\), then we must have that \\(\\mathbb{P}(\\mathcal{E})&gt;0\\). This is because the factor in (Equation 2) can be inverted, being strictly positive. More precisely, we have:\n\\[\\begin{aligned}\n\\mathbb{P}(\\mathcal{E}) & =\\mathbb{E}[1_{\\mathcal{E}}]\\\\\n& =\\mathbb{E}\\left[1_{\\mathcal{E}}\\frac{e^{aX(\\omega)}}{\\mathbb{E}[e^{aX}]}\\left(\\frac{e^{aX(\\omega)}}{\\mathbb{E}[e^{aX}]}\\right)^{-1}\\right]\\\\\n& =\\tilde{\\mathbb{E}}\\left[1_{\\mathcal{E}}\\left(\\frac{e^{aX(\\omega)}}{\\mathbb{E}[e^{aX}]}\\right)^{-1}\\right]\n\\end{aligned}\\]\nThe factor \\(\\left(\\frac{e^{aX(\\omega)}}{\\mathbb{E}[e^{aX}]}\\right)^{-1}\\) is also strictly positive, proving the claim. To sum it all up, the probabilities \\(\\mathbb{P}\\) and \\(\\tilde{\\mathbb{P}}\\) essentially share the same possible outcomes. Such probability measures are said to be equivalent measures.\n\nDefinition 1 Consider the two probabilities \\(\\mathbb{P}\\) and \\(\\tilde{\\mathbb{P}}\\) on \\((\\Omega,\\mathcal{F})\\). They are said to be equivalent, if for any event \\(\\mathcal{E}\\in\\mathcal{F}\\), we have \\(\\mathbb{P}(\\mathcal{E})&gt;0\\) if and only if \\(\\mathbb{P}(\\mathcal{E})&gt;0\\). Thus, \\(\\mathbb{P}\\) and \\(\\tilde{\\mathbb{P}}\\) agree on the null sets. If \\(A\\in\\mathcal{F}\\) is such that \\(\\mathbb{P}(A)=0\\), then \\(\\mathbb{\\tilde{P}}(A)=0\\) and vice-versa.\n\nKeep in mind that two probabilities that are equivalent might still be very far from being equal!"
  },
  {
    "objectID": "posts/girsanov-theorem/index.html#the-cameron-martin-theorem.",
    "href": "posts/girsanov-theorem/index.html#the-cameron-martin-theorem.",
    "title": "A gentle introduction to the Girsanov Theorem - Back to the basics",
    "section": "The Cameron-Martin Theorem.",
    "text": "The Cameron-Martin Theorem.\n\nTheorem 2 (Cameron-Martin Theorem for constant drift.) Let \\((\\tilde{B(t)},t\\in[0,T])\\) be a \\(\\mathbb{P}-\\)Brownian motion with constant drift \\(\\theta\\) defined on \\((\\Omega,\\mathcal{F},\\mathbb{P})\\). Consider the probability \\(\\tilde{\\mathbb{P}}\\)on \\(\\Omega\\) given by:\n\\[\\begin{aligned}\n\\tilde{\\mathbb{P}}(\\mathcal{E}) & =\\mathbb{E}\\left[e^{-\\theta\\tilde{B}(T)+\\frac{\\theta^{2}}{2}T}1_{\\mathcal{E}}\\right],\\quad\\mathcal{E}\\in\\mathcal{F}\n\\end{aligned} \\tag{5}\\]\nThen, the process \\((\\tilde{B}(t),t\\in[0,T])\\) under \\(\\mathbb{\\tilde{P}}\\)is distributed like a standard brownian motion. Moreover, since we can write \\(\\tilde{B_{t}}=\\theta t+B_{t}\\) for some standard brownian motion \\((B_{t},t\\in[0,T])\\) on \\((\\Omega,\\mathcal{F},\\mathbb{P})\\), the probability \\(\\tilde{\\mathbb{P}}\\) can also be written as:\n\\[\\begin{aligned}\n\\tilde{\\mathbb{P}}(\\mathcal{E}) & =\\mathbb{E}\\left[e^{-\\theta B(T)-\\frac{\\theta^{2}}{2}T}1_{\\mathcal{E}}\\right]\n\\end{aligned} \\tag{6}\\]\n\nIt is a good idea to pause again and look at the signs in the exponential in equations (Equation 5) and (Equation 6). They behave the same way as in Theorem 1. There is a minus sign in front of \\(B_{T}\\) to remove the drift. Before proving the theorem, we make some important remarks.\n(1) The end-point. Note that only the endpoint \\(\\tilde{B}(T)\\) of the Brownian motion is involved in the change of probability. In particular, \\(T\\) cannot be \\(+\\infty\\). The Cameron-Martin theorem can only be applied on a finite interval.\n(2) A martingale. The factor \\(M_{T}=e^{-\\theta B(T)-\\frac{\\theta^{2}}{2}T}=e^{-\\theta\\tilde{B}(T)+\\frac{1}{2}\\theta^{2}T}\\) involved in the change of probability is the end-point of a \\(\\mathbb{P}-\\)martingale, that is, it is a martingale under the original probability \\(\\mathbb{P}\\). To see this:\n\\[\\begin{aligned}\n\\mathbb{E}[M_{T}|\\mathcal{F}_{t}] & =\\mathbb{E}\\left[e^{-\\theta B(T)-\\frac{1}{2}\\theta^{2}T}|\\mathcal{F}_{t}\\right]\\\\\n& =e^{-\\theta B(t)}\\mathbb{E}\\left[e^{-\\theta(B(T)-B(t))}|\\mathcal{F}_{t}\\right]e^{-\\frac{\\theta^{2}}{2}T}\\\\\n& \\{\\text{Using }B(T)-B(t)\\perp\\mathcal{F}_{t}\\}\\\\\n& =e^{-\\theta B(t)}\\mathbb{E}\\left[e^{-\\theta(B(T)-B(t))}\\right]e^{-\\frac{\\theta^{2}}{2}T}\\\\\n& =e^{-\\theta B(t)}e^{\\frac{\\theta^{2}}{2}(T-t)}e^{-\\frac{\\theta^{2}}{2}T}\\\\\n& =e^{-\\theta B(t)-\\frac{\\theta^{2}}{2}t}\n\\end{aligned}\\]\nIn fact, since \\(B(t)\\) is a \\(\\mathbb{P}\\)-standard Brownian motion, \\(M(t)=e^{-\\theta B(t)-\\frac{\\theta^{2}}{2}t}\\) is a geometric brownian motion.\nInterestingly, the drift of \\(\\tilde{B}(t)\\) becomes the volatility factor in \\(M_{T}\\)! \\(\\mathbb{E}[M_{T}^{2}]=\\mathbb{E}[e^{-2\\theta B(T)-\\theta^{2}T}]=e^{-\\theta^{2}T}\\cdot\\mathbb{E}[e^{-2\\theta B(T)}]=e^{-\\theta^{2}T}\\cdot e^{2\\theta^{2}T}=e^{\\theta^{2}T}\\).\nThe fact that \\(M(t)\\) is a martingale is very helpful in calculations. Indeed, suppose we want to compute the expectation of a function \\(F(\\tilde{B}(s))\\) of a Brownian motion with drift at time \\(s&lt;T\\). Then, we have by Theorem 2:\n\\[\\begin{aligned}\n\\mathbb{E}[F(\\tilde{B}(s))] & =\\mathbb{E}[M_{T}M_{T}^{-1}F(\\tilde{B}(s))]\\\\\n& =\\tilde{\\mathbb{E}}[M_{T}^{-1}F(\\tilde{B}(s))]\\\\\n& =\\tilde{\\mathbb{E}}[e^{\\theta\\tilde{B}(T)-\\frac{1}{2}\\theta^{2}T}F(\\tilde{B}(s))]\n\\end{aligned}\\]\nNow, we know that under \\(\\tilde{\\mathbb{P}}\\)probability, \\((\\tilde{B}(t),t\\in[0,T])\\) is a standard brownian motion, or \\(\\tilde{\\mathbb{P}}\\)-standard brownian motion for short. Therefore, the process \\(e^{\\theta\\tilde{B}(t)-\\frac{1}{2}\\theta^{2}t}\\) is a martingale under the new probability measure \\(\\tilde{\\mathbb{P}}\\), or a \\(\\tilde{\\mathbb{P}}\\)-martingale for short. By conditioning over \\(\\mathcal{F}_{s}\\) and applying the martingale property, we get:\n\\[\\begin{aligned}\n\\mathbb{E}\\left[F(\\tilde{B}_{s})\\right] & =\\tilde{\\mathbb{E}}[e^{\\theta\\tilde{B}(T)-\\frac{1}{2}\\theta^{2}T}F(\\tilde{B}(s))]\\\\\n& =\\tilde{\\mathbb{E}}[\\tilde{\\mathbb{E}}[e^{\\theta\\tilde{B}(T)-\\frac{1}{2}\\theta^{2}T}F(\\tilde{B}(s))|\\mathcal{F}_{s}]]\\\\\n& =\\tilde{\\mathbb{E}}[e^{\\theta\\tilde{B}(s)-\\frac{1}{2}\\theta^{2}s}F(\\tilde{B}(s))]\\\\\n& =\\mathbb{E}[e^{\\theta B(s)-\\frac{1}{2}\\theta^{2}s}F(B(s))]\n\\end{aligned}\\]\nThe last equality may seem wrong as removed all the tildes. It is not! It holds because \\((\\tilde{B}(t))\\) under \\(\\tilde{\\mathbb{P}}\\) has the same distribution as \\((B(t))\\) under \\(\\mathbb{P}\\): a standard brownian motion. Of course, it would be possible to directly evaluate \\(\\mathbb{E}[F(\\tilde{B}(s))]\\) here as we know the distribution of a Brownian motion with drift. However, when the function will involve more than one point (such as the maximum of the path), the Cameron-Martin theorem is a powerful tool to evaluate expectations.\n(3) The paths with or without the drift are the same. Let \\((B(t),t\\leq T)\\) be a standard Brownian motion defined on \\((\\Omega,\\mathcal{F},\\mathbb{P})\\). Heuristically, it is fruitful to think of the sample space of \\(\\Omega\\) as the different continuous paths of Brownian motion. Since, the change of probability from \\(\\mathbb{P}\\) to \\(\\tilde{\\mathbb{P}}\\)simply changes the relative weights of the paths (and this change of weight is never zero, similarly to equation ([eq:girsanov-probability-scaling]) for a single random variable), the theorem suggests that the paths of a standard Brownian motion and those of a Brownian motion with a constant drift \\(\\theta\\) (with volatility \\(1\\)) are essentially the same.\nThe form of the factor \\(M_{T}=e^{-\\theta\\tilde{B}_{T}+\\theta^{2}T}\\) can be easily understood at the heuristic level. For each outcome \\(\\omega\\), it is proportional to \\(e^{-\\theta\\tilde{B}_{T}(\\omega)}\\) (The term \\(e^{(\\theta^{2}/2)T}\\) is simply to ensure that \\(\\mathbb{P}(\\Omega)=1\\)) Therefore, the factor \\(M_{T}\\) penalizes the paths for which \\(\\tilde{B}_{T}(\\omega)\\) is large and positive (if \\(\\theta&gt;0\\)). In particular, it is conceivable that the Brownian motion with positive drift is reduced to standard Brownian motion under the new probability.\n(4) Changing the volatility. What about the volatility? Is it possible to change the probability \\(\\mathbb{P}\\) to \\(\\tilde{\\mathbb{P}}\\) in such a way that the Brownian motion under \\(\\mathbb{P}\\) has volatility \\(\\sigma\\neq1\\) under \\(\\tilde{\\mathbb{P}}\\)? The answer is no! The paths of the Brownian motions with different volatilities are inherently different. Indeed, it suffices to compute the quadratic variation. If \\((B_{t}:t\\in[0,T])\\) has volatility \\(1\\) and \\((\\tilde{B_{t}},t\\in[0,T])\\) has volatility \\(2\\). then the following convergence holds for \\(\\omega\\) in a set of probability one (for a partition fine enough, say \\(t_{j+1}-t_{j}=2^{-n}\\). Then \\(B_{t}=\\int1\\cdot dB_{t}\\) and \\(\\tilde{B_{t}}=\\int2\\cdot dB_{t}\\)\n\\[\\begin{aligned}\n\\lim_{n\\to\\infty}\\sum_{j=0}^{n-1}(B_{t_{j+1}}(\\omega)-B_{t_{j}}(\\omega))^{2} & =\\int_{0}^{T}1^{2}\\cdot ds=T\n\\end{aligned}\\]\n\\[\\begin{aligned}\n\\lim_{n\\to\\infty}\\sum_{j=0}^{n-1}(\\tilde{B}_{t_{j+1}}(\\omega)-\\tilde{B}_{t_{j}}(\\omega))^{2} & =\\int_{0}^{T}2^{2}\\cdot ds=4T\n\\end{aligned}\\]\nIn other words, the distribution of the standard brownian motion on \\([0,T]\\) is supported on paths whose quadratic variation is \\(T\\), whereas the distribution of \\((\\tilde{B}_{t},t\\geq0)\\) is supported on paths where the quadratic variation is \\(4T\\). These paths are very different. We conclude that the distributions of the two processes are not equivalent. Hence, a change of probability from \\(\\mathbb{P}\\) to \\(\\mathbb{\\tilde{P}}\\) is not possible. In fact, we say that they are mutually singular, meaning the set of paths on which they are supported are disjoint.\nProof.\nLet \\((\\tilde{B}_{t}:t\\in[0,T])\\) be a Brownian motion with constant drift \\(\\theta\\) defined on \\((\\Omega,\\mathcal{F},\\mathbb{P})\\). Thus, \\(\\tilde{B}_{t}=\\theta t+B_{t}\\).\nClaim. \\(\\tilde{B}_{t}\\) is a \\(\\mathbb{\\tilde{P}}\\)-martingale.\nLet\n\\[\\begin{aligned}\nM_{t} & =f(t,B_{t})=\\exp(-\\theta B_{t}-(\\theta^{2}/2)t)\n\\end{aligned}\\]\nSo:\n\\[\\begin{aligned}\ndM_{t} & =-\\frac{\\theta^{2}}{2}M_{t}dt-\\theta M_{t}dB_{t}+\\frac{1}{2}\\theta^{2}M(t)dt\\\\\n& =-\\theta M_{t}dB_{t}\n\\end{aligned}\\]\nConsider the product \\((M_{t}\\tilde{B}_{t})\\). We have:\n\\[\\begin{aligned}\nd(M_{t}\\tilde{B}_{t}) & =\\tilde{B}_{t}dM_{t}+M_{t}d\\tilde{B}_{t}+dM_{t}\\cdot d\\tilde{B}_{t}\\\\\n& =-\\tilde{B}_{t}\\theta M_{t}dB_{t}+M_{t}(\\theta dt+dB_{t})-\\theta M_{t}dB_{t}(\\theta dt+dB_{t})\\\\\n& =-\\tilde{B}_{t}\\theta M_{t}dB_{t}+\\theta M_{t}dt+M_{t}dB_{t}-\\theta M_{t}dt\\\\\n& =(-\\tilde{B}_{t}\\theta+1)M_{t}dB_{t}\n\\end{aligned}\\]\nThus, by the properties of Ito integral,\\(M_{t}\\tilde{B}_{t}\\) is a martingale under \\(\\mathbb{P}\\). By the abstract Bayes formula ([th:abstract-bayes-formula]):\n\\[\\begin{aligned}\n\\tilde{\\mathbb{E}}[\\tilde{B}_{t}|\\mathcal{F}_{s}] & =\\frac{1}{M_{s}}\\mathbb{E}[M_{t}\\tilde{B}_{t}|\\mathcal{F}_{s}]\\\\\n& =\\frac{1}{M_{s}}\\cdot M_{s}\\tilde{B}_{s}\\\\\n& =\\tilde{B}_{s}\n\\end{aligned}\\]\nThus, \\(\\tilde{B}_{t}\\) is a \\(\\tilde{\\mathbb{P}}\\)-martingale.\nClaim. Our claim is that under the \\(\\tilde{\\mathbb{P}}\\) measure, \\(\\tilde{B}_{t}\\sim\\mathcal{N}^{\\mathbb{\\tilde{P}}}(0,t)\\) and to do this we rely on the the moment-generating function.\nBy definition, for a constant \\(\\Psi\\):\n\\[\\begin{aligned}\nM_{\\tilde{B}_{t}}(\\Psi) & =\\tilde{\\mathbb{E}}\\left[\\exp\\left(\\Psi\\tilde{B}_{t}\\right)\\right]\\\\\n& =\\mathbb{E}\\left[M_{T}\\exp\\left(\\Psi\\tilde{B}_{t}\\right)\\right]\\\\\n& =\\mathbb{E}\\left[\\exp\\left(-\\theta\\tilde{B}_{T}+\\frac{\\theta^{2}}{2}T+\\Psi\\tilde{B}_{t}\\right)\\right]\\\\\n& =\\mathbb{E}\\left[\\exp\\left(-\\theta(\\theta T+B_{T})+\\frac{\\theta^{2}}{2}T+\\Psi(\\theta t+B_{t})\\right)\\right]\\\\\n& =\\mathbb{E}\\left[\\exp\\left(-\\theta B_{T}-\\frac{\\theta^{2}}{2}T+\\Psi\\theta t+\\Psi B_{t})\\right)\\right]\\\\\n& =\\mathbb{E}\\left[\\exp\\left(-\\theta(B_{T}-B_{t})-\\frac{\\theta^{2}}{2}T+\\Psi\\theta t+(\\Psi-\\theta)B_{t})\\right)\\right]\\\\\n& =\\exp\\left(-\\frac{\\theta^{2}}{2}T+\\Psi\\theta t\\right)\\mathbb{E}\\left(-\\theta(B_{T}-B_{t})\\right)\\mathbb{E}\\left((\\Psi-\\theta)B_{t}\\right)\\\\\n& =\\exp\\left(-\\frac{\\theta^{2}}{2}T+\\Psi\\theta t\\right)\\exp\\left[\\frac{1}{2}\\theta^{2}(T-t)\\right]\\exp\\left[\\frac{1}{2}(\\Psi-\\theta)^{2}t\\right]\\\\\n& =\\exp\\left[-\\frac{1}{2}\\left(\\theta^{2}-2\\Psi\\theta-(\\Psi-\\theta)^{2}\\right)t\\right]\\\\\n& =\\exp\\left[-\\frac{1}{2}\\left(\\theta^{2}-2\\Psi\\theta-(\\Psi^{2}-2\\Psi\\theta+\\theta^{2}\\right)t\\right]\\\\\n& =\\exp(-\\Psi^{2}t)\n\\end{aligned}\\]\nThus, \\(\\tilde{B}_{t}\\sim\\mathcal{N}^{\\tilde{\\mathbb{P}}}(0,t)\\).\nClaim. Finally, to show that \\(\\tilde{B}_{t}\\) is indeed a \\(\\mathbb{\\tilde{P}}-\\)standard brownian motion, we have the following:\n(a) \\(\\tilde{B}_{0}=\\theta(0)+B_{0}=0\\) and \\(\\tilde{B}_{t}\\) has almost surely continuous paths.\n(b) We would like to prove that, for \\(s&lt;t\\), \\(\\tilde{B}_{t}-\\tilde{B}_{s}\\sim\\mathcal{N}^{\\tilde{\\mathbb{P}}}(0,t-s)\\). We have:\n\\[\\begin{aligned}\n\\mathbb{E}[\\tilde{B}_{t}-\\tilde{B}_{s}] & =\\tilde{\\mathbb{E}}[\\tilde{B}_{t}]-\\tilde{\\mathbb{E}}[B_{s}]\\\\\n& =0\n\\end{aligned}\\]\nAnd,\n\\[\\begin{aligned}\n\\tilde{\\mathbb{E}}[(\\tilde{B}_{t}-\\tilde{B}_{s})^{2}] & =\\tilde{\\mathbb{E}}[\\tilde{B}_{t}^{2}-2\\tilde{B}_{t}\\tilde{B}_{s}+\\tilde{B}_{s}^{2}]\\\\\n& =\\tilde{\\mathbb{E}}[B_{t}^{2}]-2\\tilde{\\mathbb{E}}[\\tilde{B}_{t}\\tilde{B}_{s}]+\\tilde{\\mathbb{E}}[\\tilde{B}_{s}^{2}]\\\\\n& =t+s-2\\tilde{\\mathbb{E}}[\\tilde{B}_{t}\\tilde{B}_{s}]\n\\end{aligned}\\]\n(c) The non-overlapping increments of a \\(\\tilde{\\mathbb{P}}\\)-martingale are independent. To see this, suppose \\(t_{1}\\leq t_{2}\\leq t_{3}\\):\n\\[\\begin{aligned}\n\\tilde{\\mathbb{E}}[(B_{t_{3}}-B_{t_{2}})(B_{t_{2}}-B_{t_{1}})] & =\\tilde{\\mathbb{E}}[\\tilde{\\mathbb{E}}[(B_{t_{3}}-B_{t_{2}})(B_{t_{2}}-B_{t_{1}})|\\mathcal{F}_{t_{2}}]]\\\\\n& =\\tilde{\\mathbb{E}}[(B_{t_{2}}-B_{t_{1}})\\tilde{\\mathbb{E}}[(B_{t_{3}}-B_{t_{2}})|\\mathcal{F}_{t_{2}}]]\\\\\n& =\\tilde{\\mathbb{E}}[(B_{t_{2}}-B_{t_{1}})(B_{t_{2}}-B_{t_{2}})]]=0\n\\end{aligned}\\]\nAlso, the covariance\n\\[\\begin{aligned}\n\\tilde{\\mathbb{E}}[\\tilde{B}_{t}\\tilde{B}_{s}] & =\\tilde{\\mathbb{E}}[(\\tilde{B}_{t}-\\tilde{B}_{s})\\tilde{B}_{s}]+\\tilde{\\mathbb{E}}[\\tilde{B}_{s}^{2}]\\\\\n& =0+s\n\\end{aligned}\\]\nSo, \\(\\mathbb{E}[(\\tilde{B}_{t}-\\tilde{B}_{s})^{2}]=t+s-2s=t-s\\).\nConsequently, \\(\\tilde{B}_{t}\\) is a \\(\\tilde{\\mathbb{P}}\\)-standard brownian motion."
  },
  {
    "objectID": "posts/interpolation-and-approximation/index.html",
    "href": "posts/interpolation-and-approximation/index.html",
    "title": "Interpolation and Approximation",
    "section": "",
    "text": "In this blog post, I would like to implement some interpolation algorithms using modern C++. It’s important we understand how and why these algorithms work. Because there are nuances, exceptions and corner-cases, we need to understand. It’s a great learning experience! You never fully understand something like the \\(QR\\)-algorithm (which is actually incredibly complicated to get the details right), unless you spend some time implementing it. A lot of the skills you pick up will translate when you write numerical codes.\nEven if you have excellent implementations of any algorithm, you still need to understand some of the internals in order to make good use of your library. For example, any linear algebra library can compute an inverse matrix really fast and as accurately as mathematics allows. But, you have to know a little theory in order to know that you should still avoid using that if at all possible. (Matrix decomposition and solving without explicitly computing the inverse is better, generally speaking)."
  },
  {
    "objectID": "posts/interpolation-and-approximation/index.html#introduction",
    "href": "posts/interpolation-and-approximation/index.html#introduction",
    "title": "Interpolation and Approximation",
    "section": "",
    "text": "In this blog post, I would like to implement some interpolation algorithms using modern C++. It’s important we understand how and why these algorithms work. Because there are nuances, exceptions and corner-cases, we need to understand. It’s a great learning experience! You never fully understand something like the \\(QR\\)-algorithm (which is actually incredibly complicated to get the details right), unless you spend some time implementing it. A lot of the skills you pick up will translate when you write numerical codes.\nEven if you have excellent implementations of any algorithm, you still need to understand some of the internals in order to make good use of your library. For example, any linear algebra library can compute an inverse matrix really fast and as accurately as mathematics allows. But, you have to know a little theory in order to know that you should still avoid using that if at all possible. (Matrix decomposition and solving without explicitly computing the inverse is better, generally speaking)."
  },
  {
    "objectID": "posts/interpolation-and-approximation/index.html#the-interpolation-problem",
    "href": "posts/interpolation-and-approximation/index.html#the-interpolation-problem",
    "title": "Interpolation and Approximation",
    "section": "The Interpolation Problem",
    "text": "The Interpolation Problem\nPolynomials are used as the basic means of approximation and are ubiquitous in nearly all areas of computational science.\nLet \\(a=x_1 &lt; x_2 &lt; \\ldots &lt; x_n = b\\) be a grid of distinct points. Let \\(\\mathcal{P}_n\\) be the vector space of of polynomials in one variable with degree \\(\\leq n - 1\\). We are interested to find a polynomial \\(p \\in \\mathcal{P}_n\\) such that:\n\\[\n\\begin{align*}\np(x_i) = f(x_i), \\quad i = 1 : n\n\\end{align*}\n\\tag{1}\\]\n\nTheorem 1 (Uniqueness of the interpolating polynomial) If \\(x_1,\\ldots,x_n\\) are distinct real numbers, then for arbitrary values \\(y_1,\\ldots,y_n\\), there is a unique polynomial \\(p\\in \\mathcal{P}_{n}\\) of degree at most \\(n-1\\) such that:\n\\[p(x_i) = y_i,  \\quad i = 1 : n\\]\n\nProof.\nSuppose that there were two such polynomials \\(p\\) and \\(q\\). Then, the polynomial \\(p-q\\) would have the property \\((p-q)(x_i)=0\\) for \\(1 \\leq i \\leq n\\). Since, the degree of \\((p-q)\\) can be at most \\(n-1\\), this polynomial can have atmost \\((n-1)\\) zeroes, if is not the \\(0\\) polynomial. Since the \\(x_i\\)’s are distinct, it follows that:\n\\[\n(p-q)(x) = (x - x_1)(x - x_2)\\ldots(x-x_n) = \\prod_{i=1}^n (x-x_i)\n\\]\nand it has atleast \\(n\\) zeroes. Hence, \\((p-q)(x)\\equiv 0\\) - it must be identically equal to zero. So, \\(p(x) = q(x)\\) for all \\(x\\). This closes the proof. \\(\\blacksquare\\)\n\nBases for polynomial interpolation\nA set of polynomials \\(\\{p_1(x), p_2(x), \\ldots, p_n(x)\\}\\) such that the polynomial \\(p \\in \\mathcal{P}_n\\) can be expressed as a linear combination :\n\\[\np(x) = \\sum_{j=1} c_j p_j(x)\n\\]\nis called a basis for \\(\\mathcal{P}_n\\). The column vector \\(c=(c_1,c_2,\\ldots,c_n)^T\\) can be viewed as the coordinate vector of \\(p\\) in the polynomial space \\(\\mathcal{P}_n\\). The inerpolation problem leads to a system of equations:\n\\[\n\\begin{align*}\nc_1 p_1(x_i) + c_2 p_2(x_i) + \\ldots + c_n p_n(x_i) = f(x_i), \\quad i=1:n\n\\end{align*}\n\\tag{2}\\]\nIf we introduce the matrix :\n\\[\n\\begin{align*}\nP_n = [p_j(x_i)]_{i,j=1}^n\n\\end{align*}\n\\tag{3}\\]\nand the column vector \\(f=(f(x_1),\\ldots,f(x_n))^T\\), then the linear system becomes:\n\\[\n\\begin{align*}\nP_n c = f\n\\end{align*}\n\\tag{4}\\]\nMathematically, the choice of a basis (for a finite-dimensional space) makes no difference. Computationally, when working with rounded values of coefficients, the choice of basis can make a great difference. If the purpose is to compute derivatives or integrals of the interpolation polynomial, the power basis or the shifted power basis, where \\(p_j(x) = (x - c)^{j-1}\\) that is:\n\\[\np(x)= \\sum_{j=1}^n c_j(x)(x - c)^{j-1}\n\\]\nis convenient although not always the best. If a shifted power basis is to be used for polynomial approximation on an interval \\([a,b]\\), it is often the best to choose \\(c = (a + b)/2\\), equal to the midpoint of the interval.\nFor the power basis \\(p_j(x) = x^{j-1}\\), the coefficients of the interpolation polynomial are given by the solution of the linear system \\(V_n^T c = f\\), where \\(V_n\\) is the Vandermonde matrix\n\\[\nV_n = [x_j^{i-1}]_{i,j=1}^n =\n\\begin{bmatrix}\n1 & 1 & \\ldots & 1\\\\\nx_1 & x_2 & \\ldots & x_n \\\\\n\\vdots & \\vdots & \\ldots & \\vdots\\\\\nx_1^{n-1} & x_2^{n-1} & \\ldots & x_n^{n-1}\n\\end{bmatrix}\n\\tag{5}\\]"
  },
  {
    "objectID": "posts/interpolation-and-approximation/index.html#piecewise-polynomial-interpolation",
    "href": "posts/interpolation-and-approximation/index.html#piecewise-polynomial-interpolation",
    "title": "Interpolation and Approximation",
    "section": "Piecewise Polynomial Interpolation",
    "text": "Piecewise Polynomial Interpolation\nInterpolating a given function by a single polynomial over its entire range can be an ill-conditioned problem, as illustrated by Runge’s phenomenon. On the other hand, polynomials of low degree can give good approximations locally in a small interval. I would like to discuss approximation schemes for piecewise polynomial interpolation with different degrees of global continuity.\nWith the use of piecewise polynomials, there is no reason to fear equidistant data, as opposed to the situation with higher-degree polynomials. In computer graphics and computer-aided design(CAD), curves and surfaces have to be represented mathematically, so that they can be manipulated and visualized easily. In 1962, Bezier and de Casteljau, working for French car companies Renault and Citroen, independently developed Bezier curves for fitting curves and surfaces. Similar work, using bicubic splines, was done in USA at general motors by Garret Birkhoff and Henry Garabedian.\nToday, Bezier curves and spline functions are used extensively in all aircraft and automotive industries. Spline functions can also be used in the numerical treatment of boundary value problems for differential equations. Bezier curves have found use in computer graphics and typography. Trutype font glyphs are made of quadratic bezier curves.\n\nBernstein Polynomials and Bezier Curves\nParametric curves are often used find the functional form of a curve given geometrically by a set of points \\(p_i \\in \\mathbf{R}^d\\), \\(i=0:n\\).\nLet \\(c(t) \\in \\mathbf{R}^d\\), \\(t\\in[0,1]\\), be a parameteric curve. In the simplest case, \\(n=1\\), we take \\(c(t)\\) to be linear:\n\\[\nc(t) = (1-t)p_0 + tp_1\n\\]\nand connecting the two points \\(p_0\\) and \\(p_1\\), so that \\(p(0)=c_0\\) and \\(p_1 = c(1)\\). It is the parametric equation for a straight-line.\nFor \\(n &gt; 1\\), this will not give a smooth curve and is therefore of limited interest.\nWe can generalize this approach and take \\(c(t)\\) to be a polynomial of degree \\(n\\):\n\\[\nc(t) =\\sum_{i=0}^{n-1} p_i B_i(t),\\quad t\\in[0,1]\n\\]\nwhere \\(B_i(t)\\), \\(i=0 : n\\) are the Bernstein polynomials defined by :\n\\[\nB_i^{n}(t) = {n \\choose i} t^{i} (1-t)^{n-i}, \\quad i=0:n\n\\]\nUsing the binomial theorem, we have:\n\\[\n1 = ((1-t) + t)^n = \\sum_{i=0}^n {n \\choose i}t^i (1-t)^{n-i} = \\sum_{i=0}^n B_i^{n}(t)\n\\]\nThus, the Bernstein polynomials of degree \\(n\\) are non-negative on \\([0,1]\\) and give a partition of unity.\nFor \\(n=3\\), the four cubic Bernstein polynmials are:\n\\[\n\\begin{align*}\nB_0^3 &= (1-t)^3\\\\\nB_1^3 &= 3(1-t)^2 t\\\\\nB_2^3 &= 3(1-t)t^2\\\\\nB_3^3 &= t^3\n\\end{align*}\n\\]\n\nusing Plots\nusing LaTeXStrings\n\nB₀(t) = (1-t)^3\nB₁(t) = 3*(1-t)^2*t\nB₂(t) = 3*(1-t)*t^2\nB₃(t) = t^3\n\nplot([B₀, B₁, B₂, B₃], 0.0, 1.0, label=[L\"B_0\" L\"B_1\" L\"B_2\" L\"B_3\"])\n\n\n\n\n  \n    \n  \n\n\n\n  \n    \n  \n\n\n\n  \n    \n  \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nSome important properties of the Bernstein polynomials are given in the following theorem.\n\nTheorem 2 (Berstein polynomial properties) The Bernstein polynomials \\(B_i^{n}(t)\\) have the following properties:\n\nNon-negativity: \\(B_i^{n}(t) &gt; 0\\), \\(t\\in(0,1)\\)\nSymmetry: \\(B_i^{n}(t)=B_{n-i}^{n}(1-t)\\)\n\\(B_i^{n}(t)\\) has a root \\(t=0\\) of multiplicity \\(i\\) and a root \\(t=1\\) of multiplicity \\(n-i\\)\nThe Bernstein polynomials \\(B_i^{n}(t)\\) have a unique maximum value at \\(t=i/n\\) on \\([0,1]\\)\nThe Bernstein polynomials satisfy the following recursion formula: \\[\n\\begin{align*}\nB_i^n(t) = (1-t)B_i^{n-1}(t) + tB_{i-1}^{n-1}(t),\\quad i=0:n\n\\end{align*}\n\\tag{6}\\]\n\n\n\nThe Bernstein polynomials of degree \\(n\\) form a basis for the space of polynomials of degree \\(\\leq n\\).\n\nProof.\nNon-negativity: For \\(t\\in[0,1]\\), \\(0&lt;1-t&lt;1\\), so \\(B_i^{n}(t) \\geq 0\\).\nSymmetry: Since \\({n \\choose k} = {n \\choose n-k}\\), we have:\n\\[\nB_k^{n}(t) = {n \\choose k}t^k (1-t)^{n-k} = {n \\choose (n-k)} (1-t)^{n-k} t^k = B_{n-k}^n(1-t)\n\\]\nRoots. By definition, \\(B_k^{n}(t) = {n \\choose k}t^k (1-t)^{n-k}\\) so it has a root \\(t=0\\) with multiplicity \\(k\\) and a root \\(t=1\\) with multiplicity \\((n-k)\\).\nMoreover, differentiating \\(B_k^{n}(t)\\) with respect to \\(t\\), setting the first derivative equal to \\(0\\), we have:\n\\[\n\\begin{align*}\n\\frac{d}{dt}(B_k^{n}(t)) &= {n \\choose k} kt^{k-1} (1-t)^{n-k} - (n-k)t^k(1-t)^{n-k-1} = 0 \\\\\n0 &= k(1-t) - (n-k)t \\\\\n0 &= k - kt - nt + kt \\\\\nnt &= k \\\\\nt &= \\frac{k}{n}\n\\end{align*}\n\\]\nConsider the combinatorial identity:\n\\[\n{n \\choose k} = {n-1 \\choose k} + {n - 1\\choose k - 1}\n\\]\nAssume that we would like to assemble team of size \\(k\\) from a population of size \\(n\\). There are \\({n \\choose k}\\) distinguishable teams. Another way to count is as follows. Label one member of the population as president. Then, there are \\({n - 1 \\choose k}\\) distinguishable teams that always include the president and \\({n - 1 \\choose k - 1}\\) distinct teams excluding the president. The sum must equal \\({n \\choose k}\\).\nWe can use this to prove the recursion formula:\n\\[\n\\begin{align*}\n{n \\choose k}t^k(1-t)^{n-k} &= {n-1 \\choose k}t^k(1-t)^{n-k} + {n - 1\\choose k - 1}t^k(1-t)^{n-k}\\\\\n&= (1-t) {n-1 \\choose k}t^k(1-t)^{n-1-k} + t{n - 1\\choose k - 1}t^{k-1}(1-t)^{(n-1)-(k-1)}\\\\\n&= (1-t)B_{k}^{n-1}(t) + tB_{k-1}^{n-1}(t)\n\\end{align*}\n\\]\nTo show the linear independence, we observe that if:\n\\[\n\\begin{align*}\n\\sum_{i=0}^n a_i B_i^{n}(t) &\\equiv 0\n\\end{align*}\n\\tag{7}\\]\nfor all \\(t \\in [0,1]\\). Then, expanding and substituting \\(t=1\\) in the above expression, we have:\n\\[\n\\begin{align*}\n\\sum_{i=0}^n a_i B_i^{n}(i) &= 0\\\\\na_0 (1-t)^n + a_1 {n \\choose 1} (1-t)^{n-1}t + \\ldots + a_n t^n &= 0\\\\\na_n &= 0\n\\end{align*}\n\\]\nSubstituting \\(a_n = 0\\) in Equation 7, we get:\n\\[\n\\begin{align*}\na_0 (1-t)^n + a_1 {n \\choose 1} (1-t)^{n-1} t + \\ldots + a_{n-1}(1-t)t^{n-1} &= 0\\\\\na_0 (1-t)^{n-1} + a_1 {n \\choose 1} (1-t)^{n-2} t + \\ldots + a_{n-1}t^{n-1} &= 0\n\\end{align*}\n\\]\nAgain, subbing \\(t=1\\), we find that \\(a_{n-1}=0\\). By repeatedly dividing by \\((1-t)\\) and using the same argument, we find that:\n\\[\na_0 = a_1 = \\ldots = a_n = 0\n\\]\nThis closes the proof. \\(\\blacksquare\\)\nThe unique parametric Bezier curve corresponding to a given set of \\(n+1\\) control points \\(p_i\\), \\(i=0:n\\), equals:\n\\[\n\\begin{align*}\nc(t) = \\sum_{i=0}^n p_i B_i^{n}(t), \\quad t\\in[0,1]\n\\end{align*}\n\\tag{8}\\]\nwhere \\(B_i^{n}(t)\\) are Bernstein polynomials of degree \\(n\\). By property 3, in Theorem 2, the Bezier curve interpolates the first and last control points \\(p_0\\) and \\(p_n\\). Often, a curve is constructed by smoothly patching together several Bezier curves of low order.\n\n\nIntuition\n\nThe case \\(n=1\\)\nImagine a particle travelling in a straight line joining the points \\(p_0=(x_0,y_0)\\) and \\(p_1=(x_1,y_1)\\), where the time \\(t\\in[0,1]\\). Let’s compute the position \\(c(t)=(x(t),y(t))\\) of the particle at time \\(t\\). The point \\(c(t)\\) divides the straight-line \\(p_0p_1\\) in the proportion \\(t:(1-t)\\). By the section formula, the position vector of \\(c(t)\\) is:\n\\[\n\\begin{align*}\n(x(t),y(t)) &= ((1-t)x_0 + tx_1, (1-t)y_0 + ty_1)\\\\\n&= (1-t)(x_0,y_0) + t(x_1,y_1)\\\\\n&= (1-t)p_0 + tp_1\n\\end{align*}\n\\]\nThis is the parametric equation of motion of the particle. It is the Bezier curve for \\(n=1\\). The points \\(p_0\\) and \\(p_1\\) control what the straight-line path looks like, so they are called control-points.\n\nusing Plots\nusing LaTeXStrings\n\nfunction bezier_1(t, a, b)\n    @. (1-t)*a + t*b\nend\n\ntvec = range(0.0, 1.0, 101)\npts = [\n    0.0 1.0;\n    1.0 0.0;\n]\n\nx = bezier_1(tvec, pts[1,1], pts[2,1])\ny = bezier_1(tvec, pts[1,2], pts[2,2])\n\n@gif for (xVal, yVal) in zip(x,y)\n    plot(x, y, line=(:path,:dash,:gray))\n    scatter!([xVal], [yVal], marker=(:circle,3,:green,:green))\nend\n\n[ Info: Saved animation to C:\\Data\\dev\\repo\\quantinsights.github.io\\posts\\interpolation-and-approximation\\tmp.gif\n\n\n\n\n\n\n\n\nThe case \\(n=2\\)\nAssume that, we have 3 points \\(p_0=(0.0, 1.0)\\), \\(p_1=(1.3, 1.3)\\) and \\(p_2=(1.0, 0.0)\\). Imagine a red particle \\(p_R\\) moving from \\(p_0\\) towards \\(p_1\\) on a straight-line, a blue particle \\(p_B\\) moving from \\(p_1\\) towards \\(p_2\\). Suppose, a third green particle \\(p_G\\) moves along the straight-line joining the blue and green particles instantaneously:\n\n\nShow the code\nfunction bezier_2(t, a, b, c)\n    @. (1-t)^2 *a + 2*(1-t)*t*b + t^2 * c\nend\n\npts = [\n    0.0 1.0;\n    1.3 1.3;\n    1.0 0.0;\n]\n\nxRed = bezier_1(tvec, pts[1,1], pts[2,1])\nyRed = bezier_1(tvec, pts[1,2], pts[2,2])\n\nxBlue = bezier_1(tvec, pts[2,1], pts[3,1])\nyBlue = bezier_1(tvec, pts[2,2], pts[3,2])\n\nxGreen = bezier_2(tvec, pts[1,1], pts[2,1], pts[3,1])\nyGreen = bezier_2(tvec, pts[1,2], pts[2,2], pts[3,2])\n\n@gif for ((xr, yr),(xb,yb),(xg,yg)) in zip(zip(xRed,yRed),zip(xBlue,yBlue),zip(xGreen,yGreen))\n        plot(xRed, yRed, line=(:path,:dash,:gray))\n        scatter!([xr], [yr], marker=(:circle,3,:red,:red))\n        plot!(xBlue, yBlue, line=(:path,:dash,:gray))\n        scatter!([xb], [yb], marker=(:circle,3,:blue,:blue))\n        x = bezier_1(tvec, xr, xb)\n        y = bezier_1(tvec, yr, yb)\n        plot!(x, y, line=(:path,:dash,:gray))\n        plot!(xGreen, yGreen, line=(:path,:solid,:gray))\n        scatter!([xg], [yg], marker=(:circle,3,:green,:green))\nend\n\n\n[ Info: Saved animation to C:\\Data\\dev\\repo\\quantinsights.github.io\\posts\\interpolation-and-approximation\\tmp.gif\n\n\n\n\n\nHow might we compute the trajectory of the green particle? By a double-application of the section formula, we have:\n\\[\n\\begin{align*}\np_G(t) &= (1-t)\\cdot p_R(t) + t\\cdot p_B(t)\\\\\n&= (1-t)((1-t)p_0 + tp_1) + t((1-t)p_1 + t p_2)\\\\\n&= (1-t)^2 p_0 +2t(1-t)p_1 + t^2 p_2\n\\end{align*}\n\\]\nThus, the trajectory of the green particle is a quadratic Bezier curve with \\(n+1=3\\) control points. The quadratic Bezier curve interpolates between the points \\(p_0\\) and \\(p_2\\), whereas \\(p_1\\) is an off-curve point.\nComputer graphics(CG) aficionados reserve the term control point for an off-curve point such as \\(p_1\\) and refer to the on-curve points, as anchor points. In CG editors such as Adobe Illustrator, not all control points are known in advance. The shape of the quadratic curve is controlled by moving around the control points using the Pen tool (Bezier tool) until the curve has the desired shape. Thus, using the Bernstein basis to represent degree 2 polynomials is advantageous. Moving \\(p_1\\) has a direct and intuitive effect on the curve.\nThe Bezier polygon is the closed piecewise linear curve connecting the control points \\(p_i\\) and \\(p_{i+1}\\), \\(i=0:n-1\\) and finally \\(p_n\\) and back to \\(p_0\\). This polygon provides a rough idea of the shape of the curve. From the definition(Equation 8) of the Bezier curve, it follows that for all \\(t\\in[0,1]\\), the curve \\(c(t)\\) is a convex combination of the control points. Therefore, \\(c(t)\\) lies within the convex hull of the control points.\n\nTheorem 3 The Bezier curve \\(c(t)\\) is tangent to \\(p_1- p_0\\) and \\(p_n - p_{n-1}\\) for \\(t=0\\) and \\(t=1\\) respectively.\n\nProof."
  },
  {
    "objectID": "posts/interpolation-and-approximation/index.html#spline-functions",
    "href": "posts/interpolation-and-approximation/index.html#spline-functions",
    "title": "Interpolation and Approximation",
    "section": "Spline Functions",
    "text": "Spline Functions\nThe mathematical concept of spline functions was introduced in 1946 by Schoenberg. The importance of the B-spline basis for approximation was also first appreciated by Schoenberg. Today, B-Splines enable the mathematical representation of surfaces far beyond hand-techniques. In aircraft design computations, they may involve more than \\(50,000\\) data points.\n\nLinear and Cubic Splines\nWe start by formally defining a spline function of order \\(k \\geq 1\\).\n\nDefinition 1 A spline function \\(S(x)\\) of order \\(k \\geq 1\\) (degree \\(k-1 \\geq 0\\)), on a grid\n\\[\n\\Delta = \\{a=x_0 &lt; x_1 &lt; \\ldots &lt; x_n = b\\}\n\\]\nof distinct knots is a real function \\(s\\) with the following properties:\n\nFor \\(x \\in [x_i, x_{i+1}]\\), \\(i=0:m-1\\), \\(S(x)\\) is a polynomial of degree \\(&lt;k\\)."
  },
  {
    "objectID": "posts/ito-processes-and-stochastic-diff-eqs/index.html",
    "href": "posts/ito-processes-and-stochastic-diff-eqs/index.html",
    "title": "Ito Processes and Stochastic Differential Equations",
    "section": "",
    "text": "Let’s start with the definition of Ito processes.\n\nDefinition 1 (Ito Process) Let \\((B(t):t\\geq0)\\) be a standard brownian motion defined on \\((\\Omega,\\mathcal{F},\\mathbb{P})\\). An Ito process \\((X(t):t\\geq0)\\) is of the form:\n\\[\\begin{aligned}\nX(t) & =X(0)+\\int_{0}^{t}V(s)dB(s)+\\int_{0}^{t}D(s)ds\n\\end{aligned} \\tag{1}\\]\nwhere \\((V(t),t\\geq0)\\) and \\((D(t),t\\geq0)\\) are two adapted processes for which the integrals make sense in the sense of Ito and Riemann. We refer to \\((V(t):t\\geq0)\\) as the local volatility and to \\((D(t):t\\geq0)\\) as the local drift.\n\nWe will often denote an Ito process \\((X(t):t\\geq0)\\) in differential form as:\n\\[\\begin{aligned}\ndX(t) & =D(t)dt+V(t)dB(t)\n\\end{aligned} \\tag{2}\\]\nThis form makes no rigorous sense; when we write it, we mean Equation 1. Nevertheless, the differential equation has two great advantages:\n(1) It gives some intuition on what drives the variation of \\(X(t)\\). On one hand, there is a contribution of the Brownian increments which are modulated by the volatility \\(V(t)\\). On the other hand, there is a smoother contribution coming from the time variation which is modulated by the drift \\(D(t)\\).\n(2) The differential notation has computational power. In particular, evaluating Ito’s formula is reduced to computing differentials, as in classical calculus, but by doing it upto the second order.\nAn important class of Ito processes is given by processes for which the volatility and the drift are simply functions of the position of the process.\n\nDefinition 2 Let \\((B(t):t\\geq0)\\) be a standard Brownian motion. An Ito process \\((X(t):t\\geq0)\\) of the form\n\\[\\begin{aligned}\ndX(t) & =\\mu(X(t))dt+\\sigma(X(t))dB(t),\\quad X(0)=x\n\\end{aligned} \\tag{3}\\]\nwhere \\(\\mu\\) and \\(\\sigma\\) are functions from \\(\\mathbf{R}\\) to \\(\\mathbf{R}\\), is called a time-homogenous diffusion.\n\n\nDefinition 3 An Ito-process \\((Y(t),t\\geq0)\\) of the form:\n\\[\\begin{aligned}\n{1}\ndY(t) & =\\mu(t,X(t))dt+\\sigma(t,X(t))dB(t)\\quad Y(0)=y\n\\end{aligned} \\tag{4}\\]\nwhere \\(\\mu\\) and \\(\\sigma\\) are now functions \\([0,\\infty)\\times\\mathbf{R}\\to\\mathbf{R}\\) is called a time-inhomogenous diffusion.\n\nThe equations above are called stochastic differential equations (SDE) of the respective process \\((X(t))\\) and \\((Y(t))\\).\nIn other words, a diffusion \\((X(t),t\\geq 0)\\) is an Ito process whose local volatility \\(V(t)\\) and local drift \\(D(t)\\) at time \\(t\\) depend only on the position of the process at time \\(t\\) and possibly on the time \\(t\\) itself. It cannot depend on the path of the process before time \\(t\\) or on the explicit values of the driving Brownian motion at that time (which is not the process \\(X(t)\\) itself). The class of diffusions, and of the Ito processes in general, constitutes a huge collection of stochastic processes for stochastic modelling.\nNote that an SDE is a generalization of ordinary differential equations or ODEs. Indeed, if there were no randomness, that is, no Brownian motion, the SDE would be reduced to\n\\[\\begin{aligned}\ndX(t) & =\\mu(X(t))dt\n\\end{aligned}\\]\nThis can be written for \\(X(t)=f(t)\\) as:\n\\[\\begin{aligned}\n\\frac{df}{dt} & =\\mu(f)\n\\end{aligned}\\]\nThis is a first-order ordinary differential equation. It governs the deterministic evolution of the function \\(X(t)=f(t)\\) in time. An SDE adds a random term to this evolution that is formally written as:\n\\[\\begin{aligned}\n\\frac{dX}{dt} & =\\mu(X(t))+\\sigma(X(t))\\frac{dB(t)}{dt}\n\\end{aligned}\\]\nWe know very well, that Brownian motion is not differentiable; hence the above is not well-defined. The ill-defined term \\(dB(t)/dt\\) is sometimes called white noise. However, equation Equation 3 is well-defined in the sense of the Ito process. These types of equations are well-suited to model phenomena with intrinsic randomness.\nHere are some examples of diffusions:\n\nExample 1 (Brownian Motion with a drift). If we take \\(X(t)=\\sigma B(t)+\\mu t\\) for some \\(\\sigma&gt;0\\) and \\(\\mu\\in\\mathbf{R}\\), then we can write \\(X(t)\\) as:\n\\[\\begin{aligned}\nX(t) & =\\int_{0}^{t}\\sigma dB(t)+\\int_{0}^{t}\\mu dt,\\quad X(0)=0\n\\end{aligned}\\]\nIn the differential form this becomes\n\\[\\begin{aligned}\ndX(t) & =\\mu dt+\\sigma dB(t)\n\\end{aligned}\\]\nIn this case, the local drift and the local volatility are constant.\n\n\nExample 2 (Geometric Brownian Motion). We consider the process \\(S(t)=\\exp((\\mu-\\sigma^{2}/2)t+\\sigma B(t))\\). To find the stochastic differential equation, we apply the Ito’s Lemma to\n\\[\\begin{aligned}\nf(t,x) & =\\exp((\\mu-\\sigma^{2}/2)t+\\sigma x)\n\\end{aligned}\\]\nWe have:\n\\[\\begin{aligned}\ndf(t,x) & =\\left((\\mu-\\sigma^{2}/2)+\\frac{1}{2}\\sigma^{2}\\right)\\exp((\\mu-\\sigma^{2}/2)t+\\sigma x)dt+\\sigma\\exp((\\mu-\\sigma^{2}/2)t+\\sigma x)dB(t)\\\\\n& =\\mu S(t)dt+\\sigma S(t)dB(t)\n\\end{aligned}\\]\nNote that the local drift and the local volatility are now proportional to the position. So, the higher \\(S(t)\\), the higher the volatility and drift.\n\n\nExample 3 (Any smooth function of Brownian motion). Ito’s formula gurarantees that any smooth function \\(f(t,B(t))\\) of time and a Brownian motion is an Ito process with volatility \\(V(t)=\\partial_{t}f(t,B(t))\\) and drift \\(D(t)=\\partial_{x}f(t,B(t))+\\frac{1}{2}\\partial_{xx}f(t,B(t))\\). We will see in further ahead, that, in general, any reasonable function of an Ito process remains an Ito process.\n\n\nExample 4 (An Ito process that is not a diffusion) Consider the process\n\\[\\begin{aligned}\nX(t) & =\\int_{0}^{t}B^{2}(s)dB(s)\n\\end{aligned}\\]\nThis is an Ito process with local volatility \\(V(t)=B(t)^{2}\\) and local drift \\(D(t)=0\\). However, it is not a diffusion, because the local volatility is not an explicit function of \\(X(t)\\).\nIt turns out that the Brownian bridge is a time-inhomogenous diffusion and that the Ornstein-Uhlenbeck process is a time-homogenous diffusion. To understand these examples, we need to extend Ito’s formula to Ito processes.\n\n\n\nThe first step towards a general Ito’s formula is the quadratic variation of an Ito process.\n\nProposition 1 (Quadratic variation of an Ito process.) Let \\((B(t),t\\geq0)\\) be a standard Brownian motion and \\((X(t):t\\geq0)\\) be an Ito process of the form \\(dX(t)=V(t)dB(t)+D(t)dt\\). Then, the quadratic variation of the process \\((X(t):t\\geq0)\\) is:*\n\\[\\begin{aligned}\n&lt;X,X&gt;_{t} & =\\lim_{n\\to\\infty}\\sum_{j=0}^{n-1}(X(t_{j+1})-X(t_{j}))^{2}=\\int_{0}^{t}V(s)^{2}ds\n\\end{aligned} \\tag{5}\\]\nfor any partition \\((t_{j},j\\leq n)\\) of \\([0,t]\\), where the limit is in probability.\n\n\nNote that the quadratic variation is increasing in \\(t\\), but it is not deterministic in general! \\(V_t\\) is a random variable. The quadratic variation is a smooth stochastic process. (It is differentiable) Observe that we recover the quadratic variation for the Brownian motion for \\(V(t)=1\\) as expected. We also notice that the formula follows easily from the rules of Ito Calculus, thereby showing the consistency of the theory. Indeed we have:\n\\[\\begin{aligned}\nd&lt;X,X&gt;_{t} & =(dX(t))^{2}=(V(t)dB(t)+D(t)dt)^{2}\\\\\n& =V(t)^{2}(dB(t))^{2}+2V(t)D(t)dB(t)\\cdot dt+D^{2}(t)(dt)^{2}\\\\\n& =V(t)^{2}dt\n\\end{aligned}\\]\n\n\nProof. Proof. The proof is involved, but it reviews some important concepts of stochastic calculus. We prove the case when the process \\(V\\) is in \\(\\mathcal{L}_{c}^{2}(T)\\) for some \\(T&gt;0\\). We write \\(I(t)=\\int_{0}^{t}V(s)dB(s)\\) and \\(R(t)=\\int_{0}^{t}D(s)ds\\). We first show that only the Ito integral contributes to the quadratic variation and the Riemann integral does not contribute, so that:\n\\[\\begin{aligned}\n&lt;X,X&gt;_{t} & =&lt;I,I&gt;_{t}\n\\end{aligned} \\tag{6}\\]\nWe have that the increment square of \\(X(t)\\) is:\n\\[\\begin{aligned}\n(X(t_{j+1})-X(t_{j}))^{2} & =(I(t_{j+1})-I(t_{j}))^{2}+2(I(t_{j+1})-I(t_{j}))(R(t_{j+1})-R(t_{j}))+(R(t_{j+1})-R(t_{j}))^{2}\n\\end{aligned}\\]\nThe Cauchy-Schwarz inequality implies :\n\\[\\begin{aligned}\n\\sum_{j=0}^{n-1}(I(t_{j+1})-I(t_{j}))(R(t_{j+1})-R(t_{j})) & \\leq\\left(\\sum_{j=0}^{n-1}(I(t_{j+1})-I(t_{j}))^{2}\\right)^{1/2}\\left(\\sum_{j=0}^{n-1}(R(t_{j+1})-R(t_{j}))^{2}\\right)^{1/2}\n\\end{aligned}\\]\nTherefore, to prove equation Equation 5, it suffices to show that \\(\\sum_{j=0}^{n-1}(R(t_{j+1})-R(t_{j}))^{2}\\to 0\\) almost surely. Since \\(D(s)\\) is an almost surely continuous process, the stochastic process \\(R(t)=\\int_{0}^{t}D(s)ds\\) has continuous paths with probability \\(1\\). Therefore:\n\\[\\begin{aligned}\n\\sum_{j=0}^{n-1}(R(t_{j+1})-R(t_{j}))^{2} & =\\max_{1\\leq j\\leq n}|R(t_{j+1})-R(t_{j})|\\sum_{j=0}^{n-1}(R(t_{j+1})-R(t_{j}))\n\\end{aligned}\\]\nSince, \\(R(t)\\) is continuous on the compact set \\([0,t]\\), it is uniformly continuous a.s. So, as \\(|t_{j+1}-t_{j}|\\to 0\\), by uniform continuity it follows that \\(\\max|R(t_{j+1})-R(t_{j})|\\to 0\\) a.s.\nIt remains to prove that \\(&lt;I,I&gt;_{t}=\\int_{0}^{t}V(s)^{2}ds\\). We first prove the case when \\(V\\in\\mathcal{S}(T)\\) is a simple adapted process. Consider a partition \\((t_{j}:j\\leq n)\\) of \\([0,t]\\). Without loss of generality, we can suppose that \\(V\\) is constant on each \\([t_{j},t_{j+1})\\) by refining the partition. We then have:\n\\[\\begin{aligned}\n\\sum_{j=0}^{n-1}(I(t_{j+1})-I(t_{j}))^{2} & =\\sum_{j=0}^{n-1}V(t_{j})^{2}(B(t_{j+1})-B(t_{j}))^{2}\n\\end{aligned}\\]\nNow, we have seen in the proof of Ito’s formula that \\(\\mathbb{E}\\left[\\left\\{ \\sum_{j=0}^{n-1}V(t_{j})^{2}((B(t_{j+1})-B(t_{j}))^{2}-(t_{j+1}-t_{j})\\right\\} ^{2}\\right]\\to 0\\), so \\(\\sum_{j=0}^{n-1}V(t_{j})^{2}(B(t_{j+1})-B(t_{j}))^{2}\\) approaches \\(\\sum_{j=0}^{n-1}V(t_{j})^{2}(t_{j+1}-t_{j})\\) in the mean square sense. As the mesh size becomes finer, the \\(L^{2}\\)-limit is \\(\\int_{0}^{t}V(t)^{2}dt\\).\nThe case \\(V\\in\\mathcal{L}_{c}^{2}(T)\\) is proved by approximating \\(V\\) by a simple process in \\(\\mathcal{S}(T)\\). More precisely, we can find a simple process \\(V^{(\\epsilon)}(t)\\) that is \\(\\epsilon\\)-close to \\(V\\) in the sense:\n\\[\\begin{aligned}\n||I^{(\\epsilon)}-I|| & =||\\int V^{\\epsilon}dB(t)-\\int VdB(t)||=\\int_{0}^{t}\\mathbb{E}[(V^{(\\epsilon)}(t)-V(t))^{2}]ds&lt;\\epsilon\n\\end{aligned} \\tag{7}\\]\nTo prove the claim, we need to show that for \\(t\\leq T\\),\n\\[\\begin{aligned}\n\\mathbb{E}\\left[\\left|\\sum_{j=0}^{n-1}(I(t_{j+1})-I(t_{j}))^{2}-\\int_{0}^{t}(V(s))^{2}ds\\right|\\right] & \\to0\\quad\\text{as }\\quad n\\to\\infty\n\\end{aligned}\\]\n\\(L^{1}\\)-convergence implies convergence in probability of the sequence \\(\\sum_{j=0}^{n-1}(I(t_{j+1})-I(t_{j}))^{2}\\). We now introduce the \\(V^{(\\epsilon)}(t)\\) approximation inside the absolute value as well as its corresponding integral \\(I^{(\\epsilon)}(t)=\\int_{0}^{t}V^{(\\epsilon)}(s)ds\\). By the triangle inequality, we have:\n\\[\\begin{aligned}\n& \\mathbb{E}\\left[\\left|\\sum_{j=0}^{n-1}(I(t_{j+1})-I(t_{j}))^{2}-\\int_{0}^{t}(V(s))^{2}ds\\right|\\right]\\nonumber \\\\\n= & \\mathbb{E}\\left[\\Biggl|\\sum_{j=0}^{n-1}(I(t_{j+1})-I(t_{j}))^{2}-(I^{(\\epsilon)}(t_{j+1})-I^{(\\epsilon)}(t_{j}))^{2}+(I^{(\\epsilon)}(t_{j+1})-I^{(\\epsilon)}(t_{j}))^{2}-\\int_{0}^{t}(V^{(\\epsilon)}(s))^{2}ds\\right.\\nonumber \\\\\n& +\\int_{0}^{t}(V^{(\\epsilon)}(s))^{2}ds-\\int_{0}^{t}(V(s))^{2}ds\\Biggr|\\Biggr]\\nonumber \\\\\n\\leq & \\mathbb{E}\\left[\\left|\\sum_{j=0}^{n-1}(I(t_{j+1})-I(t_{j}))^{2}-(I^{(\\epsilon)}(t_{j+1})-I^{(\\epsilon)}(t_{j}))^{2}\\right|\\right]+\\mathbb{E}\\left[\\left|\\sum_{j=0}^{n-1}(I^{(\\epsilon)}(t_{j+1})-I^{(\\epsilon)}(t_{j}))^{2}-\\int_{0}^{t}(V^{(\\epsilon)}(s))^{2}ds\\right|\\right]\\\\\n& +\\mathbb{E}\\left[\\Biggl|\\int_{0}^{t}(V^{(\\epsilon)}(s))^{2}ds-\\int_{0}^{t}(V(s))^{2}ds\\Biggr|\\right]\\nonumber\n\\end{aligned} \\tag{8}\\]\nWe show that the first and third terms converge uniformly and that the second term goes to \\(0\\) as \\(n\\to\\infty\\).\nThe second term goes to \\(0\\) as \\(n\\to\\infty\\) by the argument for simple processes.\n\\(&lt;I^{(\\epsilon)},I^{(\\epsilon)}&gt;_{t}=\\int_{0}^{t}V^{(\\epsilon)}(s)^{2}ds\\).\nFor the third term, the linearity of the integral and the Cauchy Schwarz inequality (applied to \\(\\mathbb{E}\\int_{0}^{t}\\)) imply that it is:\n\\[\\begin{aligned}\n\\mathbb{E}\\left[\\Biggl|\\int_{0}^{t}(V^{(\\epsilon)}(s))^{2}ds-\\int_{0}^{t}(V(s))^{2}ds\\Biggr|\\right] & \\leq\\mathbb{E}\\left[\\Biggl|\\int_{0}^{t}(V^{(\\epsilon)}(s)-V(s))^{2}ds\\Biggr|\\right]^{1/2}\\mathbb{E}\\left[\\Biggl|\\int_{0}^{t}(V^{(\\epsilon)}(s)+V(s))^{2}ds\\Biggr|\\right]^{1/2}\n\\end{aligned}\\]\nThe first factor is smaller than the square root of \\(\\epsilon\\) by Equation 7, whereas the second factor is bounded.\nThe first term in equation Equation 8 is handled similarly. The linearity of the Ito integral and the Cauchy-Schwarz inequality applied to \\(\\mathbb{E}\\left[\\sum_{j=0}^{n-1}\\left(\\int_{t_{j}}^{t_{j+1}}\\cdot\\right)\\right]\\) give that the first term is:\n\\[\\begin{aligned}\n& \\mathbb{E}\\left[\\left|\\sum_{j=0}^{n-1}\\int_{t_{j}}^{t_{j+1}}(V(s))^{2}dB(s)-\\int_{t_{j}}^{t_{j+1}}(V^{\\epsilon}(s))^{2}dB(s)\\right|\\right]\\\\\n= & \\mathbb{E}\\left[\\left|\\sum_{j=0}^{n-1}\\int_{t_{j}}^{t_{j+1}}(V(s)-V^{\\epsilon}(s))dB(s)\\int_{t_{j}}^{t_{j+1}}(V(s)+V^{\\epsilon}(s))dB(s)\\right|\\right]\\\\\n\\leq & \\mathbb{E}\\left[\\sum_{j=0}^{n-1}\\left(\\int_{t_{j}}^{t_{j+1}}(V(s)-V^{\\epsilon}(s))dB(s)\\right)^{2}\\right]^{1/2}\\mathbb{E}\\left[\\Biggl|\\sum_{j=0}^{n-1}\\left(\\int_{t_{j}}^{t_{j+1}}(V(s)+V^{\\epsilon}(s))dB(s)\\right)^{2}\\Biggr|\\right]^{1/2}\n\\end{aligned}\\]\nBy Ito isometry, the first factor in the above expression can be simplified:\n\\[\\begin{aligned}\n\\mathbb{E}\\left[\\sum_{j=0}^{n-1}\\left(\\int_{t_{j}}^{t_{j+1}}(V(s)-V^{\\epsilon}(s))dB(s)\\right)^{2}\\right]^{1/2} & =\\sum_{j=0}^{n-1}\\mathbb{E}\\left(\\int_{t_{j}}^{t_{j+1}}(V(s)-V^{\\epsilon}(s))dB(s)\\right)^{2}\\\\\n& =\\sum_{j=0}^{n-1}\\int_{t_{j}}^{t_{j+1}}\\mathbb{E}[(V(s)-V^{\\epsilon}(s))^{2}]ds\n\\end{aligned}\\]\nBy Equation 7, this factor is smaller than \\(\\epsilon\\). The second factor equals \\(\\sum_{j=0}^{n-1}\\int_{t_{j}}^{t_{j+1}}\\mathbb{E}[(V(s)+V^{\\epsilon}(s))^{2}]ds\\) by Ito-isometry and is uniformly bounded. This concludes the proof of the proposition. \\(\\blacksquare\\)\n\nNote that quadratic variation \\(&lt;I,I&gt;_{t}=\\int(V(s))^{2}ds\\) is computed path-by-path and hence the result is random. On the other the variance of the Ito integral \\(Var(I(t))=\\mathbb{E}[I_{t}^{2}]=\\int\\mathbb{E}[V_{s}^{2}]ds\\) is the mean value of all possible paths of the quadratic variation and hence is non-random. We are now ready to state Ito’s formula for Ito processes. We write the result in differential form for conciseness.\n\nTheorem 1 (Ito’s formula for Ito processes) Let \\((B(t):t\\geq0)\\) be a standard brownian motion, and let \\((X(t):t\\geq0)\\) be an Ito process of the form \\(dX(t)=V(t)dB(t)+D(t)dt\\). Consider a function \\(f(t,x)\\in\\mathcal{C}^{1,2}([0,T]\\times\\mathbf{R})\\). Then we have with probability one for all \\(t\\leq T\\):*\n\\[\\begin{aligned}\ndf(t,X(t)) & =\\partial_{x}f(t,X(t))dX(t)+\\partial_{t}f(t,X(t))dt+\\frac{1}{2}\\partial_{xx}f(t,X(t))d&lt;X,X&gt;_{t}\n\\end{aligned}\\]\nThis can also be written as:\n\\[\\begin{aligned}\ndf(t,X(t))= & \\partial_{x}f(t,X(t))V(t)dB(t)+\\left[\\partial_{x}f(t,X(t))D(t)+\\partial_{t}f(t,X(t))+\\frac{1}{2}(V(t))^{2}\\partial_{xx}f(t,X(t))\\right]dt\n\\end{aligned}\\]\n\nThe proof of the Theorem 1 is again a Taylor approximation with the form of the quadratic variation of the process. We will omit it.\n\nExample 5 (Ornstein-Uhlenbeck Process). Consider the Ornstein-Uhlenbeck process \\((Y(t):t\\geq0)\\):\n\\[\\begin{aligned}\nY(t) & =Y(0)e^{-t}+e^{-t}\\int_{0}^{t}e^{s}dB(s)\n\\end{aligned}\\]\nNote that this process is an explicit function of \\(t\\) and of the Ito process \\(X(t)=Y(0)+\\int_{0}^{t}e^{s}dB(s)\\). Indeed, we have:\n\\[\\begin{aligned}\nY(t) & =e^{-t}X(t)\n\\end{aligned}\\]\nLet \\(f(t,x)=e^{-t}x\\). Then, \\(f_{x}(t,x)=e^{-t}\\), \\(f_{xx}(t,x)=0\\) and \\(f_{t}(t,x)=-e^{-t}x\\). So, by Ito’s lemma,\n\\[\\begin{aligned}\ndf(t,x) & =f_{t}(t,X(t))dt+f_{x}(t,X(t))dX(t)+\\frac{1}{2}f_{xx}(t,X(t))d&lt;X,X&gt;_{t}\\nonumber \\\\\ndY(t) & =-Y(t)dt+e^{-t}dX(t)\\nonumber \\\\\ndY(t) & =-Y(t)dt+e^{-t}(e^{t}dB(t))\\nonumber \\\\\ndY(t) & =-Y(t)dt+dB(t)\n\\end{aligned} \\tag{9}\\]\nThis is the SDE for the Ornstein Uhlenbeck process.\nThe SDE has a very nice interpretation: The drift is positive if \\(Y(t)&lt;0\\) and negative if \\(Y(t)&gt;0\\). Moreover, the drift is proportional to the position (exactly like a spring pulling the process back to the \\(x\\)-axis following the Hooke’s law!). This is the mechanism that ensures that the process does not venture too far from \\(0\\) and is eventually stationary.\nThe SDE Equation 9 is now easily generalized by adding two parameters for the volatility and the drift:\n\\[\\begin{aligned}\ndY(t) & =-kY(t)dt+\\sigma dB(t),\\quad k\\in\\mathbf{R},\\sigma&gt;0\n\\end{aligned} \\tag{10}\\]\nIt is not hard to check that the solution to the SDE is:\n\\[\\begin{aligned}\nY(t) & =Y(0)e^{-kt}+e^{-kt}\\int_{0}^{t}e^{ks}\\sigma dB(s)\n\\end{aligned} \\tag{11}\\]\n\n\nExercise 1 The Ornstein-Uhlenbeck process with parameters. Use the Ito’s formula to show that the Equation 11 is the solution to the Ornstein-Uhlenbeck SDE Equation 10.\n\nSolution.\nLet \\(X(t)=Y(0)+\\int_{0}^{t}e^{ks}\\sigma dB(s)\\), so \\(dX(t)=e^{kt}\\sigma dB(t)\\). Then, \\(Y(t)=e^{-kt}X(t)\\). Let \\(f(t,x)=e^{-kt}x\\). Then, by Ito’s formula:\n\\[\\begin{aligned}\ndf(t,x) & =-ke^{-kt}X(t)dt+e^{-kt}dX(t)\\\\\ndY(t) & =-kY(t)dt+e^{-kt}e^{kt}\\sigma dB(t)\\\\\ndY(t) & =-kY(t)dt+\\sigma dB(t)\n\\end{aligned}\\]\nThe latest version of Ito’s formula is another useful tool for producing martingales from a function of an Ito process. We start with two examples generalizing martingales for Brownian motion.\n\nExample 6 (A generalization of \\((B(t))^{2}-t\\)). Let \\((V(t):t\\leq T)\\) be a process in \\(\\mathcal{L}_{c}^{2}(T)\\). Consider an Ito process \\((X(t):t\\leq T)\\) given by \\(dX(t)=V(t)dB(t)\\). Note that \\(((X(t))^{2}:t\\leq T)\\) is a submartingale by Jensen’s inequality, since \\(\\mathbb{E}[X^{2}(t)|\\mathcal{F}_{s}]\\geq(\\mathbb{E}[X(t)|\\mathcal{F}_{s})^{2}=X^{2}(s)\\). We show that the compensated process\n\\[\\begin{aligned}\nM(t) & =X^{2}(t)-\\int_{0}^{t}V^{2}(s)ds,\\quad t\\leq T\n\\end{aligned}\\]\nis a martingale for the Brownian filtration. (This is another instance of the Doob-Meyer decomposition). By the Ito’s formula for \\(f(x)=x^{2}\\), we have:\n\\[\\begin{aligned}\ndf(x) & =f_{x}(X(t)dX(t)+\\frac{1}{2}f_{xx}(X(t))d&lt;X,X&gt;_{t}\\\\\n& =2X(t)dX(t)+(V(t))^{2}dt\\\\\ndf(X(t)) & =2X(t)V(t)dB(t)+(V(t))^{2}dt\n\\end{aligned}\\]\nIn Integral form this implies:\n\\[\\begin{aligned}\n(X(t))^{2} & =(X(0))^{2}+2\\int_{0}^{t}X(s)V(s)dB(s)+\\int_{0}^{t}(V(s))^{2}ds\\\\\nM(t)=(X(t))^{2}-\\int_{0}^{t}(V(s))^{2}ds & =(X(0))^{2}+2\\int_{0}^{t}X(s)V(s)dB(s)\n\\end{aligned}\\]\nWe conclude that \\((M(t):t\\leq T)\\) is a martingale, provided \\(X(t)V(t)\\in L_{c}^{2}(T)\\).\nThere is another more direct way to prove that \\((M(t):t\\leq T)\\) is a martingale whenever \\((V(t):t\\leq T)\\in\\mathcal{L}_{c}^{2}(T)\\). This is by using increments: for \\(t'&lt;t\\leq T\\),\n\\[\\begin{aligned}\n\\mathbb{E}[X_{t'}^{2}|\\mathcal{F}_{t}] & =\\mathbb{E}[(X_{t}+(X_{t'}-X_{t}))^{2}|\\mathcal{F}_{t}]\\\\\n& =\\mathbb{E}[X_{t}^{2}+2X_{t}(X_{t'}-X_{t})+(X_{t'}-X_{t})^{2}|\\mathcal{F}_{t}]\\\\\n& =X_{t}^{2}+2X_{t}\\mathbb{E}[X_{t'}-X_{t}|\\mathcal{F}_{t}]+\\mathbb{E}[(X_{t'}-X_{t})^{2}|\\mathcal{F}_{t}]\n\\end{aligned}\\]\nSince \\((X_{t}:t\\geq0)\\) is a martingale, \\(\\mathbb{E}[(X_{t'}-X_{t})|M_{t}]=0\\), so the middle term equals zero and we are left with:\n\\[\\begin{aligned}\n\\mathbb{E}[X_{t'}^{2}|\\mathcal{F}_{t}] & =X_{t}^{2}+\\mathbb{E}[(X_{t'}-X_{t})^{2}|\\mathcal{F}_{t}]\n\\end{aligned}\\]\nBy conditional Ito Isometry,\n\\[\\begin{aligned}\n\\mathbb{E}[(X_{t'}-X_{t})^{2}|\\mathcal{F}_{t}] & =\\int_{0}^{t'}V_{s}^{2}ds-\\int_{0}^{t}V_{s}^{2}ds=\\int_{t}^{t'}V_{s}^{2}ds\n\\end{aligned}\\]\n\n\nExample 7 (A generalization of the geometric Brownian motion). Let \\(\\sigma(t)\\) be a continuous, deterministic function such that \\(|\\sigma(t)|\\leq1\\), \\(t\\in[0,T]\\). The process\n\\[\\begin{aligned}\nM(t) & =\\exp\\left(\\int_{0}^{t}\\sigma(s)dB(s)-\\frac{1}{2}\\int_{0}^{t}\\sigma^{2}(s)ds\\right),\\quad t\\leq T\n\\end{aligned}\\]\nis a martingale for the Brownian filtration. To see this, note that we can write \\(M(t)=f(t,X(t))\\) where \\(f(t,x)=\\exp(x-\\frac{1}{2}\\int\\sigma^{2}(s)ds)\\) and \\(X(t)=\\int_{0}^{t}\\sigma(s)dB(s)\\), so \\(dX(t)=\\sigma(t)dB(t)\\). Ito’s formula gives:\n\\[\\begin{aligned}\ndf(t,x) & =f_{t}(t,X(t)dt+f_{x}(t,X(t))dX(t)+\\frac{1}{2}f_{xx}(t,X(t))d&lt;X,X&gt;_{t}\\\\\ndM(t) & =-\\frac{1}{2}\\sigma^{2}(t)M(t)dt+M(t)\\sigma(t)dB(t)+\\frac{1}{2}M(t)\\sigma^{2}(t)dt\\\\\n& =M(t)\\sigma(t)dB(t)\\\\\nM(t) & =M(0)+\\int_{0}^{t}M(s)\\sigma(s)dB(s)\n\\end{aligned}\\]\nObserve also that:\n\\[\\begin{aligned}\n\\mathbb{E}[M_{t}^{2}] & =e^{-\\int_{0}^{t}\\sigma^{2}(s)ds}\\mathbb{E}[e^{2\\int_{0}^{t}\\sigma(s)dB(s)}]=e^{\\int_{0}^{t}\\sigma^{2}(s)ds}\n\\end{aligned}\\]\nsince \\(\\int_{0}^{t}\\sigma(s)dB(s)\\) is a Gaussian random variable with mean \\(0\\) and variance \\(\\int_{0}^{t}\\sigma^{2}(s)ds\\).\nWe conclude from the equation that \\((M(t),t\\geq0)\\) is a martingale.\n\n\nExample 8 (Martingales of Geometric Brownian Motion). Let\n\\[\\begin{aligned}\nS(t) & =S(0)\\exp(\\sigma B(t)-\\sigma^{2}t/2)\n\\end{aligned}\\]\nbe a geometric brownian motion. We find a PDE satisfied by \\(f(t,x)\\) for \\(f(t,S(t))\\) to be a martingale. It suffices to apply Ito’s formula of Theorem 1. We get:\n\\[\\begin{aligned}\ndf(t,S(t)) & =f_{t}(t,S(t))dt+f_{x}(t,S(t))dS(t)+\\frac{1}{2}f_{xx}(t,S(t))dS(t)\\cdot dS(t)\n\\end{aligned}\\]\nNow note from the earlier result that \\(dS(t)=S(t)\\sigma dB(t)\\). So, \\(dS(t)\\cdot dS(t)=\\frac{1}{2}\\sigma^{2}(S(t))^{2}dt\\). So,\n\\[\\begin{aligned}\ndf(t,S(t)) & =\\left\\{ \\frac{\\partial f}{\\partial t}+\\frac{1}{2}\\sigma^{2}(S(t))^{2}\\frac{\\partial^{2}f}{\\partial x^{2}}\\right\\} dt+\\sigma S(t)\\frac{\\partial f}{\\partial x}dB(t)\n\\end{aligned}\\]\nFinally, the PDE for \\(f(t,x)\\) is obtained by setting the factor in front of \\(dt\\) to \\(0\\), because we want \\(f\\) to be a martingale process. It is important to keep in mind, that the PDE should always be written in terms of the time variable \\(t\\) and the space variable \\(x\\). Therefore, the PDE of \\(f\\) as a function of time and space is:\n\\[\\begin{aligned}\n\\frac{1}{2}\\sigma^{2}x^{2}\\frac{\\partial^{2}f}{\\partial x^{2}}(t,x)+\\frac{\\partial f}{\\partial t}(t,x) & =0\n\\end{aligned}\\]\nNo more randomness appears in the PDE!\n\nHere is a specific case where we can apply the Ito’s formula to construct martingales of Ito processes.\n\nExample 9 Consider the process given by the SDE:\n\\[\\begin{aligned}\ndX(t) & =X(t)dB(t),\\quad X(0)=2\n\\end{aligned}\\]\nLet’s find a PDE for which \\(f(t,X(t))\\) is a martingale for the Brownian filtration. We have by Ito’s formula that:\n\\[\\begin{aligned}\ndf(t,X(t)) & =f_{t}(t,X(t))dt+f_{x}(t,X(t))dX(t)+\\frac{1}{2}f_{xx}(t,X(t))d&lt;X,X&gt;_{t}\\\\\n& =\\left(\\frac{\\partial f}{\\partial t}+\\frac{1}{2}(X(t))^{2}\\frac{\\partial^{2}f}{\\partial x^{2}}\\right)dt+X(t)\\frac{\\partial f}{\\partial x}dB(t)\n\\end{aligned}\\]\nSetting the drift term to \\(0\\) gives the PDE:\n\\[\\begin{aligned}\n\\frac{\\partial f}{\\partial t}+\\frac{1}{2}x^{2}\\frac{\\partial^{2}f}{\\partial x^{2}} & =0\n\\end{aligned}\\]\nIt is then easy to check that \\(X(t)\\) is a martingale and so is \\(t+\\log(X(t))^{2}\\), since the functions \\(f(t,x)=x\\) and \\(f(t,x)=t+\\log x^{2}\\) satisfy the PDE. However, the process \\(tX(t)\\) is not, as the function \\(f(t,x)=xt\\) is not a solution of the PDE.\n\n\n\n\nIto’s formula can be generalized to several Ito processes. Let’s start by stating an example of a function of two Ito processes. Such a function \\(f(x_{1},x_{2})\\) will be a function of two space variables. Not surprisingly, it needs to have two derivatives in each variable and they need to be a continuous function; we need \\(f\\in\\mathcal{C}^{2\\times2}(\\mathbf{R}\\times\\mathbf{R})\\).\n\nTheorem 2 (Ito’s formula for many Ito processes) Let \\((X(t):t\\geq0)\\) and (Y(t):t)$ be two Ito processes of the form:\n\\[\\begin{aligned}\ndX(t) & =V(t)dB(t)+D(t)dt\\nonumber \\\\\ndY(t) & =U(t)dB(t)+R(t)dt\n\\end{aligned} \\tag{12}\\]\nwhere \\((B(t):t\\geq0)\\) is a standard Brownian motion. Then, for \\(f\\in\\mathcal{C}^{2\\times2}(\\mathbf{R}\\times\\mathbf{R})\\), we have:\n\\[\\begin{aligned}\ndf(X(t),Y(t)) & =f_{x}(X(t),Y(t))dX(t)+f_{y}(X(t),Y(t))dY(t)+\\frac{1}{2}f_{xx}(X(t),Y(t))d&lt;X,X&gt;_{t}\\\\\n& +f_{xy}(X(t),Y(t))d&lt;X,Y&gt;_{t}+\\frac{1}{2}f_{yy}(X(t),Y(t))d&lt;Y,Y&gt;_{t}\n\\end{aligned}\\]\n\nThe idea of the proof is the same as in Theorem 1 : Taylor’s expansion and quadratic variation, together with the cross-variation of two processes.\n\\[\\begin{aligned}\ndX(t)\\cdot dY(t) & =(V(t)dB(t)+D(t)dt)(U(t)dB(t)+R(t)dt)\\\\\n& =U(t)V(t)dt\n\\end{aligned}\\]\n\nExample 10 (Product Rule) An important example of this formula is Ito’s product rule. Let \\(X(t)\\) and \\(Y(t)\\) be as in Equation 12. Then:\n\\[\\begin{aligned}\nd(X(t)Y(t)) & =Y(t)dX(t)+X(t)dY(t)+dX(t)\\cdot dY(t)\n\\end{aligned}\\]\n\n\nExercise 2 Let \\((\\Omega,\\mathcal{F},\\mathbb{P})\\) be a probability space and let \\((B_{t}:t\\geq0)\\) be a standard brownian motion. Using integration by parts, show that\n\\[\\begin{aligned}\n\\int_{0}^{t}B(s)ds & =\\int_{0}^{t}(t-s)dB(s)\n\\end{aligned}\\]\nand prove that \\(\\int_{0}^{t}B(s)ds\\sim\\mathcal{N}(0,t^{3}/3)\\).\nIs\n\\[\\begin{aligned}\nX(t) & =\\begin{cases}\n0 & t=0\\\\\n\\frac{\\sqrt{3}}{t}\\int_{0}^{t}B(s)ds & t&gt;0\n\\end{cases}\n\\end{aligned}\\]\na standard Wiener process?\nSolution.\nClearly, \\(B(s,\\omega)\\) is a random variable and the Riemann integral \\(\\int_0^t B(s,\\omega)ds\\) depends on the sample path \\(\\omega\\). So, \\((\\int_0^t B_s ds, t\\leq T)\\) is a stochastic process. Using integration by parts:\n\\[\\begin{aligned}\n\\int u\\left(\\frac{dv}{ds}\\right)ds & =uv-\\int v\\left(\\frac{du}{ds}\\right)ds\n\\end{aligned}\\]\nWe set \\(u=B(s)\\) and \\(dv/ds=1\\). Then:\n\\[\\begin{aligned}\n\\int_{0}^{t}B(s)ds & =sB(s)|_{0}^{t}-\\int_{0}^{t}sdB(s)\\\\\n& =tB(t)-\\int_{0}^{t}sdB(s)\\\\\n& =\\int_{s=0}^{s=t}tdB(s)-\\int_{0}^{t}sdB(s)\\\\\n& =\\int_{0}^{t}(t-s)dB(s)\n\\end{aligned}\\]\nThus, \\(\\int_{0}^{t}B(s)ds\\) is a Gaussian random variable with:\n\\[\\begin{aligned}\n\\mathbb{E}\\left[\\int_{0}^{t}B(s)ds\\right] & =\\mathbb{E}\\left[\\int_{0}^{t}(t-s)dB(s)\\right]\\\\\n& =0\n\\end{aligned}\\]\nand\n\\[\\begin{aligned}\n\\mathbb{E}\\left[\\left(\\int_{0}^{t}B(s)ds\\right)^{2}\\right] & =\\int_{0}^{t}(t-s)^{2}ds\\\\\n& =\\left.\\frac{(t-s)^{3}}{-3}\\right|_{0}^{t}\\\\\n& =\\frac{t^{3}}{3}\n\\end{aligned}\\]\nThus, using the properties of Ito Integral, \\(\\int_{0}^{t}B(s)ds=\\int_{0}^{t}(t-s)dB(s)\\) is a martingale. Now the quadratic variation \\(&lt;M,M&gt;_{t}=0\\), and this can be a bit tricky. Remember, \\(\\left\\langle \\int_{0}^{t}f(s,B_{s})dB(s),\\int_{0}^{t}f(s,B_{s})dB(s)\\right\\rangle =\\int_{0}^{t}f^{2}(s,B_{s})ds\\) if and only if \\(f\\) is a function of the time \\(s\\) and the position of the Brownian motion \\(B(s)\\). Since, \\(f\\) is a function of \\(t\\) as well, this rule cannot be applied.\nBy first principles, we can show that, the quadratic variation is indeed \\(0\\): \\[\\begin{aligned}\n\\lim_{n\\to\\infty}\\mathbb{E}\\left[\\sum_{j=0}^{n-1}\\left(I(t_{j+1})-I(t_{j})\\right)^{2}\\right] & =\\lim_{n\\to\\infty}\\mathbb{E}\\left[\\sum_{j=0}^{n-1}B_{t_{j}}^{2}(t_{j+1}-t_{j})^{2}\\right]\\\\\n& =\\lim_{n\\to\\infty}\\max_{1\\leq j\\leq n}|t_{j+1}-t_{j}|\\cdot\\mathbb{E}\\left[\\sum_{j=0}^{n-1}B_{t_{j}}^{2}(t_{j+1}-t_{j})\\right]\n\\end{aligned}\\]\nSince the paths of \\(B_{t}\\) are continuous, so are the paths \\(B_{t}^{2}\\) on the compact interval \\([0,t]\\). So, \\((B_{s}^{2},s\\in[0,t])\\) is uniformly bounded. Thus, the expectation term is bounded. As \\(n\\to\\infty\\), the mesh size approaches zero, and consequently the quadratic variation approaches zero.\n\n\nExample 11 Let \\(X_{t}=\\int_{0}^{t}B_{s}dB_{s}\\) and \\(Y_{t}=\\int_{0}^{t}B_{s}^{2}dB_{s}\\). Is \\((X_{t}Y_{t},t\\geq0)\\) a martingale?\n\nSolution.\nBy Ito’s product rule, we have:\n\\[\\begin{aligned}\nd(X_{t}Y_{t}) & =X_{t}dY_{t}+Y_{t}dX_{t}+dX_{t}\\cdot dY_{t}\\\\\n& =X_{t}B_{s}^{2}dB_{s}+Y_{t}B_{s}dB_{s}+(B_{s}dB_{s})\\cdot(B_{s}^{2}dB_{s})\\\\\n& =X_{t}B_{s}^{2}dB_{s}+Y_{t}B_{s}dB_{s}+B_{s}^{3}dt\\\\\nX_{t}Y_{t} & =X_{0}Y_{0}+\\int_{0}^{t}X_{t}B_{s}^{2}dB_{s}+\\int_{0}^{t}Y_{t}B_{s}dB_{s}+\\int_{0}^{t}B_{s}^{3}dt\n\\end{aligned}\\]\nThe term in \\(dt\\) is not zero, so the product cannot be a martingale.\n\nExample 12 (A generalization of Geometric Brownian Motion). Consider \\((\\int_{0}^{t}V_{s}dB_{s},t\\geq0)\\) an Ito process. Define the positive process:\n\\[\\begin{aligned}\nM_{t} & =\\exp\\left(\\int_{0}^{t}V_{s}dB_{s}-\\frac{1}{2}\\int_{0}^{t}V_{s}^{2}ds\\right),\\quad t\\geq0\n\\end{aligned} \\tag{13}\\]\n\nSolution.\nIto’s formula applied to the processes \\(X_{t}=\\int_{0}^{t}V_{s}dB_{s}\\) and \\(Y_{t}=\\frac{1}{2}\\int_{0}^{t}V_{s}^{2}ds\\) with the function \\(f(x,y)=e^{x-y}\\) yields:\n\\[\\begin{aligned}\ndf(x,y) & =f_{x}(X_{t},Y_{t})dX_{t}+f_{y}(X_{t},Y_{t})dY_{t}\\\\\n& +\\frac{1}{2}f_{xx}(X_{t},Y_{t})dX_{t}\\cdot dX_{t}+\\frac{1}{2}f_{yy}(X_{t},Y_{t})dY_{t}\\cdot dY_{t}\\\\\n& +f_{xy}(X_{t},Y_{t})dX_{t}\\cdot dY_{t}\n\\end{aligned}\\]\nNow, all first and second order derivatives are \\(\\partial_{x}(e^{x-y})=M_{t}\\), \\(\\partial_{y}(e^{x-y})=-e^{x-y}=-M_{t}\\), \\(\\partial_{xx}(e^{x-y})=M_{t}\\)\n\\(dX_{t}=V_{t}dB_{t}\\). \\(dY_{t}=\\frac{1}{2}V_{t}^{2}dt\\).\n\\(dX_{t}\\cdot dX_{t}=V_{t}^{2}dt\\), \\(dX_{t}\\cdot dY_{t}=0\\),\n\\(dY_{t}\\cdot dY_{t}=0\\).\nConsequently, we have:\n\\[\\begin{aligned}\ndM_{t} & =M_{t}V_{t}dB_{t}-\\frac{1}{2}M_{t}V_{t}^{2}dt\\\\\n& +\\frac{1}{2}M_{t}V_{t}^{2}dt\\\\\n& =M_{t}V_{t}dB_{t}\n\\end{aligned}\\]\nThus, \\((M_{t},t\\geq0)\\) is a martingale.\n\nExercise 3 (Generalized Ito Integral). Let \\((\\Omega,\\mathcal{F},\\mathbb{P})\\) be a probability space and let \\((B_{t}:t\\geq0)\\) be a standard brownian motion. Given that \\(f\\) is a simple process, show that:\n\\[\\begin{aligned}\n\\int_{0}^{t}f(s,B_{s})dB_{s} & =B_{t}f(t,B_{t})-\\int_{0}^{t}\\left[B_{s}\\frac{\\partial f}{\\partial t}+\\frac{\\partial f}{\\partial x}+\\frac{1}{2}B_{s}\\frac{\\partial^{2}f}{\\partial x^{2}}\\right]ds\\\\\n& -\\int_{0}^{t}B_{s}\\frac{\\partial f}{\\partial x}dB_{s}\n\\end{aligned}\\]\nand\n\\[\\begin{aligned}\n\\int_{0}^{t}f(s,B_{s})ds & =tf(t,B_{t})-\\int_{0}^{t}s\\left[\\frac{\\partial f}{\\partial t}+\\frac{1}{2}\\frac{\\partial^{2}f}{\\partial x^{2}}\\right]ds-\\int_{0}^{t}s\\frac{\\partial f}{\\partial x}dB_{s}\n\\end{aligned}\\]\n\nSolution.\nI suppress \\((t,B_{t})\\) for simplicity. Applying the product rule to \\(B_{t}f\\), we get:\n\\[\\begin{aligned}\nd(B_{t}f) & =fdB_{t}+B_{t}df+dB_{t}\\cdot df\\\\\n& =fdB_{t}+B_{t}\\left(\\frac{\\partial f}{\\partial t}dt+\\frac{\\partial f}{\\partial x}dB_{t}+\\frac{1}{2}\\frac{\\partial^{2}f}{\\partial x^{2}}(dB_{t})^{2}\\right)\\\\\n& +dB_{t}\\cdot\\left(\\frac{\\partial f}{\\partial t}dt+\\frac{\\partial f}{\\partial x}dB_{t}+\\frac{1}{2}\\frac{\\partial^{2}f}{\\partial x^{2}}(dB_{t})^{2}\\right)\\\\\n& =fdB_{t}+\\left(B_{t}\\frac{\\partial f}{\\partial t}+\\frac{\\partial f}{\\partial x}+\\frac{1}{2}B_{t}\\right)dt+B_{t}\\frac{\\partial f}{\\partial x}dB_{t}\\\\\nB_{t}f & =\\int_{0}^{t}fdB_{s}+\\int_{0}^{t}\\left(B_{s}\\frac{\\partial f}{\\partial t}+\\frac{\\partial f}{\\partial x}+\\frac{1}{2}\\frac{\\partial^{2}f}{\\partial x^{2}}B_{s}\\right)ds+\\int_{0}^{t}B_{s}\\frac{\\partial f}{\\partial x}dB_{s}\\\\\n\\int_{0}^{t}fdB_{s} & =B_{t}f-\\int_{0}^{t}\\left(B_{s}\\frac{\\partial f}{\\partial t}+\\frac{\\partial f}{\\partial x}+\\frac{1}{2}\\frac{\\partial^{2}f}{\\partial x^{2}}B_{s}\\right)ds-\\int_{0}^{t}B_{s}\\frac{\\partial f}{\\partial x}dB_{s}\n\\end{aligned}\\]\nApplying product rule to \\(tf(t,B_{t})\\), we get:\n\\[\\begin{aligned}\nd(tf) & =fdt+tdf+dt\\cdot df\\\\\n& =fdt+t\\left(\\frac{\\partial f}{\\partial t}dt+\\frac{\\partial f}{\\partial x}dB_{t}+\\frac{1}{2}\\frac{\\partial^{2}f}{\\partial x^{2}}(dB_{t})^{2}\\right)\\\\\n& +dt\\left(\\frac{\\partial f}{\\partial t}dt+\\frac{\\partial f}{\\partial x}dB_{t}+\\frac{1}{2}\\frac{\\partial^{2}f}{\\partial x^{2}}(dB_{t})^{2}\\right)\\\\\n& =fdt+t\\left(\\frac{\\partial f}{\\partial t}+\\frac{1}{2}\\frac{\\partial^{2}f}{\\partial x^{2}}\\right)dt+t\\frac{\\partial f}{\\partial x}dB_{t}\\\\\ntf & =\\int_{0}^{t}fds+\\int_{0}^{t}s\\left(\\frac{\\partial f}{\\partial t}+\\frac{1}{2}\\frac{\\partial^{2}f}{\\partial x^{2}}\\right)ds+\\int_{0}^{t}s\\frac{\\partial f}{\\partial x}dB_{s}\\\\\n\\int_{0}^{t}fds & =tf-\\int_{0}^{t}s\\left(\\frac{\\partial f}{\\partial t}+\\frac{1}{2}\\frac{\\partial^{2}f}{\\partial x^{2}}\\right)ds-\\int_{0}^{t}s\\frac{\\partial f}{\\partial x}dB_{s}\n\\end{aligned}\\]\nThe following example will be important when we discuss the Girsanov theorem.\n\nTheorem 3 (Ito’s formula for many Ito processes) Let \\(X_t = (X_t^{(j)},j\\leq d,j\\in\\mathbf{N})\\) be Ito processes constructed on \\((\\Omega,\\mathcal{F},\\mathbb{P})\\) and \\(f \\in C^{1,2}([0,T]\\times \\mathbb{R}^d)\\). Then for \\(t \\in [0,T]\\), we have:\n\\[\ndf(t,X_t) = \\partial_t f(t,X_t) dt + \\sum_{j=1}^{d} \\partial_{x_j} f(t,X_t) dX_t^{(j)} + \\frac{1}{2}\\sum_{j=1}^{d} \\sum_{k=1}^d \\partial_{x_j x_k}^2 f(t,X_t) dX_t^{(j)}\\cdot dX_t^{(k)}\n\\]\n\n\n\n\nThe good news is that it is not too hard to implement iterative schemes to sample paths of a diffusion. Consider \\((X_t,t\\leq T)\\) a solution to the SDE:\n\\[\ndX_t = \\sigma(X_t) dB_t + \\mu(X_t) dt\n\\]\nTo keep the notation to a minimum, we consider a time-homogeonous diffusion. For a partition \\((t_j,j\\leq n)\\) of \\([0,T]\\) with \\(t_n = T\\), consider the increment\n\\[\nX_{t_{j+1}} - X_{t_j} = \\int_{t_j}^{t_{j+1}} \\sigma(X_s) dB(s) + \\int_{t_j}^{t_{j+1}} \\mu(X_s) ds\n\\tag{14}\\]\nNote that, if \\(\\sigma\\) and \\(\\mu\\) are smooth functions, we can apply Ito’s formula to \\(\\sigma(X_s)\\) and \\(\\mu(X_s)\\) for \\(s\\in (t_j,t_{j+1}]\\)! We get:\n\\[\n\\begin{align*}\n\\sigma(X_s) &= \\sigma(X_{t_j}) + \\int_{t_j}^{s}\\sigma'(X_u) dX_u + \\frac{1}{2}\\int_{t_j}^{s} \\sigma''(X_u)(dX_u)^2\\\\\n\\mu(X_s) &= \\mu(X_{t_j}) + \\int_{t_j}^{s}\\mu'(X_u) dX_u + \\frac{1}{2}\\int_{t_j}^{s} \\mu''(X_u)(dX_u)^2\n\\end{align*}\n\\tag{15}\\]\nNow, we can approximate the increment in Equation 14 at different levels of precision by considering a different estimate for Equation 15.\n\nExample 13 (Euler-Maruyama Scheme). This scheme consists of taking \\(\\sigma(X_s) \\approx \\sigma(X_{t_j})\\) and \\(\\mu(X_s) \\approx \\mu(X_{t_j})\\) for \\(s \\in [t_j,t_{j+1})\\) in Equation 15. Putting this back in Equation 14, we get:\n\\[\nX_{t_{j+1}} - X_{t_j} \\approx \\sigma(X_{t_j})(B_{t_{j+1}}-B_{t_j}) + \\mu(X_{t_j})(t_{j+1} - t_j)\n\\tag{16}\\]\nThe process \\(X_t\\) can then be constructed recursively on the discrete set \\((t_j,j \\leq n)\\) as follows:\n\\[\n\\begin{align*}\nX_0 &= x\\\\\nX_{t_1} &= (X_{t_1} - X_0) + X_0\\\\\nX_{t_2} &= (X_{t_2} - X_{t_1}) + (X_{t_1} - X_0) + X_0\\\\\n\\vdots\\\\\nX_{t_n} &= \\sum_{j=0}^{n-1}(X_{t_{j+1}} - X_{t_j}) + X_0\n\\end{align*}\n\\]\n\n\nExample 14 (Milstein Scheme). In this scheme, we go an order further for the approximation of the volatility in Equation 15 and consider also the integral in \\(dX_u\\). We take \\(dX_u = \\sigma(X_{t_j})dB_u\\). We then express \\(\\sigma(X_s)\\) in Equation 15 as:\n\\[\n\\begin{align*}\n\\sigma(X_s) &\\approx \\sigma(X_{t_j}) + \\int_{t_j}^{s} \\sigma'(X_{t_j}) (\\sigma(X_{t_j})dB_u)\\\\\n&= \\sigma(X_{t_j}) + \\sigma'(X_{t_j}) \\sigma(X_{t_j}) \\int_{t_j}^{s}  dB_u\\\\\n&= \\sigma(X_{t_j}) + \\sigma'(X_{t_j}) \\sigma(X_{t_j}) (B_s - B_{t_j})\n\\end{align*}\n\\]\nIf we put this back in Equation 14, we get:\n\\[\n\\begin{align*}\nX_{t_{j+1}} - X_{t_j} &\\approx \\sigma(X_{t_j})(B_{t_{j+1}}-B_{t_j}) + \\mu(X_{t_j})(t_{j+1} - t_j) \\\\\n&+ \\sigma'(X_{t_j}) \\sigma(X_{t_j}) \\int_{t_j}^{t_{j+1}} (B(s) - B(t_j))dB(s)\n\\end{align*}\n\\tag{17}\\]\nNow, consider the function \\(f(x)=x^2\\). We have:\n\\[\n\\begin{align*}\nf_x(x) &= 2x\\\\\nf_{xx}(x) &= 2\n\\end{align*}\n\\]\nSo, we get:\n\\[\nB^2(t_{j+1}) - B^2(t_j) = 2 \\int_{t_j}^{t_{j+1}} B(s) dB(s) + \\frac{1}{2} \\int_{t_j}^{t_{j+1}} (2) ds\n\\]\nThus,\n\\[\n\\int_{t_j}^{t_{j+1}} B(s) dB(s) = \\frac{1}{2}[(B_{t_{j+1}}^2 - B_{t_j}^2)-(t_{j+1}-t_j)]\n\\tag{18}\\]\nSubstituting Equation 18 into Equation 17, we get the Milstein approximation:\n\\[\n\\begin{align*}\nX_{t_{j+1}} - X_{t_j} &\\approx \\sigma(X_{t_j})(B_{t_{j+1}}-B_{t_j}) + \\mu(X_{t_j})(t_{j+1} - t_j) \\\\\n&+\\sigma'(X_{t_j}) \\sigma(X_{t_j})  \\left[\\frac{1}{2}((B_{t_{j+1}}^2 - B_{t_j}^2)-(t_{j+1}-t_j)) -  B_{t_j}(B_{t_{j+1}}-B_{t_j})\\right]\\\\\n&= \\sigma(X_{t_j})(B_{t_{j+1}}-B_{t_j}) + \\mu(X_{t_j})(t_{j+1} - t_j) \\\\\n&+ \\frac{\\sigma'(X_{t_j}) \\sigma(X_{t_j})}{2}  \\left[(B_{t_{j+1}}^2 - B_{t_j}^2)-(t_{j+1}-t_j) -  2B_{t_j}B_{t_{j+1}}+2B_{t_j}^2\\right]\\\\\n&= \\sigma(X_{t_j})(B_{t_{j+1}}-B_{t_j}) + \\mu(X_{t_j})(t_{j+1} - t_j) \\\\\n&+ \\frac{\\sigma'(X_{t_j}) \\sigma(X_{t_j})}{2}  \\left[(B_{t_{j+1}} - B_{t_j})^2-(t_{j+1}-t_j)\\right]\n\\end{align*}\n\\]\nThus, under the Milstein scheme\n\\[\n\\begin{align*}\nX_{t_{j+1}} - X_{t_j} &\\approx \\sigma(X_{t_j})(B_{t_{j+1}}-B_{t_j}) + \\mu(X_{t_j})(t_{j+1} - t_j) \\\\\n&+ \\frac{\\sigma'(X_{t_j}) \\sigma(X_{t_j})}{2}  \\left[(B_{t_{j+1}} - B_{t_j})^2-(t_{j+1}-t_j)\\right]\n\\end{align*}\n\\tag{19}\\]\nThe recursive nature of these two schemes makes them easy to implement numerically. The Milstein scheme is not much more costly to implement as it contains only one more term than the Euler scheme.\n\n\n\nLet’s code an SIVP class and an abstract base class Solver.\n\nfrom dataclasses import dataclass\nfrom abc import ABC, abstractmethod\nfrom typing import Callable, Optional\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nsns.set_style(\"whitegrid\")\n\n# More descriptive type hints\nT = np.ndarray\nX = np.ndarray\n\n@dataclass\nclass SIVP:\n    \"\"\"\n    An abstraction for a stochastic initial value problem\n    \"\"\"\n    t_start : float\n    t_end : float\n    initial_condition: float\n\n    drift: Callable[[float, np.ndarray], np.ndarray]\n    vol: Callable[[float, np.ndarray], np.ndarray]\n    dvol_dx: Optional[Callable[[float, np.ndarray], np.ndarray]] = None\n\n\n\n@dataclass\nclass Solver(ABC):\n    \"\"\"\n    An abstract base class for all numerical schemes\n    \"\"\"\n\n    num_steps: int = 100\n    num_paths: int = 100\n\n    def __post_init__(self):\n        self.iter = 0\n\n        # x_values is a matrix of shape [num_paths,num_steps]\n        self.x_values = np.zeros((self.num_paths, self.num_steps + 1))\n        self.step_size = 1.0 / self.num_steps\n\n        # gaussian increments\n        self.brownian_increments = np.sqrt(self.step_size) * np.random.standard_normal(\n            size=(self.num_paths, self.num_steps)\n        )\n        self.brownian = np.cumsum(self.brownian_increments, axis=1)\n        self.brownian = np.concatenate(\n            [np.zeros(shape=(self.num_paths, 1)), self.brownian], axis=1\n        )\n\n    @abstractmethod\n    def iterate(self, sivp: SIVP) -&gt; X:\n        \"\"\"\n        Compute the next iterate X(n+1)\n        \"\"\"\n\n    def solve(self, sivp: SIVP) -&gt; (T, X):\n        \"\"\"\n        Solve the SIVP\n        \"\"\"\n        self.x_values[:, 0] = np.full(\n            shape=(self.num_paths,), fill_value=sivp.initial_condition\n        )\n        while self.iter &lt; self.num_steps:\n            self.x_values[:, self.iter + 1] = self.iterate(sivp)\n            self.iter += 1\n\n        times = np.linspace(sivp.t_start, sivp.t_end, self.num_steps + 1)\n        return times, self.x_values\n\n    def reset(self):\n        self.__post_init__()\n\nThe EulerMaruyama and Milstein methods will derive from the abstract base class Solver.\n\n@dataclass\nclass EulerMaruyama(Solver):\n    \"\"\"\n    Numerical solver for a stochastic differential equation(SDE) using\n    the Euler-Maruyama method.\n\n    Consider an SDE of the form :\n\n    dX_t = mu(t,X_t) dt + sigma(t,X_t) dB_t\n\n    with initial condition X_0 = x_0\n\n    The solution to the SDE can be computed using the increments\n\n    X_{n+1} - X_n = mu(n,X_n)(t_{n+1}-t_n) + sigma(n,X_n)(B(n+1)-B(n))\n\n    \"\"\"\n\n    def iterate(self, sivp: SIVP) -&gt; X:\n        \"\"\"\n        Generate the next iterate X(n+1)\n        \"\"\"\n        current_time = self.iter * self.step_size\n        mu_n = sivp.drift(current_time, self.x_values[:, self.iter])\n        sigma_n = sivp.vol(current_time, self.x_values[:, self.iter])\n        delta_x = (\n            mu_n * self.step_size + sigma_n * self.brownian_increments[:, self.iter]\n        )\n        return self.x_values[:, self.iter] + delta_x\n\n\n@dataclass\nclass Milstein(Solver):\n    \"\"\"\n    Numerical solver for a stochastic differential equation(SDE) using\n    the Euler-Maruyama method.\n\n    Consider an SDE of the form :\n\n    dX_t = mu(t,X_t) dt + sigma(t,X_t) dB_t\n\n    with initial condition X_0 = x_0\n\n    The solution to the SDE can be computed using the increments\n\n    X_{n+1} - X_n = mu(n,X_n)(t_{n+1}-t_n) + sigma(n,X_n)(B(n+1)-B(n))\n    + 0.5 * sigma(n,X_n) * sigma'(n,X_n) * ((B(n+1) - B(n))**2 - (t_{n+1} - t_n))\n\n    \"\"\"\n\n    def iterate(self, sivp: SIVP):\n        \"\"\"\n        Generate the next iterate X(n+1)\n        \"\"\"\n        current_time = self.iter * self.step_size\n        mu_n = sivp.drift(current_time, self.x_values[:, self.iter])\n        sigma_n = sivp.vol(current_time, self.x_values[:, self.iter])\n        dvol_dx_n = sivp.dvol_dx(current_time, self.x_values[:, self.iter])\n\n        delta_x = (\n            mu_n * self.step_size\n            + sigma_n * self.brownian_increments[:, self.iter]\n            + 0.5\n            * sigma_n\n            * dvol_dx_n\n            * (self.brownian_increments[:, self.iter] ** 2 - self.step_size)\n        )\n\n        return self.x_values[:, self.iter] + delta_x\n\n\nExercise 4 (Simulating SDEs) Simulate 100 paths for the following diffusions given by their SDEs on \\([0,1]\\) using the Euler-Maruyama scheme and the Milstein scheme for a discretization of \\(0.01\\).\n\nGeometric Brownian Motion:\n\n\\[\ndS_t = S_t dB_t + \\left(\\mu + \\frac{\\sigma^2}{2}\\right)S_t dt, \\quad S_0 = 1\n\\]\nfor \\(\\mu=-1/2\\), \\(\\mu=-2\\), and \\(\\mu=0\\)\n\nOrnstein-Uhlenbeck process:\n\n\\[\ndX_t = -X_t dt + dB_t, \\quad X_0 = 1\n\\]\n\nThe diffusion:\n\n\\[\ndX_t = \\sqrt{1+X_t^2}dB_t + \\sin X_t dt, \\quad X_0 = 0\n\\]\n\nSolution.\nWe can now use EulerMaruyama and Milstein solvers and generate some sample paths.\n\n\nShow the code\ndef plot_trajectories(ts, xs, title):\n    plt.xlabel(r'Time $t$')\n    plt.ylabel(r'$X(t)$')\n    plt.title(title)\n    plt.grid(True)\n    plt.plot(ts, xs.transpose())\n    plt.show()\n\n# mu = -0.5 case\neuler = EulerMaruyama(num_paths=10, num_steps=100)\n\ngbm_sde = SIVP(\n    t_start=0.0,\n    t_end=1.0,\n    initial_condition=1.0,\n    drift=lambda t, s_t: np.zeros(10),\n    vol=lambda t, s_t: s_t,\n    dvol_dx=lambda t, s_t: np.ones(10),\n)\n\n\nts, xs = euler.solve(gbm_sde)\neuler.reset()\n\nplot_trajectories(ts, xs, r'10 sample paths of Geometric Brownian Motion, $\\mu=-0.5$')\n\n# mu = -2 case\ngbm_sde.drift = lambda t, s_t : -1.5 * s_t\nts, xs = euler.solve(gbm_sde)\neuler.reset()\n\nplot_trajectories(ts, xs, r'10 sample paths of Geometric Brownian Motion, $\\mu=-2.0$')\n\n# mu = 0 case\ngbm_sde.drift = lambda t, s_t : 0.5 * s_t\nts, xs = euler.solve(gbm_sde)\neuler.reset()\n\nplot_trajectories(ts, xs, r'10 sample paths of Geometric Brownian Motion, $\\mu=0.0$')\n\n# ornstein-uhlenbeck\nornstein_uhlenbeck_sde = SIVP(\n    t_start=0.0,\n    t_end=1.0,\n    initial_condition=1.0,\n    drift = lambda t, s_t : -s_t,\n    vol = lambda t, s_t : np.ones(10),\n    dvol_dx = lambda t, s_t : np.zeros(10)\n)\n\nts, xs = euler.solve(ornstein_uhlenbeck_sde)\neuler.reset()\n\nplot_trajectories(ts, xs, r'10 sample paths of Ornstein-Uhlenbeck')\n\n# diffusion\ndiffusion_sde = SIVP(\n    t_start=0.0,\n    t_end=1.0,\n    initial_condition=0.0,\n    drift = lambda t, s_t : np.sin(s_t),\n    vol = lambda t, s_t : np.sqrt(1+s_t**2),\n    dvol_dx = lambda t, s_t : s_t / np.sqrt(1 + s_t**2) \n)\n\nts,xs = euler.solve(diffusion_sde)\neuler.reset()\n\nplot_trajectories(ts, xs, r'10 sample paths of the diffusion')\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nIt is of course possible go beyond the Milstein scheme to improve the approximation. However, it turns out that the above schemes already converge quite rapidly to the process itself. To see this, consider the mean absolute error between the approximation \\(X_T^{(n)}\\) at time \\(T\\) and \\(X_T\\). Suppose that the approximation \\(X^{(n)}\\) is obtained for a partition with discretization \\(t_{j+1}-t_j = 1/n\\). It is possible to show that for the Euler scheme, we have:\n\\[\n\\begin{align*}\n\\mathbb{E}[|X_T^{(n)} - X_T|] \\leq \\frac{C}{\\sqrt{n}}\n\\end{align*}\n\\]\nwhereas for the Milstein scheme\n\\[\n\\begin{align*}\n\\mathbb{E}[|X_T^{(n)} - X_T|] \\leq \\frac{C'}{n}\n\\end{align*}\n\\]\nfor some constants \\(C,C'&gt;0\\). Note that the mean error between the two process must be the worst at the last point, since the errors add up.\n\n\n\n\nAs for the differential equations in standard calculus, SDEs play an important role in modelling stochastic phenomena. To model a trajectory \\(X_t, t\\leq T\\), it suffices to write down the variation due to the deterministic change \\(\\mu(X_t)dt\\) for some function \\(\\mu(X_t)\\) and the variation due to local fluctuations \\(\\sigma(X_t)dB_t\\) for some function \\(\\sigma(X_t)\\). Here, we assume that the local drift and volatility are time-homogenous for simplicity. This gives the SDE:\n\\[\ndX_t = \\mu(X_t) dt + \\sigma(X_t) dB_t\n\\]\nDo we get one nice Ito process for any choice of functions \\(\\sigma\\) and \\(\\mu\\)? The short answer is no. Here are sufficient conditions for the existence of a unique process.\n\nTheorem 4 (Existence and Uniqueness of solutions to SDE) Consider the SDE\n\\[\ndX_t = \\mu(X_t) dt  + \\sigma(X_t)dB_t, \\quad X_0 = x, \\quad t\\in [0,T]\n\\]\nIf the functions \\(\\sigma\\) and \\(\\mu\\) grow not faster than \\(Kx^2\\) for some \\(K&gt;0\\) and are differentiable with bounded derivatives on \\(\\mathbb{R}^1\\), then there exists a unique solution \\((X_t,t\\in[0,T])\\) to the SDE. In other words, there exists a continuous process \\((X_t, t \\leq T)\\) adapted to the filtration of the Brownian motion given by:\n\\[\nX_t = x + \\int_0^t \\mu(X_s) ds + \\int_0^t \\sigma(X_s) dB_s, \\quad t\\leq T\n\\]\n\n\nExample 15 Consider the SDE :\n\\[\ndX_t = \\sqrt{1 + X_t^2}dB_t + \\sin X_t dt\n\\tag{20}\\]\nThere exists a unique diffusion process \\((X_t,t\\geq 0)\\) that is a solution of this SDE. To see this, we verify the conditions of the Theorem 4. We have:\n\\[\n\\sigma(x) = \\sqrt{1 + x^2}, \\quad \\mu(x) = \\sin x\n\\]\nClearly, these functions satisfy the growth condition since \\(\\mu\\) is bounded and \\(\\sigma\\) grows like \\(|x|\\) for large \\(x\\). As for the derivatives, we have \\(\\sigma'(x)=\\frac{x}{\\sqrt{1+x^2}}\\) and \\(\\mu'(x)=\\cos x\\). The two derivatives are bounded.\n\nThe assumptions of Theorem 4 are not too surprising, since similar ones are found in the classical case of ODE. For example, if we have the ODE\n\\[\n\\frac{dX_t}{dt} = X_t^{1/2}, \\quad X_0 = 0\n\\]\nthen clearly \\(X_t = 0\\) for all \\(t\\) is a solution. But, we also have by integrating that:\n\\[\nX_t = \\frac{t^2}{4}, t \\geq 0\n\\]\nTherefore, the uniqueness breaks down. Note, that the function \\(\\mu(x)=\\sqrt{x}\\) does not have bounded derivatives at \\(0\\). Similarly, consider the ODE:\n\\[\n\\frac{dX_t}{dt} = e^{X_t}, X_0 = 0\n\\]\nHere, the function \\(\\mu(x)\\) grows much faster than \\(x^2\\). The solution of the ODE is by integrating\n\\[\n\\begin{align*}\n-(e^{-X_t} - 1) &= t\\\\\ne^{-X_t} &= (1 - t)\\\\\n-X_t &= \\log(1 - t)\\\\\nX_t &= \\log \\left(\\frac{1}{1-t}\\right)\n\\end{align*}\n\\]\nThe solution explodes at \\(t=1\\). The same phenomenon may occur for SDE; that is the process will almost surely go \\(\\infty\\) in finite time. These times are called explosion times. Note that it is possible to consider the paths of the diffusion upto these explosion times. It is important to keep in mind that the conditions of Theorem 4 are sufficient, but not necessary. In particular, it is sometimes possible to explicitly construct a diffusion whose local volatility and drift do not satisfy the conditions. Let’s look at two important instances of such diffusions.\n\nLet \\(B_t\\) be a brownian motion in \\(\\mathbb{R}^d\\) for \\(d&gt;1\\). Consider the process giving the distance at time \\(t\\) of \\(B_t\\) to the origin; that is:\n\\[\nR_t = ||B_t|| = \\left(\\sum_{j=1}^d B_t^{(j)}\\right)^2\n\\]\n(For \\(d=1\\), this is simply \\(|B_t|\\). Ito’s formula cannot be applied in this case, since the absolute value is not differentiable at the origin.) In higher dimensions, the function is smooth enough as long as we stay away from the origin. This is not a problem as long as \\(R_0 &gt; 0\\).\n\nLet’s find out the SDE that this process satisfies.\nLet \\(r=f(x_1,x_2,\\ldots,x_d)=\\sqrt{\\sum_{j=1}^d x_j^2}\\). We have:\n\\[\\begin{align*}\n\\frac{\\partial r}{\\partial x_j} &= \\frac{x_j}{\\sqrt{\\sum_{j=1}^d x_j^2}}\\\\\n\\frac{\\partial^2 r}{\\partial x_j^2} &= \\frac{||x|| - x_j \\cdot \\frac{x_j}{||x||}}{||x||^2}\\\\\n&= \\frac{||x||^2 - x_j^2}{||x||^3}\n\\end{align*}\\]\nBy Ito’s formula,\n\\[\\begin{align*}\ndR_t &= \\sum_{j=1}^{d} \\frac{B_t^{j}}{R_t} dB_t^{(j)} + \\frac{1}{2} \\sum_{j=1}^{d} \\frac{R_t^2 - (B_t^{(j)})^2}{R_t^3}\\\\\n&= \\sum_{j=1}^{d} \\frac{B_t^{j}}{R_t} dB_t^{(j)} + \\frac{1}{2} \\frac{d R_t^2 - R_t^2}{R_t^3}\\\\\n&= \\sum_{j=1}^{d} \\frac{B_t^{j}}{R_t} dB_t^{(j)} + \\frac{1}{2} \\frac{(d-1)}{R_t}\n\\end{align*}\\]\nWe can define \\(dW_t = \\sum_{j=1}^{d} \\frac{B_t^{(j)}}{R_t} dB_t^{(j)}\\). Then, \\(dR_t = dW_t + \\frac{d-1}{2R_t}dt\\)\nIt turns out that \\((W_t,t \\geq 0)\\) is a standard Brownian motion by Levy’s characterization theorem. This is the subject of the next section. The SDE shows that \\(dR_t\\) is a diffusion. The SDE makes sense for any real number \\(d &gt; 1\\), not only integers. Moreover, the SDE is well-defined since \\(R_t\\) is never equal to \\(0\\). However, the SDE does not satisfy the assumption of the existence and uniqueness of the solution of SDEs since \\(1/x\\) diverges at \\(0\\). The solution to the SDE still exists since we constructed it! We sample paths of this process in numerical project.\n\nExample 16 (The Cox-Ingersoll-Ross (CIR) model.) Consider the SDE:\n\\[\ndS_t = \\sigma \\sqrt{S_t} dW_t + (a - bS_t)dt, \\quad S_0 &gt; 0\n\\tag{21}\\]\nfor some parameters \\(a,b &gt; 0\\) where \\((W_t,t \\geq 0)\\) is a standard Brownian motion. The local volatility \\(\\sigma(x)=\\sigma \\sqrt{x}\\) does not have a bounded derivative close to \\(0\\), since \\(\\sigma'(x)=\\frac{\\sigma}{2\\sqrt{x}}\\). We will nevertheless construct a diffusion that is a solution to the SDE. Consider independent Ornstein-Uhlenbeck processes \\(X_t^{(j)}, j \\leq d\\), with SDE:\n\\[\ndX_t^{(j)} = \\frac{-b}{2}X_t^{(j)}dt + \\frac{\\sigma}{2}dB_t^{(j)}, \\quad X_0^{(j)} &gt; 0\n\\]\nwhere \\(B_t = (B_t^{(j)},j\\leq d)\\) is a Brownian motion in \\(\\mathbb{R}^d\\). We consider the process\n\\[\nS_t = \\sum_{j \\leq d} (X_t^{(j)})^2\n\\]\nClearly, \\(S_t\\) is nongegative for all \\(t \\geq 0\\) by design, so \\(\\sqrt{S_t}\\) is well-defined. Let’s compute the SDE of the process. By Ito’s formula, we have:\n\\[\n\\begin{align*}\ndS_t &= 2\\sum_{j=1}^{d}X_t^{(j)} dX_t^{(j)} + \\frac{1}{2}\\sum_{j=1}^{d} 2 (dX_t^{(j)})^2\\\\\n&=2\\sum_{j=1}^{d}X_t^{(j)} dX_t^{(j)} + \\frac{\\sigma^2}{4}\\sum_{j=1}^{d} dt \\\\\n&=2\\sum_{j=1}^{d}X_t^{(j)} \\left(\\frac{-b}{2}X_t^{(j)}dt + \\frac{\\sigma}{2}dB_t^{(j)}\\right) + \\frac{d\\sigma^2}{4} dt\\\\\n&=\\left[\\left(\\sum_{j=1}^d (-b)(X_t^{(j)})^2\\right) + \\frac{d\\sigma^2}{4}\\right] dt + \\sigma \\sum_{j=1}^{d} X_t^{(j)} dB_t^{(j)}\\\\\n&=\\sigma \\sum_{j=1}^{d} X_t^{(j)} dB_t^{(j)} + \\left[\\frac{d\\sigma^2}{4} - b S_t\\right] dt \\\\\n&= \\sigma \\sqrt{S_t} \\sum_{j=1}^{d} \\frac{X_t^{(j)}}{\\sqrt{S_t}} dB_t^{(j)}  + \\left[\\frac{d\\sigma^2}{4} - b S_t\\right] dt \\\\\n&= \\sigma \\sqrt{S_t} dW_t  + \\left[\\frac{d\\sigma^2}{4} - b S_t\\right] dt \\\\\n\\end{align*}\n\\]\nwhere we have defined \\(dW_t = \\sum_{j=1}^d \\frac{X_t^{(j)}}{\\sqrt{S_t}} dB_t^{(j)}\\). It turns out that the process \\((W_t,t\\geq 0)\\) is a standard brownian motion by Levy’s characterization theorem. If we accept this for a moment, we have the SDE:\n\\[\ndS_t = \\sigma \\sqrt{S_t} dW_t + \\left(\\frac{d \\sigma^2}{4} - bS_t\\right) dt, \\quad S_0 &gt; 0\n\\tag{22}\\]\nThis is a time-homogenous diffusion called the Cox-Ingersoll-Ross (CIR) process. Again, notice that there are no issues with square root, since \\(S_t\\) is positive by construction! The SDE also makes sense if replace \\(d\\sigma^2/4\\) by a parameter \\(a\\) in Equation 21 as long as \\(a \\geq \\frac{d\\sigma^2}{4}\\). This process is important for interest rates and stochastic volatility models.\nNote that the local drift is \\(a - bS_t, a\\ge \\frac{d\\sigma^2}{4}\\). This can be written as:\n\\[\\begin{align*}\na - bS_t = b\\left(\\frac{b}{a} - S_t \\right)\n\\end{align*}\\]\nThis means that the local drift is negative if \\(S_t &gt; \\frac{a}{b}\\) and it is positive if \\(S_t &lt; \\frac{a}{b}\\). So, the SDE exhibits the same phenomenon as for the SDE of the Ornstein-Uhlenbeck process in Example 5. In particular we should expect that for \\(t\\) large, the process should fluctuate around the mean value \\(\\frac{a}{b}\\). The CIR model is therefore an example of a mean-reverting process. More generally, this hints to the fact, that the process is stationary in the long run.\n\n\n\n\nWe know very well by now, that an Ito integral is continuous martingale with respect to the Brownian filtration, whenever the integrand is in \\(\\mathcal{L}_c^2(T)\\). What can we say about the converse? In other words, if we have a martingale with respect to the Brownian filtration, can it be expressed as an Ito integral for some integrand \\((V_t,t\\leq T)\\)? Amazingly, the answer to this question is yes!\n\nTheorem 5 (Martingale Representation Theorem.) Let \\((B_t,t \\geq 0)\\) be a Brownian motion with filtration \\((\\mathcal{F}_t,t\\geq 0)\\) on \\((\\Omega,\\mathcal{F},\\mathbb{P})\\). Consider a martingale \\((M_t,t\\leq T)\\) with respect to this filtration. Then, there exists an adapted process \\((V_t,t \\leq T)\\) such that:\n\\[\nM_t = M_0 + \\int_0^t V_s dB_s, \\quad t \\leq T\n\\tag{23}\\]\nOne striking fact of the result is that \\((M_t,t\\leq T)\\) ought to be continuous. In other words, we cannot construct a process with a jump that is a martingale adapted to Brownian motion!\nInstead of the proving the theorem, we will see how the result is not too surprising with stronger assumptions. Instead of supposing that \\(M_t\\) is \\(\\mathcal{F}_t\\) measurable, take that \\(M_t\\) is \\(\\sigma(B_t)\\)-measurable. In other words, \\(M_t=h(B_t)\\) for some function \\(h\\). In the case where \\(h\\) is smooth, then it is clear by Ito’s formula that the representation Equation 23 holds with \\(V_s = h'(B_s)\\).\n\nAn important consequence of Theorem 5 is a third definition of Brownian motion.\n\nTheorem 6 (One-dimensional Levy’s Characterization theorem) Let \\((M_t,t\\in [0,T])\\) be a continuous martingale with respect to the filtration \\((\\mathcal{F}_t,t \\leq T)\\) with \\(M_0 = 0\\) and with quadratic variation \\(&lt;M&gt;_t = t\\). Then, \\((M_t,t\\leq T)\\) is a standard brownian motion.\n\nProof.\nWe first need to show that \\(M_t - M_s \\sim \\mathcal{N}(0,t - s)\\) or using the characteristic function approach, we need to show that \\(f_{(M_t - M_s)}(\\theta)=\\mathbb{E}[e^{\\theta (M_t - M_s)}] = e^{\\frac{1}{2}\\theta^2 (t-s)}\\) for constant \\(\\theta\\).\nLet \\(f(t,x) = e^{\\theta x - \\frac{1}{2}\\theta^2 t}\\).\nBy Ito’s formula, we have:\n\\[\\begin{align*}\ndf(t,M_t) &= \\theta e^{\\theta M_t - \\frac{1}{2}\\theta^2 t} dM_t + \\left(-\\frac{1}{2}\\theta^2 + \\frac{1}{2} \\theta^2 \\right)e^{\\theta M_t - \\frac{1}{2}\\theta^2 t}dt\\\\\n&= \\theta f(t,M_t) dM_t\n\\end{align*}\\]\nIntegrating on both sides, we get:\n\\[\\begin{align*}\nf(t,M_t) - f(s,M_s) &= \\theta \\int_0^t f(u,M_u) dM_u\n\\end{align*}\\]\nThe ito integral \\(\\int_0^t f(s,M_s) dM_s\\) is well-defined and its expectation is \\(0\\). Hence, applying expectation operator on both sides, we get:\n\\[\\begin{align*}\n\\mathbb{E}[f(t,M_t) - f(s,M_s)] &= \\theta \\mathbb{E} \\left[ \\int_0^t f(s,M_s) dM_s\\right]\\\\\n&= 0\n\\end{align*}\\]\nSince \\(e^{x} \\neq 0\\) for all \\(x\\), dividing by \\(f(s,M_s)\\), we get:\n\\[\\begin{align*}\n\\mathbb{E}\\left[\\frac{f(t,M_t)}{f(s,M_s)}\\right] &= 1\\\\\n\\mathbb{E}\\left[\\frac{e^{\\theta M_t - \\frac{1}{2}\\theta^2 t}}{e^{\\theta M_s - \\frac{1}{2}\\theta^2 s}}\\right] &= 1\\\\\n\\mathbb{E}\\left[e^{\\theta(M_t - M_s)}\\right] &= e^{\\frac{1}{2}\\theta^2(t-s)}\n\\end{align*}\\]\nwhich is the moment generating function for the normal distribution with mean zero and variance \\(t-s\\). So, \\(M_t - M_s \\sim \\mathcal{N}(0, t - s)\\).\nFurther, consider \\(t_1 \\leq t_2 \\leq t_3\\). We have:\n\\[\\begin{align*}\n\\mathbb{E}[(M_{t_3} - M_{t_2})(M_{t_2} - M_{t_1})] &= \\mathbb{E}[\\mathbb{E}[(M_{t_3} - M_{t_2})(M_{t_2} - M_{t_1})|\\mathcal{F}_{t_2}]] \\\\\n&= \\mathbb{E}[(M_{t_2} - M_{t_1})\\mathbb{E}[(M_{t_3} - M_{t_2})|\\mathcal{F}_{t_2}]] \\\\\n&= \\mathbb{E}[(M_{t_2} - M_{t_1})(M_{t_2} - M_{t_2})] \\\\\n&= 0\n\\end{align*}\\]\nwhere \\(\\mathbb{E}[M_{t_3} - M_{t_2}|\\mathcal{F}_{t_2}] = 0\\) follows from the fact that \\((M_t,t\\geq 0)\\) is a martingale. Consequently, \\(M_{t_3} - M_{t_2} \\perp M_{t_2} - M_{t_1}\\) and non-overlapping increments are independent.\nMoreover, \\(M(0) = 0\\). So, \\((M_t,t\\geq 0)\\) is a standard brownian motion. This closes the proof. \\(\\blacksquare\\)\n\n\n\n\nExercise 5 Let \\((\\Omega,\\mathcal{F},\\mathbb{P})\\) be a probability space and \\((W_t,t\\geq 0)\\) be a standard Wiener process. Find the SDE for the random process \\(X_t = W_t^n, n \\in \\mathbb{Z}^{+}\\).\nShow that\n\\[\n\\mathbb{E}[W_t^n] = \\frac{1}{2}n(n-1) \\int_0^t \\mathbb{E}\\left[W_s^{(n-2)}\\right] ds\n\\]\nand using mathematical induction prove that:\n\\[\n\\mathbb{E}[W_t^n] = \\begin{cases}\n\\frac{n! t^{n/2}}{2^{n/2} \\left(\\frac{n}{2}\\right)!}, & n=2,4,6,\\ldots\\\\\n0, & n=1,3,5,\\ldots\n\\end{cases}\n\\]\n\nSolution."
  },
  {
    "objectID": "posts/ito-processes-and-stochastic-diff-eqs/index.html#itos-formula.",
    "href": "posts/ito-processes-and-stochastic-diff-eqs/index.html#itos-formula.",
    "title": "Ito Processes and Stochastic Differential Equations",
    "section": "",
    "text": "The first step towards a general Ito’s formula is the quadratic variation of an Ito process.\n\nProposition 1 (Quadratic variation of an Ito process.) Let \\((B(t),t\\geq0)\\) be a standard Brownian motion and \\((X(t):t\\geq0)\\) be an Ito process of the form \\(dX(t)=V(t)dB(t)+D(t)dt\\). Then, the quadratic variation of the process \\((X(t):t\\geq0)\\) is:*\n\\[\\begin{aligned}\n&lt;X,X&gt;_{t} & =\\lim_{n\\to\\infty}\\sum_{j=0}^{n-1}(X(t_{j+1})-X(t_{j}))^{2}=\\int_{0}^{t}V(s)^{2}ds\n\\end{aligned} \\tag{5}\\]\nfor any partition \\((t_{j},j\\leq n)\\) of \\([0,t]\\), where the limit is in probability.\n\n\nNote that the quadratic variation is increasing in \\(t\\), but it is not deterministic in general! \\(V_t\\) is a random variable. The quadratic variation is a smooth stochastic process. (It is differentiable) Observe that we recover the quadratic variation for the Brownian motion for \\(V(t)=1\\) as expected. We also notice that the formula follows easily from the rules of Ito Calculus, thereby showing the consistency of the theory. Indeed we have:\n\\[\\begin{aligned}\nd&lt;X,X&gt;_{t} & =(dX(t))^{2}=(V(t)dB(t)+D(t)dt)^{2}\\\\\n& =V(t)^{2}(dB(t))^{2}+2V(t)D(t)dB(t)\\cdot dt+D^{2}(t)(dt)^{2}\\\\\n& =V(t)^{2}dt\n\\end{aligned}\\]\n\n\nProof. Proof. The proof is involved, but it reviews some important concepts of stochastic calculus. We prove the case when the process \\(V\\) is in \\(\\mathcal{L}_{c}^{2}(T)\\) for some \\(T&gt;0\\). We write \\(I(t)=\\int_{0}^{t}V(s)dB(s)\\) and \\(R(t)=\\int_{0}^{t}D(s)ds\\). We first show that only the Ito integral contributes to the quadratic variation and the Riemann integral does not contribute, so that:\n\\[\\begin{aligned}\n&lt;X,X&gt;_{t} & =&lt;I,I&gt;_{t}\n\\end{aligned} \\tag{6}\\]\nWe have that the increment square of \\(X(t)\\) is:\n\\[\\begin{aligned}\n(X(t_{j+1})-X(t_{j}))^{2} & =(I(t_{j+1})-I(t_{j}))^{2}+2(I(t_{j+1})-I(t_{j}))(R(t_{j+1})-R(t_{j}))+(R(t_{j+1})-R(t_{j}))^{2}\n\\end{aligned}\\]\nThe Cauchy-Schwarz inequality implies :\n\\[\\begin{aligned}\n\\sum_{j=0}^{n-1}(I(t_{j+1})-I(t_{j}))(R(t_{j+1})-R(t_{j})) & \\leq\\left(\\sum_{j=0}^{n-1}(I(t_{j+1})-I(t_{j}))^{2}\\right)^{1/2}\\left(\\sum_{j=0}^{n-1}(R(t_{j+1})-R(t_{j}))^{2}\\right)^{1/2}\n\\end{aligned}\\]\nTherefore, to prove equation Equation 5, it suffices to show that \\(\\sum_{j=0}^{n-1}(R(t_{j+1})-R(t_{j}))^{2}\\to 0\\) almost surely. Since \\(D(s)\\) is an almost surely continuous process, the stochastic process \\(R(t)=\\int_{0}^{t}D(s)ds\\) has continuous paths with probability \\(1\\). Therefore:\n\\[\\begin{aligned}\n\\sum_{j=0}^{n-1}(R(t_{j+1})-R(t_{j}))^{2} & =\\max_{1\\leq j\\leq n}|R(t_{j+1})-R(t_{j})|\\sum_{j=0}^{n-1}(R(t_{j+1})-R(t_{j}))\n\\end{aligned}\\]\nSince, \\(R(t)\\) is continuous on the compact set \\([0,t]\\), it is uniformly continuous a.s. So, as \\(|t_{j+1}-t_{j}|\\to 0\\), by uniform continuity it follows that \\(\\max|R(t_{j+1})-R(t_{j})|\\to 0\\) a.s.\nIt remains to prove that \\(&lt;I,I&gt;_{t}=\\int_{0}^{t}V(s)^{2}ds\\). We first prove the case when \\(V\\in\\mathcal{S}(T)\\) is a simple adapted process. Consider a partition \\((t_{j}:j\\leq n)\\) of \\([0,t]\\). Without loss of generality, we can suppose that \\(V\\) is constant on each \\([t_{j},t_{j+1})\\) by refining the partition. We then have:\n\\[\\begin{aligned}\n\\sum_{j=0}^{n-1}(I(t_{j+1})-I(t_{j}))^{2} & =\\sum_{j=0}^{n-1}V(t_{j})^{2}(B(t_{j+1})-B(t_{j}))^{2}\n\\end{aligned}\\]\nNow, we have seen in the proof of Ito’s formula that \\(\\mathbb{E}\\left[\\left\\{ \\sum_{j=0}^{n-1}V(t_{j})^{2}((B(t_{j+1})-B(t_{j}))^{2}-(t_{j+1}-t_{j})\\right\\} ^{2}\\right]\\to 0\\), so \\(\\sum_{j=0}^{n-1}V(t_{j})^{2}(B(t_{j+1})-B(t_{j}))^{2}\\) approaches \\(\\sum_{j=0}^{n-1}V(t_{j})^{2}(t_{j+1}-t_{j})\\) in the mean square sense. As the mesh size becomes finer, the \\(L^{2}\\)-limit is \\(\\int_{0}^{t}V(t)^{2}dt\\).\nThe case \\(V\\in\\mathcal{L}_{c}^{2}(T)\\) is proved by approximating \\(V\\) by a simple process in \\(\\mathcal{S}(T)\\). More precisely, we can find a simple process \\(V^{(\\epsilon)}(t)\\) that is \\(\\epsilon\\)-close to \\(V\\) in the sense:\n\\[\\begin{aligned}\n||I^{(\\epsilon)}-I|| & =||\\int V^{\\epsilon}dB(t)-\\int VdB(t)||=\\int_{0}^{t}\\mathbb{E}[(V^{(\\epsilon)}(t)-V(t))^{2}]ds&lt;\\epsilon\n\\end{aligned} \\tag{7}\\]\nTo prove the claim, we need to show that for \\(t\\leq T\\),\n\\[\\begin{aligned}\n\\mathbb{E}\\left[\\left|\\sum_{j=0}^{n-1}(I(t_{j+1})-I(t_{j}))^{2}-\\int_{0}^{t}(V(s))^{2}ds\\right|\\right] & \\to0\\quad\\text{as }\\quad n\\to\\infty\n\\end{aligned}\\]\n\\(L^{1}\\)-convergence implies convergence in probability of the sequence \\(\\sum_{j=0}^{n-1}(I(t_{j+1})-I(t_{j}))^{2}\\). We now introduce the \\(V^{(\\epsilon)}(t)\\) approximation inside the absolute value as well as its corresponding integral \\(I^{(\\epsilon)}(t)=\\int_{0}^{t}V^{(\\epsilon)}(s)ds\\). By the triangle inequality, we have:\n\\[\\begin{aligned}\n& \\mathbb{E}\\left[\\left|\\sum_{j=0}^{n-1}(I(t_{j+1})-I(t_{j}))^{2}-\\int_{0}^{t}(V(s))^{2}ds\\right|\\right]\\nonumber \\\\\n= & \\mathbb{E}\\left[\\Biggl|\\sum_{j=0}^{n-1}(I(t_{j+1})-I(t_{j}))^{2}-(I^{(\\epsilon)}(t_{j+1})-I^{(\\epsilon)}(t_{j}))^{2}+(I^{(\\epsilon)}(t_{j+1})-I^{(\\epsilon)}(t_{j}))^{2}-\\int_{0}^{t}(V^{(\\epsilon)}(s))^{2}ds\\right.\\nonumber \\\\\n& +\\int_{0}^{t}(V^{(\\epsilon)}(s))^{2}ds-\\int_{0}^{t}(V(s))^{2}ds\\Biggr|\\Biggr]\\nonumber \\\\\n\\leq & \\mathbb{E}\\left[\\left|\\sum_{j=0}^{n-1}(I(t_{j+1})-I(t_{j}))^{2}-(I^{(\\epsilon)}(t_{j+1})-I^{(\\epsilon)}(t_{j}))^{2}\\right|\\right]+\\mathbb{E}\\left[\\left|\\sum_{j=0}^{n-1}(I^{(\\epsilon)}(t_{j+1})-I^{(\\epsilon)}(t_{j}))^{2}-\\int_{0}^{t}(V^{(\\epsilon)}(s))^{2}ds\\right|\\right]\\\\\n& +\\mathbb{E}\\left[\\Biggl|\\int_{0}^{t}(V^{(\\epsilon)}(s))^{2}ds-\\int_{0}^{t}(V(s))^{2}ds\\Biggr|\\right]\\nonumber\n\\end{aligned} \\tag{8}\\]\nWe show that the first and third terms converge uniformly and that the second term goes to \\(0\\) as \\(n\\to\\infty\\).\nThe second term goes to \\(0\\) as \\(n\\to\\infty\\) by the argument for simple processes.\n\\(&lt;I^{(\\epsilon)},I^{(\\epsilon)}&gt;_{t}=\\int_{0}^{t}V^{(\\epsilon)}(s)^{2}ds\\).\nFor the third term, the linearity of the integral and the Cauchy Schwarz inequality (applied to \\(\\mathbb{E}\\int_{0}^{t}\\)) imply that it is:\n\\[\\begin{aligned}\n\\mathbb{E}\\left[\\Biggl|\\int_{0}^{t}(V^{(\\epsilon)}(s))^{2}ds-\\int_{0}^{t}(V(s))^{2}ds\\Biggr|\\right] & \\leq\\mathbb{E}\\left[\\Biggl|\\int_{0}^{t}(V^{(\\epsilon)}(s)-V(s))^{2}ds\\Biggr|\\right]^{1/2}\\mathbb{E}\\left[\\Biggl|\\int_{0}^{t}(V^{(\\epsilon)}(s)+V(s))^{2}ds\\Biggr|\\right]^{1/2}\n\\end{aligned}\\]\nThe first factor is smaller than the square root of \\(\\epsilon\\) by Equation 7, whereas the second factor is bounded.\nThe first term in equation Equation 8 is handled similarly. The linearity of the Ito integral and the Cauchy-Schwarz inequality applied to \\(\\mathbb{E}\\left[\\sum_{j=0}^{n-1}\\left(\\int_{t_{j}}^{t_{j+1}}\\cdot\\right)\\right]\\) give that the first term is:\n\\[\\begin{aligned}\n& \\mathbb{E}\\left[\\left|\\sum_{j=0}^{n-1}\\int_{t_{j}}^{t_{j+1}}(V(s))^{2}dB(s)-\\int_{t_{j}}^{t_{j+1}}(V^{\\epsilon}(s))^{2}dB(s)\\right|\\right]\\\\\n= & \\mathbb{E}\\left[\\left|\\sum_{j=0}^{n-1}\\int_{t_{j}}^{t_{j+1}}(V(s)-V^{\\epsilon}(s))dB(s)\\int_{t_{j}}^{t_{j+1}}(V(s)+V^{\\epsilon}(s))dB(s)\\right|\\right]\\\\\n\\leq & \\mathbb{E}\\left[\\sum_{j=0}^{n-1}\\left(\\int_{t_{j}}^{t_{j+1}}(V(s)-V^{\\epsilon}(s))dB(s)\\right)^{2}\\right]^{1/2}\\mathbb{E}\\left[\\Biggl|\\sum_{j=0}^{n-1}\\left(\\int_{t_{j}}^{t_{j+1}}(V(s)+V^{\\epsilon}(s))dB(s)\\right)^{2}\\Biggr|\\right]^{1/2}\n\\end{aligned}\\]\nBy Ito isometry, the first factor in the above expression can be simplified:\n\\[\\begin{aligned}\n\\mathbb{E}\\left[\\sum_{j=0}^{n-1}\\left(\\int_{t_{j}}^{t_{j+1}}(V(s)-V^{\\epsilon}(s))dB(s)\\right)^{2}\\right]^{1/2} & =\\sum_{j=0}^{n-1}\\mathbb{E}\\left(\\int_{t_{j}}^{t_{j+1}}(V(s)-V^{\\epsilon}(s))dB(s)\\right)^{2}\\\\\n& =\\sum_{j=0}^{n-1}\\int_{t_{j}}^{t_{j+1}}\\mathbb{E}[(V(s)-V^{\\epsilon}(s))^{2}]ds\n\\end{aligned}\\]\nBy Equation 7, this factor is smaller than \\(\\epsilon\\). The second factor equals \\(\\sum_{j=0}^{n-1}\\int_{t_{j}}^{t_{j+1}}\\mathbb{E}[(V(s)+V^{\\epsilon}(s))^{2}]ds\\) by Ito-isometry and is uniformly bounded. This concludes the proof of the proposition. \\(\\blacksquare\\)\n\nNote that quadratic variation \\(&lt;I,I&gt;_{t}=\\int(V(s))^{2}ds\\) is computed path-by-path and hence the result is random. On the other the variance of the Ito integral \\(Var(I(t))=\\mathbb{E}[I_{t}^{2}]=\\int\\mathbb{E}[V_{s}^{2}]ds\\) is the mean value of all possible paths of the quadratic variation and hence is non-random. We are now ready to state Ito’s formula for Ito processes. We write the result in differential form for conciseness.\n\nTheorem 1 (Ito’s formula for Ito processes) Let \\((B(t):t\\geq0)\\) be a standard brownian motion, and let \\((X(t):t\\geq0)\\) be an Ito process of the form \\(dX(t)=V(t)dB(t)+D(t)dt\\). Consider a function \\(f(t,x)\\in\\mathcal{C}^{1,2}([0,T]\\times\\mathbf{R})\\). Then we have with probability one for all \\(t\\leq T\\):*\n\\[\\begin{aligned}\ndf(t,X(t)) & =\\partial_{x}f(t,X(t))dX(t)+\\partial_{t}f(t,X(t))dt+\\frac{1}{2}\\partial_{xx}f(t,X(t))d&lt;X,X&gt;_{t}\n\\end{aligned}\\]\nThis can also be written as:\n\\[\\begin{aligned}\ndf(t,X(t))= & \\partial_{x}f(t,X(t))V(t)dB(t)+\\left[\\partial_{x}f(t,X(t))D(t)+\\partial_{t}f(t,X(t))+\\frac{1}{2}(V(t))^{2}\\partial_{xx}f(t,X(t))\\right]dt\n\\end{aligned}\\]\n\nThe proof of the Theorem 1 is again a Taylor approximation with the form of the quadratic variation of the process. We will omit it.\n\nExample 5 (Ornstein-Uhlenbeck Process). Consider the Ornstein-Uhlenbeck process \\((Y(t):t\\geq0)\\):\n\\[\\begin{aligned}\nY(t) & =Y(0)e^{-t}+e^{-t}\\int_{0}^{t}e^{s}dB(s)\n\\end{aligned}\\]\nNote that this process is an explicit function of \\(t\\) and of the Ito process \\(X(t)=Y(0)+\\int_{0}^{t}e^{s}dB(s)\\). Indeed, we have:\n\\[\\begin{aligned}\nY(t) & =e^{-t}X(t)\n\\end{aligned}\\]\nLet \\(f(t,x)=e^{-t}x\\). Then, \\(f_{x}(t,x)=e^{-t}\\), \\(f_{xx}(t,x)=0\\) and \\(f_{t}(t,x)=-e^{-t}x\\). So, by Ito’s lemma,\n\\[\\begin{aligned}\ndf(t,x) & =f_{t}(t,X(t))dt+f_{x}(t,X(t))dX(t)+\\frac{1}{2}f_{xx}(t,X(t))d&lt;X,X&gt;_{t}\\nonumber \\\\\ndY(t) & =-Y(t)dt+e^{-t}dX(t)\\nonumber \\\\\ndY(t) & =-Y(t)dt+e^{-t}(e^{t}dB(t))\\nonumber \\\\\ndY(t) & =-Y(t)dt+dB(t)\n\\end{aligned} \\tag{9}\\]\nThis is the SDE for the Ornstein Uhlenbeck process.\nThe SDE has a very nice interpretation: The drift is positive if \\(Y(t)&lt;0\\) and negative if \\(Y(t)&gt;0\\). Moreover, the drift is proportional to the position (exactly like a spring pulling the process back to the \\(x\\)-axis following the Hooke’s law!). This is the mechanism that ensures that the process does not venture too far from \\(0\\) and is eventually stationary.\nThe SDE Equation 9 is now easily generalized by adding two parameters for the volatility and the drift:\n\\[\\begin{aligned}\ndY(t) & =-kY(t)dt+\\sigma dB(t),\\quad k\\in\\mathbf{R},\\sigma&gt;0\n\\end{aligned} \\tag{10}\\]\nIt is not hard to check that the solution to the SDE is:\n\\[\\begin{aligned}\nY(t) & =Y(0)e^{-kt}+e^{-kt}\\int_{0}^{t}e^{ks}\\sigma dB(s)\n\\end{aligned} \\tag{11}\\]\n\n\nExercise 1 The Ornstein-Uhlenbeck process with parameters. Use the Ito’s formula to show that the Equation 11 is the solution to the Ornstein-Uhlenbeck SDE Equation 10.\n\nSolution.\nLet \\(X(t)=Y(0)+\\int_{0}^{t}e^{ks}\\sigma dB(s)\\), so \\(dX(t)=e^{kt}\\sigma dB(t)\\). Then, \\(Y(t)=e^{-kt}X(t)\\). Let \\(f(t,x)=e^{-kt}x\\). Then, by Ito’s formula:\n\\[\\begin{aligned}\ndf(t,x) & =-ke^{-kt}X(t)dt+e^{-kt}dX(t)\\\\\ndY(t) & =-kY(t)dt+e^{-kt}e^{kt}\\sigma dB(t)\\\\\ndY(t) & =-kY(t)dt+\\sigma dB(t)\n\\end{aligned}\\]\nThe latest version of Ito’s formula is another useful tool for producing martingales from a function of an Ito process. We start with two examples generalizing martingales for Brownian motion.\n\nExample 6 (A generalization of \\((B(t))^{2}-t\\)). Let \\((V(t):t\\leq T)\\) be a process in \\(\\mathcal{L}_{c}^{2}(T)\\). Consider an Ito process \\((X(t):t\\leq T)\\) given by \\(dX(t)=V(t)dB(t)\\). Note that \\(((X(t))^{2}:t\\leq T)\\) is a submartingale by Jensen’s inequality, since \\(\\mathbb{E}[X^{2}(t)|\\mathcal{F}_{s}]\\geq(\\mathbb{E}[X(t)|\\mathcal{F}_{s})^{2}=X^{2}(s)\\). We show that the compensated process\n\\[\\begin{aligned}\nM(t) & =X^{2}(t)-\\int_{0}^{t}V^{2}(s)ds,\\quad t\\leq T\n\\end{aligned}\\]\nis a martingale for the Brownian filtration. (This is another instance of the Doob-Meyer decomposition). By the Ito’s formula for \\(f(x)=x^{2}\\), we have:\n\\[\\begin{aligned}\ndf(x) & =f_{x}(X(t)dX(t)+\\frac{1}{2}f_{xx}(X(t))d&lt;X,X&gt;_{t}\\\\\n& =2X(t)dX(t)+(V(t))^{2}dt\\\\\ndf(X(t)) & =2X(t)V(t)dB(t)+(V(t))^{2}dt\n\\end{aligned}\\]\nIn Integral form this implies:\n\\[\\begin{aligned}\n(X(t))^{2} & =(X(0))^{2}+2\\int_{0}^{t}X(s)V(s)dB(s)+\\int_{0}^{t}(V(s))^{2}ds\\\\\nM(t)=(X(t))^{2}-\\int_{0}^{t}(V(s))^{2}ds & =(X(0))^{2}+2\\int_{0}^{t}X(s)V(s)dB(s)\n\\end{aligned}\\]\nWe conclude that \\((M(t):t\\leq T)\\) is a martingale, provided \\(X(t)V(t)\\in L_{c}^{2}(T)\\).\nThere is another more direct way to prove that \\((M(t):t\\leq T)\\) is a martingale whenever \\((V(t):t\\leq T)\\in\\mathcal{L}_{c}^{2}(T)\\). This is by using increments: for \\(t'&lt;t\\leq T\\),\n\\[\\begin{aligned}\n\\mathbb{E}[X_{t'}^{2}|\\mathcal{F}_{t}] & =\\mathbb{E}[(X_{t}+(X_{t'}-X_{t}))^{2}|\\mathcal{F}_{t}]\\\\\n& =\\mathbb{E}[X_{t}^{2}+2X_{t}(X_{t'}-X_{t})+(X_{t'}-X_{t})^{2}|\\mathcal{F}_{t}]\\\\\n& =X_{t}^{2}+2X_{t}\\mathbb{E}[X_{t'}-X_{t}|\\mathcal{F}_{t}]+\\mathbb{E}[(X_{t'}-X_{t})^{2}|\\mathcal{F}_{t}]\n\\end{aligned}\\]\nSince \\((X_{t}:t\\geq0)\\) is a martingale, \\(\\mathbb{E}[(X_{t'}-X_{t})|M_{t}]=0\\), so the middle term equals zero and we are left with:\n\\[\\begin{aligned}\n\\mathbb{E}[X_{t'}^{2}|\\mathcal{F}_{t}] & =X_{t}^{2}+\\mathbb{E}[(X_{t'}-X_{t})^{2}|\\mathcal{F}_{t}]\n\\end{aligned}\\]\nBy conditional Ito Isometry,\n\\[\\begin{aligned}\n\\mathbb{E}[(X_{t'}-X_{t})^{2}|\\mathcal{F}_{t}] & =\\int_{0}^{t'}V_{s}^{2}ds-\\int_{0}^{t}V_{s}^{2}ds=\\int_{t}^{t'}V_{s}^{2}ds\n\\end{aligned}\\]\n\n\nExample 7 (A generalization of the geometric Brownian motion). Let \\(\\sigma(t)\\) be a continuous, deterministic function such that \\(|\\sigma(t)|\\leq1\\), \\(t\\in[0,T]\\). The process\n\\[\\begin{aligned}\nM(t) & =\\exp\\left(\\int_{0}^{t}\\sigma(s)dB(s)-\\frac{1}{2}\\int_{0}^{t}\\sigma^{2}(s)ds\\right),\\quad t\\leq T\n\\end{aligned}\\]\nis a martingale for the Brownian filtration. To see this, note that we can write \\(M(t)=f(t,X(t))\\) where \\(f(t,x)=\\exp(x-\\frac{1}{2}\\int\\sigma^{2}(s)ds)\\) and \\(X(t)=\\int_{0}^{t}\\sigma(s)dB(s)\\), so \\(dX(t)=\\sigma(t)dB(t)\\). Ito’s formula gives:\n\\[\\begin{aligned}\ndf(t,x) & =f_{t}(t,X(t)dt+f_{x}(t,X(t))dX(t)+\\frac{1}{2}f_{xx}(t,X(t))d&lt;X,X&gt;_{t}\\\\\ndM(t) & =-\\frac{1}{2}\\sigma^{2}(t)M(t)dt+M(t)\\sigma(t)dB(t)+\\frac{1}{2}M(t)\\sigma^{2}(t)dt\\\\\n& =M(t)\\sigma(t)dB(t)\\\\\nM(t) & =M(0)+\\int_{0}^{t}M(s)\\sigma(s)dB(s)\n\\end{aligned}\\]\nObserve also that:\n\\[\\begin{aligned}\n\\mathbb{E}[M_{t}^{2}] & =e^{-\\int_{0}^{t}\\sigma^{2}(s)ds}\\mathbb{E}[e^{2\\int_{0}^{t}\\sigma(s)dB(s)}]=e^{\\int_{0}^{t}\\sigma^{2}(s)ds}\n\\end{aligned}\\]\nsince \\(\\int_{0}^{t}\\sigma(s)dB(s)\\) is a Gaussian random variable with mean \\(0\\) and variance \\(\\int_{0}^{t}\\sigma^{2}(s)ds\\).\nWe conclude from the equation that \\((M(t),t\\geq0)\\) is a martingale.\n\n\nExample 8 (Martingales of Geometric Brownian Motion). Let\n\\[\\begin{aligned}\nS(t) & =S(0)\\exp(\\sigma B(t)-\\sigma^{2}t/2)\n\\end{aligned}\\]\nbe a geometric brownian motion. We find a PDE satisfied by \\(f(t,x)\\) for \\(f(t,S(t))\\) to be a martingale. It suffices to apply Ito’s formula of Theorem 1. We get:\n\\[\\begin{aligned}\ndf(t,S(t)) & =f_{t}(t,S(t))dt+f_{x}(t,S(t))dS(t)+\\frac{1}{2}f_{xx}(t,S(t))dS(t)\\cdot dS(t)\n\\end{aligned}\\]\nNow note from the earlier result that \\(dS(t)=S(t)\\sigma dB(t)\\). So, \\(dS(t)\\cdot dS(t)=\\frac{1}{2}\\sigma^{2}(S(t))^{2}dt\\). So,\n\\[\\begin{aligned}\ndf(t,S(t)) & =\\left\\{ \\frac{\\partial f}{\\partial t}+\\frac{1}{2}\\sigma^{2}(S(t))^{2}\\frac{\\partial^{2}f}{\\partial x^{2}}\\right\\} dt+\\sigma S(t)\\frac{\\partial f}{\\partial x}dB(t)\n\\end{aligned}\\]\nFinally, the PDE for \\(f(t,x)\\) is obtained by setting the factor in front of \\(dt\\) to \\(0\\), because we want \\(f\\) to be a martingale process. It is important to keep in mind, that the PDE should always be written in terms of the time variable \\(t\\) and the space variable \\(x\\). Therefore, the PDE of \\(f\\) as a function of time and space is:\n\\[\\begin{aligned}\n\\frac{1}{2}\\sigma^{2}x^{2}\\frac{\\partial^{2}f}{\\partial x^{2}}(t,x)+\\frac{\\partial f}{\\partial t}(t,x) & =0\n\\end{aligned}\\]\nNo more randomness appears in the PDE!\n\nHere is a specific case where we can apply the Ito’s formula to construct martingales of Ito processes.\n\nExample 9 Consider the process given by the SDE:\n\\[\\begin{aligned}\ndX(t) & =X(t)dB(t),\\quad X(0)=2\n\\end{aligned}\\]\nLet’s find a PDE for which \\(f(t,X(t))\\) is a martingale for the Brownian filtration. We have by Ito’s formula that:\n\\[\\begin{aligned}\ndf(t,X(t)) & =f_{t}(t,X(t))dt+f_{x}(t,X(t))dX(t)+\\frac{1}{2}f_{xx}(t,X(t))d&lt;X,X&gt;_{t}\\\\\n& =\\left(\\frac{\\partial f}{\\partial t}+\\frac{1}{2}(X(t))^{2}\\frac{\\partial^{2}f}{\\partial x^{2}}\\right)dt+X(t)\\frac{\\partial f}{\\partial x}dB(t)\n\\end{aligned}\\]\nSetting the drift term to \\(0\\) gives the PDE:\n\\[\\begin{aligned}\n\\frac{\\partial f}{\\partial t}+\\frac{1}{2}x^{2}\\frac{\\partial^{2}f}{\\partial x^{2}} & =0\n\\end{aligned}\\]\nIt is then easy to check that \\(X(t)\\) is a martingale and so is \\(t+\\log(X(t))^{2}\\), since the functions \\(f(t,x)=x\\) and \\(f(t,x)=t+\\log x^{2}\\) satisfy the PDE. However, the process \\(tX(t)\\) is not, as the function \\(f(t,x)=xt\\) is not a solution of the PDE."
  },
  {
    "objectID": "posts/ito-processes-and-stochastic-diff-eqs/index.html#multivariate-extension.",
    "href": "posts/ito-processes-and-stochastic-diff-eqs/index.html#multivariate-extension.",
    "title": "Ito Processes and Stochastic Differential Equations",
    "section": "",
    "text": "Ito’s formula can be generalized to several Ito processes. Let’s start by stating an example of a function of two Ito processes. Such a function \\(f(x_{1},x_{2})\\) will be a function of two space variables. Not surprisingly, it needs to have two derivatives in each variable and they need to be a continuous function; we need \\(f\\in\\mathcal{C}^{2\\times2}(\\mathbf{R}\\times\\mathbf{R})\\).\n\nTheorem 2 (Ito’s formula for many Ito processes) Let \\((X(t):t\\geq0)\\) and (Y(t):t)$ be two Ito processes of the form:\n\\[\\begin{aligned}\ndX(t) & =V(t)dB(t)+D(t)dt\\nonumber \\\\\ndY(t) & =U(t)dB(t)+R(t)dt\n\\end{aligned} \\tag{12}\\]\nwhere \\((B(t):t\\geq0)\\) is a standard Brownian motion. Then, for \\(f\\in\\mathcal{C}^{2\\times2}(\\mathbf{R}\\times\\mathbf{R})\\), we have:\n\\[\\begin{aligned}\ndf(X(t),Y(t)) & =f_{x}(X(t),Y(t))dX(t)+f_{y}(X(t),Y(t))dY(t)+\\frac{1}{2}f_{xx}(X(t),Y(t))d&lt;X,X&gt;_{t}\\\\\n& +f_{xy}(X(t),Y(t))d&lt;X,Y&gt;_{t}+\\frac{1}{2}f_{yy}(X(t),Y(t))d&lt;Y,Y&gt;_{t}\n\\end{aligned}\\]\n\nThe idea of the proof is the same as in Theorem 1 : Taylor’s expansion and quadratic variation, together with the cross-variation of two processes.\n\\[\\begin{aligned}\ndX(t)\\cdot dY(t) & =(V(t)dB(t)+D(t)dt)(U(t)dB(t)+R(t)dt)\\\\\n& =U(t)V(t)dt\n\\end{aligned}\\]\n\nExample 10 (Product Rule) An important example of this formula is Ito’s product rule. Let \\(X(t)\\) and \\(Y(t)\\) be as in Equation 12. Then:\n\\[\\begin{aligned}\nd(X(t)Y(t)) & =Y(t)dX(t)+X(t)dY(t)+dX(t)\\cdot dY(t)\n\\end{aligned}\\]\n\n\nExercise 2 Let \\((\\Omega,\\mathcal{F},\\mathbb{P})\\) be a probability space and let \\((B_{t}:t\\geq0)\\) be a standard brownian motion. Using integration by parts, show that\n\\[\\begin{aligned}\n\\int_{0}^{t}B(s)ds & =\\int_{0}^{t}(t-s)dB(s)\n\\end{aligned}\\]\nand prove that \\(\\int_{0}^{t}B(s)ds\\sim\\mathcal{N}(0,t^{3}/3)\\).\nIs\n\\[\\begin{aligned}\nX(t) & =\\begin{cases}\n0 & t=0\\\\\n\\frac{\\sqrt{3}}{t}\\int_{0}^{t}B(s)ds & t&gt;0\n\\end{cases}\n\\end{aligned}\\]\na standard Wiener process?\nSolution.\nClearly, \\(B(s,\\omega)\\) is a random variable and the Riemann integral \\(\\int_0^t B(s,\\omega)ds\\) depends on the sample path \\(\\omega\\). So, \\((\\int_0^t B_s ds, t\\leq T)\\) is a stochastic process. Using integration by parts:\n\\[\\begin{aligned}\n\\int u\\left(\\frac{dv}{ds}\\right)ds & =uv-\\int v\\left(\\frac{du}{ds}\\right)ds\n\\end{aligned}\\]\nWe set \\(u=B(s)\\) and \\(dv/ds=1\\). Then:\n\\[\\begin{aligned}\n\\int_{0}^{t}B(s)ds & =sB(s)|_{0}^{t}-\\int_{0}^{t}sdB(s)\\\\\n& =tB(t)-\\int_{0}^{t}sdB(s)\\\\\n& =\\int_{s=0}^{s=t}tdB(s)-\\int_{0}^{t}sdB(s)\\\\\n& =\\int_{0}^{t}(t-s)dB(s)\n\\end{aligned}\\]\nThus, \\(\\int_{0}^{t}B(s)ds\\) is a Gaussian random variable with:\n\\[\\begin{aligned}\n\\mathbb{E}\\left[\\int_{0}^{t}B(s)ds\\right] & =\\mathbb{E}\\left[\\int_{0}^{t}(t-s)dB(s)\\right]\\\\\n& =0\n\\end{aligned}\\]\nand\n\\[\\begin{aligned}\n\\mathbb{E}\\left[\\left(\\int_{0}^{t}B(s)ds\\right)^{2}\\right] & =\\int_{0}^{t}(t-s)^{2}ds\\\\\n& =\\left.\\frac{(t-s)^{3}}{-3}\\right|_{0}^{t}\\\\\n& =\\frac{t^{3}}{3}\n\\end{aligned}\\]\nThus, using the properties of Ito Integral, \\(\\int_{0}^{t}B(s)ds=\\int_{0}^{t}(t-s)dB(s)\\) is a martingale. Now the quadratic variation \\(&lt;M,M&gt;_{t}=0\\), and this can be a bit tricky. Remember, \\(\\left\\langle \\int_{0}^{t}f(s,B_{s})dB(s),\\int_{0}^{t}f(s,B_{s})dB(s)\\right\\rangle =\\int_{0}^{t}f^{2}(s,B_{s})ds\\) if and only if \\(f\\) is a function of the time \\(s\\) and the position of the Brownian motion \\(B(s)\\). Since, \\(f\\) is a function of \\(t\\) as well, this rule cannot be applied.\nBy first principles, we can show that, the quadratic variation is indeed \\(0\\): \\[\\begin{aligned}\n\\lim_{n\\to\\infty}\\mathbb{E}\\left[\\sum_{j=0}^{n-1}\\left(I(t_{j+1})-I(t_{j})\\right)^{2}\\right] & =\\lim_{n\\to\\infty}\\mathbb{E}\\left[\\sum_{j=0}^{n-1}B_{t_{j}}^{2}(t_{j+1}-t_{j})^{2}\\right]\\\\\n& =\\lim_{n\\to\\infty}\\max_{1\\leq j\\leq n}|t_{j+1}-t_{j}|\\cdot\\mathbb{E}\\left[\\sum_{j=0}^{n-1}B_{t_{j}}^{2}(t_{j+1}-t_{j})\\right]\n\\end{aligned}\\]\nSince the paths of \\(B_{t}\\) are continuous, so are the paths \\(B_{t}^{2}\\) on the compact interval \\([0,t]\\). So, \\((B_{s}^{2},s\\in[0,t])\\) is uniformly bounded. Thus, the expectation term is bounded. As \\(n\\to\\infty\\), the mesh size approaches zero, and consequently the quadratic variation approaches zero.\n\n\nExample 11 Let \\(X_{t}=\\int_{0}^{t}B_{s}dB_{s}\\) and \\(Y_{t}=\\int_{0}^{t}B_{s}^{2}dB_{s}\\). Is \\((X_{t}Y_{t},t\\geq0)\\) a martingale?\n\nSolution.\nBy Ito’s product rule, we have:\n\\[\\begin{aligned}\nd(X_{t}Y_{t}) & =X_{t}dY_{t}+Y_{t}dX_{t}+dX_{t}\\cdot dY_{t}\\\\\n& =X_{t}B_{s}^{2}dB_{s}+Y_{t}B_{s}dB_{s}+(B_{s}dB_{s})\\cdot(B_{s}^{2}dB_{s})\\\\\n& =X_{t}B_{s}^{2}dB_{s}+Y_{t}B_{s}dB_{s}+B_{s}^{3}dt\\\\\nX_{t}Y_{t} & =X_{0}Y_{0}+\\int_{0}^{t}X_{t}B_{s}^{2}dB_{s}+\\int_{0}^{t}Y_{t}B_{s}dB_{s}+\\int_{0}^{t}B_{s}^{3}dt\n\\end{aligned}\\]\nThe term in \\(dt\\) is not zero, so the product cannot be a martingale.\n\nExample 12 (A generalization of Geometric Brownian Motion). Consider \\((\\int_{0}^{t}V_{s}dB_{s},t\\geq0)\\) an Ito process. Define the positive process:\n\\[\\begin{aligned}\nM_{t} & =\\exp\\left(\\int_{0}^{t}V_{s}dB_{s}-\\frac{1}{2}\\int_{0}^{t}V_{s}^{2}ds\\right),\\quad t\\geq0\n\\end{aligned} \\tag{13}\\]\n\nSolution.\nIto’s formula applied to the processes \\(X_{t}=\\int_{0}^{t}V_{s}dB_{s}\\) and \\(Y_{t}=\\frac{1}{2}\\int_{0}^{t}V_{s}^{2}ds\\) with the function \\(f(x,y)=e^{x-y}\\) yields:\n\\[\\begin{aligned}\ndf(x,y) & =f_{x}(X_{t},Y_{t})dX_{t}+f_{y}(X_{t},Y_{t})dY_{t}\\\\\n& +\\frac{1}{2}f_{xx}(X_{t},Y_{t})dX_{t}\\cdot dX_{t}+\\frac{1}{2}f_{yy}(X_{t},Y_{t})dY_{t}\\cdot dY_{t}\\\\\n& +f_{xy}(X_{t},Y_{t})dX_{t}\\cdot dY_{t}\n\\end{aligned}\\]\nNow, all first and second order derivatives are \\(\\partial_{x}(e^{x-y})=M_{t}\\), \\(\\partial_{y}(e^{x-y})=-e^{x-y}=-M_{t}\\), \\(\\partial_{xx}(e^{x-y})=M_{t}\\)\n\\(dX_{t}=V_{t}dB_{t}\\). \\(dY_{t}=\\frac{1}{2}V_{t}^{2}dt\\).\n\\(dX_{t}\\cdot dX_{t}=V_{t}^{2}dt\\), \\(dX_{t}\\cdot dY_{t}=0\\),\n\\(dY_{t}\\cdot dY_{t}=0\\).\nConsequently, we have:\n\\[\\begin{aligned}\ndM_{t} & =M_{t}V_{t}dB_{t}-\\frac{1}{2}M_{t}V_{t}^{2}dt\\\\\n& +\\frac{1}{2}M_{t}V_{t}^{2}dt\\\\\n& =M_{t}V_{t}dB_{t}\n\\end{aligned}\\]\nThus, \\((M_{t},t\\geq0)\\) is a martingale.\n\nExercise 3 (Generalized Ito Integral). Let \\((\\Omega,\\mathcal{F},\\mathbb{P})\\) be a probability space and let \\((B_{t}:t\\geq0)\\) be a standard brownian motion. Given that \\(f\\) is a simple process, show that:\n\\[\\begin{aligned}\n\\int_{0}^{t}f(s,B_{s})dB_{s} & =B_{t}f(t,B_{t})-\\int_{0}^{t}\\left[B_{s}\\frac{\\partial f}{\\partial t}+\\frac{\\partial f}{\\partial x}+\\frac{1}{2}B_{s}\\frac{\\partial^{2}f}{\\partial x^{2}}\\right]ds\\\\\n& -\\int_{0}^{t}B_{s}\\frac{\\partial f}{\\partial x}dB_{s}\n\\end{aligned}\\]\nand\n\\[\\begin{aligned}\n\\int_{0}^{t}f(s,B_{s})ds & =tf(t,B_{t})-\\int_{0}^{t}s\\left[\\frac{\\partial f}{\\partial t}+\\frac{1}{2}\\frac{\\partial^{2}f}{\\partial x^{2}}\\right]ds-\\int_{0}^{t}s\\frac{\\partial f}{\\partial x}dB_{s}\n\\end{aligned}\\]\n\nSolution.\nI suppress \\((t,B_{t})\\) for simplicity. Applying the product rule to \\(B_{t}f\\), we get:\n\\[\\begin{aligned}\nd(B_{t}f) & =fdB_{t}+B_{t}df+dB_{t}\\cdot df\\\\\n& =fdB_{t}+B_{t}\\left(\\frac{\\partial f}{\\partial t}dt+\\frac{\\partial f}{\\partial x}dB_{t}+\\frac{1}{2}\\frac{\\partial^{2}f}{\\partial x^{2}}(dB_{t})^{2}\\right)\\\\\n& +dB_{t}\\cdot\\left(\\frac{\\partial f}{\\partial t}dt+\\frac{\\partial f}{\\partial x}dB_{t}+\\frac{1}{2}\\frac{\\partial^{2}f}{\\partial x^{2}}(dB_{t})^{2}\\right)\\\\\n& =fdB_{t}+\\left(B_{t}\\frac{\\partial f}{\\partial t}+\\frac{\\partial f}{\\partial x}+\\frac{1}{2}B_{t}\\right)dt+B_{t}\\frac{\\partial f}{\\partial x}dB_{t}\\\\\nB_{t}f & =\\int_{0}^{t}fdB_{s}+\\int_{0}^{t}\\left(B_{s}\\frac{\\partial f}{\\partial t}+\\frac{\\partial f}{\\partial x}+\\frac{1}{2}\\frac{\\partial^{2}f}{\\partial x^{2}}B_{s}\\right)ds+\\int_{0}^{t}B_{s}\\frac{\\partial f}{\\partial x}dB_{s}\\\\\n\\int_{0}^{t}fdB_{s} & =B_{t}f-\\int_{0}^{t}\\left(B_{s}\\frac{\\partial f}{\\partial t}+\\frac{\\partial f}{\\partial x}+\\frac{1}{2}\\frac{\\partial^{2}f}{\\partial x^{2}}B_{s}\\right)ds-\\int_{0}^{t}B_{s}\\frac{\\partial f}{\\partial x}dB_{s}\n\\end{aligned}\\]\nApplying product rule to \\(tf(t,B_{t})\\), we get:\n\\[\\begin{aligned}\nd(tf) & =fdt+tdf+dt\\cdot df\\\\\n& =fdt+t\\left(\\frac{\\partial f}{\\partial t}dt+\\frac{\\partial f}{\\partial x}dB_{t}+\\frac{1}{2}\\frac{\\partial^{2}f}{\\partial x^{2}}(dB_{t})^{2}\\right)\\\\\n& +dt\\left(\\frac{\\partial f}{\\partial t}dt+\\frac{\\partial f}{\\partial x}dB_{t}+\\frac{1}{2}\\frac{\\partial^{2}f}{\\partial x^{2}}(dB_{t})^{2}\\right)\\\\\n& =fdt+t\\left(\\frac{\\partial f}{\\partial t}+\\frac{1}{2}\\frac{\\partial^{2}f}{\\partial x^{2}}\\right)dt+t\\frac{\\partial f}{\\partial x}dB_{t}\\\\\ntf & =\\int_{0}^{t}fds+\\int_{0}^{t}s\\left(\\frac{\\partial f}{\\partial t}+\\frac{1}{2}\\frac{\\partial^{2}f}{\\partial x^{2}}\\right)ds+\\int_{0}^{t}s\\frac{\\partial f}{\\partial x}dB_{s}\\\\\n\\int_{0}^{t}fds & =tf-\\int_{0}^{t}s\\left(\\frac{\\partial f}{\\partial t}+\\frac{1}{2}\\frac{\\partial^{2}f}{\\partial x^{2}}\\right)ds-\\int_{0}^{t}s\\frac{\\partial f}{\\partial x}dB_{s}\n\\end{aligned}\\]\nThe following example will be important when we discuss the Girsanov theorem.\n\nTheorem 3 (Ito’s formula for many Ito processes) Let \\(X_t = (X_t^{(j)},j\\leq d,j\\in\\mathbf{N})\\) be Ito processes constructed on \\((\\Omega,\\mathcal{F},\\mathbb{P})\\) and \\(f \\in C^{1,2}([0,T]\\times \\mathbb{R}^d)\\). Then for \\(t \\in [0,T]\\), we have:\n\\[\ndf(t,X_t) = \\partial_t f(t,X_t) dt + \\sum_{j=1}^{d} \\partial_{x_j} f(t,X_t) dX_t^{(j)} + \\frac{1}{2}\\sum_{j=1}^{d} \\sum_{k=1}^d \\partial_{x_j x_k}^2 f(t,X_t) dX_t^{(j)}\\cdot dX_t^{(k)}\n\\]"
  },
  {
    "objectID": "posts/ito-processes-and-stochastic-diff-eqs/index.html#numerical-simulation-of-sdes",
    "href": "posts/ito-processes-and-stochastic-diff-eqs/index.html#numerical-simulation-of-sdes",
    "title": "Ito Processes and Stochastic Differential Equations",
    "section": "",
    "text": "The good news is that it is not too hard to implement iterative schemes to sample paths of a diffusion. Consider \\((X_t,t\\leq T)\\) a solution to the SDE:\n\\[\ndX_t = \\sigma(X_t) dB_t + \\mu(X_t) dt\n\\]\nTo keep the notation to a minimum, we consider a time-homogeonous diffusion. For a partition \\((t_j,j\\leq n)\\) of \\([0,T]\\) with \\(t_n = T\\), consider the increment\n\\[\nX_{t_{j+1}} - X_{t_j} = \\int_{t_j}^{t_{j+1}} \\sigma(X_s) dB(s) + \\int_{t_j}^{t_{j+1}} \\mu(X_s) ds\n\\tag{14}\\]\nNote that, if \\(\\sigma\\) and \\(\\mu\\) are smooth functions, we can apply Ito’s formula to \\(\\sigma(X_s)\\) and \\(\\mu(X_s)\\) for \\(s\\in (t_j,t_{j+1}]\\)! We get:\n\\[\n\\begin{align*}\n\\sigma(X_s) &= \\sigma(X_{t_j}) + \\int_{t_j}^{s}\\sigma'(X_u) dX_u + \\frac{1}{2}\\int_{t_j}^{s} \\sigma''(X_u)(dX_u)^2\\\\\n\\mu(X_s) &= \\mu(X_{t_j}) + \\int_{t_j}^{s}\\mu'(X_u) dX_u + \\frac{1}{2}\\int_{t_j}^{s} \\mu''(X_u)(dX_u)^2\n\\end{align*}\n\\tag{15}\\]\nNow, we can approximate the increment in Equation 14 at different levels of precision by considering a different estimate for Equation 15.\n\nExample 13 (Euler-Maruyama Scheme). This scheme consists of taking \\(\\sigma(X_s) \\approx \\sigma(X_{t_j})\\) and \\(\\mu(X_s) \\approx \\mu(X_{t_j})\\) for \\(s \\in [t_j,t_{j+1})\\) in Equation 15. Putting this back in Equation 14, we get:\n\\[\nX_{t_{j+1}} - X_{t_j} \\approx \\sigma(X_{t_j})(B_{t_{j+1}}-B_{t_j}) + \\mu(X_{t_j})(t_{j+1} - t_j)\n\\tag{16}\\]\nThe process \\(X_t\\) can then be constructed recursively on the discrete set \\((t_j,j \\leq n)\\) as follows:\n\\[\n\\begin{align*}\nX_0 &= x\\\\\nX_{t_1} &= (X_{t_1} - X_0) + X_0\\\\\nX_{t_2} &= (X_{t_2} - X_{t_1}) + (X_{t_1} - X_0) + X_0\\\\\n\\vdots\\\\\nX_{t_n} &= \\sum_{j=0}^{n-1}(X_{t_{j+1}} - X_{t_j}) + X_0\n\\end{align*}\n\\]\n\n\nExample 14 (Milstein Scheme). In this scheme, we go an order further for the approximation of the volatility in Equation 15 and consider also the integral in \\(dX_u\\). We take \\(dX_u = \\sigma(X_{t_j})dB_u\\). We then express \\(\\sigma(X_s)\\) in Equation 15 as:\n\\[\n\\begin{align*}\n\\sigma(X_s) &\\approx \\sigma(X_{t_j}) + \\int_{t_j}^{s} \\sigma'(X_{t_j}) (\\sigma(X_{t_j})dB_u)\\\\\n&= \\sigma(X_{t_j}) + \\sigma'(X_{t_j}) \\sigma(X_{t_j}) \\int_{t_j}^{s}  dB_u\\\\\n&= \\sigma(X_{t_j}) + \\sigma'(X_{t_j}) \\sigma(X_{t_j}) (B_s - B_{t_j})\n\\end{align*}\n\\]\nIf we put this back in Equation 14, we get:\n\\[\n\\begin{align*}\nX_{t_{j+1}} - X_{t_j} &\\approx \\sigma(X_{t_j})(B_{t_{j+1}}-B_{t_j}) + \\mu(X_{t_j})(t_{j+1} - t_j) \\\\\n&+ \\sigma'(X_{t_j}) \\sigma(X_{t_j}) \\int_{t_j}^{t_{j+1}} (B(s) - B(t_j))dB(s)\n\\end{align*}\n\\tag{17}\\]\nNow, consider the function \\(f(x)=x^2\\). We have:\n\\[\n\\begin{align*}\nf_x(x) &= 2x\\\\\nf_{xx}(x) &= 2\n\\end{align*}\n\\]\nSo, we get:\n\\[\nB^2(t_{j+1}) - B^2(t_j) = 2 \\int_{t_j}^{t_{j+1}} B(s) dB(s) + \\frac{1}{2} \\int_{t_j}^{t_{j+1}} (2) ds\n\\]\nThus,\n\\[\n\\int_{t_j}^{t_{j+1}} B(s) dB(s) = \\frac{1}{2}[(B_{t_{j+1}}^2 - B_{t_j}^2)-(t_{j+1}-t_j)]\n\\tag{18}\\]\nSubstituting Equation 18 into Equation 17, we get the Milstein approximation:\n\\[\n\\begin{align*}\nX_{t_{j+1}} - X_{t_j} &\\approx \\sigma(X_{t_j})(B_{t_{j+1}}-B_{t_j}) + \\mu(X_{t_j})(t_{j+1} - t_j) \\\\\n&+\\sigma'(X_{t_j}) \\sigma(X_{t_j})  \\left[\\frac{1}{2}((B_{t_{j+1}}^2 - B_{t_j}^2)-(t_{j+1}-t_j)) -  B_{t_j}(B_{t_{j+1}}-B_{t_j})\\right]\\\\\n&= \\sigma(X_{t_j})(B_{t_{j+1}}-B_{t_j}) + \\mu(X_{t_j})(t_{j+1} - t_j) \\\\\n&+ \\frac{\\sigma'(X_{t_j}) \\sigma(X_{t_j})}{2}  \\left[(B_{t_{j+1}}^2 - B_{t_j}^2)-(t_{j+1}-t_j) -  2B_{t_j}B_{t_{j+1}}+2B_{t_j}^2\\right]\\\\\n&= \\sigma(X_{t_j})(B_{t_{j+1}}-B_{t_j}) + \\mu(X_{t_j})(t_{j+1} - t_j) \\\\\n&+ \\frac{\\sigma'(X_{t_j}) \\sigma(X_{t_j})}{2}  \\left[(B_{t_{j+1}} - B_{t_j})^2-(t_{j+1}-t_j)\\right]\n\\end{align*}\n\\]\nThus, under the Milstein scheme\n\\[\n\\begin{align*}\nX_{t_{j+1}} - X_{t_j} &\\approx \\sigma(X_{t_j})(B_{t_{j+1}}-B_{t_j}) + \\mu(X_{t_j})(t_{j+1} - t_j) \\\\\n&+ \\frac{\\sigma'(X_{t_j}) \\sigma(X_{t_j})}{2}  \\left[(B_{t_{j+1}} - B_{t_j})^2-(t_{j+1}-t_j)\\right]\n\\end{align*}\n\\tag{19}\\]\nThe recursive nature of these two schemes makes them easy to implement numerically. The Milstein scheme is not much more costly to implement as it contains only one more term than the Euler scheme.\n\n\n\nLet’s code an SIVP class and an abstract base class Solver.\n\nfrom dataclasses import dataclass\nfrom abc import ABC, abstractmethod\nfrom typing import Callable, Optional\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nsns.set_style(\"whitegrid\")\n\n# More descriptive type hints\nT = np.ndarray\nX = np.ndarray\n\n@dataclass\nclass SIVP:\n    \"\"\"\n    An abstraction for a stochastic initial value problem\n    \"\"\"\n    t_start : float\n    t_end : float\n    initial_condition: float\n\n    drift: Callable[[float, np.ndarray], np.ndarray]\n    vol: Callable[[float, np.ndarray], np.ndarray]\n    dvol_dx: Optional[Callable[[float, np.ndarray], np.ndarray]] = None\n\n\n\n@dataclass\nclass Solver(ABC):\n    \"\"\"\n    An abstract base class for all numerical schemes\n    \"\"\"\n\n    num_steps: int = 100\n    num_paths: int = 100\n\n    def __post_init__(self):\n        self.iter = 0\n\n        # x_values is a matrix of shape [num_paths,num_steps]\n        self.x_values = np.zeros((self.num_paths, self.num_steps + 1))\n        self.step_size = 1.0 / self.num_steps\n\n        # gaussian increments\n        self.brownian_increments = np.sqrt(self.step_size) * np.random.standard_normal(\n            size=(self.num_paths, self.num_steps)\n        )\n        self.brownian = np.cumsum(self.brownian_increments, axis=1)\n        self.brownian = np.concatenate(\n            [np.zeros(shape=(self.num_paths, 1)), self.brownian], axis=1\n        )\n\n    @abstractmethod\n    def iterate(self, sivp: SIVP) -&gt; X:\n        \"\"\"\n        Compute the next iterate X(n+1)\n        \"\"\"\n\n    def solve(self, sivp: SIVP) -&gt; (T, X):\n        \"\"\"\n        Solve the SIVP\n        \"\"\"\n        self.x_values[:, 0] = np.full(\n            shape=(self.num_paths,), fill_value=sivp.initial_condition\n        )\n        while self.iter &lt; self.num_steps:\n            self.x_values[:, self.iter + 1] = self.iterate(sivp)\n            self.iter += 1\n\n        times = np.linspace(sivp.t_start, sivp.t_end, self.num_steps + 1)\n        return times, self.x_values\n\n    def reset(self):\n        self.__post_init__()\n\nThe EulerMaruyama and Milstein methods will derive from the abstract base class Solver.\n\n@dataclass\nclass EulerMaruyama(Solver):\n    \"\"\"\n    Numerical solver for a stochastic differential equation(SDE) using\n    the Euler-Maruyama method.\n\n    Consider an SDE of the form :\n\n    dX_t = mu(t,X_t) dt + sigma(t,X_t) dB_t\n\n    with initial condition X_0 = x_0\n\n    The solution to the SDE can be computed using the increments\n\n    X_{n+1} - X_n = mu(n,X_n)(t_{n+1}-t_n) + sigma(n,X_n)(B(n+1)-B(n))\n\n    \"\"\"\n\n    def iterate(self, sivp: SIVP) -&gt; X:\n        \"\"\"\n        Generate the next iterate X(n+1)\n        \"\"\"\n        current_time = self.iter * self.step_size\n        mu_n = sivp.drift(current_time, self.x_values[:, self.iter])\n        sigma_n = sivp.vol(current_time, self.x_values[:, self.iter])\n        delta_x = (\n            mu_n * self.step_size + sigma_n * self.brownian_increments[:, self.iter]\n        )\n        return self.x_values[:, self.iter] + delta_x\n\n\n@dataclass\nclass Milstein(Solver):\n    \"\"\"\n    Numerical solver for a stochastic differential equation(SDE) using\n    the Euler-Maruyama method.\n\n    Consider an SDE of the form :\n\n    dX_t = mu(t,X_t) dt + sigma(t,X_t) dB_t\n\n    with initial condition X_0 = x_0\n\n    The solution to the SDE can be computed using the increments\n\n    X_{n+1} - X_n = mu(n,X_n)(t_{n+1}-t_n) + sigma(n,X_n)(B(n+1)-B(n))\n    + 0.5 * sigma(n,X_n) * sigma'(n,X_n) * ((B(n+1) - B(n))**2 - (t_{n+1} - t_n))\n\n    \"\"\"\n\n    def iterate(self, sivp: SIVP):\n        \"\"\"\n        Generate the next iterate X(n+1)\n        \"\"\"\n        current_time = self.iter * self.step_size\n        mu_n = sivp.drift(current_time, self.x_values[:, self.iter])\n        sigma_n = sivp.vol(current_time, self.x_values[:, self.iter])\n        dvol_dx_n = sivp.dvol_dx(current_time, self.x_values[:, self.iter])\n\n        delta_x = (\n            mu_n * self.step_size\n            + sigma_n * self.brownian_increments[:, self.iter]\n            + 0.5\n            * sigma_n\n            * dvol_dx_n\n            * (self.brownian_increments[:, self.iter] ** 2 - self.step_size)\n        )\n\n        return self.x_values[:, self.iter] + delta_x\n\n\nExercise 4 (Simulating SDEs) Simulate 100 paths for the following diffusions given by their SDEs on \\([0,1]\\) using the Euler-Maruyama scheme and the Milstein scheme for a discretization of \\(0.01\\).\n\nGeometric Brownian Motion:\n\n\\[\ndS_t = S_t dB_t + \\left(\\mu + \\frac{\\sigma^2}{2}\\right)S_t dt, \\quad S_0 = 1\n\\]\nfor \\(\\mu=-1/2\\), \\(\\mu=-2\\), and \\(\\mu=0\\)\n\nOrnstein-Uhlenbeck process:\n\n\\[\ndX_t = -X_t dt + dB_t, \\quad X_0 = 1\n\\]\n\nThe diffusion:\n\n\\[\ndX_t = \\sqrt{1+X_t^2}dB_t + \\sin X_t dt, \\quad X_0 = 0\n\\]\n\nSolution.\nWe can now use EulerMaruyama and Milstein solvers and generate some sample paths.\n\n\nShow the code\ndef plot_trajectories(ts, xs, title):\n    plt.xlabel(r'Time $t$')\n    plt.ylabel(r'$X(t)$')\n    plt.title(title)\n    plt.grid(True)\n    plt.plot(ts, xs.transpose())\n    plt.show()\n\n# mu = -0.5 case\neuler = EulerMaruyama(num_paths=10, num_steps=100)\n\ngbm_sde = SIVP(\n    t_start=0.0,\n    t_end=1.0,\n    initial_condition=1.0,\n    drift=lambda t, s_t: np.zeros(10),\n    vol=lambda t, s_t: s_t,\n    dvol_dx=lambda t, s_t: np.ones(10),\n)\n\n\nts, xs = euler.solve(gbm_sde)\neuler.reset()\n\nplot_trajectories(ts, xs, r'10 sample paths of Geometric Brownian Motion, $\\mu=-0.5$')\n\n# mu = -2 case\ngbm_sde.drift = lambda t, s_t : -1.5 * s_t\nts, xs = euler.solve(gbm_sde)\neuler.reset()\n\nplot_trajectories(ts, xs, r'10 sample paths of Geometric Brownian Motion, $\\mu=-2.0$')\n\n# mu = 0 case\ngbm_sde.drift = lambda t, s_t : 0.5 * s_t\nts, xs = euler.solve(gbm_sde)\neuler.reset()\n\nplot_trajectories(ts, xs, r'10 sample paths of Geometric Brownian Motion, $\\mu=0.0$')\n\n# ornstein-uhlenbeck\nornstein_uhlenbeck_sde = SIVP(\n    t_start=0.0,\n    t_end=1.0,\n    initial_condition=1.0,\n    drift = lambda t, s_t : -s_t,\n    vol = lambda t, s_t : np.ones(10),\n    dvol_dx = lambda t, s_t : np.zeros(10)\n)\n\nts, xs = euler.solve(ornstein_uhlenbeck_sde)\neuler.reset()\n\nplot_trajectories(ts, xs, r'10 sample paths of Ornstein-Uhlenbeck')\n\n# diffusion\ndiffusion_sde = SIVP(\n    t_start=0.0,\n    t_end=1.0,\n    initial_condition=0.0,\n    drift = lambda t, s_t : np.sin(s_t),\n    vol = lambda t, s_t : np.sqrt(1+s_t**2),\n    dvol_dx = lambda t, s_t : s_t / np.sqrt(1 + s_t**2) \n)\n\nts,xs = euler.solve(diffusion_sde)\neuler.reset()\n\nplot_trajectories(ts, xs, r'10 sample paths of the diffusion')\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nIt is of course possible go beyond the Milstein scheme to improve the approximation. However, it turns out that the above schemes already converge quite rapidly to the process itself. To see this, consider the mean absolute error between the approximation \\(X_T^{(n)}\\) at time \\(T\\) and \\(X_T\\). Suppose that the approximation \\(X^{(n)}\\) is obtained for a partition with discretization \\(t_{j+1}-t_j = 1/n\\). It is possible to show that for the Euler scheme, we have:\n\\[\n\\begin{align*}\n\\mathbb{E}[|X_T^{(n)} - X_T|] \\leq \\frac{C}{\\sqrt{n}}\n\\end{align*}\n\\]\nwhereas for the Milstein scheme\n\\[\n\\begin{align*}\n\\mathbb{E}[|X_T^{(n)} - X_T|] \\leq \\frac{C'}{n}\n\\end{align*}\n\\]\nfor some constants \\(C,C'&gt;0\\). Note that the mean error between the two process must be the worst at the last point, since the errors add up."
  },
  {
    "objectID": "posts/ito-processes-and-stochastic-diff-eqs/index.html#existence-and-uniqueness-of-sdes",
    "href": "posts/ito-processes-and-stochastic-diff-eqs/index.html#existence-and-uniqueness-of-sdes",
    "title": "Ito Processes and Stochastic Differential Equations",
    "section": "",
    "text": "As for the differential equations in standard calculus, SDEs play an important role in modelling stochastic phenomena. To model a trajectory \\(X_t, t\\leq T\\), it suffices to write down the variation due to the deterministic change \\(\\mu(X_t)dt\\) for some function \\(\\mu(X_t)\\) and the variation due to local fluctuations \\(\\sigma(X_t)dB_t\\) for some function \\(\\sigma(X_t)\\). Here, we assume that the local drift and volatility are time-homogenous for simplicity. This gives the SDE:\n\\[\ndX_t = \\mu(X_t) dt + \\sigma(X_t) dB_t\n\\]\nDo we get one nice Ito process for any choice of functions \\(\\sigma\\) and \\(\\mu\\)? The short answer is no. Here are sufficient conditions for the existence of a unique process.\n\nTheorem 4 (Existence and Uniqueness of solutions to SDE) Consider the SDE\n\\[\ndX_t = \\mu(X_t) dt  + \\sigma(X_t)dB_t, \\quad X_0 = x, \\quad t\\in [0,T]\n\\]\nIf the functions \\(\\sigma\\) and \\(\\mu\\) grow not faster than \\(Kx^2\\) for some \\(K&gt;0\\) and are differentiable with bounded derivatives on \\(\\mathbb{R}^1\\), then there exists a unique solution \\((X_t,t\\in[0,T])\\) to the SDE. In other words, there exists a continuous process \\((X_t, t \\leq T)\\) adapted to the filtration of the Brownian motion given by:\n\\[\nX_t = x + \\int_0^t \\mu(X_s) ds + \\int_0^t \\sigma(X_s) dB_s, \\quad t\\leq T\n\\]\n\n\nExample 15 Consider the SDE :\n\\[\ndX_t = \\sqrt{1 + X_t^2}dB_t + \\sin X_t dt\n\\tag{20}\\]\nThere exists a unique diffusion process \\((X_t,t\\geq 0)\\) that is a solution of this SDE. To see this, we verify the conditions of the Theorem 4. We have:\n\\[\n\\sigma(x) = \\sqrt{1 + x^2}, \\quad \\mu(x) = \\sin x\n\\]\nClearly, these functions satisfy the growth condition since \\(\\mu\\) is bounded and \\(\\sigma\\) grows like \\(|x|\\) for large \\(x\\). As for the derivatives, we have \\(\\sigma'(x)=\\frac{x}{\\sqrt{1+x^2}}\\) and \\(\\mu'(x)=\\cos x\\). The two derivatives are bounded.\n\nThe assumptions of Theorem 4 are not too surprising, since similar ones are found in the classical case of ODE. For example, if we have the ODE\n\\[\n\\frac{dX_t}{dt} = X_t^{1/2}, \\quad X_0 = 0\n\\]\nthen clearly \\(X_t = 0\\) for all \\(t\\) is a solution. But, we also have by integrating that:\n\\[\nX_t = \\frac{t^2}{4}, t \\geq 0\n\\]\nTherefore, the uniqueness breaks down. Note, that the function \\(\\mu(x)=\\sqrt{x}\\) does not have bounded derivatives at \\(0\\). Similarly, consider the ODE:\n\\[\n\\frac{dX_t}{dt} = e^{X_t}, X_0 = 0\n\\]\nHere, the function \\(\\mu(x)\\) grows much faster than \\(x^2\\). The solution of the ODE is by integrating\n\\[\n\\begin{align*}\n-(e^{-X_t} - 1) &= t\\\\\ne^{-X_t} &= (1 - t)\\\\\n-X_t &= \\log(1 - t)\\\\\nX_t &= \\log \\left(\\frac{1}{1-t}\\right)\n\\end{align*}\n\\]\nThe solution explodes at \\(t=1\\). The same phenomenon may occur for SDE; that is the process will almost surely go \\(\\infty\\) in finite time. These times are called explosion times. Note that it is possible to consider the paths of the diffusion upto these explosion times. It is important to keep in mind that the conditions of Theorem 4 are sufficient, but not necessary. In particular, it is sometimes possible to explicitly construct a diffusion whose local volatility and drift do not satisfy the conditions. Let’s look at two important instances of such diffusions.\n\nLet \\(B_t\\) be a brownian motion in \\(\\mathbb{R}^d\\) for \\(d&gt;1\\). Consider the process giving the distance at time \\(t\\) of \\(B_t\\) to the origin; that is:\n\\[\nR_t = ||B_t|| = \\left(\\sum_{j=1}^d B_t^{(j)}\\right)^2\n\\]\n(For \\(d=1\\), this is simply \\(|B_t|\\). Ito’s formula cannot be applied in this case, since the absolute value is not differentiable at the origin.) In higher dimensions, the function is smooth enough as long as we stay away from the origin. This is not a problem as long as \\(R_0 &gt; 0\\).\n\nLet’s find out the SDE that this process satisfies.\nLet \\(r=f(x_1,x_2,\\ldots,x_d)=\\sqrt{\\sum_{j=1}^d x_j^2}\\). We have:\n\\[\\begin{align*}\n\\frac{\\partial r}{\\partial x_j} &= \\frac{x_j}{\\sqrt{\\sum_{j=1}^d x_j^2}}\\\\\n\\frac{\\partial^2 r}{\\partial x_j^2} &= \\frac{||x|| - x_j \\cdot \\frac{x_j}{||x||}}{||x||^2}\\\\\n&= \\frac{||x||^2 - x_j^2}{||x||^3}\n\\end{align*}\\]\nBy Ito’s formula,\n\\[\\begin{align*}\ndR_t &= \\sum_{j=1}^{d} \\frac{B_t^{j}}{R_t} dB_t^{(j)} + \\frac{1}{2} \\sum_{j=1}^{d} \\frac{R_t^2 - (B_t^{(j)})^2}{R_t^3}\\\\\n&= \\sum_{j=1}^{d} \\frac{B_t^{j}}{R_t} dB_t^{(j)} + \\frac{1}{2} \\frac{d R_t^2 - R_t^2}{R_t^3}\\\\\n&= \\sum_{j=1}^{d} \\frac{B_t^{j}}{R_t} dB_t^{(j)} + \\frac{1}{2} \\frac{(d-1)}{R_t}\n\\end{align*}\\]\nWe can define \\(dW_t = \\sum_{j=1}^{d} \\frac{B_t^{(j)}}{R_t} dB_t^{(j)}\\). Then, \\(dR_t = dW_t + \\frac{d-1}{2R_t}dt\\)\nIt turns out that \\((W_t,t \\geq 0)\\) is a standard Brownian motion by Levy’s characterization theorem. This is the subject of the next section. The SDE shows that \\(dR_t\\) is a diffusion. The SDE makes sense for any real number \\(d &gt; 1\\), not only integers. Moreover, the SDE is well-defined since \\(R_t\\) is never equal to \\(0\\). However, the SDE does not satisfy the assumption of the existence and uniqueness of the solution of SDEs since \\(1/x\\) diverges at \\(0\\). The solution to the SDE still exists since we constructed it! We sample paths of this process in numerical project.\n\nExample 16 (The Cox-Ingersoll-Ross (CIR) model.) Consider the SDE:\n\\[\ndS_t = \\sigma \\sqrt{S_t} dW_t + (a - bS_t)dt, \\quad S_0 &gt; 0\n\\tag{21}\\]\nfor some parameters \\(a,b &gt; 0\\) where \\((W_t,t \\geq 0)\\) is a standard Brownian motion. The local volatility \\(\\sigma(x)=\\sigma \\sqrt{x}\\) does not have a bounded derivative close to \\(0\\), since \\(\\sigma'(x)=\\frac{\\sigma}{2\\sqrt{x}}\\). We will nevertheless construct a diffusion that is a solution to the SDE. Consider independent Ornstein-Uhlenbeck processes \\(X_t^{(j)}, j \\leq d\\), with SDE:\n\\[\ndX_t^{(j)} = \\frac{-b}{2}X_t^{(j)}dt + \\frac{\\sigma}{2}dB_t^{(j)}, \\quad X_0^{(j)} &gt; 0\n\\]\nwhere \\(B_t = (B_t^{(j)},j\\leq d)\\) is a Brownian motion in \\(\\mathbb{R}^d\\). We consider the process\n\\[\nS_t = \\sum_{j \\leq d} (X_t^{(j)})^2\n\\]\nClearly, \\(S_t\\) is nongegative for all \\(t \\geq 0\\) by design, so \\(\\sqrt{S_t}\\) is well-defined. Let’s compute the SDE of the process. By Ito’s formula, we have:\n\\[\n\\begin{align*}\ndS_t &= 2\\sum_{j=1}^{d}X_t^{(j)} dX_t^{(j)} + \\frac{1}{2}\\sum_{j=1}^{d} 2 (dX_t^{(j)})^2\\\\\n&=2\\sum_{j=1}^{d}X_t^{(j)} dX_t^{(j)} + \\frac{\\sigma^2}{4}\\sum_{j=1}^{d} dt \\\\\n&=2\\sum_{j=1}^{d}X_t^{(j)} \\left(\\frac{-b}{2}X_t^{(j)}dt + \\frac{\\sigma}{2}dB_t^{(j)}\\right) + \\frac{d\\sigma^2}{4} dt\\\\\n&=\\left[\\left(\\sum_{j=1}^d (-b)(X_t^{(j)})^2\\right) + \\frac{d\\sigma^2}{4}\\right] dt + \\sigma \\sum_{j=1}^{d} X_t^{(j)} dB_t^{(j)}\\\\\n&=\\sigma \\sum_{j=1}^{d} X_t^{(j)} dB_t^{(j)} + \\left[\\frac{d\\sigma^2}{4} - b S_t\\right] dt \\\\\n&= \\sigma \\sqrt{S_t} \\sum_{j=1}^{d} \\frac{X_t^{(j)}}{\\sqrt{S_t}} dB_t^{(j)}  + \\left[\\frac{d\\sigma^2}{4} - b S_t\\right] dt \\\\\n&= \\sigma \\sqrt{S_t} dW_t  + \\left[\\frac{d\\sigma^2}{4} - b S_t\\right] dt \\\\\n\\end{align*}\n\\]\nwhere we have defined \\(dW_t = \\sum_{j=1}^d \\frac{X_t^{(j)}}{\\sqrt{S_t}} dB_t^{(j)}\\). It turns out that the process \\((W_t,t\\geq 0)\\) is a standard brownian motion by Levy’s characterization theorem. If we accept this for a moment, we have the SDE:\n\\[\ndS_t = \\sigma \\sqrt{S_t} dW_t + \\left(\\frac{d \\sigma^2}{4} - bS_t\\right) dt, \\quad S_0 &gt; 0\n\\tag{22}\\]\nThis is a time-homogenous diffusion called the Cox-Ingersoll-Ross (CIR) process. Again, notice that there are no issues with square root, since \\(S_t\\) is positive by construction! The SDE also makes sense if replace \\(d\\sigma^2/4\\) by a parameter \\(a\\) in Equation 21 as long as \\(a \\geq \\frac{d\\sigma^2}{4}\\). This process is important for interest rates and stochastic volatility models.\nNote that the local drift is \\(a - bS_t, a\\ge \\frac{d\\sigma^2}{4}\\). This can be written as:\n\\[\\begin{align*}\na - bS_t = b\\left(\\frac{b}{a} - S_t \\right)\n\\end{align*}\\]\nThis means that the local drift is negative if \\(S_t &gt; \\frac{a}{b}\\) and it is positive if \\(S_t &lt; \\frac{a}{b}\\). So, the SDE exhibits the same phenomenon as for the SDE of the Ornstein-Uhlenbeck process in Example 5. In particular we should expect that for \\(t\\) large, the process should fluctuate around the mean value \\(\\frac{a}{b}\\). The CIR model is therefore an example of a mean-reverting process. More generally, this hints to the fact, that the process is stationary in the long run."
  },
  {
    "objectID": "posts/ito-processes-and-stochastic-diff-eqs/index.html#martingale-representation-and-levys-characterization",
    "href": "posts/ito-processes-and-stochastic-diff-eqs/index.html#martingale-representation-and-levys-characterization",
    "title": "Ito Processes and Stochastic Differential Equations",
    "section": "",
    "text": "We know very well by now, that an Ito integral is continuous martingale with respect to the Brownian filtration, whenever the integrand is in \\(\\mathcal{L}_c^2(T)\\). What can we say about the converse? In other words, if we have a martingale with respect to the Brownian filtration, can it be expressed as an Ito integral for some integrand \\((V_t,t\\leq T)\\)? Amazingly, the answer to this question is yes!\n\nTheorem 5 (Martingale Representation Theorem.) Let \\((B_t,t \\geq 0)\\) be a Brownian motion with filtration \\((\\mathcal{F}_t,t\\geq 0)\\) on \\((\\Omega,\\mathcal{F},\\mathbb{P})\\). Consider a martingale \\((M_t,t\\leq T)\\) with respect to this filtration. Then, there exists an adapted process \\((V_t,t \\leq T)\\) such that:\n\\[\nM_t = M_0 + \\int_0^t V_s dB_s, \\quad t \\leq T\n\\tag{23}\\]\nOne striking fact of the result is that \\((M_t,t\\leq T)\\) ought to be continuous. In other words, we cannot construct a process with a jump that is a martingale adapted to Brownian motion!\nInstead of the proving the theorem, we will see how the result is not too surprising with stronger assumptions. Instead of supposing that \\(M_t\\) is \\(\\mathcal{F}_t\\) measurable, take that \\(M_t\\) is \\(\\sigma(B_t)\\)-measurable. In other words, \\(M_t=h(B_t)\\) for some function \\(h\\). In the case where \\(h\\) is smooth, then it is clear by Ito’s formula that the representation Equation 23 holds with \\(V_s = h'(B_s)\\).\n\nAn important consequence of Theorem 5 is a third definition of Brownian motion.\n\nTheorem 6 (One-dimensional Levy’s Characterization theorem) Let \\((M_t,t\\in [0,T])\\) be a continuous martingale with respect to the filtration \\((\\mathcal{F}_t,t \\leq T)\\) with \\(M_0 = 0\\) and with quadratic variation \\(&lt;M&gt;_t = t\\). Then, \\((M_t,t\\leq T)\\) is a standard brownian motion.\n\nProof.\nWe first need to show that \\(M_t - M_s \\sim \\mathcal{N}(0,t - s)\\) or using the characteristic function approach, we need to show that \\(f_{(M_t - M_s)}(\\theta)=\\mathbb{E}[e^{\\theta (M_t - M_s)}] = e^{\\frac{1}{2}\\theta^2 (t-s)}\\) for constant \\(\\theta\\).\nLet \\(f(t,x) = e^{\\theta x - \\frac{1}{2}\\theta^2 t}\\).\nBy Ito’s formula, we have:\n\\[\\begin{align*}\ndf(t,M_t) &= \\theta e^{\\theta M_t - \\frac{1}{2}\\theta^2 t} dM_t + \\left(-\\frac{1}{2}\\theta^2 + \\frac{1}{2} \\theta^2 \\right)e^{\\theta M_t - \\frac{1}{2}\\theta^2 t}dt\\\\\n&= \\theta f(t,M_t) dM_t\n\\end{align*}\\]\nIntegrating on both sides, we get:\n\\[\\begin{align*}\nf(t,M_t) - f(s,M_s) &= \\theta \\int_0^t f(u,M_u) dM_u\n\\end{align*}\\]\nThe ito integral \\(\\int_0^t f(s,M_s) dM_s\\) is well-defined and its expectation is \\(0\\). Hence, applying expectation operator on both sides, we get:\n\\[\\begin{align*}\n\\mathbb{E}[f(t,M_t) - f(s,M_s)] &= \\theta \\mathbb{E} \\left[ \\int_0^t f(s,M_s) dM_s\\right]\\\\\n&= 0\n\\end{align*}\\]\nSince \\(e^{x} \\neq 0\\) for all \\(x\\), dividing by \\(f(s,M_s)\\), we get:\n\\[\\begin{align*}\n\\mathbb{E}\\left[\\frac{f(t,M_t)}{f(s,M_s)}\\right] &= 1\\\\\n\\mathbb{E}\\left[\\frac{e^{\\theta M_t - \\frac{1}{2}\\theta^2 t}}{e^{\\theta M_s - \\frac{1}{2}\\theta^2 s}}\\right] &= 1\\\\\n\\mathbb{E}\\left[e^{\\theta(M_t - M_s)}\\right] &= e^{\\frac{1}{2}\\theta^2(t-s)}\n\\end{align*}\\]\nwhich is the moment generating function for the normal distribution with mean zero and variance \\(t-s\\). So, \\(M_t - M_s \\sim \\mathcal{N}(0, t - s)\\).\nFurther, consider \\(t_1 \\leq t_2 \\leq t_3\\). We have:\n\\[\\begin{align*}\n\\mathbb{E}[(M_{t_3} - M_{t_2})(M_{t_2} - M_{t_1})] &= \\mathbb{E}[\\mathbb{E}[(M_{t_3} - M_{t_2})(M_{t_2} - M_{t_1})|\\mathcal{F}_{t_2}]] \\\\\n&= \\mathbb{E}[(M_{t_2} - M_{t_1})\\mathbb{E}[(M_{t_3} - M_{t_2})|\\mathcal{F}_{t_2}]] \\\\\n&= \\mathbb{E}[(M_{t_2} - M_{t_1})(M_{t_2} - M_{t_2})] \\\\\n&= 0\n\\end{align*}\\]\nwhere \\(\\mathbb{E}[M_{t_3} - M_{t_2}|\\mathcal{F}_{t_2}] = 0\\) follows from the fact that \\((M_t,t\\geq 0)\\) is a martingale. Consequently, \\(M_{t_3} - M_{t_2} \\perp M_{t_2} - M_{t_1}\\) and non-overlapping increments are independent.\nMoreover, \\(M(0) = 0\\). So, \\((M_t,t\\geq 0)\\) is a standard brownian motion. This closes the proof. \\(\\blacksquare\\)"
  },
  {
    "objectID": "posts/ito-processes-and-stochastic-diff-eqs/index.html#exercise-problems",
    "href": "posts/ito-processes-and-stochastic-diff-eqs/index.html#exercise-problems",
    "title": "Ito Processes and Stochastic Differential Equations",
    "section": "",
    "text": "Exercise 5 Let \\((\\Omega,\\mathcal{F},\\mathbb{P})\\) be a probability space and \\((W_t,t\\geq 0)\\) be a standard Wiener process. Find the SDE for the random process \\(X_t = W_t^n, n \\in \\mathbb{Z}^{+}\\).\nShow that\n\\[\n\\mathbb{E}[W_t^n] = \\frac{1}{2}n(n-1) \\int_0^t \\mathbb{E}\\left[W_s^{(n-2)}\\right] ds\n\\]\nand using mathematical induction prove that:\n\\[\n\\mathbb{E}[W_t^n] = \\begin{cases}\n\\frac{n! t^{n/2}}{2^{n/2} \\left(\\frac{n}{2}\\right)!}, & n=2,4,6,\\ldots\\\\\n0, & n=1,3,5,\\ldots\n\\end{cases}\n\\]\n\nSolution."
  },
  {
    "objectID": "posts/kirks_approximation_a_numerical_experiment/index.html",
    "href": "posts/kirks_approximation_a_numerical_experiment/index.html",
    "title": "Margrabe’s formula",
    "section": "",
    "text": "Let \\(S_1(t)\\) and \\(S_2(t)\\) denote the prices of two risky assets which have dynamics:\n\\[\n\\begin{align*}\ndS_1(t)/ S_1(t) &= r dt + \\sigma_1 dW_1^{\\mathbb{Q}}(t) \\\\\ndS_2(t)/ S_2(t) &= r dt + \\sigma_2 dW_2^{\\mathbb{Q}}(t)\n\\end{align*}\n\\]\nwhere \\(r\\) is the constant risk-free rate, \\(W_1^{\\mathbb{Q}}(t)\\) and \\(W_2^{\\mathbb{Q}}(t)\\) are brownian motions with instantaneous correlation \\(\\rho\\).\nWe are interested to price the payoff\n\\[\nV_T = (S_1(T) - S_2(T))^+\n\\]\nBy the risk-neutral pricing formula,\n\\[\n\\begin{align*}\nV_0 &= M(0)\\mathbb{E}^{\\mathbb{Q}}\\left[\\frac{V(T)}{M(T)}\\right]\\\\\n&= S_2(0)\\mathbb{E}^{\\mathbb{Q}^{S_2}}\\left[\\frac{V(T)}{S_2(T)}\\right]\\\\\n& \\quad \\{\\text{Switching from }\\mathbb{Q}\\text{ to }\\mathbb{Q}^{S_2}\\text{-measure.}\\}\\\\\n&= S_2(0)\\mathbb{E}^{\\mathbb{Q}^{S_2}}\\left[\\frac{1}{S_2(T)}S_1(T) - S_2(T) 1_{S_1(T) &gt; S_2(T)}\\right]\\\\\n&= S_2(0)\\mathbb{E}^{\\mathbb{Q}^{S_2}}\\left[\\left(\\frac{S_1(T)}{S_2(T)} - 1 \\right) 1_{S_1(T) &gt; S_2(T)}\\right]\\\\\n\\end{align*}\n\\]\nDefine the asset price process \\(Y(t)\\) as:\n\\[\nY(t) := \\frac{S_1(t)}{S_2(t)}\n\\]\nSo, we want to compute the expectation\n\\[\nV_0 = S_2(0) \\mathbb{E}^{\\mathbb{Q}^{S_2}} \\left[(Y_T - 1)^+\\right]\n\\]\n\n\nWe know that \\((Y_t,t\\geq 0)\\) is a \\(\\mathbb{Q}^{S_2}\\) martingale. The \\(\\mathbb{Q}\\)-dynamics of \\((Y_t)\\) is:\n\\[\n\\begin{aligned}\ndY_{t} & =d\\left(\\frac{S_{1}( t)}{S_{2}( t)}\\right)\\\\\n& \\left\\{\\text{Applying Ito's product rule }\\right\\}\\\\\n& =S_{1}( t) d\\left(\\frac{1}{S_{2}( t)}\\right) +\\frac{1}{S_{2}( t)} dS_{1}( t) +dS_{1}( t) d\\left(\\frac{1}{S_{2}( t)}\\right)\\\\\n& =-S_{1}( t)\\left[\\frac{1}{S_{2}( t)^{2}} dS_{2}( t) +\\frac{1}{2}\\left(\\frac{2}{S_{2}( t)^{3}}\\right) dS_{2}( t) \\cdot dS_{2}( t)\\right] +\\frac{1}{S_{2}( t)}\\left( rS_{1}( t) dt+\\sigma _{1} S_{1}( t) dW_{1}^{\\mathbb{Q}}( t)\\right)\\\\\n& +S_{1}\\left( rdt+\\sigma _{1} dW_{1}^{\\mathbb{Q}}( t)\\right)\\left[ -\\frac{1}{S_{2}( t)^{2}} dS_{2}( t) +\\frac{1}{2}\\left(\\frac{2}{S_{2}( t)^{3}}\\right) dS_{2}( t) \\cdot dS_{2}( t)\\right]\\\\\n& =-\\frac{S_{1}( t)}{S_{2}( t)}\\left(\\cancel{rdt} +\\sigma _{2} dW_{2}^{\\mathbb{Q}}( t)\\right) -\\frac{S_{1}( t)}{S_{2}( t)} \\sigma _{2}^{2} dt+\\frac{S_{1}( t)}{S_{2}( t)}\\left(\\cancel{rdt} +\\sigma _{1} dW_{1}^{\\mathbb{Q}}( t)\\right)\\\\\n& +\\frac{S_{1}}{S_{2}}\\left( rdt+\\sigma _{1} dW_{1}^{\\mathbb{Q}}( t)\\right)\\left[ -\\left( rdt+\\sigma _{2} dW_{2}^{\\mathbb{Q}}( t)\\right) +\\sigma _{2}^{2} dt\\right]\\\\\n& =\\frac{S_{1}}{S_{2}}\\left[ -\\sigma _{2} dW_{2}^{\\mathbb{Q}}( t) +\\sigma _{1} dW_{1}^{\\mathbb{Q}}( t) -\\rho \\sigma _{1} \\sigma _{2} dt-\\sigma _{2}^{2} dt\\right]\\\\\n&=Y_t\\left[ -\\sigma _{2} dW_{2}^{\\mathbb{Q}}( t) +\\sigma _{1} dW_{1}^{\\mathbb{Q}}( t) -\\rho \\sigma _{1} \\sigma _{2} dt-\\sigma _{2}^{2} dt\\right]\n\\end{aligned}\n\\]\nSince we know, the \\(Y_t\\) is the price of \\(S_1(t)\\) expressed in units of \\(S_2(t)\\), it is a \\(\\mathbb{Q}^{S_2}\\)-martingale. So, we can just drop the \\((...)dt\\) terms and write:\n\\[\ndY_t = Y_t \\left[ -\\sigma_{2} dW_{2}^{\\mathbb{Q}^{S_2}}( t) +\\sigma_{1} dW_{1}^{\\mathbb{Q}^{S_2}}(t) \\right]\n\\]\nWe can perform an orthogonal decomposition of the correlated brownian motions \\(W_1^{\\mathbb{Q}^{S_2}}(t)\\) and \\(W_2^{\\mathbb{Q}^{S_2}}(t)\\) and write:\n\\[\n\\begin{align*}\ndY_t = Y_t \\left[ -\\sigma_{2} (\\rho dB_1^{\\mathbb{Q}^{S_2}} (t) + \\sqrt{1 - \\rho^2} dB_2^{\\mathbb{Q}^{S_2}}(t)) +\\sigma_{1} dB_{1}^{\\mathbb{Q}^{S_2}}(t) \\right]\\\\\ndY_t = Y_t \\left[(\\sigma_1 - \\rho \\sigma_2) dB_1^{\\mathbb{Q}^{S_2}} (t) - \\sigma_2 \\sqrt{1 - \\rho^2}dB_2^{\\mathbb{Q}^{S_2}}(t)\\right]\n\\end{align*}\n\\]\nDefine the process \\((X_t,t\\geq 0)\\) as:\n\\[\ndX_t = \\frac{1}{\\sigma} \\left[(\\sigma_1 - \\rho \\sigma_2) dB_1^{\\mathbb{Q}^{S_2}} (t) - \\sigma_2 \\sqrt{1 - \\rho^2}dB_2^{\\mathbb{Q}^{S_2}}(t)\\right]\n\\]\nwhere \\(\\sigma = \\sqrt{\\sigma_1^2 + \\sigma_2^2 - 2\\rho \\sigma_1 \\sigma_2}\\).\nIt follows that \\((X_t,t\\geq 0)\\) is a martingale and\n\\[\n\\begin{align*}\ndX_t \\cdot dX_t &=\\frac{1}{\\sigma^2}\\left[ \\sigma_2^2(\\rho dB_1^{\\mathbb{Q}^{S_2}} (t) + \\sqrt{1 - \\rho^2} dB_2^{\\mathbb{Q}^{S_2}}(t))^2 + \\sigma_1^2 dt - 2\\rho \\sigma_1 \\sigma_2 dt\\right]\\\\\n&=\\frac{1}{\\sigma^2}(\\sigma_1^2 + \\sigma_2^2 - 2\\rho \\sigma_1 \\sigma_2)dt \\\\\n&= dt\n\\end{align*}\n\\]\nBy Levy’s characterization theorem, \\((X_t,t\\geq 0)\\) is a standard brownian motion. Hence, \\((Y_t)\\) given by the SDE:\n\\[\ndY_t = \\sigma Y_t dX_t\n\\]\nfollows lognormal dynamics.\n\n\n\nWe can thus price the claim \\(\\mathbb{E}^{\\mathbb{Q}^{S_2}}\\left[(Y_T - 1)^+\\right]\\) using the Black formula for a european call option with the asset price given by \\(Y_t = S_1(t)/S_2(t)\\), strike \\(K = 1\\), the volatility parameter \\(\\sigma = \\sqrt{\\sigma_1^2 + \\sigma_2^2 - 2\\rho \\sigma_1 \\sigma_2}\\) and riskfree rate \\(r=0\\). Subbing these quantities in the Black formula, we have:\n\\[\n\\begin{align*}\nV(0) &= S_2(0) (F\\Phi(d_{+}) - K\\Phi(d_{-})) \\\\\n&= S_2(0)\\left(\\frac{S_1(0)}{S_2(0)}\\Phi(d_{+}) - \\Phi(d_{-})\\right)\\\\\n&=S_1(0)\\Phi(d_{+}) - S_2(0)\\Phi(d_{-})\n\\end{align*}\n\\]\nwhere\n\\[\nd_{\\pm} = \\frac{\\ln\\left(\\frac{S_1(0)}{S_2(0)}\\right) \\pm \\frac{\\sigma^2}{2}T}{\\sigma\\sqrt{T}}\n\\]"
  },
  {
    "objectID": "posts/kirks_approximation_a_numerical_experiment/index.html#margrabes-formula",
    "href": "posts/kirks_approximation_a_numerical_experiment/index.html#margrabes-formula",
    "title": "Margrabe’s formula",
    "section": "",
    "text": "Let \\(S_1(t)\\) and \\(S_2(t)\\) denote the prices of two risky assets which have dynamics:\n\\[\n\\begin{align*}\ndS_1(t)/ S_1(t) &= r dt + \\sigma_1 dW_1^{\\mathbb{Q}}(t) \\\\\ndS_2(t)/ S_2(t) &= r dt + \\sigma_2 dW_2^{\\mathbb{Q}}(t)\n\\end{align*}\n\\]\nwhere \\(r\\) is the constant risk-free rate, \\(W_1^{\\mathbb{Q}}(t)\\) and \\(W_2^{\\mathbb{Q}}(t)\\) are brownian motions with instantaneous correlation \\(\\rho\\).\nWe are interested to price the payoff\n\\[\nV_T = (S_1(T) - S_2(T))^+\n\\]\nBy the risk-neutral pricing formula,\n\\[\n\\begin{align*}\nV_0 &= M(0)\\mathbb{E}^{\\mathbb{Q}}\\left[\\frac{V(T)}{M(T)}\\right]\\\\\n&= S_2(0)\\mathbb{E}^{\\mathbb{Q}^{S_2}}\\left[\\frac{V(T)}{S_2(T)}\\right]\\\\\n& \\quad \\{\\text{Switching from }\\mathbb{Q}\\text{ to }\\mathbb{Q}^{S_2}\\text{-measure.}\\}\\\\\n&= S_2(0)\\mathbb{E}^{\\mathbb{Q}^{S_2}}\\left[\\frac{1}{S_2(T)}S_1(T) - S_2(T) 1_{S_1(T) &gt; S_2(T)}\\right]\\\\\n&= S_2(0)\\mathbb{E}^{\\mathbb{Q}^{S_2}}\\left[\\left(\\frac{S_1(T)}{S_2(T)} - 1 \\right) 1_{S_1(T) &gt; S_2(T)}\\right]\\\\\n\\end{align*}\n\\]\nDefine the asset price process \\(Y(t)\\) as:\n\\[\nY(t) := \\frac{S_1(t)}{S_2(t)}\n\\]\nSo, we want to compute the expectation\n\\[\nV_0 = S_2(0) \\mathbb{E}^{\\mathbb{Q}^{S_2}} \\left[(Y_T - 1)^+\\right]\n\\]\n\n\nWe know that \\((Y_t,t\\geq 0)\\) is a \\(\\mathbb{Q}^{S_2}\\) martingale. The \\(\\mathbb{Q}\\)-dynamics of \\((Y_t)\\) is:\n\\[\n\\begin{aligned}\ndY_{t} & =d\\left(\\frac{S_{1}( t)}{S_{2}( t)}\\right)\\\\\n& \\left\\{\\text{Applying Ito's product rule }\\right\\}\\\\\n& =S_{1}( t) d\\left(\\frac{1}{S_{2}( t)}\\right) +\\frac{1}{S_{2}( t)} dS_{1}( t) +dS_{1}( t) d\\left(\\frac{1}{S_{2}( t)}\\right)\\\\\n& =-S_{1}( t)\\left[\\frac{1}{S_{2}( t)^{2}} dS_{2}( t) +\\frac{1}{2}\\left(\\frac{2}{S_{2}( t)^{3}}\\right) dS_{2}( t) \\cdot dS_{2}( t)\\right] +\\frac{1}{S_{2}( t)}\\left( rS_{1}( t) dt+\\sigma _{1} S_{1}( t) dW_{1}^{\\mathbb{Q}}( t)\\right)\\\\\n& +S_{1}\\left( rdt+\\sigma _{1} dW_{1}^{\\mathbb{Q}}( t)\\right)\\left[ -\\frac{1}{S_{2}( t)^{2}} dS_{2}( t) +\\frac{1}{2}\\left(\\frac{2}{S_{2}( t)^{3}}\\right) dS_{2}( t) \\cdot dS_{2}( t)\\right]\\\\\n& =-\\frac{S_{1}( t)}{S_{2}( t)}\\left(\\cancel{rdt} +\\sigma _{2} dW_{2}^{\\mathbb{Q}}( t)\\right) -\\frac{S_{1}( t)}{S_{2}( t)} \\sigma _{2}^{2} dt+\\frac{S_{1}( t)}{S_{2}( t)}\\left(\\cancel{rdt} +\\sigma _{1} dW_{1}^{\\mathbb{Q}}( t)\\right)\\\\\n& +\\frac{S_{1}}{S_{2}}\\left( rdt+\\sigma _{1} dW_{1}^{\\mathbb{Q}}( t)\\right)\\left[ -\\left( rdt+\\sigma _{2} dW_{2}^{\\mathbb{Q}}( t)\\right) +\\sigma _{2}^{2} dt\\right]\\\\\n& =\\frac{S_{1}}{S_{2}}\\left[ -\\sigma _{2} dW_{2}^{\\mathbb{Q}}( t) +\\sigma _{1} dW_{1}^{\\mathbb{Q}}( t) -\\rho \\sigma _{1} \\sigma _{2} dt-\\sigma _{2}^{2} dt\\right]\\\\\n&=Y_t\\left[ -\\sigma _{2} dW_{2}^{\\mathbb{Q}}( t) +\\sigma _{1} dW_{1}^{\\mathbb{Q}}( t) -\\rho \\sigma _{1} \\sigma _{2} dt-\\sigma _{2}^{2} dt\\right]\n\\end{aligned}\n\\]\nSince we know, the \\(Y_t\\) is the price of \\(S_1(t)\\) expressed in units of \\(S_2(t)\\), it is a \\(\\mathbb{Q}^{S_2}\\)-martingale. So, we can just drop the \\((...)dt\\) terms and write:\n\\[\ndY_t = Y_t \\left[ -\\sigma_{2} dW_{2}^{\\mathbb{Q}^{S_2}}( t) +\\sigma_{1} dW_{1}^{\\mathbb{Q}^{S_2}}(t) \\right]\n\\]\nWe can perform an orthogonal decomposition of the correlated brownian motions \\(W_1^{\\mathbb{Q}^{S_2}}(t)\\) and \\(W_2^{\\mathbb{Q}^{S_2}}(t)\\) and write:\n\\[\n\\begin{align*}\ndY_t = Y_t \\left[ -\\sigma_{2} (\\rho dB_1^{\\mathbb{Q}^{S_2}} (t) + \\sqrt{1 - \\rho^2} dB_2^{\\mathbb{Q}^{S_2}}(t)) +\\sigma_{1} dB_{1}^{\\mathbb{Q}^{S_2}}(t) \\right]\\\\\ndY_t = Y_t \\left[(\\sigma_1 - \\rho \\sigma_2) dB_1^{\\mathbb{Q}^{S_2}} (t) - \\sigma_2 \\sqrt{1 - \\rho^2}dB_2^{\\mathbb{Q}^{S_2}}(t)\\right]\n\\end{align*}\n\\]\nDefine the process \\((X_t,t\\geq 0)\\) as:\n\\[\ndX_t = \\frac{1}{\\sigma} \\left[(\\sigma_1 - \\rho \\sigma_2) dB_1^{\\mathbb{Q}^{S_2}} (t) - \\sigma_2 \\sqrt{1 - \\rho^2}dB_2^{\\mathbb{Q}^{S_2}}(t)\\right]\n\\]\nwhere \\(\\sigma = \\sqrt{\\sigma_1^2 + \\sigma_2^2 - 2\\rho \\sigma_1 \\sigma_2}\\).\nIt follows that \\((X_t,t\\geq 0)\\) is a martingale and\n\\[\n\\begin{align*}\ndX_t \\cdot dX_t &=\\frac{1}{\\sigma^2}\\left[ \\sigma_2^2(\\rho dB_1^{\\mathbb{Q}^{S_2}} (t) + \\sqrt{1 - \\rho^2} dB_2^{\\mathbb{Q}^{S_2}}(t))^2 + \\sigma_1^2 dt - 2\\rho \\sigma_1 \\sigma_2 dt\\right]\\\\\n&=\\frac{1}{\\sigma^2}(\\sigma_1^2 + \\sigma_2^2 - 2\\rho \\sigma_1 \\sigma_2)dt \\\\\n&= dt\n\\end{align*}\n\\]\nBy Levy’s characterization theorem, \\((X_t,t\\geq 0)\\) is a standard brownian motion. Hence, \\((Y_t)\\) given by the SDE:\n\\[\ndY_t = \\sigma Y_t dX_t\n\\]\nfollows lognormal dynamics.\n\n\n\nWe can thus price the claim \\(\\mathbb{E}^{\\mathbb{Q}^{S_2}}\\left[(Y_T - 1)^+\\right]\\) using the Black formula for a european call option with the asset price given by \\(Y_t = S_1(t)/S_2(t)\\), strike \\(K = 1\\), the volatility parameter \\(\\sigma = \\sqrt{\\sigma_1^2 + \\sigma_2^2 - 2\\rho \\sigma_1 \\sigma_2}\\) and riskfree rate \\(r=0\\). Subbing these quantities in the Black formula, we have:\n\\[\n\\begin{align*}\nV(0) &= S_2(0) (F\\Phi(d_{+}) - K\\Phi(d_{-})) \\\\\n&= S_2(0)\\left(\\frac{S_1(0)}{S_2(0)}\\Phi(d_{+}) - \\Phi(d_{-})\\right)\\\\\n&=S_1(0)\\Phi(d_{+}) - S_2(0)\\Phi(d_{-})\n\\end{align*}\n\\]\nwhere\n\\[\nd_{\\pm} = \\frac{\\ln\\left(\\frac{S_1(0)}{S_2(0)}\\right) \\pm \\frac{\\sigma^2}{2}T}{\\sigma\\sqrt{T}}\n\\]"
  },
  {
    "objectID": "posts/kirks_approximation_a_numerical_experiment/index.html#references",
    "href": "posts/kirks_approximation_a_numerical_experiment/index.html#references",
    "title": "Margrabe’s formula",
    "section": "References",
    "text": "References\n\n\nMargrabe’s formula, Wikipedia."
  },
  {
    "objectID": "posts/martingales/index.html",
    "href": "posts/martingales/index.html",
    "title": "Martingales",
    "section": "",
    "text": "In elementary probability, the conditional expectation of a variable \\(Y\\) given another random variable \\(X\\) refers to the expectation of \\(Y\\) given the conditional distribution \\(f_{Y|X}(y|x)\\) of \\(Y\\) given \\(X\\). To illustrate this, let’s go through a simple example. Consider \\(\\mathcal{B}_{1}\\), \\(\\mathcal{B}_{2}\\) to be two independent Bernoulli-distributed random variables with \\(p=1/2\\). Then, construct:\n\\[\\begin{aligned}\nX=\\mathcal{B}_{1}, & \\quad Y=\\mathcal{B}_{1}+\\mathcal{B}_{2}\n\\end{aligned}\\]\nIt is easy to compute \\(\\mathbb{E}[Y|X=0]\\) and \\(\\mathbb{E}[Y|X=1]\\). By definition, it is given by:\n\\[\\begin{aligned}\n\\mathbb{E}[Y|X=0] & =\\sum_{j=0}^{2}j\\mathbb{P}(Y=j|X=0)\\\\\n& =\\sum_{j=0}^{2}j\\cdot\\frac{\\mathbb{P}(Y=j,X=0)}{P(X=0)}\\\\\n& =0+1\\cdot\\frac{(1/4)}{(1/2)}+2\\cdot\\frac{0}{(1/2)}\\\\\n& =\\frac{1}{2}\n\\end{aligned}\\]\nand\n\\[\\begin{aligned}\n\\mathbb{E}[Y|X=1] & =\\sum_{j=0}^{2}j\\mathbb{P}(Y=j|X=1)\\\\\n& =\\sum_{j=0}^{2}j\\cdot\\frac{\\mathbb{P}(Y=j,X=1)}{P(X=1)}\\\\\n& =0+1\\cdot\\frac{(1/4)}{(1/2)}+2\\cdot\\frac{(1/4)}{(1/2)}\\\\\n& =\\frac{3}{2}\n\\end{aligned}\\]\nWith this point of view, the conditional expectation is computed given the information that the event \\(\\{X=0\\}\\) occurred or the event \\(\\{X=1\\}\\) occurred. It is possible to regroup both conditional expectations in a single object, if we think of the conditional expectation as a random variable and denote it by \\(\\mathbb{E}[Y|X]\\). Namely, we take:\n\\[\\begin{aligned}\n\\mathbb{E}[Y|X](\\omega) & =\\begin{cases}\n\\frac{1}{2} & \\text{if }X(\\omega)=0\\\\\n\\frac{3}{2} & \\text{if }X(\\omega)=1\n\\end{cases}\\label{eq:elementary-conditional-expectation-example}\n\\end{aligned}\\]\nThis random variable is called the conditional expectation of \\(Y\\) given \\(X\\). We make two important observations:\n(i) If the value of \\(X\\) is known, then the value of \\(\\mathbb{E}[Y|X]\\) is determined.\n(ii) If we have another random variable \\(g(X)\\) constructed from \\(X\\), then we have:\n\\[\\begin{aligned}\n\\mathbb{E}[g(X)Y] & =\\mathbb{E}[g(X)\\mathbb{E}[Y|X]]\n\\end{aligned}\\]\nIn other words, as far as \\(X\\) is concerned, the conditional expectation \\(\\mathbb{E}[Y|X]\\) is a proxy for \\(Y\\) in the expectation. We sometimes say that \\(\\mathbb{E}[Y|X]\\) is the best estimate of \\(Y\\) given the information of \\(X\\).\nThe last observation is easy to verify since:\n\\[\\begin{aligned}\n\\mathbb{E}[g(X)Y] & =\\sum_{i=0}^{1}\\sum_{j=0}^{2}g(i)\\cdot j\\cdot\\mathbb{P}(X=i,Y=j)\\\\\n& =\\sum_{i=0}^{1}\\mathbb{P}(X=i)g(i)\\left\\{ \\sum_{j=0}^{2}j\\cdot\\frac{\\mathbb{P}(X=i,Y=j)}{\\mathbb{P}(X=i)}\\right\\} \\\\\n& =\\mathbb{E}[g(X)\\mathbb{E}[Y|X]]\n\\end{aligned}\\]\n\n(Elementary Definitions of Conditional Expectation).\n(1) \\((X,Y)\\) discrete. The treatment is similar to the above. If a random variable \\(X\\) takes values \\((x_{i},i\\geq1)\\) and \\(Y\\) takes values \\((y_{j},j\\geq1)\\), we have by definition that the conditional expectation as a random variable is:\n\\[\\begin{aligned}\n\\mathbb{E}[Y|X](\\omega) & =\\sum_{j\\geq1}y_{j}\\mathbb{P}(Y=y_{j}|X=x_{i})\\quad\\text{for }\\omega\\text{ such that }X(\\omega)=x_{i}\n\\end{aligned}\\] (2) \\((X,Y)\\) continuous with joint PDF \\(f_{X,Y}(x,y)\\): In this case, the conditional expectation is the random variable given by\n\\[\\begin{aligned}\n\\mathbb{E}[Y|X] & =h(X)\n\\end{aligned}\\]\nwhere\n\\[\\begin{aligned}\nh(x) & =\\int_{\\mathbf{R}}yf_{Y|X}(y|x)dy=\\int_{\\mathbf{R}}y\\frac{f_{X,Y}(x,y)}{f_{X}(x)}dy=\\frac{\\int_{\\mathbf{R}}yf_{X,Y}(x,y)dy}{\\int_{\\mathbf{R}}f_{X,Y}(x,y)dy}\n\\end{aligned}\\]\n\nIn the two examples above, the expectation of the random variable \\(\\mathbb{E}[Y|X]\\) is equal to \\(\\mathbb{E}[Y]\\). Indeed in the discrete case, we have:\n\\[\\begin{aligned}\n\\mathbb{E}[\\mathbb{E}[Y|X]] & =\\sum_{i=0}^{1}P(X=x_{i})\\cdot\\sum_{j=0}^{2}y_{j}\\mathbb{P}(Y=y_{j}|X=x_{i})\\\\\n& =\\sum_{i=0}^{1}\\sum_{j=0}^{2}y_{j}\\mathbb{P}(Y=y_{j},X=x_{i})\\\\\n& =\\sum_{j=0}^{2}y_{j}\\mathbb{P}(Y=y_{j})\\\\\n& =\\mathbb{E}[Y]\n\\end{aligned}\\]\n\n(Conditional Probability vs Conditional expectation). The conditional probability of the event \\(A\\) given \\(B\\) can be recast in terms of conditional expectation using indicator functions. If \\(0&lt;\\mathbb{P}(B)&lt;1\\), it is not hard to check that: \\(\\mathbb{P}(A|B)=\\mathbb{E}[\\mathbf{1}_{A}|\\mathbf{1}_{B}=1]\\) and \\(\\mathbb{P}(A|B^{C})=\\mathbb{E}[\\mathbf{1}_{A}|1_{B}=0]\\). Indeed the random variables \\(\\mathbf{1}_{A}\\) and \\(\\mathbf{1}_{B}\\) are discrete. If we proceed as in the discrete case above, we have:\n\\[\\begin{aligned}\n\\mathbb{E}[\\mathbf{1}_{A}|\\mathbf{1}_{B}=1] & =1\\cdot\\mathbb{P}(\\mathbf{1}_{A}=1|\\mathbf{1}_{B}=1)\\\\\n& =\\frac{\\mathbb{P}(\\mathbf{1}_{A}=1,\\mathbf{1}_{B}=1)}{\\mathbb{P}(\\mathbf{1}_{B}=1)}\\\\\n& =\\frac{\\mathbb{P}(A\\cap B)}{\\mathbb{P}(B)}\\\\\n& =\\mathbb{P}(A|B)\n\\end{aligned}\\]\nA similar calculation gives \\(\\mathbb{P}(A|B^{C})\\). In particular, the formula for total probability for \\(A\\) is a rewriting of the expectation of the random variable \\(\\mathbb{E}[\\mathbf{1}_{A}|\\mathbf{1}_{B}]\\):\n\\[\\begin{aligned}\n\\mathbb{E}[\\mathbb{E}[\\mathbf{1}_{A}|\\mathbf{1}_{B}]] & =\\mathbb{E}[\\mathbf{1}_{A}|\\mathbf{1}_{B}=1]\\mathbb{P}(\\mathbf{1}_{B}=1)+\\mathbb{E}[\\mathbf{1}_{A}|\\mathbf{1}_{B}=0]\\mathbb{P}(\\mathbf{1}_{B}=0)\\\\\n& =\\mathbb{P}(A|B)\\cdot\\mathbb{P}(B)+\\mathbb{P}(A|B^{C})\\cdot\\mathbb{P}(B^{C})\\\\\n& =\\mathbb{P}(A)\n\\end{aligned}\\]\n\n\n\n\n\n\nWe start by giving the definition of conditional expectation given a single variable. This relates to the two observations (A) and (B) made previously. We assume that the random variable is integrable for the expectations to be well-defined.\n\nLet \\(X\\) and \\(Y\\) be integrable random variables on \\((\\Omega,\\mathcal{F},\\mathbb{P})\\). The conditional expectation of \\(Y\\) given \\(X\\) is the random variable denoted by \\(\\mathbb{E}[Y|X]\\) with the following two properties:\n(A) There exists a function \\(h:\\mathbf{R}\\to\\mathbf{R}\\) such that \\(\\mathbb{E}[Y|X]=h(X)\\).\n(B) For any bounded random variable of the form \\(g(X)\\) for some function \\(g\\),\n\\[\\mathbb{E}[g(X)Y]=\\mathbb{E}[g(X)\\mathbb{E}[Y|X]]\\label{eq:definition-conditional-expectation}\\]\nWe can intepret the second property as follows. The conditional expectation \\(\\mathbb{E}[Y|X]\\) serves as a proxy for \\(Y\\) as far as \\(X\\) is concerned. Note that in equation ([eq:definition-conditional-expectation]), the expectation on the left can be seen as an average over the joint values of \\((X,Y)\\), whereas the one on the right is an average over the values of \\(X\\) only! Another way to see this property is to write is as:\n\\[\\mathbb{E}[g(X)(Y-\\mathbb{E}[Y|X])]=0\\]\nIn other words, the random variable \\(Y-\\mathbb{E}[Y|X]\\) is orthogonal to any random variable constructed from \\(X\\).\nFinally, it is important to notice that if we take \\(g(X)=1\\), then the second property implies :\n\\[\\begin{aligned}\n\\mathbb{E}[Y] & =\\mathbb{E}[\\mathbb{E}[Y|X]]\n\\end{aligned}\\]\nIn other words, the expectation of the conditional expectation of \\(Y\\) is simply the expectation of \\(Y\\).\nThe existence of the conditional expectation \\(\\mathbb{E}[Y|X]\\) is not obvious. We know, it exists in particular cases given in example ([ex:elementary-definitions-of-conditional-expectation]). We will show more generally, that it exists, it is unique whenever \\(Y\\) is in \\(L^{2}(\\Omega,\\mathcal{F},\\mathbb{P})\\) (In fact, it can be shown to exist whenever \\(Y\\) is integrable). Before doing so, let’s warm up by looking at the case of Gaussian vectors.\n\n\n(Conditional expectation of Gaussian vectors - I). Let \\((X,Y)\\) be a Gaussian vector of mean \\(0\\). Then:\n\\[\\mathbb{E}[Y|X]=\\frac{\\mathbb{E}[XY]}{\\mathbb{E}[X^{2}]}X\\label{eq:conditional-expectation-of-gaussian-vector}\\]\nThis candidate satisfies the two defining properties of conditional expectation : (A) It is clearly a function of \\(X\\); in fact it is a simple multiple of \\(X\\). (B) We have that the random variable \\(\\left(Y-\\frac{\\mathbb{E}[XY]}{\\mathbb{E}[X^{2}]}X\\right)\\) is orthogonal and thus independent to \\(X\\). This is a consequence of the proposition ([prop:diagonal-cov-matrix-implies-independence-of-gaussians]), since:\n\\[\\begin{aligned}\n\\mathbb{E}\\left[X\\left(Y-\\frac{\\mathbb{E}[XY]}{\\mathbb{E}[X^{2}]}X\\right)\\right] & =\\mathbb{E}XY-\\frac{\\mathbb{E}[XY]}{\\mathbb{E}[X^{2}]}\\mathbb{E}X^{2}\\\\\n& =\\mathbb{E}XY-\\frac{\\mathbb{E}[XY]}{\\cancel{\\mathbb{E}[X^{2}]}}\\cancel{\\mathbb{E}X^{2}}\\\\\n& =0\n\\end{aligned}\\]\nTherefore, we have for any bounded function \\(g(X)\\) of \\(X\\):\n\\[\\begin{aligned}\n\\mathbb{E}[g(X)(Y-\\mathbb{E}(Y|X))] & =\\mathbb{E}[g(X)]\\mathbb{E}[Y-\\mathbb{E}[Y|X]]=0\n\\end{aligned}\\]\n\n\n(Brownian conditioning-I) Let \\((B_{t},t\\geq0)\\) be a standard Brownian motion. Consider the Gaussian vector \\((B_{1/2},B_{1})\\). Its covariance matrix is:\n\\[\\begin{aligned}\nC & =\\left[\\begin{array}{cc}\n1/2 & 1/2\\\\\n1/2 & 1\n\\end{array}\\right]\n\\end{aligned}\\]\nLet’s compute \\(\\mathbb{E}[B_{1}|B_{1/2}]\\) and \\(\\mathbb{E}[B_{1/2}|B_{1}]\\). This is easy using the equation ([eq:conditional-expectation-of-gaussian-vector]). We have:\n\\[\\begin{aligned}\n\\mathbb{E}[B_{1}|B_{1/2}] & =\\frac{\\mathbb{E}[B_{1}B_{1/2}]}{\\mathbb{E}[B_{1/2}^{2}]}B_{1/2}\\\\\n& =\\frac{(1/2)}{(1/2)}B_{1/2}\\\\\n& =B_{1/2}\n\\end{aligned}\\]\nIn other words, the best approximation of \\(B_{1}\\) given the information of \\(B_{1/2}\\) is \\(B_{1/2}\\). There is no problem in computing \\(\\mathbb{E}[B_{1/2}|B_{1}]\\), even though we are conditioning on a future position. Indeed the same formula gives\n\\[\\begin{aligned}\n\\mathbb{E}[B_{1/2}|B_{1}] & =\\frac{\\mathbb{E}[B_{1}B_{1/2}]}{\\mathbb{E}[B_{1}^{2}]}B_{1}=\\frac{1}{2}B_{1}\n\\end{aligned}\\]\nThis means that the best approximation of \\(B_{1/2}\\) given the position at time \\(1\\), is \\(\\frac{1}{2}B_{1}\\) which makes a whole lot of sense!\n\nIn example ([eq:conditional-expectation-of-gaussian-vector]) for the Gaussian vector \\((X,Y)\\), the conditional expectation was equal to the orthogonal projection of \\(Y\\) onto \\(X\\) in \\(L^{2}\\). In particular, the conditional expectation was a multiple of \\(X\\). Is this always the case? Unfortunately, it is not. For example, in the equation ([eq:elementary-conditional-expectation-example]), the conditional expectation is clearly not a multiple of the random variable \\(X\\). However, it is a function of \\(X\\), as is always the case by definition ([def:conditional-expectation]).\nThe idea to construct the conditional expectation \\(\\mathbb{E}[Y|X]\\) in general is to project \\(Y\\) on the space of all random variables that can be constructed from \\(X\\). To make this precise, consider the following subspace of \\(L^{2}(\\Omega,\\mathcal{F},\\mathbb{P})\\) :\n\nLet \\((\\Omega,\\mathcal{F},\\mathbb{P})\\) be a probability space and \\(X\\) a random variable defined on it. The space \\(L^{2}(\\Omega,\\sigma(X),\\mathbb{P})\\) is the linear subspace of \\(L^{2}(\\Omega,\\mathcal{F},\\mathbb{P})\\) consisting of the square-integrable random variables of the form \\(g(X)\\) for some function \\(g:\\mathbf{R}\\to\\mathbf{R}\\).\n\nThis is a linear subspace of \\(L^{2}(\\Omega,\\mathcal{F},\\mathbb{P})\\): It contains the random variable \\(0\\), and any linear combination of random variables of this kind is also a function of \\(X\\) and must have a finite second moment. We note the following:\n\n\\(L^{2}(\\Omega,\\sigma(X),\\mathbb{P})\\) is a subspace of \\(L^{2}(\\Omega,\\mathcal{F},\\mathbb{P})\\), very much how a plane or line (going through the origin) is a subspace of \\(\\mathbf{R}^{3}\\).\nIn particular, as in the case of a line or a plane, we can project an element of \\(Y\\) of \\(L^{2}(\\Omega,\\mathcal{F},\\mathbb{P})\\) onto \\(L^{2}(\\Omega,\\sigma(X),\\mathbb{P})\\). The resulting projection is an element of \\(L^{2}(\\Omega,\\sigma(X),\\mathbb{P})\\), a square-integrable random-variable that is a function of \\(X\\). For a subspace \\(\\mathcal{S}\\) of \\(\\mathbf{R}^{3}\\) (e.g. a line or a plane), the projection of the vector \\(\\mathbf{v}\\in\\mathbf{R}^{3}\\) onto the subspace \\(\\mathcal{S}\\), denoted \\(\\text{Proj}_{\\mathcal{S}}(\\mathbf{v})\\) is the closest point to \\(\\mathbf{v}\\) lying in the subspace \\(\\mathcal{S}\\). Moreover, \\(\\mathbf{v}-\\text{Proj}_{\\mathcal{S}}(\\mathbf{v})\\) is orthogonal to the subspace. This picture of orthogonal projection also holds in \\(L^{2}\\). Let \\(Y\\) be a random variable in \\(L^{2}(\\Omega,\\mathcal{F},\\mathbb{P})\\) and let \\(L^{2}(\\Omega,\\sigma(X),\\mathbb{P})\\) be the subspace of those random variables that are functions of \\(X\\). We write \\(Y^{\\star}\\) for the random variable in \\(L^{2}(\\Omega,\\sigma(X),\\mathbb{P})\\) that is closest to \\(Y\\). In other words, we have (using the definition of the \\(L^{2}\\)-distance square):\n\\[\\inf_{Z\\in L^{2}(\\Omega,\\sigma(X),\\mathbb{P})}\\mathbb{E}[(Y-Z)^{2}]=\\mathbb{E}[(Y-Y^{\\star})^{2}]\\label{eq:Y-star-is-the-closest-to-Y-in-L2-sense}\\]\n\nIt turns out that \\(Y^{\\star}\\) is the right candidate for the conditional expectation.\n\nFigure. An illustration of the conditional expectation \\(\\mathbb{E}[Y|X]\\) as an orthogonal projection of \\(Y\\) onto the subspace \\(L^2(\\Omega,\\sigma(X),\\mathbb{P})\\).\n\n\n(Existence and uniqueness of the conditional expectation) Let \\(X\\) be a random variable on \\((\\Omega,\\mathcal{F},\\mathbb{P})\\). Let \\(Y\\) be a random variable in \\(L^{2}(\\Omega,\\mathcal{F},\\mathbb{P})\\). Then the conditional expectation \\(\\mathbb{E}[Y|X]\\) is the random variable \\(Y^{\\star}\\) given in the equation ([eq:Y-star-is-the-closest-to-Y-in-L2-sense]). Namely, it is the random variable in \\(L^{2}(\\Omega,\\sigma(X),\\mathbb{P})\\) that is closest to \\(Y\\) in the \\(L^{2}\\)-distance.\nIn particular we have the following:\n1) It is the orthogonal projection of \\(Y\\) onto \\(L^{2}(\\Omega,\\sigma(X),\\mathbb{P})\\), that is \\(Y-Y^{\\star}\\) is orthogonal to any random variables in the subspace \\(L^{2}(\\Omega,\\sigma(X),\\mathbb{P})\\).\n2) It is unique.\n\n\nThis result reinforces the meaning of the conditional expectation \\(\\mathbb{E}[Y|X]\\) as the best estimation of \\(Y\\) given the information of \\(X\\): it is the closest random variable to \\(Y\\) among all the functions of \\(X\\) in the sense of \\(L^{2}\\).\n\n\nProof. Proof. We write for short \\(L^{2}(X)\\) for the subspace \\(L^{2}(\\Omega,\\sigma(X),\\mathbb{P})\\). Let \\(Y^{\\star}\\) be as in equation ([eq:Y-star-is-the-closest-to-Y-in-L2-sense]). We show successively that (1) \\(Y-Y^{\\star}\\) is orthogonal to any element of \\(L^{2}(X)\\), so it is the orthogonal projection (2) \\(Y^{\\star}\\) has the properties of conditional expectation in definition ([eq:definition-conditional-expectation]) (3) \\(Y^{\\star}\\) is unique.\n(1) Let \\(W=g(X)\\) be a random variable in \\(L^{2}(X)\\). We show that \\(W\\) is orthogonal to \\(Y-Y^{\\star}\\); that is \\(\\mathbb{E}[(Y-Y^{\\star})W]=0\\). This should be intuitively clear from figure above. On the one hand, we have by developing the square:\n\\[\\begin{aligned}\n\\mathbb{E}[(W-(Y-Y^{\\star}))^{2}] & =\\mathbb{E}[W^{2}-2W(Y-Y^{\\star})+(Y-Y^{\\star})^{2}]\\nonumber \\\\\n& =\\mathbb{E}[W^{2}]-2\\mathbb{E}[W(Y-Y^{\\star})]+\\mathbb{E}(Y-Y^{\\star})^{2}]\\label{eq:developing-the-square}\n\\end{aligned}\\]\nOn the other hand, \\(Y^{\\star}+W\\) is an arbitrary vector in \\(L^{2}(X)\\)(it is a linear combination of the elements in \\(L^{2}(X)\\)), we must have from equation ([eq:Y-star-is-the-closest-to-Y-in-L2-sense]):\n\\[\\begin{aligned}\n\\mathbb{E}[(W-(Y-Y^{\\star}))^{2}] & =\\mathbb{E}[(Y-(Y^{\\star}+W))^{2}]\\nonumber \\\\\n& \\geq\\inf_{Z\\in L^{2}(X)}\\mathbb{E}[(Y-Z)^{2}]\\nonumber \\\\\n& =\\mathbb{E}[(Y-Y^{\\star})^{2}]\\label{eq:lower-bound}\n\\end{aligned}\\]\nPutting the last two equations ([eq:developing-the-square]), ([eq:lower-bound]) together, we get that for any \\(W\\in L^{2}(X)\\):\n\\[\\begin{aligned}\n\\mathbb{E}[W^{2}]-2\\mathbb{E}[W(Y-Y^{\\star})] & \\geq0\n\\end{aligned}\\]\nIn particular, this also holds for \\(aW\\), in which case we get:\n\\[\\begin{aligned}\na^{2}\\mathbb{E}[W^{2}]-2a\\mathbb{E}[W(Y-Y^{\\star})] & \\geq0\\\\\n\\implies a\\left\\{ a\\mathbb{E}[W^{2}]-2\\mathbb{E}[W(Y-Y^{\\star})]\\right\\}  & \\geq0\n\\end{aligned}\\]\nIf \\(a&gt;0\\), then:\n\\[a\\mathbb{E}[W^{2}]-2\\mathbb{E}[W(Y-Y^{\\star})]\\geq0\\label{eq:case-when-a-gt-zero}\\]\nwhereas if \\(a&lt;0\\), then the sign changes upon dividing throughout by \\(a\\), and we have:\n\\[a\\mathbb{E}[W^{2}]-2\\mathbb{E}[W(Y-Y^{\\star})]\\leq0\\label{eq:case-when-a-lt-zero}\\]\nRearranging ([eq:case-when-a-gt-zero]) yields:\n\\[\\mathbb{E}[W(Y-Y^{\\star})]\\leq a\\mathbb{E}[W^{2}]/2\\label{eq:case-when-a-gt-zero-rearranged}\\]\nRearranging ([eq:case-when-a-lt-zero]) yields:\n\\[\\mathbb{E}[W(Y-Y^{\\star})]\\geq a\\mathbb{E}[W^{2}]/2\\label{eq:case-when-a-lt-zero-rearranged}\\]\nSince ([eq:case-when-a-gt-zero-rearranged]) holds for all \\(a&gt;0\\), the stronger inequality, \\(\\mathbb{E}[W(Y-Y^{\\star})]\\leq0\\) must hold. Since, ([eq:case-when-a-lt-zero-rearranged]) holds for all \\(a&lt;0\\), the stronger inequality \\(\\mathbb{E}[W(Y-Y^{\\star})]\\geq0\\) must hold. Consequently,\n\\[\\mathbb{E}[W(Y-Y^{\\star})]=0\\]\n(2) It is clear that \\(Y^{\\star}\\) is a function of \\(X\\) by construction, since it is in \\(L^{2}(X)\\). Moreover, for any \\(W\\in L^{2}(X)\\), we have from (1) that:\n\\[\\begin{aligned}\n\\mathbb{E}[W(Y-Y^{\\star})] & =0\n\\end{aligned}\\]\nwhich is the second defining property of conditional expectations.\n(3) Lastly, suppose there is another element \\(Y'\\) that is in \\(L^{2}(X)\\) that minimizes the distance to \\(Y\\). Then we would get:\n\\[\\begin{aligned}\n\\mathbb{E}[(Y-Y')^{2}] & =\\mathbb{E}[(Y-Y^{\\star}+Y^{\\star}-Y')^{2}]\\\\\n& =\\mathbb{E}[(Y-Y^{\\star})^{2}]+2\\mathbb{E}[(Y-Y^{\\star})(Y^{\\star}-Y')]+\\mathbb{E}[(Y^{\\star}-Y')^{2}]\\\\\n& =\\mathbb{E}[(Y-Y^{\\star})^{2}]+0+\\mathbb{E}[(Y^{\\star}-Y')^{2}]\\\\\n& \\quad\\left\\{ (Y^{\\star}-Y')\\in L^{2}(X)\\perp(Y-Y^{\\star})\\right\\}\n\\end{aligned}\\]\nwhere we used the fact, that \\(Y^{\\star}-Y'\\) is a vector in \\(L^{2}(X)\\) and the orthogonality of \\(Y-Y^{\\star}\\) with \\(L^{2}(X)\\) as in (1). But, this implies that:\n\\[\\begin{aligned}\n\\cancel{\\mathbb{E}[(Y-Y')^{2}]} & =\\cancel{\\mathbb{E}[(Y-Y^{\\star})^{2}]}+\\mathbb{E}[(Y^{\\star}-Y')^{2}]\\\\\n\\mathbb{E}[(Y^{\\star}-Y')^{2}] & =0\n\\end{aligned}\\]\nSo, \\(Y^{\\star}=Y'\\) almost surely. ◻\n\n\nConditional Expectation of continuous random variables. Let \\((X,Y)\\) be two random variables with joint density \\(f_{X,Y}(x,y)\\) on \\(\\mathbf{R}^{2}\\). Suppose for simplicity, that \\(\\int_{\\mathbf{R}}f(x,y)dx&gt;0\\) for every \\(y\\) belonging to \\(\\mathbf{R}\\). Show that the conditional expectation \\(\\mathbf{E}[Y|X]\\) equals \\(h(X)\\) where \\(h\\) is the function:\n\\[\\begin{aligned}\nh(x) & =\\frac{\\int_{\\mathbf{R}}yf_{X,Y}(x,y)dy}{\\int_{\\mathbf{R}}f_{X,Y}(x,y)dy}\\label{eq:conditional-expectation-of-continuous-random-variables}\n\\end{aligned}\\]\nIn particular, verify that \\(\\mathbf{E}[\\mathbf{E}[Y|X]]=\\mathbf{E}[Y]\\).\nHint: To prove this, verify that the above formula satisfies both the properties of conditional expectations; then invoke uniqueness to finish it off.\n\n\n(i) The density function \\(f_{X,Y}(x,y)\\) is a map \\(f:\\mathbf{R}^{2}\\to\\mathbf{R}\\). The integral \\(\\int_{y=-\\infty}^{y=+\\infty}yf_{X,Y}(x_{0},y)dy\\) is the area under the curve \\(yf(x,y)\\) at the point \\(x=x_{0}\\). Let’s call it \\(A(x_{0})\\). If instead, we have an arbitrary \\(x\\), \\(\\int_{y=-\\infty}^{y=+\\infty}yf_{X,Y}(x,y)dy\\) represents the area \\(A(x)\\) of an arbitrary slice of the surface \\(yf_{X,Y}\\) at the point \\(x\\). Hence, it is a function of \\(x\\). The denominator \\(\\int_{\\mathbf{R}}f_{X,Y}(x,y)dy=f_{X}(x)\\), the density of \\(X\\), which is a function of \\(x\\). Hence, the ratio is a function of \\(x\\).\n(ii) Let \\(g(X)\\) is a bounded random variable. We have:\n\\[\\begin{aligned}\n\\mathbf{E}[g(X)(Y-h(X))] & =\\mathbf{E}[Yg(X)]-\\mathbf{E}[g(X)h(X)]\\\\\n& =\\int\\int_{\\mathbf{R}^{2}}yg(x)f_{X,Y}(x,y)dydx-\\int_{\\mathbf{R}}g(x)h(x)f(x)dx\\\\\n& =\\int\\int_{\\mathbf{R}^{2}}yg(x)f_{X,Y}(x,y)dydx\\\\\n& -\\int_{\\mathbf{R}}\\begin{array}{c}\ng(x)\\cdot\\frac{\\int_{\\mathbf{R}}yf_{X,Y}(x,y)dy}{\\int_{\\mathbf{R}}f_{X,Y}(x,y)dy}\\end{array}\\cdot\\int_{\\mathbf{R}}f_{X,Y}(x,y)dy\\ dx\\\\\n& =\\int\\int_{\\mathbf{R}^{2}}yg(x)f_{X,Y}(x,y)dydx\\\\\n& -\\int_{\\mathbf{R}}\\begin{array}{c}\ng(x)\\cdot\\frac{\\int_{\\mathbf{R}}yf_{X,Y}(x,y)dy}{\\cancel{\\int_{\\mathbf{R}}f_{X,Y}(x,y)dy}}\\end{array}\\cdot\\cancel{\\int_{\\mathbf{R}}f_{X,Y}(x,y)dy}\\ dx\\\\\n& =\\int\\int_{\\mathbf{R}^{2}}yg(x)f_{X,Y}(x,y)dydx-\\int_{\\mathbf{R}^{2}}yg(x)f_{X,Y}(x,y)\\cdot dx\\cdot dy\\\\\n& =0\n\\end{aligned}\\]\n\nThus, \\(h(X)\\) is a valid candidate for the conditional expectation \\(\\mathbf{E}[Y|X]\\). Moreover, by the existence and uniqueness theorem ([th:existence-and-uniqueness-of-the-conditional-expectation]), \\(\\mathbf{E}[Y|X]\\) is unique and equals \\(h(X)\\).\n\n\n\nWe would like to generalize the conditional expectation to the case when we condition on the information of more than one random variable. Taking the \\(L^{2}\\) point of view, we should expect that the conditional expectation is the orthogonal projection of the given random variable on the subspace generated by square integrable functions of all the variables on which we condition.\nIt is now useful to study sigma-fields, an object that was defined in chapter 1.\n\n(Sigma-Field) A sigma-field or sigma-algebra \\(\\mathcal{F}\\) of a sample space \\(\\Omega\\) is a collection of all measurable events with the following properties:\n(1) \\(\\Omega\\) is in \\(\\mathcal{F}\\).\n(2) Closure under complement. If \\(A\\in\\mathcal{F}\\), then \\(A^{C}\\in\\mathcal{F}\\).\n(3) Closure under countable unions. If \\(A_{1},A_{2},\\ldots,\\in\\mathcal{F}\\), then \\(\\bigcup_{n=1}^{\\infty}A_{n}\\in\\mathcal{F}\\).\n\nSuch objects play a fundamental role in the rigorous study of probability and real analysis in general. We will focus on the intuition behind them. First let’s mention some examples of sigma-fields of a given sample space \\(\\Omega\\) to get acquainted with the concept.\n\n(Examples of sigma-fields).\n(1) The trivial sigma-field. Note that the collection of events \\(\\{\\emptyset,\\Omega\\}\\) is a sigma-field of \\(\\Omega\\). We generally denote it by \\(\\mathcal{F}_{0}\\).\n(2) The \\(\\sigma\\)-field generated by an event \\(A\\). Let \\(A\\) be an event that is not \\(\\emptyset\\) and not the entire \\(\\Omega\\). Then the smallest sigma-field containing \\(A\\) ought to be:\n\\[\\begin{aligned}\n\\mathcal{F}_{1} & =\\{\\emptyset,A,A^{C},\\Omega\\}\n\\end{aligned}\\]\nThis sigma-field is denoted by \\(\\sigma(A)\\).\n(3) The sigma-field generated by a random variable \\(X\\).\nWe now define the \\(\\mathcal{F}_{X}\\) as follows:\n\\[\\begin{aligned}\n\\mathcal{F}_{X} & =X^{-1}(\\mathcal{B}):=\\{\\omega:X(\\omega)\\in B\\},\\forall B\\in\\mathcal{B}(\\mathbf{R})\n\\end{aligned}\\]\nwhere \\(\\mathcal{B}\\) is the Borel \\(\\sigma\\)-algebra on \\(\\mathbf{R}\\). \\(\\mathcal{F}_{X}\\) is sometimes denoted as \\(\\sigma(X)\\). \\(\\mathcal{F}_{X}\\)is the set of all events pertaining to \\(X\\). It is a sigma-algebra because:\n(i) \\(\\Omega\\in\\sigma(X)\\) because \\(\\Omega=\\{\\omega:X(\\omega)\\in\\mathbf{R}\\}\\) and \\(\\mathbf{R}\\in\\mathcal{B}(\\mathbf{R})\\).\n(ii) Let any event \\(C\\in\\sigma(X)\\). We need to show that \\(\\Omega\\setminus C\\in\\sigma(X)\\).\nSince \\(C\\in\\sigma(X)\\), there exists \\(A\\in\\mathcal{B}(\\mathbf{R})\\), such that:\n\\[\\begin{aligned}\nC & =\\{\\omega\\in\\Omega:X(\\omega)\\in A\\}\n\\end{aligned}\\]\nNow, we calculate:\n\\[\\begin{aligned}\n\\Omega\\setminus C & =\\{\\omega\\in\\Omega:X(\\omega)\\in\\mathbf{R}\\setminus A\\}\n\\end{aligned}\\]\nSince \\(\\mathcal{B}(\\mathbf{R})\\) is a sigma-algebra, it is closed under complementation. Hence, if \\(A\\in\\mathcal{B}(\\mathbf{R})\\), it implies that \\(\\mathbf{R}\\setminus A\\in\\mathcal{B}(\\mathbf{R})\\). So, \\(\\Omega\\setminus C\\in\\sigma(X)\\).\n(iii) Consider a sequence of events \\(C_{1},C_{2},\\ldots,C_{n},\\ldots\\in\\sigma(X)\\). We need to prove that \\(\\bigcup_{n=1}^{\\infty}C_{n}\\in\\sigma(X)\\).\nSince \\(C_{n}\\in\\sigma(X)\\), there exists \\(A_{n}\\in\\mathcal{B}(\\mathbf{R})\\) such that:\n\\[\\begin{aligned}\nC_{n} & =\\{\\omega\\in\\Omega:X(\\omega)\\in A_{n}\\}\n\\end{aligned}\\]\nNow, we calculuate:\n\\[\\begin{aligned}\n\\bigcup_{n=1}C_{n} & =\\{\\omega\\in\\Omega:X(\\omega)\\in\\bigcup_{n=1}^{\\infty}A_{n}\\}\n\\end{aligned}\\]\nBut, \\(\\bigcup_{n=1}^{\\infty}A_{n}\\in\\mathcal{B}(\\mathbf{R})\\). So, \\(\\bigcup_{n=1}^{\\infty}C_{n}\\in\\sigma(X)\\).\nConsequently, \\(\\sigma(X)\\) is indeed a \\(\\sigma\\)-algebra.\nIntuitively, we think of \\(\\sigma(X)\\) as containing all information about \\(X\\).\n(4) The sigma-field generated by a stochastic process \\((X_{s},s\\leq t)\\). Let \\((X_{s},s\\geq0)\\) be a stochastic process. Consider the process restricted to \\([0,t]\\), \\((X_{s},s\\leq t)\\). We consider the smallest sigma-field containing all events pertaining to the random variables \\(X_{s},s\\leq t\\). We denote it by \\(\\sigma(X_{s},s\\leq t)\\) or \\(\\mathcal{F}_{t}\\).\n\nThe sigma-fields on \\(\\Omega\\) have a natural (partial) ordering: two sigma-fields \\(\\mathcal{G}\\) and \\(\\mathcal{F}\\) of \\(\\Omega\\) are such that \\(\\mathcal{G}\\subseteq\\mathcal{F}\\) if all the events in \\(\\mathcal{G}\\) are in \\(\\mathcal{F}\\). For example, the trivial \\(\\sigma\\)-field \\(\\mathcal{F}_{0}=\\{\\emptyset,\\Omega\\}\\) is contained in all the \\(\\sigma\\)-fields of \\(\\Omega\\). Clearly, the \\(\\sigma\\)-field \\(\\mathcal{F}_{t}=\\sigma(X_{s},s\\leq t)\\) is contained in \\(\\mathcal{F}_{t'}\\) if \\(t\\leq t'\\).\nIf all the events pertaining to a random variable \\(X\\) are in the \\(\\sigma\\)-field \\(\\mathcal{G}\\) (and thus we can compute \\(\\mu(X^{-1}((a,b]))\\)), we will say that \\(X\\) is \\(\\mathcal{G}\\)-measurable. This means that all information about \\(X\\) is contained in \\(\\mathcal{G}\\).\n\nLet \\(X\\) be a random variable defined on \\((\\Omega,\\mathcal{F},\\mathbb{P})\\). Consider another \\(\\mathcal{G}\\subseteq\\mathcal{F}\\). Then \\(X\\) is said to be \\(\\mathcal{G}\\)-measurable, if and only if:\n\\[\\begin{aligned}\n\\{\\omega:X(\\omega)\\in(a,b]\\} & \\in\\mathcal{G}\\text{ for all intervals }(a,b]\\in\\mathbf{R}\n\\end{aligned}\\]\n\n\n(\\(\\mathcal{F}_{0}\\)-measurable random variables). Consider the trivial sigma-field \\(\\mathcal{F}_{0}=\\{\\emptyset,\\Omega\\}\\). A random variable that is \\(\\mathcal{F}_{0}\\)-measurable must be a constant. Indeed, we have that for any interval \\((a,b]\\), \\(\\{\\omega:X(\\omega)\\in(a,b]\\}=\\emptyset\\) or \\(\\{\\omega:X(\\omega)\\in(a,b]\\}=\\Omega\\). This can only hold if \\(X\\) takes a single value.\n\n\n[]{#ex:sigma(X)-measurable-random-variables-example label=“ex:sigma(X)-measurable-random-variables-example”}(\\(\\sigma(X)\\)-measurable random variables). Let \\(X\\) be a given random variable on \\((\\Omega,\\mathcal{F},\\mathbb{P})\\). Roughly speaking, a \\(\\sigma(X)\\)-measurable random variable is determined by the information of \\(X\\) only. Here is the simplest example of a \\(\\sigma(X)\\)-measurable random variable. Take the indicator function \\(Y=\\mathbf{1}_{\\{X\\in B\\}}\\) for some event \\(\\{X\\in B\\}\\) pertaining to \\(X\\). Then the pre-images \\(\\{\\omega:Y(\\omega)\\in(a,b]\\}\\) are either \\(\\emptyset\\), \\(\\{X\\in B\\}\\), \\(\\{X\\in B^{C}\\}\\) or \\(\\Omega\\) depending on whether \\(0,1\\) are in \\((a,b]\\) or not. All of these events are in \\(\\sigma(X)\\). More generally, one can construct a \\(\\sigma(X)\\)-measurable random variable by taking linear combinations of indicator functions of events of the form \\(\\{X\\in B\\}\\).\nIt turns out that any (Borel measurable) function of \\(X\\) can be approximated by taking limits of such simple functions.\nConcretely, this translates to the following statement:\n\\[\\text{If }Y\\text{ is \\ensuremath{\\sigma}(X)-measurable, then Y=g(X) for some function g}\\]\nIn the same way, if \\(Z\\) is \\(\\sigma(X,Y)\\)-measurable, then \\(Z=h(X,Y)\\) for some \\(h\\). These facts can be proved rigorously using measure theory.\n\nWe are ready to give the general definition of conditional expectation.\n\n(Coin-Tossing Space). Suppose a coin is tossed infinitely many times. Let \\(\\Omega\\) be the set of all infinite sequences of \\(H\\)s and \\(T\\)s. A generic element of \\(\\Omega\\) is denoted by \\(\\omega_{1}\\omega_{2}\\ldots\\), where \\(\\omega_{n}\\) indicates the result of the \\(n\\)th coin toss. \\(\\Omega\\) is an uncountable sample space. The trivial sigma-field \\(\\mathcal{F}_{0}=\\{\\emptyset,\\Omega\\}\\). Assume that we don’t know anything about the outcome of the experiement. Even without any information, we know that the true \\(\\omega\\) belongs to \\(\\Omega\\) and does not belong to \\(\\emptyset\\). It is the information learned at time \\(0\\).\nNext, assume that we know the outcome of the first coin toss. Define \\(A_{H}=\\{\\omega:\\omega_{1}=H\\}\\)=set of all sequences beginning with \\(H\\) and \\(A_{T}=\\{\\omega:\\omega_{1}=T\\}\\)=set of all sequences beginning with \\(T\\). The four sets resolved by the first coin-toss form the the \\(\\sigma\\)-field \\(\\mathcal{F}_{1}=\\{\\emptyset,A_{H},A_{T},\\Omega\\}\\). We shall think of this \\(\\sigma\\)-field as containing the information learned by knowing the outcome of the first coin toss. More precisely, if instead of being told about the first coin toss, we are told for each set in \\(\\mathcal{F}_{1}\\), whether or not the true \\(\\omega\\) belongs to that set, then we know the outcome of the first coin toss and nothing more.\nIf we are told the first two coin tosses, we obtain a finer resolution. In particular, the four sets:\n\\[\\begin{aligned}\nA_{HH} & =\\{\\omega:\\omega_{1}=H,\\omega_{2}=H\\}\\\\\nA_{HT} & =\\{\\omega:\\omega_{1}=H,\\omega_{2}=T\\}\\\\\nA_{TH} & =\\{\\omega:\\omega_{1}=T,\\omega_{2}=H\\}\\\\\nA_{TT} & =\\{\\omega:\\omega_{1}=T,\\omega_{2}=T\\}\n\\end{aligned}\\]\nare resolved. Of course, the sets in \\(\\mathcal{F}_{1}\\) are resolved. Whenever a set is resolved, so is its complement, which means that \\(A_{HH}^{C}\\), \\(A_{HT}^{C}\\), \\(A_{TH}^{C}\\) and \\(A_{TT}^{C}\\) are resolved, so is their union which means that \\(A_{HH}\\cup A_{TH}\\), \\(A_{HH}\\cup A_{TT}\\), \\(A_{HT}\\cup A_{TH}\\) and \\(A_{HT}\\cup A_{TT}\\) are resolved. The other two pair-wise unions \\(A_{HH}\\cup A_{HT}=A_{H}\\) and \\(A_{TH}\\cup A_{TT}=A_{T}\\) are already resolved. Finally, the triple unions are also resolved, because \\(A_{HH}\\cup A_{HT}\\cup A_{TH}=A_{TT}^{C}\\) and so forth. Hence, the information pertaining to the second coin-toss is contained in:\n\\[\\begin{aligned}\n\\mathcal{F}_{2} & =\\{\\emptyset,\\Omega,\\\\\n& A_{H},A_{T},\\\\\n& A_{HH},A_{HT},A_{TH},A_{TT},\\\\\n& A_{HH}^{C},A_{HT}^{C},A_{TH}^{C},A_{TT}^{C},\\\\\n& A_{HH}\\cup A_{TH},A_{HH}\\cup A_{TT},A_{HT}\\cup A_{TH},A_{HT}\\cup A_{TT}\\}\n\\end{aligned}\\]\nHence, if the outcome of the first two coin tosses is known, all of the events in \\(\\mathcal{F}_{2}\\) are resolved - we exactly know, if each event has ocurred or not. \\(\\mathcal{F}_{2}\\) is the information learned by observing the first two coin tosses.\n\n\n(Exercises on sigma-fields).\n(a) Let \\(A\\), \\(B\\) be two proper subsets of \\(\\Omega\\) such that \\(A\\cap B\\neq\\emptyset\\) and \\(A\\cup B\\neq\\Omega\\). Write down \\(\\sigma(\\{A,B\\})\\), the smallest sigma-field containing \\(A\\) and \\(B\\) explicitly. What if \\(A\\cap B=\\emptyset\\)?\n(b) The Borel sigma-field is the smallest sigma-field containing intervals of the form \\((a,b]\\) in \\(\\mathbf{R}\\). Show that all singletons \\(\\{b\\}\\) are in \\(\\mathcal{B}(\\mathbf{R})\\) by writing \\(\\{b\\}\\) as a countable intersection of intervals \\((a,b]\\). Conclude that all open intervals \\((a,b)\\) and all closed intervals \\([a,b]\\) are in \\(\\mathcal{B}(\\mathbf{R})\\). Is the subset \\(\\mathbf{Q}\\) of rational numbers a Borel set?\n\n\nProof. Proof. (a) The sigma-field generated by the two events \\(A\\), \\(B\\) is given by:\n\\[\\begin{aligned}\n\\sigma(\\{A,B\\}) & =\\{\\emptyset,\\Omega,\\\\\n& A,B,A^{C},B^{C},\\\\\n& A\\cup B,A\\cap B,\\\\\n& A\\cup B^{C},A^{C}\\cup B,A^{C}\\cup B^{C},\\\\\n& A\\cap B^{C},A^{C}\\cap B,A^{C}\\cap B^{C},\\\\\n& (A\\cup B)\\cap(A\\cap B)^{C},\\\\\n& (A\\cup B)^{C}\\cup(A\\cap B)\\}\n\\end{aligned}\\]\n(b) Firstly, recall that:\n\\[\\begin{aligned}\n\\mathcal{B}(\\mathbf{R}) & =\\bigcap_{\\alpha\\in\\Lambda}\\mathcal{F}_{\\alpha}=\\bigcap\\sigma(\\{I:I\\text{ is an interval }(a,b]\\subseteq\\mathbf{R}\\})\n\\end{aligned}\\]\nWe can write:\n\\[\\begin{aligned}\n\\{b\\} & =\\bigcap_{n=1}^{\\infty}\\left(b-\\frac{1}{n},b\\right]\n\\end{aligned}\\]\nAs \\(\\mathcal{B}(\\mathbf{R})\\) is a sigma-field, it is closed under countable intersections. Hence, the singleton set \\(\\{b\\}\\)is a Borel set.\nSimilarly, we can write, any open interval as the countable union:\n\\[\\begin{aligned}\n(a,b) & =\\bigcup_{n=1}^{\\infty}\\left(a,b-\\frac{1}{n}\\right]\n\\end{aligned}\\]\nWe can convince ourselves, that equality indeed holds. Let \\(x\\in(a,b)\\) and choose \\(N\\), such that \\(\\frac{1}{N}&lt;|b-x|\\). Then, for all \\(n\\geq N\\), \\(x\\in(a,b-1/n]\\). Thus, it belongs to the RHS. In the reverse direction, let \\(x\\) belong to \\(\\bigcup_{n=1}^{\\infty}\\left(a,b-\\frac{1}{n}\\right]\\). So, \\(x\\) belongs to atleast one of these sets. Therefore, \\(x\\in(a,b)\\) is trivially true. So, the two sets are equal.\nHence, open intervals are Borel sets.\nSimilarly, we may write:\n\\[\\begin{aligned}\n[a,b] & =\\bigcap_{n=1}^{\\infty}\\left(a-\\frac{1}{n},b+\\frac{1}{n}\\right)\n\\end{aligned}\\]\nConsequently, closed intervals are Borel sets. Since \\(\\mathbf{Q}\\) is countable, it is a Borel set. Moreover, the empty set \\(\\emptyset\\) and \\(\\mathbf{R}\\) are Borel sets. So, \\(\\mathbf{R}\\backslash\\mathbf{Q}\\) is also a Borel set. ◻\n\n\nLet \\((X,Y)\\) be a Gaussian vector with mean \\(0\\) and covariance matrix\n\\[\\begin{aligned}\nC & =\\left[\\begin{array}{cc}\n1 & \\rho\\\\\n\\rho & 1\n\\end{array}\\right]\n\\end{aligned}\\]\nfor \\(\\rho\\in(-1,1)\\). We verify that the example ([ex:conditional-expectation-of-gaussian-vectors]) and exercise ([ex:=00005BArguin-4.1=00005D-Conditional-Expectation-of-continuous-random-variables]) yield the same conditional expectation.\n(a) Use equation ([eq:conditional-expectation-of-gaussian-vector]) to show that \\(\\mathbf{E}[Y|X]=\\rho X\\).\n(b) Write down the joint PDF \\(f(x,y)\\) of \\((X,Y)\\).\n(c) Show that \\(\\int_{\\mathbf{R}}yf(x,y)dy=\\rho x\\) and that \\(\\int_{\\mathbf{R}}f(x,y)dy=1\\).\n(d) Deduce that \\(\\mathbf{E}[Y|X]=\\rho X\\) using the equation ([eq:conditional-expectation-of-continuous-random-variables]).\n\n\nProof. Proof. (a) Since \\((X,Y)\\) have mean \\(0\\) and variance \\(1\\), it follows that:\n\\[\\begin{aligned}\n\\mathbf{E}[(X-EX)(Y-EY)] & =\\mathbf{E}(XY)\\\\\n\\sqrt{(\\mathbf{E}[X^{2}]-(\\mathbf{E}X)^{2})}\\cdot\\sqrt{(\\mathbf{E}[Y^{2}]-(\\mathbf{E}Y)^{2})} & =\\sqrt{(1-0)(1-0)}\\\\\n& =1\n\\end{aligned}\\]\nand therefore,\n\\[\\begin{aligned}\n\\rho & =\\frac{\\mathbf{E}(XY)}{1}=\\frac{\\mathbf{E}[XY]}{\\mathbf{E}[X^{2}]}\n\\end{aligned}\\]\nSince \\((X,Y)\\) is a Gaussian vector, using ([eq:conditional-expectation-of-gaussian-vector]), we have:\n\\[\\begin{aligned}\n\\mathbf{E}[Y|X] & =\\frac{\\mathbf{E}[XY]}{\\mathbf{E}[X^{2}]}X=\\rho X\n\\end{aligned}\\]\n(b) Consider the augmented matrix \\([C|I]\\). We have:\n\\[\\begin{aligned}\n[C|I] & =\\left[\\left.\\begin{array}{cc}\n1 & \\rho\\\\\n\\rho & 1\n\\end{array}\\right|\\begin{array}{cc}\n1 & 0\\\\\n0 & 1\n\\end{array}\\right]\n\\end{aligned}\\]\nPerforming \\(R_{2}=R_{2}-\\rho R_{1}\\), the above system is row-equivalent to:\n\\[\\left[\\left.\\begin{array}{cc}\n1 & \\rho\\\\\n0 & 1-\\rho^{2}\n\\end{array}\\right|\\begin{array}{cc}\n1 & 0\\\\\n-\\rho & 1\n\\end{array}\\right]\\]\nPerforming \\(R_{2}=\\frac{1}{1-\\rho^{2}}R_{2}\\), the above system is row-equivalent to:\n\\[\\left[\\begin{array}{cc}\n1 & \\rho\\\\\n0 & 1\n\\end{array}\\left|\\begin{array}{cc}\n1 & 0\\\\\n\\frac{-\\rho}{1-\\rho^{2}} & \\frac{1}{1-\\rho^{2}}\n\\end{array}\\right.\\right]\\]\nPerforming \\(R_{1}=R_{1}-\\rho R_{2}\\), we have:\n\\[\\left[\\begin{array}{cc}\n1 & 0\\\\\n0 & 1\n\\end{array}\\left|\\begin{array}{cc}\n\\frac{1}{1-\\rho^{2}} & -\\frac{\\rho}{1-\\rho^{2}}\\\\\n\\frac{-\\rho}{1-\\rho^{2}} & \\frac{1}{1-\\rho^{2}}\n\\end{array}\\right.\\right]\\]\nThus, \\[\\begin{aligned}\nC^{-1} & =\\frac{1}{1-\\rho^{2}}\\left[\\begin{array}{cc}\n1 & -\\rho\\\\\n-\\rho & 1\n\\end{array}\\right]\n\\end{aligned}\\]\nMoreover, \\(\\det C=1-\\rho^{2}.\\)\nTherefore, the joint density of \\((X,Y)\\) is given by:\n\\[\\begin{aligned}\nf(x,y) & =\\frac{1}{2\\pi\\sqrt{1-\\rho^{2}}}\\exp\\left[-\\frac{1}{2(1-\\rho^{2})}\\left[\\begin{array}{cc}\nx & y\\end{array}\\right]\\left[\\begin{array}{cc}\n1 & -\\rho\\\\\n-\\rho & 1\n\\end{array}\\right]\\left[\\begin{array}{c}\nx\\\\\ny\n\\end{array}\\right]\\right]\\\\\n& =\\frac{1}{2\\pi\\sqrt{1-\\rho^{2}}}\\exp\\left[-\\frac{1}{2(1-\\rho^{2})}\\left[\\begin{array}{cc}\nx-\\rho y & -\\rho x+y\\end{array}\\right]\\left[\\begin{array}{c}\nx\\\\\ny\n\\end{array}\\right]\\right]\\\\\n& \\frac{1}{2\\pi\\sqrt{1-\\rho^{2}}}\\exp\\left[-\\frac{1}{2(1-\\rho^{2})}(x^{2}-2\\rho xy+y^{2})\\right]\n\\end{aligned}\\]\n(c) Claim I. \\(\\int_{\\mathbf{R}}yf(x,y)dy=\\rho x\\).\nCompleting the square, we have:\n\\[\\begin{aligned}\n(x^{2}-2\\rho xy+y^{2}) & =(y-\\rho x)^{2}+x^{2}(1-\\rho^{2})\n\\end{aligned}\\]\nThus, we can write:\n\\[\\begin{aligned}\n\\int_{\\mathbf{R}}yf(x,y)dy & =\\frac{1}{2\\pi\\sqrt{1-\\rho^{2}}}e^{-\\frac{1}{2}x^{2}}\\int_{\\mathbf{R}}ye^{-\\frac{1}{2}\\frac{(y-\\rho x)^{2}}{(1-\\rho^{2})}}dy\n\\end{aligned}\\]\nLet’s substitute\n\\[\\begin{aligned}\nz & =\\frac{(y-\\rho x)}{\\sqrt{1-\\rho^{2}}}\\\\\ndz & =\\frac{dy}{\\sqrt{1-\\rho^{2}}}\n\\end{aligned}\\]\nTherefore,\n\\[\\begin{aligned}\n\\int_{\\mathbf{R}}ye^{-\\frac{1}{2}\\frac{(y-\\rho x)^{2}}{(1-\\rho^{2})}}dy & =\\sqrt{1-\\rho^{2}}\\int_{\\mathbf{R}}(\\rho x+\\sqrt{1-\\rho^{2}}z)e^{-\\frac{z^{2}}{2}}dz\\\\\n& =\\rho x\\cdot\\sqrt{1-\\rho^{2}}\\int_{\\mathbf{R}}e^{-\\frac{z^{2}}{2}}dz+(1-\\rho^{2})\\int_{\\mathbf{R}}ze^{-\\frac{z^{2}}{2}}dz\\\\\n& =\\rho x\\cdot\\sqrt{1-\\rho^{2}}\\cdot\\sqrt{2\\pi}+(1-\\rho^{2})\\cdot0\\\\\n& =\\rho x\\cdot\\sqrt{1-\\rho^{2}}\\cdot\\sqrt{2\\pi}\n\\end{aligned}\\]\nConsequently,\n\\[\\begin{aligned}\n\\int_{\\mathbf{R}}yf(x,y)dy & =\\frac{1}{2\\pi\\cancel{\\sqrt{1-\\rho^{2}}}}e^{-\\frac{1}{2}x^{2}}\\rho x\\cdot\\cancel{\\sqrt{1-\\rho^{2}}}\\cdot\\sqrt{2\\pi}\\\\\n& =\\rho x\\cdot\\frac{1}{\\sqrt{2\\pi}}e^{-\\frac{1}{2}x^{2}}\\\\\n& =\\rho x\\cdot f_{X}(x)\\\\\n\\frac{\\int_{\\mathbf{R}}yf(x,y)dy}{f_{X}(x)} & =\\frac{\\int_{\\mathbf{R}}yf(x,y)dy}{\\int_{\\mathbf{R}}f(x,y)}=\\rho x\n\\end{aligned}\\]\n(d) For a Gaussian vector \\((X,Y),\\) the conditional expectation \\(\\mathbf{E}[Y|X]=h(X)\\). Hence, \\(\\mathbf{E}[Y|X]=\\rho X\\). ◻\n\n\n(Conditional Expectation) Let \\(Y\\) be an integrable random variable on \\((\\Omega,\\mathcal{F},\\mathbb{P})\\) and let \\(\\mathcal{G}\\subseteq\\mathcal{F}\\) be a sigma-field of \\(\\Omega\\). The conditional expectation of \\(Y\\) given \\(\\mathcal{G}\\) is the random variable denoted by \\(\\mathbb{E}[Y|\\mathcal{G}]\\) such that the following hold:\n(a) \\(\\mathbb{E}[Y|\\mathcal{G}]\\) is \\(\\mathcal{G}\\)-measurable.\nIn other words, all events pertaining to the random variable \\(\\mathbb{E}[Y|\\mathcal{G}]\\) are in \\(\\mathcal{G}\\).\n(b) For any (bounded) random variable \\(W\\), that is \\(\\mathcal{G}\\)-measurable,\n\\[\\begin{aligned}\n\\mathbb{E}[WY] & =\\mathbb{E}[W\\mathbb{E}[Y|\\mathcal{G}]]\n\\end{aligned}\\]\nIn other words, \\(\\mathbf{E}[Y|\\mathcal{G}]\\) is a proxy for \\(Y\\) as far as the events in \\(\\mathcal{G}\\) are concerned.\nNote that, by taking \\(W=1\\) in the property (B), we recover:\n\\[\\begin{aligned}\n\\mathbf{E}[\\mathbf{E}[Y|\\mathcal{G}]] & =\\mathbf{E}[Y]\n\\end{aligned}\\]\n\n\nBeware of the notation! If \\(\\mathcal{G}=\\sigma(X)\\), then the conditional expectation \\(\\mathbf{E}[Y|\\sigma(X)]\\) is usually denoted by \\(\\mathbf{E}[Y|X]\\) for short. However, one should always keep in mind that conditioning on \\(X\\) is in fact projecting on the linear subspace generated by all variables constructed from \\(X\\) and not on the linear space generated by generated by \\(X\\) alone. In the same way, the conditional expectation \\(\\mathbf{E}[Z|\\sigma(X,Y)]\\) is often written \\(\\mathbf{E}[Z|X,Y]\\) for short.\nAs expected, if \\(Y\\) is in \\(L^{2}(\\Omega,\\mathcal{F},\\mathbb{P})\\), then \\(\\mathbf{E}[Y|\\mathcal{G}]\\) is given by the orthogonal projection of \\(Y\\) onto the subspace \\(L^{2}(\\Omega,\\mathcal{G},\\mathbb{P})\\), the subspace of square integrable random variables that are \\(\\mathcal{G}\\)-measurable. We write \\(Y^{\\star}\\) for the random variable in \\(L^{2}(\\Omega,\\mathcal{G},\\mathbb{P})\\) that is closest to \\(Y\\) that is:\n\\[\\begin{aligned}\n\\min_{Z\\in L^{2}(\\Omega,\\mathcal{G},\\mathbb{P})}\\mathbf{E}[(Y-Z)^{2}] & =\\mathbf{E}[(Y-Y^{\\star})^{2}]\\label{eq:conditional-expectation}\n\\end{aligned}\\]\n\n\n(Existence and Uniqueness of Conditional Expectations) Let \\(\\mathcal{G}\\subset\\mathcal{F}\\) be a sigma-field of \\(\\Omega\\). Let \\(Y\\) be a random variable in \\(L^{2}(\\Omega,\\mathcal{F},\\mathbb{P})\\). Then, the conditional expectation \\(\\mathbf{E}[Y|\\mathcal{G}]\\) is the random variable \\(Y^{\\star}\\) given in the equation ([eq:conditional-expectation]). Namely, it is the random variable in \\(L^{2}(\\Omega,\\mathcal{G},\\mathbb{P})\\) that is closest to \\(Y\\) in the \\(L^{2}\\)-distance. In particular we have the following:\n\n\nIt is the orthogonal projection of \\(Y\\) onto \\(L^{2}(\\Omega,\\mathcal{G},\\mathbb{P})\\), that is, \\(Y-Y^{\\star}\\) is orthogonal to the random variables in \\(L^{2}(\\Omega,\\mathcal{G},\\mathbb{P})\\).\nIt is unique.\n\nAgain, the result should be interpreted as follows: The conditional expectation \\(\\mathbf{E}[Y|\\mathcal{G}]\\) is the best approximation of \\(Y\\) given the information included in \\(\\mathcal{G}\\).\n\nThe conditional expectation in fact exists and is unique for any integrable random variable \\(Y\\)(i.e. \\(Y\\in L^{1}(\\Omega,\\mathcal{F},\\mathbb{P})\\) as the definition suggests. However, there is no orthogonal projection in \\(L^{1}\\), so the intuitive geometric picture is lost.\n\n\nFigure. An illustration of the conditional expectation \\(\\mathbb{E}[Y|\\mathcal{G}]\\) as an orthogonal projection of \\(Y\\) onto the subspace \\(L^2(\\Omega,\\mathcal{G},\\mathbb{P})\\).\n\n\n(Conditional Expectation for Gaussian Vectors. II.) Consider the Gaussian vector \\((X_{1},\\ldots,X_{n})\\). Without loss of generality, suppose it has mean \\(0\\) and is non-degenerate. What is the best approximation of \\(X_{n}\\) given the information \\(X_{1},\\ldots,X_{n-1}\\)? In other words, what is:\n\\[\\mathbf{E}[X_{n}|\\sigma(X_{1},\\ldots,X_{n-1})\\]\nWith example ([ex:sigma(X)-measurable-random-variables-example]) in mind, let’s write \\(\\mathbf{E}[X_{n}|X_{1}\\ldots X_{n-1}]\\) for short. From example ([ex:=00005BArguin-4.1=00005D-Conditional-Expectation-of-continuous-random-variables]), we know that if \\((X,Y)\\) is a Gaussian vector with mean \\(0\\), then \\(\\mathbf{E}[Y|X]\\) is a multiple of \\(X\\). Thus, we expect, that \\(\\mathbf{E}[X_{n}|X_{1}X_{2}\\ldots X_{n-1}]\\) is a linear combination of \\(X_{1},X_{2},\\ldots,X_{n-1}\\). That is, there exists \\(a_{1},\\ldots,a_{n-1}\\) such that:\n\\[\\begin{aligned}\n\\mathbf{E}[X_{n}|X_{1}X_{2}\\ldots X_{n-1}] & =a_{1}X_{1}+a_{2}X_{2}+\\ldots+a_{n-1}X_{n-1}\n\\end{aligned}\\] In particular, since the conditional expectation is a linear combination of the \\(X\\)’s, it is itself a Gaussian random variable. The best way to find the coefficient \\(a\\)’s is to go back to IID decomposition of Gaussian vectors.\nLet \\((Z_{1},Z_{2},\\ldots,Z_{n-1})\\) be IID standard Gaussians constructed from the linear combination of \\((X_{1},X_{2},\\ldots,X_{n-1})\\). Then, we have:\n\\[\\begin{aligned}\n\\mathbf{E}[X_{n}|X_{1}X_{2}\\ldots X_{n-1}] & =b_{1}Z_{1}+\\ldots+b_{n-1}Z_{n-1}\n\\end{aligned}\\]\nNow, recall, that we construct the random variables \\(Z_{1}\\), \\(Z_{2}\\), \\(\\ldots\\), \\(Z_{n}\\) using Gram-Schmidt orthogonalization:\n\\[\\begin{aligned}\n\\tilde{Z_{1}} & =X_{1}, & Z_{1} & =\\frac{\\tilde{Z_{1}}}{\\mathbf{E}(\\tilde{Z}_{1}^{2})}\\\\\n\\tilde{Z_{2}} & =X_{2}-\\mathbf{E}(X_{2}Z_{1})Z_{1} & Z_{2} & =\\frac{\\tilde{Z}_{2}}{\\mathbf{E}(\\tilde{Z}_{2}^{2})}\\\\\n\\tilde{Z_{3}} & =X_{3}-\\sum_{i=1}^{2}\\mathbf{E}(X_{3}Z_{i})Z_{i} & Z_{3} & =\\frac{\\tilde{Z}_{3}}{\\mathbf{E}(\\tilde{Z}_{3}^{2})}\\\\\n& \\vdots\n\\end{aligned}\\]\n\nThe simple case for \\(n=2\\) random variables.\nWe have already seen before:\n\\[\\begin{aligned}\n\\mathbf{E}[X_{1}(X_{2}-\\mathbf{E}(X_{2}Z_{1})Z_{1})] & =\\mathbf{E}[\\tilde{Z}_{1}(X_{2}-\\mathbf{E}(X_{2}Z_{1})Z_{1})]\\\\\n& =\\frac{\\mathbf{E}[\\tilde{Z}_{1}^{2}]}{\\mathbf{E}[\\tilde{Z}_{1}^{2}]}\\times\\mathbf{E}\\left[\\tilde{Z}_{1}(X_{2}-\\mathbf{E}(X_{2}Z_{1})Z_{1})\\right]\\\\\n& =\\mathbf{E}[\\tilde{Z}_{1}^{2}]\\times\\mathbf{E}\\left[\\frac{\\tilde{Z}_{1}}{\\mathbf{E}[\\tilde{Z}_{1}^{2}]}(X_{2}-\\mathbf{E}(X_{2}Z_{1})Z_{1})\\right]\\\\\n& =\\mathbf{E}[\\tilde{Z}_{1}^{2}]\\times\\mathbf{E}[Z_{1}(X_{2}-\\mathbf{E}(X_{2}Z_{1})Z_{1})]\\\\\n& =\\mathbf{E}[\\tilde{Z}_{1}^{2}]\\times\\left(\\mathbf{E}[Z_{1}X_{2}]-\\mathbf{E}(X_{2}Z_{1})\\mathbf{E}[Z_{1}^{2}]\\right)\\\\\n& =0\n\\end{aligned}\\]\nSo,\\(X_{2}-\\mathbf{E}(X_{2}Z_{1})Z_{1}\\) is orthogonal to \\(X_{1}\\).\nMoreover, \\(\\mathbf{E}(X_{2}Z_{1})Z_{1}\\) is a function of \\(X_{1}\\). Thus, both the properties of conditional expectation are satisfied. Since conditional expectations are unique, we must have, \\(\\mathbf{E}[X_{2}|X_{1}]=\\mathbf{E}(X_{2}Z_{1})Z_{1}\\).\nThe case for \\(n=3\\) random variables.\nWe have seen that:\n\\[\\begin{aligned}\n\\mathbf{E}[X_{1}(X_{3}-\\mathbf{E}(X_{3}Z_{1})Z_{1}-\\mathbf{E}(X_{3}Z_{2})Z_{2})] & =\\frac{\\mathbf{E}[\\tilde{Z}_{1}^{2}]}{\\mathbf{E}[\\tilde{Z}_{1}^{2}]}\\times\\mathbf{E}[\\tilde{Z}_{1}(X_{3}-\\mathbf{E}(X_{3}Z_{1})Z_{1}-\\mathbf{E}(X_{3}Z_{2})Z_{2})]\\\\\n& =\\mathbf{E}[\\tilde{Z}_{1}^{2}]\\times\\mathbf{E}\\left\\{ \\frac{\\tilde{Z}_{1}}{\\mathbf{E}[\\tilde{Z}_{1}^{2}]}(X_{3}-\\mathbf{E}(X_{3}Z_{1})Z_{1}-\\mathbf{E}(X_{3}Z_{2})Z_{2})\\right\\} \\\\\n& =\\mathbf{E}[\\tilde{Z}_{1}^{2}]\\times\\mathbf{E}\\left\\{ Z_{1}(X_{3}-\\mathbf{E}(X_{3}Z_{1})Z_{1}-\\mathbf{E}(X_{3}Z_{2})Z_{2})\\right\\} \\\\\n& =\\mathbf{E}[\\tilde{Z}_{1}^{2}]\\times\\mathbf{E}[X_{3}Z_{1}]-\\mathbf{E}[X_{3}Z_{1}]\\mathbf{E}[Z_{1}^{2}]-\\mathbf{E}[X_{3}Z_{2}]\\mathbf{E}[Z_{1}Z_{2}]\\\\\n& =0\n\\end{aligned}\\]\nIt is an easy exercise to show that it is orthogonal to \\(X_{2}\\).\nHence, \\(X_{3}-\\mathbf{E}(X_{3}Z_{1})Z_{1}-\\mathbf{E}(X_{3}Z_{2})Z_{2}\\) is orthogonal to \\(X_{1}\\) and \\(X_{2}\\). Moreover, \\(\\mathbf{E}(X_{3}Z_{1})Z_{1}+\\mathbf{E}(X_{3}Z_{2})Z_{2}\\) is a function of \\(X_{1}\\), \\(X_{2}\\). Thus, we must have:\n\\[\\begin{aligned}\n\\mathbf{E}[X_{3}|X_{1}X_{2}] & =\\mathbf{E}(X_{3}Z_{1})Z_{1}+\\mathbf{E}(X_{3}Z_{2})Z_{2}\n\\end{aligned}\\]\nIn general, \\(X_{n}-\\sum_{i=1}^{n-1}\\mathbf{E}(X_{n}Z_{i})Z_{i}\\) is orthogonal to \\(X_{1}\\), \\(X_{2}\\), \\(\\ldots\\), \\(X_{n-1}\\). Hence,\n\\[\\begin{aligned}\n\\mathbf{E}[X_{n}|X_{1}X_{2}\\ldots X_{n-1}] & =\\sum_{i=1}^{n-1}\\mathbf{E}(X_{n}Z_{i})Z_{i}\n\\end{aligned}\\]\n\n\n\nWe now list the properties of conditional expectation that follow from the two defining properties (A), (B) in the definition. They are extremely useful, when doing explicit computations on martingales. A good way to remember them is to understand how they relate to the interpretation of conditional expectation as an orthogonal projection onto a subspace or, equivalently, as the best approximation of the variable given the information available.\n\nLet \\(Y\\) be an integrable random variable on \\((\\Omega,\\mathcal{F},\\mathbb{P})\\). Let \\(\\mathcal{G}\\subseteq\\mathcal{F}\\) be another sigma-field of \\(\\Omega\\). Then, the conditional expectation \\(\\mathbf{E}[Y|\\mathcal{G}]\\) has the following properties:\n(1) If \\(Y\\) is \\(\\mathcal{G}\\)-measurable, then :\n\\[\\begin{aligned}\n\\mathbf{E}[Y|\\mathcal{G}] & =Y\n\\end{aligned}\\]\n(2) Taking out what is known. More generally, if \\(Y\\) is \\(\\mathcal{G-}\\)measurable and \\(X\\) is another integrable random variable (with \\(XY\\) also integrable), then :\n\\[\\begin{aligned}\n\\mathbf{E}[XY|\\mathcal{G}] & =Y\\mathbf{E}[X|\\mathcal{G}]\n\\end{aligned}\\]\nThis makes sense, since \\(Y\\) is determined by \\(\\mathcal{G}\\), so we can take out what is known; it can be treated as a constant for the conditional expectation.\n(3) Independence. If \\(Y\\) is independent of \\(\\mathcal{G}\\), that is, for any events \\(\\{Y\\in(a,b]\\}\\) and \\(A\\in\\mathcal{G}\\):\n\\[\\begin{aligned}\n\\mathbb{P}(\\{Y\\in I\\}\\cap A) & =\\mathbb{P}(\\{Y\\in I\\})\\cdot\\mathbb{P}(A)\n\\end{aligned}\\]\nthen\n\\[\\begin{aligned}\n\\mathbf{E}[Y|\\mathcal{G}] & =\\mathbf{E}[Y]\n\\end{aligned}\\]\nIn other words, if you have no information on \\(Y\\), your best guess for its value is simply plain expectation.\n(4) Linearity of conditional expectations. Let \\(X\\) be another integrable random variable on \\((\\Omega,\\mathcal{F},\\mathbb{P})\\). Then,\n\\[\\begin{aligned}\n\\mathbf{E}[aX+bY|\\mathcal{G}] & =a\\mathbf{E}[X|\\mathcal{G}]+b\\mathbf{E}[Y|\\mathcal{G}],\\quad\\text{for any }a,b\\in\\mathbf{R}\n\\end{aligned}\\]\nThe linearity justifies the cumbersom choice of notation \\(\\mathbf{E}[Y|\\mathcal{G}]\\) for the random variable.\n(5) Tower Property : If \\(\\mathcal{H}\\subseteq\\mathcal{G}\\) is another sigma-field of \\(\\Omega\\), then:\n\\[\\begin{aligned}\n\\mathbf{E}[Y|\\mathcal{H}] & =\\mathbf{E}[\\mathbf{E}[Y|\\mathcal{G}]|\\mathcal{H}]\n\\end{aligned}\\]\nThink in terms of two successive projections: first on a plane, then on a line in the plane.\n(6) Pythagoras Theorem. We have:\n\\[\\begin{aligned}\n\\mathbf{E}[Y^{2}] & =\\mathbf{E}\\left[\\left(\\mathbf{E}[Y|\\mathcal{G}]\\right)^{2}\\right]+\\mathbf{E}\\left[\\left(Y-\\mathbf{E}[Y|\\mathcal{G}]\\right)^{2}\\right]\n\\end{aligned}\\]\nIn particular:\n\\[\\begin{aligned}\n\\mathbf{E}\\left[\\left(\\mathbf{E}\\left[Y|\\mathcal{G}\\right]\\right)^{2}\\right] & \\leq\\mathbf{E}[Y^{2}]\n\\end{aligned}\\]\nIn words, the \\(L^{2}\\) norm of \\(\\mathbf{E}[X|\\mathcal{G}]\\) is smaller than the one of \\(X\\), which is clear if you think in terms of orthogonal projection.\n(7) Expectation of the conditional expectation.\n\\[\\begin{aligned}\n\\mathbf{E}\\left[\\mathbf{E}[Y|\\mathcal{G}]\\right] & =\\mathbf{E}[Y]\n\\end{aligned}\\]\n\nProof.\nThe uniqueness property of conditional expectations in theorem ([th:existence-and-uniqueness-of-conditional-expectations-II]) might appear to be an academic curiosity. On the contrary, it is very practical, since it ensures, that if we find a candidate for the conditional expectation that has the two properties in Definition ([def:conditional-expectation]), then it must be the conditional expectation. To see this, let’s prove property (1).\n\nIf \\(Y\\) is \\(\\mathcal{G}\\)-measurable, then \\(\\mathbf{E}[Y|\\mathcal{G}]=Y\\).\nIt suffices to show that \\(Y\\) has the two defining properties of conditional expectation.\n(1) We are given that, \\(Y\\) is \\(\\mathcal{G}\\)-measurable. So, property (A) is satisfied.\n(2) For any bounded random variable \\(W\\) that is \\(\\mathcal{G}\\)-measurable, we have:\n\\[\\begin{aligned}\n\\mathbf{E}[W(Y-Y)] & =\\mathbf{E}[0]=0\n\\end{aligned}\\]\nSo, property (B) is also a triviality.\n\n\n(Taking out what is known.) If \\(Y\\) is \\(\\mathcal{G}\\)-measurable and \\(X\\) is another integrable random variable, then:\n\\[\\begin{aligned}\n\\mathbf{E}[XY|\\mathcal{G}] & =Y\\mathbf{E}[X|\\mathcal{G}]\n\\end{aligned}\\]\nIn a similar vein, it suffices to show that, \\(Y\\mathbf{E}[X|\\mathcal{G}]\\) has the two defining properties of conditional expectation.\n(1) We are given that \\(Y\\) is \\(\\mathcal{G}\\)-measurable; from property (1), \\(\\mathbf{E}[X|\\mathcal{G}]\\) is \\(\\mathcal{G}\\)-measurable. It follows that, \\(Y\\mathbf{E}[X|\\mathcal{G}]\\) is \\(\\mathcal{G}\\)-measurable.\n(2) From theorem ([th:existence-and-uniqueness-of-conditional-expectations-II]), \\(X-\\mathbf{E}[X|\\mathcal{G}]\\) is orthogonal to the random variables \\(L^{2}(\\Omega,\\mathcal{G},\\mathbb{P})\\). So, if \\(W\\) is any bounded \\(\\mathcal{G}\\)-measurable random variable, it follows that:\n\\[\\begin{aligned}\n\\mathbf{E}[WY(X-\\mathbf{E}[X|\\mathcal{G}])] & =0\\\\\n\\implies\\mathbf{E}[W\\cdot XY] & =\\mathbf{E}[WY\\mathbf{E}[X|\\mathcal{G}]]\n\\end{aligned}\\]\nThis closes the proof.\n\n\n(Independence.) If \\(Y\\) is independent of \\(\\mathcal{G}\\), that is, for all events \\(\\{Y\\in(a,b]\\}\\) and \\(A\\in\\mathcal{G}\\),\n\\[\\begin{aligned}\n\\mathbf{\\mathbb{P}}\\{Y\\in(a,b]\\cap A\\} & =\\mathbb{P}\\{Y\\in(a,b]\\}\\cdot\\mathbb{P}(A)\n\\end{aligned}\\]\nthen\n\\[\\begin{aligned}\n\\mathbf{E}[Y|\\mathcal{G}] & =\\mathbf{E}[Y]\n\\end{aligned}\\]\nLet us show that \\(\\mathbf{E}[Y]\\) has the two defining properties of conditional expectations.\n(1) \\(\\mathbf{E}[Y]\\) is a constant and so it is \\(\\mathcal{F}_{0}\\) measurable. Hence, it is \\(\\mathcal{G}\\) measurable.\n(2) If \\(W\\) is another \\(\\mathcal{G}\\)-measurable random variable,\n\\[\\begin{aligned}\n\\mathbf{E}[WY] & =\\mathbf{E}[W]\\cdot\\mathbf{E}[Y]\n\\end{aligned}\\]\nsince \\(Y\\) is independent of \\(\\mathcal{G}\\) and therefore it is independent of \\(Y\\). Hence,\n\\[\\begin{aligned}\n\\mathbf{E}[W(Y-\\mathbf{E}[Y])] & =0\n\\end{aligned}\\]\nConsequently, \\(\\mathbf{E}[Y|\\mathcal{G}]=\\mathbf{E}[Y]\\).\n\n\n(Linearity of conditional expectations) Let \\(X\\) be another integrable random variable on \\((\\Omega,\\mathcal{F},\\mathbb{P})\\). Then,\n\\[\\begin{aligned}\n\\mathbf{E}[aX+bY|\\mathcal{G}] & =a\\mathbf{E}[X|\\mathcal{G}]+b\\mathbf{E}[Y|\\mathcal{G}],\\quad\\text{for any }a,b\\in\\mathbf{R}\n\\end{aligned}\\]\n\nSince \\(\\mathbf{E}[X|\\mathcal{G}]\\) and \\(\\mathbf{E}[Y|\\mathcal{G}]\\) are \\(\\mathcal{G}-\\)measurable, any linear combination of these two random variables is also \\(\\mathcal{G}\\)-measurable.\nAlso, if \\(W\\) is any bounded \\(\\mathcal{G}-\\)measurable random variable, we have:\n\\[\\begin{aligned}\n\\mathbf{E}[W(aX+bY-(a\\mathbf{E}[X|\\mathcal{G}]+b\\mathbf{E}[Y|\\mathcal{G}]))] & =a\\mathbf{E}[W(X-\\mathbf{E}[X|\\mathcal{G}])]\\\\\n& +b\\mathbf{E}[W(Y-\\mathbf{E}[Y|\\mathcal{G}])]\n\\end{aligned}\\]\nBy definition, \\(X-\\mathbf{E}(X|\\mathcal{G})\\) is orthogonal t o the subspace \\(L^{2}(\\Omega,\\mathcal{G},\\mathbb{P})\\) and hence to all \\(\\mathcal{G}\\)-measurable random-variables. Hence, the two expectations on the right hand side of the above expression are \\(0\\). Since, conditional expectations are unique, we have the desired result.\n\nIf \\(\\mathcal{H}\\subseteq\\mathcal{G}\\) is another sigma-field of \\(\\Omega\\), then\n\\[\\begin{aligned}\n\\mathbf{E}[Y|\\mathcal{H}] & =\\mathbf{E}[\\mathbf{E}[Y|\\mathcal{G}]|\\mathcal{H}]\n\\end{aligned}\\]\nDefine \\(U:=\\mathbf{E}[Y|\\mathcal{G}]\\). By definition, \\(\\mathbf{E}[U|\\mathcal{H}]\\) is \\(\\mathcal{H}\\)-measurable.\nLet \\(W\\) be any bounded \\(\\mathcal{H}\\)-measurable random variable. We have:\n\\[\\begin{aligned}\n\\mathbf{E}[W\\{\\mathbf{E}(Y|\\mathcal{G})-\\mathbf{E}(\\mathbf{E}(Y|\\mathcal{G})|\\mathcal{H})\\}] & =\\mathbf{E}[W(U-\\mathbf{E}(U|\\mathcal{H})]\n\\end{aligned}\\]\nBut, by definition \\(U-\\mathbf{E}(U|\\mathcal{H})\\) is always orthogonal to the subspace \\(L^{2}(\\Omega,\\mathcal{H},\\mathbb{P})\\) and hence, \\(\\mathbf{E}[W(U-\\mathbf{\\mathbf{E}}(U|\\mathcal{H})]=0\\). Since, conditional expectations are unique, we have the desired result.\n\n\nPythagoras’s theorem. We have:\n\\[\\begin{aligned}\n\\mathbf{E}[Y^{2}] & =\\mathbf{E}[(\\mathbf{E}[Y|\\mathcal{G}])^{2}]+\\mathbf{E}[(Y-\\mathbf{E}(Y|\\mathcal{G}))^{2}]\n\\end{aligned}\\]\nIn particular,\n\\[\\begin{aligned}\n\\mathbf{E}[(\\mathbf{E}[Y|\\mathcal{G}])^{2}] & \\leq\\mathbf{E}[Y^{2}]\n\\end{aligned}\\]\nConsider the orthogonal decomposition:\n\\[\\begin{aligned}\nY & =\\mathbf{E}[Y|\\mathcal{G}]+(Y-\\mathbf{E}[Y|\\mathcal{G}])\n\\end{aligned}\\]\nSquaring on both sides and taking expectations, we have:\n\\[\\begin{aligned}\n\\mathbf{E}[Y^{2}] & =\\mathbf{E}[(\\mathbf{E}(Y|\\mathcal{G}))^{2}]+\\mathbf{E}[(Y-\\mathbf{E}[Y|\\mathcal{G}])^{2}]+2\\mathbf{E}\\left[\\mathbf{E}[Y|\\mathcal{G}](Y-\\mathbf{E}[Y|\\mathcal{G}])\\right]\n\\end{aligned}\\]\nBy definition of conditional expectation, \\((Y-\\mathbf{E}[Y|\\mathcal{G}])\\) is orthogonal to the subspace \\(L^{2}(\\Omega,\\mathcal{G},\\mathbb{P})\\). By the properties of conditional expectation, \\(\\mathbf{E}[Y|\\mathcal{G}]\\) is \\(\\mathcal{G}-\\)measurable, so it belongs to \\(L^{2}(\\Omega,\\mathcal{G},\\mathbb{P})\\). Hence, the dot-product on the right-hand side is \\(0\\). Consequently, we have the desired result.\nMoreover, since \\((Y-\\mathbf{E}[Y|\\mathcal{G}])^{2}\\) is a non-negative random variable, \\(\\mathbf{E}[(Y-\\mathbf{E}[Y|\\mathcal{G}])^{2}]\\geq0\\). It follows that: \\(\\mathbf{E}[Y^{2}]\\geq\\mathbf{E}[(\\mathbf{E}(Y|\\mathcal{G}))^{2}]\\).\n\n\nOur claim is:\n\\[\\begin{aligned}\n\\mathbf{E}\\left[\\mathbf{E}[Y|\\mathcal{G}]\\right] & =\\mathbf{E}[Y]\n\\end{aligned}\\]\nWe know that, if \\(W\\) is any bounded \\(\\mathcal{G}\\)-measurable random variable:\n\\[\\begin{aligned}\n\\mathbf{E}\\left[WY\\right] & =\\mathbf{E}[W\\mathbf{E}[Y|\\mathcal{G}]]\n\\end{aligned}\\]\nTaking \\(W=1\\), we have:\n\\[\\begin{aligned}\n\\mathbf{E}\\left[Y\\right] & =\\mathbf{E}[\\mathbf{E}[Y|\\mathcal{G}]]\n\\end{aligned}\\]\n\n\n(Brownian Conditioning II). We continue the example ([ex:brownian-conditioning-I]). Let’s now compute the conditional expectations \\(\\mathbf{E}[e^{aB_{1}}|B_{1/2}]\\) and \\(\\mathbf{E}[e^{aB_{1/2}}|B_{1}]\\) for some parameter \\(a\\). We shall need the properties of conditional expectation in proposition ([prop:properties-of-conditional-expectation]). For the first one we use the fact that \\(B_{1/2}\\) is independent of \\(B_{1}-B_{1/2}\\) to get:\n\\[\\begin{aligned}\n\\mathbf{E}[e^{aB_{1}}|B_{1/2}] & =\\mathbf{E}[e^{a((B_{1}-B_{1/2})+B_{1/2})}|B_{1/2}]\\\\\n& =\\mathbf{E}[e^{a(B_{1}-B_{2})}\\cdot e^{aB_{1/2}}|B_{1/2}]\\\\\n& \\quad\\left\\{ \\text{Taking out what is known}\\right\\} \\\\\n& =e^{aB_{1/2}}\\mathbf{E}[e^{a(B_{1}-B_{1/2})}|B_{1/2}]\\\\\n& =e^{aB_{1/2}}\\cdot\\mathbf{E}[e^{a(B_{1}-B_{1/2})}]\\\\\n& \\quad\\{\\text{Independence}\\}\n\\end{aligned}\\]\nWe know that, \\(a(B_{1}-B_{1/2})\\) is a gaussian random variable with mean \\(0\\) and variance \\(a^{2}/2\\). We also know that, \\(\\mathbf{E}[e^{tZ}]=e^{t^{2}/2}\\). So, \\(\\mathbf{E}[e^{a(B_{1}-B_{1/2})}]=e^{a^{2}/4}\\). Consequently, \\(\\mathbf{E}[e^{aB_{1}}|B_{1/2}]=e^{aB_{1/2}+a^{2}/4}\\).\nThe result itself has the form of the MGF of a Gaussian with mean \\(B_{1/2}\\) and variance \\(1/2\\). (The MGF of \\(X=\\mu+\\sigma Z\\), \\(Z=N(0,1)\\) is \\(M_{X}(a)=\\exp\\left[\\mu+\\frac{1}{2}\\sigma^{2}a^{2}\\right]\\).) In fact, this shows that the conditional distribution of \\(B_{1}\\) given \\(B_{1/2}\\) is Gaussian of mean \\(B_{1/2}\\) and variance \\(1/2\\).\nFor the other expectation, note that \\(B_{1/2}-\\frac{1}{2}B_{1}\\) is independent of \\(B_{1}\\). We have: \\[\\begin{aligned}\n\\mathbf{E}\\left[\\left(B_{1/2}-\\frac{1}{2}B_{1}\\right)B_{1}\\right] & =\\mathbf{E}(B_{1/2}B_{1})-\\frac{1}{2}\\mathbf{E}[B_{1}^{2}]\\\\\n& =\\frac{1}{2}-\\frac{1}{2}\\cdot1\\\\\n& =0\n\\end{aligned}\\]\nTherefore, we have:\n\\[\\begin{aligned}\n\\mathbf{E}[e^{aB_{1/2}}|B_{1}] & =\\mathbf{E}[e^{a(B_{1/2}-\\frac{1}{2}B_{1})+\\frac{a}{2}B_{1}}|B_{1}]\\\\\n& =\\mathbf{E}[e^{a(B_{1/2}-\\frac{1}{2}B_{1})}\\cdot e^{\\frac{a}{2}B_{1}}|B_{1}]\\\\\n& =e^{\\frac{a}{2}B_{1}}\\mathbf{E}[e^{a(B_{1/2}-\\frac{1}{2}B_{1})}|B_{1}]\\\\\n& \\quad\\{\\text{Taking out what is known }\\}\\\\\n& =e^{\\frac{a}{2}B_{1}}\\mathbf{E}[e^{a(B_{1/2}-\\frac{1}{2}B_{1})}]\\\\\n& \\quad\\{\\text{Independence}\\}\n\\end{aligned}\\]\nNow, \\(a(B_{1/2}-\\frac{1}{2}B_{1})\\) is a random variable with mean \\(0\\) and variance \\(a^{2}(\\frac{1}{2}-\\frac{1}{4})=\\frac{a^{2}}{4}\\). Consequently, \\(\\mathbf{E}[e^{(a/2)Z}]=e^{\\frac{a^{2}}{8}}\\). Thus, \\(\\mathbf{E}[e^{aB_{1/2}}|B_{1}]=e^{\\frac{a}{2}B_{1}+\\frac{a^{2}}{8}}\\).\n\n\n(Brownian bridge is conditioned Brownian motion). We know that the Brownian bridge \\(M_{t}=B_{t}-tB_{1}\\), \\(t\\in[0,1]\\) is independent of \\(B_{1}\\). We use this to show that the conditional distribution of the Brownian motion given the value at the end-point \\(B_{1}\\) is the one of a Brownian bridge shifted by the straight line going from \\(0\\) to \\(B_{1}\\). To see this, we compute the conditional MGF of \\((B_{t_{1}},B_{t_{2}},\\ldots,B_{t_{n}})\\) given \\(B_{1}\\) for some arbitrary choices of \\(t_{1},t_{2},\\ldots,t_{n}\\) in \\([0,1]\\). We get the following by adding and subtracting \\(t_{j}B_{1}\\):\n\\[\\begin{aligned}\n\\mathbf{E}[e^{a_{1}B_{t_{1}}+\\ldots+a_{n}B_{t_{n}}}|B_{1}] & =\\mathbf{E}[e^{a_{1}(B_{t_{1}}-t_{1}B_{1})+\\ldots+a_{n}(B_{t_{n}}-t_{n}B_{1})}\\cdot e^{(a_{1}t_{1}B_{1}+\\ldots+a_{n}t_{n}B_{1})}|B_{1}]\\\\\n& =e^{(a_{1}t_{1}B_{1}+\\ldots+a_{n}t_{n}B_{1})}\\mathbf{E}[e^{a_{1}M_{t_{1}}+\\ldots+a_{n}M_{t_{n}}}|B_{1}]\\\\\n& \\quad\\{\\text{Taking out what is known}\\}\\\\\n& =e^{(a_{1}t_{1}B_{1}+\\ldots+a_{n}t_{n}B_{1})}\\mathbf{E}[e^{a_{1}M_{t_{1}}+\\ldots+a_{n}M_{t_{n}}}]\\\\\n& \\quad\\{\\text{Independence}\\}\n\\end{aligned}\\]\nThe right side is exactly the MGF of the process \\(M_{t}+tB_{1},t\\in[0,1]\\) (for a fixed value \\(B_{1})\\), where \\((M_{t},t\\in[0,1])\\) is a Brownian bridge. This proves the claim.\n\n\n(Conditional Jensen’s Inequality) If \\(c\\) is a convex function on \\(\\mathbf{R}\\) and \\(X\\) is a random variable on \\((\\Omega,\\mathcal{F},\\mathbb{P})\\), then:\n\\[\\begin{aligned}\n\\mathbf{E}[c(X)] & \\geq c(\\mathbf{E}[X])\n\\end{aligned}\\]\nMore generally, if \\(\\mathcal{G}\\subseteq\\mathcal{F}\\) is a sigma-field, then:\n\\[\\mathbf{E}[c(X)|\\mathcal{G}]\\geq c(\\mathbf{E}[X|\\mathcal{G}])\\]\n\n\nProof. Proof. We know that, if \\(c(x)\\) is a convex function, the tangent to the curve \\(c\\) at any point lies below the curve. The tangent to the cuve at this point, is a straight-line of the form:\n\\[\\begin{aligned}\nc(t)=y & =mt+c\n\\end{aligned}\\]\nwhere \\(m(t)=c'(t)\\). This holds for all \\(t\\in\\mathbf{R}\\). At an arbitrary point \\(x\\) we have:\n\\[\\begin{aligned}\nc(x)\\geq & y=mx+c\n\\end{aligned}\\]\nTherefore, we have:\n\\[\\begin{aligned}\nc(x)-c(t) & \\geq m(t)(x-t)\n\\end{aligned}\\]\nfor any \\(x\\) and any point of tangency \\(t\\).\n\\[\\begin{aligned}\nc(X)-c(Y) & \\geq m(Y)(X-Y)\n\\end{aligned}\\]\nSubstituting \\(Y=\\mathbf{E}[X|\\mathcal{G}]\\), we get:\n\\[\\begin{aligned}\nc(X)-c(\\mathbf{E}[X|\\mathcal{G}]) & \\geq m(\\mathbf{E}[X|\\mathcal{G}])(X-\\mathbf{E}[X|\\mathcal{G}])\n\\end{aligned}\\]\nTaking expectations on both sides, we get:\n\\[\\begin{aligned}\n\\mathbf{E}[(c(X)-c(\\mathbf{E}[X|\\mathcal{G}]))|\\mathcal{G}] & \\geq\\mathbf{E}[m(\\mathbf{E}[X|\\mathcal{G}])(X-\\mathbf{E}[X|\\mathcal{G}])|\\mathcal{G}]\n\\end{aligned}\\]\nThe left-hand side simplifies as:\n\\[\\begin{aligned}\n\\mathbf{E}[(c(X)-c(\\mathbf{E}[X|\\mathcal{G}]))|\\mathcal{G}] & =\\mathbf{E}[c(X)|\\mathcal{G}]-\\mathbf{E}[c(\\mathbf{E}[X|\\mathcal{G}]))|\\mathcal{G}]\\\\\n& \\quad\\{\\text{Linearity}\\}\\\\\n& =\\mathbf{E}[c(X)|\\mathcal{G}]-c(\\mathbf{E}[X|\\mathcal{G}])\\\\\n& \\quad\\{\\text{c(\\ensuremath{\\mathbf{E}}[X|\\ensuremath{\\mathcal{G}}])) is \\ensuremath{\\mathcal{G}}-measurable}\\}\n\\end{aligned}\\]\nOn the right hand side, we have:\n\\[\\begin{aligned}\n\\mathbf{E}[m(\\mathbf{E}[X|\\mathcal{G}])(X-\\mathbf{E}[X|\\mathcal{G}])|\\mathcal{G}] & =\\mathbf{E}[m(\\mathbf{E}[X|\\mathcal{G}])\\cdot X|\\mathcal{G}]-\\mathbf{E}[m(\\mathbf{E}[X|\\mathcal{G}])\\cdot\\mathbf{E}[X|\\mathcal{G}]|\\mathcal{G}]\\\\\n& =\\mathbf{E}[X|\\mathcal{G}]m(\\mathbf{E}[X|\\mathcal{G}])-m(\\mathbf{E}[X|\\mathcal{G}])\\cdot\\mathbf{E}[X|\\mathcal{G}]\\\\\n& =0\n\\end{aligned}\\]\nConsequently, it follows that \\(\\mathbf{E}[c(X)|\\mathcal{G}]\\geq c(\\mathbf{E}[X|\\mathcal{G}])\\). ◻\n\n\n(Embeddings of \\(L^{p}\\) spaces) Square-integrable random variables are in fact integrable. In other words, there is always the inclusion \\(L^{2}(\\Omega,\\mathcal{F},\\mathbb{P})\\subseteq L^{1}(\\Omega,\\mathcal{F},\\mathbb{P})\\). In particular, square integrable random variables always have a well-defined variance. This embedding is a simple consequence of Jensen’s inequality since:\n\\[\\begin{aligned}\n|\\mathbf{E}[X]|^{2} & \\leq\\mathbf{E}[|X|^{2}]\n\\end{aligned}\\]\nas \\(f(x)=|x|^{2}\\) is convex. By taking the square root on both sides, we get:\n\\[\\begin{aligned}\n\\left\\Vert X\\right\\Vert _{1} & \\leq\\left\\Vert X\\right\\Vert _{2}\n\\end{aligned}\\]\nMore generally, for any \\(1&lt;p&lt;\\infty\\), we can define \\(L^{p}(\\Omega,\\mathcal{F},\\mathbb{P})\\) to be the linear space of random variables such that \\(\\mathbf{E}[|X|^{p}]&lt;\\infty\\). Then for \\(p&lt;q\\), since \\(x^{q/p}\\) is convex, we get by Jensen’s inequality :\n\\[\\begin{aligned}\n\\mathbf{E}[|X|^{q}] & =\\mathbf{E}[(|X|^{p})^{\\frac{q}{p}}]\\geq\\left(\\mathbf{E}[|X|^{p}]\\right)^{\\frac{q}{p}}\n\\end{aligned}\\]\nTaking the \\(q\\)-th root on both sides:\n\\[\\begin{aligned}\n\\mathbf{E}[|X|^{p}]^{1/p} & \\leq\\mathbf{E}[|X|^{q}]^{1/q}\n\\end{aligned}\\]\nSo, if \\(X\\in L^{q}\\), then it must also be in \\(L^{p}\\). Concretely, this means that any random variable with a finite \\(q\\)-moment will also have a finite \\(p\\)-moment, for \\(q&gt;p\\).\n\n\n\n\n\nWe now have all the tools to define martingales.\n\n(Filtration). A filtration \\((\\mathcal{F}_{t}:t\\geq0)\\) of \\(\\Omega\\) is an increasing sequence of \\(\\sigma\\)-fields of \\(\\Omega\\). That is,\n\\[\\begin{aligned}\n\\mathcal{F}_{s} & \\subseteq\\mathcal{F}_{t},\\quad\\forall s\\leq t\n\\end{aligned}\\]\nWe will usually take \\(\\mathcal{F}_{0}=\\{\\emptyset,\\Omega\\}\\). The canonical example of a filtration is the natural filtration of a given process \\((M_{s}:s\\geq0)\\). This is the filtration given by \\(\\mathcal{F}_{t}=\\sigma(M_{s},s\\leq t)\\). The inclusions of the \\(\\sigma\\)-fields are then clear. For a given Brownian motion \\((B_{t},t\\geq0)\\), the filtration \\(\\mathcal{F}_{t}=\\sigma(B_{s},s\\leq t)\\) is sometimes called the Brownian filtration. We think of the filtration as the flow of information of the process.\n\n\nA stochastic process \\((X_{t}:t\\geq0)\\) is said to be adapted to \\((\\mathcal{F}_{t}:t\\geq0)\\), if for each \\(t\\), the random variable \\(X_{t}\\) is \\(\\mathcal{F}_{t}-\\)measurable.\n\n\n(Martingale). A process \\((M_{t}:t\\geq0)\\) is a martingale for the filtration \\((\\mathcal{F}_{t}:t\\geq0)\\) if the following hold:\n(1) The process is adapted, that is \\(M_{t}\\) is \\(\\mathcal{F}_{t}-\\)measurable for all \\(t\\geq0\\).\n(2) \\(\\mathbf{E}[|M_{t}|]&lt;\\infty\\) for all \\(t\\geq0\\). (This ensures that the conditional expectation is well defined.)\n(3) Martingale property:\n\\[\\begin{aligned}\n\\mathbf{E}[M_{t}|\\mathcal{F}_{s}] & =M_{s}\\quad\\forall s\\leq t\n\\end{aligned}\\]\nRoughly, speaking this means that the best approximation of a process at a future time \\(t\\) is its value at the present.\n\nIn particular, the martingale property implies that:\n\\[\\begin{aligned}\n\\mathbf{E}[M_{t}|\\mathcal{F}_{0}] & =M_{0}\\nonumber \\\\\n\\mathbf{E}[\\mathbf{E}[M_{t}|\\mathcal{F}_{0}]] & =\\mathbf{E}[M_{0}]\\nonumber \\\\\n\\mathbf{E}[M_{t}] & =\\mathbf{E}[M_{0}]\\label{eq:expected-value-of-martingale-at-any-time-is-constant}\\\\\n& \\quad\\{\\text{Tower Property}\\}\\nonumber\n\\end{aligned}\\]\nUsually, we take \\(\\mathcal{F}_{0}\\) to be the trivial sigma-field \\(\\{\\emptyset,\\Omega\\}\\). A random variable that is \\(\\mathcal{F}_{0}\\)-measurable must be a constant, so \\(M_{0}\\) is a constant. In this case, \\(\\mathbf{E}[M_{t}]=M_{0}\\) for all \\(t\\). If properties (1) and (2) are satisfied, but the best approximation is larger, \\(\\mathbf{E}[M_{t}|\\mathcal{F}_{s}]\\geq M_{s}\\), the process is called a submartingale. If it is smaller on average, \\(\\mathbf{E}[M_{t}|\\mathcal{F}_{s}]\\leq\\mathbf{E}[M_{s}]\\), we say it is a supermartingale.\nWe will be mostly interested in martingales that are continuous and square-integrable. Continuous martingales are martingales whose paths \\(t\\mapsto M_{t}(\\omega)\\) are continuous almost surely. Square-integrable martingales are such that \\(\\mathbf{E}[|M_{t}|^{2}]&lt;\\infty\\) for all \\(t\\)’s. This condition is stronger than \\(\\mathbf{E}[|M_{t}|]&lt;\\infty\\) due to Jensen’s inequality.\n\n(Martingales in Discrete-time). Martingales can be defined the same way if the index set of the process is discrete. For example, the filtration \\((\\mathcal{F}_{n}:n\\in\\mathbf{N})\\) is a countable set and the martingale property is then replaced by \\(\\mathbf{E}[M_{n+1}|\\mathcal{F}_{n}]=M_{n}\\) as expected. The tower-property then yields the martingale property \\(\\mathbf{E}[M_{n+k}|\\mathcal{F}_{n}]=M_{n}\\) for \\(k\\geq1\\).\n\n\n(Continuous Filtrations). Filtrations with continuous time can be tricky to handle rigorously. For example, one has to make sense of what it means for \\(\\mathcal{F}_{s}\\) as \\(s\\) approaches \\(t\\) from the left. Is it equal to \\(\\mathcal{F}_{t}\\)? Or is there actually less information in \\(\\lim_{s\\to t^{-}}\\mathcal{F}_{s}\\) than in \\(\\mathcal{F}_{t}\\)? This is a bit of headache when dealing with processes with jumps, like the Poisson process. However, if the paths are continuous, the technical problems are not as heavy.\nLet’s look at some of the important examples of martingales constructed from Brownian Motion.\n\n\n(Examples of Brownian Martingales)\n(i) Standard Brownian Motion. Let \\((B_{t}:t\\geq0)\\) be a standard Brownian motion and let \\((\\mathcal{F}_{t}:t\\geq0)\\) be a Brownian filtration. Then \\((B_{t}:t\\geq0)\\) is a square integrable martingale for the filtration \\((\\mathcal{F}_{t}:t\\geq0)\\). Property (1) is obvious, because all the sets in \\(\\mathcal{F}_{t}\\) are resolved, upon observing the outcome of \\(B_{t}\\). Similarly, \\(\\mathbf{E}[|B_{t}|]=0\\). As for the martingale property, note that, by the properties of conditional expectation in proposition ([prop:properties-of-conditional-expectation]), we have:\n\\[\\begin{aligned}\n\\mathbf{E}[B_{t}|\\mathcal{F}_{s}] & =\\mathbf{E}[B_{t}|B_{s}]\\\\\n& =\\mathbf{E}[B_{t}-B_{s}+B_{s}|B_{s}]\\\\\n& =\\mathbf{E}[B_{t}-B_{s}|B_{s}]+\\mathbf{E}[B_{s}|B_{s}]\\\\\n& \\quad\\{\\text{Linearity}\\}\\\\\n& =\\mathbf{E}[B_{t}-B_{s}]+B_{s}\\\\\n& \\quad\\{\\text{Independence}\\}\\\\\n& =B_{s}\n\\end{aligned}\\]\n(ii) Geometric Brownian Motion. Let \\((B_{t},t\\ge0)\\) be a standard brownian motion, and \\(\\mathcal{F}_{t}=\\sigma(B_{s},s\\leq t)\\). A geometric brownian motion is a process \\((S_{t},t\\geq0)\\) defined by:\n\\[\\begin{aligned}\nS_{t} & =S_{0}\\exp\\left(\\sigma B_{t}+\\mu t\\right)\n\\end{aligned}\\]\nfor some parameter \\(\\sigma&gt;0\\) and \\(\\mu\\in\\mathbf{R}\\). This is simply the exponential of the Brownian motion with drift. This is not a martingale for most choices of \\(\\mu\\)! In fact, one must take\n\\[\\begin{aligned}\n\\mu & =-\\frac{1}{2}\\sigma^{2}\n\\end{aligned}\\] for the process to be a martingale for the Brownian filtration. Let’s verify this. Property (1) is obvious since \\(S_{t}\\) is a function of \\(B_{t}\\) for each \\(t\\). So, it is \\(\\mathcal{F}_{t}\\) measurable. Moreover, property (2) is clear: \\(\\mathbf{E}[\\exp(\\sigma B_{t}+\\mu t)]=\\mathbf{E}[\\exp(\\sigma\\sqrt{t}Z+\\mu t)]=\\exp(\\mu t+\\frac{1}{2}\\sigma^{2}t)\\). So, its a finite quantity. As for the martingale property, note that by the properties of conditional expectation, and the MGF of Gaussians, we have for \\(s\\leq t\\):\n\\[\\begin{aligned}\n\\mathbf{E}[S_{t}|\\mathcal{F}_{s}] & =\\mathbf{E}\\left[S_{0}\\exp\\left(\\sigma B_{t}-\\frac{1}{2}\\sigma^{2}t\\right)|\\mathcal{F}_{s}\\right]\\\\\n& =S_{0}\\exp(-\\frac{1}{2}\\sigma^{2}t)\\mathbf{E}[\\exp(\\sigma(B_{t}-B_{s}+B_{s}))|\\mathcal{F}_{s}]\\\\\n& =S_{0}\\exp(-\\frac{1}{2}\\sigma^{2}t)\\exp(\\sigma B_{s})\\mathbf{E}[\\exp(\\sigma(B_{t}-B_{s}))|\\mathcal{F}_{s}]\\\\\n& \\quad\\{\\text{Taking out what is known}\\}\\\\\n& =S_{0}\\exp\\left(\\sigma B_{s}-\\frac{1}{2}\\sigma^{2}t\\right)\\mathbf{E}\\left[\\exp\\left(\\sigma(B_{t}-B_{s})\\right)\\right]\\\\\n& \\quad\\{\\text{Independence}\\}\\\\\n& =S_{0}\\exp\\left(\\sigma B_{s}-\\frac{1}{2}\\sigma^{2}t+\\frac{1}{2}\\sigma^{2}(t-s)\\right)\\\\\n& =S_{0}\\exp(\\sigma B_{s}-\\frac{1}{2}\\sigma^{2}s)\\\\\n& =S_{s}\n\\end{aligned}\\]\nWe will sometimes abuse terminology and refer to the martingale case of geometric brownian motion simply as geometric Brownian Motion when the context is clear.\n(iii) The square of the Brownian motion, compensated. It is easy to check \\((B_{t}^{2},t\\geq0)\\) is a submartingale by direct computation using increments or by Jensen’s inequality: \\(\\mathbf{E}[B_{t}^{2}|\\mathcal{F}_{s}]&gt;(\\mathbf{E}[B_{t}|\\mathcal{F}_{s}])^{2}=B_{s}^{2}\\), \\(s&lt;t\\). It is nevertheless possible to compensate to get a martingale:\n\\[\\begin{aligned}\nM_{t} & =B_{t}^{2}-t\n\\end{aligned}\\]\nIt is an easy exercise to verify that \\((M_{t}:t\\geq0)\\) is a martingale for the Brownian filtration \\((\\mathcal{F}_{t}:t\\geq0)\\).\n\\[\\begin{aligned}\n\\mathbf{E}[M_{t}|\\mathcal{F}_{s}] & =\\mathbf{E}[B_{t}^{2}-t|\\mathcal{F}_{s}]\\\\\n& =\\mathbf{E}[B_{t}^{2}|\\mathcal{F}_{s}]-t\\\\\n& =\\mathbf{E}[(B_{t}-B_{s}+B_{s})^{2}|\\mathcal{F}_{s}]-t\\\\\n& =\\mathbf{E}[(B_{t}-B_{s})^{2}|\\mathcal{F}_{s}]+2\\mathbf{E}[(B_{t}-B_{s})B_{s}|\\mathcal{F}_{s}]+\\mathbf{E}[B_{s}^{2}|\\mathcal{F}_{s}]-t\\\\\n& =\\mathbf{E}[(B_{t}-B_{s})^{2}]+2B_{s}\\mathbf{E}[(B_{t}-B_{s})|\\mathcal{F}_{s}]+B_{s}^{2}-t\\\\\n& =\\mathbf{E}[(B_{t}-B_{s})^{2}]+2B_{s}\\mathbf{E}[(B_{t}-B_{s})]+B_{s}^{2}-t\\\\\n& \\left\\{ \\begin{array}{c}\n\\text{\\ensuremath{(B_{t}-B_{s})} is independent of \\ensuremath{\\mathcal{F}_{s}}}\\\\\n\\text{Also, \\ensuremath{B_{s}} is known at time \\ensuremath{s}}\n\\end{array}\\right\\} \\\\\n& =(t-s)+2B_{s}\\cdot0+B_{s}^{2}-t\\\\\n& =B_{s}^{2}-s\\\\\n& =M_{s}\n\\end{aligned}\\]\n\n\n(Other important martingales).\n(1) Symmetric random walks. This is an example of a martingale in discrete time. Take \\((X_{i}:i\\in\\mathbf{N})\\) to be IID random variables with \\(\\mathbf{E}[X_{i}]=0\\) and \\(\\mathbf{E}[|X_{i}|]&lt;\\infty\\). Take \\(\\mathcal{F}_{n}=\\sigma(X_{i},i\\leq n)\\) and\n\\[\\begin{aligned}\nS_{n} & =X_{1}+X_{2}+\\ldots+X_{n},\\quad S_{0}=0\n\\end{aligned}\\]\nFirstly, the information learned by observing the outcomes of \\(X_{1}\\),\\(\\ldots\\),\\(X_{n}\\) is enough to completely determine \\(S_{n}\\). Hence, \\(S_{n}\\) is \\(\\mathcal{F}_{n}-\\)measurable.\nNext, \\[\\begin{aligned}\n|S_{n}| & =\\left|\\sum_{i=1}^{n}X_{i}\\right|\\\\\n& \\leq\\sum_{i=1}^{n}|X_{i}|\n\\end{aligned}\\]\nConsequently, by the montonocity of expectations, we have:\n\\[\\begin{aligned}\n\\mathbf{E}[|S_{n}|] & \\leq\\sum_{i=1}^{n}\\mathbf{E}[|X_{i}|]&lt;\\infty\n\\end{aligned}\\]\nThe martingale property is also satisfied. We have:\n\\[\\begin{aligned}\n\\mathbf{E}[S_{n+1}|\\mathcal{F}_{n}] & =\\mathbf{E}[S_{n}+X_{n+1}|\\mathcal{F}_{n}]\\\\\n& =\\mathbf{E}[S_{n}|\\mathcal{F}_{n}]+\\mathbf{E}[X_{n+1}|\\mathcal{F}_{n}]\\\\\n& =S_{n}+\\mathbf{E}[X_{n+1}]\\\\\n& \\left\\{ \\begin{array}{c}\n\\text{\\ensuremath{S_{n}} is \\ensuremath{\\mathcal{F}_{n}}-measurable}\\\\\n\\text{\\ensuremath{X_{n+1}} is independent of \\ensuremath{\\mathcal{F}_{n}}}\n\\end{array}\\right\\} \\\\\n& =S_{n}+0\\\\\n& =S_{n}\n\\end{aligned}\\]\n(2) Compensated Poisson process. Let \\((N_{t}:t\\geq0)\\) be a Poisson process with rate \\(\\lambda\\) and \\(\\mathcal{F}_{t}=\\sigma(N_{s},s\\leq t)\\). Then, \\(N_{t}\\) is a submartingale for its natural filtration. Again, properties (1) and (2) are easily checked. \\(N_{t}\\) is \\(\\mathcal{F}_{t}\\) measurable. Moreover, \\(\\mathbf{E}[|N_{t}|]=\\mathbf{E}[N_{t}]=\\frac{1}{\\lambda t}&lt;\\infty\\). The submartingale property follows by the independence of increments : for \\(s\\leq t\\),\n\\[\\begin{aligned}\n\\mathbf{E}[N_{t}|\\mathcal{F}_{s}] & =\\mathbf{E}[N_{t}-N_{s}+N_{s}|\\mathcal{F}_{s}]\\\\\n& =\\mathbf{E}[N_{t}-N_{s}|\\mathcal{F}_{s}]+\\mathbf{E}[N_{s}|\\mathcal{F}_{s}]\\\\\n& =\\mathbf{E}[N_{t}-N_{s}]+N_{s}\\\\\n& =\\lambda(t-s)+N_{s}\\\\\n& \\left\\{ \\because\\mathbf{E}[N_{t}]=\\lambda t\\right\\}\n\\end{aligned}\\]\nMore importantly, we get a martingale by slightly modifying the process. Indeed, if we subtract \\(\\lambda t\\), we have that the process :\n\\[\\begin{aligned}\nM_{t} & =N_{t}-\\lambda t\n\\end{aligned}\\]\nis a martingale. We have:\n\\[\\begin{aligned}\n\\mathbf{E}[M_{t}|\\mathcal{F}_{s}] & =\\mathbf{E}[N_{t}-\\lambda t|\\mathcal{F}_{s}]\\\\\n& =\\lambda t-\\lambda s+N_{s}-\\lambda t\\\\\n& =N_{s}-\\lambda s\\\\\n& =M_{s}\n\\end{aligned}\\]\nThis is called the compensated Poisson process. Let us simulate \\(10\\) paths of the compensated poisson process on \\([0,10]\\).\n\nimport numpy as np\nimport matplotlib.pyplot as plt\n\n# Generates a sample path of a compensated poisson process \n# with rate : `lambda_` per unit time\n# on the interval [0,T], and subintervals of size `stepSize`.\n\ndef generateCompensatedPoissonPath(lambda_,T,stepSize):\n    N = int(T/stepSize)   \n\n    poissonParam = lambda_ * stepSize        \n\n    x = np.random.poisson(lam=poissonParam,size=N)  \n    x = np.concatenate([[0.0], x])\n    N_t = np.cumsum(x)  \n    t = np.linspace(start=0.0,stop=10.0,num=1001)\n\n    M_t = np.subtract(N_t,lambda_ * t)  \n    return M_t\n\n\nt = np.linspace(0,10,1001)\nplt.grid(True)\n\nplt.xlabel(r'Time $t$')\nplt.ylabel(r'Compensated poisson process $M(t)$')\nplt.grid(True)\nplt.title(r'$10$ paths of the compensated Poisson process on $[0,10]$')\n\nfor i in range(10):\n    # Generate a poisson path with rate 1 /sec = 0.01 /millisec\n    n_t = generateCompensatedPoissonPath(lambda_=1.0, T=10, stepSize=0.01)\n    plt.plot(t, n_t)\n\n\nplt.show()\nplt.close()\nWe saw in the two examples, that, even though a process is not itself a martingale, we can sometimes compensate to obtain a martingale! Ito Calculus will greatly extend this perspective. We will have systematic rules that show when a function of Brownian motion is a martingale and if not, how to modify it to get one.\nFor now, we observe that a convex function of a martingale is always a submartingale by Jensen’s inequality.\n\nIf \\(c\\) is a convex function on \\(\\mathbf{R}\\) and \\((M_{t}:t\\geq0)\\) is a martingale for \\((\\mathcal{F}_{t}:t\\geq0)\\), then the process \\((c(M_{t}):t\\geq0)\\) is a submartingale for the same filtration, granted that \\(\\mathbf{E}[|c(M_{t})|]&lt;\\infty\\).\n\n\nProof. Proof. The fact that \\(c(M_{t})\\) is adapted to the filtration is clear since it is an explicit function of \\(M_{t}\\). The integrability is by assumption. The submartingale property is checked as follows:\n\\[\\begin{aligned}\n\\mathbf{E}[c(M_{t})|\\mathcal{F}_{s}] & \\geq c(\\mathbf{E}[M_{t}|\\mathcal{F}_{s}])=c(M_{s})\n\\end{aligned}\\] ◻\n\n\n(The Doob-Meyer Decomposition Theorem). Let \\((X_{n}:n\\in\\mathbf{N})\\) be a submartingale with respect to a filtration \\((\\mathcal{F}_{n}:n\\in\\mathbf{N})\\). Define a sequence of random variables \\((A_{n}:n\\in\\mathbf{N})\\) by \\(A_{0}=0\\) and\n\\[\\begin{aligned}\nA_{n} & =\\sum_{i=1}^{n}(\\mathbf{E}[X_{i}|\\mathcal{F}_{i-1}]-X_{i-1}),\\quad n\\geq1\n\\end{aligned}\\]\nNote that \\(A_{n}\\) is \\(\\mathcal{F}_{n-1}\\)-measurable. Moreover, since \\((X_{n}:n\\in\\mathbf{N})\\) is a submartingale, we have \\(\\mathbf{E}[X_{i}|\\mathcal{F}_{i-1}]-X_{i-1}\\geq0\\) almost surely. Hence, \\((A_{n}:n\\in\\mathbf{N})\\) is an increasing sequence almost surely. Let \\(M_{n}=X_{n}-A_{n}\\).\nWe have:\n\\[\\begin{aligned}\n\\mathbf{E}[M_{n}|\\mathcal{F}_{n-1}] & =\\mathbf{E}[X_{n}-A_{n}|\\mathcal{F}_{n-1}]\\\\\n& =\\mathbf{E}[X_{n}|\\mathcal{F}_{n-1}]-\\mathbf{E}[A_{n}|\\mathcal{F}_{n-1}]\\\\\n& =\\mathbf{E}[X_{n}|\\mathcal{F}_{n-1}]-\\mathbf{E}\\left[\\left.\\mathbf{E}[X_{n}|\\mathcal{F}_{n-1}]-X_{n-1}+A_{n-1}\\right|\\mathcal{F}_{n-1}\\right]\\\\\n& =\\mathbf{E}[X_{n}|\\mathcal{F}_{n-1}]-\\mathbf{E}[X_{n}|\\mathcal{F}_{n-1}]+\\mathbf{E}[X_{n-1}|\\mathcal{F}_{n-1}]-\\mathbf{E}[A_{n-1}|\\mathcal{F}_{n-1}]\\\\\n& =\\cancel{\\mathbf{E}[X_{n}|\\mathcal{F}_{n-1}]}-\\cancel{\\mathbf{E}[X_{n}|\\mathcal{F}_{n-1}]}+X_{n-1}-A_{n-1}\\\\\n& =M_{n-1}\n\\end{aligned}\\]\nThus, \\((M_{n}:n\\in\\mathbf{N})\\) is a martingale. Thus, we have obtained the Doob decomposition:\n\\[\\begin{aligned}\nX_{n} & =M_{n}+A_{n}\\label{eq:doob-decomposition}\n\\end{aligned}\\]\nThis decomposition of a submartingale as a sum of a martingale and an adapted increasing sequence is unique, if we require that \\(A_{0}=0\\) and that \\(A_{n}\\) is \\(\\mathcal{F}_{n-1}\\)-measurable.\nFor the continuous-time case, the situation is much more complicated. The analogue of equation ([eq:doob-decomposition]) is called the Doob-Meyer decomposition. We briefly describe this decomposition and avoid the technical details. All stochastic processes \\(X(t)\\) are assumed to be right-continuous with left-hand limits \\(X(t-)\\).\nLet \\(X(t)\\), \\(a\\leq t\\leq b\\) be a submartingale with respect to a right-continuous filtration \\((\\mathcal{F}_{t}:a\\leq t\\leq b)\\). If \\(X(t)\\) satisfies certain conditions, then it can be uniquely decomposed as:\n\\[\\begin{aligned}\nX(t) & =M(t)+C(t),\\quad a\\leq t\\leq b\n\\end{aligned}\\]\nwhere \\(M(t)\\), \\(a\\leq t\\leq b\\) is a martingale with respect to \\((\\mathcal{F}_{t};a\\leq t\\leq b)\\), \\(C(t)\\) is right-continuous and increasing almost surely with \\(\\mathbf{E}[C(t)]&lt;\\infty\\).\n\n\n(Square of a Poisson Process). Let \\((N_{t}:t\\geq0)\\) be a Poisson process with rate \\(\\lambda\\). We consider the compensated process \\(M_{t}=N_{t}-\\lambda t\\). By ([corollary:the-convex-function-of-martingale-is-a-submartingale]), the process \\((M_{t}^{2}:t\\geq0)\\) is a submartingale for the filtration \\((\\mathcal{F}_{t}:t\\geq0)\\) of the Poisson process. How should we compensated \\(M_{t}^{2}\\) to get a martingale? A direct computation using the properties of conditional expectation yields:\n\\[\\begin{aligned}\n\\mathbf{E}[M_{t}^{2}|\\mathcal{F}_{s}] & =\\mathbf{E}[(M_{t}-M_{s}+M_{s})^{2}|\\mathcal{F}_{s}]\\\\\n& =\\mathbf{E}[(M_{t}-M_{s})^{2}+2(M_{t}-M_{s})M_{s}+M_{s}^{2}|\\mathcal{F}_{s}]\\\\\n& =\\mathbf{E}[(M_{t}-M_{s})^{2}|\\mathcal{F}_{s}]+2\\mathbf{E}[(M_{t}-M_{s})M_{s}|\\mathcal{F}_{s}]+\\mathbf{E}[M_{s}^{2}|\\mathcal{F}_{s}]\\\\\n& =\\mathbf{E}[(M_{t}-M_{s})^{2}]+2M_{s}\\underbrace{\\mathbf{E}[M_{t}-M_{s}]}_{\\text{equals \\ensuremath{0}}}+M_{s}^{2}\\\\\n& =\\mathbf{E}[(M_{t}-M_{s})^{2}]+M_{s}^{2}\n\\end{aligned}\\]\nNow, if \\(X\\sim\\text{Poisson\\ensuremath{(\\lambda t)}}\\), then \\(\\mathbf{E}[X]=\\lambda t\\) and \\(\\mathbf{E}\\ensuremath{[X^{2}]}=\\lambda t(\\lambda t+1)\\).\n\\[\\begin{aligned}\n\\mathbf{E}[(M_{t}-M_{s})^{2}] & =\\mathbf{E}\\left[\\left\\{ (N_{t}-N_{s})-\\lambda(t-s)\\right\\} ^{2}\\right]\\\\\n& =\\mathbf{E}\\left[(N_{t}-N_{s})^{2}\\right]-2\\lambda(t-s)\\mathbf{E}\\left[(N_{t}-N_{s})\\right]+\\lambda^{2}(t-s)^{2}\\\\\n& =\\lambda^{2}(t-s)^{2}+\\lambda(t-s)-2\\lambda(t-s)\\cdot\\lambda(t-s)+\\lambda^{2}(t-s)^{2}\\\\\n& =\\lambda(t-s)\n\\end{aligned}\\]\nThus,\n\\[\\begin{aligned}\n\\mathbf{E}[M_{t}^{2}-\\lambda t|\\mathcal{F}_{s}] & =M_{s}^{2}-\\lambda s\n\\end{aligned}\\]\nWe conclude that the process \\((M_{t}^{2}-\\lambda t:t\\geq0)\\) is a martingale. The Doob-Meyer decomposition of the submartingale \\(M_{t}^{2}\\) is then:\n\\[\\begin{aligned}\nM_{t}^{2} & =(M_{t}^{2}-\\lambda t)+\\lambda t\n\\end{aligned}\\]\n\n\nConsider a Brownian motion \\(B(t)\\). The quadratic variation of the process \\((B(t):t\\geq0)\\) over the interval \\([0,t]\\) is given by \\([B]_{t}=t\\). On the other hand, we saw, that the square of Brownian motion compensated, \\((B_{t}^{2}-t:t\\geq0)\\) is a martingale. Hence, the Doob-Meyer decomposition of \\(B(t)^{2}\\) is given by:\n\\[\\begin{aligned}\nB(t)^{2} & =(B(t)^{2}-t)+t\n\\end{aligned}\\]\n\n\n\n\nMartingales are not only conceptually interesting, they are also formidable tools to compute probabilities and expectations of processes. For example, in this section, we will solve the gambler’s ruin problem for Brownian motion. For convenience, we introduce the notion of stopping time before doing so.\n\nA random variable \\(\\tau:\\Omega\\to\\mathbf{N}\\cup\\{+\\infty\\}\\) is said to be a stopping time for the filtration \\((\\mathcal{F}_{t}:t\\geq0)\\) if and only if:\n\\[\\begin{aligned}\n\\{\\omega:\\tau(\\omega)\\leq t\\} & \\in\\mathcal{F}_{t},\\quad\\forall t\\geq0\n\\end{aligned}\\] Note that since \\(\\mathcal{F}_{t}\\) is a sigma-field, if \\(\\tau\\) is a stopping time, then we must also have that \\(\\{\\omega:\\tau(\\omega)&gt;t\\}\\in\\mathcal{F}_{t}\\).\nIn other words, \\(\\tau\\) is a stopping time, if we can decide if the events \\(\\{\\tau\\leq t\\}\\) occurred or not based on the information available at time \\(t\\).\nThe term stopping time comes from gambling: a gambler can decide to stop playing at a random time (depending for example on previous gains or losses), but when he or she decides to stop, his/her decision is based solely upon the knowledge of what happened before, and does not depend on future outcomes. In other words, the stopping policy/strategy can only depend on past outcomes. Otherwise, it would mean that he/she has a crystall ball.\n\n\n(Examples of stopping times).\n(i) First passage time. This is the first time when a process reaches a certain value. To be precise, let \\(X=(X_{t}:t\\geq0)\\) be a process and \\((\\mathcal{F}_{t}:t\\geq0)\\) be its natural filtration. For \\(a&gt;0\\), we define the first passage time at \\(a\\) to be:\n\\[\\begin{aligned}\n\\tau(\\omega) & =\\inf\\{s\\geq0:X_{s}(\\omega)\\geq a\\}\n\\end{aligned}\\]\nIf the path \\(\\omega\\) never reaches \\(a\\), we set \\(\\tau(\\omega)=\\infty\\). Now, for \\(t\\) fixed and for a given path \\(X(\\omega)\\), it is possible to know if \\(\\{\\tau(\\omega)\\leq t\\}\\) (the path has reached \\(a\\) before time \\(t\\)) or \\(\\{\\tau(\\omega)&gt;t\\}\\) (the path has not reached \\(a\\) before time \\(t\\)) with the information available at time \\(t\\), since we are looking at the first time the process reaches \\(a\\). Hence, we conclude that \\(\\tau\\) is a stopping time.\n(ii) Hitting time. More generally, we can consider the first time (if ever) that the path of a process \\((X_{t}:t\\geq0)\\) enters or hits a subset \\(B\\) of \\(\\mathbf{R}\\):\n\\[\\begin{aligned}\n\\tau(\\omega) & =\\min\\{s\\geq0:X_{s}(\\omega)\\in B\\}\n\\end{aligned}\\]\nThe first passage time is the particular case in which \\(B=[a,\\infty)\\).\n(iii) Minimum of two stopping times. If \\(\\tau\\) and \\(\\tau'\\) are two stopping times for the same filtration \\((\\mathcal{F}_{t}:t\\geq0)\\), then so is the minimum \\(\\tau\\land\\tau'\\) between the two, where\n\\[\\begin{aligned}\n(\\tau\\land\\tau')(\\omega) & =\\min\\{\\tau(\\omega),\\tau'(\\omega)\\}\n\\end{aligned}\\]\nThis is because for any \\(t\\geq0\\):\n\\[\\begin{aligned}\n\\{\\omega: & (\\tau\\land\\tau')(\\omega)\\leq t\\}=\\{\\omega:\\tau(\\omega)\\leq t\\}\\cup\\{\\omega:\\tau'(\\omega)\\leq t\\}\n\\end{aligned}\\]\nSince the right hand side is the union of two events in \\(\\mathcal{F}_{t}\\), it must also be in \\(\\mathcal{F}_{t}\\) by the properties of a sigma-field. We conclude that \\(\\tau\\land\\tau'\\) is a stopping time. Is it also the case that the maximum \\(\\tau\\lor\\tau'\\) is a stopping time?\nFor any fixed \\(t\\geq0\\), we have:\n\\[\\begin{aligned}\n\\{\\omega:(\\tau\\lor\\tau')(\\omega)\\leq t\\} & =\\{\\omega:\\tau(\\omega)\\leq t\\}\\cap\\{\\omega:\\tau'(\\omega)\\leq t\\}\n\\end{aligned}\\]\nSince the right hand side is the intersection of two events in \\(\\mathcal{F}_{t}\\), it must also be in \\(\\mathcal{F}_{t}\\) by the properties of a sigma-field. We conclude that \\(\\tau\\lor\\tau'\\) is a stopping time.\n\n\n(Last passage time is not a stopping time). What if we look at the last time the process reaches \\(a\\), that is:\n\\[\\begin{aligned}\n\\rho(\\omega) & =\\sup\\{t\\geq0:X_{t}(\\omega)\\geq a\\}\n\\end{aligned}\\]\nThis is a well-defined random variable, but it is not a stopping time. Based on the information available at time \\(t\\), we are not able to decide whether or not \\(\\{\\rho(\\omega)\\leq t\\}\\) occurred or not, as the path can always reach \\(a\\) one more time after \\(t\\).\n\nIt turns out that a martingale that is stopped when the stopping time is attained remains a martingale.\n\n(Stopped Martingale). If \\((M_{t}:t\\geq0)\\) is a continuous martingale for the filtration \\((\\mathcal{F}_{t}:t\\geq0)\\) and \\(\\tau\\) is a stopping time for the same filtration, then the stopped process defined by \\[\\begin{aligned}\nM_{t\\land\\tau} & =\\begin{cases}\nM_{t} & t\\leq\\tau\\\\\nM_{\\tau} & t&gt;\\tau\n\\end{cases}\n\\end{aligned}\\]\nis also a continuous martingale for the same filtration.\n\n\n[]{#th:doob’s-optional-sampling-theorem label=“th:doob’s-optional-sampling-theorem”}(Doob’s Optional sampling theorem). If \\((M_{t}:t\\geq0)\\) is a continuous martingale for the filtration \\((\\mathcal{F}_{t}:t\\geq0)\\) and \\(\\tau\\) is a stopping time such that \\(\\tau&lt;\\infty\\) and the stopped process \\((M_{t\\land\\tau}:t\\geq0)\\) is bounded, then:\n\\[\\begin{aligned}\n\\mathbf{E}[M_{\\tau}] & =M_{0}\n\\end{aligned}\\]\n\n\nProof. Proof. Since \\((M_{\\tau\\land t}:t\\geq0)\\) is a martingale, we always have:\n\\[\\begin{aligned}\n\\mathbf{E}[M_{\\tau\\land t}] & =M_{0}\n\\end{aligned}\\]\nNow, since \\(\\tau(\\omega)&lt;\\infty\\), we must\nhave that \\(\\lim_{t\\to\\infty}M_{\\tau\\land t}=M_{\\tau}\\) almost surely. In particular, we have:\n\\[\\begin{aligned}\n\\mathbf{E}[M_{\\tau}] & =\\mathbf{E}\\left[\\lim_{t\\to\\infty}M_{\\tau\\land t}\\right]=\\lim_{t\\to\\infty}\\mathbf{E}[M_{\\tau\\land t}]=\\lim_{t\\to\\infty}M_{0}\n\\end{aligned}\\]\nwhere we passed to the limit, using the dominated convergence theorem ([th:dominated-convergence-theorem]). ◻\n\n\n(Gambler’s ruin with Brownian motion). The gambler’s ruin problem is known in different forms. Roughly speaking, it refers to the problem of computing the probability of a gambler making a series of bets reaching a certain amount before going broke. In terms of Brownian motion (and stochastic processes in general), it translates to the following questions: Let \\((B_{t}:t\\geq0)\\) be a standard brownian motion starting at \\(B_{0}=0\\) and \\(a,b&gt;0\\).\n(1) What is the probability that a Brownian path reaches \\(a\\) before \\(-b\\)?\n(2) What is the expected waiting time for the path to reach \\(a\\) or \\(-b\\)?\nFor the first question, it is a simple computation using stopping time and martingale properties. Define the hitting time:\n\\[\\begin{aligned}\n\\tau(\\omega) & =\\inf\\{t\\geq0:B_{t}(\\omega)\\geq a\\text{ or }B_{t}(\\omega)\\leq-b\\}\n\\end{aligned}\\]\nNote that \\(\\tau\\) is the minimum between the first passage time at \\(a\\) and the one at \\(-b\\).\nWe first show that \\(\\tau&lt;\\infty\\) almost surely. In other words, all Brownian paths reach \\(a\\) or \\(-b\\) eventually. To see this, consider the event \\(E_{n}\\) that the \\(n\\)-th increment exceeds \\(a+b\\)\n\\[\\begin{aligned}\nE_{n} & :=\\left\\{ |B_{n}-B_{n-1}|&gt;a+b\\right\\}\n\\end{aligned}\\]\nNote that, if \\(E_{n}\\) occurs, then we must have that the Brownian motion path exits the interval \\([-b,a].\\) Moreover, we have \\(\\mathbb{P}(E_{n})=\\mathbb{P}(E_{1})\\) for all \\(n\\). Call this probability \\(p\\).\nSince the events \\(E_{n}\\) are independent, we have:\n\\[\\begin{aligned}\n\\mathbb{P}(E_{1}^{C}\\cap E_{2}^{C}\\cap\\ldots\\cap E_{n}^{C}) & =(1-p)^{n}\n\\end{aligned}\\]\nAs \\(n\\to\\infty\\) we have:\n\\[\\begin{aligned}\n\\lim_{n\\to\\infty}\\mathbb{P}(E_{1}^{C}\\cap E_{2}^{C}\\cap\\ldots\\cap E_{n}^{C}) & =0\n\\end{aligned}\\]\nThe sequence of events \\((F_{n})\\) where \\(F_{n}=E_{1}^{C}\\cap E_{2}^{C}\\cap\\ldots\\cap E_{n}^{C}\\) is a decreasing sequence of events. By the continuity of probability measure lemma ([th:continuity-property-of-lebesgue-measure]), we conclude that:\n\\[\\begin{aligned}\n\\lim_{n\\to\\infty}\\mathbb{P}\\left(F_{n}\\right) & =\\mathbb{P}\\left(\\bigcap_{n=1}^{\\infty}F_{n}\\right)=0\n\\end{aligned}\\]\nTherefore, it must be the case \\(\\mathbb{P}(\\cup_{n=1}^{\\infty}E_{n})=1\\). So, \\(E_{n}\\) must occur for some \\(n\\), so all brownian motion paths reach \\(a\\) or \\(-b\\) almost surely.\nSince \\(\\tau&lt;\\infty\\) with probability one, the random variable \\(B_{\\tau}\\) is well-defined : \\(B_{\\tau}(\\omega)=B_{t}(\\omega)\\) if \\(\\tau(\\omega)=t\\). It can only take two values: \\(a\\) or \\(-b\\). Question (1) above translates into computing \\(\\mathbb{P}(B_{\\tau}=a)\\). On one hand, we have:\n\\[\\begin{aligned}\n\\mathbf{E}[B_{\\tau}] & =a\\mathbb{P}(B_{\\tau}=a)+(-b)(1-\\mathbb{P}(B_{\\tau}=a))\n\\end{aligned}\\]\nOn the other hand, by corollary ([th:doob's-optional-sampling-theorem]), we have \\(\\mathbf{E}[B_{\\tau}]=\\mathbf{E}[B_{0}]=0\\). (Note that the stopped process \\((B_{t\\land\\tau}:t\\geq0)\\) is bounded above by \\(a\\) and by \\(-b\\) below). Putting these two observations together, we get:\n\\[\\begin{aligned}\n\\mathbb{P}(B_{\\tau}=a) & =\\frac{b}{a+b}\n\\end{aligned}\\]\nA very simple and elegant answer!\nWe will revisit this problem again and again. In particular, we will answer the question above for Brownian motion with a drift at length further ahead.\n\n\n(Expected Waiting Time). Let \\(\\tau\\) be as in the last example. We now answer question (2) of the gambler’s ruin problem:\n\\[\\begin{aligned}\n\\mathbf{E}[\\tau] & =ab\n\\end{aligned}\\]\nNote that the expected waiting time is consistent with the rough heuristic that Brownian motion travels a distance \\(\\sqrt{t}\\) by time \\(t\\). We now use the martingale \\(M_{t}=B_{t}^{2}-t\\). On the one hand, if we apply optional stopping in corollary ([th:doob's-optional-sampling-theorem]), we get:\n\\[\\begin{aligned}\n\\mathbf{E}[M_{\\tau}] & =M_{0}=0\n\\end{aligned}\\]\nMoreover, we know the distribution of \\(B_{\\tau}\\), thanks to the probability calculated in the last example. We can therefore compute \\(\\mathbf{E}[M_{\\tau}]\\) directly:\n\\[\\begin{aligned}\n0 & =\\mathbf{E}[M_{\\tau}]\\\\\n& =\\mathbf{E}[B_{\\tau}^{2}-\\tau]\\\\\n& =\\mathbf{E}[B_{\\tau}^{2}]-\\mathbf{E}[\\tau]\\\\\n& =a^{2}\\cdot\\frac{b}{a+b}+b^{2}\\cdot\\frac{a}{a+b}-\\mathbf{E}[\\tau]\\\\\n\\mathbf{E}[\\tau] & =\\frac{a^{2}b+b^{2}a}{a+b}\\\\\n& =\\frac{ab\\cancel{(a+b)}}{\\cancel{(a+b)}}=ab\n\\end{aligned}\\]\nWhy can we apply optional stopping here? The random variable \\(\\tau\\) is finite with probability \\(1\\) as before. However, the stopped martingale is not necessarily bounded as before: \\(B_{\\tau\\land t}\\) is bounded but \\(\\tau\\) is not. However, the conclusion of optional stopping still holds. Indeed, we have:\n\\[\\begin{aligned}\n\\mathbf{E}[M_{t\\land\\tau}] & =\\mathbf{E}[B_{t\\land\\tau}^{2}]-\\mathbf{E}[t\\land\\tau]\n\\end{aligned}\\]\nBy the bounded convergence theorem, we get \\(\\lim_{t\\to\\infty}\\mathbf{E}[B_{t\\land\\tau}^{2}]=\\mathbf{E}[\\lim_{t\\to\\infty}B_{t\\land\\tau}^{2}]=\\mathbf{E}[B_{\\tau}^{2}]\\). Since \\(\\tau\\land t\\) is a non-decreasing sequence and as \\(t\\to\\infty\\), \\(t\\land\\tau\\to\\tau\\) almost surely, as \\(\\tau&lt;\\infty\\), by the monotone convergence theorem, \\(\\lim_{t\\to\\infty}\\mathbf{E}[t\\land\\tau]=\\mathbf{E}[\\tau]\\).\n\n\n(First passage time of Brownian Motion.) We can use the previous two examples to get some very interesting information on the first passage time:\n\\[\\begin{aligned}\n\\tau_{a} & =\\inf\\{t\\geq0:B_{t}\\geq a\\}\n\\end{aligned}\\]\nLet \\(\\tau=\\tau_{a}\\land\\tau_{-b}\\) be as in the previous examples with \\(\\tau_{-b}=\\inf\\{t\\geq0:B_{t}\\leq-b\\}\\). Note that \\((\\tau_{-b},b\\in\\mathbf{R}_{+})\\) is a sequence of random variables that is increasing in \\(b\\). A brownian motion path must cross through \\(-1\\) before it hits \\(-2\\) for the first time and in general \\(\\tau_{-n}(\\omega)\\leq\\tau_{-(n+1)}(\\omega)\\). Moreover, we have \\(\\tau_{-b}\\to\\infty\\) almost surely as \\(b\\to\\infty\\). That’s because, \\(\\mathbb{P}\\{\\tau&lt;\\infty\\}=1\\). Moreover, the event \\(\\{B_{\\tau}=a\\}\\) is the same as \\(\\{\\tau_{a}&lt;\\tau_{-b}\\}\\). Now, the events \\(\\{\\tau_{a}&lt;\\tau_{-b}\\}\\) are increasing in \\(b\\), since if a path reaches \\(a\\) before \\(-b\\), it will do so as well for a more negative value of \\(-b\\). On one hand, this means by the continuity of probability measure lemma ([th:continuity-property-of-lebesgue-measure]) that:\n\\[\\begin{aligned}\n\\lim_{b\\to\\infty}\\mathbb{P}\\left\\{ \\tau_{a}&lt;\\tau_{-b}\\right\\}  & =\\mathbb{P}\\{\\lim_{b\\to\\infty}\\tau_{a}&lt;\\tau_{-b}\\}\\\\\n& =\\mathbb{P}\\{\\tau_{a}&lt;\\infty\\}\n\\end{aligned}\\]\nOn the other hand, we have by example ([example:probability-of-hitting-times])\n\\[\\begin{aligned}\n\\lim_{b\\to\\infty}\\mathbb{P}\\left\\{ \\tau_{a}&lt;\\tau_{-b}\\right\\}  & =\\lim_{b\\to\\infty}\\mathbb{P}\\{B_{\\tau}=a\\}\\\\\n& =\\lim_{b\\to\\infty}\\frac{b}{b+a}\\\\\n& =1\n\\end{aligned}\\]\nWe just showed that:\n\\[\\begin{aligned}\n\\mathbb{P}\\left\\{ \\tau_{a}&lt;\\infty\\right\\}  & =1\\label{eq:first-passage-time-to-a-is-finite-almost-surely}\n\\end{aligned}\\]\nIn other words, every Brownian path will reach \\(a\\), no matter how large \\(a\\) is!\nHow long will it take to reach \\(a\\) on average? Well, we know from example ([ex:expected-waiting-times]) that \\(\\mathbf{E}[\\tau_{a}\\land\\tau_{-b}]=ab\\). On one hand this means,\n\\[\\begin{aligned}\n\\lim_{b\\to\\infty}\\mathbf{E}[\\tau_{a}\\land\\tau_{-b}] & =\\lim_{b\\to\\infty}ab=\\infty\n\\end{aligned}\\]\nOn the other hand, since the random variables \\(\\tau_{-b}\\) are increasing,\n\\[\\begin{aligned}\n\\lim_{b\\to\\infty}\\mathbf{E}[\\tau_{a}\\land\\tau_{-b}] & =\\mathbf{E}\\left[\\lim_{b\\to\\infty}\\tau_{a}\\land\\tau_{-b}\\right]=\\mathbf{E}[\\tau_{a}]\n\\end{aligned}\\]\nby the monotone convergence theorem ([th:monotone-convergence-theorem]). We just proved that:\n\\[\\begin{aligned}\n\\mathbf{E}[\\tau_{a}] & =\\infty\n\\end{aligned}\\]\nIn other words, any Brownian motion path will reach \\(a\\), but the expected waiting time for this to occur is infinite, no matter, how small \\(a\\) is! What is happening here? No matter, how small \\(a\\) is, there is always paths that reach very large negative values before hitting \\(a\\). These paths might be unlikely. However, the first passage time for these paths is so large that they affect the value of the expectation substantially. In other words, \\(\\tau_{a}\\) is a heavy-tailed random variable. We look at the distribution of \\(\\tau_{a}\\) in more detail in the next section.\n\n\n(When option stopping fails). Consider \\(\\tau_{a}\\), the first passage time at \\(a&gt;0\\). The random variable \\(B_{\\tau_{a}}\\) is well-defined since \\(\\tau_{a}&lt;\\infty\\). In fact, we have \\(B_{\\tau_{a}}=a\\) with probability one. Therefore, the following must hold:\n\\[\\begin{aligned}\n\\mathbf{E}[B_{\\tau_{a}}] & =a\\neq B_{0}\n\\end{aligned}\\]\nOptional stopping theorem corollary ([th:doob's-optional-sampling-theorem]) does not apply here, since the stopped process \\((B_{t\\land\\tau_{a}}:t\\geq0)\\) is not bounded. \\(B_{t\\land\\tau_{a}}\\) can become infinitely negative before hitting \\(a\\).\n\n\n\n\n\n(Bachelier’s formula). Let \\((B_{t}:t\\leq T)\\) be a standard brownian motion on \\([0,T].\\) Then, the CDF of the random variable \\(\\sup_{0\\leq t\\leq T}B_{t}\\) is:\n\\[\\begin{aligned}\n\\mathbb{P}\\left(\\sup_{0\\leq t\\leq T}B_{t}\\leq a\\right) & =\\mathbb{P}\\left(|B_{T}|\\leq a\\right)\n\\end{aligned}\\]\nIn particular, its PDF is:\n\\[\\begin{aligned}\nf_{\\max}(a) & =\\frac{2}{\\sqrt{2\\pi T}}e^{-\\frac{a^{2}}{2T}}\n\\end{aligned}\\]\n\n\nWe can verify these results empirically. Note that the paths of the random variables \\(\\max_{0\\leq s\\leq t}B_{s}\\) and \\(|B_{t}|\\) are very different as \\(t\\) varies for a given \\(\\omega\\). One is increasing and the other is not. The equality holds in distribution for a fixed \\(t\\). As a bonus corollary, we get the distribution of the first passage time at \\(a\\).\n\n\nLet \\(a\\geq0\\) and \\(\\tau_{a}=\\inf\\{t\\geq0:B_{t}\\geq a\\}\\). Then:\n\\[\\begin{aligned}\n\\mathbb{P}\\left(\\tau_{a}\\leq T\\right) & =\\mathbb{P}\\left(\\max_{0\\leq t\\leq T}B_{t}\\geq a\\right)=\\int_{a}^{\\infty}\\frac{2}{\\sqrt{2\\pi T}}e^{-\\frac{x^{2}}{2T}}dx\n\\end{aligned}\\]\nIn particular, the random variable \\(\\tau_{a}\\) has the PDF:\n\\[\\begin{aligned}\nf_{\\tau_{a}}(t) & =\\frac{a}{\\sqrt{2\\pi}}\\frac{e^{-\\frac{a^{2}}{2t}}}{t^{3/2}},\\quad t&gt;0\n\\end{aligned}\\]\nThis implies that it is heavy-tailed with \\(\\mathbf{E}[\\tau_{a}]=\\infty\\).\n\n\nProof. Proof. The maximum on \\([0,T]\\) is larger than or equal to \\(a\\) if and only if \\(\\tau_{a}\\leq T\\). Therefore, the events \\(\\{\\max_{0\\leq t\\leq T}B_{t}\\geq a\\}\\) and \\(\\{\\tau_{a}\\leq T\\}\\) are the same. So, the CDF \\(\\mathbb{P}(\\tau_{a}\\leq t)\\) of \\(\\tau_{a}\\), by proposition ([prop:bacheliers-formula]) \\(\\int_{a}^{\\infty}f_{\\max}(x)dx=\\int_{a}^{\\infty}\\frac{2}{\\sqrt{2\\pi T}}e^{-\\frac{x^{2}}{2T}}dx\\).\n\\[\\begin{aligned}\nf_{\\tau_{a}}(t) & =-2\\phi(a/\\sqrt{t})\\cdot a\\cdot\\left(-\\frac{1}{2t^{3/2}}\\right)\\\\\n& =\\frac{a}{t^{3/2}}\\phi\\left(\\frac{a}{\\sqrt{t}}\\right)\\\\\n& =\\frac{a}{t^{3/2}}\\cdot\\frac{1}{\\sqrt{2\\pi}}e^{-\\frac{a^{2}}{2t}}\n\\end{aligned}\\]\nTo estimate the expectation, it suffices to realize that for \\(t\\geq1\\), \\(e^{-\\frac{a^{2}}{2t}}\\) is larger than \\(e^{-\\frac{a^{2}}{2}}\\). Therefore, we have:\n\\[\\begin{aligned}\n\\mathbf{E}[\\tau_{a}] & =\\int_{0}^{\\infty}t\\frac{a}{\\sqrt{2\\pi}}\\frac{e^{-a^{2}/2t}}{t^{3/2}}dt\\geq\\frac{ae^{-a^{2}/2}}{\\sqrt{2\\pi}}\\int_{1}^{\\infty}t^{-1/2}dt\n\\end{aligned}\\]\nThis is an improper integral and it diverges like \\(\\sqrt{t}\\) and is infinite as claimed. ◻\n\nTo prove proposition ([prop:bacheliers-formula]), we will need an important property of Brownian motion called the reflection principle. To motivate it, recall the reflection symmetry of Brownian motion at time \\(s\\) in proposition ([prop:brownian-motion-symmetry-of-reflection-at-time-s]). It turns out that this reflection property also holds if \\(s\\) is replaced by a stopping time.\n\n(Reflection principle). Let \\((B_{t}:t\\geq0)\\) be a standard Brownian motion and let \\(\\tau\\) be a stopping time for its filtration. Then, the process \\((\\tilde{B}_{t}:t\\geq0)\\) defined by the reflection at time \\(\\tau\\):\n\\[\\begin{aligned}\n\\tilde{B}_{t} & =\\begin{cases}\nB_{t} & \\text{if \\ensuremath{t\\leq\\tau}}\\\\\nB_{\\tau}-(B_{t}-B_{\\tau}) & \\text{if \\ensuremath{t&gt;\\tau}}\n\\end{cases}\n\\end{aligned}\\]\nis also a standard brownian motion.\n\n\nWe defer the proof of the reflection property of Brownian motion to a further section. It is intuitive and instructive to quickly picture this in the discrete-time setting. I adopt the approach as in Shreve-I.\nWe repeatedly toss a fair coin (\\(p\\), the probability of \\(H\\) on each toss, and \\(q=1-p\\), the probability of \\(T\\) on each toss, are both equal to \\(\\frac{1}{2}\\)). We denote the successive outcomes of the tosses by \\(\\omega_{1}\\omega_{2}\\omega_{3}\\ldots\\). Let\n\\[\\begin{aligned}\nX_{j} & =\\begin{cases}\n-1 & \\text{if \\ensuremath{\\omega_{j}=H}}\\\\\n+1 & \\text{if \\ensuremath{\\omega_{j}=T}}\n\\end{cases}\n\\end{aligned}\\]\nand define \\(M_{0}=0\\), \\(M_{n}=\\sum_{j=1}^{n}X_{n}\\). The process \\((M_{n}:n\\in\\mathbf{N})\\) is a symmetric random walk.\nSuppose we toss a coin an odd number \\((2j-1)\\) of times. Some of the paths will reach level \\(1\\) in the first \\(2j-1\\) steps and other will not reach. In the case of \\(3\\) tosses, there are \\(2^{3}=8\\) possible paths and \\(5\\) of these reach level \\(1\\) at some time \\(\\tau_{1}\\leq2j-1\\). From that moment on, we can create a reflected path, which steps up each time the original path steps down and steps down each time the original path steps up. If the original path ends above \\(1\\) at the final time \\(2j-1\\), the reflected path ends below \\(1\\) and vice versa. If the original path ends at \\(1\\), the reflected path does also. In fact, the reflection at the first hitting time has the same distribution as the original random walk.\nThe key here is, out of the \\(5\\) paths that reach level \\(1\\) at some time, there are as many reflected paths that exceed \\(1\\) at time \\((2j-1)\\) as there are original paths that exceed \\(1\\) at time \\((2j-1)\\). So, to count the total number of paths that reach level \\(1\\) by time \\((2j-1)\\), we can count the paths that are at \\(1\\) at time \\((2j-1)\\) and then add on twice the number of paths that exceed \\(1\\) at time \\((2j-1)\\).\n\nWith this new tool, we can now prove proposition ([prop:bacheliers-formula]).\n\nProof. Proof. Consider \\(\\mathbb{P}(\\max_{t\\leq T}B_{t}\\geq a)\\). By splitting this probability over the event of the endpoint, we have:\n\\[\\begin{aligned}\n\\mathbb{P}\\left(\\max_{t\\leq T}B_{t}\\geq a\\right) & =\\mathbb{P}\\left(\\max_{t\\leq T}B_{t}\\geq a,B_{T}&gt;a\\right)+\\mathbb{P}\\left(\\max_{t\\leq T}B_{t}\\geq a,B_{T}\\leq a\\right)\n\\end{aligned}\\]\nNote also, that \\(\\mathbb{P}(B_{T}=a)=0\\). Hence, the first probability equals \\(\\mathbb{P}(B_{T}\\geq a)\\). As for the second, consider the time \\(\\tau_{a}\\). On the event considered, we have \\(\\tau_{a}\\leq T\\) and using lemma ([lemma:BM-reflection-principle]) at that time, we get\n\\[\\begin{aligned}\n\\mathbb{P}\\left(\\max_{t\\leq T}B_{t}\\geq a,B_{T}\\leq a\\right) & =\\mathbb{P}\\left(\\max_{t\\leq T}B_{t}\\geq a,\\tilde{B}_{T}\\geq a\\right)\n\\end{aligned}\\]\nObserve that the event \\(\\{\\max_{t\\leq T}B_{t}\\geq a\\}\\) is the same as \\(\\{\\max_{t\\leq T}\\tilde{B}_{T}\\geq a\\}\\). (A rough picture might help here.) Thereforem the above probability is\n\\[\\begin{aligned}\n\\mathbb{P}\\left(\\max_{t\\leq T}B_{t}\\geq a,B_{T}\\leq a\\right) & =\\mathbb{P}\\left(\\max_{t\\leq T}\\tilde{B}_{t}\\geq a,\\tilde{B}_{T}\\geq a\\right)=\\mathbb{P}\\left(\\max_{t\\leq T}B_{t}\\geq a,B_{T}\\geq a\\right)\n\\end{aligned}\\]\nwhere the last equality follows from the reflection principle (\\(\\tilde{B}_{t}\\) is also a standard brownian motion, and \\(B_{T}\\) and \\(\\tilde{B}_{T}\\) have the same distribution.) But, as above, the last probability is equal to \\(\\mathbb{P}(B_{T}\\geq a)\\). We conclude that:\n\\[\\begin{aligned}\n\\mathbb{P}\\left(\\max_{t\\leq T}B_{t}\\geq a\\right) & =2\\mathbb{P}(B_{T}\\geq a)=\\frac{2}{\\sqrt{2\\pi T}}\\int_{a}^{\\infty}e^{-\\frac{x^{2}}{2T}}dx=\\mathbb{P}(|B_{T}|\\geq a)\n\\end{aligned}\\]\nThis implies in particular that \\(\\mathbb{P}\\left(\\max_{t\\leq T}B_{t}=a\\right)=0\\). Thus, we also have \\(\\mathbb{P}(\\max_{t\\leq T}B_{t}\\leq a)=\\mathbb{P}(|B_{T}|\\leq a)\\) as claimed. ◻\n\n\n(Simulating Martingales) Sample \\(10\\) paths of the following process with a step-size of \\(0.01\\):\n(a) \\(B_{t}^{2}-t\\), \\(t\\in[0,1]\\)\n(b) Geometric Brownian motion : \\(S_{t}=\\exp(B_{t}-t/2)\\), \\(t\\in[0,1]\\).\nLet’s write a simple \\(\\texttt{BrownianMotion}\\) class, that we shall use to generate sample paths.\n\nimport numpy as np\nimport matplotlib.pyplot as plt\n\nimport attrs\nfrom attrs import define, field\n\n@define\nclass BrownianMotion:\n    _step_size = field(validator=attrs.validators.and_(attrs.validators.instance_of(float),\n                                                       attrs.validators.ge(0.0)))\n    # Time T\n    _T = field(validator=attrs.validators.and_(attrs.validators.instance_of(float),\n                                               attrs.validators.ge(0.0)))\n    # number of paths\n    _N = field(validator=attrs.validators.and_(attrs.validators.instance_of(int),\n                                               attrs.validators.gt(0)))\n\n    _num_steps = field(init=False)\n\n    def __attrs_post_init__(self):\n        self._num_steps = int(self._T/self._step_size)\n\n    def covariance_matrix(self):\n        C = np.zeros((self._num_steps,self._num_steps))\n\n        for i in range(self._num_steps):\n            for j in range(self._num_steps):\n                s = (i+1) * self._step_size\n                t = (j+1) * self._step_size\n                C[i,j] = min(s,t)\n        return C\n\n    # Each column vector represents a sample path\n    def generate_paths(self):\n        C = self.covariance_matrix()\n        A = np.linalg.cholesky(C)\n        Z = np.random.standard_normal((self._num_steps, self._N))\n        X = np.matmul(A,Z)\n        X = np.concatenate((np.zeros((1,self._N)),X),axis=0)\n        return X.transpose()\nNow, the process \\(B_{t}^{2}-t\\) can be sampled as follows:\n\ndef generateSquareOfBMCompensated(numOfPaths,stepSize,T):\n    N = int(T/stepSize)\n\n    X = []\n    brownianMotion = BrownianMotion(stepSize,T)\n    for n in range(numOfPaths):\n\n        B_t = brownianMotion.samplePath()\n\n        B_t_sq = np.square(B_t)\n\n        t = np.linspace(start=0.0,stop=1.0,num=N+1)\n        M_t = np.subtract(B_t_sq,t)\n        X.append(M_t)\n\n    return X\nThe gBM process can be sampled similarly, with \\(\\texttt{\\ensuremath{M_{t}} = np.exp(np.subtract(\\ensuremath{B_{t}},t/2))}\\).\n\n(Maximum of Brownian Motion.) Consider the maximum of Brownian motion on \\([0,1]\\): \\(\\max_{s\\leq1}B_{s}\\).\n(a) Draw the histogram of the random variable \\(\\max_{s\\leq1}B_{s}\\)using \\(10,0000\\) sampled Brownian paths with a step size of \\(0.01\\).\n(b) Compare this to the PDF of the random variable \\(|B_{1}|\\).\n\nSolution.\nI use the \\(\\texttt{itertools}\\) python library to compute the running maximum of a brownian motion path.\n\nbrownianMotion = BrownianMotion(stepSize=0.01,T=1)\ndata = []\n\nfor i in range(10000):\n    B_t = brownianMotion.samplePath()\n    max_B_t = list(itertools.accumulate(B_t,max))\n    data.append(max_B_t[100])\nAnalytically, we know that \\(B_{1}\\) is a gaussian random variable with mean \\(0\\) and variance \\(1\\).\n\\[\\begin{aligned}\n\\mathbb{P}(|B_{1}|\\leq z) & =\\mathbb{P}(|Z|\\leq z)\\\\\n& =\\mathbb{P}(-z\\leq Z\\leq z)\\\\\n& =\\mathbb{P}(Z\\leq z)-\\mathbb{P}(Z\\leq-z)\\\\\n& =\\mathbb{P}(Z\\leq z)-(1-\\mathbb{P}(Z\\leq z))\\\\\nF_{|B_{1}|}(z) & =2\\Phi(z)-1\n\\end{aligned}\\]\nDifferentiating on both sides, we get:\n\\[\\begin{aligned}\nf_{|B_{1}|}(z) & =2\\phi(z)=\\frac{2}{\\sqrt{2\\pi}}e^{-\\frac{z^{2}}{2}},\\quad z\\in[0,\\infty)\n\\end{aligned}\\]\n\n(First passage time.) Let \\((B_{t}:t\\geq0)\\) be a standard brownian motion. Consider the random variable:\n\\[\\begin{aligned}\n\\tau & =\\min\\{t\\geq0:B_{t}\\geq1\\}\n\\end{aligned}\\]\nThis is the first time that \\(B_{t}\\) reaches \\(1\\).\n(a) Draw a histogram for the distribution of \\(\\tau\\land10\\) on the time-interval \\([0,10]\\) using \\(10,000\\) brownian motion paths on \\([0,10]\\) with discretization \\(0.01\\).\nThe notation \\(\\tau\\land10\\) means that if the path does not reach \\(1\\) on \\([0,10]\\), then give the value \\(10\\) to the stopping time.\n(b) Estimate \\(\\mathbf{E}[\\tau\\land10]\\).\n(c) What proportion of paths never reach \\(1\\) in the time interval \\([0,10]\\)?\n\nSolution.\nTo compute the expectation, we classify the hitting times of all paths into \\(50\\) bins. I simply did\n\\(\\texttt{frequency, bins = np.histogram(firstPassageTimes,bins=50,range=(0,10))}\\)\nand then computed\n\\(\\texttt{expectation=np.dot(frequency,bins[1:])/10000}\\).\nThis expectation estimate on my machine is \\(\\mathbf{E}[\\tau\\land10]=4.34\\) secs. There were approximately \\(2600\\) paths out of \\(10,000\\) that did not reach \\(1\\).\n\nGambler’s ruin at the French Roulette. Consider the scenario in which you are gambling \\(\\$1\\) at the French roulette on the reds: You gain \\(\\$1\\) with probability \\(18/38\\) and you lose a dollar with probability \\(20/38\\). We estimate the probability of your fortune reaching \\(\\$200\\) before it reaches \\(0\\).\n(a) Write a function that samples the simple random walk path from time \\(0\\) to time \\(5,000\\) with a given starting point.\n(b) Use the above to estimate the probability of reaching \\(\\$200\\) before \\(\\$0\\) on a sample of \\(100\\) paths if you start with \\(\\$100\\).\n\n\n[]{#ex:doob’s-maximal-inequality label=“ex:doob’s-maximal-inequality”}Doob’s maximal inequalities. We prove the following: Let \\((M_{k}:k\\geq1)\\) be positive submartingale for the filtration \\((\\mathcal{F}_{k}:k\\in\\mathbf{N})\\). Then, for any \\(1\\leq p&lt;\\infty\\) and \\(a&gt;0\\)\n\\[\\begin{aligned}\n\\mathbb{P}\\left(\\max_{k\\leq n}M_{k}&gt;a\\right) & \\leq\\frac{1}{a^{p}}\\mathbf{E}[M_{n}^{p}]\n\\end{aligned}\\]\n(a) Use Jensen’s inequality to show that if \\((M_{k}:k\\geq1)\\) is a positive submartingale, then so is \\((M_{k}^{p}:k\\geq1)\\) for \\(1\\leq p&lt;\\infty\\). Conclude that it suffices to prove the statement for \\(p=1\\).\n\nSolution.\nThe function \\(f(x)=x^{p}\\) is convex. By conditional Jensen’s inequality,\n\\[\\begin{aligned}\n\\left(\\mathbf{E}[M_{k+1}|\\mathcal{F}_{k}]\\right)^{p} & \\leq\\mathbf{E}[M_{k}^{p}|\\mathcal{F}_{k}]\n\\end{aligned}\\]\nThus,\n\\[\\begin{aligned}\n\\mathbf{E}[M_{k+1}^{p}|\\mathcal{F}_{k}] & \\geq\\left(\\mathbf{E}[M_{k+1}|\\mathcal{F}_{k}]\\right)^{p}\\geq M_{k}^{p}\n\\end{aligned}\\]\nwhere the last inequality follows from the fact that \\((M_{k}:k\\geq1)\\) is a positive submartingale, so \\(\\mathbf{E}[M_{k+1}|\\mathcal{F}_{k}]\\geq M_{k}\\). Consequently, \\((M_{k}^{p}:k\\geq1)\\) is also a positive submartingale.\n(b) Consider the events\n\\[\\begin{aligned}\nB_{k} & =\\bigcap_{j&lt;k}\\{\\omega:M_{j}(\\omega)\\leq a\\}\\cap\\{\\omega:M_{k}(\\omega)&gt;a\\}\n\\end{aligned}\\]\nArgue that the \\(B_{k}\\)’s are disjoint and that \\(\\bigcup_{k\\leq n}B_{k}=\\{\\max_{k\\leq n}M_{k}&gt;a\\}=B\\).\nSolution.\nClearly, \\(B_{k}\\) is the event that the first time to cross \\(a\\) is \\(k\\). If \\(B_{k}\\) occurs, \\(B_{k+1},B_{k+2},\\ldots\\) fail to occur. Hence, all \\(B_{k}'s\\) are pairwise disjoint. The event \\(\\bigcup_{k\\leq n}B_{k}\\) is the event that the random walk crosses \\(a\\) at any time \\(k\\leq n\\). Thus, the running maximum of the Brownian motion at time \\(n\\) exceeds \\(a\\).\n(c) Show that\n\\[\\begin{aligned}\n\\mathbf{E}[M_{n}]\\geq\\mathbf{E}[M_{n}\\mathbf{1}_{B}] & \\geq a\\sum_{k\\leq n}\\mathbb{P}(B_{k})=a\\mathbb{P}(B)\n\\end{aligned}\\]\nby decomposing \\(B\\) in \\(B_{k}\\)’s and by using the properties of expectations, as well as the submartingale property.\nSolution.\nClearly, \\(M_{n}\\geq M_{n}\\mathbf{1}_{B}\\geq a\\mathbf{1}_{B}\\). And \\(M_{n}\\) is a positive random variable. By monotonicity of expectations, \\(\\mathbf{E}[M_{n}]\\geq\\mathbf{E}[M_{n}\\mathbf{1}_{B}]\\geq a\\mathbf{E}[\\mathbf{1}_{B}]=a\\mathbb{P}(B)=a\\sum_{k\\leq n}\\mathbb{P}(B_{k})\\), where the last equality holds because the \\(B_{k}\\)’s are disjoint.\n(d) Argue that the inequality holds for continuous paths by discretizing time and using convergence theorems : If \\((M_{t}:t\\geq0)\\) is a positive submartingale with continuous paths for the filtration \\((\\mathcal{F}_{t}:t\\geq0)\\), then for any \\(1\\leq p&lt;\\infty\\) and \\(a&gt;0\\):\n\\[\\begin{aligned}\n\\mathbb{P}\\left(\\max_{s\\leq t}M_{s}&gt;a\\right) & \\leq\\frac{1}{a^{p}}\\mathbf{E}[M_{t}^{p}]\n\\end{aligned}\\]\nSolution.\nLet \\((M_{t}:t\\geq0)\\) be a positive submartingale with continuous paths for the filtration \\((\\mathcal{F}_{t}:t\\geq0)\\). Consider a sequence of partitions of the interval \\([0,t]\\) into \\(2^{r}\\) subintervals :\n\\[\\begin{aligned}\nD_{r} & =\\left\\{ \\frac{kt}{2^{r}}:k=0,1,2,\\ldots,2^{n}\\right\\}\n\\end{aligned}\\]\nAnd consider a sequence of discrete positive sub-martingales:\n\\[\\begin{aligned}\nM_{kt/2^{r}}^{(r)} & =M_{kt/2^{r}},\\quad k\\in\\mathbf{N},0\\leq k\\leq2^{r}\n\\end{aligned}\\]\nNext, we define for \\(r=1,2,3,\\ldots\\)\n\\[\\begin{aligned}\nA_{r} & =\\left\\{ \\sup_{s\\in D_{r}}|M_{s}^{(r)}|&gt;a\\right\\}\n\\end{aligned}\\]\nBy using the maximal inequality in discrete time, gives us:\n\\[\\begin{aligned}\n\\mathbb{P}(A_{r})=\\mathbb{P}\\left\\{ \\sup_{s\\in D_{r}}|M_{s}^{(r)}|&gt;a\\right\\}  & \\leq\\frac{1}{a^{p}}\\mathbf{E}\\left[\\left(M_{s}^{(r)}\\right)^{p}\\right]=\\frac{1}{a^{p}}\\mathbf{E}\\left[M_{t}^{p}\\right]\n\\end{aligned}\\]\n\\[\\begin{aligned}\n\\mathbb{P}\\left(\\max_{s\\leq t}M_{s}&gt;a\\right) & =\\mathbb{P}\\left(\\bigcup_{r=1}^{\\infty}A_{r}\\right)\\\\\n& =\\lim_{r\\to\\infty}\\mathbb{P}\\left(A_{r}\\right)\\\\\n& \\left\\{ \\text{Continuity of probability measure}\\right\\} \\\\\n& \\leq\\lim_{r\\to\\infty}\\frac{1}{a^{p}}\\mathbf{E}\\left[M_{t}^{p}\\right]\n\\end{aligned}\\]"
  },
  {
    "objectID": "posts/martingales/index.html#elementary-conditional-expectation.",
    "href": "posts/martingales/index.html#elementary-conditional-expectation.",
    "title": "Martingales",
    "section": "",
    "text": "In elementary probability, the conditional expectation of a variable \\(Y\\) given another random variable \\(X\\) refers to the expectation of \\(Y\\) given the conditional distribution \\(f_{Y|X}(y|x)\\) of \\(Y\\) given \\(X\\). To illustrate this, let’s go through a simple example. Consider \\(\\mathcal{B}_{1}\\), \\(\\mathcal{B}_{2}\\) to be two independent Bernoulli-distributed random variables with \\(p=1/2\\). Then, construct:\n\\[\\begin{aligned}\nX=\\mathcal{B}_{1}, & \\quad Y=\\mathcal{B}_{1}+\\mathcal{B}_{2}\n\\end{aligned}\\]\nIt is easy to compute \\(\\mathbb{E}[Y|X=0]\\) and \\(\\mathbb{E}[Y|X=1]\\). By definition, it is given by:\n\\[\\begin{aligned}\n\\mathbb{E}[Y|X=0] & =\\sum_{j=0}^{2}j\\mathbb{P}(Y=j|X=0)\\\\\n& =\\sum_{j=0}^{2}j\\cdot\\frac{\\mathbb{P}(Y=j,X=0)}{P(X=0)}\\\\\n& =0+1\\cdot\\frac{(1/4)}{(1/2)}+2\\cdot\\frac{0}{(1/2)}\\\\\n& =\\frac{1}{2}\n\\end{aligned}\\]\nand\n\\[\\begin{aligned}\n\\mathbb{E}[Y|X=1] & =\\sum_{j=0}^{2}j\\mathbb{P}(Y=j|X=1)\\\\\n& =\\sum_{j=0}^{2}j\\cdot\\frac{\\mathbb{P}(Y=j,X=1)}{P(X=1)}\\\\\n& =0+1\\cdot\\frac{(1/4)}{(1/2)}+2\\cdot\\frac{(1/4)}{(1/2)}\\\\\n& =\\frac{3}{2}\n\\end{aligned}\\]\nWith this point of view, the conditional expectation is computed given the information that the event \\(\\{X=0\\}\\) occurred or the event \\(\\{X=1\\}\\) occurred. It is possible to regroup both conditional expectations in a single object, if we think of the conditional expectation as a random variable and denote it by \\(\\mathbb{E}[Y|X]\\). Namely, we take:\n\\[\\begin{aligned}\n\\mathbb{E}[Y|X](\\omega) & =\\begin{cases}\n\\frac{1}{2} & \\text{if }X(\\omega)=0\\\\\n\\frac{3}{2} & \\text{if }X(\\omega)=1\n\\end{cases}\\label{eq:elementary-conditional-expectation-example}\n\\end{aligned}\\]\nThis random variable is called the conditional expectation of \\(Y\\) given \\(X\\). We make two important observations:\n(i) If the value of \\(X\\) is known, then the value of \\(\\mathbb{E}[Y|X]\\) is determined.\n(ii) If we have another random variable \\(g(X)\\) constructed from \\(X\\), then we have:\n\\[\\begin{aligned}\n\\mathbb{E}[g(X)Y] & =\\mathbb{E}[g(X)\\mathbb{E}[Y|X]]\n\\end{aligned}\\]\nIn other words, as far as \\(X\\) is concerned, the conditional expectation \\(\\mathbb{E}[Y|X]\\) is a proxy for \\(Y\\) in the expectation. We sometimes say that \\(\\mathbb{E}[Y|X]\\) is the best estimate of \\(Y\\) given the information of \\(X\\).\nThe last observation is easy to verify since:\n\\[\\begin{aligned}\n\\mathbb{E}[g(X)Y] & =\\sum_{i=0}^{1}\\sum_{j=0}^{2}g(i)\\cdot j\\cdot\\mathbb{P}(X=i,Y=j)\\\\\n& =\\sum_{i=0}^{1}\\mathbb{P}(X=i)g(i)\\left\\{ \\sum_{j=0}^{2}j\\cdot\\frac{\\mathbb{P}(X=i,Y=j)}{\\mathbb{P}(X=i)}\\right\\} \\\\\n& =\\mathbb{E}[g(X)\\mathbb{E}[Y|X]]\n\\end{aligned}\\]\n\n(Elementary Definitions of Conditional Expectation).\n(1) \\((X,Y)\\) discrete. The treatment is similar to the above. If a random variable \\(X\\) takes values \\((x_{i},i\\geq1)\\) and \\(Y\\) takes values \\((y_{j},j\\geq1)\\), we have by definition that the conditional expectation as a random variable is:\n\\[\\begin{aligned}\n\\mathbb{E}[Y|X](\\omega) & =\\sum_{j\\geq1}y_{j}\\mathbb{P}(Y=y_{j}|X=x_{i})\\quad\\text{for }\\omega\\text{ such that }X(\\omega)=x_{i}\n\\end{aligned}\\] (2) \\((X,Y)\\) continuous with joint PDF \\(f_{X,Y}(x,y)\\): In this case, the conditional expectation is the random variable given by\n\\[\\begin{aligned}\n\\mathbb{E}[Y|X] & =h(X)\n\\end{aligned}\\]\nwhere\n\\[\\begin{aligned}\nh(x) & =\\int_{\\mathbf{R}}yf_{Y|X}(y|x)dy=\\int_{\\mathbf{R}}y\\frac{f_{X,Y}(x,y)}{f_{X}(x)}dy=\\frac{\\int_{\\mathbf{R}}yf_{X,Y}(x,y)dy}{\\int_{\\mathbf{R}}f_{X,Y}(x,y)dy}\n\\end{aligned}\\]\n\nIn the two examples above, the expectation of the random variable \\(\\mathbb{E}[Y|X]\\) is equal to \\(\\mathbb{E}[Y]\\). Indeed in the discrete case, we have:\n\\[\\begin{aligned}\n\\mathbb{E}[\\mathbb{E}[Y|X]] & =\\sum_{i=0}^{1}P(X=x_{i})\\cdot\\sum_{j=0}^{2}y_{j}\\mathbb{P}(Y=y_{j}|X=x_{i})\\\\\n& =\\sum_{i=0}^{1}\\sum_{j=0}^{2}y_{j}\\mathbb{P}(Y=y_{j},X=x_{i})\\\\\n& =\\sum_{j=0}^{2}y_{j}\\mathbb{P}(Y=y_{j})\\\\\n& =\\mathbb{E}[Y]\n\\end{aligned}\\]\n\n(Conditional Probability vs Conditional expectation). The conditional probability of the event \\(A\\) given \\(B\\) can be recast in terms of conditional expectation using indicator functions. If \\(0&lt;\\mathbb{P}(B)&lt;1\\), it is not hard to check that: \\(\\mathbb{P}(A|B)=\\mathbb{E}[\\mathbf{1}_{A}|\\mathbf{1}_{B}=1]\\) and \\(\\mathbb{P}(A|B^{C})=\\mathbb{E}[\\mathbf{1}_{A}|1_{B}=0]\\). Indeed the random variables \\(\\mathbf{1}_{A}\\) and \\(\\mathbf{1}_{B}\\) are discrete. If we proceed as in the discrete case above, we have:\n\\[\\begin{aligned}\n\\mathbb{E}[\\mathbf{1}_{A}|\\mathbf{1}_{B}=1] & =1\\cdot\\mathbb{P}(\\mathbf{1}_{A}=1|\\mathbf{1}_{B}=1)\\\\\n& =\\frac{\\mathbb{P}(\\mathbf{1}_{A}=1,\\mathbf{1}_{B}=1)}{\\mathbb{P}(\\mathbf{1}_{B}=1)}\\\\\n& =\\frac{\\mathbb{P}(A\\cap B)}{\\mathbb{P}(B)}\\\\\n& =\\mathbb{P}(A|B)\n\\end{aligned}\\]\nA similar calculation gives \\(\\mathbb{P}(A|B^{C})\\). In particular, the formula for total probability for \\(A\\) is a rewriting of the expectation of the random variable \\(\\mathbb{E}[\\mathbf{1}_{A}|\\mathbf{1}_{B}]\\):\n\\[\\begin{aligned}\n\\mathbb{E}[\\mathbb{E}[\\mathbf{1}_{A}|\\mathbf{1}_{B}]] & =\\mathbb{E}[\\mathbf{1}_{A}|\\mathbf{1}_{B}=1]\\mathbb{P}(\\mathbf{1}_{B}=1)+\\mathbb{E}[\\mathbf{1}_{A}|\\mathbf{1}_{B}=0]\\mathbb{P}(\\mathbf{1}_{B}=0)\\\\\n& =\\mathbb{P}(A|B)\\cdot\\mathbb{P}(B)+\\mathbb{P}(A|B^{C})\\cdot\\mathbb{P}(B^{C})\\\\\n& =\\mathbb{P}(A)\n\\end{aligned}\\]"
  },
  {
    "objectID": "posts/martingales/index.html#conditional-expectation-as-a-projection.",
    "href": "posts/martingales/index.html#conditional-expectation-as-a-projection.",
    "title": "Martingales",
    "section": "",
    "text": "We start by giving the definition of conditional expectation given a single variable. This relates to the two observations (A) and (B) made previously. We assume that the random variable is integrable for the expectations to be well-defined.\n\nLet \\(X\\) and \\(Y\\) be integrable random variables on \\((\\Omega,\\mathcal{F},\\mathbb{P})\\). The conditional expectation of \\(Y\\) given \\(X\\) is the random variable denoted by \\(\\mathbb{E}[Y|X]\\) with the following two properties:\n(A) There exists a function \\(h:\\mathbf{R}\\to\\mathbf{R}\\) such that \\(\\mathbb{E}[Y|X]=h(X)\\).\n(B) For any bounded random variable of the form \\(g(X)\\) for some function \\(g\\),\n\\[\\mathbb{E}[g(X)Y]=\\mathbb{E}[g(X)\\mathbb{E}[Y|X]]\\label{eq:definition-conditional-expectation}\\]\nWe can intepret the second property as follows. The conditional expectation \\(\\mathbb{E}[Y|X]\\) serves as a proxy for \\(Y\\) as far as \\(X\\) is concerned. Note that in equation ([eq:definition-conditional-expectation]), the expectation on the left can be seen as an average over the joint values of \\((X,Y)\\), whereas the one on the right is an average over the values of \\(X\\) only! Another way to see this property is to write is as:\n\\[\\mathbb{E}[g(X)(Y-\\mathbb{E}[Y|X])]=0\\]\nIn other words, the random variable \\(Y-\\mathbb{E}[Y|X]\\) is orthogonal to any random variable constructed from \\(X\\).\nFinally, it is important to notice that if we take \\(g(X)=1\\), then the second property implies :\n\\[\\begin{aligned}\n\\mathbb{E}[Y] & =\\mathbb{E}[\\mathbb{E}[Y|X]]\n\\end{aligned}\\]\nIn other words, the expectation of the conditional expectation of \\(Y\\) is simply the expectation of \\(Y\\).\nThe existence of the conditional expectation \\(\\mathbb{E}[Y|X]\\) is not obvious. We know, it exists in particular cases given in example ([ex:elementary-definitions-of-conditional-expectation]). We will show more generally, that it exists, it is unique whenever \\(Y\\) is in \\(L^{2}(\\Omega,\\mathcal{F},\\mathbb{P})\\) (In fact, it can be shown to exist whenever \\(Y\\) is integrable). Before doing so, let’s warm up by looking at the case of Gaussian vectors.\n\n\n(Conditional expectation of Gaussian vectors - I). Let \\((X,Y)\\) be a Gaussian vector of mean \\(0\\). Then:\n\\[\\mathbb{E}[Y|X]=\\frac{\\mathbb{E}[XY]}{\\mathbb{E}[X^{2}]}X\\label{eq:conditional-expectation-of-gaussian-vector}\\]\nThis candidate satisfies the two defining properties of conditional expectation : (A) It is clearly a function of \\(X\\); in fact it is a simple multiple of \\(X\\). (B) We have that the random variable \\(\\left(Y-\\frac{\\mathbb{E}[XY]}{\\mathbb{E}[X^{2}]}X\\right)\\) is orthogonal and thus independent to \\(X\\). This is a consequence of the proposition ([prop:diagonal-cov-matrix-implies-independence-of-gaussians]), since:\n\\[\\begin{aligned}\n\\mathbb{E}\\left[X\\left(Y-\\frac{\\mathbb{E}[XY]}{\\mathbb{E}[X^{2}]}X\\right)\\right] & =\\mathbb{E}XY-\\frac{\\mathbb{E}[XY]}{\\mathbb{E}[X^{2}]}\\mathbb{E}X^{2}\\\\\n& =\\mathbb{E}XY-\\frac{\\mathbb{E}[XY]}{\\cancel{\\mathbb{E}[X^{2}]}}\\cancel{\\mathbb{E}X^{2}}\\\\\n& =0\n\\end{aligned}\\]\nTherefore, we have for any bounded function \\(g(X)\\) of \\(X\\):\n\\[\\begin{aligned}\n\\mathbb{E}[g(X)(Y-\\mathbb{E}(Y|X))] & =\\mathbb{E}[g(X)]\\mathbb{E}[Y-\\mathbb{E}[Y|X]]=0\n\\end{aligned}\\]\n\n\n(Brownian conditioning-I) Let \\((B_{t},t\\geq0)\\) be a standard Brownian motion. Consider the Gaussian vector \\((B_{1/2},B_{1})\\). Its covariance matrix is:\n\\[\\begin{aligned}\nC & =\\left[\\begin{array}{cc}\n1/2 & 1/2\\\\\n1/2 & 1\n\\end{array}\\right]\n\\end{aligned}\\]\nLet’s compute \\(\\mathbb{E}[B_{1}|B_{1/2}]\\) and \\(\\mathbb{E}[B_{1/2}|B_{1}]\\). This is easy using the equation ([eq:conditional-expectation-of-gaussian-vector]). We have:\n\\[\\begin{aligned}\n\\mathbb{E}[B_{1}|B_{1/2}] & =\\frac{\\mathbb{E}[B_{1}B_{1/2}]}{\\mathbb{E}[B_{1/2}^{2}]}B_{1/2}\\\\\n& =\\frac{(1/2)}{(1/2)}B_{1/2}\\\\\n& =B_{1/2}\n\\end{aligned}\\]\nIn other words, the best approximation of \\(B_{1}\\) given the information of \\(B_{1/2}\\) is \\(B_{1/2}\\). There is no problem in computing \\(\\mathbb{E}[B_{1/2}|B_{1}]\\), even though we are conditioning on a future position. Indeed the same formula gives\n\\[\\begin{aligned}\n\\mathbb{E}[B_{1/2}|B_{1}] & =\\frac{\\mathbb{E}[B_{1}B_{1/2}]}{\\mathbb{E}[B_{1}^{2}]}B_{1}=\\frac{1}{2}B_{1}\n\\end{aligned}\\]\nThis means that the best approximation of \\(B_{1/2}\\) given the position at time \\(1\\), is \\(\\frac{1}{2}B_{1}\\) which makes a whole lot of sense!\n\nIn example ([eq:conditional-expectation-of-gaussian-vector]) for the Gaussian vector \\((X,Y)\\), the conditional expectation was equal to the orthogonal projection of \\(Y\\) onto \\(X\\) in \\(L^{2}\\). In particular, the conditional expectation was a multiple of \\(X\\). Is this always the case? Unfortunately, it is not. For example, in the equation ([eq:elementary-conditional-expectation-example]), the conditional expectation is clearly not a multiple of the random variable \\(X\\). However, it is a function of \\(X\\), as is always the case by definition ([def:conditional-expectation]).\nThe idea to construct the conditional expectation \\(\\mathbb{E}[Y|X]\\) in general is to project \\(Y\\) on the space of all random variables that can be constructed from \\(X\\). To make this precise, consider the following subspace of \\(L^{2}(\\Omega,\\mathcal{F},\\mathbb{P})\\) :\n\nLet \\((\\Omega,\\mathcal{F},\\mathbb{P})\\) be a probability space and \\(X\\) a random variable defined on it. The space \\(L^{2}(\\Omega,\\sigma(X),\\mathbb{P})\\) is the linear subspace of \\(L^{2}(\\Omega,\\mathcal{F},\\mathbb{P})\\) consisting of the square-integrable random variables of the form \\(g(X)\\) for some function \\(g:\\mathbf{R}\\to\\mathbf{R}\\).\n\nThis is a linear subspace of \\(L^{2}(\\Omega,\\mathcal{F},\\mathbb{P})\\): It contains the random variable \\(0\\), and any linear combination of random variables of this kind is also a function of \\(X\\) and must have a finite second moment. We note the following:\n\n\\(L^{2}(\\Omega,\\sigma(X),\\mathbb{P})\\) is a subspace of \\(L^{2}(\\Omega,\\mathcal{F},\\mathbb{P})\\), very much how a plane or line (going through the origin) is a subspace of \\(\\mathbf{R}^{3}\\).\nIn particular, as in the case of a line or a plane, we can project an element of \\(Y\\) of \\(L^{2}(\\Omega,\\mathcal{F},\\mathbb{P})\\) onto \\(L^{2}(\\Omega,\\sigma(X),\\mathbb{P})\\). The resulting projection is an element of \\(L^{2}(\\Omega,\\sigma(X),\\mathbb{P})\\), a square-integrable random-variable that is a function of \\(X\\). For a subspace \\(\\mathcal{S}\\) of \\(\\mathbf{R}^{3}\\) (e.g. a line or a plane), the projection of the vector \\(\\mathbf{v}\\in\\mathbf{R}^{3}\\) onto the subspace \\(\\mathcal{S}\\), denoted \\(\\text{Proj}_{\\mathcal{S}}(\\mathbf{v})\\) is the closest point to \\(\\mathbf{v}\\) lying in the subspace \\(\\mathcal{S}\\). Moreover, \\(\\mathbf{v}-\\text{Proj}_{\\mathcal{S}}(\\mathbf{v})\\) is orthogonal to the subspace. This picture of orthogonal projection also holds in \\(L^{2}\\). Let \\(Y\\) be a random variable in \\(L^{2}(\\Omega,\\mathcal{F},\\mathbb{P})\\) and let \\(L^{2}(\\Omega,\\sigma(X),\\mathbb{P})\\) be the subspace of those random variables that are functions of \\(X\\). We write \\(Y^{\\star}\\) for the random variable in \\(L^{2}(\\Omega,\\sigma(X),\\mathbb{P})\\) that is closest to \\(Y\\). In other words, we have (using the definition of the \\(L^{2}\\)-distance square):\n\\[\\inf_{Z\\in L^{2}(\\Omega,\\sigma(X),\\mathbb{P})}\\mathbb{E}[(Y-Z)^{2}]=\\mathbb{E}[(Y-Y^{\\star})^{2}]\\label{eq:Y-star-is-the-closest-to-Y-in-L2-sense}\\]\n\nIt turns out that \\(Y^{\\star}\\) is the right candidate for the conditional expectation.\n\nFigure. An illustration of the conditional expectation \\(\\mathbb{E}[Y|X]\\) as an orthogonal projection of \\(Y\\) onto the subspace \\(L^2(\\Omega,\\sigma(X),\\mathbb{P})\\).\n\n\n(Existence and uniqueness of the conditional expectation) Let \\(X\\) be a random variable on \\((\\Omega,\\mathcal{F},\\mathbb{P})\\). Let \\(Y\\) be a random variable in \\(L^{2}(\\Omega,\\mathcal{F},\\mathbb{P})\\). Then the conditional expectation \\(\\mathbb{E}[Y|X]\\) is the random variable \\(Y^{\\star}\\) given in the equation ([eq:Y-star-is-the-closest-to-Y-in-L2-sense]). Namely, it is the random variable in \\(L^{2}(\\Omega,\\sigma(X),\\mathbb{P})\\) that is closest to \\(Y\\) in the \\(L^{2}\\)-distance.\nIn particular we have the following:\n1) It is the orthogonal projection of \\(Y\\) onto \\(L^{2}(\\Omega,\\sigma(X),\\mathbb{P})\\), that is \\(Y-Y^{\\star}\\) is orthogonal to any random variables in the subspace \\(L^{2}(\\Omega,\\sigma(X),\\mathbb{P})\\).\n2) It is unique.\n\n\nThis result reinforces the meaning of the conditional expectation \\(\\mathbb{E}[Y|X]\\) as the best estimation of \\(Y\\) given the information of \\(X\\): it is the closest random variable to \\(Y\\) among all the functions of \\(X\\) in the sense of \\(L^{2}\\).\n\n\nProof. Proof. We write for short \\(L^{2}(X)\\) for the subspace \\(L^{2}(\\Omega,\\sigma(X),\\mathbb{P})\\). Let \\(Y^{\\star}\\) be as in equation ([eq:Y-star-is-the-closest-to-Y-in-L2-sense]). We show successively that (1) \\(Y-Y^{\\star}\\) is orthogonal to any element of \\(L^{2}(X)\\), so it is the orthogonal projection (2) \\(Y^{\\star}\\) has the properties of conditional expectation in definition ([eq:definition-conditional-expectation]) (3) \\(Y^{\\star}\\) is unique.\n(1) Let \\(W=g(X)\\) be a random variable in \\(L^{2}(X)\\). We show that \\(W\\) is orthogonal to \\(Y-Y^{\\star}\\); that is \\(\\mathbb{E}[(Y-Y^{\\star})W]=0\\). This should be intuitively clear from figure above. On the one hand, we have by developing the square:\n\\[\\begin{aligned}\n\\mathbb{E}[(W-(Y-Y^{\\star}))^{2}] & =\\mathbb{E}[W^{2}-2W(Y-Y^{\\star})+(Y-Y^{\\star})^{2}]\\nonumber \\\\\n& =\\mathbb{E}[W^{2}]-2\\mathbb{E}[W(Y-Y^{\\star})]+\\mathbb{E}(Y-Y^{\\star})^{2}]\\label{eq:developing-the-square}\n\\end{aligned}\\]\nOn the other hand, \\(Y^{\\star}+W\\) is an arbitrary vector in \\(L^{2}(X)\\)(it is a linear combination of the elements in \\(L^{2}(X)\\)), we must have from equation ([eq:Y-star-is-the-closest-to-Y-in-L2-sense]):\n\\[\\begin{aligned}\n\\mathbb{E}[(W-(Y-Y^{\\star}))^{2}] & =\\mathbb{E}[(Y-(Y^{\\star}+W))^{2}]\\nonumber \\\\\n& \\geq\\inf_{Z\\in L^{2}(X)}\\mathbb{E}[(Y-Z)^{2}]\\nonumber \\\\\n& =\\mathbb{E}[(Y-Y^{\\star})^{2}]\\label{eq:lower-bound}\n\\end{aligned}\\]\nPutting the last two equations ([eq:developing-the-square]), ([eq:lower-bound]) together, we get that for any \\(W\\in L^{2}(X)\\):\n\\[\\begin{aligned}\n\\mathbb{E}[W^{2}]-2\\mathbb{E}[W(Y-Y^{\\star})] & \\geq0\n\\end{aligned}\\]\nIn particular, this also holds for \\(aW\\), in which case we get:\n\\[\\begin{aligned}\na^{2}\\mathbb{E}[W^{2}]-2a\\mathbb{E}[W(Y-Y^{\\star})] & \\geq0\\\\\n\\implies a\\left\\{ a\\mathbb{E}[W^{2}]-2\\mathbb{E}[W(Y-Y^{\\star})]\\right\\}  & \\geq0\n\\end{aligned}\\]\nIf \\(a&gt;0\\), then:\n\\[a\\mathbb{E}[W^{2}]-2\\mathbb{E}[W(Y-Y^{\\star})]\\geq0\\label{eq:case-when-a-gt-zero}\\]\nwhereas if \\(a&lt;0\\), then the sign changes upon dividing throughout by \\(a\\), and we have:\n\\[a\\mathbb{E}[W^{2}]-2\\mathbb{E}[W(Y-Y^{\\star})]\\leq0\\label{eq:case-when-a-lt-zero}\\]\nRearranging ([eq:case-when-a-gt-zero]) yields:\n\\[\\mathbb{E}[W(Y-Y^{\\star})]\\leq a\\mathbb{E}[W^{2}]/2\\label{eq:case-when-a-gt-zero-rearranged}\\]\nRearranging ([eq:case-when-a-lt-zero]) yields:\n\\[\\mathbb{E}[W(Y-Y^{\\star})]\\geq a\\mathbb{E}[W^{2}]/2\\label{eq:case-when-a-lt-zero-rearranged}\\]\nSince ([eq:case-when-a-gt-zero-rearranged]) holds for all \\(a&gt;0\\), the stronger inequality, \\(\\mathbb{E}[W(Y-Y^{\\star})]\\leq0\\) must hold. Since, ([eq:case-when-a-lt-zero-rearranged]) holds for all \\(a&lt;0\\), the stronger inequality \\(\\mathbb{E}[W(Y-Y^{\\star})]\\geq0\\) must hold. Consequently,\n\\[\\mathbb{E}[W(Y-Y^{\\star})]=0\\]\n(2) It is clear that \\(Y^{\\star}\\) is a function of \\(X\\) by construction, since it is in \\(L^{2}(X)\\). Moreover, for any \\(W\\in L^{2}(X)\\), we have from (1) that:\n\\[\\begin{aligned}\n\\mathbb{E}[W(Y-Y^{\\star})] & =0\n\\end{aligned}\\]\nwhich is the second defining property of conditional expectations.\n(3) Lastly, suppose there is another element \\(Y'\\) that is in \\(L^{2}(X)\\) that minimizes the distance to \\(Y\\). Then we would get:\n\\[\\begin{aligned}\n\\mathbb{E}[(Y-Y')^{2}] & =\\mathbb{E}[(Y-Y^{\\star}+Y^{\\star}-Y')^{2}]\\\\\n& =\\mathbb{E}[(Y-Y^{\\star})^{2}]+2\\mathbb{E}[(Y-Y^{\\star})(Y^{\\star}-Y')]+\\mathbb{E}[(Y^{\\star}-Y')^{2}]\\\\\n& =\\mathbb{E}[(Y-Y^{\\star})^{2}]+0+\\mathbb{E}[(Y^{\\star}-Y')^{2}]\\\\\n& \\quad\\left\\{ (Y^{\\star}-Y')\\in L^{2}(X)\\perp(Y-Y^{\\star})\\right\\}\n\\end{aligned}\\]\nwhere we used the fact, that \\(Y^{\\star}-Y'\\) is a vector in \\(L^{2}(X)\\) and the orthogonality of \\(Y-Y^{\\star}\\) with \\(L^{2}(X)\\) as in (1). But, this implies that:\n\\[\\begin{aligned}\n\\cancel{\\mathbb{E}[(Y-Y')^{2}]} & =\\cancel{\\mathbb{E}[(Y-Y^{\\star})^{2}]}+\\mathbb{E}[(Y^{\\star}-Y')^{2}]\\\\\n\\mathbb{E}[(Y^{\\star}-Y')^{2}] & =0\n\\end{aligned}\\]\nSo, \\(Y^{\\star}=Y'\\) almost surely. ◻\n\n\nConditional Expectation of continuous random variables. Let \\((X,Y)\\) be two random variables with joint density \\(f_{X,Y}(x,y)\\) on \\(\\mathbf{R}^{2}\\). Suppose for simplicity, that \\(\\int_{\\mathbf{R}}f(x,y)dx&gt;0\\) for every \\(y\\) belonging to \\(\\mathbf{R}\\). Show that the conditional expectation \\(\\mathbf{E}[Y|X]\\) equals \\(h(X)\\) where \\(h\\) is the function:\n\\[\\begin{aligned}\nh(x) & =\\frac{\\int_{\\mathbf{R}}yf_{X,Y}(x,y)dy}{\\int_{\\mathbf{R}}f_{X,Y}(x,y)dy}\\label{eq:conditional-expectation-of-continuous-random-variables}\n\\end{aligned}\\]\nIn particular, verify that \\(\\mathbf{E}[\\mathbf{E}[Y|X]]=\\mathbf{E}[Y]\\).\nHint: To prove this, verify that the above formula satisfies both the properties of conditional expectations; then invoke uniqueness to finish it off.\n\n\n(i) The density function \\(f_{X,Y}(x,y)\\) is a map \\(f:\\mathbf{R}^{2}\\to\\mathbf{R}\\). The integral \\(\\int_{y=-\\infty}^{y=+\\infty}yf_{X,Y}(x_{0},y)dy\\) is the area under the curve \\(yf(x,y)\\) at the point \\(x=x_{0}\\). Let’s call it \\(A(x_{0})\\). If instead, we have an arbitrary \\(x\\), \\(\\int_{y=-\\infty}^{y=+\\infty}yf_{X,Y}(x,y)dy\\) represents the area \\(A(x)\\) of an arbitrary slice of the surface \\(yf_{X,Y}\\) at the point \\(x\\). Hence, it is a function of \\(x\\). The denominator \\(\\int_{\\mathbf{R}}f_{X,Y}(x,y)dy=f_{X}(x)\\), the density of \\(X\\), which is a function of \\(x\\). Hence, the ratio is a function of \\(x\\).\n(ii) Let \\(g(X)\\) is a bounded random variable. We have:\n\\[\\begin{aligned}\n\\mathbf{E}[g(X)(Y-h(X))] & =\\mathbf{E}[Yg(X)]-\\mathbf{E}[g(X)h(X)]\\\\\n& =\\int\\int_{\\mathbf{R}^{2}}yg(x)f_{X,Y}(x,y)dydx-\\int_{\\mathbf{R}}g(x)h(x)f(x)dx\\\\\n& =\\int\\int_{\\mathbf{R}^{2}}yg(x)f_{X,Y}(x,y)dydx\\\\\n& -\\int_{\\mathbf{R}}\\begin{array}{c}\ng(x)\\cdot\\frac{\\int_{\\mathbf{R}}yf_{X,Y}(x,y)dy}{\\int_{\\mathbf{R}}f_{X,Y}(x,y)dy}\\end{array}\\cdot\\int_{\\mathbf{R}}f_{X,Y}(x,y)dy\\ dx\\\\\n& =\\int\\int_{\\mathbf{R}^{2}}yg(x)f_{X,Y}(x,y)dydx\\\\\n& -\\int_{\\mathbf{R}}\\begin{array}{c}\ng(x)\\cdot\\frac{\\int_{\\mathbf{R}}yf_{X,Y}(x,y)dy}{\\cancel{\\int_{\\mathbf{R}}f_{X,Y}(x,y)dy}}\\end{array}\\cdot\\cancel{\\int_{\\mathbf{R}}f_{X,Y}(x,y)dy}\\ dx\\\\\n& =\\int\\int_{\\mathbf{R}^{2}}yg(x)f_{X,Y}(x,y)dydx-\\int_{\\mathbf{R}^{2}}yg(x)f_{X,Y}(x,y)\\cdot dx\\cdot dy\\\\\n& =0\n\\end{aligned}\\]\n\nThus, \\(h(X)\\) is a valid candidate for the conditional expectation \\(\\mathbf{E}[Y|X]\\). Moreover, by the existence and uniqueness theorem ([th:existence-and-uniqueness-of-the-conditional-expectation]), \\(\\mathbf{E}[Y|X]\\) is unique and equals \\(h(X)\\).\n\n\n\nWe would like to generalize the conditional expectation to the case when we condition on the information of more than one random variable. Taking the \\(L^{2}\\) point of view, we should expect that the conditional expectation is the orthogonal projection of the given random variable on the subspace generated by square integrable functions of all the variables on which we condition.\nIt is now useful to study sigma-fields, an object that was defined in chapter 1.\n\n(Sigma-Field) A sigma-field or sigma-algebra \\(\\mathcal{F}\\) of a sample space \\(\\Omega\\) is a collection of all measurable events with the following properties:\n(1) \\(\\Omega\\) is in \\(\\mathcal{F}\\).\n(2) Closure under complement. If \\(A\\in\\mathcal{F}\\), then \\(A^{C}\\in\\mathcal{F}\\).\n(3) Closure under countable unions. If \\(A_{1},A_{2},\\ldots,\\in\\mathcal{F}\\), then \\(\\bigcup_{n=1}^{\\infty}A_{n}\\in\\mathcal{F}\\).\n\nSuch objects play a fundamental role in the rigorous study of probability and real analysis in general. We will focus on the intuition behind them. First let’s mention some examples of sigma-fields of a given sample space \\(\\Omega\\) to get acquainted with the concept.\n\n(Examples of sigma-fields).\n(1) The trivial sigma-field. Note that the collection of events \\(\\{\\emptyset,\\Omega\\}\\) is a sigma-field of \\(\\Omega\\). We generally denote it by \\(\\mathcal{F}_{0}\\).\n(2) The \\(\\sigma\\)-field generated by an event \\(A\\). Let \\(A\\) be an event that is not \\(\\emptyset\\) and not the entire \\(\\Omega\\). Then the smallest sigma-field containing \\(A\\) ought to be:\n\\[\\begin{aligned}\n\\mathcal{F}_{1} & =\\{\\emptyset,A,A^{C},\\Omega\\}\n\\end{aligned}\\]\nThis sigma-field is denoted by \\(\\sigma(A)\\).\n(3) The sigma-field generated by a random variable \\(X\\).\nWe now define the \\(\\mathcal{F}_{X}\\) as follows:\n\\[\\begin{aligned}\n\\mathcal{F}_{X} & =X^{-1}(\\mathcal{B}):=\\{\\omega:X(\\omega)\\in B\\},\\forall B\\in\\mathcal{B}(\\mathbf{R})\n\\end{aligned}\\]\nwhere \\(\\mathcal{B}\\) is the Borel \\(\\sigma\\)-algebra on \\(\\mathbf{R}\\). \\(\\mathcal{F}_{X}\\) is sometimes denoted as \\(\\sigma(X)\\). \\(\\mathcal{F}_{X}\\)is the set of all events pertaining to \\(X\\). It is a sigma-algebra because:\n(i) \\(\\Omega\\in\\sigma(X)\\) because \\(\\Omega=\\{\\omega:X(\\omega)\\in\\mathbf{R}\\}\\) and \\(\\mathbf{R}\\in\\mathcal{B}(\\mathbf{R})\\).\n(ii) Let any event \\(C\\in\\sigma(X)\\). We need to show that \\(\\Omega\\setminus C\\in\\sigma(X)\\).\nSince \\(C\\in\\sigma(X)\\), there exists \\(A\\in\\mathcal{B}(\\mathbf{R})\\), such that:\n\\[\\begin{aligned}\nC & =\\{\\omega\\in\\Omega:X(\\omega)\\in A\\}\n\\end{aligned}\\]\nNow, we calculate:\n\\[\\begin{aligned}\n\\Omega\\setminus C & =\\{\\omega\\in\\Omega:X(\\omega)\\in\\mathbf{R}\\setminus A\\}\n\\end{aligned}\\]\nSince \\(\\mathcal{B}(\\mathbf{R})\\) is a sigma-algebra, it is closed under complementation. Hence, if \\(A\\in\\mathcal{B}(\\mathbf{R})\\), it implies that \\(\\mathbf{R}\\setminus A\\in\\mathcal{B}(\\mathbf{R})\\). So, \\(\\Omega\\setminus C\\in\\sigma(X)\\).\n(iii) Consider a sequence of events \\(C_{1},C_{2},\\ldots,C_{n},\\ldots\\in\\sigma(X)\\). We need to prove that \\(\\bigcup_{n=1}^{\\infty}C_{n}\\in\\sigma(X)\\).\nSince \\(C_{n}\\in\\sigma(X)\\), there exists \\(A_{n}\\in\\mathcal{B}(\\mathbf{R})\\) such that:\n\\[\\begin{aligned}\nC_{n} & =\\{\\omega\\in\\Omega:X(\\omega)\\in A_{n}\\}\n\\end{aligned}\\]\nNow, we calculuate:\n\\[\\begin{aligned}\n\\bigcup_{n=1}C_{n} & =\\{\\omega\\in\\Omega:X(\\omega)\\in\\bigcup_{n=1}^{\\infty}A_{n}\\}\n\\end{aligned}\\]\nBut, \\(\\bigcup_{n=1}^{\\infty}A_{n}\\in\\mathcal{B}(\\mathbf{R})\\). So, \\(\\bigcup_{n=1}^{\\infty}C_{n}\\in\\sigma(X)\\).\nConsequently, \\(\\sigma(X)\\) is indeed a \\(\\sigma\\)-algebra.\nIntuitively, we think of \\(\\sigma(X)\\) as containing all information about \\(X\\).\n(4) The sigma-field generated by a stochastic process \\((X_{s},s\\leq t)\\). Let \\((X_{s},s\\geq0)\\) be a stochastic process. Consider the process restricted to \\([0,t]\\), \\((X_{s},s\\leq t)\\). We consider the smallest sigma-field containing all events pertaining to the random variables \\(X_{s},s\\leq t\\). We denote it by \\(\\sigma(X_{s},s\\leq t)\\) or \\(\\mathcal{F}_{t}\\).\n\nThe sigma-fields on \\(\\Omega\\) have a natural (partial) ordering: two sigma-fields \\(\\mathcal{G}\\) and \\(\\mathcal{F}\\) of \\(\\Omega\\) are such that \\(\\mathcal{G}\\subseteq\\mathcal{F}\\) if all the events in \\(\\mathcal{G}\\) are in \\(\\mathcal{F}\\). For example, the trivial \\(\\sigma\\)-field \\(\\mathcal{F}_{0}=\\{\\emptyset,\\Omega\\}\\) is contained in all the \\(\\sigma\\)-fields of \\(\\Omega\\). Clearly, the \\(\\sigma\\)-field \\(\\mathcal{F}_{t}=\\sigma(X_{s},s\\leq t)\\) is contained in \\(\\mathcal{F}_{t'}\\) if \\(t\\leq t'\\).\nIf all the events pertaining to a random variable \\(X\\) are in the \\(\\sigma\\)-field \\(\\mathcal{G}\\) (and thus we can compute \\(\\mu(X^{-1}((a,b]))\\)), we will say that \\(X\\) is \\(\\mathcal{G}\\)-measurable. This means that all information about \\(X\\) is contained in \\(\\mathcal{G}\\).\n\nLet \\(X\\) be a random variable defined on \\((\\Omega,\\mathcal{F},\\mathbb{P})\\). Consider another \\(\\mathcal{G}\\subseteq\\mathcal{F}\\). Then \\(X\\) is said to be \\(\\mathcal{G}\\)-measurable, if and only if:\n\\[\\begin{aligned}\n\\{\\omega:X(\\omega)\\in(a,b]\\} & \\in\\mathcal{G}\\text{ for all intervals }(a,b]\\in\\mathbf{R}\n\\end{aligned}\\]\n\n\n(\\(\\mathcal{F}_{0}\\)-measurable random variables). Consider the trivial sigma-field \\(\\mathcal{F}_{0}=\\{\\emptyset,\\Omega\\}\\). A random variable that is \\(\\mathcal{F}_{0}\\)-measurable must be a constant. Indeed, we have that for any interval \\((a,b]\\), \\(\\{\\omega:X(\\omega)\\in(a,b]\\}=\\emptyset\\) or \\(\\{\\omega:X(\\omega)\\in(a,b]\\}=\\Omega\\). This can only hold if \\(X\\) takes a single value.\n\n\n[]{#ex:sigma(X)-measurable-random-variables-example label=“ex:sigma(X)-measurable-random-variables-example”}(\\(\\sigma(X)\\)-measurable random variables). Let \\(X\\) be a given random variable on \\((\\Omega,\\mathcal{F},\\mathbb{P})\\). Roughly speaking, a \\(\\sigma(X)\\)-measurable random variable is determined by the information of \\(X\\) only. Here is the simplest example of a \\(\\sigma(X)\\)-measurable random variable. Take the indicator function \\(Y=\\mathbf{1}_{\\{X\\in B\\}}\\) for some event \\(\\{X\\in B\\}\\) pertaining to \\(X\\). Then the pre-images \\(\\{\\omega:Y(\\omega)\\in(a,b]\\}\\) are either \\(\\emptyset\\), \\(\\{X\\in B\\}\\), \\(\\{X\\in B^{C}\\}\\) or \\(\\Omega\\) depending on whether \\(0,1\\) are in \\((a,b]\\) or not. All of these events are in \\(\\sigma(X)\\). More generally, one can construct a \\(\\sigma(X)\\)-measurable random variable by taking linear combinations of indicator functions of events of the form \\(\\{X\\in B\\}\\).\nIt turns out that any (Borel measurable) function of \\(X\\) can be approximated by taking limits of such simple functions.\nConcretely, this translates to the following statement:\n\\[\\text{If }Y\\text{ is \\ensuremath{\\sigma}(X)-measurable, then Y=g(X) for some function g}\\]\nIn the same way, if \\(Z\\) is \\(\\sigma(X,Y)\\)-measurable, then \\(Z=h(X,Y)\\) for some \\(h\\). These facts can be proved rigorously using measure theory.\n\nWe are ready to give the general definition of conditional expectation.\n\n(Coin-Tossing Space). Suppose a coin is tossed infinitely many times. Let \\(\\Omega\\) be the set of all infinite sequences of \\(H\\)s and \\(T\\)s. A generic element of \\(\\Omega\\) is denoted by \\(\\omega_{1}\\omega_{2}\\ldots\\), where \\(\\omega_{n}\\) indicates the result of the \\(n\\)th coin toss. \\(\\Omega\\) is an uncountable sample space. The trivial sigma-field \\(\\mathcal{F}_{0}=\\{\\emptyset,\\Omega\\}\\). Assume that we don’t know anything about the outcome of the experiement. Even without any information, we know that the true \\(\\omega\\) belongs to \\(\\Omega\\) and does not belong to \\(\\emptyset\\). It is the information learned at time \\(0\\).\nNext, assume that we know the outcome of the first coin toss. Define \\(A_{H}=\\{\\omega:\\omega_{1}=H\\}\\)=set of all sequences beginning with \\(H\\) and \\(A_{T}=\\{\\omega:\\omega_{1}=T\\}\\)=set of all sequences beginning with \\(T\\). The four sets resolved by the first coin-toss form the the \\(\\sigma\\)-field \\(\\mathcal{F}_{1}=\\{\\emptyset,A_{H},A_{T},\\Omega\\}\\). We shall think of this \\(\\sigma\\)-field as containing the information learned by knowing the outcome of the first coin toss. More precisely, if instead of being told about the first coin toss, we are told for each set in \\(\\mathcal{F}_{1}\\), whether or not the true \\(\\omega\\) belongs to that set, then we know the outcome of the first coin toss and nothing more.\nIf we are told the first two coin tosses, we obtain a finer resolution. In particular, the four sets:\n\\[\\begin{aligned}\nA_{HH} & =\\{\\omega:\\omega_{1}=H,\\omega_{2}=H\\}\\\\\nA_{HT} & =\\{\\omega:\\omega_{1}=H,\\omega_{2}=T\\}\\\\\nA_{TH} & =\\{\\omega:\\omega_{1}=T,\\omega_{2}=H\\}\\\\\nA_{TT} & =\\{\\omega:\\omega_{1}=T,\\omega_{2}=T\\}\n\\end{aligned}\\]\nare resolved. Of course, the sets in \\(\\mathcal{F}_{1}\\) are resolved. Whenever a set is resolved, so is its complement, which means that \\(A_{HH}^{C}\\), \\(A_{HT}^{C}\\), \\(A_{TH}^{C}\\) and \\(A_{TT}^{C}\\) are resolved, so is their union which means that \\(A_{HH}\\cup A_{TH}\\), \\(A_{HH}\\cup A_{TT}\\), \\(A_{HT}\\cup A_{TH}\\) and \\(A_{HT}\\cup A_{TT}\\) are resolved. The other two pair-wise unions \\(A_{HH}\\cup A_{HT}=A_{H}\\) and \\(A_{TH}\\cup A_{TT}=A_{T}\\) are already resolved. Finally, the triple unions are also resolved, because \\(A_{HH}\\cup A_{HT}\\cup A_{TH}=A_{TT}^{C}\\) and so forth. Hence, the information pertaining to the second coin-toss is contained in:\n\\[\\begin{aligned}\n\\mathcal{F}_{2} & =\\{\\emptyset,\\Omega,\\\\\n& A_{H},A_{T},\\\\\n& A_{HH},A_{HT},A_{TH},A_{TT},\\\\\n& A_{HH}^{C},A_{HT}^{C},A_{TH}^{C},A_{TT}^{C},\\\\\n& A_{HH}\\cup A_{TH},A_{HH}\\cup A_{TT},A_{HT}\\cup A_{TH},A_{HT}\\cup A_{TT}\\}\n\\end{aligned}\\]\nHence, if the outcome of the first two coin tosses is known, all of the events in \\(\\mathcal{F}_{2}\\) are resolved - we exactly know, if each event has ocurred or not. \\(\\mathcal{F}_{2}\\) is the information learned by observing the first two coin tosses.\n\n\n(Exercises on sigma-fields).\n(a) Let \\(A\\), \\(B\\) be two proper subsets of \\(\\Omega\\) such that \\(A\\cap B\\neq\\emptyset\\) and \\(A\\cup B\\neq\\Omega\\). Write down \\(\\sigma(\\{A,B\\})\\), the smallest sigma-field containing \\(A\\) and \\(B\\) explicitly. What if \\(A\\cap B=\\emptyset\\)?\n(b) The Borel sigma-field is the smallest sigma-field containing intervals of the form \\((a,b]\\) in \\(\\mathbf{R}\\). Show that all singletons \\(\\{b\\}\\) are in \\(\\mathcal{B}(\\mathbf{R})\\) by writing \\(\\{b\\}\\) as a countable intersection of intervals \\((a,b]\\). Conclude that all open intervals \\((a,b)\\) and all closed intervals \\([a,b]\\) are in \\(\\mathcal{B}(\\mathbf{R})\\). Is the subset \\(\\mathbf{Q}\\) of rational numbers a Borel set?\n\n\nProof. Proof. (a) The sigma-field generated by the two events \\(A\\), \\(B\\) is given by:\n\\[\\begin{aligned}\n\\sigma(\\{A,B\\}) & =\\{\\emptyset,\\Omega,\\\\\n& A,B,A^{C},B^{C},\\\\\n& A\\cup B,A\\cap B,\\\\\n& A\\cup B^{C},A^{C}\\cup B,A^{C}\\cup B^{C},\\\\\n& A\\cap B^{C},A^{C}\\cap B,A^{C}\\cap B^{C},\\\\\n& (A\\cup B)\\cap(A\\cap B)^{C},\\\\\n& (A\\cup B)^{C}\\cup(A\\cap B)\\}\n\\end{aligned}\\]\n(b) Firstly, recall that:\n\\[\\begin{aligned}\n\\mathcal{B}(\\mathbf{R}) & =\\bigcap_{\\alpha\\in\\Lambda}\\mathcal{F}_{\\alpha}=\\bigcap\\sigma(\\{I:I\\text{ is an interval }(a,b]\\subseteq\\mathbf{R}\\})\n\\end{aligned}\\]\nWe can write:\n\\[\\begin{aligned}\n\\{b\\} & =\\bigcap_{n=1}^{\\infty}\\left(b-\\frac{1}{n},b\\right]\n\\end{aligned}\\]\nAs \\(\\mathcal{B}(\\mathbf{R})\\) is a sigma-field, it is closed under countable intersections. Hence, the singleton set \\(\\{b\\}\\)is a Borel set.\nSimilarly, we can write, any open interval as the countable union:\n\\[\\begin{aligned}\n(a,b) & =\\bigcup_{n=1}^{\\infty}\\left(a,b-\\frac{1}{n}\\right]\n\\end{aligned}\\]\nWe can convince ourselves, that equality indeed holds. Let \\(x\\in(a,b)\\) and choose \\(N\\), such that \\(\\frac{1}{N}&lt;|b-x|\\). Then, for all \\(n\\geq N\\), \\(x\\in(a,b-1/n]\\). Thus, it belongs to the RHS. In the reverse direction, let \\(x\\) belong to \\(\\bigcup_{n=1}^{\\infty}\\left(a,b-\\frac{1}{n}\\right]\\). So, \\(x\\) belongs to atleast one of these sets. Therefore, \\(x\\in(a,b)\\) is trivially true. So, the two sets are equal.\nHence, open intervals are Borel sets.\nSimilarly, we may write:\n\\[\\begin{aligned}\n[a,b] & =\\bigcap_{n=1}^{\\infty}\\left(a-\\frac{1}{n},b+\\frac{1}{n}\\right)\n\\end{aligned}\\]\nConsequently, closed intervals are Borel sets. Since \\(\\mathbf{Q}\\) is countable, it is a Borel set. Moreover, the empty set \\(\\emptyset\\) and \\(\\mathbf{R}\\) are Borel sets. So, \\(\\mathbf{R}\\backslash\\mathbf{Q}\\) is also a Borel set. ◻\n\n\nLet \\((X,Y)\\) be a Gaussian vector with mean \\(0\\) and covariance matrix\n\\[\\begin{aligned}\nC & =\\left[\\begin{array}{cc}\n1 & \\rho\\\\\n\\rho & 1\n\\end{array}\\right]\n\\end{aligned}\\]\nfor \\(\\rho\\in(-1,1)\\). We verify that the example ([ex:conditional-expectation-of-gaussian-vectors]) and exercise ([ex:=00005BArguin-4.1=00005D-Conditional-Expectation-of-continuous-random-variables]) yield the same conditional expectation.\n(a) Use equation ([eq:conditional-expectation-of-gaussian-vector]) to show that \\(\\mathbf{E}[Y|X]=\\rho X\\).\n(b) Write down the joint PDF \\(f(x,y)\\) of \\((X,Y)\\).\n(c) Show that \\(\\int_{\\mathbf{R}}yf(x,y)dy=\\rho x\\) and that \\(\\int_{\\mathbf{R}}f(x,y)dy=1\\).\n(d) Deduce that \\(\\mathbf{E}[Y|X]=\\rho X\\) using the equation ([eq:conditional-expectation-of-continuous-random-variables]).\n\n\nProof. Proof. (a) Since \\((X,Y)\\) have mean \\(0\\) and variance \\(1\\), it follows that:\n\\[\\begin{aligned}\n\\mathbf{E}[(X-EX)(Y-EY)] & =\\mathbf{E}(XY)\\\\\n\\sqrt{(\\mathbf{E}[X^{2}]-(\\mathbf{E}X)^{2})}\\cdot\\sqrt{(\\mathbf{E}[Y^{2}]-(\\mathbf{E}Y)^{2})} & =\\sqrt{(1-0)(1-0)}\\\\\n& =1\n\\end{aligned}\\]\nand therefore,\n\\[\\begin{aligned}\n\\rho & =\\frac{\\mathbf{E}(XY)}{1}=\\frac{\\mathbf{E}[XY]}{\\mathbf{E}[X^{2}]}\n\\end{aligned}\\]\nSince \\((X,Y)\\) is a Gaussian vector, using ([eq:conditional-expectation-of-gaussian-vector]), we have:\n\\[\\begin{aligned}\n\\mathbf{E}[Y|X] & =\\frac{\\mathbf{E}[XY]}{\\mathbf{E}[X^{2}]}X=\\rho X\n\\end{aligned}\\]\n(b) Consider the augmented matrix \\([C|I]\\). We have:\n\\[\\begin{aligned}\n[C|I] & =\\left[\\left.\\begin{array}{cc}\n1 & \\rho\\\\\n\\rho & 1\n\\end{array}\\right|\\begin{array}{cc}\n1 & 0\\\\\n0 & 1\n\\end{array}\\right]\n\\end{aligned}\\]\nPerforming \\(R_{2}=R_{2}-\\rho R_{1}\\), the above system is row-equivalent to:\n\\[\\left[\\left.\\begin{array}{cc}\n1 & \\rho\\\\\n0 & 1-\\rho^{2}\n\\end{array}\\right|\\begin{array}{cc}\n1 & 0\\\\\n-\\rho & 1\n\\end{array}\\right]\\]\nPerforming \\(R_{2}=\\frac{1}{1-\\rho^{2}}R_{2}\\), the above system is row-equivalent to:\n\\[\\left[\\begin{array}{cc}\n1 & \\rho\\\\\n0 & 1\n\\end{array}\\left|\\begin{array}{cc}\n1 & 0\\\\\n\\frac{-\\rho}{1-\\rho^{2}} & \\frac{1}{1-\\rho^{2}}\n\\end{array}\\right.\\right]\\]\nPerforming \\(R_{1}=R_{1}-\\rho R_{2}\\), we have:\n\\[\\left[\\begin{array}{cc}\n1 & 0\\\\\n0 & 1\n\\end{array}\\left|\\begin{array}{cc}\n\\frac{1}{1-\\rho^{2}} & -\\frac{\\rho}{1-\\rho^{2}}\\\\\n\\frac{-\\rho}{1-\\rho^{2}} & \\frac{1}{1-\\rho^{2}}\n\\end{array}\\right.\\right]\\]\nThus, \\[\\begin{aligned}\nC^{-1} & =\\frac{1}{1-\\rho^{2}}\\left[\\begin{array}{cc}\n1 & -\\rho\\\\\n-\\rho & 1\n\\end{array}\\right]\n\\end{aligned}\\]\nMoreover, \\(\\det C=1-\\rho^{2}.\\)\nTherefore, the joint density of \\((X,Y)\\) is given by:\n\\[\\begin{aligned}\nf(x,y) & =\\frac{1}{2\\pi\\sqrt{1-\\rho^{2}}}\\exp\\left[-\\frac{1}{2(1-\\rho^{2})}\\left[\\begin{array}{cc}\nx & y\\end{array}\\right]\\left[\\begin{array}{cc}\n1 & -\\rho\\\\\n-\\rho & 1\n\\end{array}\\right]\\left[\\begin{array}{c}\nx\\\\\ny\n\\end{array}\\right]\\right]\\\\\n& =\\frac{1}{2\\pi\\sqrt{1-\\rho^{2}}}\\exp\\left[-\\frac{1}{2(1-\\rho^{2})}\\left[\\begin{array}{cc}\nx-\\rho y & -\\rho x+y\\end{array}\\right]\\left[\\begin{array}{c}\nx\\\\\ny\n\\end{array}\\right]\\right]\\\\\n& \\frac{1}{2\\pi\\sqrt{1-\\rho^{2}}}\\exp\\left[-\\frac{1}{2(1-\\rho^{2})}(x^{2}-2\\rho xy+y^{2})\\right]\n\\end{aligned}\\]\n(c) Claim I. \\(\\int_{\\mathbf{R}}yf(x,y)dy=\\rho x\\).\nCompleting the square, we have:\n\\[\\begin{aligned}\n(x^{2}-2\\rho xy+y^{2}) & =(y-\\rho x)^{2}+x^{2}(1-\\rho^{2})\n\\end{aligned}\\]\nThus, we can write:\n\\[\\begin{aligned}\n\\int_{\\mathbf{R}}yf(x,y)dy & =\\frac{1}{2\\pi\\sqrt{1-\\rho^{2}}}e^{-\\frac{1}{2}x^{2}}\\int_{\\mathbf{R}}ye^{-\\frac{1}{2}\\frac{(y-\\rho x)^{2}}{(1-\\rho^{2})}}dy\n\\end{aligned}\\]\nLet’s substitute\n\\[\\begin{aligned}\nz & =\\frac{(y-\\rho x)}{\\sqrt{1-\\rho^{2}}}\\\\\ndz & =\\frac{dy}{\\sqrt{1-\\rho^{2}}}\n\\end{aligned}\\]\nTherefore,\n\\[\\begin{aligned}\n\\int_{\\mathbf{R}}ye^{-\\frac{1}{2}\\frac{(y-\\rho x)^{2}}{(1-\\rho^{2})}}dy & =\\sqrt{1-\\rho^{2}}\\int_{\\mathbf{R}}(\\rho x+\\sqrt{1-\\rho^{2}}z)e^{-\\frac{z^{2}}{2}}dz\\\\\n& =\\rho x\\cdot\\sqrt{1-\\rho^{2}}\\int_{\\mathbf{R}}e^{-\\frac{z^{2}}{2}}dz+(1-\\rho^{2})\\int_{\\mathbf{R}}ze^{-\\frac{z^{2}}{2}}dz\\\\\n& =\\rho x\\cdot\\sqrt{1-\\rho^{2}}\\cdot\\sqrt{2\\pi}+(1-\\rho^{2})\\cdot0\\\\\n& =\\rho x\\cdot\\sqrt{1-\\rho^{2}}\\cdot\\sqrt{2\\pi}\n\\end{aligned}\\]\nConsequently,\n\\[\\begin{aligned}\n\\int_{\\mathbf{R}}yf(x,y)dy & =\\frac{1}{2\\pi\\cancel{\\sqrt{1-\\rho^{2}}}}e^{-\\frac{1}{2}x^{2}}\\rho x\\cdot\\cancel{\\sqrt{1-\\rho^{2}}}\\cdot\\sqrt{2\\pi}\\\\\n& =\\rho x\\cdot\\frac{1}{\\sqrt{2\\pi}}e^{-\\frac{1}{2}x^{2}}\\\\\n& =\\rho x\\cdot f_{X}(x)\\\\\n\\frac{\\int_{\\mathbf{R}}yf(x,y)dy}{f_{X}(x)} & =\\frac{\\int_{\\mathbf{R}}yf(x,y)dy}{\\int_{\\mathbf{R}}f(x,y)}=\\rho x\n\\end{aligned}\\]\n(d) For a Gaussian vector \\((X,Y),\\) the conditional expectation \\(\\mathbf{E}[Y|X]=h(X)\\). Hence, \\(\\mathbf{E}[Y|X]=\\rho X\\). ◻\n\n\n(Conditional Expectation) Let \\(Y\\) be an integrable random variable on \\((\\Omega,\\mathcal{F},\\mathbb{P})\\) and let \\(\\mathcal{G}\\subseteq\\mathcal{F}\\) be a sigma-field of \\(\\Omega\\). The conditional expectation of \\(Y\\) given \\(\\mathcal{G}\\) is the random variable denoted by \\(\\mathbb{E}[Y|\\mathcal{G}]\\) such that the following hold:\n(a) \\(\\mathbb{E}[Y|\\mathcal{G}]\\) is \\(\\mathcal{G}\\)-measurable.\nIn other words, all events pertaining to the random variable \\(\\mathbb{E}[Y|\\mathcal{G}]\\) are in \\(\\mathcal{G}\\).\n(b) For any (bounded) random variable \\(W\\), that is \\(\\mathcal{G}\\)-measurable,\n\\[\\begin{aligned}\n\\mathbb{E}[WY] & =\\mathbb{E}[W\\mathbb{E}[Y|\\mathcal{G}]]\n\\end{aligned}\\]\nIn other words, \\(\\mathbf{E}[Y|\\mathcal{G}]\\) is a proxy for \\(Y\\) as far as the events in \\(\\mathcal{G}\\) are concerned.\nNote that, by taking \\(W=1\\) in the property (B), we recover:\n\\[\\begin{aligned}\n\\mathbf{E}[\\mathbf{E}[Y|\\mathcal{G}]] & =\\mathbf{E}[Y]\n\\end{aligned}\\]\n\n\nBeware of the notation! If \\(\\mathcal{G}=\\sigma(X)\\), then the conditional expectation \\(\\mathbf{E}[Y|\\sigma(X)]\\) is usually denoted by \\(\\mathbf{E}[Y|X]\\) for short. However, one should always keep in mind that conditioning on \\(X\\) is in fact projecting on the linear subspace generated by all variables constructed from \\(X\\) and not on the linear space generated by generated by \\(X\\) alone. In the same way, the conditional expectation \\(\\mathbf{E}[Z|\\sigma(X,Y)]\\) is often written \\(\\mathbf{E}[Z|X,Y]\\) for short.\nAs expected, if \\(Y\\) is in \\(L^{2}(\\Omega,\\mathcal{F},\\mathbb{P})\\), then \\(\\mathbf{E}[Y|\\mathcal{G}]\\) is given by the orthogonal projection of \\(Y\\) onto the subspace \\(L^{2}(\\Omega,\\mathcal{G},\\mathbb{P})\\), the subspace of square integrable random variables that are \\(\\mathcal{G}\\)-measurable. We write \\(Y^{\\star}\\) for the random variable in \\(L^{2}(\\Omega,\\mathcal{G},\\mathbb{P})\\) that is closest to \\(Y\\) that is:\n\\[\\begin{aligned}\n\\min_{Z\\in L^{2}(\\Omega,\\mathcal{G},\\mathbb{P})}\\mathbf{E}[(Y-Z)^{2}] & =\\mathbf{E}[(Y-Y^{\\star})^{2}]\\label{eq:conditional-expectation}\n\\end{aligned}\\]\n\n\n(Existence and Uniqueness of Conditional Expectations) Let \\(\\mathcal{G}\\subset\\mathcal{F}\\) be a sigma-field of \\(\\Omega\\). Let \\(Y\\) be a random variable in \\(L^{2}(\\Omega,\\mathcal{F},\\mathbb{P})\\). Then, the conditional expectation \\(\\mathbf{E}[Y|\\mathcal{G}]\\) is the random variable \\(Y^{\\star}\\) given in the equation ([eq:conditional-expectation]). Namely, it is the random variable in \\(L^{2}(\\Omega,\\mathcal{G},\\mathbb{P})\\) that is closest to \\(Y\\) in the \\(L^{2}\\)-distance. In particular we have the following:\n\n\nIt is the orthogonal projection of \\(Y\\) onto \\(L^{2}(\\Omega,\\mathcal{G},\\mathbb{P})\\), that is, \\(Y-Y^{\\star}\\) is orthogonal to the random variables in \\(L^{2}(\\Omega,\\mathcal{G},\\mathbb{P})\\).\nIt is unique.\n\nAgain, the result should be interpreted as follows: The conditional expectation \\(\\mathbf{E}[Y|\\mathcal{G}]\\) is the best approximation of \\(Y\\) given the information included in \\(\\mathcal{G}\\).\n\nThe conditional expectation in fact exists and is unique for any integrable random variable \\(Y\\)(i.e. \\(Y\\in L^{1}(\\Omega,\\mathcal{F},\\mathbb{P})\\) as the definition suggests. However, there is no orthogonal projection in \\(L^{1}\\), so the intuitive geometric picture is lost.\n\n\nFigure. An illustration of the conditional expectation \\(\\mathbb{E}[Y|\\mathcal{G}]\\) as an orthogonal projection of \\(Y\\) onto the subspace \\(L^2(\\Omega,\\mathcal{G},\\mathbb{P})\\).\n\n\n(Conditional Expectation for Gaussian Vectors. II.) Consider the Gaussian vector \\((X_{1},\\ldots,X_{n})\\). Without loss of generality, suppose it has mean \\(0\\) and is non-degenerate. What is the best approximation of \\(X_{n}\\) given the information \\(X_{1},\\ldots,X_{n-1}\\)? In other words, what is:\n\\[\\mathbf{E}[X_{n}|\\sigma(X_{1},\\ldots,X_{n-1})\\]\nWith example ([ex:sigma(X)-measurable-random-variables-example]) in mind, let’s write \\(\\mathbf{E}[X_{n}|X_{1}\\ldots X_{n-1}]\\) for short. From example ([ex:=00005BArguin-4.1=00005D-Conditional-Expectation-of-continuous-random-variables]), we know that if \\((X,Y)\\) is a Gaussian vector with mean \\(0\\), then \\(\\mathbf{E}[Y|X]\\) is a multiple of \\(X\\). Thus, we expect, that \\(\\mathbf{E}[X_{n}|X_{1}X_{2}\\ldots X_{n-1}]\\) is a linear combination of \\(X_{1},X_{2},\\ldots,X_{n-1}\\). That is, there exists \\(a_{1},\\ldots,a_{n-1}\\) such that:\n\\[\\begin{aligned}\n\\mathbf{E}[X_{n}|X_{1}X_{2}\\ldots X_{n-1}] & =a_{1}X_{1}+a_{2}X_{2}+\\ldots+a_{n-1}X_{n-1}\n\\end{aligned}\\] In particular, since the conditional expectation is a linear combination of the \\(X\\)’s, it is itself a Gaussian random variable. The best way to find the coefficient \\(a\\)’s is to go back to IID decomposition of Gaussian vectors.\nLet \\((Z_{1},Z_{2},\\ldots,Z_{n-1})\\) be IID standard Gaussians constructed from the linear combination of \\((X_{1},X_{2},\\ldots,X_{n-1})\\). Then, we have:\n\\[\\begin{aligned}\n\\mathbf{E}[X_{n}|X_{1}X_{2}\\ldots X_{n-1}] & =b_{1}Z_{1}+\\ldots+b_{n-1}Z_{n-1}\n\\end{aligned}\\]\nNow, recall, that we construct the random variables \\(Z_{1}\\), \\(Z_{2}\\), \\(\\ldots\\), \\(Z_{n}\\) using Gram-Schmidt orthogonalization:\n\\[\\begin{aligned}\n\\tilde{Z_{1}} & =X_{1}, & Z_{1} & =\\frac{\\tilde{Z_{1}}}{\\mathbf{E}(\\tilde{Z}_{1}^{2})}\\\\\n\\tilde{Z_{2}} & =X_{2}-\\mathbf{E}(X_{2}Z_{1})Z_{1} & Z_{2} & =\\frac{\\tilde{Z}_{2}}{\\mathbf{E}(\\tilde{Z}_{2}^{2})}\\\\\n\\tilde{Z_{3}} & =X_{3}-\\sum_{i=1}^{2}\\mathbf{E}(X_{3}Z_{i})Z_{i} & Z_{3} & =\\frac{\\tilde{Z}_{3}}{\\mathbf{E}(\\tilde{Z}_{3}^{2})}\\\\\n& \\vdots\n\\end{aligned}\\]\n\nThe simple case for \\(n=2\\) random variables.\nWe have already seen before:\n\\[\\begin{aligned}\n\\mathbf{E}[X_{1}(X_{2}-\\mathbf{E}(X_{2}Z_{1})Z_{1})] & =\\mathbf{E}[\\tilde{Z}_{1}(X_{2}-\\mathbf{E}(X_{2}Z_{1})Z_{1})]\\\\\n& =\\frac{\\mathbf{E}[\\tilde{Z}_{1}^{2}]}{\\mathbf{E}[\\tilde{Z}_{1}^{2}]}\\times\\mathbf{E}\\left[\\tilde{Z}_{1}(X_{2}-\\mathbf{E}(X_{2}Z_{1})Z_{1})\\right]\\\\\n& =\\mathbf{E}[\\tilde{Z}_{1}^{2}]\\times\\mathbf{E}\\left[\\frac{\\tilde{Z}_{1}}{\\mathbf{E}[\\tilde{Z}_{1}^{2}]}(X_{2}-\\mathbf{E}(X_{2}Z_{1})Z_{1})\\right]\\\\\n& =\\mathbf{E}[\\tilde{Z}_{1}^{2}]\\times\\mathbf{E}[Z_{1}(X_{2}-\\mathbf{E}(X_{2}Z_{1})Z_{1})]\\\\\n& =\\mathbf{E}[\\tilde{Z}_{1}^{2}]\\times\\left(\\mathbf{E}[Z_{1}X_{2}]-\\mathbf{E}(X_{2}Z_{1})\\mathbf{E}[Z_{1}^{2}]\\right)\\\\\n& =0\n\\end{aligned}\\]\nSo,\\(X_{2}-\\mathbf{E}(X_{2}Z_{1})Z_{1}\\) is orthogonal to \\(X_{1}\\).\nMoreover, \\(\\mathbf{E}(X_{2}Z_{1})Z_{1}\\) is a function of \\(X_{1}\\). Thus, both the properties of conditional expectation are satisfied. Since conditional expectations are unique, we must have, \\(\\mathbf{E}[X_{2}|X_{1}]=\\mathbf{E}(X_{2}Z_{1})Z_{1}\\).\nThe case for \\(n=3\\) random variables.\nWe have seen that:\n\\[\\begin{aligned}\n\\mathbf{E}[X_{1}(X_{3}-\\mathbf{E}(X_{3}Z_{1})Z_{1}-\\mathbf{E}(X_{3}Z_{2})Z_{2})] & =\\frac{\\mathbf{E}[\\tilde{Z}_{1}^{2}]}{\\mathbf{E}[\\tilde{Z}_{1}^{2}]}\\times\\mathbf{E}[\\tilde{Z}_{1}(X_{3}-\\mathbf{E}(X_{3}Z_{1})Z_{1}-\\mathbf{E}(X_{3}Z_{2})Z_{2})]\\\\\n& =\\mathbf{E}[\\tilde{Z}_{1}^{2}]\\times\\mathbf{E}\\left\\{ \\frac{\\tilde{Z}_{1}}{\\mathbf{E}[\\tilde{Z}_{1}^{2}]}(X_{3}-\\mathbf{E}(X_{3}Z_{1})Z_{1}-\\mathbf{E}(X_{3}Z_{2})Z_{2})\\right\\} \\\\\n& =\\mathbf{E}[\\tilde{Z}_{1}^{2}]\\times\\mathbf{E}\\left\\{ Z_{1}(X_{3}-\\mathbf{E}(X_{3}Z_{1})Z_{1}-\\mathbf{E}(X_{3}Z_{2})Z_{2})\\right\\} \\\\\n& =\\mathbf{E}[\\tilde{Z}_{1}^{2}]\\times\\mathbf{E}[X_{3}Z_{1}]-\\mathbf{E}[X_{3}Z_{1}]\\mathbf{E}[Z_{1}^{2}]-\\mathbf{E}[X_{3}Z_{2}]\\mathbf{E}[Z_{1}Z_{2}]\\\\\n& =0\n\\end{aligned}\\]\nIt is an easy exercise to show that it is orthogonal to \\(X_{2}\\).\nHence, \\(X_{3}-\\mathbf{E}(X_{3}Z_{1})Z_{1}-\\mathbf{E}(X_{3}Z_{2})Z_{2}\\) is orthogonal to \\(X_{1}\\) and \\(X_{2}\\). Moreover, \\(\\mathbf{E}(X_{3}Z_{1})Z_{1}+\\mathbf{E}(X_{3}Z_{2})Z_{2}\\) is a function of \\(X_{1}\\), \\(X_{2}\\). Thus, we must have:\n\\[\\begin{aligned}\n\\mathbf{E}[X_{3}|X_{1}X_{2}] & =\\mathbf{E}(X_{3}Z_{1})Z_{1}+\\mathbf{E}(X_{3}Z_{2})Z_{2}\n\\end{aligned}\\]\nIn general, \\(X_{n}-\\sum_{i=1}^{n-1}\\mathbf{E}(X_{n}Z_{i})Z_{i}\\) is orthogonal to \\(X_{1}\\), \\(X_{2}\\), \\(\\ldots\\), \\(X_{n-1}\\). Hence,\n\\[\\begin{aligned}\n\\mathbf{E}[X_{n}|X_{1}X_{2}\\ldots X_{n-1}] & =\\sum_{i=1}^{n-1}\\mathbf{E}(X_{n}Z_{i})Z_{i}\n\\end{aligned}\\]\n\n\n\nWe now list the properties of conditional expectation that follow from the two defining properties (A), (B) in the definition. They are extremely useful, when doing explicit computations on martingales. A good way to remember them is to understand how they relate to the interpretation of conditional expectation as an orthogonal projection onto a subspace or, equivalently, as the best approximation of the variable given the information available.\n\nLet \\(Y\\) be an integrable random variable on \\((\\Omega,\\mathcal{F},\\mathbb{P})\\). Let \\(\\mathcal{G}\\subseteq\\mathcal{F}\\) be another sigma-field of \\(\\Omega\\). Then, the conditional expectation \\(\\mathbf{E}[Y|\\mathcal{G}]\\) has the following properties:\n(1) If \\(Y\\) is \\(\\mathcal{G}\\)-measurable, then :\n\\[\\begin{aligned}\n\\mathbf{E}[Y|\\mathcal{G}] & =Y\n\\end{aligned}\\]\n(2) Taking out what is known. More generally, if \\(Y\\) is \\(\\mathcal{G-}\\)measurable and \\(X\\) is another integrable random variable (with \\(XY\\) also integrable), then :\n\\[\\begin{aligned}\n\\mathbf{E}[XY|\\mathcal{G}] & =Y\\mathbf{E}[X|\\mathcal{G}]\n\\end{aligned}\\]\nThis makes sense, since \\(Y\\) is determined by \\(\\mathcal{G}\\), so we can take out what is known; it can be treated as a constant for the conditional expectation.\n(3) Independence. If \\(Y\\) is independent of \\(\\mathcal{G}\\), that is, for any events \\(\\{Y\\in(a,b]\\}\\) and \\(A\\in\\mathcal{G}\\):\n\\[\\begin{aligned}\n\\mathbb{P}(\\{Y\\in I\\}\\cap A) & =\\mathbb{P}(\\{Y\\in I\\})\\cdot\\mathbb{P}(A)\n\\end{aligned}\\]\nthen\n\\[\\begin{aligned}\n\\mathbf{E}[Y|\\mathcal{G}] & =\\mathbf{E}[Y]\n\\end{aligned}\\]\nIn other words, if you have no information on \\(Y\\), your best guess for its value is simply plain expectation.\n(4) Linearity of conditional expectations. Let \\(X\\) be another integrable random variable on \\((\\Omega,\\mathcal{F},\\mathbb{P})\\). Then,\n\\[\\begin{aligned}\n\\mathbf{E}[aX+bY|\\mathcal{G}] & =a\\mathbf{E}[X|\\mathcal{G}]+b\\mathbf{E}[Y|\\mathcal{G}],\\quad\\text{for any }a,b\\in\\mathbf{R}\n\\end{aligned}\\]\nThe linearity justifies the cumbersom choice of notation \\(\\mathbf{E}[Y|\\mathcal{G}]\\) for the random variable.\n(5) Tower Property : If \\(\\mathcal{H}\\subseteq\\mathcal{G}\\) is another sigma-field of \\(\\Omega\\), then:\n\\[\\begin{aligned}\n\\mathbf{E}[Y|\\mathcal{H}] & =\\mathbf{E}[\\mathbf{E}[Y|\\mathcal{G}]|\\mathcal{H}]\n\\end{aligned}\\]\nThink in terms of two successive projections: first on a plane, then on a line in the plane.\n(6) Pythagoras Theorem. We have:\n\\[\\begin{aligned}\n\\mathbf{E}[Y^{2}] & =\\mathbf{E}\\left[\\left(\\mathbf{E}[Y|\\mathcal{G}]\\right)^{2}\\right]+\\mathbf{E}\\left[\\left(Y-\\mathbf{E}[Y|\\mathcal{G}]\\right)^{2}\\right]\n\\end{aligned}\\]\nIn particular:\n\\[\\begin{aligned}\n\\mathbf{E}\\left[\\left(\\mathbf{E}\\left[Y|\\mathcal{G}\\right]\\right)^{2}\\right] & \\leq\\mathbf{E}[Y^{2}]\n\\end{aligned}\\]\nIn words, the \\(L^{2}\\) norm of \\(\\mathbf{E}[X|\\mathcal{G}]\\) is smaller than the one of \\(X\\), which is clear if you think in terms of orthogonal projection.\n(7) Expectation of the conditional expectation.\n\\[\\begin{aligned}\n\\mathbf{E}\\left[\\mathbf{E}[Y|\\mathcal{G}]\\right] & =\\mathbf{E}[Y]\n\\end{aligned}\\]\n\nProof.\nThe uniqueness property of conditional expectations in theorem ([th:existence-and-uniqueness-of-conditional-expectations-II]) might appear to be an academic curiosity. On the contrary, it is very practical, since it ensures, that if we find a candidate for the conditional expectation that has the two properties in Definition ([def:conditional-expectation]), then it must be the conditional expectation. To see this, let’s prove property (1).\n\nIf \\(Y\\) is \\(\\mathcal{G}\\)-measurable, then \\(\\mathbf{E}[Y|\\mathcal{G}]=Y\\).\nIt suffices to show that \\(Y\\) has the two defining properties of conditional expectation.\n(1) We are given that, \\(Y\\) is \\(\\mathcal{G}\\)-measurable. So, property (A) is satisfied.\n(2) For any bounded random variable \\(W\\) that is \\(\\mathcal{G}\\)-measurable, we have:\n\\[\\begin{aligned}\n\\mathbf{E}[W(Y-Y)] & =\\mathbf{E}[0]=0\n\\end{aligned}\\]\nSo, property (B) is also a triviality.\n\n\n(Taking out what is known.) If \\(Y\\) is \\(\\mathcal{G}\\)-measurable and \\(X\\) is another integrable random variable, then:\n\\[\\begin{aligned}\n\\mathbf{E}[XY|\\mathcal{G}] & =Y\\mathbf{E}[X|\\mathcal{G}]\n\\end{aligned}\\]\nIn a similar vein, it suffices to show that, \\(Y\\mathbf{E}[X|\\mathcal{G}]\\) has the two defining properties of conditional expectation.\n(1) We are given that \\(Y\\) is \\(\\mathcal{G}\\)-measurable; from property (1), \\(\\mathbf{E}[X|\\mathcal{G}]\\) is \\(\\mathcal{G}\\)-measurable. It follows that, \\(Y\\mathbf{E}[X|\\mathcal{G}]\\) is \\(\\mathcal{G}\\)-measurable.\n(2) From theorem ([th:existence-and-uniqueness-of-conditional-expectations-II]), \\(X-\\mathbf{E}[X|\\mathcal{G}]\\) is orthogonal to the random variables \\(L^{2}(\\Omega,\\mathcal{G},\\mathbb{P})\\). So, if \\(W\\) is any bounded \\(\\mathcal{G}\\)-measurable random variable, it follows that:\n\\[\\begin{aligned}\n\\mathbf{E}[WY(X-\\mathbf{E}[X|\\mathcal{G}])] & =0\\\\\n\\implies\\mathbf{E}[W\\cdot XY] & =\\mathbf{E}[WY\\mathbf{E}[X|\\mathcal{G}]]\n\\end{aligned}\\]\nThis closes the proof.\n\n\n(Independence.) If \\(Y\\) is independent of \\(\\mathcal{G}\\), that is, for all events \\(\\{Y\\in(a,b]\\}\\) and \\(A\\in\\mathcal{G}\\),\n\\[\\begin{aligned}\n\\mathbf{\\mathbb{P}}\\{Y\\in(a,b]\\cap A\\} & =\\mathbb{P}\\{Y\\in(a,b]\\}\\cdot\\mathbb{P}(A)\n\\end{aligned}\\]\nthen\n\\[\\begin{aligned}\n\\mathbf{E}[Y|\\mathcal{G}] & =\\mathbf{E}[Y]\n\\end{aligned}\\]\nLet us show that \\(\\mathbf{E}[Y]\\) has the two defining properties of conditional expectations.\n(1) \\(\\mathbf{E}[Y]\\) is a constant and so it is \\(\\mathcal{F}_{0}\\) measurable. Hence, it is \\(\\mathcal{G}\\) measurable.\n(2) If \\(W\\) is another \\(\\mathcal{G}\\)-measurable random variable,\n\\[\\begin{aligned}\n\\mathbf{E}[WY] & =\\mathbf{E}[W]\\cdot\\mathbf{E}[Y]\n\\end{aligned}\\]\nsince \\(Y\\) is independent of \\(\\mathcal{G}\\) and therefore it is independent of \\(Y\\). Hence,\n\\[\\begin{aligned}\n\\mathbf{E}[W(Y-\\mathbf{E}[Y])] & =0\n\\end{aligned}\\]\nConsequently, \\(\\mathbf{E}[Y|\\mathcal{G}]=\\mathbf{E}[Y]\\).\n\n\n(Linearity of conditional expectations) Let \\(X\\) be another integrable random variable on \\((\\Omega,\\mathcal{F},\\mathbb{P})\\). Then,\n\\[\\begin{aligned}\n\\mathbf{E}[aX+bY|\\mathcal{G}] & =a\\mathbf{E}[X|\\mathcal{G}]+b\\mathbf{E}[Y|\\mathcal{G}],\\quad\\text{for any }a,b\\in\\mathbf{R}\n\\end{aligned}\\]\n\nSince \\(\\mathbf{E}[X|\\mathcal{G}]\\) and \\(\\mathbf{E}[Y|\\mathcal{G}]\\) are \\(\\mathcal{G}-\\)measurable, any linear combination of these two random variables is also \\(\\mathcal{G}\\)-measurable.\nAlso, if \\(W\\) is any bounded \\(\\mathcal{G}-\\)measurable random variable, we have:\n\\[\\begin{aligned}\n\\mathbf{E}[W(aX+bY-(a\\mathbf{E}[X|\\mathcal{G}]+b\\mathbf{E}[Y|\\mathcal{G}]))] & =a\\mathbf{E}[W(X-\\mathbf{E}[X|\\mathcal{G}])]\\\\\n& +b\\mathbf{E}[W(Y-\\mathbf{E}[Y|\\mathcal{G}])]\n\\end{aligned}\\]\nBy definition, \\(X-\\mathbf{E}(X|\\mathcal{G})\\) is orthogonal t o the subspace \\(L^{2}(\\Omega,\\mathcal{G},\\mathbb{P})\\) and hence to all \\(\\mathcal{G}\\)-measurable random-variables. Hence, the two expectations on the right hand side of the above expression are \\(0\\). Since, conditional expectations are unique, we have the desired result.\n\nIf \\(\\mathcal{H}\\subseteq\\mathcal{G}\\) is another sigma-field of \\(\\Omega\\), then\n\\[\\begin{aligned}\n\\mathbf{E}[Y|\\mathcal{H}] & =\\mathbf{E}[\\mathbf{E}[Y|\\mathcal{G}]|\\mathcal{H}]\n\\end{aligned}\\]\nDefine \\(U:=\\mathbf{E}[Y|\\mathcal{G}]\\). By definition, \\(\\mathbf{E}[U|\\mathcal{H}]\\) is \\(\\mathcal{H}\\)-measurable.\nLet \\(W\\) be any bounded \\(\\mathcal{H}\\)-measurable random variable. We have:\n\\[\\begin{aligned}\n\\mathbf{E}[W\\{\\mathbf{E}(Y|\\mathcal{G})-\\mathbf{E}(\\mathbf{E}(Y|\\mathcal{G})|\\mathcal{H})\\}] & =\\mathbf{E}[W(U-\\mathbf{E}(U|\\mathcal{H})]\n\\end{aligned}\\]\nBut, by definition \\(U-\\mathbf{E}(U|\\mathcal{H})\\) is always orthogonal to the subspace \\(L^{2}(\\Omega,\\mathcal{H},\\mathbb{P})\\) and hence, \\(\\mathbf{E}[W(U-\\mathbf{\\mathbf{E}}(U|\\mathcal{H})]=0\\). Since, conditional expectations are unique, we have the desired result.\n\n\nPythagoras’s theorem. We have:\n\\[\\begin{aligned}\n\\mathbf{E}[Y^{2}] & =\\mathbf{E}[(\\mathbf{E}[Y|\\mathcal{G}])^{2}]+\\mathbf{E}[(Y-\\mathbf{E}(Y|\\mathcal{G}))^{2}]\n\\end{aligned}\\]\nIn particular,\n\\[\\begin{aligned}\n\\mathbf{E}[(\\mathbf{E}[Y|\\mathcal{G}])^{2}] & \\leq\\mathbf{E}[Y^{2}]\n\\end{aligned}\\]\nConsider the orthogonal decomposition:\n\\[\\begin{aligned}\nY & =\\mathbf{E}[Y|\\mathcal{G}]+(Y-\\mathbf{E}[Y|\\mathcal{G}])\n\\end{aligned}\\]\nSquaring on both sides and taking expectations, we have:\n\\[\\begin{aligned}\n\\mathbf{E}[Y^{2}] & =\\mathbf{E}[(\\mathbf{E}(Y|\\mathcal{G}))^{2}]+\\mathbf{E}[(Y-\\mathbf{E}[Y|\\mathcal{G}])^{2}]+2\\mathbf{E}\\left[\\mathbf{E}[Y|\\mathcal{G}](Y-\\mathbf{E}[Y|\\mathcal{G}])\\right]\n\\end{aligned}\\]\nBy definition of conditional expectation, \\((Y-\\mathbf{E}[Y|\\mathcal{G}])\\) is orthogonal to the subspace \\(L^{2}(\\Omega,\\mathcal{G},\\mathbb{P})\\). By the properties of conditional expectation, \\(\\mathbf{E}[Y|\\mathcal{G}]\\) is \\(\\mathcal{G}-\\)measurable, so it belongs to \\(L^{2}(\\Omega,\\mathcal{G},\\mathbb{P})\\). Hence, the dot-product on the right-hand side is \\(0\\). Consequently, we have the desired result.\nMoreover, since \\((Y-\\mathbf{E}[Y|\\mathcal{G}])^{2}\\) is a non-negative random variable, \\(\\mathbf{E}[(Y-\\mathbf{E}[Y|\\mathcal{G}])^{2}]\\geq0\\). It follows that: \\(\\mathbf{E}[Y^{2}]\\geq\\mathbf{E}[(\\mathbf{E}(Y|\\mathcal{G}))^{2}]\\).\n\n\nOur claim is:\n\\[\\begin{aligned}\n\\mathbf{E}\\left[\\mathbf{E}[Y|\\mathcal{G}]\\right] & =\\mathbf{E}[Y]\n\\end{aligned}\\]\nWe know that, if \\(W\\) is any bounded \\(\\mathcal{G}\\)-measurable random variable:\n\\[\\begin{aligned}\n\\mathbf{E}\\left[WY\\right] & =\\mathbf{E}[W\\mathbf{E}[Y|\\mathcal{G}]]\n\\end{aligned}\\]\nTaking \\(W=1\\), we have:\n\\[\\begin{aligned}\n\\mathbf{E}\\left[Y\\right] & =\\mathbf{E}[\\mathbf{E}[Y|\\mathcal{G}]]\n\\end{aligned}\\]\n\n\n(Brownian Conditioning II). We continue the example ([ex:brownian-conditioning-I]). Let’s now compute the conditional expectations \\(\\mathbf{E}[e^{aB_{1}}|B_{1/2}]\\) and \\(\\mathbf{E}[e^{aB_{1/2}}|B_{1}]\\) for some parameter \\(a\\). We shall need the properties of conditional expectation in proposition ([prop:properties-of-conditional-expectation]). For the first one we use the fact that \\(B_{1/2}\\) is independent of \\(B_{1}-B_{1/2}\\) to get:\n\\[\\begin{aligned}\n\\mathbf{E}[e^{aB_{1}}|B_{1/2}] & =\\mathbf{E}[e^{a((B_{1}-B_{1/2})+B_{1/2})}|B_{1/2}]\\\\\n& =\\mathbf{E}[e^{a(B_{1}-B_{2})}\\cdot e^{aB_{1/2}}|B_{1/2}]\\\\\n& \\quad\\left\\{ \\text{Taking out what is known}\\right\\} \\\\\n& =e^{aB_{1/2}}\\mathbf{E}[e^{a(B_{1}-B_{1/2})}|B_{1/2}]\\\\\n& =e^{aB_{1/2}}\\cdot\\mathbf{E}[e^{a(B_{1}-B_{1/2})}]\\\\\n& \\quad\\{\\text{Independence}\\}\n\\end{aligned}\\]\nWe know that, \\(a(B_{1}-B_{1/2})\\) is a gaussian random variable with mean \\(0\\) and variance \\(a^{2}/2\\). We also know that, \\(\\mathbf{E}[e^{tZ}]=e^{t^{2}/2}\\). So, \\(\\mathbf{E}[e^{a(B_{1}-B_{1/2})}]=e^{a^{2}/4}\\). Consequently, \\(\\mathbf{E}[e^{aB_{1}}|B_{1/2}]=e^{aB_{1/2}+a^{2}/4}\\).\nThe result itself has the form of the MGF of a Gaussian with mean \\(B_{1/2}\\) and variance \\(1/2\\). (The MGF of \\(X=\\mu+\\sigma Z\\), \\(Z=N(0,1)\\) is \\(M_{X}(a)=\\exp\\left[\\mu+\\frac{1}{2}\\sigma^{2}a^{2}\\right]\\).) In fact, this shows that the conditional distribution of \\(B_{1}\\) given \\(B_{1/2}\\) is Gaussian of mean \\(B_{1/2}\\) and variance \\(1/2\\).\nFor the other expectation, note that \\(B_{1/2}-\\frac{1}{2}B_{1}\\) is independent of \\(B_{1}\\). We have: \\[\\begin{aligned}\n\\mathbf{E}\\left[\\left(B_{1/2}-\\frac{1}{2}B_{1}\\right)B_{1}\\right] & =\\mathbf{E}(B_{1/2}B_{1})-\\frac{1}{2}\\mathbf{E}[B_{1}^{2}]\\\\\n& =\\frac{1}{2}-\\frac{1}{2}\\cdot1\\\\\n& =0\n\\end{aligned}\\]\nTherefore, we have:\n\\[\\begin{aligned}\n\\mathbf{E}[e^{aB_{1/2}}|B_{1}] & =\\mathbf{E}[e^{a(B_{1/2}-\\frac{1}{2}B_{1})+\\frac{a}{2}B_{1}}|B_{1}]\\\\\n& =\\mathbf{E}[e^{a(B_{1/2}-\\frac{1}{2}B_{1})}\\cdot e^{\\frac{a}{2}B_{1}}|B_{1}]\\\\\n& =e^{\\frac{a}{2}B_{1}}\\mathbf{E}[e^{a(B_{1/2}-\\frac{1}{2}B_{1})}|B_{1}]\\\\\n& \\quad\\{\\text{Taking out what is known }\\}\\\\\n& =e^{\\frac{a}{2}B_{1}}\\mathbf{E}[e^{a(B_{1/2}-\\frac{1}{2}B_{1})}]\\\\\n& \\quad\\{\\text{Independence}\\}\n\\end{aligned}\\]\nNow, \\(a(B_{1/2}-\\frac{1}{2}B_{1})\\) is a random variable with mean \\(0\\) and variance \\(a^{2}(\\frac{1}{2}-\\frac{1}{4})=\\frac{a^{2}}{4}\\). Consequently, \\(\\mathbf{E}[e^{(a/2)Z}]=e^{\\frac{a^{2}}{8}}\\). Thus, \\(\\mathbf{E}[e^{aB_{1/2}}|B_{1}]=e^{\\frac{a}{2}B_{1}+\\frac{a^{2}}{8}}\\).\n\n\n(Brownian bridge is conditioned Brownian motion). We know that the Brownian bridge \\(M_{t}=B_{t}-tB_{1}\\), \\(t\\in[0,1]\\) is independent of \\(B_{1}\\). We use this to show that the conditional distribution of the Brownian motion given the value at the end-point \\(B_{1}\\) is the one of a Brownian bridge shifted by the straight line going from \\(0\\) to \\(B_{1}\\). To see this, we compute the conditional MGF of \\((B_{t_{1}},B_{t_{2}},\\ldots,B_{t_{n}})\\) given \\(B_{1}\\) for some arbitrary choices of \\(t_{1},t_{2},\\ldots,t_{n}\\) in \\([0,1]\\). We get the following by adding and subtracting \\(t_{j}B_{1}\\):\n\\[\\begin{aligned}\n\\mathbf{E}[e^{a_{1}B_{t_{1}}+\\ldots+a_{n}B_{t_{n}}}|B_{1}] & =\\mathbf{E}[e^{a_{1}(B_{t_{1}}-t_{1}B_{1})+\\ldots+a_{n}(B_{t_{n}}-t_{n}B_{1})}\\cdot e^{(a_{1}t_{1}B_{1}+\\ldots+a_{n}t_{n}B_{1})}|B_{1}]\\\\\n& =e^{(a_{1}t_{1}B_{1}+\\ldots+a_{n}t_{n}B_{1})}\\mathbf{E}[e^{a_{1}M_{t_{1}}+\\ldots+a_{n}M_{t_{n}}}|B_{1}]\\\\\n& \\quad\\{\\text{Taking out what is known}\\}\\\\\n& =e^{(a_{1}t_{1}B_{1}+\\ldots+a_{n}t_{n}B_{1})}\\mathbf{E}[e^{a_{1}M_{t_{1}}+\\ldots+a_{n}M_{t_{n}}}]\\\\\n& \\quad\\{\\text{Independence}\\}\n\\end{aligned}\\]\nThe right side is exactly the MGF of the process \\(M_{t}+tB_{1},t\\in[0,1]\\) (for a fixed value \\(B_{1})\\), where \\((M_{t},t\\in[0,1])\\) is a Brownian bridge. This proves the claim.\n\n\n(Conditional Jensen’s Inequality) If \\(c\\) is a convex function on \\(\\mathbf{R}\\) and \\(X\\) is a random variable on \\((\\Omega,\\mathcal{F},\\mathbb{P})\\), then:\n\\[\\begin{aligned}\n\\mathbf{E}[c(X)] & \\geq c(\\mathbf{E}[X])\n\\end{aligned}\\]\nMore generally, if \\(\\mathcal{G}\\subseteq\\mathcal{F}\\) is a sigma-field, then:\n\\[\\mathbf{E}[c(X)|\\mathcal{G}]\\geq c(\\mathbf{E}[X|\\mathcal{G}])\\]\n\n\nProof. Proof. We know that, if \\(c(x)\\) is a convex function, the tangent to the curve \\(c\\) at any point lies below the curve. The tangent to the cuve at this point, is a straight-line of the form:\n\\[\\begin{aligned}\nc(t)=y & =mt+c\n\\end{aligned}\\]\nwhere \\(m(t)=c'(t)\\). This holds for all \\(t\\in\\mathbf{R}\\). At an arbitrary point \\(x\\) we have:\n\\[\\begin{aligned}\nc(x)\\geq & y=mx+c\n\\end{aligned}\\]\nTherefore, we have:\n\\[\\begin{aligned}\nc(x)-c(t) & \\geq m(t)(x-t)\n\\end{aligned}\\]\nfor any \\(x\\) and any point of tangency \\(t\\).\n\\[\\begin{aligned}\nc(X)-c(Y) & \\geq m(Y)(X-Y)\n\\end{aligned}\\]\nSubstituting \\(Y=\\mathbf{E}[X|\\mathcal{G}]\\), we get:\n\\[\\begin{aligned}\nc(X)-c(\\mathbf{E}[X|\\mathcal{G}]) & \\geq m(\\mathbf{E}[X|\\mathcal{G}])(X-\\mathbf{E}[X|\\mathcal{G}])\n\\end{aligned}\\]\nTaking expectations on both sides, we get:\n\\[\\begin{aligned}\n\\mathbf{E}[(c(X)-c(\\mathbf{E}[X|\\mathcal{G}]))|\\mathcal{G}] & \\geq\\mathbf{E}[m(\\mathbf{E}[X|\\mathcal{G}])(X-\\mathbf{E}[X|\\mathcal{G}])|\\mathcal{G}]\n\\end{aligned}\\]\nThe left-hand side simplifies as:\n\\[\\begin{aligned}\n\\mathbf{E}[(c(X)-c(\\mathbf{E}[X|\\mathcal{G}]))|\\mathcal{G}] & =\\mathbf{E}[c(X)|\\mathcal{G}]-\\mathbf{E}[c(\\mathbf{E}[X|\\mathcal{G}]))|\\mathcal{G}]\\\\\n& \\quad\\{\\text{Linearity}\\}\\\\\n& =\\mathbf{E}[c(X)|\\mathcal{G}]-c(\\mathbf{E}[X|\\mathcal{G}])\\\\\n& \\quad\\{\\text{c(\\ensuremath{\\mathbf{E}}[X|\\ensuremath{\\mathcal{G}}])) is \\ensuremath{\\mathcal{G}}-measurable}\\}\n\\end{aligned}\\]\nOn the right hand side, we have:\n\\[\\begin{aligned}\n\\mathbf{E}[m(\\mathbf{E}[X|\\mathcal{G}])(X-\\mathbf{E}[X|\\mathcal{G}])|\\mathcal{G}] & =\\mathbf{E}[m(\\mathbf{E}[X|\\mathcal{G}])\\cdot X|\\mathcal{G}]-\\mathbf{E}[m(\\mathbf{E}[X|\\mathcal{G}])\\cdot\\mathbf{E}[X|\\mathcal{G}]|\\mathcal{G}]\\\\\n& =\\mathbf{E}[X|\\mathcal{G}]m(\\mathbf{E}[X|\\mathcal{G}])-m(\\mathbf{E}[X|\\mathcal{G}])\\cdot\\mathbf{E}[X|\\mathcal{G}]\\\\\n& =0\n\\end{aligned}\\]\nConsequently, it follows that \\(\\mathbf{E}[c(X)|\\mathcal{G}]\\geq c(\\mathbf{E}[X|\\mathcal{G}])\\). ◻\n\n\n(Embeddings of \\(L^{p}\\) spaces) Square-integrable random variables are in fact integrable. In other words, there is always the inclusion \\(L^{2}(\\Omega,\\mathcal{F},\\mathbb{P})\\subseteq L^{1}(\\Omega,\\mathcal{F},\\mathbb{P})\\). In particular, square integrable random variables always have a well-defined variance. This embedding is a simple consequence of Jensen’s inequality since:\n\\[\\begin{aligned}\n|\\mathbf{E}[X]|^{2} & \\leq\\mathbf{E}[|X|^{2}]\n\\end{aligned}\\]\nas \\(f(x)=|x|^{2}\\) is convex. By taking the square root on both sides, we get:\n\\[\\begin{aligned}\n\\left\\Vert X\\right\\Vert _{1} & \\leq\\left\\Vert X\\right\\Vert _{2}\n\\end{aligned}\\]\nMore generally, for any \\(1&lt;p&lt;\\infty\\), we can define \\(L^{p}(\\Omega,\\mathcal{F},\\mathbb{P})\\) to be the linear space of random variables such that \\(\\mathbf{E}[|X|^{p}]&lt;\\infty\\). Then for \\(p&lt;q\\), since \\(x^{q/p}\\) is convex, we get by Jensen’s inequality :\n\\[\\begin{aligned}\n\\mathbf{E}[|X|^{q}] & =\\mathbf{E}[(|X|^{p})^{\\frac{q}{p}}]\\geq\\left(\\mathbf{E}[|X|^{p}]\\right)^{\\frac{q}{p}}\n\\end{aligned}\\]\nTaking the \\(q\\)-th root on both sides:\n\\[\\begin{aligned}\n\\mathbf{E}[|X|^{p}]^{1/p} & \\leq\\mathbf{E}[|X|^{q}]^{1/q}\n\\end{aligned}\\]\nSo, if \\(X\\in L^{q}\\), then it must also be in \\(L^{p}\\). Concretely, this means that any random variable with a finite \\(q\\)-moment will also have a finite \\(p\\)-moment, for \\(q&gt;p\\)."
  },
  {
    "objectID": "posts/martingales/index.html#martingales.-1",
    "href": "posts/martingales/index.html#martingales.-1",
    "title": "Martingales",
    "section": "",
    "text": "We now have all the tools to define martingales.\n\n(Filtration). A filtration \\((\\mathcal{F}_{t}:t\\geq0)\\) of \\(\\Omega\\) is an increasing sequence of \\(\\sigma\\)-fields of \\(\\Omega\\). That is,\n\\[\\begin{aligned}\n\\mathcal{F}_{s} & \\subseteq\\mathcal{F}_{t},\\quad\\forall s\\leq t\n\\end{aligned}\\]\nWe will usually take \\(\\mathcal{F}_{0}=\\{\\emptyset,\\Omega\\}\\). The canonical example of a filtration is the natural filtration of a given process \\((M_{s}:s\\geq0)\\). This is the filtration given by \\(\\mathcal{F}_{t}=\\sigma(M_{s},s\\leq t)\\). The inclusions of the \\(\\sigma\\)-fields are then clear. For a given Brownian motion \\((B_{t},t\\geq0)\\), the filtration \\(\\mathcal{F}_{t}=\\sigma(B_{s},s\\leq t)\\) is sometimes called the Brownian filtration. We think of the filtration as the flow of information of the process.\n\n\nA stochastic process \\((X_{t}:t\\geq0)\\) is said to be adapted to \\((\\mathcal{F}_{t}:t\\geq0)\\), if for each \\(t\\), the random variable \\(X_{t}\\) is \\(\\mathcal{F}_{t}-\\)measurable.\n\n\n(Martingale). A process \\((M_{t}:t\\geq0)\\) is a martingale for the filtration \\((\\mathcal{F}_{t}:t\\geq0)\\) if the following hold:\n(1) The process is adapted, that is \\(M_{t}\\) is \\(\\mathcal{F}_{t}-\\)measurable for all \\(t\\geq0\\).\n(2) \\(\\mathbf{E}[|M_{t}|]&lt;\\infty\\) for all \\(t\\geq0\\). (This ensures that the conditional expectation is well defined.)\n(3) Martingale property:\n\\[\\begin{aligned}\n\\mathbf{E}[M_{t}|\\mathcal{F}_{s}] & =M_{s}\\quad\\forall s\\leq t\n\\end{aligned}\\]\nRoughly, speaking this means that the best approximation of a process at a future time \\(t\\) is its value at the present.\n\nIn particular, the martingale property implies that:\n\\[\\begin{aligned}\n\\mathbf{E}[M_{t}|\\mathcal{F}_{0}] & =M_{0}\\nonumber \\\\\n\\mathbf{E}[\\mathbf{E}[M_{t}|\\mathcal{F}_{0}]] & =\\mathbf{E}[M_{0}]\\nonumber \\\\\n\\mathbf{E}[M_{t}] & =\\mathbf{E}[M_{0}]\\label{eq:expected-value-of-martingale-at-any-time-is-constant}\\\\\n& \\quad\\{\\text{Tower Property}\\}\\nonumber\n\\end{aligned}\\]\nUsually, we take \\(\\mathcal{F}_{0}\\) to be the trivial sigma-field \\(\\{\\emptyset,\\Omega\\}\\). A random variable that is \\(\\mathcal{F}_{0}\\)-measurable must be a constant, so \\(M_{0}\\) is a constant. In this case, \\(\\mathbf{E}[M_{t}]=M_{0}\\) for all \\(t\\). If properties (1) and (2) are satisfied, but the best approximation is larger, \\(\\mathbf{E}[M_{t}|\\mathcal{F}_{s}]\\geq M_{s}\\), the process is called a submartingale. If it is smaller on average, \\(\\mathbf{E}[M_{t}|\\mathcal{F}_{s}]\\leq\\mathbf{E}[M_{s}]\\), we say it is a supermartingale.\nWe will be mostly interested in martingales that are continuous and square-integrable. Continuous martingales are martingales whose paths \\(t\\mapsto M_{t}(\\omega)\\) are continuous almost surely. Square-integrable martingales are such that \\(\\mathbf{E}[|M_{t}|^{2}]&lt;\\infty\\) for all \\(t\\)’s. This condition is stronger than \\(\\mathbf{E}[|M_{t}|]&lt;\\infty\\) due to Jensen’s inequality.\n\n(Martingales in Discrete-time). Martingales can be defined the same way if the index set of the process is discrete. For example, the filtration \\((\\mathcal{F}_{n}:n\\in\\mathbf{N})\\) is a countable set and the martingale property is then replaced by \\(\\mathbf{E}[M_{n+1}|\\mathcal{F}_{n}]=M_{n}\\) as expected. The tower-property then yields the martingale property \\(\\mathbf{E}[M_{n+k}|\\mathcal{F}_{n}]=M_{n}\\) for \\(k\\geq1\\).\n\n\n(Continuous Filtrations). Filtrations with continuous time can be tricky to handle rigorously. For example, one has to make sense of what it means for \\(\\mathcal{F}_{s}\\) as \\(s\\) approaches \\(t\\) from the left. Is it equal to \\(\\mathcal{F}_{t}\\)? Or is there actually less information in \\(\\lim_{s\\to t^{-}}\\mathcal{F}_{s}\\) than in \\(\\mathcal{F}_{t}\\)? This is a bit of headache when dealing with processes with jumps, like the Poisson process. However, if the paths are continuous, the technical problems are not as heavy.\nLet’s look at some of the important examples of martingales constructed from Brownian Motion.\n\n\n(Examples of Brownian Martingales)\n(i) Standard Brownian Motion. Let \\((B_{t}:t\\geq0)\\) be a standard Brownian motion and let \\((\\mathcal{F}_{t}:t\\geq0)\\) be a Brownian filtration. Then \\((B_{t}:t\\geq0)\\) is a square integrable martingale for the filtration \\((\\mathcal{F}_{t}:t\\geq0)\\). Property (1) is obvious, because all the sets in \\(\\mathcal{F}_{t}\\) are resolved, upon observing the outcome of \\(B_{t}\\). Similarly, \\(\\mathbf{E}[|B_{t}|]=0\\). As for the martingale property, note that, by the properties of conditional expectation in proposition ([prop:properties-of-conditional-expectation]), we have:\n\\[\\begin{aligned}\n\\mathbf{E}[B_{t}|\\mathcal{F}_{s}] & =\\mathbf{E}[B_{t}|B_{s}]\\\\\n& =\\mathbf{E}[B_{t}-B_{s}+B_{s}|B_{s}]\\\\\n& =\\mathbf{E}[B_{t}-B_{s}|B_{s}]+\\mathbf{E}[B_{s}|B_{s}]\\\\\n& \\quad\\{\\text{Linearity}\\}\\\\\n& =\\mathbf{E}[B_{t}-B_{s}]+B_{s}\\\\\n& \\quad\\{\\text{Independence}\\}\\\\\n& =B_{s}\n\\end{aligned}\\]\n(ii) Geometric Brownian Motion. Let \\((B_{t},t\\ge0)\\) be a standard brownian motion, and \\(\\mathcal{F}_{t}=\\sigma(B_{s},s\\leq t)\\). A geometric brownian motion is a process \\((S_{t},t\\geq0)\\) defined by:\n\\[\\begin{aligned}\nS_{t} & =S_{0}\\exp\\left(\\sigma B_{t}+\\mu t\\right)\n\\end{aligned}\\]\nfor some parameter \\(\\sigma&gt;0\\) and \\(\\mu\\in\\mathbf{R}\\). This is simply the exponential of the Brownian motion with drift. This is not a martingale for most choices of \\(\\mu\\)! In fact, one must take\n\\[\\begin{aligned}\n\\mu & =-\\frac{1}{2}\\sigma^{2}\n\\end{aligned}\\] for the process to be a martingale for the Brownian filtration. Let’s verify this. Property (1) is obvious since \\(S_{t}\\) is a function of \\(B_{t}\\) for each \\(t\\). So, it is \\(\\mathcal{F}_{t}\\) measurable. Moreover, property (2) is clear: \\(\\mathbf{E}[\\exp(\\sigma B_{t}+\\mu t)]=\\mathbf{E}[\\exp(\\sigma\\sqrt{t}Z+\\mu t)]=\\exp(\\mu t+\\frac{1}{2}\\sigma^{2}t)\\). So, its a finite quantity. As for the martingale property, note that by the properties of conditional expectation, and the MGF of Gaussians, we have for \\(s\\leq t\\):\n\\[\\begin{aligned}\n\\mathbf{E}[S_{t}|\\mathcal{F}_{s}] & =\\mathbf{E}\\left[S_{0}\\exp\\left(\\sigma B_{t}-\\frac{1}{2}\\sigma^{2}t\\right)|\\mathcal{F}_{s}\\right]\\\\\n& =S_{0}\\exp(-\\frac{1}{2}\\sigma^{2}t)\\mathbf{E}[\\exp(\\sigma(B_{t}-B_{s}+B_{s}))|\\mathcal{F}_{s}]\\\\\n& =S_{0}\\exp(-\\frac{1}{2}\\sigma^{2}t)\\exp(\\sigma B_{s})\\mathbf{E}[\\exp(\\sigma(B_{t}-B_{s}))|\\mathcal{F}_{s}]\\\\\n& \\quad\\{\\text{Taking out what is known}\\}\\\\\n& =S_{0}\\exp\\left(\\sigma B_{s}-\\frac{1}{2}\\sigma^{2}t\\right)\\mathbf{E}\\left[\\exp\\left(\\sigma(B_{t}-B_{s})\\right)\\right]\\\\\n& \\quad\\{\\text{Independence}\\}\\\\\n& =S_{0}\\exp\\left(\\sigma B_{s}-\\frac{1}{2}\\sigma^{2}t+\\frac{1}{2}\\sigma^{2}(t-s)\\right)\\\\\n& =S_{0}\\exp(\\sigma B_{s}-\\frac{1}{2}\\sigma^{2}s)\\\\\n& =S_{s}\n\\end{aligned}\\]\nWe will sometimes abuse terminology and refer to the martingale case of geometric brownian motion simply as geometric Brownian Motion when the context is clear.\n(iii) The square of the Brownian motion, compensated. It is easy to check \\((B_{t}^{2},t\\geq0)\\) is a submartingale by direct computation using increments or by Jensen’s inequality: \\(\\mathbf{E}[B_{t}^{2}|\\mathcal{F}_{s}]&gt;(\\mathbf{E}[B_{t}|\\mathcal{F}_{s}])^{2}=B_{s}^{2}\\), \\(s&lt;t\\). It is nevertheless possible to compensate to get a martingale:\n\\[\\begin{aligned}\nM_{t} & =B_{t}^{2}-t\n\\end{aligned}\\]\nIt is an easy exercise to verify that \\((M_{t}:t\\geq0)\\) is a martingale for the Brownian filtration \\((\\mathcal{F}_{t}:t\\geq0)\\).\n\\[\\begin{aligned}\n\\mathbf{E}[M_{t}|\\mathcal{F}_{s}] & =\\mathbf{E}[B_{t}^{2}-t|\\mathcal{F}_{s}]\\\\\n& =\\mathbf{E}[B_{t}^{2}|\\mathcal{F}_{s}]-t\\\\\n& =\\mathbf{E}[(B_{t}-B_{s}+B_{s})^{2}|\\mathcal{F}_{s}]-t\\\\\n& =\\mathbf{E}[(B_{t}-B_{s})^{2}|\\mathcal{F}_{s}]+2\\mathbf{E}[(B_{t}-B_{s})B_{s}|\\mathcal{F}_{s}]+\\mathbf{E}[B_{s}^{2}|\\mathcal{F}_{s}]-t\\\\\n& =\\mathbf{E}[(B_{t}-B_{s})^{2}]+2B_{s}\\mathbf{E}[(B_{t}-B_{s})|\\mathcal{F}_{s}]+B_{s}^{2}-t\\\\\n& =\\mathbf{E}[(B_{t}-B_{s})^{2}]+2B_{s}\\mathbf{E}[(B_{t}-B_{s})]+B_{s}^{2}-t\\\\\n& \\left\\{ \\begin{array}{c}\n\\text{\\ensuremath{(B_{t}-B_{s})} is independent of \\ensuremath{\\mathcal{F}_{s}}}\\\\\n\\text{Also, \\ensuremath{B_{s}} is known at time \\ensuremath{s}}\n\\end{array}\\right\\} \\\\\n& =(t-s)+2B_{s}\\cdot0+B_{s}^{2}-t\\\\\n& =B_{s}^{2}-s\\\\\n& =M_{s}\n\\end{aligned}\\]\n\n\n(Other important martingales).\n(1) Symmetric random walks. This is an example of a martingale in discrete time. Take \\((X_{i}:i\\in\\mathbf{N})\\) to be IID random variables with \\(\\mathbf{E}[X_{i}]=0\\) and \\(\\mathbf{E}[|X_{i}|]&lt;\\infty\\). Take \\(\\mathcal{F}_{n}=\\sigma(X_{i},i\\leq n)\\) and\n\\[\\begin{aligned}\nS_{n} & =X_{1}+X_{2}+\\ldots+X_{n},\\quad S_{0}=0\n\\end{aligned}\\]\nFirstly, the information learned by observing the outcomes of \\(X_{1}\\),\\(\\ldots\\),\\(X_{n}\\) is enough to completely determine \\(S_{n}\\). Hence, \\(S_{n}\\) is \\(\\mathcal{F}_{n}-\\)measurable.\nNext, \\[\\begin{aligned}\n|S_{n}| & =\\left|\\sum_{i=1}^{n}X_{i}\\right|\\\\\n& \\leq\\sum_{i=1}^{n}|X_{i}|\n\\end{aligned}\\]\nConsequently, by the montonocity of expectations, we have:\n\\[\\begin{aligned}\n\\mathbf{E}[|S_{n}|] & \\leq\\sum_{i=1}^{n}\\mathbf{E}[|X_{i}|]&lt;\\infty\n\\end{aligned}\\]\nThe martingale property is also satisfied. We have:\n\\[\\begin{aligned}\n\\mathbf{E}[S_{n+1}|\\mathcal{F}_{n}] & =\\mathbf{E}[S_{n}+X_{n+1}|\\mathcal{F}_{n}]\\\\\n& =\\mathbf{E}[S_{n}|\\mathcal{F}_{n}]+\\mathbf{E}[X_{n+1}|\\mathcal{F}_{n}]\\\\\n& =S_{n}+\\mathbf{E}[X_{n+1}]\\\\\n& \\left\\{ \\begin{array}{c}\n\\text{\\ensuremath{S_{n}} is \\ensuremath{\\mathcal{F}_{n}}-measurable}\\\\\n\\text{\\ensuremath{X_{n+1}} is independent of \\ensuremath{\\mathcal{F}_{n}}}\n\\end{array}\\right\\} \\\\\n& =S_{n}+0\\\\\n& =S_{n}\n\\end{aligned}\\]\n(2) Compensated Poisson process. Let \\((N_{t}:t\\geq0)\\) be a Poisson process with rate \\(\\lambda\\) and \\(\\mathcal{F}_{t}=\\sigma(N_{s},s\\leq t)\\). Then, \\(N_{t}\\) is a submartingale for its natural filtration. Again, properties (1) and (2) are easily checked. \\(N_{t}\\) is \\(\\mathcal{F}_{t}\\) measurable. Moreover, \\(\\mathbf{E}[|N_{t}|]=\\mathbf{E}[N_{t}]=\\frac{1}{\\lambda t}&lt;\\infty\\). The submartingale property follows by the independence of increments : for \\(s\\leq t\\),\n\\[\\begin{aligned}\n\\mathbf{E}[N_{t}|\\mathcal{F}_{s}] & =\\mathbf{E}[N_{t}-N_{s}+N_{s}|\\mathcal{F}_{s}]\\\\\n& =\\mathbf{E}[N_{t}-N_{s}|\\mathcal{F}_{s}]+\\mathbf{E}[N_{s}|\\mathcal{F}_{s}]\\\\\n& =\\mathbf{E}[N_{t}-N_{s}]+N_{s}\\\\\n& =\\lambda(t-s)+N_{s}\\\\\n& \\left\\{ \\because\\mathbf{E}[N_{t}]=\\lambda t\\right\\}\n\\end{aligned}\\]\nMore importantly, we get a martingale by slightly modifying the process. Indeed, if we subtract \\(\\lambda t\\), we have that the process :\n\\[\\begin{aligned}\nM_{t} & =N_{t}-\\lambda t\n\\end{aligned}\\]\nis a martingale. We have:\n\\[\\begin{aligned}\n\\mathbf{E}[M_{t}|\\mathcal{F}_{s}] & =\\mathbf{E}[N_{t}-\\lambda t|\\mathcal{F}_{s}]\\\\\n& =\\lambda t-\\lambda s+N_{s}-\\lambda t\\\\\n& =N_{s}-\\lambda s\\\\\n& =M_{s}\n\\end{aligned}\\]\nThis is called the compensated Poisson process. Let us simulate \\(10\\) paths of the compensated poisson process on \\([0,10]\\).\n\nimport numpy as np\nimport matplotlib.pyplot as plt\n\n# Generates a sample path of a compensated poisson process \n# with rate : `lambda_` per unit time\n# on the interval [0,T], and subintervals of size `stepSize`.\n\ndef generateCompensatedPoissonPath(lambda_,T,stepSize):\n    N = int(T/stepSize)   \n\n    poissonParam = lambda_ * stepSize        \n\n    x = np.random.poisson(lam=poissonParam,size=N)  \n    x = np.concatenate([[0.0], x])\n    N_t = np.cumsum(x)  \n    t = np.linspace(start=0.0,stop=10.0,num=1001)\n\n    M_t = np.subtract(N_t,lambda_ * t)  \n    return M_t\n\n\nt = np.linspace(0,10,1001)\nplt.grid(True)\n\nplt.xlabel(r'Time $t$')\nplt.ylabel(r'Compensated poisson process $M(t)$')\nplt.grid(True)\nplt.title(r'$10$ paths of the compensated Poisson process on $[0,10]$')\n\nfor i in range(10):\n    # Generate a poisson path with rate 1 /sec = 0.01 /millisec\n    n_t = generateCompensatedPoissonPath(lambda_=1.0, T=10, stepSize=0.01)\n    plt.plot(t, n_t)\n\n\nplt.show()\nplt.close()\nWe saw in the two examples, that, even though a process is not itself a martingale, we can sometimes compensate to obtain a martingale! Ito Calculus will greatly extend this perspective. We will have systematic rules that show when a function of Brownian motion is a martingale and if not, how to modify it to get one.\nFor now, we observe that a convex function of a martingale is always a submartingale by Jensen’s inequality.\n\nIf \\(c\\) is a convex function on \\(\\mathbf{R}\\) and \\((M_{t}:t\\geq0)\\) is a martingale for \\((\\mathcal{F}_{t}:t\\geq0)\\), then the process \\((c(M_{t}):t\\geq0)\\) is a submartingale for the same filtration, granted that \\(\\mathbf{E}[|c(M_{t})|]&lt;\\infty\\).\n\n\nProof. Proof. The fact that \\(c(M_{t})\\) is adapted to the filtration is clear since it is an explicit function of \\(M_{t}\\). The integrability is by assumption. The submartingale property is checked as follows:\n\\[\\begin{aligned}\n\\mathbf{E}[c(M_{t})|\\mathcal{F}_{s}] & \\geq c(\\mathbf{E}[M_{t}|\\mathcal{F}_{s}])=c(M_{s})\n\\end{aligned}\\] ◻\n\n\n(The Doob-Meyer Decomposition Theorem). Let \\((X_{n}:n\\in\\mathbf{N})\\) be a submartingale with respect to a filtration \\((\\mathcal{F}_{n}:n\\in\\mathbf{N})\\). Define a sequence of random variables \\((A_{n}:n\\in\\mathbf{N})\\) by \\(A_{0}=0\\) and\n\\[\\begin{aligned}\nA_{n} & =\\sum_{i=1}^{n}(\\mathbf{E}[X_{i}|\\mathcal{F}_{i-1}]-X_{i-1}),\\quad n\\geq1\n\\end{aligned}\\]\nNote that \\(A_{n}\\) is \\(\\mathcal{F}_{n-1}\\)-measurable. Moreover, since \\((X_{n}:n\\in\\mathbf{N})\\) is a submartingale, we have \\(\\mathbf{E}[X_{i}|\\mathcal{F}_{i-1}]-X_{i-1}\\geq0\\) almost surely. Hence, \\((A_{n}:n\\in\\mathbf{N})\\) is an increasing sequence almost surely. Let \\(M_{n}=X_{n}-A_{n}\\).\nWe have:\n\\[\\begin{aligned}\n\\mathbf{E}[M_{n}|\\mathcal{F}_{n-1}] & =\\mathbf{E}[X_{n}-A_{n}|\\mathcal{F}_{n-1}]\\\\\n& =\\mathbf{E}[X_{n}|\\mathcal{F}_{n-1}]-\\mathbf{E}[A_{n}|\\mathcal{F}_{n-1}]\\\\\n& =\\mathbf{E}[X_{n}|\\mathcal{F}_{n-1}]-\\mathbf{E}\\left[\\left.\\mathbf{E}[X_{n}|\\mathcal{F}_{n-1}]-X_{n-1}+A_{n-1}\\right|\\mathcal{F}_{n-1}\\right]\\\\\n& =\\mathbf{E}[X_{n}|\\mathcal{F}_{n-1}]-\\mathbf{E}[X_{n}|\\mathcal{F}_{n-1}]+\\mathbf{E}[X_{n-1}|\\mathcal{F}_{n-1}]-\\mathbf{E}[A_{n-1}|\\mathcal{F}_{n-1}]\\\\\n& =\\cancel{\\mathbf{E}[X_{n}|\\mathcal{F}_{n-1}]}-\\cancel{\\mathbf{E}[X_{n}|\\mathcal{F}_{n-1}]}+X_{n-1}-A_{n-1}\\\\\n& =M_{n-1}\n\\end{aligned}\\]\nThus, \\((M_{n}:n\\in\\mathbf{N})\\) is a martingale. Thus, we have obtained the Doob decomposition:\n\\[\\begin{aligned}\nX_{n} & =M_{n}+A_{n}\\label{eq:doob-decomposition}\n\\end{aligned}\\]\nThis decomposition of a submartingale as a sum of a martingale and an adapted increasing sequence is unique, if we require that \\(A_{0}=0\\) and that \\(A_{n}\\) is \\(\\mathcal{F}_{n-1}\\)-measurable.\nFor the continuous-time case, the situation is much more complicated. The analogue of equation ([eq:doob-decomposition]) is called the Doob-Meyer decomposition. We briefly describe this decomposition and avoid the technical details. All stochastic processes \\(X(t)\\) are assumed to be right-continuous with left-hand limits \\(X(t-)\\).\nLet \\(X(t)\\), \\(a\\leq t\\leq b\\) be a submartingale with respect to a right-continuous filtration \\((\\mathcal{F}_{t}:a\\leq t\\leq b)\\). If \\(X(t)\\) satisfies certain conditions, then it can be uniquely decomposed as:\n\\[\\begin{aligned}\nX(t) & =M(t)+C(t),\\quad a\\leq t\\leq b\n\\end{aligned}\\]\nwhere \\(M(t)\\), \\(a\\leq t\\leq b\\) is a martingale with respect to \\((\\mathcal{F}_{t};a\\leq t\\leq b)\\), \\(C(t)\\) is right-continuous and increasing almost surely with \\(\\mathbf{E}[C(t)]&lt;\\infty\\).\n\n\n(Square of a Poisson Process). Let \\((N_{t}:t\\geq0)\\) be a Poisson process with rate \\(\\lambda\\). We consider the compensated process \\(M_{t}=N_{t}-\\lambda t\\). By ([corollary:the-convex-function-of-martingale-is-a-submartingale]), the process \\((M_{t}^{2}:t\\geq0)\\) is a submartingale for the filtration \\((\\mathcal{F}_{t}:t\\geq0)\\) of the Poisson process. How should we compensated \\(M_{t}^{2}\\) to get a martingale? A direct computation using the properties of conditional expectation yields:\n\\[\\begin{aligned}\n\\mathbf{E}[M_{t}^{2}|\\mathcal{F}_{s}] & =\\mathbf{E}[(M_{t}-M_{s}+M_{s})^{2}|\\mathcal{F}_{s}]\\\\\n& =\\mathbf{E}[(M_{t}-M_{s})^{2}+2(M_{t}-M_{s})M_{s}+M_{s}^{2}|\\mathcal{F}_{s}]\\\\\n& =\\mathbf{E}[(M_{t}-M_{s})^{2}|\\mathcal{F}_{s}]+2\\mathbf{E}[(M_{t}-M_{s})M_{s}|\\mathcal{F}_{s}]+\\mathbf{E}[M_{s}^{2}|\\mathcal{F}_{s}]\\\\\n& =\\mathbf{E}[(M_{t}-M_{s})^{2}]+2M_{s}\\underbrace{\\mathbf{E}[M_{t}-M_{s}]}_{\\text{equals \\ensuremath{0}}}+M_{s}^{2}\\\\\n& =\\mathbf{E}[(M_{t}-M_{s})^{2}]+M_{s}^{2}\n\\end{aligned}\\]\nNow, if \\(X\\sim\\text{Poisson\\ensuremath{(\\lambda t)}}\\), then \\(\\mathbf{E}[X]=\\lambda t\\) and \\(\\mathbf{E}\\ensuremath{[X^{2}]}=\\lambda t(\\lambda t+1)\\).\n\\[\\begin{aligned}\n\\mathbf{E}[(M_{t}-M_{s})^{2}] & =\\mathbf{E}\\left[\\left\\{ (N_{t}-N_{s})-\\lambda(t-s)\\right\\} ^{2}\\right]\\\\\n& =\\mathbf{E}\\left[(N_{t}-N_{s})^{2}\\right]-2\\lambda(t-s)\\mathbf{E}\\left[(N_{t}-N_{s})\\right]+\\lambda^{2}(t-s)^{2}\\\\\n& =\\lambda^{2}(t-s)^{2}+\\lambda(t-s)-2\\lambda(t-s)\\cdot\\lambda(t-s)+\\lambda^{2}(t-s)^{2}\\\\\n& =\\lambda(t-s)\n\\end{aligned}\\]\nThus,\n\\[\\begin{aligned}\n\\mathbf{E}[M_{t}^{2}-\\lambda t|\\mathcal{F}_{s}] & =M_{s}^{2}-\\lambda s\n\\end{aligned}\\]\nWe conclude that the process \\((M_{t}^{2}-\\lambda t:t\\geq0)\\) is a martingale. The Doob-Meyer decomposition of the submartingale \\(M_{t}^{2}\\) is then:\n\\[\\begin{aligned}\nM_{t}^{2} & =(M_{t}^{2}-\\lambda t)+\\lambda t\n\\end{aligned}\\]\n\n\nConsider a Brownian motion \\(B(t)\\). The quadratic variation of the process \\((B(t):t\\geq0)\\) over the interval \\([0,t]\\) is given by \\([B]_{t}=t\\). On the other hand, we saw, that the square of Brownian motion compensated, \\((B_{t}^{2}-t:t\\geq0)\\) is a martingale. Hence, the Doob-Meyer decomposition of \\(B(t)^{2}\\) is given by:\n\\[\\begin{aligned}\nB(t)^{2} & =(B(t)^{2}-t)+t\n\\end{aligned}\\]"
  },
  {
    "objectID": "posts/martingales/index.html#computations-with-martingales.",
    "href": "posts/martingales/index.html#computations-with-martingales.",
    "title": "Martingales",
    "section": "",
    "text": "Martingales are not only conceptually interesting, they are also formidable tools to compute probabilities and expectations of processes. For example, in this section, we will solve the gambler’s ruin problem for Brownian motion. For convenience, we introduce the notion of stopping time before doing so.\n\nA random variable \\(\\tau:\\Omega\\to\\mathbf{N}\\cup\\{+\\infty\\}\\) is said to be a stopping time for the filtration \\((\\mathcal{F}_{t}:t\\geq0)\\) if and only if:\n\\[\\begin{aligned}\n\\{\\omega:\\tau(\\omega)\\leq t\\} & \\in\\mathcal{F}_{t},\\quad\\forall t\\geq0\n\\end{aligned}\\] Note that since \\(\\mathcal{F}_{t}\\) is a sigma-field, if \\(\\tau\\) is a stopping time, then we must also have that \\(\\{\\omega:\\tau(\\omega)&gt;t\\}\\in\\mathcal{F}_{t}\\).\nIn other words, \\(\\tau\\) is a stopping time, if we can decide if the events \\(\\{\\tau\\leq t\\}\\) occurred or not based on the information available at time \\(t\\).\nThe term stopping time comes from gambling: a gambler can decide to stop playing at a random time (depending for example on previous gains or losses), but when he or she decides to stop, his/her decision is based solely upon the knowledge of what happened before, and does not depend on future outcomes. In other words, the stopping policy/strategy can only depend on past outcomes. Otherwise, it would mean that he/she has a crystall ball.\n\n\n(Examples of stopping times).\n(i) First passage time. This is the first time when a process reaches a certain value. To be precise, let \\(X=(X_{t}:t\\geq0)\\) be a process and \\((\\mathcal{F}_{t}:t\\geq0)\\) be its natural filtration. For \\(a&gt;0\\), we define the first passage time at \\(a\\) to be:\n\\[\\begin{aligned}\n\\tau(\\omega) & =\\inf\\{s\\geq0:X_{s}(\\omega)\\geq a\\}\n\\end{aligned}\\]\nIf the path \\(\\omega\\) never reaches \\(a\\), we set \\(\\tau(\\omega)=\\infty\\). Now, for \\(t\\) fixed and for a given path \\(X(\\omega)\\), it is possible to know if \\(\\{\\tau(\\omega)\\leq t\\}\\) (the path has reached \\(a\\) before time \\(t\\)) or \\(\\{\\tau(\\omega)&gt;t\\}\\) (the path has not reached \\(a\\) before time \\(t\\)) with the information available at time \\(t\\), since we are looking at the first time the process reaches \\(a\\). Hence, we conclude that \\(\\tau\\) is a stopping time.\n(ii) Hitting time. More generally, we can consider the first time (if ever) that the path of a process \\((X_{t}:t\\geq0)\\) enters or hits a subset \\(B\\) of \\(\\mathbf{R}\\):\n\\[\\begin{aligned}\n\\tau(\\omega) & =\\min\\{s\\geq0:X_{s}(\\omega)\\in B\\}\n\\end{aligned}\\]\nThe first passage time is the particular case in which \\(B=[a,\\infty)\\).\n(iii) Minimum of two stopping times. If \\(\\tau\\) and \\(\\tau'\\) are two stopping times for the same filtration \\((\\mathcal{F}_{t}:t\\geq0)\\), then so is the minimum \\(\\tau\\land\\tau'\\) between the two, where\n\\[\\begin{aligned}\n(\\tau\\land\\tau')(\\omega) & =\\min\\{\\tau(\\omega),\\tau'(\\omega)\\}\n\\end{aligned}\\]\nThis is because for any \\(t\\geq0\\):\n\\[\\begin{aligned}\n\\{\\omega: & (\\tau\\land\\tau')(\\omega)\\leq t\\}=\\{\\omega:\\tau(\\omega)\\leq t\\}\\cup\\{\\omega:\\tau'(\\omega)\\leq t\\}\n\\end{aligned}\\]\nSince the right hand side is the union of two events in \\(\\mathcal{F}_{t}\\), it must also be in \\(\\mathcal{F}_{t}\\) by the properties of a sigma-field. We conclude that \\(\\tau\\land\\tau'\\) is a stopping time. Is it also the case that the maximum \\(\\tau\\lor\\tau'\\) is a stopping time?\nFor any fixed \\(t\\geq0\\), we have:\n\\[\\begin{aligned}\n\\{\\omega:(\\tau\\lor\\tau')(\\omega)\\leq t\\} & =\\{\\omega:\\tau(\\omega)\\leq t\\}\\cap\\{\\omega:\\tau'(\\omega)\\leq t\\}\n\\end{aligned}\\]\nSince the right hand side is the intersection of two events in \\(\\mathcal{F}_{t}\\), it must also be in \\(\\mathcal{F}_{t}\\) by the properties of a sigma-field. We conclude that \\(\\tau\\lor\\tau'\\) is a stopping time.\n\n\n(Last passage time is not a stopping time). What if we look at the last time the process reaches \\(a\\), that is:\n\\[\\begin{aligned}\n\\rho(\\omega) & =\\sup\\{t\\geq0:X_{t}(\\omega)\\geq a\\}\n\\end{aligned}\\]\nThis is a well-defined random variable, but it is not a stopping time. Based on the information available at time \\(t\\), we are not able to decide whether or not \\(\\{\\rho(\\omega)\\leq t\\}\\) occurred or not, as the path can always reach \\(a\\) one more time after \\(t\\).\n\nIt turns out that a martingale that is stopped when the stopping time is attained remains a martingale.\n\n(Stopped Martingale). If \\((M_{t}:t\\geq0)\\) is a continuous martingale for the filtration \\((\\mathcal{F}_{t}:t\\geq0)\\) and \\(\\tau\\) is a stopping time for the same filtration, then the stopped process defined by \\[\\begin{aligned}\nM_{t\\land\\tau} & =\\begin{cases}\nM_{t} & t\\leq\\tau\\\\\nM_{\\tau} & t&gt;\\tau\n\\end{cases}\n\\end{aligned}\\]\nis also a continuous martingale for the same filtration.\n\n\n[]{#th:doob’s-optional-sampling-theorem label=“th:doob’s-optional-sampling-theorem”}(Doob’s Optional sampling theorem). If \\((M_{t}:t\\geq0)\\) is a continuous martingale for the filtration \\((\\mathcal{F}_{t}:t\\geq0)\\) and \\(\\tau\\) is a stopping time such that \\(\\tau&lt;\\infty\\) and the stopped process \\((M_{t\\land\\tau}:t\\geq0)\\) is bounded, then:\n\\[\\begin{aligned}\n\\mathbf{E}[M_{\\tau}] & =M_{0}\n\\end{aligned}\\]\n\n\nProof. Proof. Since \\((M_{\\tau\\land t}:t\\geq0)\\) is a martingale, we always have:\n\\[\\begin{aligned}\n\\mathbf{E}[M_{\\tau\\land t}] & =M_{0}\n\\end{aligned}\\]\nNow, since \\(\\tau(\\omega)&lt;\\infty\\), we must\nhave that \\(\\lim_{t\\to\\infty}M_{\\tau\\land t}=M_{\\tau}\\) almost surely. In particular, we have:\n\\[\\begin{aligned}\n\\mathbf{E}[M_{\\tau}] & =\\mathbf{E}\\left[\\lim_{t\\to\\infty}M_{\\tau\\land t}\\right]=\\lim_{t\\to\\infty}\\mathbf{E}[M_{\\tau\\land t}]=\\lim_{t\\to\\infty}M_{0}\n\\end{aligned}\\]\nwhere we passed to the limit, using the dominated convergence theorem ([th:dominated-convergence-theorem]). ◻\n\n\n(Gambler’s ruin with Brownian motion). The gambler’s ruin problem is known in different forms. Roughly speaking, it refers to the problem of computing the probability of a gambler making a series of bets reaching a certain amount before going broke. In terms of Brownian motion (and stochastic processes in general), it translates to the following questions: Let \\((B_{t}:t\\geq0)\\) be a standard brownian motion starting at \\(B_{0}=0\\) and \\(a,b&gt;0\\).\n(1) What is the probability that a Brownian path reaches \\(a\\) before \\(-b\\)?\n(2) What is the expected waiting time for the path to reach \\(a\\) or \\(-b\\)?\nFor the first question, it is a simple computation using stopping time and martingale properties. Define the hitting time:\n\\[\\begin{aligned}\n\\tau(\\omega) & =\\inf\\{t\\geq0:B_{t}(\\omega)\\geq a\\text{ or }B_{t}(\\omega)\\leq-b\\}\n\\end{aligned}\\]\nNote that \\(\\tau\\) is the minimum between the first passage time at \\(a\\) and the one at \\(-b\\).\nWe first show that \\(\\tau&lt;\\infty\\) almost surely. In other words, all Brownian paths reach \\(a\\) or \\(-b\\) eventually. To see this, consider the event \\(E_{n}\\) that the \\(n\\)-th increment exceeds \\(a+b\\)\n\\[\\begin{aligned}\nE_{n} & :=\\left\\{ |B_{n}-B_{n-1}|&gt;a+b\\right\\}\n\\end{aligned}\\]\nNote that, if \\(E_{n}\\) occurs, then we must have that the Brownian motion path exits the interval \\([-b,a].\\) Moreover, we have \\(\\mathbb{P}(E_{n})=\\mathbb{P}(E_{1})\\) for all \\(n\\). Call this probability \\(p\\).\nSince the events \\(E_{n}\\) are independent, we have:\n\\[\\begin{aligned}\n\\mathbb{P}(E_{1}^{C}\\cap E_{2}^{C}\\cap\\ldots\\cap E_{n}^{C}) & =(1-p)^{n}\n\\end{aligned}\\]\nAs \\(n\\to\\infty\\) we have:\n\\[\\begin{aligned}\n\\lim_{n\\to\\infty}\\mathbb{P}(E_{1}^{C}\\cap E_{2}^{C}\\cap\\ldots\\cap E_{n}^{C}) & =0\n\\end{aligned}\\]\nThe sequence of events \\((F_{n})\\) where \\(F_{n}=E_{1}^{C}\\cap E_{2}^{C}\\cap\\ldots\\cap E_{n}^{C}\\) is a decreasing sequence of events. By the continuity of probability measure lemma ([th:continuity-property-of-lebesgue-measure]), we conclude that:\n\\[\\begin{aligned}\n\\lim_{n\\to\\infty}\\mathbb{P}\\left(F_{n}\\right) & =\\mathbb{P}\\left(\\bigcap_{n=1}^{\\infty}F_{n}\\right)=0\n\\end{aligned}\\]\nTherefore, it must be the case \\(\\mathbb{P}(\\cup_{n=1}^{\\infty}E_{n})=1\\). So, \\(E_{n}\\) must occur for some \\(n\\), so all brownian motion paths reach \\(a\\) or \\(-b\\) almost surely.\nSince \\(\\tau&lt;\\infty\\) with probability one, the random variable \\(B_{\\tau}\\) is well-defined : \\(B_{\\tau}(\\omega)=B_{t}(\\omega)\\) if \\(\\tau(\\omega)=t\\). It can only take two values: \\(a\\) or \\(-b\\). Question (1) above translates into computing \\(\\mathbb{P}(B_{\\tau}=a)\\). On one hand, we have:\n\\[\\begin{aligned}\n\\mathbf{E}[B_{\\tau}] & =a\\mathbb{P}(B_{\\tau}=a)+(-b)(1-\\mathbb{P}(B_{\\tau}=a))\n\\end{aligned}\\]\nOn the other hand, by corollary ([th:doob's-optional-sampling-theorem]), we have \\(\\mathbf{E}[B_{\\tau}]=\\mathbf{E}[B_{0}]=0\\). (Note that the stopped process \\((B_{t\\land\\tau}:t\\geq0)\\) is bounded above by \\(a\\) and by \\(-b\\) below). Putting these two observations together, we get:\n\\[\\begin{aligned}\n\\mathbb{P}(B_{\\tau}=a) & =\\frac{b}{a+b}\n\\end{aligned}\\]\nA very simple and elegant answer!\nWe will revisit this problem again and again. In particular, we will answer the question above for Brownian motion with a drift at length further ahead.\n\n\n(Expected Waiting Time). Let \\(\\tau\\) be as in the last example. We now answer question (2) of the gambler’s ruin problem:\n\\[\\begin{aligned}\n\\mathbf{E}[\\tau] & =ab\n\\end{aligned}\\]\nNote that the expected waiting time is consistent with the rough heuristic that Brownian motion travels a distance \\(\\sqrt{t}\\) by time \\(t\\). We now use the martingale \\(M_{t}=B_{t}^{2}-t\\). On the one hand, if we apply optional stopping in corollary ([th:doob's-optional-sampling-theorem]), we get:\n\\[\\begin{aligned}\n\\mathbf{E}[M_{\\tau}] & =M_{0}=0\n\\end{aligned}\\]\nMoreover, we know the distribution of \\(B_{\\tau}\\), thanks to the probability calculated in the last example. We can therefore compute \\(\\mathbf{E}[M_{\\tau}]\\) directly:\n\\[\\begin{aligned}\n0 & =\\mathbf{E}[M_{\\tau}]\\\\\n& =\\mathbf{E}[B_{\\tau}^{2}-\\tau]\\\\\n& =\\mathbf{E}[B_{\\tau}^{2}]-\\mathbf{E}[\\tau]\\\\\n& =a^{2}\\cdot\\frac{b}{a+b}+b^{2}\\cdot\\frac{a}{a+b}-\\mathbf{E}[\\tau]\\\\\n\\mathbf{E}[\\tau] & =\\frac{a^{2}b+b^{2}a}{a+b}\\\\\n& =\\frac{ab\\cancel{(a+b)}}{\\cancel{(a+b)}}=ab\n\\end{aligned}\\]\nWhy can we apply optional stopping here? The random variable \\(\\tau\\) is finite with probability \\(1\\) as before. However, the stopped martingale is not necessarily bounded as before: \\(B_{\\tau\\land t}\\) is bounded but \\(\\tau\\) is not. However, the conclusion of optional stopping still holds. Indeed, we have:\n\\[\\begin{aligned}\n\\mathbf{E}[M_{t\\land\\tau}] & =\\mathbf{E}[B_{t\\land\\tau}^{2}]-\\mathbf{E}[t\\land\\tau]\n\\end{aligned}\\]\nBy the bounded convergence theorem, we get \\(\\lim_{t\\to\\infty}\\mathbf{E}[B_{t\\land\\tau}^{2}]=\\mathbf{E}[\\lim_{t\\to\\infty}B_{t\\land\\tau}^{2}]=\\mathbf{E}[B_{\\tau}^{2}]\\). Since \\(\\tau\\land t\\) is a non-decreasing sequence and as \\(t\\to\\infty\\), \\(t\\land\\tau\\to\\tau\\) almost surely, as \\(\\tau&lt;\\infty\\), by the monotone convergence theorem, \\(\\lim_{t\\to\\infty}\\mathbf{E}[t\\land\\tau]=\\mathbf{E}[\\tau]\\).\n\n\n(First passage time of Brownian Motion.) We can use the previous two examples to get some very interesting information on the first passage time:\n\\[\\begin{aligned}\n\\tau_{a} & =\\inf\\{t\\geq0:B_{t}\\geq a\\}\n\\end{aligned}\\]\nLet \\(\\tau=\\tau_{a}\\land\\tau_{-b}\\) be as in the previous examples with \\(\\tau_{-b}=\\inf\\{t\\geq0:B_{t}\\leq-b\\}\\). Note that \\((\\tau_{-b},b\\in\\mathbf{R}_{+})\\) is a sequence of random variables that is increasing in \\(b\\). A brownian motion path must cross through \\(-1\\) before it hits \\(-2\\) for the first time and in general \\(\\tau_{-n}(\\omega)\\leq\\tau_{-(n+1)}(\\omega)\\). Moreover, we have \\(\\tau_{-b}\\to\\infty\\) almost surely as \\(b\\to\\infty\\). That’s because, \\(\\mathbb{P}\\{\\tau&lt;\\infty\\}=1\\). Moreover, the event \\(\\{B_{\\tau}=a\\}\\) is the same as \\(\\{\\tau_{a}&lt;\\tau_{-b}\\}\\). Now, the events \\(\\{\\tau_{a}&lt;\\tau_{-b}\\}\\) are increasing in \\(b\\), since if a path reaches \\(a\\) before \\(-b\\), it will do so as well for a more negative value of \\(-b\\). On one hand, this means by the continuity of probability measure lemma ([th:continuity-property-of-lebesgue-measure]) that:\n\\[\\begin{aligned}\n\\lim_{b\\to\\infty}\\mathbb{P}\\left\\{ \\tau_{a}&lt;\\tau_{-b}\\right\\}  & =\\mathbb{P}\\{\\lim_{b\\to\\infty}\\tau_{a}&lt;\\tau_{-b}\\}\\\\\n& =\\mathbb{P}\\{\\tau_{a}&lt;\\infty\\}\n\\end{aligned}\\]\nOn the other hand, we have by example ([example:probability-of-hitting-times])\n\\[\\begin{aligned}\n\\lim_{b\\to\\infty}\\mathbb{P}\\left\\{ \\tau_{a}&lt;\\tau_{-b}\\right\\}  & =\\lim_{b\\to\\infty}\\mathbb{P}\\{B_{\\tau}=a\\}\\\\\n& =\\lim_{b\\to\\infty}\\frac{b}{b+a}\\\\\n& =1\n\\end{aligned}\\]\nWe just showed that:\n\\[\\begin{aligned}\n\\mathbb{P}\\left\\{ \\tau_{a}&lt;\\infty\\right\\}  & =1\\label{eq:first-passage-time-to-a-is-finite-almost-surely}\n\\end{aligned}\\]\nIn other words, every Brownian path will reach \\(a\\), no matter how large \\(a\\) is!\nHow long will it take to reach \\(a\\) on average? Well, we know from example ([ex:expected-waiting-times]) that \\(\\mathbf{E}[\\tau_{a}\\land\\tau_{-b}]=ab\\). On one hand this means,\n\\[\\begin{aligned}\n\\lim_{b\\to\\infty}\\mathbf{E}[\\tau_{a}\\land\\tau_{-b}] & =\\lim_{b\\to\\infty}ab=\\infty\n\\end{aligned}\\]\nOn the other hand, since the random variables \\(\\tau_{-b}\\) are increasing,\n\\[\\begin{aligned}\n\\lim_{b\\to\\infty}\\mathbf{E}[\\tau_{a}\\land\\tau_{-b}] & =\\mathbf{E}\\left[\\lim_{b\\to\\infty}\\tau_{a}\\land\\tau_{-b}\\right]=\\mathbf{E}[\\tau_{a}]\n\\end{aligned}\\]\nby the monotone convergence theorem ([th:monotone-convergence-theorem]). We just proved that:\n\\[\\begin{aligned}\n\\mathbf{E}[\\tau_{a}] & =\\infty\n\\end{aligned}\\]\nIn other words, any Brownian motion path will reach \\(a\\), but the expected waiting time for this to occur is infinite, no matter, how small \\(a\\) is! What is happening here? No matter, how small \\(a\\) is, there is always paths that reach very large negative values before hitting \\(a\\). These paths might be unlikely. However, the first passage time for these paths is so large that they affect the value of the expectation substantially. In other words, \\(\\tau_{a}\\) is a heavy-tailed random variable. We look at the distribution of \\(\\tau_{a}\\) in more detail in the next section.\n\n\n(When option stopping fails). Consider \\(\\tau_{a}\\), the first passage time at \\(a&gt;0\\). The random variable \\(B_{\\tau_{a}}\\) is well-defined since \\(\\tau_{a}&lt;\\infty\\). In fact, we have \\(B_{\\tau_{a}}=a\\) with probability one. Therefore, the following must hold:\n\\[\\begin{aligned}\n\\mathbf{E}[B_{\\tau_{a}}] & =a\\neq B_{0}\n\\end{aligned}\\]\nOptional stopping theorem corollary ([th:doob's-optional-sampling-theorem]) does not apply here, since the stopped process \\((B_{t\\land\\tau_{a}}:t\\geq0)\\) is not bounded. \\(B_{t\\land\\tau_{a}}\\) can become infinitely negative before hitting \\(a\\)."
  },
  {
    "objectID": "posts/martingales/index.html#reflection-principle-for-brownian-motion.",
    "href": "posts/martingales/index.html#reflection-principle-for-brownian-motion.",
    "title": "Martingales",
    "section": "",
    "text": "(Bachelier’s formula). Let \\((B_{t}:t\\leq T)\\) be a standard brownian motion on \\([0,T].\\) Then, the CDF of the random variable \\(\\sup_{0\\leq t\\leq T}B_{t}\\) is:\n\\[\\begin{aligned}\n\\mathbb{P}\\left(\\sup_{0\\leq t\\leq T}B_{t}\\leq a\\right) & =\\mathbb{P}\\left(|B_{T}|\\leq a\\right)\n\\end{aligned}\\]\nIn particular, its PDF is:\n\\[\\begin{aligned}\nf_{\\max}(a) & =\\frac{2}{\\sqrt{2\\pi T}}e^{-\\frac{a^{2}}{2T}}\n\\end{aligned}\\]\n\n\nWe can verify these results empirically. Note that the paths of the random variables \\(\\max_{0\\leq s\\leq t}B_{s}\\) and \\(|B_{t}|\\) are very different as \\(t\\) varies for a given \\(\\omega\\). One is increasing and the other is not. The equality holds in distribution for a fixed \\(t\\). As a bonus corollary, we get the distribution of the first passage time at \\(a\\).\n\n\nLet \\(a\\geq0\\) and \\(\\tau_{a}=\\inf\\{t\\geq0:B_{t}\\geq a\\}\\). Then:\n\\[\\begin{aligned}\n\\mathbb{P}\\left(\\tau_{a}\\leq T\\right) & =\\mathbb{P}\\left(\\max_{0\\leq t\\leq T}B_{t}\\geq a\\right)=\\int_{a}^{\\infty}\\frac{2}{\\sqrt{2\\pi T}}e^{-\\frac{x^{2}}{2T}}dx\n\\end{aligned}\\]\nIn particular, the random variable \\(\\tau_{a}\\) has the PDF:\n\\[\\begin{aligned}\nf_{\\tau_{a}}(t) & =\\frac{a}{\\sqrt{2\\pi}}\\frac{e^{-\\frac{a^{2}}{2t}}}{t^{3/2}},\\quad t&gt;0\n\\end{aligned}\\]\nThis implies that it is heavy-tailed with \\(\\mathbf{E}[\\tau_{a}]=\\infty\\).\n\n\nProof. Proof. The maximum on \\([0,T]\\) is larger than or equal to \\(a\\) if and only if \\(\\tau_{a}\\leq T\\). Therefore, the events \\(\\{\\max_{0\\leq t\\leq T}B_{t}\\geq a\\}\\) and \\(\\{\\tau_{a}\\leq T\\}\\) are the same. So, the CDF \\(\\mathbb{P}(\\tau_{a}\\leq t)\\) of \\(\\tau_{a}\\), by proposition ([prop:bacheliers-formula]) \\(\\int_{a}^{\\infty}f_{\\max}(x)dx=\\int_{a}^{\\infty}\\frac{2}{\\sqrt{2\\pi T}}e^{-\\frac{x^{2}}{2T}}dx\\).\n\\[\\begin{aligned}\nf_{\\tau_{a}}(t) & =-2\\phi(a/\\sqrt{t})\\cdot a\\cdot\\left(-\\frac{1}{2t^{3/2}}\\right)\\\\\n& =\\frac{a}{t^{3/2}}\\phi\\left(\\frac{a}{\\sqrt{t}}\\right)\\\\\n& =\\frac{a}{t^{3/2}}\\cdot\\frac{1}{\\sqrt{2\\pi}}e^{-\\frac{a^{2}}{2t}}\n\\end{aligned}\\]\nTo estimate the expectation, it suffices to realize that for \\(t\\geq1\\), \\(e^{-\\frac{a^{2}}{2t}}\\) is larger than \\(e^{-\\frac{a^{2}}{2}}\\). Therefore, we have:\n\\[\\begin{aligned}\n\\mathbf{E}[\\tau_{a}] & =\\int_{0}^{\\infty}t\\frac{a}{\\sqrt{2\\pi}}\\frac{e^{-a^{2}/2t}}{t^{3/2}}dt\\geq\\frac{ae^{-a^{2}/2}}{\\sqrt{2\\pi}}\\int_{1}^{\\infty}t^{-1/2}dt\n\\end{aligned}\\]\nThis is an improper integral and it diverges like \\(\\sqrt{t}\\) and is infinite as claimed. ◻\n\nTo prove proposition ([prop:bacheliers-formula]), we will need an important property of Brownian motion called the reflection principle. To motivate it, recall the reflection symmetry of Brownian motion at time \\(s\\) in proposition ([prop:brownian-motion-symmetry-of-reflection-at-time-s]). It turns out that this reflection property also holds if \\(s\\) is replaced by a stopping time.\n\n(Reflection principle). Let \\((B_{t}:t\\geq0)\\) be a standard Brownian motion and let \\(\\tau\\) be a stopping time for its filtration. Then, the process \\((\\tilde{B}_{t}:t\\geq0)\\) defined by the reflection at time \\(\\tau\\):\n\\[\\begin{aligned}\n\\tilde{B}_{t} & =\\begin{cases}\nB_{t} & \\text{if \\ensuremath{t\\leq\\tau}}\\\\\nB_{\\tau}-(B_{t}-B_{\\tau}) & \\text{if \\ensuremath{t&gt;\\tau}}\n\\end{cases}\n\\end{aligned}\\]\nis also a standard brownian motion.\n\n\nWe defer the proof of the reflection property of Brownian motion to a further section. It is intuitive and instructive to quickly picture this in the discrete-time setting. I adopt the approach as in Shreve-I.\nWe repeatedly toss a fair coin (\\(p\\), the probability of \\(H\\) on each toss, and \\(q=1-p\\), the probability of \\(T\\) on each toss, are both equal to \\(\\frac{1}{2}\\)). We denote the successive outcomes of the tosses by \\(\\omega_{1}\\omega_{2}\\omega_{3}\\ldots\\). Let\n\\[\\begin{aligned}\nX_{j} & =\\begin{cases}\n-1 & \\text{if \\ensuremath{\\omega_{j}=H}}\\\\\n+1 & \\text{if \\ensuremath{\\omega_{j}=T}}\n\\end{cases}\n\\end{aligned}\\]\nand define \\(M_{0}=0\\), \\(M_{n}=\\sum_{j=1}^{n}X_{n}\\). The process \\((M_{n}:n\\in\\mathbf{N})\\) is a symmetric random walk.\nSuppose we toss a coin an odd number \\((2j-1)\\) of times. Some of the paths will reach level \\(1\\) in the first \\(2j-1\\) steps and other will not reach. In the case of \\(3\\) tosses, there are \\(2^{3}=8\\) possible paths and \\(5\\) of these reach level \\(1\\) at some time \\(\\tau_{1}\\leq2j-1\\). From that moment on, we can create a reflected path, which steps up each time the original path steps down and steps down each time the original path steps up. If the original path ends above \\(1\\) at the final time \\(2j-1\\), the reflected path ends below \\(1\\) and vice versa. If the original path ends at \\(1\\), the reflected path does also. In fact, the reflection at the first hitting time has the same distribution as the original random walk.\nThe key here is, out of the \\(5\\) paths that reach level \\(1\\) at some time, there are as many reflected paths that exceed \\(1\\) at time \\((2j-1)\\) as there are original paths that exceed \\(1\\) at time \\((2j-1)\\). So, to count the total number of paths that reach level \\(1\\) by time \\((2j-1)\\), we can count the paths that are at \\(1\\) at time \\((2j-1)\\) and then add on twice the number of paths that exceed \\(1\\) at time \\((2j-1)\\).\n\nWith this new tool, we can now prove proposition ([prop:bacheliers-formula]).\n\nProof. Proof. Consider \\(\\mathbb{P}(\\max_{t\\leq T}B_{t}\\geq a)\\). By splitting this probability over the event of the endpoint, we have:\n\\[\\begin{aligned}\n\\mathbb{P}\\left(\\max_{t\\leq T}B_{t}\\geq a\\right) & =\\mathbb{P}\\left(\\max_{t\\leq T}B_{t}\\geq a,B_{T}&gt;a\\right)+\\mathbb{P}\\left(\\max_{t\\leq T}B_{t}\\geq a,B_{T}\\leq a\\right)\n\\end{aligned}\\]\nNote also, that \\(\\mathbb{P}(B_{T}=a)=0\\). Hence, the first probability equals \\(\\mathbb{P}(B_{T}\\geq a)\\). As for the second, consider the time \\(\\tau_{a}\\). On the event considered, we have \\(\\tau_{a}\\leq T\\) and using lemma ([lemma:BM-reflection-principle]) at that time, we get\n\\[\\begin{aligned}\n\\mathbb{P}\\left(\\max_{t\\leq T}B_{t}\\geq a,B_{T}\\leq a\\right) & =\\mathbb{P}\\left(\\max_{t\\leq T}B_{t}\\geq a,\\tilde{B}_{T}\\geq a\\right)\n\\end{aligned}\\]\nObserve that the event \\(\\{\\max_{t\\leq T}B_{t}\\geq a\\}\\) is the same as \\(\\{\\max_{t\\leq T}\\tilde{B}_{T}\\geq a\\}\\). (A rough picture might help here.) Thereforem the above probability is\n\\[\\begin{aligned}\n\\mathbb{P}\\left(\\max_{t\\leq T}B_{t}\\geq a,B_{T}\\leq a\\right) & =\\mathbb{P}\\left(\\max_{t\\leq T}\\tilde{B}_{t}\\geq a,\\tilde{B}_{T}\\geq a\\right)=\\mathbb{P}\\left(\\max_{t\\leq T}B_{t}\\geq a,B_{T}\\geq a\\right)\n\\end{aligned}\\]\nwhere the last equality follows from the reflection principle (\\(\\tilde{B}_{t}\\) is also a standard brownian motion, and \\(B_{T}\\) and \\(\\tilde{B}_{T}\\) have the same distribution.) But, as above, the last probability is equal to \\(\\mathbb{P}(B_{T}\\geq a)\\). We conclude that:\n\\[\\begin{aligned}\n\\mathbb{P}\\left(\\max_{t\\leq T}B_{t}\\geq a\\right) & =2\\mathbb{P}(B_{T}\\geq a)=\\frac{2}{\\sqrt{2\\pi T}}\\int_{a}^{\\infty}e^{-\\frac{x^{2}}{2T}}dx=\\mathbb{P}(|B_{T}|\\geq a)\n\\end{aligned}\\]\nThis implies in particular that \\(\\mathbb{P}\\left(\\max_{t\\leq T}B_{t}=a\\right)=0\\). Thus, we also have \\(\\mathbb{P}(\\max_{t\\leq T}B_{t}\\leq a)=\\mathbb{P}(|B_{T}|\\leq a)\\) as claimed. ◻\n\n\n(Simulating Martingales) Sample \\(10\\) paths of the following process with a step-size of \\(0.01\\):\n(a) \\(B_{t}^{2}-t\\), \\(t\\in[0,1]\\)\n(b) Geometric Brownian motion : \\(S_{t}=\\exp(B_{t}-t/2)\\), \\(t\\in[0,1]\\).\nLet’s write a simple \\(\\texttt{BrownianMotion}\\) class, that we shall use to generate sample paths.\n\nimport numpy as np\nimport matplotlib.pyplot as plt\n\nimport attrs\nfrom attrs import define, field\n\n@define\nclass BrownianMotion:\n    _step_size = field(validator=attrs.validators.and_(attrs.validators.instance_of(float),\n                                                       attrs.validators.ge(0.0)))\n    # Time T\n    _T = field(validator=attrs.validators.and_(attrs.validators.instance_of(float),\n                                               attrs.validators.ge(0.0)))\n    # number of paths\n    _N = field(validator=attrs.validators.and_(attrs.validators.instance_of(int),\n                                               attrs.validators.gt(0)))\n\n    _num_steps = field(init=False)\n\n    def __attrs_post_init__(self):\n        self._num_steps = int(self._T/self._step_size)\n\n    def covariance_matrix(self):\n        C = np.zeros((self._num_steps,self._num_steps))\n\n        for i in range(self._num_steps):\n            for j in range(self._num_steps):\n                s = (i+1) * self._step_size\n                t = (j+1) * self._step_size\n                C[i,j] = min(s,t)\n        return C\n\n    # Each column vector represents a sample path\n    def generate_paths(self):\n        C = self.covariance_matrix()\n        A = np.linalg.cholesky(C)\n        Z = np.random.standard_normal((self._num_steps, self._N))\n        X = np.matmul(A,Z)\n        X = np.concatenate((np.zeros((1,self._N)),X),axis=0)\n        return X.transpose()\nNow, the process \\(B_{t}^{2}-t\\) can be sampled as follows:\n\ndef generateSquareOfBMCompensated(numOfPaths,stepSize,T):\n    N = int(T/stepSize)\n\n    X = []\n    brownianMotion = BrownianMotion(stepSize,T)\n    for n in range(numOfPaths):\n\n        B_t = brownianMotion.samplePath()\n\n        B_t_sq = np.square(B_t)\n\n        t = np.linspace(start=0.0,stop=1.0,num=N+1)\n        M_t = np.subtract(B_t_sq,t)\n        X.append(M_t)\n\n    return X\nThe gBM process can be sampled similarly, with \\(\\texttt{\\ensuremath{M_{t}} = np.exp(np.subtract(\\ensuremath{B_{t}},t/2))}\\).\n\n(Maximum of Brownian Motion.) Consider the maximum of Brownian motion on \\([0,1]\\): \\(\\max_{s\\leq1}B_{s}\\).\n(a) Draw the histogram of the random variable \\(\\max_{s\\leq1}B_{s}\\)using \\(10,0000\\) sampled Brownian paths with a step size of \\(0.01\\).\n(b) Compare this to the PDF of the random variable \\(|B_{1}|\\).\n\nSolution.\nI use the \\(\\texttt{itertools}\\) python library to compute the running maximum of a brownian motion path.\n\nbrownianMotion = BrownianMotion(stepSize=0.01,T=1)\ndata = []\n\nfor i in range(10000):\n    B_t = brownianMotion.samplePath()\n    max_B_t = list(itertools.accumulate(B_t,max))\n    data.append(max_B_t[100])\nAnalytically, we know that \\(B_{1}\\) is a gaussian random variable with mean \\(0\\) and variance \\(1\\).\n\\[\\begin{aligned}\n\\mathbb{P}(|B_{1}|\\leq z) & =\\mathbb{P}(|Z|\\leq z)\\\\\n& =\\mathbb{P}(-z\\leq Z\\leq z)\\\\\n& =\\mathbb{P}(Z\\leq z)-\\mathbb{P}(Z\\leq-z)\\\\\n& =\\mathbb{P}(Z\\leq z)-(1-\\mathbb{P}(Z\\leq z))\\\\\nF_{|B_{1}|}(z) & =2\\Phi(z)-1\n\\end{aligned}\\]\nDifferentiating on both sides, we get:\n\\[\\begin{aligned}\nf_{|B_{1}|}(z) & =2\\phi(z)=\\frac{2}{\\sqrt{2\\pi}}e^{-\\frac{z^{2}}{2}},\\quad z\\in[0,\\infty)\n\\end{aligned}\\]\n\n(First passage time.) Let \\((B_{t}:t\\geq0)\\) be a standard brownian motion. Consider the random variable:\n\\[\\begin{aligned}\n\\tau & =\\min\\{t\\geq0:B_{t}\\geq1\\}\n\\end{aligned}\\]\nThis is the first time that \\(B_{t}\\) reaches \\(1\\).\n(a) Draw a histogram for the distribution of \\(\\tau\\land10\\) on the time-interval \\([0,10]\\) using \\(10,000\\) brownian motion paths on \\([0,10]\\) with discretization \\(0.01\\).\nThe notation \\(\\tau\\land10\\) means that if the path does not reach \\(1\\) on \\([0,10]\\), then give the value \\(10\\) to the stopping time.\n(b) Estimate \\(\\mathbf{E}[\\tau\\land10]\\).\n(c) What proportion of paths never reach \\(1\\) in the time interval \\([0,10]\\)?\n\nSolution.\nTo compute the expectation, we classify the hitting times of all paths into \\(50\\) bins. I simply did\n\\(\\texttt{frequency, bins = np.histogram(firstPassageTimes,bins=50,range=(0,10))}\\)\nand then computed\n\\(\\texttt{expectation=np.dot(frequency,bins[1:])/10000}\\).\nThis expectation estimate on my machine is \\(\\mathbf{E}[\\tau\\land10]=4.34\\) secs. There were approximately \\(2600\\) paths out of \\(10,000\\) that did not reach \\(1\\).\n\nGambler’s ruin at the French Roulette. Consider the scenario in which you are gambling \\(\\$1\\) at the French roulette on the reds: You gain \\(\\$1\\) with probability \\(18/38\\) and you lose a dollar with probability \\(20/38\\). We estimate the probability of your fortune reaching \\(\\$200\\) before it reaches \\(0\\).\n(a) Write a function that samples the simple random walk path from time \\(0\\) to time \\(5,000\\) with a given starting point.\n(b) Use the above to estimate the probability of reaching \\(\\$200\\) before \\(\\$0\\) on a sample of \\(100\\) paths if you start with \\(\\$100\\).\n\n\n[]{#ex:doob’s-maximal-inequality label=“ex:doob’s-maximal-inequality”}Doob’s maximal inequalities. We prove the following: Let \\((M_{k}:k\\geq1)\\) be positive submartingale for the filtration \\((\\mathcal{F}_{k}:k\\in\\mathbf{N})\\). Then, for any \\(1\\leq p&lt;\\infty\\) and \\(a&gt;0\\)\n\\[\\begin{aligned}\n\\mathbb{P}\\left(\\max_{k\\leq n}M_{k}&gt;a\\right) & \\leq\\frac{1}{a^{p}}\\mathbf{E}[M_{n}^{p}]\n\\end{aligned}\\]\n(a) Use Jensen’s inequality to show that if \\((M_{k}:k\\geq1)\\) is a positive submartingale, then so is \\((M_{k}^{p}:k\\geq1)\\) for \\(1\\leq p&lt;\\infty\\). Conclude that it suffices to prove the statement for \\(p=1\\).\n\nSolution.\nThe function \\(f(x)=x^{p}\\) is convex. By conditional Jensen’s inequality,\n\\[\\begin{aligned}\n\\left(\\mathbf{E}[M_{k+1}|\\mathcal{F}_{k}]\\right)^{p} & \\leq\\mathbf{E}[M_{k}^{p}|\\mathcal{F}_{k}]\n\\end{aligned}\\]\nThus,\n\\[\\begin{aligned}\n\\mathbf{E}[M_{k+1}^{p}|\\mathcal{F}_{k}] & \\geq\\left(\\mathbf{E}[M_{k+1}|\\mathcal{F}_{k}]\\right)^{p}\\geq M_{k}^{p}\n\\end{aligned}\\]\nwhere the last inequality follows from the fact that \\((M_{k}:k\\geq1)\\) is a positive submartingale, so \\(\\mathbf{E}[M_{k+1}|\\mathcal{F}_{k}]\\geq M_{k}\\). Consequently, \\((M_{k}^{p}:k\\geq1)\\) is also a positive submartingale.\n(b) Consider the events\n\\[\\begin{aligned}\nB_{k} & =\\bigcap_{j&lt;k}\\{\\omega:M_{j}(\\omega)\\leq a\\}\\cap\\{\\omega:M_{k}(\\omega)&gt;a\\}\n\\end{aligned}\\]\nArgue that the \\(B_{k}\\)’s are disjoint and that \\(\\bigcup_{k\\leq n}B_{k}=\\{\\max_{k\\leq n}M_{k}&gt;a\\}=B\\).\nSolution.\nClearly, \\(B_{k}\\) is the event that the first time to cross \\(a\\) is \\(k\\). If \\(B_{k}\\) occurs, \\(B_{k+1},B_{k+2},\\ldots\\) fail to occur. Hence, all \\(B_{k}'s\\) are pairwise disjoint. The event \\(\\bigcup_{k\\leq n}B_{k}\\) is the event that the random walk crosses \\(a\\) at any time \\(k\\leq n\\). Thus, the running maximum of the Brownian motion at time \\(n\\) exceeds \\(a\\).\n(c) Show that\n\\[\\begin{aligned}\n\\mathbf{E}[M_{n}]\\geq\\mathbf{E}[M_{n}\\mathbf{1}_{B}] & \\geq a\\sum_{k\\leq n}\\mathbb{P}(B_{k})=a\\mathbb{P}(B)\n\\end{aligned}\\]\nby decomposing \\(B\\) in \\(B_{k}\\)’s and by using the properties of expectations, as well as the submartingale property.\nSolution.\nClearly, \\(M_{n}\\geq M_{n}\\mathbf{1}_{B}\\geq a\\mathbf{1}_{B}\\). And \\(M_{n}\\) is a positive random variable. By monotonicity of expectations, \\(\\mathbf{E}[M_{n}]\\geq\\mathbf{E}[M_{n}\\mathbf{1}_{B}]\\geq a\\mathbf{E}[\\mathbf{1}_{B}]=a\\mathbb{P}(B)=a\\sum_{k\\leq n}\\mathbb{P}(B_{k})\\), where the last equality holds because the \\(B_{k}\\)’s are disjoint.\n(d) Argue that the inequality holds for continuous paths by discretizing time and using convergence theorems : If \\((M_{t}:t\\geq0)\\) is a positive submartingale with continuous paths for the filtration \\((\\mathcal{F}_{t}:t\\geq0)\\), then for any \\(1\\leq p&lt;\\infty\\) and \\(a&gt;0\\):\n\\[\\begin{aligned}\n\\mathbb{P}\\left(\\max_{s\\leq t}M_{s}&gt;a\\right) & \\leq\\frac{1}{a^{p}}\\mathbf{E}[M_{t}^{p}]\n\\end{aligned}\\]\nSolution.\nLet \\((M_{t}:t\\geq0)\\) be a positive submartingale with continuous paths for the filtration \\((\\mathcal{F}_{t}:t\\geq0)\\). Consider a sequence of partitions of the interval \\([0,t]\\) into \\(2^{r}\\) subintervals :\n\\[\\begin{aligned}\nD_{r} & =\\left\\{ \\frac{kt}{2^{r}}:k=0,1,2,\\ldots,2^{n}\\right\\}\n\\end{aligned}\\]\nAnd consider a sequence of discrete positive sub-martingales:\n\\[\\begin{aligned}\nM_{kt/2^{r}}^{(r)} & =M_{kt/2^{r}},\\quad k\\in\\mathbf{N},0\\leq k\\leq2^{r}\n\\end{aligned}\\]\nNext, we define for \\(r=1,2,3,\\ldots\\)\n\\[\\begin{aligned}\nA_{r} & =\\left\\{ \\sup_{s\\in D_{r}}|M_{s}^{(r)}|&gt;a\\right\\}\n\\end{aligned}\\]\nBy using the maximal inequality in discrete time, gives us:\n\\[\\begin{aligned}\n\\mathbb{P}(A_{r})=\\mathbb{P}\\left\\{ \\sup_{s\\in D_{r}}|M_{s}^{(r)}|&gt;a\\right\\}  & \\leq\\frac{1}{a^{p}}\\mathbf{E}\\left[\\left(M_{s}^{(r)}\\right)^{p}\\right]=\\frac{1}{a^{p}}\\mathbf{E}\\left[M_{t}^{p}\\right]\n\\end{aligned}\\]\n\\[\\begin{aligned}\n\\mathbb{P}\\left(\\max_{s\\leq t}M_{s}&gt;a\\right) & =\\mathbb{P}\\left(\\bigcup_{r=1}^{\\infty}A_{r}\\right)\\\\\n& =\\lim_{r\\to\\infty}\\mathbb{P}\\left(A_{r}\\right)\\\\\n& \\left\\{ \\text{Continuity of probability measure}\\right\\} \\\\\n& \\leq\\lim_{r\\to\\infty}\\frac{1}{a^{p}}\\mathbf{E}\\left[M_{t}^{p}\\right]\n\\end{aligned}\\]"
  },
  {
    "objectID": "posts/multivariate_ito_calculus/index.html",
    "href": "posts/multivariate_ito_calculus/index.html",
    "title": "Multivariate Ito Calculus",
    "section": "",
    "text": "We can generalize the theory to functions of several brownian motions. This unleashes the full power of Ito calculus.\n\n\n\nDefinition 1 (Brownian motion in \\(\\mathbf{R}^{d}\\).) Take \\(d\\in\\mathbf{N}\\). Let \\(B^{(1)},\\ldots,B^{(d)}\\) be independent standard Brownian motions in \\((\\Omega,\\mathcal{F},\\mathbb{P})\\). The process \\((B_{t}:t\\geq0)\\) taking values in \\(\\mathbf{R}^{d}\\) defined by :\n\\[\\begin{aligned}\nB_{t} & =(B_{t}^{(1)},\\ldots,B_{t}^{(d)}),\\quad t\\geq0\n\\end{aligned}\\]\nis called a \\(d-\\)dimensional Brownian motion or a Brownian motion in \\(\\mathbf{R}^{d}\\).\n\nThe Brownian filtration \\((\\mathcal{F}_{t}:t\\geq0)\\) is now composed of the information of all Brownian motions. In other words, it is given by the sigma-fields:\n\\[\\begin{aligned}\n\\mathcal{F}_{t} & =\\sigma(B_{s}^{(i)},1\\leq i\\leq d,s\\leq t)\n\\end{aligned}\\]\nFor every outcome \\(\\omega\\), the path of trajectory of a \\(d-\\)dimensional Brownian motion is a curve in space parametrized by the time \\(t\\):\n\\[\\begin{aligned}\nt\\mapsto B_{t}(\\omega) & =(B_{t}^{(1)}(\\omega),B_{t}^{(2)}(\\omega),\\ldots,B_{t}^{(d)}(\\omega))\n\\end{aligned}\\]\nOf course, this curve is continuous, since each coordinate is. The below numerical project gives an example of one path of a two-dimensional brownian motion. This is a very rugged and intertwined curve! We might wonder, what it does as \\(t\\to\\infty\\). Does it wander around \\((0,0)\\) ad infinitum or does it eventually escape to infinity? We will answer this question in a later section. For doing so, we shall need a version of Ito’s formula for multi-dimensional Brownian motion. We finish this section by noticing that it is also easy to construct Brownian motions in higher dimensions for which the coordinates are correlated.\n\n\nConsider a two-dimensional Brownian motion \\((B_{t}^{(1)},B_{2}^{(2)})\\) starting at \\((0,0)\\).\nLet’s plot one path of this Brownian motion on the plane \\(\\mathbf{R}^{2}\\) on the plane in \\(\\mathbf{R}^{2}\\) on the time interval \\([0,5]\\) using a discretization of \\(0.001\\).\nWe define BrownianMotion2D class.\n\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nsns.set_style(\"whitegrid\")\n\nclass BrownianMotion2D:\n    \"\"\"\n    Generate sample paths for a 2d-brownian motion\n    \"\"\"\n    def __init__(\n        self,\n        endpoint : float = 1.0,\n        discretization : float = 0.01\n    ):\n        self.endpoint = endpoint\n        self.discretization = discretization\n\n    def generate_paths(self, num_paths : int):\n        steps = int(self.endpoint/self.discretization)\n        delta_z = np.sqrt(self.discretization) * np.random.randn(num_paths,2,steps)\n        \n        # paths has shape [num_paths,2,num_steps]\n        paths = np.cumsum(delta_z,axis=2)\n\n        # Brownian motion has position (0,0) at time t=0\n        # Append initial position \n        init_position = np.zeros((num_paths,2,1))\n        paths = np.append(init_position,paths,axis=2)\n\n        return paths\n\nWe can then configure and use BrownianMotion2D objects as we please.\n\n\nShow the code\nbm = BrownianMotion2D(endpoint=5.0,discretization=0.001)\npaths = bm.generate_paths(num_paths=1)\npath = paths[0]\n\n\nplt.xlabel(r'$x$')\nplt.ylabel(r'$y$')\nplt.title(r'2D-Brownian motion')\nplt.grid(True)\nplt.plot(path[0],path[1],linewidth=1,color='blue')\nplt.show()\n\n\n\n\n\n\n\n\n\nExample 1 (Brownian motion with correlated coordinates) Let \\((B_{t}:t\\geq0)\\) be a two dimensional brownian motion. Let \\(-1&lt;\\rho&lt;1\\). We construct the two dimensional process as follows: \\(W_{t}=(W_{t}^{(1)},W_{t}^{(2)})\\) where:\n\\[\\begin{aligned}\nW_{t}^{(1)} & =B_{t}^{(1)}\\\\\nW_{t}^{(2)} & =\\rho B_{t}^{(1)}+\\sqrt{1-\\rho^{2}}B_{t}^{(2)}\n\\end{aligned}\\]\n\\(W_{t}^{(1)}=B_{t}^{(1)}\\) is Gaussian with mean \\(0\\) and variance \\(t\\). Since, \\(B_{t}^{(1)}\\) and \\(B_{t}^{(2)}\\)are independent gaussian random variables and the sum of IID Gaussians is Gaussian, \\(W_{t}^{(2)}\\) is Gaussian with mean \\(0\\) and variance \\(t\\). The covariance between \\(W_{t}^{(1)}\\) and \\(W_{t}^{(2)}\\) is:\n\\[\\begin{aligned}\n\\mathbf{E}[W_{t}^{(1)}W_{t}^{(2)}] & =\\mathbf{E}[B_{t}^{(1)}(\\rho B_{t}^{(1)}+\\sqrt{1-\\rho^{2}}B_{t}^{(2)})]\\\\\n& =\\mathbf{E}[\\rho(B_{t}^{(1)})^{2}+\\sqrt{1-\\rho^{2}}B_{t}^{(1)}B_{t}^{(2)}]\\\\\n& =\\rho t\n\\end{aligned}\\]\nHence, the coordinates at time \\(t\\) are not independent.\n\nConsider now the process \\((W_{t}:t\\geq0)\\) for \\(\\rho=1/2\\) as in example 2. Let’s plot one path of this process on the plane \\(\\mathbf{R}^{2}\\) on the time-interval \\([0,5]\\) using a discretization of \\(0.001\\).\n\nclass BrownianMotion2DWithCorrelatedCoords(BrownianMotion2D):\n    \"\"\"\n    Generate sample paths for a 2d-brownian motion\n    have correlated coordiantes\n    \"\"\"\n\n    def __init__(\n        self, \n        endpoint: float = 1.0, \n        discretization: float = 0.01, \n        rho: float = 0.0\n    ):\n        self.endpoint = endpoint\n        self.discretization = discretization\n        self.rho = rho\n\n    def generate_paths(self, num_paths: int):\n\n        # Call the base class generate_paths() method to generate a pair of\n        # independent brownian motion paths. It returns a tensor of\n        # shape (num_paths, 2, num_steps)\n        paths = super().generate_paths(num_paths=num_paths)\n\n        # Extract the brownian motions B1(t) and B2(t)\n        # B1(t) and B2(t) have dimensions [num_paths,num_steps]\n        x_coord = paths[:, 0, :]\n        y_coord = paths[:, 1, :]\n\n        # Apply the transformation\n        # W1(t) = B1(t)\n        # W2(t) = rho * B1(t) + sqrt(1 - rho**2) B2(t)\n        x_coord = x_coord\n        y_coord = self.rho * x_coord + np.sqrt(1 - self.rho**2) * y_coord\n\n        # Assemble back the x- and y- coordinates\n        x_coord = np.expand_dims(x_coord, axis=1)\n        y_coord = np.expand_dims(y_coord, axis=1)\n\n        # Return a tensor of shape [num_paths,d=2,num_steps]\n        return np.concatenate([x_coord, y_coord], axis=1)\n\nLet’s configure the BrownianMotion2DWithCorrelatedCoords engine with the settings endpoint=5.0, discretization=0.001 and rho=0.5 and generate a sample path.\n\n\nShow the code\nbm = BrownianMotion2DWithCorrelatedCoords(\n    endpoint=5.0,\n    discretization=0.001,\n    rho=0.50\n)\npaths = bm.generate_paths(num_paths=1)\npath = paths[0]\n\nplt.xlabel(r'$x$')\nplt.ylabel(r'$y$')\nplt.title(r'Correlated Brownian motion $W(t)=(W^{(1)}(t),W^{(2)}(t))$')\nplt.grid(True)\nplt.plot(path[0],path[1],linewidth=1,color='blue')\nplt.show()\n\n\n\n\n\n\n\nShow the code\nplt.xlabel(r'$t$')\nplt.ylabel(r'$W_t$')\nplt.title(r'Correlated Brownian motion paths')\nplt.grid(True)\nt = np.linspace(0.0,stop=5.0,num=5001)\nplt.plot(t,path[0],linewidth=0.75)\nplt.plot(t,path[1],linewidth=0.75)\nplt.show()\n\n\n\n\n\n\n\n\n\n\nTheorem 1 (Ito’s Formula.) Let \\((B_{t}:t\\geq0)\\) be a \\(d-\\)dimensional brownian motion. Consider \\(f\\in\\mathcal{C}^{2}(\\mathbf{R}^{d})\\). Then, we have with probability one that for all \\(t\\geq0\\):\n\\[\\begin{aligned}\nf(B_{t})-f(B_{0}) & =\\sum_{i=1}^{d}\\int_{0}^{t}\\partial_{x_{i}}f(B_{s})dB_{s}^{(i)}+\\frac{1}{2}\\int_{0}^{t}\\sum_{i=1}^{d}\\partial_{x_{i}}^{2}f(B_{s})ds\\label{eq:multidimensional-ito-formula}\n\\end{aligned}\\]\n\n\nI stress that, as in the one-dimensional case, Ito’s formula is an equality of processes (and not an equality in distribution). Thus, the processes on both sides must agree for each path.\n\nInterestingly, the mixed partials \\(\\partial_{x_{i}x_{j}}f(B_{s})\\), \\(i\\neq j\\) do not appear in the formula! We see from Ito’s formula that the process \\(f(B_{t})\\) can be represented as a sum of \\(d+1\\) processes: \\(d\\) Ito integrals and one Riemann integral (which is a process of finite variation). In vector notation, the formula takes the form:\n\\[\\begin{aligned}\nf(B_{t})-f(B_{0}) & =\\int_{0}^{t}\\nabla f(B_{s})^{T}dB_{s}+\\frac{1}{2}\\int_{0}^{t}\\nabla^{2}f(B_{s})ds\n\\end{aligned}\\]\nwhere it is understood that the first term is the sum of the \\(d\\) Ito integrals in the equation. The symbol \\(\\nabla^{2}\\) is the Laplacian of \\(f\\):\n\\(\\sum_{i=1}^{d}\\frac{\\partial^{2}}{\\partial x_{i}^{2}}f(B_{s}^{(1)},\\ldots,B_{s}^{(d)})ds\\)\nIn differential form, Ito’s formula becomes very neat:\n\\[\\begin{aligned}\ndf(B_{t}) & =\\sum_{i=1}^{d}\\partial_{x_{i}}f(B_{s})dB_{t}^{(i)}+\\frac{1}{2}\\sum_{i=1}^{d}\\partial_{x_{i}}^{2}f(B_{s})dt=\\nabla f(B_{t})^{T}dB_{s}+\\frac{1}{2}\\nabla^{2}f(B_{t})dt\n\\end{aligned}\\]\n\nExample 2 Consider the functions (1) \\(f(x_{1},x_{2})=x_{1}^{2}+x_{2}^{2}\\) (2) \\(f(x_{1},x_{2})=e^{x_{1}}\\cos x_{2}\\) and the processes \\((X_{t}:t\\geq0)\\) and \\((Y_{t}:t\\geq0)\\). If we apply Ito’s formula to the first process, we have:\n\\[\\begin{aligned}\nX_{t} & =\\int_{0}^{t}2B_{s}^{(1)}dB_{s}^{(1)}+\\int_{0}^{t}2B_{s}^{(2)}dB_{s}^{(2)}+\\frac{1}{2}\\int_{0}^{t}(4dt)\\\\\n& =\\int_{0}^{t}2B_{s}^{(1)}dB_{s}^{(1)}+\\int_{0}^{t}2B_{s}^{(2)}dB_{s}^{(2)}+2t\n\\end{aligned}\\]\nThe second process gives:\n\\[\\begin{aligned}\nY_{t} & =\\cos B_{s}^{(2)}\\int_{0}^{t}e^{B_{s}^{(1)}}dB_{s}^{(1)}-e^{B_{s}^{(1)}}\\int\\sin B_{s}^{(2)}dB_{s}^{(2)}+\\frac{1}{2}\\int_{0}^{t}\\left(e^{B_{s}^{(1)}}\\cos B_{s}^{(2)}-e^{B_{s}^{(1)}}\\cos B_{s}^{(2)}\\right)dt\\\\\n& =1+\\cos B_{s}^{(2)}\\int_{0}^{t}e^{B_{s}^{(1)}}dB_{s}^{(1)}-e^{B_{s}^{(1)}}\\int\\sin B_{s}^{(2)}dB_{s}^{(2)}\n\\end{aligned}\\]\n\n\nExample 3 (Cross-Variation of \\(B_{t}^{(1)}\\) and \\(B_{t}^{(2)}\\)). Let \\((t_{j}:j\\leq n)\\) be a sequence of partitions of \\([0,t]\\) such that \\(\\max_{j}|t_{j+1}-t_{j}|\\to0\\) as \\(n\\to\\infty\\). Prove that:\n\\[\\begin{aligned}\n\\lim_{n\\to\\infty}\\sum_{j=0}^{n-1}(B_{t_{j+1}}^{(1)}-B_{t_{j}}^{(1)})(B_{t_{j+1}}^{(2)}-B_{t_{j}}^{(2)}) & =0\\quad\\text{in } L^{2}\n\\end{aligned}\\]\nThis justifies the rule \\(dB_{t}^{(1)}\\cdot dB_{t}^{(2)}=0\\).\nHint: Just compute the second moment of the sum.\n\n\nWe have:\n\\[\\begin{aligned}\n& \\mathbf{E}\\left[\\left(\\sum_{j=0}^{n-1}(B_{t_{j+1}}^{(1)}-B_{t_{j}}^{(1)})(B_{t_{j+1}}^{(2)}-B_{t_{j}}^{(2)})\\right)^{2}\\right]\\\\\n= & \\sum_{j=0}^{n-1}\\mathbf{E}[(B_{t_{j+1}}^{(1)}-B_{t_{j}}^{(1)})^{2}(B_{t_{j+1}}^{(2)}-B_{t_{j}}^{(2)})^{2}]\\\\\n+ & 2\\sum_{j&lt;k}\\mathbf{E}\\left[(B_{t_{j+1}}^{(1)}-B_{t_{j}}^{(1)})(B_{t_{k+1}}^{(1)}-B_{t_{k}}^{(1)})(B_{t_{j+1}}^{(2)}-B_{t_{j}}^{(2)})(B_{t_{k+1}}^{(2)}-B_{t_{k}}^{(2)})\\right]\n\\end{aligned}\\]\nBoth these expectations are zero, since the brownian motions are independent and non-overlapping increments are independent.\nConsequently, \\(\\sum_{j=0}^{n-1}(B_{t_{j+1}}^{(1)}-B_{t_{j}}^{(1)})(B_{t_{j+1}}^{(2)}-B_{t_{j}}^{(2)})\\to0\\) in the \\(L^{2}\\) sense.\n\n\nProof. The proof of the formula follows the usual recipe: Taylor’s theorem together with the quadratic variation and the cross-variation. In this case, we do get a cross-variation between the different Brownian motions. More precisely, consider a partition \\((t_{j}:j\\leq n)\\) of \\([0,t]\\). Then we can write:\n\\[\\begin{aligned}\nf(B_{t})-f(B_{0}) & =\\sum_{j=0}^{n-1}(f(B_{t_{j+1}})-f(B_{t_{j}}))\n\\end{aligned}\\]\nWe can apply the Taylor’s series expansion for each \\(j\\) to get:\n\\[\\begin{aligned}\nf(B_{t})-f(B_{0}) & =\\sum_{j=0}^{n-1}\\nabla f(B_{t_{j}})(B_{t_{j+1}}-B_{t_{j}})\\\\\n& +\\frac{1}{2}\\sum_{j=0}^{n-1}(B_{t_{j+1}}-B_{t_{j}})^{T}Hf(B_{t_{j}})(B_{t_{j+1}}-B_{t_{j}})+\\mathcal{E}\n\\end{aligned}\\]\nwhere \\(Hf\\) is the Hessian matrix of \\(f\\). We wrote the expansion using the vector notation to be economical. Let’s keep in mind that each term is a sum over the derivatives. The first term will converge to \\(d\\) Ito integrals as in the one-dimensional case. Now, the summand in the second term is:\n\\[(B_{t_{j+1}}^{(1)}-B_{t_{j}}^{(1)},\\ldots,B_{t_{j+1}}^{(d)}-B_{t_{j}}^{(d)})\\left[\\begin{array}{ccc}\n\\partial_{x_{1}}^{2}f(B_{t_{j}}) & \\ldots & \\partial_{x_{1}x_{d}}^{2}f(B_{t_{j}})\\\\\n\\vdots & \\ddots\\\\\n\\partial_{x_{d}x_{1}}^{2}f(B_{t_{j}}) &  & \\partial_{x_{d}}^{2}f(B_{t_{j}})\n\\end{array}\\right]\\left[\\begin{array}{c}\nB_{t_{j+1}}^{(1)}-B_{t_{j}}^{(1)}\\\\\n\\vdots\\\\\nB_{t_{j+1}}^{(d)}-B_{t_{j}}^{(d)}\n\\end{array}\\right]\\]\nSo, \\((B_{t_{j+1}}^{(i)}-B_{t_{j}}^{(i)})\\) is pre-multiplied with the term \\(\\partial_{x_{i}x_{k}}^{2}f(B_{t_{j}})\\) and it is post-multiplied \\((B_{t_{j+1}}^{(k)}-B_{t_{j}}^{(k)})\\). Consequently, the second term in the Taylor’s series expansion can be re-written as:\n\\[\\sum_{j=0}^{n-1}\\left(\\sum_{i=1}^{d}\\partial_{x_{i}}^{2}f(B_{t_{j}})(B_{t_{j+1}}^{(i)}-B_{t_{j}}^{(i)})^{2}+\\sum_{1\\leq i&lt;k\\leq d}\\partial_{x_{i}x_{k}}^{2}f(B_{t_{j}})(B_{t_{j+1}}^{(i)}-B_{t_{j}}^{(i)})(B_{t_{j+1}}^{(k)}-B_{t_{j}}^{(k)})\\right)\\]\nThe second term on the right converges to \\(0\\) in the \\(L^{2}\\) sense when \\(i\\neq k\\), from exercise. This explains why the mixed derivatives disappear in the multi-dimensional Ito’s formula. As for the case \\(i=k\\), it reduces to the quadratic variation as in the one-dimensional case. This is where the Riemann integral arises, after suitable conditioning on \\(\\mathcal{F}_{t_{j}}\\), the sigma-field generated by \\(B_{s}\\), \\(s\\leq t_{j}\\).\n\nAs in the one-dimensional case,it is not necessary to learn Ito’s formula by heart. It suffices to write the differential of the function \\(f\\) to second order. We can then apply the rules of multivariate Ito calculus:\n\n\n\n\\(\\cdot\\)\n\\(dt\\)\n\\(dB_{t}^{(1)}\\)\n\\(dB_{t}^{(2)}\\)\n\\(\\ldots\\)\n\n\n\n\n\\(dt\\)\n\\(0\\)\n\\(0\\)\n\\(0\\)\n\\(0\\)\n\n\n\\(dB_{t}^{(1)}\\)\n\\(0\\)\n\\(dt\\)\n\\(0\\)\n\\(0\\)\n\n\n\\(dB_{t}^{(2)}\\)\n\\(0\\)\n\\(0\\)\n\\(dt\\)\n\\(0\\)\n\n\n\\(\\ldots\\)\n\\(0\\)\n\\(0\\)\n\\(0\\)\n\\(dt\\)\n\n\n\nNote that the rule \\(dB_{t}^{(i)}dB_{t}^{(j)}=0\\) for \\(i\\neq j\\) is being motivated by the cross-variation result.\nHow can we construct martingales using the Ito’s formula? Recall that an Ito integral \\((\\int_{0}^{t}X_{s}dB_{s},t\\leq T)\\) is a martingale whenever the integrand is in \\(\\mathcal{L}_{c}^{2}(T)\\), the space of adapted processes with continuous paths and for which:\n\\[\\begin{aligned}\n\\int_{0}^{T}\\mathbf{E}[X_{s}^{2}]ds & &lt;\\infty\n\\end{aligned}\\]\nThe only difference here is that the integrand is a function of many Brownian motions. However, the integrands involved in the Ito integrals of the multidimensional Ito’s formula are clearly adapted to the filtration \\((\\mathcal{F}_{t}:t\\geq0)\\) of \\((B_{t}:t\\geq0)\\) as they are functions of the Brownian motion at the time. The arguments of Ito integral in and apply verbatim, if we take the definition of \\(\\mathcal{L}_{c}^{2}(t)\\) with the filtration \\((\\mathcal{F}_{t}:t\\geq0)\\) of \\((B_{t}:t\\geq0)\\). With this in mind, we have the following corollary.\n\n\n\nCorollary 1 (Brownian Martingales.) Let \\((B_{t}:t\\geq0)\\) be a Brownian motion in \\(\\mathbf{R}^{d}\\). Consider \\(f\\in\\mathcal{C}^{2}(\\mathbf{R}^{d})\\) such that processes \\((\\partial_{x {i}}f(B_{t}),t\\leq T)\\in\\mathcal{L}_{c}^{2}(T)\\) for every \\(i\\leq d\\). Then, the process :\n\\[f(B_{t})-\\frac{1}{2}\\int_{0}^{t}\\nabla^{2}f(B_{s})ds,\\quad t\\leq T\\]\nwhere \\(\\nabla^{2}=\\sum_{i=1}^{d}\\partial_{x_{i}}^{2}\\) is the Laplacian, is a martingale for the Brownian filtration.\n\nFor example, consider the processes \\(X_{t}=(B_{t}^{(1)})^{2}+(B_{t}^{(2)})^{2}\\) and \\(Y_{t}=\\exp(B_{t}^{(1)})\\cos(B_{t}^{(2)})\\). Then, we have :\n\\[\\frac{1}{2}\\int_{0}^{t}\\nabla^{2}X_{s}ds=\\frac{1}{2}\\int_{0}^{t}4ds=2t\\]\nand\n\\[\\begin{aligned}\n\\frac{1}{2}\\int_{0}^{t}\\nabla^{2}Y_{s}ds & =\\frac{1}{2}\\int_{0}^{t}0\\cdot ds=0\n\\end{aligned}\\]\nThus, the processes \\(X_{t}-2t\\) and \\(Y_{t}\\) are martingales for the Brownian filtration. In one dimension, there are no interesting martingales constructed with functions of space only. Indeed, \\((f(B_{t}):t\\geq0)\\) is a martingale if and only if \\(f''(x)=0\\) for all \\(x\\). But, such functions are of the form \\(f(x)=ax+b\\), \\(a,b\\in\\mathbf{R}\\). In other words, in one dimension, Brownian martingales of the form \\(f(B_{t})\\) are simply \\(aB_{t}+b\\). Not very surprising! The situation is very different in higher dimensions. Indeed, corollary implies that \\(f(B_{t})\\) is a martingale whenever \\(f\\) is a harmonic function:\n\nDefinition 2 (Harmonic function.) A function \\(f:\\mathbf{R}^{d}\\to\\mathbf{R}\\) is harmonic in \\(\\mathbf{R}^{d}\\) if and only if \\(\\nabla^{2}f(x)\\equiv0\\) for all \\(x\\in\\mathbf{R}^{d}\\). More generally, a function \\(f:\\mathbf{R}^{d}\\to\\mathbf{R}\\) is harmonic in the region \\(\\mathcal{O}\\subset\\mathbf{R}^{d}\\) if and only if \\(\\nabla^{2}f(x)\\equiv0\\) for all \\(x\\in\\mathcal{O}\\).\n\nNote that the function \\(f(x)=e^{x_{1}}\\cos x_{2}\\) is harmonic in \\(\\mathbf{R}^{d}\\). This is why the process \\(Y_{t}=\\exp(B_{t}^{(1)})\\cos(B_{t}^{(2)})\\) is a martingale. The distinction to a subset of \\(\\mathbf{R}^{d}\\) in the above definition is important since it may happen that the function is harmonic only in a subset of the space; see for example equation. It is possible to define a Brownian martingale in such cases by considering the process until it exits the region. This will turn out to be important as we move ahead.\nThe multidimensional Ito’s formula generalizes to functions of time and space as in proposition:\n\nDefinition 3 A function \\(f:[0,\\infty)\\times\\mathbf{R}^{d}\\to\\mathbf{R}\\) is in \\(\\mathcal{C}^{1,2}([0,T]\\times\\mathbf{R}^{d})\\) if the partial derivative in time :\n\\[\\frac{\\partial}{\\partial t}f(t,\\mathbf{x})\\]\nexists and is continuous and the second order partial derivatives in space:\n\\[\\frac{\\partial^{2}}{\\partial x_{i}^{2}}f(t,x_{1},x_{2},\\ldots,x_{i},\\ldots,x_{d}),\\quad1\\leq i\\leq d\\]\nexist and are continuous.\n\n\n\n\n\n\nTheorem 2 (Multidimensional Ito’s formula for functions of space and time) Let \\((B_{t}:t\\leq T)\\) be a \\(d\\)-dimensional Brownian motion. Consider a function \\(f\\in\\mathcal{C}^{1,2}([0,T]\\times\\mathbf{R}^{d})\\). Then, we have with probability one for all \\(t\\leq T\\):\n\\[\\begin{aligned}\nf(t,B_{t})-f(0,B_{0}) & =\\sum_{i=1}^{d}\\int_{0}^{t}\\partial_{x_{i}}f(s,B_{s})dB_{s}^{(i)}+\\int_{0}^{t}\\left(\\partial_{t}f(s,B_{s})+\\sum_{i=1}^{d}\\partial_{x_{i}}^{2}f(s,B_{s})\\right)ds\n\\end{aligned}\\]\n\nThe martingale condition is then similar to the ones in corollary ([cor:brownian-martingales-in-Rd]): if the processes \\((\\partial_{x_{i}}f(s,B_{s}),t\\leq T)\\in\\mathcal{L}_{c}^{2}(T)\\) for every \\(1\\leq i\\leq d\\), then the process\n\\[f(t,B_{t})-\\int_{0}^{t}\\left\\{ \\partial_{t}f(s,B_{s})++\\sum_{i=1}^{d}\\partial_{x_{i}}^{2}f(s,B_{s})\\right\\} ds,\\quad t\\leq T \\tag{1}\\]\nis a martingale for the Brownian filtration. In particular, if \\(f\\) satisfies the partial differential equation:\n\\[\n\\begin{aligned}\n\\frac{\\partial f}{\\partial t}+\\frac{1}{2}\\nabla^{2}f & =0\n\\end{aligned}\n\\tag{2}\\]\nthen the process \\((f(t,B_{t}):t\\leq T)\\) itself is a martingale.\n\n\n\nConsider a simple random walk on the integer lattice \\(\\mathbb{Z}^d\\). At each time step, a random walker makes a random move of length one in one of the lattice directions.\nWe say that, if the random walk returns to the origin with probability one infinitely many times, it is recurrent, if it does not we will call it transient.\nIt’s worth to spend a moment visiting Polya’s Random Walk Theorem, a fascinating, but not so intuitive result.\nAssuming all random walks start at the origin, we define \\(u\\) to be the probability that a random walker returns to the origin. The probability that the random walker returns to the origin exactly \\(m\\) times is:\n\\[\\begin{align*}\n{m \\choose m-1} u^{m-1} (1 - u)^{m - (m - 1)} = u^{m-1}(1-u)\n\\end{align*}\\]\nThe expected number of times the particle returns to the origin for an infinite random walk is:\n\\[\\begin{align*}\nE &= \\sum_{m = 1}^{\\infty} m (u^{m-1}(1-u))\\\\\n&= (1-u)\\sum_{m=1}^{\\infty}mu^{m-1}\\\\\n&= (1-u)\\sum_{m=1}^{\\infty}\\frac{d}{du}u^{m}\\\\\n\\end{align*}\\]\nWe note that limit exchanging is acceptable since the power series \\(\\sum_{n=1}^{\\infty}x^n\\) converges uniformly for \\(u &lt; 1\\) and we can apply the differentiable limit theorem.\nSo we obtain:\n\\[\\begin{align*}\nE &= (1-u)\\frac{d}{du}\\sum_{m = 1}^{\\infty} u^m \\\\\n&= (1-u)\\cdot \\frac{1}{(1-u)^2}\\\\\n&= \\frac{1}{1-u}\n\\end{align*}\\]\nSo, we see that if \\(E\\) is finite, \\(u &lt; 1\\), then the walk is transient and if \\(E = +\\infty\\), \\(u=1\\), then the walk is recurrent.\nWe then define \\(u_n\\) to be the probability that a given walk is at the origin on the \\(n\\)th step, defining the value \\(u_0=1\\) for the trivial loop. We also introduce an indicator random variable \\(x_n\\), which takes the value \\(1\\), if the particle is at the origin on the \\(n\\)th step and zero otherwise.\nThen\n\\[\\begin{align*}\nT = \\sum_{n=1}^{\\infty}x_n\n\\end{align*}\\]\nis the total number of times, the particle is at the origin, so \\(E\\) is equal to the expectation of \\(T\\), \\(\\mathbb{E}(T)\\), which is equal to:\n\\[\\begin{align*}\n\\mathbb{E}[T] &= \\sum_{n=1}^{\\infty}\\mathbb{E}[x_n]\\\\\n&= \\sum_{n=1}^{\\infty} u_n\n\\end{align*}\\]\nBut, we showed previously that if \\(E\\) is finite, then the walk is transient and if \\(E = \\infty\\), then the walk is recurrent, so we have established that if:\n\\[\\begin{align*}\n\\sum_{n=1}^{\\infty}u_n\n\\end{align*}\\]\nconverges then the walk is transient and if the sum diverges, then the walk is recurrent.\n\n\nNow that we have built up the necessary tools, we will consider the cases. We start by considering a simple random walk on \\(\\mathbb{Z}^1\\). Since, as mentioned previously, a walk must have an even number of steps to be a loop, we only look at \\(u_{2n},n \\in \\mathbb{Z}^+\\). A path of length \\(2n\\) returning to the origin must have \\(n\\) up-moves and \\(n\\) down-moves. The number of such paths are \\({2n \\choose n}\\). Each such path has a probability of occurrence \\(\\frac{1}{2^{2n}}\\). Thus,\n\\[\\begin{align*}\nu_{2n} = \\frac{1}{2^{2n}}{2n \\choose n}\n\\end{align*}\\]\nUsing Stirling’s approximation \\(n! \\sim \\sqrt{2\\pi n} e^{-n} n^{n}\\), we obtain:\n\\[\\begin{align*}\nu_{2n} &= \\frac{1}{2^{2n}} \\frac{(2n)!}{n! n!}\\\\\n&\\approx \\frac{1}{2^{2n}} \\cdot \\frac{\\sqrt{2\\pi(2n)} e^{-2n}(2n)^{2n}}{\\left(\\sqrt{2\\pi n} e^{-n} n^n\\right)^2}\\\\\n&=\\frac{1}{\\sqrt{\\pi n}}\n\\end{align*}\\]\nSo, we see that:\n\\[\\begin{align*}\n\\sum_{n=0}^{\\infty} u_{2n} \\approx \\sum_{n=0}^{\\infty} \\frac{1}{\\sqrt{n\\pi}}\n\\end{align*}\\]\nAnd the series on the right certainly diverges so, we see that a simple random walk in \\(\\mathbb{Z}^1\\) is recurrent since \\(E\\) diverges.\n\n\n\nA particle has an equal probability \\(1/4\\) of moving left, right, up or down randomly in the \\(d=2\\) dimensional lattice. Each path of \\(2n\\) steps has a probability \\(\\frac{1}{4^{2n}}\\) of occurring. We then consider the number of paths with equal steps left and right (say \\(L\\) steps in each horizontal direction) and equal steps up and down (then \\(n-L\\)) is:\n\\[\\begin{align*}\n{2n \\choose L}{2n - L \\choose L}{2n - 2L \\choose n - L}{n-L \\choose n - L} = \\frac{(2n)!}{L! L! (n-L)! (n-L)!}\n\\end{align*}\\]\nSo we get:\n\\[\\begin{align*}\nu_{2n} &= \\frac{1}{4^{2n}} \\sum_{L=0}^n \\frac{(2n)!}{L! L! (n-L)! (n-L)!} \\\\\n&= \\frac{1}{4^{2n}} \\sum_{L=0}^n \\frac{(2n)!}{n! n!} \\cdot \\left(\\frac{n!}{L! (n-L)!}\\right)^2 \\\\\n&=\\frac{1}{4^{2n}} {2n \\choose n}\\sum_{L=0}^n {n \\choose L}^2\n\\end{align*}\\]\nSuppose, we are to form a team of \\(n\\) players from a population of \\(2n\\) participants. There \\({2n \\choose n}\\) distinguishable teams of size \\(n\\). Alternatively, we could divide the population into two halves of \\(n\\) participants each, choose \\(L\\) participants from the first sub-population, and the remaining \\(n-L\\) participants from the second sub-population. So, the number of distinguishable teams is:\n\\[\\begin{align*}\n\\sum_{L=0}^{n}{n \\choose L}{n \\choose n - L} = \\sum_{L=0}^{n} {n \\choose L}^2\n\\end{align*}\\]\nSo, we have the combinatorial identity:\n\\[\\begin{align*}\n\\sum_{L=0}^{n} {n \\choose L}^2 = {2n \\choose n}\n\\end{align*}\\]\nThus,\n\\[\\begin{align*}\nu_{2n} &=\\frac{1}{4^{2n}} {2n \\choose n}\\sum_{L=0}^n {n \\choose L}^2\\\\\n&= \\left(\\frac{1}{2^{2n}} {2n \\choose n}\\right)^2\n\\end{align*}\\]\nSo, we have that, it is just the square of the result from \\(\\mathbb{Z}^1\\), so we see in this case that:\n\\[\\begin{align*}\nu_{2n} &\\approx \\sum_{n=0}^{\\infty} \\frac{1}{\\pi n}\n\\end{align*}\\]\nAnd the series on the right certainly diverges, so we see that a simple random walk in \\(\\mathbb{Z}^2\\) is recurrent as \\(E\\) diverges.\n\n\n\nAs before, in order to have a walk return to the origin we must have equal steps in the positive and negative directions for each direction and each path of \\(2n\\) has a probability of occurring of \\(\\frac{1}{6^{2n}}\\). Then, extending the idea from the previous subsection, the number of paths (of total length \\(2n\\)) with \\(L\\) steps left and right, \\(U\\) steps up and down and \\(n - L - U\\) steps forward and backward is:\n\\[\\begin{align*}\n\\frac{(2n)!}{L! L! U! U! (n - L - U)! (n - L - U)!}\n\\end{align*}\\]\nSo, we get:\n\\[\n\\begin{align*}\nu_{2n} &= \\frac{1}{6^{2n}} \\sum_{L,U,L+U \\leq n} \\frac{(2n)!}{L! L! U! U! (n - L - U)! (n - L - U)!} \\\\\n&= \\frac{1}{2^{2n}} {2n \\choose n} \\sum_{L,U,L+U \\leq n} \\left(\\frac{1}{3^n}\\frac{n!}{L! U! (n - U - L)!}\\right)^2\n\\end{align*}\n\\tag{3}\\]\nConsider a \\(3\\)-sided fair coin, with \\(\\mathbb{P}\\{\\text{Heads}\\} = \\mathbb{P}\\{\\text{Tails}\\} = \\mathbb{P}\\{\\text{Edge}\\} = \\frac{1}{3}\\). Suppose that the coin is tossed \\(n=3^2 = 9\\) times. The probability of landing \\(L\\) heads, \\(U\\) tails and \\(n - L - U\\) edges is \\(\\frac{n!}{L!U!(n-L-U)!} \\frac{1}{3^n}\\). This is precisely the term seen in the above expression. The number of heads, tails and edges in \\(n\\) coin tosses follows a multinomial distribution. It can be easily demonstrated, that in, \\(n/3 = 3\\) heads, \\(n/3\\) tails and \\(n/3\\) edges are most likely to occur in \\(n\\) coin tosses. So, we can find an upper bound on the summand in Equation 3 as:\n\\[\\begin{align*}\n\\frac{n!}{3^n L! U! (n- L - U)!} \\leq \\frac{n!}{3^n \\lfloor\\frac{n}{3}\\rfloor! \\lfloor\\frac{n}{3}\\rfloor! \\lfloor\\frac{n}{3}\\rfloor!}\n\\end{align*}\\]\nAlso, from the multinomial expansion theorem:\n\\[\\begin{align*}\n(1 + a + b)^n = \\sum_{L,U,L+U\\leq n} \\frac{n!}{L! U! (n-L-U)!} a^L b^U\n\\end{align*}\\]\nSetting \\(a = b = 1\\), we get:\n\\[\\begin{align*}\n\\sum_{L,U,L+U\\leq n} \\frac{n!}{3^n L! U! (n-L-U)!} a^L b^U = 1\n\\end{align*}\\]\nWe then see that:\n\\[\\begin{align*}\nu_{2n} \\leq \\frac{1}{2^{2n}} {2n \\choose n} \\frac{n!}{3^n \\lfloor\\frac{n}{3}\\rfloor! \\lfloor\\frac{n}{3}\\rfloor! \\lfloor\\frac{n}{3}\\rfloor!}\n\\end{align*}\\]\nWe can simplify this as:\n\\[\\begin{align*}\nu_{2n} &= \\frac{1}{2^{2n}}{2n \\choose n} \\frac{n!}{3^n \\left(\\lfloor\\frac{n}{3}\\rfloor!\\right)^3} \\\\\n&\\approx \\frac{1}{\\sqrt{\\pi n}} \\times \\frac{\\sqrt{2\\pi n} e^{-n} n^n}{3^n \\left\\{\\sqrt{2\\pi \\frac{n}{3}}e^{-n/3} \\left(\\frac{n}{3}\\right)^{n/3}\\right\\}^3}\\\\\n&= \\frac{1}{\\sqrt{\\pi n}} \\frac{\\sqrt{2\\pi n} e^{-n} n^n}{3^n \\frac{(2\\pi n)^{3/2}}{3^{3/2}} e^{-n} \\frac{n^n}{3^n}}\\\\\n&= \\frac{1}{\\sqrt{\\pi n}} \\frac{\\sqrt{2\\pi n} \\cancel{e^{-n}} \\cancel{n^n}}{\\cancel{3^n} \\frac{(2\\pi n)^{3/2}}{3^{3/2}} \\cancel{e^{-n}} \\frac{ \\cancel{n^n}}{\\cancel{3^n}}}\\\\\n&\\approx \\frac{M}{(\\pi n)^{3/2}}\n\\end{align*}\\]\nwhere \\(M\\) is a positive constant. We then see:\n\\[\\begin{align*}\n\\sum_n u_{2n} &= M \\sum_n \\frac{1}{n^{\\frac{3}{2}}}\n\\end{align*}\\]\nThe sum on the right hand side converges, so we have that a simple random walk in three dimensions is transient. The proof of Polya’s Random Walk Theorem is complete.\n\n\n\n\nIn one dimension, we established that every path of a Brownian motion reaches any level \\(a \\in \\mathbf{R}\\). More precisely, for \\(a &gt; 0\\), if we define the stopping time :\n\\[\\begin{align*}\n\\tau = \\min \\{ t \\geq 0 : B_t \\geq a\\}\n\\end{align*}\\]\nwe have \\(\\mathbb{P}\\{\\tau_a &lt; \\infty \\} = 1\\). This implies in particular that every path will come back to \\(0\\) and will do infinitely many times. This is because \\(B(t+\\tau) - B(t)\\) is a standard brownian motion. This property of Brownian motion is called recurrence. This is to be compared with Brownian motion with a drift. In our analysis, we found that, if the drift is negative, then there are paths that will not reach a given level \\(a &gt; 0\\) with positive probability. Such paths go to infinity without ever going back to \\(0\\). This property of the process is called transience.\nWe can derive similar properties for the multidimensional Brownian motion. We will rely heavily on Corollary 1 and on some knowledge of harmonic functions. Harmonic functions play a very important role in mathematics, physics and in nature in general. As we mentioned earlier, if \\(d = 1\\), the only harmonic functions are the linear functions, since the equation \\(f''(x) = 0\\) has the solutions \\(f(x)=ax+b\\). However, in higher dimensions, the collection of harmonic functions is very rich. This gives access to a plethora of Brownian martingales. For example, the following functions are harmonic in the whole space minus the origin, \\(\\mathbf{R}^d \\setminus \\{0\\}\\).\n\\[\nh(x) = \\begin{cases}\n\\log ||x||, & d = 2 \\\\\n||x||^{2 - d}, & d \\geq 3\n\\end{cases}\n\\tag{4}\\]\nwhere \\(x\\in\\mathbf{R}^d\\).\n\nProof. Consider\n\\[\\begin{align*}\nf(x_1,x_2) = \\log \\sqrt {x_1^2 + x_2^2}\n\\end{align*}\\]\nWe have:\n\\[\\begin{align*}\n\\frac{\\partial f}{\\partial x_1} &= \\frac{1}{\\sqrt{x_1^2 + x_2^2}} \\cdot \\frac{\\partial }{\\partial x_1} (\\sqrt{x_1^2 + x_2^2})\\\\\n&=\\frac{1}{\\sqrt{x_1^2 + x_2^2}} \\cdot \\frac{x_1}{\\sqrt{x_1^2 + x_2^2}}\\\\\n&= \\frac{x_1}{x_1^2 + x_2^2}\n\\end{align*}\\]\nFurther,\n\\[\\begin{align*}\n\\frac{\\partial^2 f}{\\partial x_1^2} &= \\frac{(x_1^2 + x_2^2)(1) - x_1(2x_1)}{(x_1^2 + x_2^2)^2} \\\\\n&= \\frac{x_1^2 - x_2^2}{(x_1^2 + x_2^2)}\n\\end{align*}\\]\nBy symmetry,\n\\[\\begin{align*}\n\\frac{\\partial^2 f}{\\partial x_2^2}\n&= \\frac{x_2^2 - x_1^2}{(x_1^2 + x_2^2)}\n\\end{align*}\\]\nSo,\n\\[\\begin{align*}\n\\frac{\\partial^2 f}{\\partial x_1^2} &= - \\frac{\\partial^2 f}{\\partial x_2^2}\\\\\n\\frac{\\partial^2 f}{\\partial x_1^2} + \\frac{\\partial^2 f}{\\partial x_2^2}&=0\n\\end{align*}\\]\nWe conclude that \\(f\\) is harmonic.\nNext, consider\n\\[\\begin{align*}\ng(x_1,x_2,\\ldots,x_d) = \\frac{1}{\\left(\\sqrt{x_1^2 + x_2^2 + \\ldots + x_d^2}\\right)^{d-2}}\n\\end{align*}\\]\nNow,\n\\[\\begin{align*}\n\\frac{\\partial g}{\\partial x_i} &= \\frac{(2-d)}{\\left(\\sqrt{x_1^2 + x_2^2 + \\ldots + x_d^2}\\right)^{d-1}} \\cdot \\frac{\\partial }{\\partial x_i}\\left(\\sqrt{x_1^2 + x_2^2 + \\ldots + x_d^2}\\right)\\\\\n&= \\frac{(2-d)}{\\left(\\sqrt{x_1^2 + x_2^2 + \\ldots + x_d^2}\\right)^{d-1}}\\cdot \\frac{2x_i}{2\\left(\\sqrt{x_1^2 + x_2^2 + \\ldots + x_d^2}\\right)}\\\\\n&= \\frac{(2-d)x_i}{\\left(\\sqrt{x_1^2 + x_2^2 + \\ldots + x_d^2}\\right)^d}\n\\end{align*}\\]\nFurther, we have:\n\\[\\begin{align*}\n\\frac{\\partial^2 g}{\\partial x_i^2} &= (2-d)\\frac{\\left(\\sqrt{x_1^2 + x_2^2 + \\ldots + x_d^2}\\right)^d (1) - (x_i)\\cdot d \\cdot\\left(\\sqrt{x_1^2 + x_2^2 + \\ldots + x_d^2}\\right)^{d-1}\\cdot \\frac{x_i}{\\left(\\sqrt{x_1^2 + x_2^2 + \\ldots + x_d^2}\\right)}}{\\left(\\sqrt{x_1^2 + x_2^2 + \\ldots + x_d^2}\\right)^{2d}}\\\\\n&=(2-d)\\left(\\sqrt{x_1^2 + x_2^2 + \\ldots + x_d^2}\\right)^{d-2} \\frac{\\left(\\sqrt{x_1^2 + x_2^2 + \\ldots + x_d^2}\\right)^2  - d x_i^2}{\\left(\\sqrt{x_1^2 + x_2^2 + \\ldots + x_d^2}\\right)^{2d}}\\\\\n&=(2-d) \\frac{\\left(\\sum_{i=1}^d x_i^2\\right) - dx_i^2 }{||x||^{d+2}}\n\\end{align*}\\]\nWe conclude that:\n\\[\\begin{align*}\n\\sum_{i=1}^{d} \\frac{\\partial^2 g}{\\partial x_i^2} = 0\n\\end{align*}\\]\nand hence \\(g\\) is harmonic.\n\nInterestingly enough, the answer to the recurrence versus transience puzzle depends on the dimension. We will show that Brownian motion is recurrent in dimension \\(d=2\\) in the sense that every Brownian motion path starting from \\(x\\) will eventually enter a disc around the origin, no matter how small the disc is. The Brownian path will then enter this disc infinitely many times, as \\(t \\to \\infty\\). Note that, we did not say that the path actually hits \\(0\\), but that it enters a disc around the \\(0\\). This nuance is important, as we will in fact show that a Brownian path actually never hits a given point. In dimension \\(d=3\\) or higher, it is proved that there are some paths starting from a given \\(x\\) that will never enter a given ball around the origin with positive probability. This is the transience property.\nThe strategy of the proof is similar to the approach for Brownian motion with a drift. We will find a good function \\(h : \\mathbf{R}^d \\to \\mathbf{R}\\) for which \\(h(B_t)\\) is a martingale. In light of Corollary 1, this function needs to be harmonic in a suitable region. The desired probability is then obtained by considering the right boundary values.\n\nTheorem 3 (Recurrence and transience of a brownian motion in \\(\\mathbf{R}^d\\)) Let \\((B_t,t\\geq 0)\\) be a Brownian motion in \\(\\mathbf{R}^d\\) starting at \\(B_0 = x\\). Consider for \\(r &lt; ||x||\\), the stopping time\n\\[\\begin{align*}\n\\tau_r = \\min \\{t \\geq 0 : ||B_t|| &lt; r\\}\n\\end{align*}\\]\nthe first hitting time of the paths in a ball of radius \\(r\\) around the origin. We have:\n\\[\\begin{align*}\n\\mathbb{P}(\\tau_r &lt; \\infty) =\n\\begin{cases}\n1 & \\text{ if }d \\leq 2 \\\\\n\\left(\\frac{r}{||x||}\\right)^{d-2} & \\text{ if }d \\geq 3\n\\end{cases}\n\\end{align*}\\]\nIn particular, for \\(d \\leq 2\\), the paths are recurrent; that is, they come back infinitely many times in a neighbourhood of the origin. For \\(d \\geq 3\\), each path will eventually never come back to a neighbourhood of the origin.\n\nNote that we made sure that the starting point of the Brownian motion \\(x\\) is outside the ball of radius \\(r\\).\n\nProof. Consider another hitting time of a ball with a radius larger than \\(||x||\\):\n\\[\\begin{align*}\n\\tau_R' = \\min \\{t \\geq 0 : ||B_t|| \\geq R\\}, \\quad r &lt; ||x|| &lt; R\n\\end{align*}\\]\nNote that \\(\\tau_R'\\) must increase with \\(R\\) and that it must go to \\(+\\infty\\) as \\(R \\to \\infty\\). Moreover, the sequence of events \\(\\{\\tau_r &lt; \\tau_R'\\}_{R &gt; ||x||}\\) is increasing. In particular, by continuity of probability measure, we have:\n\\[\\begin{align*}\n\\lim_{R \\to \\infty} \\mathbb{P}(\\tau_r &lt; \\tau_R') &= \\mathbb{P}(\\lim_{R \\to \\infty} \\tau_r &lt; \\tau_R')\\\\\n&= \\mathbb{P}(\\tau_r &lt; \\infty)\n\\end{align*}\\]\nIf we set \\(\\tau = \\tau_r \\land \\tau_R'\\), then the event \\(\\{\\tau_r &lt; \\tau_R'\\}\\) is the same as the event \\(\\{||B_\\tau||=r\\}\\). So, \\(\\lim_{R \\to \\infty} \\mathbb{P}(\\tau_r &lt; \\tau_R') = \\lim_{R \\to \\infty} \\mathbb{P}(||B_\\tau||=r)\\).\nNow, consider the event \\(\\{\\tau &lt; \\infty\\}\\). Let \\(E_n\\) be the event that the \\(n\\)th increment \\(||B_n - B_{n-1}||\\) exceeds \\(R\\). If \\(E_n\\) occurs, then we must have the Brownian motion exits the spherical shell of thickness \\(R-r\\). Moreover, we have \\(\\mathbb{P}(E_1) = \\ldots = \\mathbb{P}(E_n)\\), for all \\(n\\). Call this probability \\(p\\). Clearly, \\(0 &lt; p &lt; 1\\). Since the events \\(E_n\\) are independent, we have:\n\\[\\begin{align*}\n\\mathbb{P}(E_1^C \\cap \\ldots \\cap E_n^C) = (1 - p)^n\n\\end{align*}\\]\nAs \\(n \\to \\infty\\), we have \\(\\lim_{n \\to \\infty} \\mathbb{P}(\\bigcap_{k=1}^{n}E_k^C) = 0\\). Now, let \\(F_k\\) be the event that there are no excursions upto \\(k\\). That is, \\(F_k = \\bigcap_{i=1}^{k}E_i^C\\). Now, the event \\(F_{k+1}\\) implies \\(F_k\\), or equivalently, \\(F_{k+1} \\subseteq F_k\\). So, \\(\\{F_k\\}_{k=1}^{\\infty}\\) is a decreasing sequence of events. Moreover, \\(\\bigcap_{k=1}^n F_k = \\bigcap_{k=1}^n E_k^C\\). So, by continuity of probability measure,\n\\[\\begin{align*}\n\\lim_{n \\to \\infty} \\mathbb{P}(\\bigcap_{k=1}^{n}E_k^C)\n&= \\lim_{n \\to \\infty} \\mathbb{P}(\\bigcap_{k=1}^{n}F_k) \\\\\n&= \\mathbb{P}(\\lim_{n \\to \\infty} \\bigcap_{k=1}^{n}F_k) \\\\\n&= \\mathbb{P}(\\bigcap_{k=1}^{\\infty}F_k) \\\\\n&= \\mathbb{P}(\\bigcap_{k=1}^{\\infty}E_k^C)\n\\end{align*}\\]\nSo, \\(\\mathbb{P}(\\bigcup_{k=1}^{\\infty}E_k) = 1\\). There exists an \\(n_0 \\in \\mathbf{N}\\), such that the event \\(E_{n_0}\\), an excursion at \\(n_0\\) occurs with probability \\(1\\). So, the event \\(\\{\\tau &lt; \\infty\\}\\) occurs almost surely.\nTo compute \\(\\mathbb{P}(||B_\\tau||=r)\\), the idea is to find a good function \\(h\\) with the following properties:\n\nMartingale: \\((h(B_t),t\\leq \\tau)\\) is a bounded martingale, so that the optional stopping theorem implies:\n\n\\[\\begin{align*}\n\\mathbb{E}[h(B_\\tau)] = h(B_0) = h(x)\n\\end{align*}\\]\n\nBoundary values: Since \\(B_\\tau\\) is a point at \\(||x||=r\\) or at \\(||x||=R\\), we pick boundary conditions for \\(h\\), so that \\(\\mathbb{E}[h(B_{\\tau})]=\\mathbb{P}(||B_\\tau||=r)\\).\n\nThe second point is easy; it suffices to take the boundary conditions \\(h(x)=0\\) at \\(||x||=R\\) and \\(h(x)=1\\) at \\(||x||=r\\). For the first point, by Ito’s formula, we pick \\(h\\) to be harmonic in the annulus \\(\\{x \\in \\mathbf{R}^d : r &lt; ||x||&lt;R \\}\\). Thus, we can use the function in Equation 4. Of course, the functions \\(ah(x) + b\\) remain harmonic. To satisfy the boundary conditions, we pick \\(a\\) and \\(b\\) suitably:\n\n\nLet \\(h(x) = ax + b\\). Then, at \\(x=r\\), we have:\n\\[\n\\begin{align*}\nar + b = 1\n\\end{align*}\n\\tag{5}\\]\nand at \\(x = R\\), we have:\n\\[\n\\begin{align*}\naR + b = 0\n\\end{align*}\n\\tag{6}\\]\nSo, \\(b = -aR\\). Substituting in Equation 5, we get:\n\\[\\begin{align*}\na &= \\frac{1}{r - R}\nb &= -\\frac{R}{r - R}\n\\end{align*}\\]\nConsequently,\n\\[\n\\begin{align*}\nh(x) &= \\frac{R - x}{R - r}\n\\end{align*}\n\\tag{7}\\]\n\n\n\nLet \\(h(x) = \\log ||x||\\). Then, at \\(||x||=r\\), we have:\n\\[\n\\begin{align*}\na \\log ||x|| + b &= 1\na \\log r + b &= 1\n\\end{align*}\n\\tag{8}\\]\nAt \\(||x||=R\\), we have:\n\\[\n\\begin{align*}\na \\log ||x|| + b &= 0\na \\log R + b &= 0\n\\end{align*}\n\\tag{9}\\]\nThus, from Equation 9, \\(b = -a \\log R\\). Substituting the value for \\(b\\) in Equation 8, we have:\n\\[\n\\begin{align*}\na \\log r - a \\log R &= 1\\\\\na &= \\frac{1}{\\log r - \\log R}\n\\end{align*}\n\\]\nConsequently,\n\\[\n\\begin{align*}\nh(x) &= \\frac{\\log ||x||}{\\log r - \\log R} -  \\frac{1}{\\log r - \\log R} \\log R\\\\\n&= \\frac{\\log R - \\log ||x||}{\\log R - \\log r}\n\\end{align*}\n\\tag{10}\\]\n\n\n\nLet \\(h(x)=||x||^{2-d}\\). At \\(||x||=r\\), \\(a h(x) + b = 1\\). So, we have:\n\\[\n\\begin{align*}\na r^{2-d} + b = 1\n\\end{align*}\n\\tag{11}\\]\nAt \\(||x||=R\\), \\(ah(x) + b = 0\\). So, we have:\n\\[\n\\begin{align*}\na ||R||^{2-d} + b &= 0\n\\end{align*}\n\\tag{12}\\]\nFrom Equation 12, we get \\(b = -a R^{2-d}\\). Substituting this value in Equation 11, we get:\n\\[\\begin{align*}\na r^{2-d} - aR^{2-d}  &= 1\\\\\na &= \\frac{1}{r^{2-d} - R^{2-d}}\n\\end{align*}\\]\nAnd\n\\[\n\\begin{align*}\nb = - \\frac{R^{2-d}}{r^{2-d} - R^{2-d}}\n\\end{align*}\n\\]\nThus,\n\\[\n\\begin{align*}\nh(x) &= \\frac{||x||^{2-d}}{r^{2-d} - R^{2-d}} - \\frac{R^{2-d}}{r^{2-d} - R^{2-d}}\\\\\n&= \\frac{R^{2-d} - ||x||}{R^{2-d} - r^{2-d}}\n\\end{align*}\n\\tag{13}\\]\nCollecting all the results together, we get:\n\\[\nh(x) = \\begin{cases}\n\\frac{R - x}{R - r}, & d=1 \\\\\n\\frac{\\log R - \\log ||x||}{\\log R - \\log r}, & d=2 \\\\\n\\frac{R^{2-d} - ||x||^{2-d}}{R^{2-d} - r^{2-d}}, & d \\geq 3\n\\end{cases}\n\\tag{14}\\]\nPassing to the limit as \\(R \\to \\infty\\), for \\(d=1\\), we have:\n\\[\\begin{align*}\n\\lim_{R \\to \\infty} h(x) &= \\lim_{R \\to \\infty} \\frac{R - x}{R - r} \\\\\n&= \\lim_{R \\to \\infty} \\frac{1 - \\frac{x}{R}}{1 - \\frac{r}{R}}\\\\\n&= 1\n\\end{align*}\\]\nFor \\(d = 2\\), we get:\n\\[\\begin{align*}\n\\lim_{R \\to \\infty} h(x) &= \\lim_{R \\to \\infty} \\frac{1 - \\frac{\\log x}{\\log R}}{1 - \\frac{\\log r}{\\log R}} \\\\\n&= 1\n\\end{align*}\\]\nFor \\(d = 3\\), we get:\n\\[\\begin{align*}\n\\lim_{R \\to \\infty}  h(x) &= \\lim_{R \\to \\infty} \\frac{R^{2-d} - ||x||^{2-d}}{R^{2-d} - r^{2-d}}\\\\\n&= \\left(\\frac{||x||}{r}\\right)^{2-d}\n\\end{align*}\\]\nThis concludes the proof. \\(\\blacksquare\\)\n\n\n\nExample 4 We get more from the above proof. Indeed, in dimension \\(d \\geq 2\\), it implies that the probability that a Brownian motion starting at \\(B_0 = x\\) eventually hits any other point \\(y\\) is \\(0\\). Indeed, if we take \\(y = 0\\) and \\(x \\neq 0\\), we have:\n\\[\n\\begin{align*}\n\\mathbb{P}(\\exists t &gt; 0: B_t = 0) &= \\lim_{R \\to \\infty} \\lim_{r \\to \\infty} \\mathbb{P}(\\tau_r &lt; \\tau_R')\\\\\n&= \\lim_{R \\to \\infty} \\lim_{r \\to \\infty} \\frac{R^{2-d} - ||x||^{2-d}}{R^{2-d} - r^{2-d}}\\\\\n&=\\lim_{R \\to \\infty}  \\lim_{r \\to \\infty} \\frac{(R/r)^{2-d} - (||x||/r)^{2-d}}{(R/r)^{2-d} - 1}\\\\\n&= \\lim_{R \\to \\infty} 0\\\\\n&= 0\n\\end{align*}\n\\]\nHere, we shrink the inner radius to \\(0\\) first and then we let the outer radius go to infinity after. It remains to take the limits of the expression obtained in equation Equation 14. The first limit \\(r \\to 0\\) gives \\(0\\) right away.\n\n\n\n\nIn the last section, we translated the problem of recurrence and transience of Brownian motion in terms of a boundary value problem: we needed to find a particular function \\(h\\) that solves a PDE (that is, \\(\\nabla^2 h=0\\)) in a certain region of space(the annulus) and that satisfies given boundary conditions (the function is \\(1\\) on the inner circle and \\(0\\) on the outer circle). This is a particular case of the Dirichlet problem in PDE.\nConsider a region \\(\\mathcal{O} \\subset \\mathbb{R}^d\\). \\(\\mathcal{O}\\) is an open ball. That is, for all \\(x \\in \\mathcal{O}\\), there exists \\(\\epsilon&gt;0\\), such that \\(V_\\epsilon(x) = \\{y : ||y - x|| &lt; \\epsilon\\}\\) is contained in \\(\\mathcal{O}\\). \\(\\mathcal{O}\\) doesn’t contain boundary points \\(\\partial \\mathcal{O}\\). In the proof of Theorem 3, the region was the annulus \\(\\{x: r &lt; ||x|| &lt; R\\}\\) and the boundary was given by the spheres \\(\\{x :||x|| = r\\}\\) and \\(\\{x: ||x||=R\\}\\). The Dirichlet problem in \\(\\mathcal{O}\\) can be stated as follows:\nLet \\(f:\\partial\\mathcal{O} \\to \\mathbb{R}\\) be a function on the boundary of \\(\\mathcal{O}\\). Can we extend the function \\(f\\) to \\(O\\) in such a way that the extension is harmonic on \\(\\mathcal{O}\\) and coincides with \\(f\\) on the boundary?\nIn the instance of the proof of the Theorem 3, we knew the solution of the problem, thanks to Equation 4. The only job left to do was to adjust some parameters to fit the boundary conditions. It turns out that the formalism of stochastic calculus allows us to express the solution of the Dirichlet problem as an average over Brownian paths for general regions of space and boundary conditions. To do so, we look at a twist on the Ito’s formula called the Dynkin’s formula.\nLet \\(x\\) be a point in \\(\\mathcal{O}\\). Consider a Brownian motion \\((B_t,t\\geq 0)\\) starting at \\(x\\), \\(B_0 = x\\). To emphasize the dependence on \\(x\\), we write \\(\\mathbb{P}_x\\) and \\(\\mathbb{E}_x\\) for the probability and the expectation for the Brownian motion. Dykin’s formula is obtained by merging Corollary 1 for the Brownian martingales together with the optional stopping theorem. More precisely, consider \\(f \\in C^2(\\mathbb{R}^d)\\) that satisfies the assumption of the Corollary 1. We then have that the process:\n\\[\\begin{align*}\nM_t &= f(B_t) - \\frac{1}{2}\\int_{0}^t \\nabla^2 f(B_s) ds, \\quad t \\geq 0\n\\end{align*}\\]\nis a Brownian martingale.\nConsider also the stopping time \\(\\tau = \\min \\{t \\geq 0 : B_t \\in \\mathcal{O}^C\\}\\). This is the first exit time of \\(\\mathcal{O}\\) of the Brownian motion path. Then, if the assumptions of the optional stopping theorem are fulfilled, we get Dynkin’s formula:\n\\[\n\\begin{align*}\n\\mathbb{E}[M_\\tau] = \\mathbb{E}[f(B_\\tau)] - \\frac{1}{2} \\mathbb{E}\\left[\\int_0^\\tau \\nabla^2 f(B_s)ds\\right] = f(B_0) = M_0\n\\end{align*}\n\\tag{15}\\]\nAs an application of Dynkin’s formula, let’s express the solution of the Dirichlet problem as an average over Brownian motion. If \\(f\\) is harmonic in \\(\\mathcal{O}\\), then \\(\\nabla^2 f = 0\\) in \\(\\mathcal{O}\\), so the process \\((f(B_t),t\\leq \\tau)\\) is itself a martingale. Note that since \\(\\mathcal{O}\\) is bounded, this is a bounded martingale! Moreover, the integrands \\(\\partial_i f(B_s)\\), \\(1 \\leq i \\leq d\\), are bounded. We conclude that the solution to the Dirichlet problem can be represented as follows:\n\\[\n\\begin{align*}\nf(x) = \\mathbb{E}_x[f(B_\\tau)], \\quad x \\in \\mathcal{O}\n\\end{align*}\n\\tag{16}\\]\nIn other words, the value of the harmonic function of \\(f\\) at \\(x\\) is given by the average over the Brownian paths of the value of the function at the exit point of the path on the boundary of \\(\\mathcal{O}\\). Equation Equation 16 does not prove the existence of the solution to the Dirichlet problem, as we assume that such a function exists. Existence of the solution to the Dirichlet problem can be shown this way, assuming the region \\(\\mathcal{O}\\) and the function on the boundary are nice enough. However, note that the averaging on the right-hand side of the formula makes sense even in the case where \\(f\\) is simply defined on the boundary \\(\\partial \\mathcal{O}\\). We then define a posteriori the harmonic extension of \\(f\\) inside \\(\\mathcal{O}\\) by defining its value at \\(x\\) as \\(\\mathbb{E}_x[f(B_\\tau)]\\).\n\n\n\n\n\n\n\nExercise 1 Gaussian Integration by parts.\n\nLet \\(Z\\) be a standard Gaussian random variable. Show using integration by parts that for a differentiable function \\(g\\):\n\n\\[\n\\begin{align*}\n\\mathbb{E}[Z g(Z)] = \\mathbb{E}[g'(Z)]\n\\end{align*}\n\\tag{17}\\]\nwhere we assume that both expectations are well-defined.\n\nUse this to recover the expression for the moments for \\(\\mathbb{E}[Z^{2j}],j \\in \\mathbb{N}\\).\n\n\nSolution.\nWe have:\n\\[\n\\begin{align*}\n\\mathbb{E}[g'(Z)] &= \\int_{-\\infty}^{\\infty}\\phi(z) \\cdot g'(z) dz \\\\\n&= \\left[\\frac{e^{-z^2/2}}{\\sqrt{2\\pi}}\\cdot g(z)\\right]_{-\\infty}^{\\infty} - \\int_{-\\infty}^{\\infty} g(z) \\frac{-ze^{-z^2/2}}{\\sqrt{2\\pi}}dz \\\\\n&= 0 + \\int_{-\\infty}^{\\infty} z g(z) \\phi(z)dz\\\\\n&= \\mathbb{E}[Zg(Z)]\n\\end{align*}\n\\]\nMoreover, we can write:\n\\[\n\\begin{align*}\n\\mathbb{E}[Z^{2n}] &= \\mathbb{E}[Z \\cdot Z^{2n-1}] \\\\\n&= \\mathbb{E}[Z \\cdot g(Z)], \\quad \\{ \\text{ where }g(x)=x^{2n - 1}\\} \\\\\n&= \\mathbb{E}[g'(Z)] \\\\\n&= (2n - 1) \\mathbb{E}[Z^{(2n - 2)}] \\\\\n& \\vdots \\\\\n&= (2n - 1)\\cdots 5 \\cdot 3 \\cdot \\mathbb{E}[Z^2] \\\\\n&= (2n - 1)\\cdots 5 \\cdot 3 \\cdot 1\n\\end{align*}\n\\]\n\nExercise 2 The Heat Equation.\nUse the Gaussian integration by parts identity to check that the solution \\(f(t,x)\\) to the heat equation is:"
  },
  {
    "objectID": "posts/multivariate_ito_calculus/index.html#multidimensional-brownian-motion.",
    "href": "posts/multivariate_ito_calculus/index.html#multidimensional-brownian-motion.",
    "title": "Multivariate Ito Calculus",
    "section": "",
    "text": "Definition 1 (Brownian motion in \\(\\mathbf{R}^{d}\\).) Take \\(d\\in\\mathbf{N}\\). Let \\(B^{(1)},\\ldots,B^{(d)}\\) be independent standard Brownian motions in \\((\\Omega,\\mathcal{F},\\mathbb{P})\\). The process \\((B_{t}:t\\geq0)\\) taking values in \\(\\mathbf{R}^{d}\\) defined by :\n\\[\\begin{aligned}\nB_{t} & =(B_{t}^{(1)},\\ldots,B_{t}^{(d)}),\\quad t\\geq0\n\\end{aligned}\\]\nis called a \\(d-\\)dimensional Brownian motion or a Brownian motion in \\(\\mathbf{R}^{d}\\).\n\nThe Brownian filtration \\((\\mathcal{F}_{t}:t\\geq0)\\) is now composed of the information of all Brownian motions. In other words, it is given by the sigma-fields:\n\\[\\begin{aligned}\n\\mathcal{F}_{t} & =\\sigma(B_{s}^{(i)},1\\leq i\\leq d,s\\leq t)\n\\end{aligned}\\]\nFor every outcome \\(\\omega\\), the path of trajectory of a \\(d-\\)dimensional Brownian motion is a curve in space parametrized by the time \\(t\\):\n\\[\\begin{aligned}\nt\\mapsto B_{t}(\\omega) & =(B_{t}^{(1)}(\\omega),B_{t}^{(2)}(\\omega),\\ldots,B_{t}^{(d)}(\\omega))\n\\end{aligned}\\]\nOf course, this curve is continuous, since each coordinate is. The below numerical project gives an example of one path of a two-dimensional brownian motion. This is a very rugged and intertwined curve! We might wonder, what it does as \\(t\\to\\infty\\). Does it wander around \\((0,0)\\) ad infinitum or does it eventually escape to infinity? We will answer this question in a later section. For doing so, we shall need a version of Ito’s formula for multi-dimensional Brownian motion. We finish this section by noticing that it is also easy to construct Brownian motions in higher dimensions for which the coordinates are correlated.\n\n\nConsider a two-dimensional Brownian motion \\((B_{t}^{(1)},B_{2}^{(2)})\\) starting at \\((0,0)\\).\nLet’s plot one path of this Brownian motion on the plane \\(\\mathbf{R}^{2}\\) on the plane in \\(\\mathbf{R}^{2}\\) on the time interval \\([0,5]\\) using a discretization of \\(0.001\\).\nWe define BrownianMotion2D class.\n\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nsns.set_style(\"whitegrid\")\n\nclass BrownianMotion2D:\n    \"\"\"\n    Generate sample paths for a 2d-brownian motion\n    \"\"\"\n    def __init__(\n        self,\n        endpoint : float = 1.0,\n        discretization : float = 0.01\n    ):\n        self.endpoint = endpoint\n        self.discretization = discretization\n\n    def generate_paths(self, num_paths : int):\n        steps = int(self.endpoint/self.discretization)\n        delta_z = np.sqrt(self.discretization) * np.random.randn(num_paths,2,steps)\n        \n        # paths has shape [num_paths,2,num_steps]\n        paths = np.cumsum(delta_z,axis=2)\n\n        # Brownian motion has position (0,0) at time t=0\n        # Append initial position \n        init_position = np.zeros((num_paths,2,1))\n        paths = np.append(init_position,paths,axis=2)\n\n        return paths\n\nWe can then configure and use BrownianMotion2D objects as we please.\n\n\nShow the code\nbm = BrownianMotion2D(endpoint=5.0,discretization=0.001)\npaths = bm.generate_paths(num_paths=1)\npath = paths[0]\n\n\nplt.xlabel(r'$x$')\nplt.ylabel(r'$y$')\nplt.title(r'2D-Brownian motion')\nplt.grid(True)\nplt.plot(path[0],path[1],linewidth=1,color='blue')\nplt.show()\n\n\n\n\n\n\n\n\n\nExample 1 (Brownian motion with correlated coordinates) Let \\((B_{t}:t\\geq0)\\) be a two dimensional brownian motion. Let \\(-1&lt;\\rho&lt;1\\). We construct the two dimensional process as follows: \\(W_{t}=(W_{t}^{(1)},W_{t}^{(2)})\\) where:\n\\[\\begin{aligned}\nW_{t}^{(1)} & =B_{t}^{(1)}\\\\\nW_{t}^{(2)} & =\\rho B_{t}^{(1)}+\\sqrt{1-\\rho^{2}}B_{t}^{(2)}\n\\end{aligned}\\]\n\\(W_{t}^{(1)}=B_{t}^{(1)}\\) is Gaussian with mean \\(0\\) and variance \\(t\\). Since, \\(B_{t}^{(1)}\\) and \\(B_{t}^{(2)}\\)are independent gaussian random variables and the sum of IID Gaussians is Gaussian, \\(W_{t}^{(2)}\\) is Gaussian with mean \\(0\\) and variance \\(t\\). The covariance between \\(W_{t}^{(1)}\\) and \\(W_{t}^{(2)}\\) is:\n\\[\\begin{aligned}\n\\mathbf{E}[W_{t}^{(1)}W_{t}^{(2)}] & =\\mathbf{E}[B_{t}^{(1)}(\\rho B_{t}^{(1)}+\\sqrt{1-\\rho^{2}}B_{t}^{(2)})]\\\\\n& =\\mathbf{E}[\\rho(B_{t}^{(1)})^{2}+\\sqrt{1-\\rho^{2}}B_{t}^{(1)}B_{t}^{(2)}]\\\\\n& =\\rho t\n\\end{aligned}\\]\nHence, the coordinates at time \\(t\\) are not independent.\n\nConsider now the process \\((W_{t}:t\\geq0)\\) for \\(\\rho=1/2\\) as in example 2. Let’s plot one path of this process on the plane \\(\\mathbf{R}^{2}\\) on the time-interval \\([0,5]\\) using a discretization of \\(0.001\\).\n\nclass BrownianMotion2DWithCorrelatedCoords(BrownianMotion2D):\n    \"\"\"\n    Generate sample paths for a 2d-brownian motion\n    have correlated coordiantes\n    \"\"\"\n\n    def __init__(\n        self, \n        endpoint: float = 1.0, \n        discretization: float = 0.01, \n        rho: float = 0.0\n    ):\n        self.endpoint = endpoint\n        self.discretization = discretization\n        self.rho = rho\n\n    def generate_paths(self, num_paths: int):\n\n        # Call the base class generate_paths() method to generate a pair of\n        # independent brownian motion paths. It returns a tensor of\n        # shape (num_paths, 2, num_steps)\n        paths = super().generate_paths(num_paths=num_paths)\n\n        # Extract the brownian motions B1(t) and B2(t)\n        # B1(t) and B2(t) have dimensions [num_paths,num_steps]\n        x_coord = paths[:, 0, :]\n        y_coord = paths[:, 1, :]\n\n        # Apply the transformation\n        # W1(t) = B1(t)\n        # W2(t) = rho * B1(t) + sqrt(1 - rho**2) B2(t)\n        x_coord = x_coord\n        y_coord = self.rho * x_coord + np.sqrt(1 - self.rho**2) * y_coord\n\n        # Assemble back the x- and y- coordinates\n        x_coord = np.expand_dims(x_coord, axis=1)\n        y_coord = np.expand_dims(y_coord, axis=1)\n\n        # Return a tensor of shape [num_paths,d=2,num_steps]\n        return np.concatenate([x_coord, y_coord], axis=1)\n\nLet’s configure the BrownianMotion2DWithCorrelatedCoords engine with the settings endpoint=5.0, discretization=0.001 and rho=0.5 and generate a sample path.\n\n\nShow the code\nbm = BrownianMotion2DWithCorrelatedCoords(\n    endpoint=5.0,\n    discretization=0.001,\n    rho=0.50\n)\npaths = bm.generate_paths(num_paths=1)\npath = paths[0]\n\nplt.xlabel(r'$x$')\nplt.ylabel(r'$y$')\nplt.title(r'Correlated Brownian motion $W(t)=(W^{(1)}(t),W^{(2)}(t))$')\nplt.grid(True)\nplt.plot(path[0],path[1],linewidth=1,color='blue')\nplt.show()\n\n\n\n\n\n\n\nShow the code\nplt.xlabel(r'$t$')\nplt.ylabel(r'$W_t$')\nplt.title(r'Correlated Brownian motion paths')\nplt.grid(True)\nt = np.linspace(0.0,stop=5.0,num=5001)\nplt.plot(t,path[0],linewidth=0.75)\nplt.plot(t,path[1],linewidth=0.75)\nplt.show()"
  },
  {
    "objectID": "posts/multivariate_ito_calculus/index.html#itos-formula.",
    "href": "posts/multivariate_ito_calculus/index.html#itos-formula.",
    "title": "Multivariate Ito Calculus",
    "section": "",
    "text": "Theorem 1 (Ito’s Formula.) Let \\((B_{t}:t\\geq0)\\) be a \\(d-\\)dimensional brownian motion. Consider \\(f\\in\\mathcal{C}^{2}(\\mathbf{R}^{d})\\). Then, we have with probability one that for all \\(t\\geq0\\):\n\\[\\begin{aligned}\nf(B_{t})-f(B_{0}) & =\\sum_{i=1}^{d}\\int_{0}^{t}\\partial_{x_{i}}f(B_{s})dB_{s}^{(i)}+\\frac{1}{2}\\int_{0}^{t}\\sum_{i=1}^{d}\\partial_{x_{i}}^{2}f(B_{s})ds\\label{eq:multidimensional-ito-formula}\n\\end{aligned}\\]\n\n\nI stress that, as in the one-dimensional case, Ito’s formula is an equality of processes (and not an equality in distribution). Thus, the processes on both sides must agree for each path.\n\nInterestingly, the mixed partials \\(\\partial_{x_{i}x_{j}}f(B_{s})\\), \\(i\\neq j\\) do not appear in the formula! We see from Ito’s formula that the process \\(f(B_{t})\\) can be represented as a sum of \\(d+1\\) processes: \\(d\\) Ito integrals and one Riemann integral (which is a process of finite variation). In vector notation, the formula takes the form:\n\\[\\begin{aligned}\nf(B_{t})-f(B_{0}) & =\\int_{0}^{t}\\nabla f(B_{s})^{T}dB_{s}+\\frac{1}{2}\\int_{0}^{t}\\nabla^{2}f(B_{s})ds\n\\end{aligned}\\]\nwhere it is understood that the first term is the sum of the \\(d\\) Ito integrals in the equation. The symbol \\(\\nabla^{2}\\) is the Laplacian of \\(f\\):\n\\(\\sum_{i=1}^{d}\\frac{\\partial^{2}}{\\partial x_{i}^{2}}f(B_{s}^{(1)},\\ldots,B_{s}^{(d)})ds\\)\nIn differential form, Ito’s formula becomes very neat:\n\\[\\begin{aligned}\ndf(B_{t}) & =\\sum_{i=1}^{d}\\partial_{x_{i}}f(B_{s})dB_{t}^{(i)}+\\frac{1}{2}\\sum_{i=1}^{d}\\partial_{x_{i}}^{2}f(B_{s})dt=\\nabla f(B_{t})^{T}dB_{s}+\\frac{1}{2}\\nabla^{2}f(B_{t})dt\n\\end{aligned}\\]\n\nExample 2 Consider the functions (1) \\(f(x_{1},x_{2})=x_{1}^{2}+x_{2}^{2}\\) (2) \\(f(x_{1},x_{2})=e^{x_{1}}\\cos x_{2}\\) and the processes \\((X_{t}:t\\geq0)\\) and \\((Y_{t}:t\\geq0)\\). If we apply Ito’s formula to the first process, we have:\n\\[\\begin{aligned}\nX_{t} & =\\int_{0}^{t}2B_{s}^{(1)}dB_{s}^{(1)}+\\int_{0}^{t}2B_{s}^{(2)}dB_{s}^{(2)}+\\frac{1}{2}\\int_{0}^{t}(4dt)\\\\\n& =\\int_{0}^{t}2B_{s}^{(1)}dB_{s}^{(1)}+\\int_{0}^{t}2B_{s}^{(2)}dB_{s}^{(2)}+2t\n\\end{aligned}\\]\nThe second process gives:\n\\[\\begin{aligned}\nY_{t} & =\\cos B_{s}^{(2)}\\int_{0}^{t}e^{B_{s}^{(1)}}dB_{s}^{(1)}-e^{B_{s}^{(1)}}\\int\\sin B_{s}^{(2)}dB_{s}^{(2)}+\\frac{1}{2}\\int_{0}^{t}\\left(e^{B_{s}^{(1)}}\\cos B_{s}^{(2)}-e^{B_{s}^{(1)}}\\cos B_{s}^{(2)}\\right)dt\\\\\n& =1+\\cos B_{s}^{(2)}\\int_{0}^{t}e^{B_{s}^{(1)}}dB_{s}^{(1)}-e^{B_{s}^{(1)}}\\int\\sin B_{s}^{(2)}dB_{s}^{(2)}\n\\end{aligned}\\]\n\n\nExample 3 (Cross-Variation of \\(B_{t}^{(1)}\\) and \\(B_{t}^{(2)}\\)). Let \\((t_{j}:j\\leq n)\\) be a sequence of partitions of \\([0,t]\\) such that \\(\\max_{j}|t_{j+1}-t_{j}|\\to0\\) as \\(n\\to\\infty\\). Prove that:\n\\[\\begin{aligned}\n\\lim_{n\\to\\infty}\\sum_{j=0}^{n-1}(B_{t_{j+1}}^{(1)}-B_{t_{j}}^{(1)})(B_{t_{j+1}}^{(2)}-B_{t_{j}}^{(2)}) & =0\\quad\\text{in } L^{2}\n\\end{aligned}\\]\nThis justifies the rule \\(dB_{t}^{(1)}\\cdot dB_{t}^{(2)}=0\\).\nHint: Just compute the second moment of the sum.\n\n\nWe have:\n\\[\\begin{aligned}\n& \\mathbf{E}\\left[\\left(\\sum_{j=0}^{n-1}(B_{t_{j+1}}^{(1)}-B_{t_{j}}^{(1)})(B_{t_{j+1}}^{(2)}-B_{t_{j}}^{(2)})\\right)^{2}\\right]\\\\\n= & \\sum_{j=0}^{n-1}\\mathbf{E}[(B_{t_{j+1}}^{(1)}-B_{t_{j}}^{(1)})^{2}(B_{t_{j+1}}^{(2)}-B_{t_{j}}^{(2)})^{2}]\\\\\n+ & 2\\sum_{j&lt;k}\\mathbf{E}\\left[(B_{t_{j+1}}^{(1)}-B_{t_{j}}^{(1)})(B_{t_{k+1}}^{(1)}-B_{t_{k}}^{(1)})(B_{t_{j+1}}^{(2)}-B_{t_{j}}^{(2)})(B_{t_{k+1}}^{(2)}-B_{t_{k}}^{(2)})\\right]\n\\end{aligned}\\]\nBoth these expectations are zero, since the brownian motions are independent and non-overlapping increments are independent.\nConsequently, \\(\\sum_{j=0}^{n-1}(B_{t_{j+1}}^{(1)}-B_{t_{j}}^{(1)})(B_{t_{j+1}}^{(2)}-B_{t_{j}}^{(2)})\\to0\\) in the \\(L^{2}\\) sense.\n\n\nProof. The proof of the formula follows the usual recipe: Taylor’s theorem together with the quadratic variation and the cross-variation. In this case, we do get a cross-variation between the different Brownian motions. More precisely, consider a partition \\((t_{j}:j\\leq n)\\) of \\([0,t]\\). Then we can write:\n\\[\\begin{aligned}\nf(B_{t})-f(B_{0}) & =\\sum_{j=0}^{n-1}(f(B_{t_{j+1}})-f(B_{t_{j}}))\n\\end{aligned}\\]\nWe can apply the Taylor’s series expansion for each \\(j\\) to get:\n\\[\\begin{aligned}\nf(B_{t})-f(B_{0}) & =\\sum_{j=0}^{n-1}\\nabla f(B_{t_{j}})(B_{t_{j+1}}-B_{t_{j}})\\\\\n& +\\frac{1}{2}\\sum_{j=0}^{n-1}(B_{t_{j+1}}-B_{t_{j}})^{T}Hf(B_{t_{j}})(B_{t_{j+1}}-B_{t_{j}})+\\mathcal{E}\n\\end{aligned}\\]\nwhere \\(Hf\\) is the Hessian matrix of \\(f\\). We wrote the expansion using the vector notation to be economical. Let’s keep in mind that each term is a sum over the derivatives. The first term will converge to \\(d\\) Ito integrals as in the one-dimensional case. Now, the summand in the second term is:\n\\[(B_{t_{j+1}}^{(1)}-B_{t_{j}}^{(1)},\\ldots,B_{t_{j+1}}^{(d)}-B_{t_{j}}^{(d)})\\left[\\begin{array}{ccc}\n\\partial_{x_{1}}^{2}f(B_{t_{j}}) & \\ldots & \\partial_{x_{1}x_{d}}^{2}f(B_{t_{j}})\\\\\n\\vdots & \\ddots\\\\\n\\partial_{x_{d}x_{1}}^{2}f(B_{t_{j}}) &  & \\partial_{x_{d}}^{2}f(B_{t_{j}})\n\\end{array}\\right]\\left[\\begin{array}{c}\nB_{t_{j+1}}^{(1)}-B_{t_{j}}^{(1)}\\\\\n\\vdots\\\\\nB_{t_{j+1}}^{(d)}-B_{t_{j}}^{(d)}\n\\end{array}\\right]\\]\nSo, \\((B_{t_{j+1}}^{(i)}-B_{t_{j}}^{(i)})\\) is pre-multiplied with the term \\(\\partial_{x_{i}x_{k}}^{2}f(B_{t_{j}})\\) and it is post-multiplied \\((B_{t_{j+1}}^{(k)}-B_{t_{j}}^{(k)})\\). Consequently, the second term in the Taylor’s series expansion can be re-written as:\n\\[\\sum_{j=0}^{n-1}\\left(\\sum_{i=1}^{d}\\partial_{x_{i}}^{2}f(B_{t_{j}})(B_{t_{j+1}}^{(i)}-B_{t_{j}}^{(i)})^{2}+\\sum_{1\\leq i&lt;k\\leq d}\\partial_{x_{i}x_{k}}^{2}f(B_{t_{j}})(B_{t_{j+1}}^{(i)}-B_{t_{j}}^{(i)})(B_{t_{j+1}}^{(k)}-B_{t_{j}}^{(k)})\\right)\\]\nThe second term on the right converges to \\(0\\) in the \\(L^{2}\\) sense when \\(i\\neq k\\), from exercise. This explains why the mixed derivatives disappear in the multi-dimensional Ito’s formula. As for the case \\(i=k\\), it reduces to the quadratic variation as in the one-dimensional case. This is where the Riemann integral arises, after suitable conditioning on \\(\\mathcal{F}_{t_{j}}\\), the sigma-field generated by \\(B_{s}\\), \\(s\\leq t_{j}\\).\n\nAs in the one-dimensional case,it is not necessary to learn Ito’s formula by heart. It suffices to write the differential of the function \\(f\\) to second order. We can then apply the rules of multivariate Ito calculus:\n\n\n\n\\(\\cdot\\)\n\\(dt\\)\n\\(dB_{t}^{(1)}\\)\n\\(dB_{t}^{(2)}\\)\n\\(\\ldots\\)\n\n\n\n\n\\(dt\\)\n\\(0\\)\n\\(0\\)\n\\(0\\)\n\\(0\\)\n\n\n\\(dB_{t}^{(1)}\\)\n\\(0\\)\n\\(dt\\)\n\\(0\\)\n\\(0\\)\n\n\n\\(dB_{t}^{(2)}\\)\n\\(0\\)\n\\(0\\)\n\\(dt\\)\n\\(0\\)\n\n\n\\(\\ldots\\)\n\\(0\\)\n\\(0\\)\n\\(0\\)\n\\(dt\\)\n\n\n\nNote that the rule \\(dB_{t}^{(i)}dB_{t}^{(j)}=0\\) for \\(i\\neq j\\) is being motivated by the cross-variation result.\nHow can we construct martingales using the Ito’s formula? Recall that an Ito integral \\((\\int_{0}^{t}X_{s}dB_{s},t\\leq T)\\) is a martingale whenever the integrand is in \\(\\mathcal{L}_{c}^{2}(T)\\), the space of adapted processes with continuous paths and for which:\n\\[\\begin{aligned}\n\\int_{0}^{T}\\mathbf{E}[X_{s}^{2}]ds & &lt;\\infty\n\\end{aligned}\\]\nThe only difference here is that the integrand is a function of many Brownian motions. However, the integrands involved in the Ito integrals of the multidimensional Ito’s formula are clearly adapted to the filtration \\((\\mathcal{F}_{t}:t\\geq0)\\) of \\((B_{t}:t\\geq0)\\) as they are functions of the Brownian motion at the time. The arguments of Ito integral in and apply verbatim, if we take the definition of \\(\\mathcal{L}_{c}^{2}(t)\\) with the filtration \\((\\mathcal{F}_{t}:t\\geq0)\\) of \\((B_{t}:t\\geq0)\\). With this in mind, we have the following corollary.\n\n\n\nCorollary 1 (Brownian Martingales.) Let \\((B_{t}:t\\geq0)\\) be a Brownian motion in \\(\\mathbf{R}^{d}\\). Consider \\(f\\in\\mathcal{C}^{2}(\\mathbf{R}^{d})\\) such that processes \\((\\partial_{x {i}}f(B_{t}),t\\leq T)\\in\\mathcal{L}_{c}^{2}(T)\\) for every \\(i\\leq d\\). Then, the process :\n\\[f(B_{t})-\\frac{1}{2}\\int_{0}^{t}\\nabla^{2}f(B_{s})ds,\\quad t\\leq T\\]\nwhere \\(\\nabla^{2}=\\sum_{i=1}^{d}\\partial_{x_{i}}^{2}\\) is the Laplacian, is a martingale for the Brownian filtration.\n\nFor example, consider the processes \\(X_{t}=(B_{t}^{(1)})^{2}+(B_{t}^{(2)})^{2}\\) and \\(Y_{t}=\\exp(B_{t}^{(1)})\\cos(B_{t}^{(2)})\\). Then, we have :\n\\[\\frac{1}{2}\\int_{0}^{t}\\nabla^{2}X_{s}ds=\\frac{1}{2}\\int_{0}^{t}4ds=2t\\]\nand\n\\[\\begin{aligned}\n\\frac{1}{2}\\int_{0}^{t}\\nabla^{2}Y_{s}ds & =\\frac{1}{2}\\int_{0}^{t}0\\cdot ds=0\n\\end{aligned}\\]\nThus, the processes \\(X_{t}-2t\\) and \\(Y_{t}\\) are martingales for the Brownian filtration. In one dimension, there are no interesting martingales constructed with functions of space only. Indeed, \\((f(B_{t}):t\\geq0)\\) is a martingale if and only if \\(f''(x)=0\\) for all \\(x\\). But, such functions are of the form \\(f(x)=ax+b\\), \\(a,b\\in\\mathbf{R}\\). In other words, in one dimension, Brownian martingales of the form \\(f(B_{t})\\) are simply \\(aB_{t}+b\\). Not very surprising! The situation is very different in higher dimensions. Indeed, corollary implies that \\(f(B_{t})\\) is a martingale whenever \\(f\\) is a harmonic function:\n\nDefinition 2 (Harmonic function.) A function \\(f:\\mathbf{R}^{d}\\to\\mathbf{R}\\) is harmonic in \\(\\mathbf{R}^{d}\\) if and only if \\(\\nabla^{2}f(x)\\equiv0\\) for all \\(x\\in\\mathbf{R}^{d}\\). More generally, a function \\(f:\\mathbf{R}^{d}\\to\\mathbf{R}\\) is harmonic in the region \\(\\mathcal{O}\\subset\\mathbf{R}^{d}\\) if and only if \\(\\nabla^{2}f(x)\\equiv0\\) for all \\(x\\in\\mathcal{O}\\).\n\nNote that the function \\(f(x)=e^{x_{1}}\\cos x_{2}\\) is harmonic in \\(\\mathbf{R}^{d}\\). This is why the process \\(Y_{t}=\\exp(B_{t}^{(1)})\\cos(B_{t}^{(2)})\\) is a martingale. The distinction to a subset of \\(\\mathbf{R}^{d}\\) in the above definition is important since it may happen that the function is harmonic only in a subset of the space; see for example equation. It is possible to define a Brownian martingale in such cases by considering the process until it exits the region. This will turn out to be important as we move ahead.\nThe multidimensional Ito’s formula generalizes to functions of time and space as in proposition:\n\nDefinition 3 A function \\(f:[0,\\infty)\\times\\mathbf{R}^{d}\\to\\mathbf{R}\\) is in \\(\\mathcal{C}^{1,2}([0,T]\\times\\mathbf{R}^{d})\\) if the partial derivative in time :\n\\[\\frac{\\partial}{\\partial t}f(t,\\mathbf{x})\\]\nexists and is continuous and the second order partial derivatives in space:\n\\[\\frac{\\partial^{2}}{\\partial x_{i}^{2}}f(t,x_{1},x_{2},\\ldots,x_{i},\\ldots,x_{d}),\\quad1\\leq i\\leq d\\]\nexist and are continuous."
  },
  {
    "objectID": "posts/multivariate_ito_calculus/index.html#multidimensional-ito-formula---functions-of-space-and-time",
    "href": "posts/multivariate_ito_calculus/index.html#multidimensional-ito-formula---functions-of-space-and-time",
    "title": "Multivariate Ito Calculus",
    "section": "",
    "text": "Theorem 2 (Multidimensional Ito’s formula for functions of space and time) Let \\((B_{t}:t\\leq T)\\) be a \\(d\\)-dimensional Brownian motion. Consider a function \\(f\\in\\mathcal{C}^{1,2}([0,T]\\times\\mathbf{R}^{d})\\). Then, we have with probability one for all \\(t\\leq T\\):\n\\[\\begin{aligned}\nf(t,B_{t})-f(0,B_{0}) & =\\sum_{i=1}^{d}\\int_{0}^{t}\\partial_{x_{i}}f(s,B_{s})dB_{s}^{(i)}+\\int_{0}^{t}\\left(\\partial_{t}f(s,B_{s})+\\sum_{i=1}^{d}\\partial_{x_{i}}^{2}f(s,B_{s})\\right)ds\n\\end{aligned}\\]\n\nThe martingale condition is then similar to the ones in corollary ([cor:brownian-martingales-in-Rd]): if the processes \\((\\partial_{x_{i}}f(s,B_{s}),t\\leq T)\\in\\mathcal{L}_{c}^{2}(T)\\) for every \\(1\\leq i\\leq d\\), then the process\n\\[f(t,B_{t})-\\int_{0}^{t}\\left\\{ \\partial_{t}f(s,B_{s})++\\sum_{i=1}^{d}\\partial_{x_{i}}^{2}f(s,B_{s})\\right\\} ds,\\quad t\\leq T \\tag{1}\\]\nis a martingale for the Brownian filtration. In particular, if \\(f\\) satisfies the partial differential equation:\n\\[\n\\begin{aligned}\n\\frac{\\partial f}{\\partial t}+\\frac{1}{2}\\nabla^{2}f & =0\n\\end{aligned}\n\\tag{2}\\]\nthen the process \\((f(t,B_{t}):t\\leq T)\\) itself is a martingale."
  },
  {
    "objectID": "posts/multivariate_ito_calculus/index.html#polyas-random-walk-theorem",
    "href": "posts/multivariate_ito_calculus/index.html#polyas-random-walk-theorem",
    "title": "Multivariate Ito Calculus",
    "section": "",
    "text": "Consider a simple random walk on the integer lattice \\(\\mathbb{Z}^d\\). At each time step, a random walker makes a random move of length one in one of the lattice directions.\nWe say that, if the random walk returns to the origin with probability one infinitely many times, it is recurrent, if it does not we will call it transient.\nIt’s worth to spend a moment visiting Polya’s Random Walk Theorem, a fascinating, but not so intuitive result.\nAssuming all random walks start at the origin, we define \\(u\\) to be the probability that a random walker returns to the origin. The probability that the random walker returns to the origin exactly \\(m\\) times is:\n\\[\\begin{align*}\n{m \\choose m-1} u^{m-1} (1 - u)^{m - (m - 1)} = u^{m-1}(1-u)\n\\end{align*}\\]\nThe expected number of times the particle returns to the origin for an infinite random walk is:\n\\[\\begin{align*}\nE &= \\sum_{m = 1}^{\\infty} m (u^{m-1}(1-u))\\\\\n&= (1-u)\\sum_{m=1}^{\\infty}mu^{m-1}\\\\\n&= (1-u)\\sum_{m=1}^{\\infty}\\frac{d}{du}u^{m}\\\\\n\\end{align*}\\]\nWe note that limit exchanging is acceptable since the power series \\(\\sum_{n=1}^{\\infty}x^n\\) converges uniformly for \\(u &lt; 1\\) and we can apply the differentiable limit theorem.\nSo we obtain:\n\\[\\begin{align*}\nE &= (1-u)\\frac{d}{du}\\sum_{m = 1}^{\\infty} u^m \\\\\n&= (1-u)\\cdot \\frac{1}{(1-u)^2}\\\\\n&= \\frac{1}{1-u}\n\\end{align*}\\]\nSo, we see that if \\(E\\) is finite, \\(u &lt; 1\\), then the walk is transient and if \\(E = +\\infty\\), \\(u=1\\), then the walk is recurrent.\nWe then define \\(u_n\\) to be the probability that a given walk is at the origin on the \\(n\\)th step, defining the value \\(u_0=1\\) for the trivial loop. We also introduce an indicator random variable \\(x_n\\), which takes the value \\(1\\), if the particle is at the origin on the \\(n\\)th step and zero otherwise.\nThen\n\\[\\begin{align*}\nT = \\sum_{n=1}^{\\infty}x_n\n\\end{align*}\\]\nis the total number of times, the particle is at the origin, so \\(E\\) is equal to the expectation of \\(T\\), \\(\\mathbb{E}(T)\\), which is equal to:\n\\[\\begin{align*}\n\\mathbb{E}[T] &= \\sum_{n=1}^{\\infty}\\mathbb{E}[x_n]\\\\\n&= \\sum_{n=1}^{\\infty} u_n\n\\end{align*}\\]\nBut, we showed previously that if \\(E\\) is finite, then the walk is transient and if \\(E = \\infty\\), then the walk is recurrent, so we have established that if:\n\\[\\begin{align*}\n\\sum_{n=1}^{\\infty}u_n\n\\end{align*}\\]\nconverges then the walk is transient and if the sum diverges, then the walk is recurrent.\n\n\nNow that we have built up the necessary tools, we will consider the cases. We start by considering a simple random walk on \\(\\mathbb{Z}^1\\). Since, as mentioned previously, a walk must have an even number of steps to be a loop, we only look at \\(u_{2n},n \\in \\mathbb{Z}^+\\). A path of length \\(2n\\) returning to the origin must have \\(n\\) up-moves and \\(n\\) down-moves. The number of such paths are \\({2n \\choose n}\\). Each such path has a probability of occurrence \\(\\frac{1}{2^{2n}}\\). Thus,\n\\[\\begin{align*}\nu_{2n} = \\frac{1}{2^{2n}}{2n \\choose n}\n\\end{align*}\\]\nUsing Stirling’s approximation \\(n! \\sim \\sqrt{2\\pi n} e^{-n} n^{n}\\), we obtain:\n\\[\\begin{align*}\nu_{2n} &= \\frac{1}{2^{2n}} \\frac{(2n)!}{n! n!}\\\\\n&\\approx \\frac{1}{2^{2n}} \\cdot \\frac{\\sqrt{2\\pi(2n)} e^{-2n}(2n)^{2n}}{\\left(\\sqrt{2\\pi n} e^{-n} n^n\\right)^2}\\\\\n&=\\frac{1}{\\sqrt{\\pi n}}\n\\end{align*}\\]\nSo, we see that:\n\\[\\begin{align*}\n\\sum_{n=0}^{\\infty} u_{2n} \\approx \\sum_{n=0}^{\\infty} \\frac{1}{\\sqrt{n\\pi}}\n\\end{align*}\\]\nAnd the series on the right certainly diverges so, we see that a simple random walk in \\(\\mathbb{Z}^1\\) is recurrent since \\(E\\) diverges.\n\n\n\nA particle has an equal probability \\(1/4\\) of moving left, right, up or down randomly in the \\(d=2\\) dimensional lattice. Each path of \\(2n\\) steps has a probability \\(\\frac{1}{4^{2n}}\\) of occurring. We then consider the number of paths with equal steps left and right (say \\(L\\) steps in each horizontal direction) and equal steps up and down (then \\(n-L\\)) is:\n\\[\\begin{align*}\n{2n \\choose L}{2n - L \\choose L}{2n - 2L \\choose n - L}{n-L \\choose n - L} = \\frac{(2n)!}{L! L! (n-L)! (n-L)!}\n\\end{align*}\\]\nSo we get:\n\\[\\begin{align*}\nu_{2n} &= \\frac{1}{4^{2n}} \\sum_{L=0}^n \\frac{(2n)!}{L! L! (n-L)! (n-L)!} \\\\\n&= \\frac{1}{4^{2n}} \\sum_{L=0}^n \\frac{(2n)!}{n! n!} \\cdot \\left(\\frac{n!}{L! (n-L)!}\\right)^2 \\\\\n&=\\frac{1}{4^{2n}} {2n \\choose n}\\sum_{L=0}^n {n \\choose L}^2\n\\end{align*}\\]\nSuppose, we are to form a team of \\(n\\) players from a population of \\(2n\\) participants. There \\({2n \\choose n}\\) distinguishable teams of size \\(n\\). Alternatively, we could divide the population into two halves of \\(n\\) participants each, choose \\(L\\) participants from the first sub-population, and the remaining \\(n-L\\) participants from the second sub-population. So, the number of distinguishable teams is:\n\\[\\begin{align*}\n\\sum_{L=0}^{n}{n \\choose L}{n \\choose n - L} = \\sum_{L=0}^{n} {n \\choose L}^2\n\\end{align*}\\]\nSo, we have the combinatorial identity:\n\\[\\begin{align*}\n\\sum_{L=0}^{n} {n \\choose L}^2 = {2n \\choose n}\n\\end{align*}\\]\nThus,\n\\[\\begin{align*}\nu_{2n} &=\\frac{1}{4^{2n}} {2n \\choose n}\\sum_{L=0}^n {n \\choose L}^2\\\\\n&= \\left(\\frac{1}{2^{2n}} {2n \\choose n}\\right)^2\n\\end{align*}\\]\nSo, we have that, it is just the square of the result from \\(\\mathbb{Z}^1\\), so we see in this case that:\n\\[\\begin{align*}\nu_{2n} &\\approx \\sum_{n=0}^{\\infty} \\frac{1}{\\pi n}\n\\end{align*}\\]\nAnd the series on the right certainly diverges, so we see that a simple random walk in \\(\\mathbb{Z}^2\\) is recurrent as \\(E\\) diverges.\n\n\n\nAs before, in order to have a walk return to the origin we must have equal steps in the positive and negative directions for each direction and each path of \\(2n\\) has a probability of occurring of \\(\\frac{1}{6^{2n}}\\). Then, extending the idea from the previous subsection, the number of paths (of total length \\(2n\\)) with \\(L\\) steps left and right, \\(U\\) steps up and down and \\(n - L - U\\) steps forward and backward is:\n\\[\\begin{align*}\n\\frac{(2n)!}{L! L! U! U! (n - L - U)! (n - L - U)!}\n\\end{align*}\\]\nSo, we get:\n\\[\n\\begin{align*}\nu_{2n} &= \\frac{1}{6^{2n}} \\sum_{L,U,L+U \\leq n} \\frac{(2n)!}{L! L! U! U! (n - L - U)! (n - L - U)!} \\\\\n&= \\frac{1}{2^{2n}} {2n \\choose n} \\sum_{L,U,L+U \\leq n} \\left(\\frac{1}{3^n}\\frac{n!}{L! U! (n - U - L)!}\\right)^2\n\\end{align*}\n\\tag{3}\\]\nConsider a \\(3\\)-sided fair coin, with \\(\\mathbb{P}\\{\\text{Heads}\\} = \\mathbb{P}\\{\\text{Tails}\\} = \\mathbb{P}\\{\\text{Edge}\\} = \\frac{1}{3}\\). Suppose that the coin is tossed \\(n=3^2 = 9\\) times. The probability of landing \\(L\\) heads, \\(U\\) tails and \\(n - L - U\\) edges is \\(\\frac{n!}{L!U!(n-L-U)!} \\frac{1}{3^n}\\). This is precisely the term seen in the above expression. The number of heads, tails and edges in \\(n\\) coin tosses follows a multinomial distribution. It can be easily demonstrated, that in, \\(n/3 = 3\\) heads, \\(n/3\\) tails and \\(n/3\\) edges are most likely to occur in \\(n\\) coin tosses. So, we can find an upper bound on the summand in Equation 3 as:\n\\[\\begin{align*}\n\\frac{n!}{3^n L! U! (n- L - U)!} \\leq \\frac{n!}{3^n \\lfloor\\frac{n}{3}\\rfloor! \\lfloor\\frac{n}{3}\\rfloor! \\lfloor\\frac{n}{3}\\rfloor!}\n\\end{align*}\\]\nAlso, from the multinomial expansion theorem:\n\\[\\begin{align*}\n(1 + a + b)^n = \\sum_{L,U,L+U\\leq n} \\frac{n!}{L! U! (n-L-U)!} a^L b^U\n\\end{align*}\\]\nSetting \\(a = b = 1\\), we get:\n\\[\\begin{align*}\n\\sum_{L,U,L+U\\leq n} \\frac{n!}{3^n L! U! (n-L-U)!} a^L b^U = 1\n\\end{align*}\\]\nWe then see that:\n\\[\\begin{align*}\nu_{2n} \\leq \\frac{1}{2^{2n}} {2n \\choose n} \\frac{n!}{3^n \\lfloor\\frac{n}{3}\\rfloor! \\lfloor\\frac{n}{3}\\rfloor! \\lfloor\\frac{n}{3}\\rfloor!}\n\\end{align*}\\]\nWe can simplify this as:\n\\[\\begin{align*}\nu_{2n} &= \\frac{1}{2^{2n}}{2n \\choose n} \\frac{n!}{3^n \\left(\\lfloor\\frac{n}{3}\\rfloor!\\right)^3} \\\\\n&\\approx \\frac{1}{\\sqrt{\\pi n}} \\times \\frac{\\sqrt{2\\pi n} e^{-n} n^n}{3^n \\left\\{\\sqrt{2\\pi \\frac{n}{3}}e^{-n/3} \\left(\\frac{n}{3}\\right)^{n/3}\\right\\}^3}\\\\\n&= \\frac{1}{\\sqrt{\\pi n}} \\frac{\\sqrt{2\\pi n} e^{-n} n^n}{3^n \\frac{(2\\pi n)^{3/2}}{3^{3/2}} e^{-n} \\frac{n^n}{3^n}}\\\\\n&= \\frac{1}{\\sqrt{\\pi n}} \\frac{\\sqrt{2\\pi n} \\cancel{e^{-n}} \\cancel{n^n}}{\\cancel{3^n} \\frac{(2\\pi n)^{3/2}}{3^{3/2}} \\cancel{e^{-n}} \\frac{ \\cancel{n^n}}{\\cancel{3^n}}}\\\\\n&\\approx \\frac{M}{(\\pi n)^{3/2}}\n\\end{align*}\\]\nwhere \\(M\\) is a positive constant. We then see:\n\\[\\begin{align*}\n\\sum_n u_{2n} &= M \\sum_n \\frac{1}{n^{\\frac{3}{2}}}\n\\end{align*}\\]\nThe sum on the right hand side converges, so we have that a simple random walk in three dimensions is transient. The proof of Polya’s Random Walk Theorem is complete."
  },
  {
    "objectID": "posts/multivariate_ito_calculus/index.html#recurrence-and-transience-of-brownian-motion",
    "href": "posts/multivariate_ito_calculus/index.html#recurrence-and-transience-of-brownian-motion",
    "title": "Multivariate Ito Calculus",
    "section": "",
    "text": "In one dimension, we established that every path of a Brownian motion reaches any level \\(a \\in \\mathbf{R}\\). More precisely, for \\(a &gt; 0\\), if we define the stopping time :\n\\[\\begin{align*}\n\\tau = \\min \\{ t \\geq 0 : B_t \\geq a\\}\n\\end{align*}\\]\nwe have \\(\\mathbb{P}\\{\\tau_a &lt; \\infty \\} = 1\\). This implies in particular that every path will come back to \\(0\\) and will do infinitely many times. This is because \\(B(t+\\tau) - B(t)\\) is a standard brownian motion. This property of Brownian motion is called recurrence. This is to be compared with Brownian motion with a drift. In our analysis, we found that, if the drift is negative, then there are paths that will not reach a given level \\(a &gt; 0\\) with positive probability. Such paths go to infinity without ever going back to \\(0\\). This property of the process is called transience.\nWe can derive similar properties for the multidimensional Brownian motion. We will rely heavily on Corollary 1 and on some knowledge of harmonic functions. Harmonic functions play a very important role in mathematics, physics and in nature in general. As we mentioned earlier, if \\(d = 1\\), the only harmonic functions are the linear functions, since the equation \\(f''(x) = 0\\) has the solutions \\(f(x)=ax+b\\). However, in higher dimensions, the collection of harmonic functions is very rich. This gives access to a plethora of Brownian martingales. For example, the following functions are harmonic in the whole space minus the origin, \\(\\mathbf{R}^d \\setminus \\{0\\}\\).\n\\[\nh(x) = \\begin{cases}\n\\log ||x||, & d = 2 \\\\\n||x||^{2 - d}, & d \\geq 3\n\\end{cases}\n\\tag{4}\\]\nwhere \\(x\\in\\mathbf{R}^d\\).\n\nProof. Consider\n\\[\\begin{align*}\nf(x_1,x_2) = \\log \\sqrt {x_1^2 + x_2^2}\n\\end{align*}\\]\nWe have:\n\\[\\begin{align*}\n\\frac{\\partial f}{\\partial x_1} &= \\frac{1}{\\sqrt{x_1^2 + x_2^2}} \\cdot \\frac{\\partial }{\\partial x_1} (\\sqrt{x_1^2 + x_2^2})\\\\\n&=\\frac{1}{\\sqrt{x_1^2 + x_2^2}} \\cdot \\frac{x_1}{\\sqrt{x_1^2 + x_2^2}}\\\\\n&= \\frac{x_1}{x_1^2 + x_2^2}\n\\end{align*}\\]\nFurther,\n\\[\\begin{align*}\n\\frac{\\partial^2 f}{\\partial x_1^2} &= \\frac{(x_1^2 + x_2^2)(1) - x_1(2x_1)}{(x_1^2 + x_2^2)^2} \\\\\n&= \\frac{x_1^2 - x_2^2}{(x_1^2 + x_2^2)}\n\\end{align*}\\]\nBy symmetry,\n\\[\\begin{align*}\n\\frac{\\partial^2 f}{\\partial x_2^2}\n&= \\frac{x_2^2 - x_1^2}{(x_1^2 + x_2^2)}\n\\end{align*}\\]\nSo,\n\\[\\begin{align*}\n\\frac{\\partial^2 f}{\\partial x_1^2} &= - \\frac{\\partial^2 f}{\\partial x_2^2}\\\\\n\\frac{\\partial^2 f}{\\partial x_1^2} + \\frac{\\partial^2 f}{\\partial x_2^2}&=0\n\\end{align*}\\]\nWe conclude that \\(f\\) is harmonic.\nNext, consider\n\\[\\begin{align*}\ng(x_1,x_2,\\ldots,x_d) = \\frac{1}{\\left(\\sqrt{x_1^2 + x_2^2 + \\ldots + x_d^2}\\right)^{d-2}}\n\\end{align*}\\]\nNow,\n\\[\\begin{align*}\n\\frac{\\partial g}{\\partial x_i} &= \\frac{(2-d)}{\\left(\\sqrt{x_1^2 + x_2^2 + \\ldots + x_d^2}\\right)^{d-1}} \\cdot \\frac{\\partial }{\\partial x_i}\\left(\\sqrt{x_1^2 + x_2^2 + \\ldots + x_d^2}\\right)\\\\\n&= \\frac{(2-d)}{\\left(\\sqrt{x_1^2 + x_2^2 + \\ldots + x_d^2}\\right)^{d-1}}\\cdot \\frac{2x_i}{2\\left(\\sqrt{x_1^2 + x_2^2 + \\ldots + x_d^2}\\right)}\\\\\n&= \\frac{(2-d)x_i}{\\left(\\sqrt{x_1^2 + x_2^2 + \\ldots + x_d^2}\\right)^d}\n\\end{align*}\\]\nFurther, we have:\n\\[\\begin{align*}\n\\frac{\\partial^2 g}{\\partial x_i^2} &= (2-d)\\frac{\\left(\\sqrt{x_1^2 + x_2^2 + \\ldots + x_d^2}\\right)^d (1) - (x_i)\\cdot d \\cdot\\left(\\sqrt{x_1^2 + x_2^2 + \\ldots + x_d^2}\\right)^{d-1}\\cdot \\frac{x_i}{\\left(\\sqrt{x_1^2 + x_2^2 + \\ldots + x_d^2}\\right)}}{\\left(\\sqrt{x_1^2 + x_2^2 + \\ldots + x_d^2}\\right)^{2d}}\\\\\n&=(2-d)\\left(\\sqrt{x_1^2 + x_2^2 + \\ldots + x_d^2}\\right)^{d-2} \\frac{\\left(\\sqrt{x_1^2 + x_2^2 + \\ldots + x_d^2}\\right)^2  - d x_i^2}{\\left(\\sqrt{x_1^2 + x_2^2 + \\ldots + x_d^2}\\right)^{2d}}\\\\\n&=(2-d) \\frac{\\left(\\sum_{i=1}^d x_i^2\\right) - dx_i^2 }{||x||^{d+2}}\n\\end{align*}\\]\nWe conclude that:\n\\[\\begin{align*}\n\\sum_{i=1}^{d} \\frac{\\partial^2 g}{\\partial x_i^2} = 0\n\\end{align*}\\]\nand hence \\(g\\) is harmonic.\n\nInterestingly enough, the answer to the recurrence versus transience puzzle depends on the dimension. We will show that Brownian motion is recurrent in dimension \\(d=2\\) in the sense that every Brownian motion path starting from \\(x\\) will eventually enter a disc around the origin, no matter how small the disc is. The Brownian path will then enter this disc infinitely many times, as \\(t \\to \\infty\\). Note that, we did not say that the path actually hits \\(0\\), but that it enters a disc around the \\(0\\). This nuance is important, as we will in fact show that a Brownian path actually never hits a given point. In dimension \\(d=3\\) or higher, it is proved that there are some paths starting from a given \\(x\\) that will never enter a given ball around the origin with positive probability. This is the transience property.\nThe strategy of the proof is similar to the approach for Brownian motion with a drift. We will find a good function \\(h : \\mathbf{R}^d \\to \\mathbf{R}\\) for which \\(h(B_t)\\) is a martingale. In light of Corollary 1, this function needs to be harmonic in a suitable region. The desired probability is then obtained by considering the right boundary values.\n\nTheorem 3 (Recurrence and transience of a brownian motion in \\(\\mathbf{R}^d\\)) Let \\((B_t,t\\geq 0)\\) be a Brownian motion in \\(\\mathbf{R}^d\\) starting at \\(B_0 = x\\). Consider for \\(r &lt; ||x||\\), the stopping time\n\\[\\begin{align*}\n\\tau_r = \\min \\{t \\geq 0 : ||B_t|| &lt; r\\}\n\\end{align*}\\]\nthe first hitting time of the paths in a ball of radius \\(r\\) around the origin. We have:\n\\[\\begin{align*}\n\\mathbb{P}(\\tau_r &lt; \\infty) =\n\\begin{cases}\n1 & \\text{ if }d \\leq 2 \\\\\n\\left(\\frac{r}{||x||}\\right)^{d-2} & \\text{ if }d \\geq 3\n\\end{cases}\n\\end{align*}\\]\nIn particular, for \\(d \\leq 2\\), the paths are recurrent; that is, they come back infinitely many times in a neighbourhood of the origin. For \\(d \\geq 3\\), each path will eventually never come back to a neighbourhood of the origin.\n\nNote that we made sure that the starting point of the Brownian motion \\(x\\) is outside the ball of radius \\(r\\).\n\nProof. Consider another hitting time of a ball with a radius larger than \\(||x||\\):\n\\[\\begin{align*}\n\\tau_R' = \\min \\{t \\geq 0 : ||B_t|| \\geq R\\}, \\quad r &lt; ||x|| &lt; R\n\\end{align*}\\]\nNote that \\(\\tau_R'\\) must increase with \\(R\\) and that it must go to \\(+\\infty\\) as \\(R \\to \\infty\\). Moreover, the sequence of events \\(\\{\\tau_r &lt; \\tau_R'\\}_{R &gt; ||x||}\\) is increasing. In particular, by continuity of probability measure, we have:\n\\[\\begin{align*}\n\\lim_{R \\to \\infty} \\mathbb{P}(\\tau_r &lt; \\tau_R') &= \\mathbb{P}(\\lim_{R \\to \\infty} \\tau_r &lt; \\tau_R')\\\\\n&= \\mathbb{P}(\\tau_r &lt; \\infty)\n\\end{align*}\\]\nIf we set \\(\\tau = \\tau_r \\land \\tau_R'\\), then the event \\(\\{\\tau_r &lt; \\tau_R'\\}\\) is the same as the event \\(\\{||B_\\tau||=r\\}\\). So, \\(\\lim_{R \\to \\infty} \\mathbb{P}(\\tau_r &lt; \\tau_R') = \\lim_{R \\to \\infty} \\mathbb{P}(||B_\\tau||=r)\\).\nNow, consider the event \\(\\{\\tau &lt; \\infty\\}\\). Let \\(E_n\\) be the event that the \\(n\\)th increment \\(||B_n - B_{n-1}||\\) exceeds \\(R\\). If \\(E_n\\) occurs, then we must have the Brownian motion exits the spherical shell of thickness \\(R-r\\). Moreover, we have \\(\\mathbb{P}(E_1) = \\ldots = \\mathbb{P}(E_n)\\), for all \\(n\\). Call this probability \\(p\\). Clearly, \\(0 &lt; p &lt; 1\\). Since the events \\(E_n\\) are independent, we have:\n\\[\\begin{align*}\n\\mathbb{P}(E_1^C \\cap \\ldots \\cap E_n^C) = (1 - p)^n\n\\end{align*}\\]\nAs \\(n \\to \\infty\\), we have \\(\\lim_{n \\to \\infty} \\mathbb{P}(\\bigcap_{k=1}^{n}E_k^C) = 0\\). Now, let \\(F_k\\) be the event that there are no excursions upto \\(k\\). That is, \\(F_k = \\bigcap_{i=1}^{k}E_i^C\\). Now, the event \\(F_{k+1}\\) implies \\(F_k\\), or equivalently, \\(F_{k+1} \\subseteq F_k\\). So, \\(\\{F_k\\}_{k=1}^{\\infty}\\) is a decreasing sequence of events. Moreover, \\(\\bigcap_{k=1}^n F_k = \\bigcap_{k=1}^n E_k^C\\). So, by continuity of probability measure,\n\\[\\begin{align*}\n\\lim_{n \\to \\infty} \\mathbb{P}(\\bigcap_{k=1}^{n}E_k^C)\n&= \\lim_{n \\to \\infty} \\mathbb{P}(\\bigcap_{k=1}^{n}F_k) \\\\\n&= \\mathbb{P}(\\lim_{n \\to \\infty} \\bigcap_{k=1}^{n}F_k) \\\\\n&= \\mathbb{P}(\\bigcap_{k=1}^{\\infty}F_k) \\\\\n&= \\mathbb{P}(\\bigcap_{k=1}^{\\infty}E_k^C)\n\\end{align*}\\]\nSo, \\(\\mathbb{P}(\\bigcup_{k=1}^{\\infty}E_k) = 1\\). There exists an \\(n_0 \\in \\mathbf{N}\\), such that the event \\(E_{n_0}\\), an excursion at \\(n_0\\) occurs with probability \\(1\\). So, the event \\(\\{\\tau &lt; \\infty\\}\\) occurs almost surely.\nTo compute \\(\\mathbb{P}(||B_\\tau||=r)\\), the idea is to find a good function \\(h\\) with the following properties:\n\nMartingale: \\((h(B_t),t\\leq \\tau)\\) is a bounded martingale, so that the optional stopping theorem implies:\n\n\\[\\begin{align*}\n\\mathbb{E}[h(B_\\tau)] = h(B_0) = h(x)\n\\end{align*}\\]\n\nBoundary values: Since \\(B_\\tau\\) is a point at \\(||x||=r\\) or at \\(||x||=R\\), we pick boundary conditions for \\(h\\), so that \\(\\mathbb{E}[h(B_{\\tau})]=\\mathbb{P}(||B_\\tau||=r)\\).\n\nThe second point is easy; it suffices to take the boundary conditions \\(h(x)=0\\) at \\(||x||=R\\) and \\(h(x)=1\\) at \\(||x||=r\\). For the first point, by Ito’s formula, we pick \\(h\\) to be harmonic in the annulus \\(\\{x \\in \\mathbf{R}^d : r &lt; ||x||&lt;R \\}\\). Thus, we can use the function in Equation 4. Of course, the functions \\(ah(x) + b\\) remain harmonic. To satisfy the boundary conditions, we pick \\(a\\) and \\(b\\) suitably:\n\n\nLet \\(h(x) = ax + b\\). Then, at \\(x=r\\), we have:\n\\[\n\\begin{align*}\nar + b = 1\n\\end{align*}\n\\tag{5}\\]\nand at \\(x = R\\), we have:\n\\[\n\\begin{align*}\naR + b = 0\n\\end{align*}\n\\tag{6}\\]\nSo, \\(b = -aR\\). Substituting in Equation 5, we get:\n\\[\\begin{align*}\na &= \\frac{1}{r - R}\nb &= -\\frac{R}{r - R}\n\\end{align*}\\]\nConsequently,\n\\[\n\\begin{align*}\nh(x) &= \\frac{R - x}{R - r}\n\\end{align*}\n\\tag{7}\\]\n\n\n\nLet \\(h(x) = \\log ||x||\\). Then, at \\(||x||=r\\), we have:\n\\[\n\\begin{align*}\na \\log ||x|| + b &= 1\na \\log r + b &= 1\n\\end{align*}\n\\tag{8}\\]\nAt \\(||x||=R\\), we have:\n\\[\n\\begin{align*}\na \\log ||x|| + b &= 0\na \\log R + b &= 0\n\\end{align*}\n\\tag{9}\\]\nThus, from Equation 9, \\(b = -a \\log R\\). Substituting the value for \\(b\\) in Equation 8, we have:\n\\[\n\\begin{align*}\na \\log r - a \\log R &= 1\\\\\na &= \\frac{1}{\\log r - \\log R}\n\\end{align*}\n\\]\nConsequently,\n\\[\n\\begin{align*}\nh(x) &= \\frac{\\log ||x||}{\\log r - \\log R} -  \\frac{1}{\\log r - \\log R} \\log R\\\\\n&= \\frac{\\log R - \\log ||x||}{\\log R - \\log r}\n\\end{align*}\n\\tag{10}\\]\n\n\n\nLet \\(h(x)=||x||^{2-d}\\). At \\(||x||=r\\), \\(a h(x) + b = 1\\). So, we have:\n\\[\n\\begin{align*}\na r^{2-d} + b = 1\n\\end{align*}\n\\tag{11}\\]\nAt \\(||x||=R\\), \\(ah(x) + b = 0\\). So, we have:\n\\[\n\\begin{align*}\na ||R||^{2-d} + b &= 0\n\\end{align*}\n\\tag{12}\\]\nFrom Equation 12, we get \\(b = -a R^{2-d}\\). Substituting this value in Equation 11, we get:\n\\[\\begin{align*}\na r^{2-d} - aR^{2-d}  &= 1\\\\\na &= \\frac{1}{r^{2-d} - R^{2-d}}\n\\end{align*}\\]\nAnd\n\\[\n\\begin{align*}\nb = - \\frac{R^{2-d}}{r^{2-d} - R^{2-d}}\n\\end{align*}\n\\]\nThus,\n\\[\n\\begin{align*}\nh(x) &= \\frac{||x||^{2-d}}{r^{2-d} - R^{2-d}} - \\frac{R^{2-d}}{r^{2-d} - R^{2-d}}\\\\\n&= \\frac{R^{2-d} - ||x||}{R^{2-d} - r^{2-d}}\n\\end{align*}\n\\tag{13}\\]\nCollecting all the results together, we get:\n\\[\nh(x) = \\begin{cases}\n\\frac{R - x}{R - r}, & d=1 \\\\\n\\frac{\\log R - \\log ||x||}{\\log R - \\log r}, & d=2 \\\\\n\\frac{R^{2-d} - ||x||^{2-d}}{R^{2-d} - r^{2-d}}, & d \\geq 3\n\\end{cases}\n\\tag{14}\\]\nPassing to the limit as \\(R \\to \\infty\\), for \\(d=1\\), we have:\n\\[\\begin{align*}\n\\lim_{R \\to \\infty} h(x) &= \\lim_{R \\to \\infty} \\frac{R - x}{R - r} \\\\\n&= \\lim_{R \\to \\infty} \\frac{1 - \\frac{x}{R}}{1 - \\frac{r}{R}}\\\\\n&= 1\n\\end{align*}\\]\nFor \\(d = 2\\), we get:\n\\[\\begin{align*}\n\\lim_{R \\to \\infty} h(x) &= \\lim_{R \\to \\infty} \\frac{1 - \\frac{\\log x}{\\log R}}{1 - \\frac{\\log r}{\\log R}} \\\\\n&= 1\n\\end{align*}\\]\nFor \\(d = 3\\), we get:\n\\[\\begin{align*}\n\\lim_{R \\to \\infty}  h(x) &= \\lim_{R \\to \\infty} \\frac{R^{2-d} - ||x||^{2-d}}{R^{2-d} - r^{2-d}}\\\\\n&= \\left(\\frac{||x||}{r}\\right)^{2-d}\n\\end{align*}\\]\nThis concludes the proof. \\(\\blacksquare\\)\n\n\n\nExample 4 We get more from the above proof. Indeed, in dimension \\(d \\geq 2\\), it implies that the probability that a Brownian motion starting at \\(B_0 = x\\) eventually hits any other point \\(y\\) is \\(0\\). Indeed, if we take \\(y = 0\\) and \\(x \\neq 0\\), we have:\n\\[\n\\begin{align*}\n\\mathbb{P}(\\exists t &gt; 0: B_t = 0) &= \\lim_{R \\to \\infty} \\lim_{r \\to \\infty} \\mathbb{P}(\\tau_r &lt; \\tau_R')\\\\\n&= \\lim_{R \\to \\infty} \\lim_{r \\to \\infty} \\frac{R^{2-d} - ||x||^{2-d}}{R^{2-d} - r^{2-d}}\\\\\n&=\\lim_{R \\to \\infty}  \\lim_{r \\to \\infty} \\frac{(R/r)^{2-d} - (||x||/r)^{2-d}}{(R/r)^{2-d} - 1}\\\\\n&= \\lim_{R \\to \\infty} 0\\\\\n&= 0\n\\end{align*}\n\\]\nHere, we shrink the inner radius to \\(0\\) first and then we let the outer radius go to infinity after. It remains to take the limits of the expression obtained in equation Equation 14. The first limit \\(r \\to 0\\) gives \\(0\\) right away."
  },
  {
    "objectID": "posts/multivariate_ito_calculus/index.html#dynkins-formula-and-the-dirichlet-problem",
    "href": "posts/multivariate_ito_calculus/index.html#dynkins-formula-and-the-dirichlet-problem",
    "title": "Multivariate Ito Calculus",
    "section": "",
    "text": "In the last section, we translated the problem of recurrence and transience of Brownian motion in terms of a boundary value problem: we needed to find a particular function \\(h\\) that solves a PDE (that is, \\(\\nabla^2 h=0\\)) in a certain region of space(the annulus) and that satisfies given boundary conditions (the function is \\(1\\) on the inner circle and \\(0\\) on the outer circle). This is a particular case of the Dirichlet problem in PDE.\nConsider a region \\(\\mathcal{O} \\subset \\mathbb{R}^d\\). \\(\\mathcal{O}\\) is an open ball. That is, for all \\(x \\in \\mathcal{O}\\), there exists \\(\\epsilon&gt;0\\), such that \\(V_\\epsilon(x) = \\{y : ||y - x|| &lt; \\epsilon\\}\\) is contained in \\(\\mathcal{O}\\). \\(\\mathcal{O}\\) doesn’t contain boundary points \\(\\partial \\mathcal{O}\\). In the proof of Theorem 3, the region was the annulus \\(\\{x: r &lt; ||x|| &lt; R\\}\\) and the boundary was given by the spheres \\(\\{x :||x|| = r\\}\\) and \\(\\{x: ||x||=R\\}\\). The Dirichlet problem in \\(\\mathcal{O}\\) can be stated as follows:\nLet \\(f:\\partial\\mathcal{O} \\to \\mathbb{R}\\) be a function on the boundary of \\(\\mathcal{O}\\). Can we extend the function \\(f\\) to \\(O\\) in such a way that the extension is harmonic on \\(\\mathcal{O}\\) and coincides with \\(f\\) on the boundary?\nIn the instance of the proof of the Theorem 3, we knew the solution of the problem, thanks to Equation 4. The only job left to do was to adjust some parameters to fit the boundary conditions. It turns out that the formalism of stochastic calculus allows us to express the solution of the Dirichlet problem as an average over Brownian paths for general regions of space and boundary conditions. To do so, we look at a twist on the Ito’s formula called the Dynkin’s formula.\nLet \\(x\\) be a point in \\(\\mathcal{O}\\). Consider a Brownian motion \\((B_t,t\\geq 0)\\) starting at \\(x\\), \\(B_0 = x\\). To emphasize the dependence on \\(x\\), we write \\(\\mathbb{P}_x\\) and \\(\\mathbb{E}_x\\) for the probability and the expectation for the Brownian motion. Dykin’s formula is obtained by merging Corollary 1 for the Brownian martingales together with the optional stopping theorem. More precisely, consider \\(f \\in C^2(\\mathbb{R}^d)\\) that satisfies the assumption of the Corollary 1. We then have that the process:\n\\[\\begin{align*}\nM_t &= f(B_t) - \\frac{1}{2}\\int_{0}^t \\nabla^2 f(B_s) ds, \\quad t \\geq 0\n\\end{align*}\\]\nis a Brownian martingale.\nConsider also the stopping time \\(\\tau = \\min \\{t \\geq 0 : B_t \\in \\mathcal{O}^C\\}\\). This is the first exit time of \\(\\mathcal{O}\\) of the Brownian motion path. Then, if the assumptions of the optional stopping theorem are fulfilled, we get Dynkin’s formula:\n\\[\n\\begin{align*}\n\\mathbb{E}[M_\\tau] = \\mathbb{E}[f(B_\\tau)] - \\frac{1}{2} \\mathbb{E}\\left[\\int_0^\\tau \\nabla^2 f(B_s)ds\\right] = f(B_0) = M_0\n\\end{align*}\n\\tag{15}\\]\nAs an application of Dynkin’s formula, let’s express the solution of the Dirichlet problem as an average over Brownian motion. If \\(f\\) is harmonic in \\(\\mathcal{O}\\), then \\(\\nabla^2 f = 0\\) in \\(\\mathcal{O}\\), so the process \\((f(B_t),t\\leq \\tau)\\) is itself a martingale. Note that since \\(\\mathcal{O}\\) is bounded, this is a bounded martingale! Moreover, the integrands \\(\\partial_i f(B_s)\\), \\(1 \\leq i \\leq d\\), are bounded. We conclude that the solution to the Dirichlet problem can be represented as follows:\n\\[\n\\begin{align*}\nf(x) = \\mathbb{E}_x[f(B_\\tau)], \\quad x \\in \\mathcal{O}\n\\end{align*}\n\\tag{16}\\]\nIn other words, the value of the harmonic function of \\(f\\) at \\(x\\) is given by the average over the Brownian paths of the value of the function at the exit point of the path on the boundary of \\(\\mathcal{O}\\). Equation Equation 16 does not prove the existence of the solution to the Dirichlet problem, as we assume that such a function exists. Existence of the solution to the Dirichlet problem can be shown this way, assuming the region \\(\\mathcal{O}\\) and the function on the boundary are nice enough. However, note that the averaging on the right-hand side of the formula makes sense even in the case where \\(f\\) is simply defined on the boundary \\(\\partial \\mathcal{O}\\). We then define a posteriori the harmonic extension of \\(f\\) inside \\(\\mathcal{O}\\) by defining its value at \\(x\\) as \\(\\mathbb{E}_x[f(B_\\tau)]\\)."
  },
  {
    "objectID": "posts/multivariate_ito_calculus/index.html#exercises",
    "href": "posts/multivariate_ito_calculus/index.html#exercises",
    "title": "Multivariate Ito Calculus",
    "section": "",
    "text": "Exercise 1 Gaussian Integration by parts.\n\nLet \\(Z\\) be a standard Gaussian random variable. Show using integration by parts that for a differentiable function \\(g\\):\n\n\\[\n\\begin{align*}\n\\mathbb{E}[Z g(Z)] = \\mathbb{E}[g'(Z)]\n\\end{align*}\n\\tag{17}\\]\nwhere we assume that both expectations are well-defined.\n\nUse this to recover the expression for the moments for \\(\\mathbb{E}[Z^{2j}],j \\in \\mathbb{N}\\).\n\n\nSolution.\nWe have:\n\\[\n\\begin{align*}\n\\mathbb{E}[g'(Z)] &= \\int_{-\\infty}^{\\infty}\\phi(z) \\cdot g'(z) dz \\\\\n&= \\left[\\frac{e^{-z^2/2}}{\\sqrt{2\\pi}}\\cdot g(z)\\right]_{-\\infty}^{\\infty} - \\int_{-\\infty}^{\\infty} g(z) \\frac{-ze^{-z^2/2}}{\\sqrt{2\\pi}}dz \\\\\n&= 0 + \\int_{-\\infty}^{\\infty} z g(z) \\phi(z)dz\\\\\n&= \\mathbb{E}[Zg(Z)]\n\\end{align*}\n\\]\nMoreover, we can write:\n\\[\n\\begin{align*}\n\\mathbb{E}[Z^{2n}] &= \\mathbb{E}[Z \\cdot Z^{2n-1}] \\\\\n&= \\mathbb{E}[Z \\cdot g(Z)], \\quad \\{ \\text{ where }g(x)=x^{2n - 1}\\} \\\\\n&= \\mathbb{E}[g'(Z)] \\\\\n&= (2n - 1) \\mathbb{E}[Z^{(2n - 2)}] \\\\\n& \\vdots \\\\\n&= (2n - 1)\\cdots 5 \\cdot 3 \\cdot \\mathbb{E}[Z^2] \\\\\n&= (2n - 1)\\cdots 5 \\cdot 3 \\cdot 1\n\\end{align*}\n\\]\n\nExercise 2 The Heat Equation.\nUse the Gaussian integration by parts identity to check that the solution \\(f(t,x)\\) to the heat equation is:"
  },
  {
    "objectID": "posts/numerical-integration/index.html",
    "href": "posts/numerical-integration/index.html",
    "title": "Numerical Integration",
    "section": "",
    "text": "We are interested in an approximate calculation of the definite integral\n\\[\n\\begin{align*}\nI[f] = \\int_{a}^{b}f(x)dx\n\\end{align*}\n\\tag{1}\\]\nwhere \\(f(x)\\) is a given function and \\([a,b]\\) is a finite interval. This problem is often called numerical quadrature, since it relates to the ancient problem of the quadrature of a circle i.e. constructing a square with equal area to that of a circle. The computation of the above quantity is equivalent to solving the IVP:\n\\[\n\\begin{align*}\ny'(x) = f(x), \\quad y(a)=0, \\quad x \\in[a,b]\n\\end{align*}\n\\tag{2}\\]\nfor \\(y(b)=I[f]\\).\nAs is well known, even many relatively simple integrals cannot be expressed in finite terms of elementary functions, and thus must be evaluated by numerical methods. Even when a closed form analytical solution exists, it may be preferable to use a numerical quadrature formula.\nSince \\(I[f]\\) is a linear functional, numerical integration is a special case of the problem of approximating a linear functional. We shall consider formulas of the form:\n\\[\n\\begin{align*}\nI[f] \\approx \\sum_{i=1}^n w_if(x_i)\n\\end{align*}\n\\tag{3}\\]\nwhere \\(x_1 &lt; x_2 &lt; \\ldots &lt; x_n\\) are distinct nodes and \\(w_1\\), \\(w_2\\), \\(\\ldots\\), \\(w_n\\) the corresponding weights. Often (but not always) all nodes lie in \\([a,b]\\).\n\nDefinition 1 (Order of accuracy of a Quadrature Rule) A quadrature rule (Equation 3) has order of accuracy (or degree of exactness) equal to \\(d\\), iff it is exact for all polynomials of degree \\(\\leq d\\), that is, for all \\(p\\in\\mathcal{P}_{d+1}\\).\n\n\n\n\nInterpolatory quadrature formulas, where the nodes are constrained to be equally spaced, are called Newton-Cotes formulas. These are especially suited for integrating a tabulated function, a task that was more common before the computer age. The midpoint, the trapezoidal and the Simpson’s rules, to be described here, are all special cases of (unweighted) Newton-Cotes formulas.\nThe trapezoidal rule is based on the linear interpolation of \\(f(x)\\) at \\(x_1 = a\\) and \\(x_2 = b\\), that is, \\(f(x)\\) is approximated by :\n\\[\n\\begin{align*}\np(x) = f(a) + (x-a)[a,b]f = f(a) + (x - a)\\frac{f(b) - f(a)}{b - a}\n\\end{align*}\n\\]\nThe integral of \\(p(x)\\) equals the area of a trapezoid with base \\((b-a)\\) times the average height \\(\\frac{1}{2}(f(a) + f(b))\\). Hence,\n\\[\n\\int_{a}^{b} f(x)dx \\approx \\frac{(b-a)}{2}(f(a) + f(b))\n\\]\nTo increase the accuracy, we subdivide the interval \\([a,b]\\) and assume that \\(f_i = f(x_i)\\) is known on a grid of equidistant points:\n\\[\n\\begin{align*}\nx_0 = a, \\quad x_i = x_0 + ih, \\quad x_n = b\n\\end{align*}\n\\tag{4}\\]\nwhere \\(h = (b - a)/n\\) is the step length. The trapezoidal approximation for the \\(i\\)th subinterval is:\n\\[\n\\begin{align*}\n\\int_{x_i}^{x_{i+1}} f(x)dx = T(h) + R_i, \\quad T(h) = \\frac{h}{2}(f_i + f_{i+1})\n\\end{align*}\n\\tag{5}\\]\nLet \\(p_2(x)\\in\\mathcal{P}_2\\) be the unique interpolating polynomial (Newton polynomial) passing through the points \\((x_i,f_i)\\) and \\((x_{i+1},f_{i+1})\\), that is, \\(p_2(x_i)=f(x_i)\\) and \\(p_2(x_{i+1}) = f(x_{i+1})\\). The exact remainder in Newton’s interpolation formula is given by:\n\\[\n\\begin{align*}\nf(x) - p_2(x) &= [x_i,x_{i+1},x]f\\cdot \\Phi_2(x)\\\\\n&=[x_i,x_{i+1},x]f \\cdot (x - x_{i+1})\\Phi_1(x)\\\\\n&=[x_i,x_{i+1},x]f \\cdot (x - x_{i+1})(x - x_{i})\\Phi_0\\\\\n&=[x_i,x_{i+1},x]f \\cdot (x - x_{i+1})(x - x_{i})\n\\end{align*}\n\\]\nSo, we have:\n\\[\n\\begin{align*}\nR_i &= \\int_{x_i}^{x_{i+1}} (f(x) - p_2(x))dx = \\int_{x_i}^{x_{i+1}}(x - x_i)(x - x_{i+1})[x_i,x_{i+1},x]f dx\n\\end{align*}\n\\tag{6}\\]\nBy the theorem on the remainder term for interpolation, we can write:\n\\[\n[x_1,\\ldots,x_n,x_{n+1}]f = \\frac{f^{(n)}(\\xi)}{n!}\n\\]\nConsequently,\n\\[\n[x_i,x_{i+1},x]f = \\frac{f''(\\xi)}{2}\n\\]\nSo, we have:\n\\[\n\\begin{align*}\nR_i &= \\frac{f''(\\xi)}{2}\\int_{x_i}^{x_{i+1}} (x - x_i)(x - x_{i+1})dx\n\\end{align*}\n\\tag{7}\\]\nSetting \\(x = x_i + ht\\), \\(dx = hdt\\) such that the limits of integration are from \\(t=0\\) to \\(t=1\\), $we get:\n\\[\n\\begin{align*}\nR_i &=  \\frac{f''(\\xi)}{2} \\int_{0}^{1}(ht)(x_i + ht - x_{i+1})h dt\\\\\n&= \\frac{f''(\\xi)}{2} \\int_{0}^{1}(ht)(ht - h)h dt\\\\\n&= \\frac{f''(\\xi)}{2} \\int_{0}^{1}(ht)(ht - h)h dt\\\\\n&= \\frac{f''(\\xi) h^3}{2} \\int_{0}^{1}(t^2 - t) dt\\\\\n&= \\frac{f''(\\xi) h^3}{2} \\left[\\frac{t^3}{3} - \\frac{t^2}{2}\\right]_{0}^{1} \\\\\n&= \\frac{f''(\\xi) h^3}{2} \\left[\\frac{1}{3} - \\frac{1}{2}\\right] \\\\\n&= -\\frac{1}{12}h^3 f''(\\xi)\n\\end{align*}\n\\tag{8}\\]\nSumming the contributions for each subinterval \\([x_i,x_{i+1}]\\), \\(i=0...n\\), gives:\n\\[\n\\begin{align*}\n\\int_{a}^{b}f(x)dx = T(h) + R_T, \\quad T(h) = \\frac{h}{2}(f_0 + f_n) + h\\sum_{i=1}^{n-1}f_i\n\\end{align*}\n\\tag{9}\\]\nwhich is the composite trapezoidal rule. The global truncation error is:"
  },
  {
    "objectID": "posts/numerical-integration/index.html#interpolatory-quadrature-rules",
    "href": "posts/numerical-integration/index.html#interpolatory-quadrature-rules",
    "title": "Numerical Integration",
    "section": "",
    "text": "We are interested in an approximate calculation of the definite integral\n\\[\n\\begin{align*}\nI[f] = \\int_{a}^{b}f(x)dx\n\\end{align*}\n\\tag{1}\\]\nwhere \\(f(x)\\) is a given function and \\([a,b]\\) is a finite interval. This problem is often called numerical quadrature, since it relates to the ancient problem of the quadrature of a circle i.e. constructing a square with equal area to that of a circle. The computation of the above quantity is equivalent to solving the IVP:\n\\[\n\\begin{align*}\ny'(x) = f(x), \\quad y(a)=0, \\quad x \\in[a,b]\n\\end{align*}\n\\tag{2}\\]\nfor \\(y(b)=I[f]\\).\nAs is well known, even many relatively simple integrals cannot be expressed in finite terms of elementary functions, and thus must be evaluated by numerical methods. Even when a closed form analytical solution exists, it may be preferable to use a numerical quadrature formula.\nSince \\(I[f]\\) is a linear functional, numerical integration is a special case of the problem of approximating a linear functional. We shall consider formulas of the form:\n\\[\n\\begin{align*}\nI[f] \\approx \\sum_{i=1}^n w_if(x_i)\n\\end{align*}\n\\tag{3}\\]\nwhere \\(x_1 &lt; x_2 &lt; \\ldots &lt; x_n\\) are distinct nodes and \\(w_1\\), \\(w_2\\), \\(\\ldots\\), \\(w_n\\) the corresponding weights. Often (but not always) all nodes lie in \\([a,b]\\).\n\nDefinition 1 (Order of accuracy of a Quadrature Rule) A quadrature rule (Equation 3) has order of accuracy (or degree of exactness) equal to \\(d\\), iff it is exact for all polynomials of degree \\(\\leq d\\), that is, for all \\(p\\in\\mathcal{P}_{d+1}\\).\n\n\n\n\nInterpolatory quadrature formulas, where the nodes are constrained to be equally spaced, are called Newton-Cotes formulas. These are especially suited for integrating a tabulated function, a task that was more common before the computer age. The midpoint, the trapezoidal and the Simpson’s rules, to be described here, are all special cases of (unweighted) Newton-Cotes formulas.\nThe trapezoidal rule is based on the linear interpolation of \\(f(x)\\) at \\(x_1 = a\\) and \\(x_2 = b\\), that is, \\(f(x)\\) is approximated by :\n\\[\n\\begin{align*}\np(x) = f(a) + (x-a)[a,b]f = f(a) + (x - a)\\frac{f(b) - f(a)}{b - a}\n\\end{align*}\n\\]\nThe integral of \\(p(x)\\) equals the area of a trapezoid with base \\((b-a)\\) times the average height \\(\\frac{1}{2}(f(a) + f(b))\\). Hence,\n\\[\n\\int_{a}^{b} f(x)dx \\approx \\frac{(b-a)}{2}(f(a) + f(b))\n\\]\nTo increase the accuracy, we subdivide the interval \\([a,b]\\) and assume that \\(f_i = f(x_i)\\) is known on a grid of equidistant points:\n\\[\n\\begin{align*}\nx_0 = a, \\quad x_i = x_0 + ih, \\quad x_n = b\n\\end{align*}\n\\tag{4}\\]\nwhere \\(h = (b - a)/n\\) is the step length. The trapezoidal approximation for the \\(i\\)th subinterval is:\n\\[\n\\begin{align*}\n\\int_{x_i}^{x_{i+1}} f(x)dx = T(h) + R_i, \\quad T(h) = \\frac{h}{2}(f_i + f_{i+1})\n\\end{align*}\n\\tag{5}\\]\nLet \\(p_2(x)\\in\\mathcal{P}_2\\) be the unique interpolating polynomial (Newton polynomial) passing through the points \\((x_i,f_i)\\) and \\((x_{i+1},f_{i+1})\\), that is, \\(p_2(x_i)=f(x_i)\\) and \\(p_2(x_{i+1}) = f(x_{i+1})\\). The exact remainder in Newton’s interpolation formula is given by:\n\\[\n\\begin{align*}\nf(x) - p_2(x) &= [x_i,x_{i+1},x]f\\cdot \\Phi_2(x)\\\\\n&=[x_i,x_{i+1},x]f \\cdot (x - x_{i+1})\\Phi_1(x)\\\\\n&=[x_i,x_{i+1},x]f \\cdot (x - x_{i+1})(x - x_{i})\\Phi_0\\\\\n&=[x_i,x_{i+1},x]f \\cdot (x - x_{i+1})(x - x_{i})\n\\end{align*}\n\\]\nSo, we have:\n\\[\n\\begin{align*}\nR_i &= \\int_{x_i}^{x_{i+1}} (f(x) - p_2(x))dx = \\int_{x_i}^{x_{i+1}}(x - x_i)(x - x_{i+1})[x_i,x_{i+1},x]f dx\n\\end{align*}\n\\tag{6}\\]\nBy the theorem on the remainder term for interpolation, we can write:\n\\[\n[x_1,\\ldots,x_n,x_{n+1}]f = \\frac{f^{(n)}(\\xi)}{n!}\n\\]\nConsequently,\n\\[\n[x_i,x_{i+1},x]f = \\frac{f''(\\xi)}{2}\n\\]\nSo, we have:\n\\[\n\\begin{align*}\nR_i &= \\frac{f''(\\xi)}{2}\\int_{x_i}^{x_{i+1}} (x - x_i)(x - x_{i+1})dx\n\\end{align*}\n\\tag{7}\\]\nSetting \\(x = x_i + ht\\), \\(dx = hdt\\) such that the limits of integration are from \\(t=0\\) to \\(t=1\\), $we get:\n\\[\n\\begin{align*}\nR_i &=  \\frac{f''(\\xi)}{2} \\int_{0}^{1}(ht)(x_i + ht - x_{i+1})h dt\\\\\n&= \\frac{f''(\\xi)}{2} \\int_{0}^{1}(ht)(ht - h)h dt\\\\\n&= \\frac{f''(\\xi)}{2} \\int_{0}^{1}(ht)(ht - h)h dt\\\\\n&= \\frac{f''(\\xi) h^3}{2} \\int_{0}^{1}(t^2 - t) dt\\\\\n&= \\frac{f''(\\xi) h^3}{2} \\left[\\frac{t^3}{3} - \\frac{t^2}{2}\\right]_{0}^{1} \\\\\n&= \\frac{f''(\\xi) h^3}{2} \\left[\\frac{1}{3} - \\frac{1}{2}\\right] \\\\\n&= -\\frac{1}{12}h^3 f''(\\xi)\n\\end{align*}\n\\tag{8}\\]\nSumming the contributions for each subinterval \\([x_i,x_{i+1}]\\), \\(i=0...n\\), gives:\n\\[\n\\begin{align*}\n\\int_{a}^{b}f(x)dx = T(h) + R_T, \\quad T(h) = \\frac{h}{2}(f_0 + f_n) + h\\sum_{i=1}^{n-1}f_i\n\\end{align*}\n\\tag{9}\\]\nwhich is the composite trapezoidal rule. The global truncation error is:"
  },
  {
    "objectID": "posts/optimization_algorithms/index.html",
    "href": "posts/optimization_algorithms/index.html",
    "title": "Optimization Algorithms",
    "section": "",
    "text": "Definition. Let \\(f:\\mathbf{R}^n \\to \\mathbf{R}\\) be a scalar-valued function. The gradient vector of \\(f\\) is defined as:\n\\[\\begin{align*}\n\\nabla f(\\mathbf{x}) = \\left[\\frac{\\partial f}{\\partial x_1},\\frac{\\partial f}{\\partial x_2},\\ldots,\\frac{\\partial f}{\\partial x_n}\\right]\n\\end{align*}\\]\nThe graph of the function \\(f:\\mathbf{R}^n \\to \\mathbf{R}\\) is the hypersurface in \\(\\mathbf{R}^{n+1}\\) given by the equation \\(x_{n+1}=f(x_1,\\ldots,x_n)\\).\nDefinition. \\(f\\) is said to be differentiable at \\(\\mathbf{a}\\) if all the partial derivatives \\(f_{x_i}(\\mathbf{a})\\) exist and if the function \\(h(\\mathbf{x})\\) defined by:\n\\[\\begin{align*}\nh(\\mathbf{x}) = f(\\mathbf{a}) + \\nabla f(\\mathbf{a})\\cdot (\\mathbf{x}-\\mathbf{a})\n\\end{align*}\\]\nis a good linear approximation to \\(f\\) near \\(a\\), meaning that:\n\\[\\begin{align*}\nL = \\lim_{\\mathbf{x} \\to \\mathbf{a}} \\frac{f(\\mathbf{x}) - h(\\mathbf{x})}{||\\mathbf{x} - \\mathbf{a}||} = 0\n\\end{align*}\\]\nIf \\(f\\) is differentiable at \\(\\mathbf{a},f(\\mathbf{a})\\), then the hypersurface determined by the graph has a tangent hyperplane at \\((\\mathbf{a},f(\\mathbf{a}))\\) given by the equation:\n\\[\\begin{align*}\nh(\\mathbf{x}) = f(\\mathbf{a}) + \\nabla f(\\mathbf{a})\\cdot (\\mathbf{x}-\\mathbf{a})\n\\end{align*}\\]\n\n\nLet \\(f(x,y)\\) be a scalar-valued function of two variables. We understand the partial derivative \\(\\frac{\\partial f}{\\partial x}(a,b)\\) as the slope at the point \\((a,b,f(a,b))\\) of the curve obtained as the intersection of the surface \\(z=f(x,y)\\) and the plane \\(y=b\\). The other partial derivative has a geometric interpretation. However, the surface \\(z=f(x,y)\\) contains infinitely many curves passing through \\((a,b,f(a,b))\\) whose slope we might choose to measure. The directional derivative enables us to do this.\nIntuitively, \\(\\frac{\\partial f}{\\partial x}(a,b)\\) is as the rate of change of \\(f\\) as we move infinitesimally from \\(\\mathbf{a}=(a,b)\\) in the \\(\\mathbf{i}\\) direction.\nMathematically, by the definition of the derivative of \\(f\\):\n\\[\\begin{align*}\n\\frac{\\partial f}{\\partial x}(a,b) &= \\lim_{h \\to 0} \\frac{f(a+h,b) - f(a,b)}{h}\\\\\n&=\\lim_{h \\to 0} \\frac{f((a,b) + (h,0)) - f(a,b)}{h}\\\\\n&=\\lim_{h \\to 0} \\frac{f((a,b) + h(1,0)) - f(a,b)}{h}\\\\\n&=\\lim_{h \\to 0} \\frac{f(\\mathbf{a} + h\\mathbf{i}) - f(\\mathbf{a})}{h}\n\\end{align*}\\]\nSimilarly, we have:\n\\[\\begin{align*}\n\\frac{\\partial f}{\\partial y}(a,b) = \\lim_{h\\to 0} \\frac{f(\\mathbf{a} + h\\mathbf{j})-f(\\mathbf{a})}{h}\n\\end{align*}\\]\nWriting partial derivatives as we have enables us to see that they are special cases of a more general type of derivative. Suppose \\(\\mathbf{v}\\) is a unit vector in \\(\\mathbf{R}^2\\). The quantity:\n\\[\\begin{align*}\n\\lim_{h \\to 0} \\frac{f(\\mathbf{a} + h\\mathbf{v}) - f(\\mathbf{a})}{h}\n\\end{align*}\\]\nis nothing more than the rate of change of \\(f\\) as we move infinitesimally from \\(\\mathbf{a} = (a,b)\\) in the direction specified by \\(\\mathbf{v}=(A,B) = A\\mathbf{i} + B\\mathbf{j}\\).\nDefinition. Let \\(\\mathbf{v}\\in \\mathbf{R}^n\\) be any unit vector, then the directional derivative of \\(f\\) at \\(\\mathbf{a}\\) in the direction of \\(\\mathbf{v}\\), denoted \\(D_{\\mathbf{v}}f(\\mathbf{a})\\) is:\n\\[\\begin{align*}\nD_{\\mathbf{v}}f(\\mathbf{a}) = \\lim_{h \\to 0} \\frac{f(\\mathbf{a} + h\\mathbf{v}) - f(\\mathbf{a})}{h}\n\\end{align*}\\]\nLet’s define a new function \\(F\\) of a single variable \\(t\\), by holding everything else constant:\n\\[\\begin{align*}\nF(t) = f(\\mathbf{a} + t\\mathbf{v})\n\\end{align*}\\]\nThen, by the definition of directional derivatives, we have:\n\\[\\begin{align*}\nD_{\\mathbf{v}}f(\\mathbf{a}) &= \\lim_{t\\to 0} \\frac{f(\\mathbf{a} + t\\mathbf{v}) - f(\\mathbf{a})}{t}\\\\\n&= \\lim_{t\\to 0} \\frac{F(t) - F(0)}{t - 0} \\\\\n&= F'(0)\n\\end{align*}\\]\nThat is:\n\\[\\begin{align*}\nD_{\\mathbf{v}}f(\\mathbf{a}) = \\frac{d}{dt} f(\\mathbf{a} + t\\mathbf{v})\\vert_{t=0}\n\\end{align*}\\]\nLet \\(\\mathbf{x}(t) = \\mathbf{a}+t\\mathbf{v}\\). Then, by the chain rule:\n\\[\\begin{align*}\n\\frac{d}{dt} f(\\mathbf{a} + t\\mathbf{v}) &= Df(\\mathbf{x}) D\\mathbf{x}(t) \\\\\n&= \\nabla f(\\mathbf{x}) \\cdot \\mathbf{v}\n\\end{align*}\\]\nThis equation emphasizes the geometry of the situation. The directional derivative is just the dot product of the gradient vector and the direction vector \\(\\mathbf{v}\\).\nTheorem. Let \\(f:X\\to\\mathbf{R}\\) be differentiable at \\(\\mathbf{a}\\in X\\). Then, the directional derivative \\(D_{\\mathbf{v}}f(\\mathbf{a})\\) exists for all directions \\(\\mathbf{v}\\in\\mathbf{R}^n\\) and moreover we have:\n\\[\\begin{align*}\nD_{\\mathbf{v}}f(\\mathbf{a}) = \\nabla f(\\mathbf{x})\\cdot \\mathbf{v}\n\\end{align*}\\]\n\n\n\nSuppose you are traveling in space near the planet Nilrebo and that one of your spaceship’s instruments measures the external atmospheric pressure on your ship as a function \\(f(x,y,z)\\) of position. Assume quite reasonably that this function is differentiable. Then, the directional derivative exists and if you travel from point \\(\\mathbf{a}=(a,b,c)\\) in the direction of the unit vector \\(\\mathbf{u}=u\\mathbf{i}+v\\mathbf{j}+w\\mathbf{k}\\), the rate of change of pressure is given by:\n\\[\\begin{align*}\nD_{\\mathbf{u}}f(\\mathbf{a}) = \\nabla f(\\mathbf{a}) \\cdot \\mathbf{u} = ||\\nabla f(\\mathbf{a})|| \\cdot ||\\mathbf{u}|| \\cos \\theta\n\\end{align*}\\]\nwhere \\(\\theta\\) is the angle between \\(\\mathbf{u}\\) and the gradient vector \\(\\nabla f(\\mathbf{a})\\). Because, \\(-1 \\leq \\cos \\theta \\leq 1\\), and \\(||\\mathbf{u}||=1\\), we have:\n\\[\\begin{align*}\n- ||\\nabla f(\\mathbf{a})|| \\leq D_{\\mathbf{u}}f(\\mathbf{a}) \\leq ||\\nabla f(\\mathbf{a})||\n\\end{align*}\\]\nMoreover, \\(\\cos \\theta = 1\\) when \\(\\theta = 0\\) and \\(\\cos \\theta = -1\\) when \\(\\theta = \\pi\\).\nTheorem. The directional derivative \\(D_{\\mathbf{u}}f(\\mathbf{a})\\) is maximized, with respect to the direction, when \\(\\mathbf{u}\\) points in the direction of the gradient vector \\(f(\\mathbf{a})\\) and is minimized when \\(\\mathbf{u}\\) points in the opposite direction. Furthermore, the maximum and minimum values of \\(D_{\\mathbf{u}}f(\\mathbf{a})\\) are \\(||\\nabla f(\\mathbf{a})||\\) and \\(-||\\nabla f(\\mathbf{a})||\\).\nTheorem Let \\(f:X \\subseteq \\mathbf{R}^n \\to \\mathbf{R}\\) be a function of class \\(C^1\\). If \\(\\mathbf{x}_0\\) is a point on the level set \\(S=\\{\\mathbf{x} \\in X | f(\\mathbf{x}) = c\\}\\), then the gradient vector \\(\\nabla f(\\mathbf{x}_0) \\in \\mathbf{R}^n\\) is perpendicular to \\(S\\).\nProof. We need to establish the following: if \\(\\mathbf{v}\\) is any vector tangent to \\(S\\) at \\(\\mathbf{x}_0\\), then \\(\\nabla f(\\mathbf{x}_0)\\) is perpendicular to \\(\\mathbf{v}\\) (i.e. \\(\\nabla f(\\mathbf{x}_0) \\cdot \\mathbf{v} = 0\\)). By a tangent vector to \\(S\\) at \\(\\mathbf{x}_0\\), we mean that \\(\\mathbf{v}\\) is the velocity vector of a curve \\(C\\) that lies in \\(S\\) and passes through \\(\\mathbf{x}_0\\).\nLet \\(C\\) be given parametrically by \\(\\mathbf{x}(t)=(x_1(t),\\ldots,x_n(t))\\) where \\(a &lt; t &lt; b\\) and \\(\\mathbf{x}(t_0) = \\mathbf{x}_0\\) for some number \\(t_0\\) in \\((a,b)\\).\n\\[\\begin{align*}\n\\frac{d}{dt}[f(\\mathbf{x}(t))] &= Df(\\mathbf{x}) \\cdot \\mathbf{x}'(t)\\\\\n&= \\nabla f(\\mathbf{x}) \\cdot \\mathbf{v}\n\\end{align*}\\]\nEvaluation at \\(t = t_0\\), yields:\n\\[\\begin{align*}\n\\nabla f (\\mathbf{x}(t_0)) \\cdot \\mathbf{x}'(t_0) = \\nabla f(\\mathbf{x}_0) \\cdot \\mathbf{v}\n\\end{align*}\\]\nOn the other hand, since \\(C\\) is contained in \\(S\\), \\(f(\\mathbf{x})=c\\). So,\n\\[\\begin{align*}\n\\frac{d}{dt}[f(\\mathbf{x}(t))] &= \\frac{d}{dt}[c] = 0\n\\end{align*}\\]\nPutting the above two facts together, we have the desired result."
  },
  {
    "objectID": "posts/optimization_algorithms/index.html#gradient-vector",
    "href": "posts/optimization_algorithms/index.html#gradient-vector",
    "title": "Optimization Algorithms",
    "section": "",
    "text": "Definition. Let \\(f:\\mathbf{R}^n \\to \\mathbf{R}\\) be a scalar-valued function. The gradient vector of \\(f\\) is defined as:\n\\[\\begin{align*}\n\\nabla f(\\mathbf{x}) = \\left[\\frac{\\partial f}{\\partial x_1},\\frac{\\partial f}{\\partial x_2},\\ldots,\\frac{\\partial f}{\\partial x_n}\\right]\n\\end{align*}\\]\nThe graph of the function \\(f:\\mathbf{R}^n \\to \\mathbf{R}\\) is the hypersurface in \\(\\mathbf{R}^{n+1}\\) given by the equation \\(x_{n+1}=f(x_1,\\ldots,x_n)\\).\nDefinition. \\(f\\) is said to be differentiable at \\(\\mathbf{a}\\) if all the partial derivatives \\(f_{x_i}(\\mathbf{a})\\) exist and if the function \\(h(\\mathbf{x})\\) defined by:\n\\[\\begin{align*}\nh(\\mathbf{x}) = f(\\mathbf{a}) + \\nabla f(\\mathbf{a})\\cdot (\\mathbf{x}-\\mathbf{a})\n\\end{align*}\\]\nis a good linear approximation to \\(f\\) near \\(a\\), meaning that:\n\\[\\begin{align*}\nL = \\lim_{\\mathbf{x} \\to \\mathbf{a}} \\frac{f(\\mathbf{x}) - h(\\mathbf{x})}{||\\mathbf{x} - \\mathbf{a}||} = 0\n\\end{align*}\\]\nIf \\(f\\) is differentiable at \\(\\mathbf{a},f(\\mathbf{a})\\), then the hypersurface determined by the graph has a tangent hyperplane at \\((\\mathbf{a},f(\\mathbf{a}))\\) given by the equation:\n\\[\\begin{align*}\nh(\\mathbf{x}) = f(\\mathbf{a}) + \\nabla f(\\mathbf{a})\\cdot (\\mathbf{x}-\\mathbf{a})\n\\end{align*}\\]\n\n\nLet \\(f(x,y)\\) be a scalar-valued function of two variables. We understand the partial derivative \\(\\frac{\\partial f}{\\partial x}(a,b)\\) as the slope at the point \\((a,b,f(a,b))\\) of the curve obtained as the intersection of the surface \\(z=f(x,y)\\) and the plane \\(y=b\\). The other partial derivative has a geometric interpretation. However, the surface \\(z=f(x,y)\\) contains infinitely many curves passing through \\((a,b,f(a,b))\\) whose slope we might choose to measure. The directional derivative enables us to do this.\nIntuitively, \\(\\frac{\\partial f}{\\partial x}(a,b)\\) is as the rate of change of \\(f\\) as we move infinitesimally from \\(\\mathbf{a}=(a,b)\\) in the \\(\\mathbf{i}\\) direction.\nMathematically, by the definition of the derivative of \\(f\\):\n\\[\\begin{align*}\n\\frac{\\partial f}{\\partial x}(a,b) &= \\lim_{h \\to 0} \\frac{f(a+h,b) - f(a,b)}{h}\\\\\n&=\\lim_{h \\to 0} \\frac{f((a,b) + (h,0)) - f(a,b)}{h}\\\\\n&=\\lim_{h \\to 0} \\frac{f((a,b) + h(1,0)) - f(a,b)}{h}\\\\\n&=\\lim_{h \\to 0} \\frac{f(\\mathbf{a} + h\\mathbf{i}) - f(\\mathbf{a})}{h}\n\\end{align*}\\]\nSimilarly, we have:\n\\[\\begin{align*}\n\\frac{\\partial f}{\\partial y}(a,b) = \\lim_{h\\to 0} \\frac{f(\\mathbf{a} + h\\mathbf{j})-f(\\mathbf{a})}{h}\n\\end{align*}\\]\nWriting partial derivatives as we have enables us to see that they are special cases of a more general type of derivative. Suppose \\(\\mathbf{v}\\) is a unit vector in \\(\\mathbf{R}^2\\). The quantity:\n\\[\\begin{align*}\n\\lim_{h \\to 0} \\frac{f(\\mathbf{a} + h\\mathbf{v}) - f(\\mathbf{a})}{h}\n\\end{align*}\\]\nis nothing more than the rate of change of \\(f\\) as we move infinitesimally from \\(\\mathbf{a} = (a,b)\\) in the direction specified by \\(\\mathbf{v}=(A,B) = A\\mathbf{i} + B\\mathbf{j}\\).\nDefinition. Let \\(\\mathbf{v}\\in \\mathbf{R}^n\\) be any unit vector, then the directional derivative of \\(f\\) at \\(\\mathbf{a}\\) in the direction of \\(\\mathbf{v}\\), denoted \\(D_{\\mathbf{v}}f(\\mathbf{a})\\) is:\n\\[\\begin{align*}\nD_{\\mathbf{v}}f(\\mathbf{a}) = \\lim_{h \\to 0} \\frac{f(\\mathbf{a} + h\\mathbf{v}) - f(\\mathbf{a})}{h}\n\\end{align*}\\]\nLet’s define a new function \\(F\\) of a single variable \\(t\\), by holding everything else constant:\n\\[\\begin{align*}\nF(t) = f(\\mathbf{a} + t\\mathbf{v})\n\\end{align*}\\]\nThen, by the definition of directional derivatives, we have:\n\\[\\begin{align*}\nD_{\\mathbf{v}}f(\\mathbf{a}) &= \\lim_{t\\to 0} \\frac{f(\\mathbf{a} + t\\mathbf{v}) - f(\\mathbf{a})}{t}\\\\\n&= \\lim_{t\\to 0} \\frac{F(t) - F(0)}{t - 0} \\\\\n&= F'(0)\n\\end{align*}\\]\nThat is:\n\\[\\begin{align*}\nD_{\\mathbf{v}}f(\\mathbf{a}) = \\frac{d}{dt} f(\\mathbf{a} + t\\mathbf{v})\\vert_{t=0}\n\\end{align*}\\]\nLet \\(\\mathbf{x}(t) = \\mathbf{a}+t\\mathbf{v}\\). Then, by the chain rule:\n\\[\\begin{align*}\n\\frac{d}{dt} f(\\mathbf{a} + t\\mathbf{v}) &= Df(\\mathbf{x}) D\\mathbf{x}(t) \\\\\n&= \\nabla f(\\mathbf{x}) \\cdot \\mathbf{v}\n\\end{align*}\\]\nThis equation emphasizes the geometry of the situation. The directional derivative is just the dot product of the gradient vector and the direction vector \\(\\mathbf{v}\\).\nTheorem. Let \\(f:X\\to\\mathbf{R}\\) be differentiable at \\(\\mathbf{a}\\in X\\). Then, the directional derivative \\(D_{\\mathbf{v}}f(\\mathbf{a})\\) exists for all directions \\(\\mathbf{v}\\in\\mathbf{R}^n\\) and moreover we have:\n\\[\\begin{align*}\nD_{\\mathbf{v}}f(\\mathbf{a}) = \\nabla f(\\mathbf{x})\\cdot \\mathbf{v}\n\\end{align*}\\]\n\n\n\nSuppose you are traveling in space near the planet Nilrebo and that one of your spaceship’s instruments measures the external atmospheric pressure on your ship as a function \\(f(x,y,z)\\) of position. Assume quite reasonably that this function is differentiable. Then, the directional derivative exists and if you travel from point \\(\\mathbf{a}=(a,b,c)\\) in the direction of the unit vector \\(\\mathbf{u}=u\\mathbf{i}+v\\mathbf{j}+w\\mathbf{k}\\), the rate of change of pressure is given by:\n\\[\\begin{align*}\nD_{\\mathbf{u}}f(\\mathbf{a}) = \\nabla f(\\mathbf{a}) \\cdot \\mathbf{u} = ||\\nabla f(\\mathbf{a})|| \\cdot ||\\mathbf{u}|| \\cos \\theta\n\\end{align*}\\]\nwhere \\(\\theta\\) is the angle between \\(\\mathbf{u}\\) and the gradient vector \\(\\nabla f(\\mathbf{a})\\). Because, \\(-1 \\leq \\cos \\theta \\leq 1\\), and \\(||\\mathbf{u}||=1\\), we have:\n\\[\\begin{align*}\n- ||\\nabla f(\\mathbf{a})|| \\leq D_{\\mathbf{u}}f(\\mathbf{a}) \\leq ||\\nabla f(\\mathbf{a})||\n\\end{align*}\\]\nMoreover, \\(\\cos \\theta = 1\\) when \\(\\theta = 0\\) and \\(\\cos \\theta = -1\\) when \\(\\theta = \\pi\\).\nTheorem. The directional derivative \\(D_{\\mathbf{u}}f(\\mathbf{a})\\) is maximized, with respect to the direction, when \\(\\mathbf{u}\\) points in the direction of the gradient vector \\(f(\\mathbf{a})\\) and is minimized when \\(\\mathbf{u}\\) points in the opposite direction. Furthermore, the maximum and minimum values of \\(D_{\\mathbf{u}}f(\\mathbf{a})\\) are \\(||\\nabla f(\\mathbf{a})||\\) and \\(-||\\nabla f(\\mathbf{a})||\\).\nTheorem Let \\(f:X \\subseteq \\mathbf{R}^n \\to \\mathbf{R}\\) be a function of class \\(C^1\\). If \\(\\mathbf{x}_0\\) is a point on the level set \\(S=\\{\\mathbf{x} \\in X | f(\\mathbf{x}) = c\\}\\), then the gradient vector \\(\\nabla f(\\mathbf{x}_0) \\in \\mathbf{R}^n\\) is perpendicular to \\(S\\).\nProof. We need to establish the following: if \\(\\mathbf{v}\\) is any vector tangent to \\(S\\) at \\(\\mathbf{x}_0\\), then \\(\\nabla f(\\mathbf{x}_0)\\) is perpendicular to \\(\\mathbf{v}\\) (i.e. \\(\\nabla f(\\mathbf{x}_0) \\cdot \\mathbf{v} = 0\\)). By a tangent vector to \\(S\\) at \\(\\mathbf{x}_0\\), we mean that \\(\\mathbf{v}\\) is the velocity vector of a curve \\(C\\) that lies in \\(S\\) and passes through \\(\\mathbf{x}_0\\).\nLet \\(C\\) be given parametrically by \\(\\mathbf{x}(t)=(x_1(t),\\ldots,x_n(t))\\) where \\(a &lt; t &lt; b\\) and \\(\\mathbf{x}(t_0) = \\mathbf{x}_0\\) for some number \\(t_0\\) in \\((a,b)\\).\n\\[\\begin{align*}\n\\frac{d}{dt}[f(\\mathbf{x}(t))] &= Df(\\mathbf{x}) \\cdot \\mathbf{x}'(t)\\\\\n&= \\nabla f(\\mathbf{x}) \\cdot \\mathbf{v}\n\\end{align*}\\]\nEvaluation at \\(t = t_0\\), yields:\n\\[\\begin{align*}\n\\nabla f (\\mathbf{x}(t_0)) \\cdot \\mathbf{x}'(t_0) = \\nabla f(\\mathbf{x}_0) \\cdot \\mathbf{v}\n\\end{align*}\\]\nOn the other hand, since \\(C\\) is contained in \\(S\\), \\(f(\\mathbf{x})=c\\). So,\n\\[\\begin{align*}\n\\frac{d}{dt}[f(\\mathbf{x}(t))] &= \\frac{d}{dt}[c] = 0\n\\end{align*}\\]\nPutting the above two facts together, we have the desired result."
  },
  {
    "objectID": "posts/optimization_algorithms/index.html#gradient-descent---naive-implementation",
    "href": "posts/optimization_algorithms/index.html#gradient-descent---naive-implementation",
    "title": "Optimization Algorithms",
    "section": "Gradient Descent - Naive Implementation",
    "text": "Gradient Descent - Naive Implementation\nBeginning at \\(\\mathbf{x}_0\\), optimization algorithms generate a sequence of iterates \\(\\{\\mathbf{x}_k\\}_{k=0}^{\\infty}\\) that terminate when no more progress can be made or it seems a solution point has been approximated with sufficient accuracy. The gradient descent method is an optimization algorithm that moves along \\(\\mathbf{d}_k = -\\nabla f(\\mathbf{x}_k)\\) at every step. Thus,\n\\[\\begin{align*}\n\\mathbf{x}_{k+1} = \\mathbf{x}_k - \\alpha_k \\mathbf{d}_k\n\\end{align*}\\]\nIt can choose the step length \\(\\alpha_k\\) in a variety of ways. One advantage of steepest descent is that it requires the calculation of the gradient \\(\\nabla f(\\mathbf{x}_k)\\), but not of the second derivatives. However, it can be excruciatingly slow on difficult problems.\n\n%load_ext itikz\n\n\nfrom typing import Callable\nimport numpy as np\n\n\ndef gradient_descent(\n    func: Callable[[float], float],\n    alpha: float,\n    xval_0: np.array,\n    epsilon: float = 1e-5,\n    n_iter: int = 10000,\n    debug_step: int = 100,\n):\n    \"\"\"\n    The gradient descent algorithm.\n    \"\"\"\n\n    xval_hist = []\n    funcval_hist = []\n\n    xval_curr = xval_0\n    error = 1.0\n    i = 0\n\n    while np.linalg.norm(error) &gt; epsilon and i &lt; n_iter:\n        # Save down x_curr and func(x_curr)\n        xval_hist.append(xval_curr)\n        funcval_hist.append(func(xval_curr))\n\n        # Calculate the forward difference\n        bump = 0.001\n        num_dims = len(xval_curr)\n        xval_bump = xval_curr + np.eye(num_dims) * bump\n        xval_nobump = np.full((num_dims, num_dims), xval_curr)\n\n        grad = np.array(\n            [\n                (func(xval_h) - func(xval)) / bump\n                for xval_h, xval in zip(xval_bump, xval_nobump)\n            ]\n        )\n\n        # Compute the next iterate\n        xval_next = xval_curr - alpha * grad\n\n        # Compute the error vector\n        error = xval_next - xval_curr\n\n        if i % debug_step == 0:\n            print(\n                f\"x[{i}] = {xval_curr}, f({xval_curr}) = {func(xval_curr)}, f'({xval_curr}) = {grad}, error={error}\"\n            )\n\n        xval_curr = xval_next\n        i += 1\n\n    return xval_hist, funcval_hist\n\nOne infamous test function is the Rosenbrock function defined as:\n\\[\\begin{align*}\nf(x,y) = (a-x)^2 + b(y-x^2)^2\n\\end{align*}\\]\n\ndef rosenbrock(x):\n    return 1*(1-x[0])**2 + 100*(x[1]-x[0]**2)**2\n\ndef f(x):\n    return x[0]**2 + x[1]**2\n\nHere is the plot of the Rosenbrock function with parameters \\(a=1,b=100\\).\n\n\nShow the code\n%%itikz --temp-dir --tex-packages=tikz,pgfplots --tikz-libraries=arrows --implicit-standalone\n\\begin{tikzpicture}[scale=1.5]\n\\begin{axis}[\n     title={Plot of $f(x,y)=(1-x)^2 + 100(y-x^2)^2$},\n]\n    \\addplot3 [surf] {(1-x)^2 + 100*(y-x^2)^2};\n\\end{axis}\n\\end{tikzpicture}\n\n\n\n\n\n\nx_history, f_x_history = gradient_descent(\n    func=rosenbrock,\n    alpha=0.001,\n    xval_0=np.array([-2.0, 2.0]),\n    epsilon=1e-7,\n    debug_step=1000,\n)\n\nprint(f\"x* = {x_history[-1]}, f(x*)={f_x_history[-1]}\")\n\nx[0] = [-2.  2.], f([-2.  2.]) = 409.0, f'([-2.  2.]) = [-1603.9997999  -399.9      ], error=[1.6039998 0.3999   ]\nx[1000] = [-0.34194164  0.12278388], f([-0.34194164  0.12278388]) = 1.804241076974863, f'([-0.34194164  0.12278388]) = [-1.8359394   1.27195859], error=[ 0.00183594 -0.00127196]\nx[2000] = [0.59082668 0.34719456], f([0.59082668 0.34719456]) = 0.16777685109400048, f'([0.59082668 0.34719456]) = [-0.23242066 -0.27632251], error=[0.00023242 0.00027632]\nx[3000] = [0.71914598 0.51617916], f([0.71914598 0.51617916]) = 0.0789773438798074, f'([0.71914598 0.51617916]) = [-0.06806067 -0.09835534], error=[6.80606659e-05 9.83553399e-05]\nx[4000] = [0.7626568  0.58094326], f([0.7626568  0.58094326]) = 0.05638109494458334, f'([0.7626568  0.58094326]) = [-0.02638936 -0.04042575], error=[2.63893643e-05 4.04257465e-05]\nx[5000] = [0.78028032 0.60825002], f([0.78028032 0.60825002]) = 0.04831123625687607, f'([0.78028032 0.60825002]) = [-0.01115051 -0.01747329], error=[1.11505139e-05 1.74732947e-05]\nx[6000] = [0.78785296 0.62017375], f([0.78785296 0.62017375]) = 0.045035368749296534, f'([0.78785296 0.62017375]) = [-0.00487137 -0.00770719], error=[4.87136843e-06 7.70718502e-06]\nx[7000] = [0.79118466 0.62545602], f([0.79118466 0.62545602]) = 0.04363059164103049, f'([0.79118466 0.62545602]) = [-0.00215834 -0.00342913], error=[2.1583377e-06 3.4291304e-06]\nx[8000] = [0.79266536 0.62781071], f([0.79266536 0.62781071]) = 0.04301342477692797, f'([0.79266536 0.62781071]) = [-0.00096218 -0.00153153], error=[9.62177510e-07 1.53153219e-06]\nx[9000] = [0.79332635 0.62886327], f([0.79332635 0.62886327]) = 0.042739342077472306, f'([0.79332635 0.62886327]) = [-0.0004301  -0.00068518], error=[4.30102710e-07 6.85176669e-07]\nx* = [0.7936218  0.62933403], f(x*)=0.04261711392593988"
  },
  {
    "objectID": "posts/optimization_algorithms/index.html#convergence.",
    "href": "posts/optimization_algorithms/index.html#convergence.",
    "title": "Optimization Algorithms",
    "section": "Convergence.",
    "text": "Convergence.\nWhen applying gradient descent in practice, we need to choose a value for the learning rate parameter \\(\\alpha\\). An error surface \\(E\\) is usually a convex function on the weight space \\(\\mathbf{w}\\). Intuitively, we might expect that increasing the value of \\(\\alpha\\) should lead to bigger steps through the weight space and hence faster convergence. However, the successive steps oscillate back and forth across the valley, and if we increase \\(\\alpha\\) too much, these oscillations will become divergent. Because \\(\\alpha\\) must be kept sufficiently small to avoid divergent oscillations across the valley, progress along the valley is very slow. Gradient descent then takes many small steps to reach the minimum and is a very inefficient procedure.\nWe can gain deeper insight into this problem, by considering a quadratic approximation to the error function in the neighbourhood of the minimum. Let the error function be given by:\n\\[\\begin{align*}\nf(w) = \\frac{1}{2}w^T A w - b^T w, \\quad w\\in\\mathbf{R}^n\n\\end{align*}\\]\nwhere \\(A\\) is symmetric and \\(A \\succ 0\\).\nDifferentiating on both sides, the gradient of the error function is:\n\\[\\begin{align*}\n\\nabla f(w) = Aw - b\n\\end{align*}\\]\nand the hessian is:\n\\[\\begin{align*}\n\\nabla^2 f(w) = A\n\\end{align*}\\]\nThe critical points of \\(f\\) are given by:\n\\[\\begin{align*}\n\\nabla f(w^*) &= 0\\\\\nAw^{*} - b &= 0\\\\\nw^{*} &= A^{-1}b\n\\end{align*}\\]\nand\n\\[\\begin{align*}\nf(w^{*}) &= \\frac{1}{2}(A^{-1}b)^T A (A^{-1}b) - b^T (A^{-1} b)\\\\\n&= \\frac{1}{2}b^T A^{-1} A A^{-1} b -b^T A^{-1} b \\\\\n&= \\frac{1}{2}b^T A^{-1} b - b^T A^{-1} b \\\\\n&= -\\frac{1}{2}b^T A^{-1} b\n\\end{align*}\\]\nTherefore, the iterates of \\(w\\) are:\n\\[\\begin{align*}\nw^{(k+1)} = w^{(k)} - \\alpha(Aw^{(k)} - b)\n\\end{align*}\\]\nBy the spectral theorem, every symmetric matrix \\(A\\) is orthogonally diagonalizable. So, \\(A\\) admits a factorization:\n\\[\\begin{align*}\nA = Q \\Lambda Q^T\n\\end{align*}\\]\nwhere \\(\\Lambda = diag(\\lambda_1,\\ldots,\\lambda_n)\\) and as per convention, we will assume that \\(\\lambda_i\\)are sorted from smallest \\(\\lambda_1\\) to biggest \\(\\lambda_n\\).\nRecall that \\(Q=[q_1,\\ldots,q_n]\\), where \\(q_i\\) are the eigenvectors of \\(A\\) and \\(Q\\) is the change of basis matrix from the standard basis to the eigenvector basis. So, if \\(a \\in \\mathbf{R}^n\\) are the coordinates of a vector in the standard basis and \\(b \\in \\mathbf{R}^n\\) are its coordinates in the eigenvector basis, then \\(a = Qb\\) or \\(b=Q^T a\\).\nLet \\(x^{(k)}=Q^T(w^{(k)}-w^{*})\\). Equivalently, \\(w^{(k)} = Qx^{(k)} + w^{*}\\). Thus, we are shifting the origin to \\(w^{*}\\) and changing the axes to be aligned with the eigenvectors. In this new coordinate system,\n\\[\\begin{align*}\nQx^{(k+1)} + w^{*} &= Qx^{(k)} + w^{*} - \\alpha(AQx^{(k)} + Aw^{*} - b)\\\\\nQx^{(k+1)} &= Qx^{(k)} - \\alpha(AQx^{(k)} + Aw^{*} - b)\\\\\nQx^{(k+1)} &= Qx^{(k)} - \\alpha(AQx^{(k)} + A(A^{-1}b) - b)\\\\\n& \\quad \\{\\text{Substituting } w^{*}=A^{-1}b \\}\\\\\nQx^{(k+1)} &= Qx^{(k)} - \\alpha(AQx^{(k)})\\\\\nQx^{(k+1)} &= Qx^{(k)} - \\alpha(Q\\Lambda Q^T Qx^{(k)})\\\\\n& \\quad \\{\\text{Substituting } A = Q\\Lambda Q^T \\}\\\\\nQx^{(k+1)} &= Qx^{(k)} - \\alpha(Q\\Lambda x^{(k)})\\\\\n& \\quad \\{\\text{Using } Q^T Q = I \\}\\\\\nx^{(k+1)} &= x^{(k)} - \\alpha\\Lambda x^{(k)}\n\\end{align*}\\]\nThe \\(i\\)-th coordinate of this recursive system is given by:\n\\[\\begin{align*}\nx_i^{(k+1)} &= x_i^{(k)} - \\alpha\\lambda_i x_i^{(k)}\\\\\n&= (1-\\alpha \\lambda_i)x_i^{(k)}\\\\\n&= (1-\\alpha \\lambda_i)^{k+1}x_i^{(0)}\n\\end{align*}\\]\nMoving back to our original space \\(w\\), we can see that:\n\\[\\begin{align*}\nw^{(k)} - w^{*} = Qx^{(k)} &= \\sum_i q_i x_i^{(k)}\\\\\n&= \\sum_i q_i (1-\\alpha \\lambda_i)^{k+1} x_i^{(0)}\n\\end{align*}\\]\nand there we have it - gradient descent in the closed form.\n\nDecomposing the error\nThe above equation admits a simple interpretation. Each element of \\(x^{(0)}\\) is the component of the error in the initial guess in \\(Q\\)-basis. There are \\(n\\) such errors and each of these errors follow their own, solitary path to the minimum, decreasing exponentially with a compounding rate of \\(1-\\alpha \\lambda_i\\). The closer that number is to \\(1\\), the slower it converges.\nFor most step-sizes, the eigenvectors with the largest eigenvalues converge the fastest. This triggers an explosion of progress in the first few iterations, before things slow down, as the eigenvectors with smaller eigenvalues’ struggles are revealed. It’s easy to visualize this - look at the sequences of \\(\\frac{1}{2^k}\\) and \\(\\frac{1}{3^k}\\).\n\n\nShow the code\n%%itikz --temp-dir --tex-packages=tikz,pgfplots --tikz-libraries=arrows --implicit-standalone\n\\begin{tikzpicture}[scale=1.5]\n\\begin{axis}[\n     title={Comparison of the rates of convergence},\n     xlabel={$n$},\n     ylabel={$f(n)$}\n]\n    \\addplot [domain=0:5,samples=400,blue] {1/(2^x)} node [midway,above] {$2^{-n}$};\n    \\addplot [domain=0:5,samples=400,red] {1/(3^x)} node [midway,below] {$3^{-n}$};\n\\end{axis}\n\\end{tikzpicture}\n\n\n\n\n\n\n\nChoosing a step size\nThe above analysis gives us immediate guidance as to how to set a step-size \\(\\alpha\\). In order to converge, each \\(|1-\\alpha \\lambda_i| &lt; 1\\). All workable step-sizes, therefore, fall in the interval:\n\\[\\begin{align*}\n-1 &\\leq 1 - \\alpha \\lambda_i &\\leq 1 \\\\\n-2 &\\leq - \\alpha \\lambda_i &\\leq 0 \\\\\n0 &\\leq \\alpha \\lambda_i &\\leq 2\n\\end{align*}\\]\nBecause \\((1-\\alpha \\lambda_i)\\) could be either positive or negative, the overall convergence rate is determined by the slowest error component, which must be either \\(\\lambda_1\\) or \\(\\lambda_n\\):\n\\[\\begin{align*}\n\\text{rate}(\\alpha) = \\max \\{|1-\\alpha \\lambda_1|,|1-\\alpha \\lambda_n|\\}\n\\end{align*}\\]\nThe optimal learning rate is that which balances the convergence rate. Setting the convergence rate to be equal for the smallest and largest eigenvalues, we can solve for the optimal step size.\n\\[\\begin{align*}\n|1- \\alpha \\lambda_1| = |1- \\alpha \\lambda_n|\n\\end{align*}\\]\nAssuming \\(\\lambda_1 \\neq \\lambda_n\\):\n\\[\\begin{align*}\n1 - \\alpha \\lambda_1 &= -1 + \\alpha \\lambda_n\\\\\n\\alpha (\\lambda_1 + \\lambda_n) &= 2\\\\\n\\alpha^* &= \\frac{2}{\\lambda_1 + \\lambda_n}\n\\end{align*}\\]\nSo, the optimal convergence rate equals:\n\\[\\begin{align*}\n\\max \\{|1-\\alpha \\lambda_1|,|1-\\alpha \\lambda_n|\\} &= 1 - \\frac{2\\lambda_1}{\\lambda_1 + \\lambda_n} \\\\\n&= \\frac{\\lambda_n - \\lambda_1}{\\lambda_n + \\lambda_1}\\\\\n&= \\frac{\\kappa - 1}{\\kappa + 1}\n\\end{align*}\\]\nThe ratio \\(\\kappa = \\lambda_n / \\lambda_1\\) determines the convergence rate of the problem. Recall that the level curves of the error surface are ellipsoids. Hence, a poorly conditioned Hessian results in stretching one of the axes of the ellipses, and taken to its extreme, the contours are almost parallel. Since gradient vectors are orthogonal to the level curves, the optimizer keeps pin-balling between parallel lines and takes forever to reach the center."
  },
  {
    "objectID": "posts/optimization_algorithms/index.html#stochastic-gradient-descentsgd",
    "href": "posts/optimization_algorithms/index.html#stochastic-gradient-descentsgd",
    "title": "Optimization Algorithms",
    "section": "Stochastic Gradient Descent(SGD)",
    "text": "Stochastic Gradient Descent(SGD)\nIn machine learning applications, we typically want to minimize the loss function \\(\\mathcal{L}(w)\\) that has the form of a sum:\n\\[\\begin{align*}\n\\mathcal{L}(w) = \\frac{1}{n}\\sum_i L_i(w)\n\\end{align*}\\]\nwhere the weights \\(w\\) (and the biases) are to be estimated. Each summand function \\(L_i\\) is typically associated with the \\(i\\)-th sample in the data-set used for training.\nWhen we minimize the above function with respect to the weights and biases, a standard gradient descent method would perform the following operations:\n\\[\\begin{align*}\nw_{k+1} := w_k - \\alpha_k \\nabla \\mathcal{L}(w_{k}) = w_k - \\frac{\\alpha_k}{n}\\sum_{i} \\nabla L_i(w_{k})\n\\end{align*}\\]\nIn the stochastic (or online) gradient descent algorithm, the true gradient of \\(\\mathcal{L}(w)\\) is approximated by the gradient at a single sample:\n\\[\\begin{align*}\nw_{k+1} := w_k - \\alpha_k \\nabla \\mathcal{L}(w_{k}) = w_k - \\alpha_k \\nabla L_i(w_{k})\n\\end{align*}\\]"
  },
  {
    "objectID": "posts/optimization_algorithms/index.html#sgdoptimizer-class",
    "href": "posts/optimization_algorithms/index.html#sgdoptimizer-class",
    "title": "Optimization Algorithms",
    "section": "SGDOptimizer class",
    "text": "SGDOptimizer class\nWe are now in a position to code the SGDOptimizer class.\n\n# Global imports\nimport numpy as np\nimport nnfs\nimport matplotlib.pyplot as plt\nfrom nnfs.datasets import spiral_data\n\nfrom dense_layer import DenseLayer\nfrom relu_activation import ReLUActivation\nfrom softmax_activation import SoftmaxActivation\n\nfrom loss import Loss\nfrom categorical_cross_entropy_loss import CategoricalCrossEntropyLoss\nfrom categorical_cross_entropy_softmax import CategoricalCrossEntropySoftmax\n\n\nclass SGDOptimizer:\n\n    # Initialize the optimizer\n    def __init__(self, learning_rate=1.0):\n        self.learning_rate = learning_rate\n\n    # Update the parameters\n    def update_params(self, layer):\n        layer.weights -= self.learning_rate * layer.dloss_dweights\n        layer.biases -= self.learning_rate * layer.dloss_dbiases\n\nLet’s play around with our optimizer.\n\n# Create dataset\nX, y = spiral_data(samples=100, classes=3)\n\n# Create a DenseLayer with 2 input features and 64 neurons\ndense1 = DenseLayer(2, 64)\n\n# Create ReLU Activation (to be used with DenseLayer 1)\nactivation1 = ReLUActivation()\n\n# Create the second DenseLayer with 64 inputs and 3 output values\ndense2 = DenseLayer(64,3)\n\n# Create SoftmaxClassifer's combined loss and activation\nloss_activation = CategoricalCrossEntropySoftmax()\n\n# The next step is to create the optimizer object\noptimizer = SGDOptimizer()\n\nNow, we perform a forward pass of our sample data.\n\n# Perform a forward pass for our sample data\ndense1.forward(X)\n\n# Performs a forward pass through the activation function\n# takes the output of the first dense layer here\nactivation1.forward(dense1.output)\n\n# Performs a forward pass through the second DenseLayer\ndense2.forward(activation1.output)\n\n# Performs a forward pass through the activation/loss function\n# takes the output of the second DenseLayer and returns the loss\nloss = loss_activation.forward(dense2.output, y)\n\n# Let's print the loss value\nprint(f\"Loss = {loss}\")\n\n# Now we do our backward pass \nloss_activation.backward(loss_activation.output, y)\ndense2.backward(loss_activation.dloss_dz)\nactivation1.backward(dense2.dloss_dinputs)\ndense1.backward(activation1.dloss_dz)\n\n# Then finally we use our optimizer to update the weights and biases\noptimizer.update_params(dense1)\noptimizer.update_params(dense2)\n\nLoss = 1.0986526582562541\n\n\nThis is everything we need to train our model!\nBut why would we only perform this optimization only once, when we can perform it many times by leveraging Python’s looping capabilities? We will repeatedly perform a forward pass, backward pass and optimization until we reach some stopping point. Each full pass through all of the training data is called an epoch.\nIn most deep learning tasks, a neural network will be trained for multiple epochs, though the ideal scenario would be to have a perfect model with ideal weights and biases after only one epoch. To add multiple epochs of our training into our code, we will initialize our model and run a loop around all the code performing the forward pass, backward pass and optimization calculations.\n\n# Create dataset\nX, y = spiral_data(samples=100, classes=3)\n\n# Create a dense layer with 2 input features and 64 output values\ndense1 = DenseLayer(2, 64)\n\n# Create ReLU Activation (to be used with the DenseLayer)\nactivation1 = ReLUActivation()\n\n# Create a second DenseLayer with 64 input features (as we take\n# output of the previous layer here) and 3 output values (output values)\ndense2 = DenseLayer(64, 3)\n\n# Create Softmax classifier's combined loss and activation\nloss_activation = CategoricalCrossEntropySoftmax()\n\n# Create optimizer\noptimizer = SGDOptimizer()\n\n# Train in loop\nfor epoch in range(10001):\n\n    # Perform a forward pass of our training data through this layer\n    dense1.forward(X)\n\n    # Perform a forward pass through the activation function\n    # takes the output of the first dense layer here\n    activation1.forward(dense1.output)\n\n    # Perform a forward pass through second DenseLayer\n    # takes the outputs of the activation function of first layer as inputs\n    dense2.forward(activation1.output)\n\n    # Perform a forward pass through the activation/loss function\n    # takes the output of the second DenseLayer here and returns the loss\n    loss = loss_activation.forward(dense2.output, y)\n\n    if not epoch % 1000:\n        print(f\"Epoch: {epoch}, Loss: {loss: .3f}\")\n\n    # Backward pass\n    loss_activation.backward(loss_activation.output, y)\n    dense2.backward(loss_activation.dloss_dz)\n    activation1.backward(dense2.dloss_dinputs)\n    dense1.backward(activation1.dloss_dz)\n\n    # Update the weights and the biases\n    optimizer.update_params(dense1)\n    optimizer.update_params(dense2)\n\nEpoch: 0, Loss:  1.099\nEpoch: 1000, Loss:  1.029\nEpoch: 2000, Loss:  0.962\nEpoch: 3000, Loss:  0.848\nEpoch: 4000, Loss:  0.699\nEpoch: 5000, Loss:  0.544\nEpoch: 6000, Loss:  0.508\nEpoch: 7000, Loss:  0.478\nEpoch: 8000, Loss:  0.460\nEpoch: 9000, Loss:  0.443\nEpoch: 10000, Loss:  0.419\n\n\nOur neural network mostly stays stuck at around a loss of \\(1.0\\) and later around \\(0.85\\)-\\(0.90\\) Given that this loss didn’t decrease much, we can assume that this learning rate being too high, also caused the model to get stuck in a local minimum, which we’ll learn more about soon. Iterating over more epochs, doesn’t seem helpful at this point, which tells us that we’re likely stuck with our optimization. Does this mean that this is the most we can get from our optimizer on this dataset?\nRecall that we’re adjusting our weights and biases by applying some fraction, in this case \\(1.0\\) to the gradient and subtracting this from the weights and biases. This fraction is called the learning rate (LR) and is the primary adjustable parameter for the optimizer as it decreases loss."
  },
  {
    "objectID": "posts/optimization_algorithms/index.html#learning-rate-decay",
    "href": "posts/optimization_algorithms/index.html#learning-rate-decay",
    "title": "Optimization Algorithms",
    "section": "Learning Rate Decay",
    "text": "Learning Rate Decay\nThe idea of a learning rate decay is to start with a large learning rate, say \\(1.0\\) in our case and then decrease it during training. There are a few methods for doing this. One option is program a decay rate, which steadily decays the learning rate per batch or per epoch.\nLet’s plan to decay per step. This can also be referred to as \\(1/t\\) decaying or exponential decaying. Basically, we’re going to update the learning rate each step by the reciprocal of the step count fraction. This fraction is a new hyper parameter that we’ll add to the optimizer, called the learning rate decay.\n\ninitial_learning_rate = 1.0\nlearning_rate_decay = 0.1\n\nfor step in range(10):\n    learning_rate = initial_learning_rate * 1.0 / (1 + learning_rate_decay * step)\n    print(learning_rate)\n\n1.0\n0.9090909090909091\n0.8333333333333334\n0.7692307692307692\n0.7142857142857143\n0.6666666666666666\n0.625\n0.588235294117647\n0.5555555555555556\n0.5263157894736842\n\n\nThe derivative of the function \\(\\frac{1}{1+x}\\) is \\(-\\frac{1}{(1+x)^2}\\).\n\n\nShow the code\n%%itikz --temp-dir --tex-packages=tikz,pgfplots --tikz-libraries=arrows --implicit-standalone\n\\begin{tikzpicture}[scale=1.5]\n\\begin{axis}[\n     title={Plot of $f(x)=-\\frac{1}{(1+x)^2}$},\n     xlabel={$x$},\n     ylabel={$f(x)$}\n]\n    \\addplot [domain=0:1,samples=400] {-1/(( 1 + x)^2)};\n\\end{axis}\n\\end{tikzpicture}\n\n\n\n\n\nThe learning rate drops fast initially, but the change in the learning rate lowers in each step. We can update our SGDOptimizer class to allow for the learning rate decay.\n\nclass SGDOptimizer:\n\n    # Initial optimizer - set settings\n    # learning rate of 1. is default for this optimizer\n    def __init__(self, learning_rate=1.0, decay=0.0):\n        self.learning_rate = learning_rate\n        self.current_learning_rate = learning_rate\n        self.decay = decay\n        self.iterations = 0\n\n    # Call once before any parameter updates\n    def pre_update_params(self):\n        if self.decay:\n            self.current_learning_rate = self.learning_rate * (\n                1.0 / (1.0 + self.decay * self.iterations)\n            )\n\n    # Update parameters\n    def update_params(self, layer):\n        layer.weights += -self.current_learning_rate * layer.dloss_dweights\n        layer.biases += -self.current_learning_rate * layer.dloss_dbiases\n\n    def post_update_params(self):\n        self.iterations += 1\n\nLet’s use a decay rate of \\(0.01\\) and train our neural network again.\n\ndef train(decay):\n    # Create a dataset\n    X, y = spiral_data(samples=100, classes=3)\n\n    # Create a dense layer with 2 input features and 64 output values\n    dense1 = DenseLayer(2, 64)\n\n    # Create ReLU activation (to be used with the dense layer)\n    activation1 = ReLUActivation()\n\n    # Create second DenseLayer with 64 input features (as we take output of the\n    # previous layer here) and 3 output values\n    dense2 = DenseLayer(64, 3)\n\n    # Create Softmax classifier's combined loss and activation\n    loss_activation = CategoricalCrossEntropySoftmax()\n\n    # Create optimizer\n    optimizer = SGDOptimizer(learning_rate=1.0,decay=decay)\n\n    acc_vals = []\n    loss_vals = []\n    lr_vals = []\n\n    # Train in a loop\n    for epoch in range(10001):\n        # Perform a forward pass of our training data through this layer\n        dense1.forward(X)\n\n        # Perform a forward pass through the activation function\n        # takes the output of the first dense layer here\n        activation1.forward(dense1.output)\n\n        # Perform a forward pass through second DenseLayer\n        # takes the outputs of the activation function of first layer as inputs\n        dense2.forward(activation1.output)\n\n        # Perform a forward pass through the activation/loss function\n        # takes the output of the second DenseLayer here and returns the loss\n        loss = loss_activation.forward(dense2.output, y)\n\n        # Calculate accuracy from output of activation2 and targets\n        # Calculate values along the first axis\n        predictions = np.argmax(loss_activation.output, axis=1)\n        if len(y.shape) == 2:\n            y = np.argmax(y, axis=1)\n\n        accuracy = np.mean(predictions == y)\n\n        if epoch % 1000 == 0:\n            print(\n                f\"epoch: {epoch}, \\\n                acc : {accuracy:.3f}, \\\n                loss: {loss: .3f}, \\\n                lr : {optimizer.current_learning_rate}\"\n            )\n\n        acc_vals.append(accuracy)\n        loss_vals.append(loss)\n        lr_vals.append(optimizer.current_learning_rate)\n\n        # Backward pass\n        loss_activation.backward(loss_activation.output, y)\n        dense2.backward(loss_activation.dloss_dz)\n        activation1.backward(dense2.dloss_dinputs)\n        dense1.backward(activation1.dloss_dz)\n\n        # Update the weights and the biases\n        optimizer.pre_update_params()\n        optimizer.update_params(dense1)\n        optimizer.update_params(dense2)\n        optimizer.post_update_params()\n\n    return acc_vals, loss_vals, lr_vals\n\n\nacc_vals, loss_vals, lr_vals = train(decay=0.01)\n\nepoch: 0,                 acc : 0.333,                 loss:  1.099,                 lr : 1.0\nepoch: 1000,                 acc : 0.477,                 loss:  1.066,                 lr : 0.09099181073703366\nepoch: 2000,                 acc : 0.457,                 loss:  1.065,                 lr : 0.047641734159123386\nepoch: 3000,                 acc : 0.453,                 loss:  1.065,                 lr : 0.03226847370119393\nepoch: 4000,                 acc : 0.450,                 loss:  1.064,                 lr : 0.02439619419370578\nepoch: 5000,                 acc : 0.440,                 loss:  1.064,                 lr : 0.019611688566385566\nepoch: 6000,                 acc : 0.443,                 loss:  1.063,                 lr : 0.016396130513198885\nepoch: 7000,                 acc : 0.447,                 loss:  1.063,                 lr : 0.014086491055078181\nepoch: 8000,                 acc : 0.447,                 loss:  1.063,                 lr : 0.012347203358439314\nepoch: 9000,                 acc : 0.447,                 loss:  1.062,                 lr : 0.010990218705352238\nepoch: 10000,                 acc : 0.447,                 loss:  1.062,                 lr : 0.009901970492127933\n\n\n\n\nShow the code\nplt.grid(True)\nepochs = np.linspace(0,10000,10001)\nplt.ylabel('Accuracy')\nplt.xlabel('Epochs')\nplt.plot(epochs,acc_vals)\nplt.show()\n\n\n\n\n\n\n\nShow the code\nplt.grid(True)\nplt.ylabel('Loss')\nplt.xlabel('Epochs')\nplt.plot(epochs,loss_vals)\nplt.show()\n\n\n\n\n\n\n\nShow the code\nplt.grid(True)\nplt.ylabel(\"Learning rate\")\nplt.xlabel(\"Epochs\")\nplt.plot(epochs, lr_vals)\nplt.show()\n\n\n\n\n\nThe optimization algorithm appears to be stuck and the reason is because the learning rate decayed far too quickly and became too small, trapping the optimizer in some local minimum. We can, instead, try to decay a bit slower by making our decay a smaller number. For example, let’s go with \\(10^{-3}\\).\n\nacc_vals, loss_vals, lr_vals = train(decay=1e-3)\n\nepoch: 0,                 acc : 0.327,                 loss:  1.099,                 lr : 1.0\nepoch: 1000,                 acc : 0.410,                 loss:  1.066,                 lr : 0.5002501250625312\nepoch: 2000,                 acc : 0.413,                 loss:  1.055,                 lr : 0.33344448149383127\nepoch: 3000,                 acc : 0.457,                 loss:  1.014,                 lr : 0.25006251562890724\nepoch: 4000,                 acc : 0.527,                 loss:  0.968,                 lr : 0.2000400080016003\nepoch: 5000,                 acc : 0.547,                 loss:  0.935,                 lr : 0.16669444907484582\nepoch: 6000,                 acc : 0.563,                 loss:  0.918,                 lr : 0.1428775539362766\nepoch: 7000,                 acc : 0.573,                 loss:  0.900,                 lr : 0.12501562695336915\nepoch: 8000,                 acc : 0.577,                 loss:  0.882,                 lr : 0.11112345816201799\nepoch: 9000,                 acc : 0.590,                 loss:  0.860,                 lr : 0.1000100010001\nepoch: 10000,                 acc : 0.603,                 loss:  0.845,                 lr : 0.09091735612328393\n\n\n\n\nShow the code\nplt.grid(True)\nepochs = np.linspace(0,10000,10001)\nplt.ylabel('Accuracy')\nplt.xlabel('Epochs')\nplt.plot(epochs,acc_vals)\nplt.show()\n\n\n\n\n\n\n\nShow the code\nplt.grid(True)\nplt.ylabel('Loss')\nplt.xlabel('Epochs')\nplt.plot(epochs,loss_vals)\nplt.show()\n\n\n\n\n\n\n\nShow the code\nplt.grid(True)\nplt.ylabel(\"Learning rate\")\nplt.xlabel(\"Epochs\")\nplt.plot(epochs, lr_vals)\nplt.show()"
  },
  {
    "objectID": "posts/optimization_algorithms/index.html#stochastic-gradient-descent-with-momentum",
    "href": "posts/optimization_algorithms/index.html#stochastic-gradient-descent-with-momentum",
    "title": "Optimization Algorithms",
    "section": "Stochastic Gradient Descent with Momentum",
    "text": "Stochastic Gradient Descent with Momentum\nMomentum proposes a small tweak to gradient descent. We give gradient descent a short-term memory. Let’s define the updated velocity \\(z^{k+1}\\) to be weighted and controlled by the mass \\(\\beta\\). When \\(\\beta\\) is high, we simply use the velocity from the last time, that is, we are entirely driven by momentum. When \\(\\beta=0\\), the momentum is zero.\n\\[\\begin{align*}\nz^{(k+1)} &= \\beta z^{(k)} + \\nabla f(w^{(k)})\\\\\nw^{k+1} &= w^k - \\alpha z^{k+1}\n\\end{align*}\\]\n\\(z^{(k+1)}\\) is called the velocity. It accumulates the past gradients similar to how a heavy ball rolling down the error function landscape integrates over past forces. To see what’s happening in more detail, we can recursively write out:\n\\[\\begin{align*}\nz^{(k)} &= \\beta z^{k-1} + \\nabla f(w^{(k-1)}) \\\\\n&= \\beta(\\beta z^{k-2} + \\nabla f(w^{(k-2)})) + \\nabla f(w^{(k-1)})\\\\\n&= \\beta^2 z^{k-2} + \\beta \\nabla f(w^{(k-2)}) + \\nabla f(w^{(k-1)})\\\\\n&= \\beta^2 (\\beta z^{k-3} + \\nabla f(w^{(k-3)}) ) + \\beta \\nabla f(w^{(k-2)}) + \\nabla f(w^{(k-1)})\\\\\n&= \\sum_{t=0}^{k} \\beta^t \\nabla f(w^{(k-1-t)})\n\\end{align*}\\]\nThe new gradient replacement no longer points into the direction of steepest descent on a particular instance any longer but rather in the direction of an exponentially weighted average of past gradients.\n\nThe dynamics of Momentum\nSince \\(\\nabla f(w^k) = Aw^k - b\\), the update on the quadratic is:\n\\[\\begin{align*}\nz^{k+1} &= \\beta z^k + (Aw^k - b)\\\\\nw^{k+1} &= w^k - \\alpha z^{k+1}\n\\end{align*}\\]\nWe go through the same motions as before with the change of basis \\((w^k - w^{*})=Qx^k\\) and \\(z^k = Q y^k\\) to yield the update rule:\n\\[\\begin{align*}\nQ y^{k+1} &= \\beta Q y^k + (AQx^k + Aw^* - b)\\\\\nQ y^{k+1} &= \\beta Q y^k + (AQx^k + AA^{-1}b - b)\\\\\nQ y^{k+1} &= \\beta Q y^k + Q\\Lambda Q^T Q x^k\\\\\nQ y^{k+1} &= \\beta Q y^k + Q\\Lambda x^k\\\\\ny^{k+1} &= \\beta y^k + \\Lambda x^k\n\\end{align*}\\]\nor equivalently:\n\\[\\begin{align*}\ny_i^{k+1} &= \\beta y_i^k + \\lambda_i x_i^k\n\\end{align*}\\]\nMoreover,\n\\[\\begin{align*}\nQx^{k+1} + w^* &= Qx^k + w^* - \\alpha Qy^{k+1}\\\\\nx^{k+1} &= x^k - \\alpha y^{k+1}\n\\end{align*}\\]\nor equivalently:\n\\[\\begin{align*}\nx_i^{k+1} &= x_i^k - \\alpha y_i^{k+1}\n\\end{align*}\\]\nThis lets us rewrite our iterates as:\n\\[\\begin{align*}\n\\begin{bmatrix}\ny_i^{k+1}\\\\\nx_i^{k+1}\n\\end{bmatrix} &=\n\\begin{bmatrix}\n\\beta y_i^k + \\lambda_i x_i^k\\\\\n(1-\\alpha\\lambda_i)x_i^k - \\alpha \\beta y_i^k\n\\end{bmatrix}\\\\\n&=\\begin{bmatrix}\n\\beta & \\lambda_i\\\\\n- \\alpha \\beta & (1-\\alpha\\lambda_i)\n\\end{bmatrix}\n\\begin{bmatrix}\ny_i^k\\\\\nx_i^k\n\\end{bmatrix}\n\\end{align*}\\]\nConsequently,\n\\[\\begin{align*}\n\\begin{bmatrix}\ny_i^k\\\\\nx_i^k\n\\end{bmatrix} = R^k \\begin{bmatrix}\ny_i^0\\\\\nx_i^0\n\\end{bmatrix},\\quad\nR = \\begin{bmatrix}\n\\beta & \\lambda_i\\\\\n- \\alpha \\beta & (1-\\alpha\\lambda_i)\n\\end{bmatrix}\n\\end{align*}\\]\nIn the case of \\(2 \\times 2\\) matrix, there is an elegant little known formula in terms of the eigenvalues of the matrix \\(R\\), \\(\\sigma_1\\) and \\(\\sigma_2\\):\n\\[\\begin{align*}\nR^k = \\begin{cases}\n\\sigma_1^k R_1 - \\sigma_2^k R_2 & \\sigma_1 \\neq \\sigma_2,\\\\\n\\sigma_1^k(kR\\sigma_1-(k-1)I) & \\sigma_1 = \\sigma_2\n\\end{cases}\n\\quad\nR_j = \\frac{R-\\sigma_j I}{\\sigma_1 - \\sigma_2}\n\\end{align*}\\]\nThe formula is rather complicated, but the takeway here is that it plays the exact same role the individual convergence rates \\((1-\\alpha \\lambda_i)\\) do in gradient descent. The convergence rate is therefore the slowest of the two rates, \\(\\max \\{|\\sigma_1|,|\\sigma_2|\\}\\).\nFor what values of \\(\\alpha\\) and \\(\\beta\\) does momentum converge? Since we need both \\(\\sigma_1\\) and \\(\\sigma_2\\) to converge, our convergence criterion is now \\(\\max \\{|\\sigma_1|,|\\sigma_2|\\} &lt; 1\\).\nIt can be shown that when we choose an optimal value of the parameters \\(\\alpha\\) and \\(\\beta\\), the convergence rate is proportional to:\n\\[\\begin{align*}\n\\frac{\\sqrt{\\kappa} - 1}{\\sqrt{\\kappa} + 1}\n\\end{align*}\\]\nWith barely a modicum of extra effort, we have square-rooted the condition number."
  },
  {
    "objectID": "posts/optimization_algorithms/index.html#adding-momentum-to-the-sgdoptimizer-class",
    "href": "posts/optimization_algorithms/index.html#adding-momentum-to-the-sgdoptimizer-class",
    "title": "Optimization Algorithms",
    "section": "Adding momentum to the SGDOptimizer class",
    "text": "Adding momentum to the SGDOptimizer class\nWe are now in a position to add momentum to the SGDOptimizer class.\n\nclass SGDOptimizer:\n\n    # Initial optimizer - set settings\n    # learning rate of 1. is default for this optimizer\n    def __init__(self, learning_rate=1.0, decay=0.0, momentum=0.0):\n        self.learning_rate = learning_rate\n        self.current_learning_rate = learning_rate\n        self.decay = decay\n        self.iterations = 0\n        self.beta = momentum\n\n    # Call once before any parameter updates\n    def pre_update_params(self):\n        if self.decay:\n            self.current_learning_rate = self.learning_rate * (\n                1.0 / (1.0 + self.decay * self.iterations)\n            )\n\n    # Update parameters\n    def update_params(self, layer):\n\n        # If we use momentum\n        if self.beta:\n\n            # If the layer does not contain momentum arrays, create them\n            # filled with zeros\n            if not hasattr(layer, \"weight_momentums\"):\n                layer.weight_momentums = np.zeros_like(layer.dloss_dweights)\n                # If there is no momentumm array for weights\n                # the array doesnt exist for biases yet either\n                layer.bias_momentums = np.zeros_like(layer.dloss_dbiases)\n\n            # Build weight updates with momentum - take previous\n            # updates multiplied by retain factor and update with\n            # with current gradients\n            # v[t+1] = \\beta * v[t] + \\alpha * dL/dw\n            weight_updates = (\n                self.beta * layer.weight_momentums\n                + self.current_learning_rate * layer.dloss_dweights\n            )\n            layer.weight_momentums = weight_updates\n\n            # Build bias updates\n            bias_updates = (\n                self.beta * layer.bias_momentums\n                + self.current_learning_rate * layer.dloss_dbiases\n            )\n            layer.bias_momentums = bias_updates\n        else:\n            # Vanilla SGD updates (as before momentum update)\n            weight_updates = self.current_learning_rate * layer.dloss_dweights\n            bias_updates = self.current_learning_rate * layer.dloss_dbiases\n\n        layer.weights -= weight_updates\n        layer.biases -= bias_updates\n\n    def post_update_params(self):\n        self.iterations += 1\n\nLet’s see an example illustrating how adding momentum changes the learning process. Keeping the same learning_rate=1.0 and decay=1e-3 from the previous training attempt and using a momentum of 0.50:\n\ndef train(decay, momentum):\n    # Create a dataset\n    X, y = spiral_data(samples=100, classes=3)\n\n    # Create a dense layer with 2 input features and 64 output values\n    dense1 = DenseLayer(2, 64)\n\n    # Create ReLU activation (to be used with the dense layer)\n    activation1 = ReLUActivation()\n\n    # Create second DenseLayer with 64 input features (as we take output of the\n    # previous layer here) and 3 output values\n    dense2 = DenseLayer(64, 3)\n\n    # Create Softmax classifier's combined loss and activation\n    loss_activation = CategoricalCrossEntropySoftmax()\n\n    # Create optimizer\n    optimizer = SGDOptimizer(learning_rate=1.0,decay=decay,momentum=momentum)\n\n    acc_vals = []\n    loss_vals = []\n    lr_vals = []\n\n    # Train in a loop\n    for epoch in range(10001):\n        # Perform a forward pass of our training data through this layer\n        dense1.forward(X)\n\n        # Perform a forward pass through the activation function\n        # takes the output of the first dense layer here\n        activation1.forward(dense1.output)\n\n        # Perform a forward pass through second DenseLayer\n        # takes the outputs of the activation function of first layer as inputs\n        dense2.forward(activation1.output)\n\n        # Perform a forward pass through the activation/loss function\n        # takes the output of the second DenseLayer here and returns the loss\n        loss = loss_activation.forward(dense2.output, y)\n\n        # Calculate accuracy from output of activation2 and targets\n        # Calculate values along the first axis\n        predictions = np.argmax(loss_activation.output, axis=1)\n        if len(y.shape) == 2:\n            y = np.argmax(y, axis=1)\n\n        accuracy = np.mean(predictions == y)\n\n        if epoch % 1000 == 0:\n            print(\n                f\"epoch: {epoch}, \\\n                acc : {accuracy:.3f}, \\\n                loss: {loss: .3f}, \\\n                lr : {optimizer.current_learning_rate}\"\n            )\n\n        acc_vals.append(accuracy)\n        loss_vals.append(loss)\n        lr_vals.append(optimizer.current_learning_rate)\n\n        # Backward pass\n        loss_activation.backward(loss_activation.output, y)\n        dense2.backward(loss_activation.dloss_dz)\n        activation1.backward(dense2.dloss_dinputs)\n        dense1.backward(activation1.dloss_dz)\n\n        # Update the weights and the biases\n        optimizer.pre_update_params()\n        optimizer.update_params(dense1)\n        optimizer.update_params(dense2)\n        optimizer.post_update_params()\n\n    return acc_vals, loss_vals, lr_vals\n\n\nacc_vals, loss_vals, lr_vals = train(decay=1e-3, momentum=0.5)\n\nepoch: 0,                 acc : 0.337,                 loss:  1.099,                 lr : 1.0\nepoch: 1000,                 acc : 0.510,                 loss:  0.978,                 lr : 0.5002501250625312\nepoch: 2000,                 acc : 0.557,                 loss:  0.879,                 lr : 0.33344448149383127\nepoch: 3000,                 acc : 0.580,                 loss:  0.771,                 lr : 0.25006251562890724\nepoch: 4000,                 acc : 0.630,                 loss:  0.735,                 lr : 0.2000400080016003\nepoch: 5000,                 acc : 0.657,                 loss:  0.670,                 lr : 0.16669444907484582\nepoch: 6000,                 acc : 0.753,                 loss:  0.573,                 lr : 0.1428775539362766\nepoch: 7000,                 acc : 0.783,                 loss:  0.522,                 lr : 0.12501562695336915\nepoch: 8000,                 acc : 0.790,                 loss:  0.481,                 lr : 0.11112345816201799\nepoch: 9000,                 acc : 0.807,                 loss:  0.441,                 lr : 0.1000100010001\nepoch: 10000,                 acc : 0.843,                 loss:  0.401,                 lr : 0.09091735612328393\n\n\nThe model achieved the lowest loss and the highest accuracy that we’ve seen so far. Can we do better? Sure, we can! Let’s try to set the momentum to \\(0.9\\):\n\nacc_vals, loss_vals, lr_vals = train(decay=1e-3, momentum=0.9)\n\nepoch: 0,                 acc : 0.340,                 loss:  1.099,                 lr : 1.0\nepoch: 1000,                 acc : 0.763,                 loss:  0.463,                 lr : 0.5002501250625312\nepoch: 2000,                 acc : 0.790,                 loss:  0.407,                 lr : 0.33344448149383127\nepoch: 3000,                 acc : 0.803,                 loss:  0.396,                 lr : 0.25006251562890724\nepoch: 4000,                 acc : 0.813,                 loss:  0.391,                 lr : 0.2000400080016003\nepoch: 5000,                 acc : 0.813,                 loss:  0.386,                 lr : 0.16669444907484582\nepoch: 6000,                 acc : 0.813,                 loss:  0.384,                 lr : 0.1428775539362766\nepoch: 7000,                 acc : 0.813,                 loss:  0.375,                 lr : 0.12501562695336915\nepoch: 8000,                 acc : 0.833,                 loss:  0.332,                 lr : 0.11112345816201799\nepoch: 9000,                 acc : 0.880,                 loss:  0.285,                 lr : 0.1000100010001\nepoch: 10000,                 acc : 0.880,                 loss:  0.277,                 lr : 0.09091735612328393"
  },
  {
    "objectID": "posts/optimization_algorithms/index.html#adagrad",
    "href": "posts/optimization_algorithms/index.html#adagrad",
    "title": "Optimization Algorithms",
    "section": "AdaGrad",
    "text": "AdaGrad\nIn real-world datasets, some input features are sparse and some features are dense. If we use the same learning rate \\(\\alpha\\) for all the weights, parameters associated with sparse features receive meaningful updates only when these features occur. Given a decreasing learning rate, we might end up with a situation where parameters for dense features converge rather quickly to their optimal values, whereas for sparse features, we are still short of observing them sufficiently frequently before their optimal values can be determined. In other words, the learning rate decreases too slowly for dense features and too quickly for sparse features.\nThe update rule for adaptive step-size gradient descent is:\n\\[\\begin{align*}\n\\mathbf{g}_t &= \\frac{\\partial \\mathcal L}{\\partial \\mathbf{w}}\\\\\n\\mathbf{s}_t &= \\mathbf{s}_{t-1} + \\mathbf{g}_{t}^2 \\\\\n\\mathbf{w}_t &= \\mathbf{w}_{t-1} + \\frac{\\alpha}{\\sqrt{\\mathbf{s}_t+\\epsilon}}\\cdot \\mathbf{g}_t\n\\end{align*}\\]\nHere the operations are applied coordinate-wise. So, the jacobian \\(\\mathbf{g}_t^2\\) has entries \\(g_t^2\\). As before, \\(\\alpha\\) is the learning rate and \\(\\epsilon\\) is an additive constant that ensures that we do not divide by \\(0\\). Thus, the learning rate for features whose weights receive frequent updates is decreased faster, whilst for those features, whose weights receive infrequent updates, it is decreased slower.\nThus, Adagrad decreases the learning-rate dynamically on a per-coordinate basis.\n\nclass AdagradOptimizer:\n\n    # Initial optimizer - set settings\n    # learning rate of 1. is default for this optimizer\n    def __init__(self, learning_rate=1.0, decay=0.0, epsilon=1e-7):\n        self.learning_rate = learning_rate\n        self.current_learning_rate = learning_rate\n        self.decay = decay\n        self.iterations = 0\n        self.epsilon = epsilon\n\n    # Call once before any parameter updates\n    def pre_update_params(self):\n        if self.decay:\n            self.current_learning_rate = self.learning_rate * (\n                1.0 / (1.0 + self.decay * self.iterations)\n            )\n\n    # Update parameters\n    def update_params(self, layer):\n        if not hasattr(layer, \"weight_cache\"):\n            layer.weight_cache = np.zeros_like(layer.weights)\n            layer.bias_cache = np.zeros_like(layer.biases)\n\n        # Update cache with squared current gradients\n        layer.weight_cache += layer.dloss_dweights**2\n        layer.bias_cache += layer.dloss_dbiases**2\n\n        # Vanilla SGD parameter update + normalization\n        # with square rooted cache\n        layer.weights += (\n            self.current_learning_rate\n            * layer.dloss_dweights\n            / (np.sqrt(layer.weight_cache) + self.epsilon)\n        )\n        layer.biases += (\n            self.current_learning_rate\n            * layer.dloss_dbiases\n            / (np.sqrt(layer.bias_cache) + self.epsilon)\n        )\n\n    def post_update_params(self):\n        self.iterations += 1"
  },
  {
    "objectID": "posts/optimization_algorithms/index.html#rmsprop",
    "href": "posts/optimization_algorithms/index.html#rmsprop",
    "title": "Optimization Algorithms",
    "section": "RMSProp",
    "text": "RMSProp\nOne of the key issues of Adagrad is that the learning rate decreases at a predefined schedule essentially at a rate proportional \\(\\frac{1}{\\sqrt{t}}\\). While this is generally appropriate for convex problems, it might not be ideal for nonconvex ones, such as those encountered in deep learning. Yet, the coordinate-wise adaptivity of Adagrad is highly desirable as a preconditioner.\nTieleman and Hinton(2012) have proposed the RMSProp algorithm as a simple fix to decouple the rate scheduling from coordinate adaptive learning rates. The issue is that the squares of the gradient \\(\\mathbf{g}_t\\) keeps accumulating into the state vector \\(\\mathbf{s}_t = \\mathbf{s}_{t-1} + \\mathbf{g}_t^2\\). As a result, \\(\\mathbf{s}_t\\) keeps on growing without bounds, essentially linearly as the algorithm converges.\n\nThe Algorithm\nThe update rule for the RMSProp algorithm is as follows:\n\\[\\begin{align*}\n\\mathbf{s}_t &= \\gamma \\mathbf{s}_{t-1} + (1- \\gamma)\\mathbf{g}_t^2\\\\\n\\mathbf{x}_t &= \\mathbf{x}_{t-1} - \\frac{\\alpha}{\\sqrt{\\mathbf{s}_t + \\epsilon}}\\odot \\mathbf{g}_t\n\\end{align*}\\]"
  },
  {
    "objectID": "posts/pricing-under-collateral/index.html",
    "href": "posts/pricing-under-collateral/index.html",
    "title": "Collateralized Discounting",
    "section": "",
    "text": "In the past, standard derivatives pricing theory assumed the existence of a risk-free rate for derivatives discounting. Until the global financial crisis(GFC), this assumption worked well, but has since been replaced by Collateral adjusted valuation(CAV). Collateralized discounting is standard practice on derivatives trading desks.\nA risk-neutral measure can still be defined and much of the pricing technology developed in the traditional setting can be reused.\nThe theoretical foundations of collateralized discounting are the papers Cooking with collateral and Funding beyond Discounting by Piterbarg. I summarize the main arguments here.\n\n\n\nWe replicate the derivative worth \\(V(t)\\), by an amount \\(\\theta_1\\) of the underlying \\(X\\), an amount \\(\\theta_2\\) of funding account \\(B_f(t)\\) and an amount \\(\\theta_3\\) of collateral account \\(B_c(t)\\). The value of the portfolio at time \\(t\\) is:\n\\[\n\\begin{align*}\nV(t) = \\theta_1(t) X(t) + \\theta_2(t) B_f(t) + \\theta_3(t) B_c(t)\n\\end{align*}\n\\tag{1}\\]\nThe self-financing assumption implies that:\n\\[\ndV(t) = \\theta_1 dX_t + \\theta_2 dB_f(t) + \\theta_3 dB_c(t)\n\\tag{2}\\]\nAssume that the dynamics of the three assets is as follows:\n\\[\n\\begin{align*}\ndX(t) &= \\mu^{\\mathbb{P}}(t) X(t) dt + \\sigma(t)X(t)dW^\\mathbb{P}(t)\\\\\ndB_f(t) &= r_f(t)B_f(t) dt\\\\\ndB_c(t) &= r_c(t)B_c(t) dt\n\\end{align*}\n\\tag{3}\\]\nThe derivative’s price dynamics \\(dV(t,X_t)\\) is obtained by the Ito’s lemma as:\n\\[\n\\begin{aligned}\ndV( t,X) & =\\frac{\\partial V}{\\partial t} dt+\\frac{\\partial V}{\\partial X} dX_{t} +\\frac{1}{2}\\frac{\\partial ^{2} V}{\\partial X^{2}}( dX_{t})^{2}\\\\\n& =\\frac{\\partial V}{\\partial t} dt+\\frac{\\partial V}{\\partial X}\\left( \\mu ^{\\mathbb{P}} X_{t} dt+\\sigma _{t} X_{t} dW_{t}^{\\mathbb{P}}\\right) +\\frac{1}{2} \\sigma _{t}^{2} X_{t}^{2} dt\\\\\n& =\\left(\\frac{\\partial V}{\\partial t} +\\mu ^{\\mathbb{P}} X_{t}\\frac{\\partial V}{\\partial X} +\\frac{1}{2} \\sigma _{t}^{2} X_{t}^{2}\\frac{\\partial ^{2} V}{\\partial X^{2}}\\right) dt+\\sigma _{t} X_{t}\\frac{\\partial V}{\\partial X} dW_{t}^{\\mathbb{P}}\n\\end{aligned}\n\\tag{4}\\]\nSubstituting Equation 3 and Equation 4 in Equation 2, we have:\n\\[\n\\begin{aligned}\n\\left(\\frac{\\partial V}{\\partial t} +\\mu ^{\\mathbb{P}} X_{t}\\frac{\\partial V}{\\partial X} +\\frac{1}{2} \\sigma _{t}^{2} X_{t}^{2}\\frac{\\partial ^{2} V}{\\partial X^{2}}\\right) dt+\\sigma _{t} X_{t}\\frac{\\partial V}{\\partial X} dW_{t}^{\\mathbb{P}} & =\\theta _{1}\\left( \\mu ^{\\mathbb{P}} X_{t} dt+\\sigma _{t} X_{t} dW_{t}^{\\mathbb{P}}\\right)\\\\\n& +\\theta _{2}( r_{f}( t) B_{f}( t) dt) +\\theta _{3}( r_{c}( t) B_{c}( t) dt)\n\\end{aligned}\n\\]\nThe perfect collateral condition implies that the collateral held at any time equals the mark-to-market(MtM) value of the derivative. So, \\(B_c(t) = V(t)\\). So, we have:\n\\[\n\\begin{aligned}\n\\left(\\frac{\\partial V}{\\partial t} +\\mu ^{\\mathbb{P}} X_{t}\\frac{\\partial V}{\\partial X} +\\frac{1}{2} \\sigma _{t}^{2} X_{t}^{2}\\frac{\\partial ^{2} V}{\\partial X^{2}}\\right) dt+\\sigma _{t} X_{t}\\frac{\\partial V}{\\partial X} dW_{t}^{\\mathbb{P}} & =\\theta _{1}\\left( \\mu ^{\\mathbb{P}} X_{t} dt+\\sigma _{t} X_{t} dW_{t}^{\\mathbb{P}}\\right)\\\\\n& +\\theta _{2}( r_{f}( t) B_{f}( t) dt) +\\theta _{3}( r_{c}( t) V( t) dt)\n\\end{aligned}\n\\tag{5}\\]\nSetting \\(\\theta_3(t) = 1\\) in Equation 1, we get :\n\\[\n\\begin{align*}\n\\theta_2(t)B_f(t) = \\theta_1(t)X(t)\n\\end{align*}\n\\tag{6}\\]\nSubstituting Equation 6 in Equation 5, we get:\n\\[\n\\begin{align*}\n\\left(\\frac{\\partial V}{\\partial t} +\\mu ^{\\mathbb{P}} X_{t}\\frac{\\partial V}{\\partial X} +\\frac{1}{2} \\sigma _{t}^{2} X_{t}^{2}\\frac{\\partial ^{2} V}{\\partial X^{2}}\\right) dt+\\sigma _{t} X_{t}\\frac{\\partial V}{\\partial X} dW_{t}^{\\mathbb{P}} & =\\theta _{1}\\left( \\mu ^{\\mathbb{P}} X_{t} dt+\\sigma _{t} X_{t} dW_{t}^{\\mathbb{P}}\\right)\\\\\n& -\\theta _{1}( r_{f}( t) X( t) dt) +( r_{c}( t) V( t) dt)\n\\end{align*}\n\\]\nRe-arranging the terms, we get:\n\\[\n\\begin{align*}\n\\left(\\frac{\\partial V}{\\partial t} -\\mu ^{\\mathbb{P}} X_{t}\\left( \\theta _{1} -\\frac{\\partial V}{\\partial X}\\right) +r_{f}( t) \\theta _{1}( t) X( t) +\\frac{1}{2} \\sigma _{t}^{2} X_{t}^{2}\\frac{\\partial ^{2} V}{\\partial X^{2}}\\right) dt & =\\sigma _{t} X_{t}\\left( \\theta _{1}( t) -\\frac{\\partial V}{\\partial X}\\right) dW_{t}^{\\mathbb{P}}\\\\\n& +( r_{c}( t) V( t) dt)\n\\end{align*}\n\\]\nSetting \\(\\theta_(t) = \\frac{\\partial V(t)}{\\partial X}\\), we get:\n\\[\n\\begin{align*}\n\\left(\\frac{\\partial V}{\\partial t} +r_{f}( t) X( t)\\frac{\\partial V}{\\partial X} +\\frac{1}{2} \\sigma _{t}^{2} X_{t}^{2}\\frac{\\partial ^{2} V}{\\partial X^{2}}\\right) dt & =r_{c}( t) V( t) dt\n\\end{align*}\n\\]\nor equivalently:\n\\[\n\\begin{align*}\n\\left(\\frac{\\partial V}{\\partial t} +r_{f}( t) X( t)\\frac{\\partial V}{\\partial X} +\\frac{1}{2} \\sigma _{t}^{2} X_{t}^{2}\\frac{\\partial ^{2} V}{\\partial X^{2}}\\right) & =r_{c}( t) V( t)\n\\end{align*}\n\\tag{7}\\]\nThis is the pricing PDE. Applying Feynman-Kac, the solution to this PDE for the boundary condition:\n\\[\nV(T,x) = g(x)\n\\]\nhas the stochastic representation:\n\\[\nV(t,x) = \\mathbb{E}^{\\mathbb{Q}^f}[e^{-\\int_t^T r_c(t) dt } g(X_T)|\\mathcal{F}_t]\n\\tag{8}\\]\nwhere \\(\\mathbb{Q}^f\\) is the measure associated with the funding account numeraire \\(B_f(t)\\) and the underlying risky asset has the dynamics:\n\\[\ndX_t = r_f(t)X(t)dt+ \\sigma(t)X(t)dW^{\\mathbb{Q}^f}(t)\n\\]"
  },
  {
    "objectID": "posts/pricing-under-collateral/index.html#introduction",
    "href": "posts/pricing-under-collateral/index.html#introduction",
    "title": "Collateralized Discounting",
    "section": "",
    "text": "In the past, standard derivatives pricing theory assumed the existence of a risk-free rate for derivatives discounting. Until the global financial crisis(GFC), this assumption worked well, but has since been replaced by Collateral adjusted valuation(CAV). Collateralized discounting is standard practice on derivatives trading desks.\nA risk-neutral measure can still be defined and much of the pricing technology developed in the traditional setting can be reused.\nThe theoretical foundations of collateralized discounting are the papers Cooking with collateral and Funding beyond Discounting by Piterbarg. I summarize the main arguments here."
  },
  {
    "objectID": "posts/pricing-under-collateral/index.html#pricing-under-collateral",
    "href": "posts/pricing-under-collateral/index.html#pricing-under-collateral",
    "title": "Collateralized Discounting",
    "section": "",
    "text": "We replicate the derivative worth \\(V(t)\\), by an amount \\(\\theta_1\\) of the underlying \\(X\\), an amount \\(\\theta_2\\) of funding account \\(B_f(t)\\) and an amount \\(\\theta_3\\) of collateral account \\(B_c(t)\\). The value of the portfolio at time \\(t\\) is:\n\\[\n\\begin{align*}\nV(t) = \\theta_1(t) X(t) + \\theta_2(t) B_f(t) + \\theta_3(t) B_c(t)\n\\end{align*}\n\\tag{1}\\]\nThe self-financing assumption implies that:\n\\[\ndV(t) = \\theta_1 dX_t + \\theta_2 dB_f(t) + \\theta_3 dB_c(t)\n\\tag{2}\\]\nAssume that the dynamics of the three assets is as follows:\n\\[\n\\begin{align*}\ndX(t) &= \\mu^{\\mathbb{P}}(t) X(t) dt + \\sigma(t)X(t)dW^\\mathbb{P}(t)\\\\\ndB_f(t) &= r_f(t)B_f(t) dt\\\\\ndB_c(t) &= r_c(t)B_c(t) dt\n\\end{align*}\n\\tag{3}\\]\nThe derivative’s price dynamics \\(dV(t,X_t)\\) is obtained by the Ito’s lemma as:\n\\[\n\\begin{aligned}\ndV( t,X) & =\\frac{\\partial V}{\\partial t} dt+\\frac{\\partial V}{\\partial X} dX_{t} +\\frac{1}{2}\\frac{\\partial ^{2} V}{\\partial X^{2}}( dX_{t})^{2}\\\\\n& =\\frac{\\partial V}{\\partial t} dt+\\frac{\\partial V}{\\partial X}\\left( \\mu ^{\\mathbb{P}} X_{t} dt+\\sigma _{t} X_{t} dW_{t}^{\\mathbb{P}}\\right) +\\frac{1}{2} \\sigma _{t}^{2} X_{t}^{2} dt\\\\\n& =\\left(\\frac{\\partial V}{\\partial t} +\\mu ^{\\mathbb{P}} X_{t}\\frac{\\partial V}{\\partial X} +\\frac{1}{2} \\sigma _{t}^{2} X_{t}^{2}\\frac{\\partial ^{2} V}{\\partial X^{2}}\\right) dt+\\sigma _{t} X_{t}\\frac{\\partial V}{\\partial X} dW_{t}^{\\mathbb{P}}\n\\end{aligned}\n\\tag{4}\\]\nSubstituting Equation 3 and Equation 4 in Equation 2, we have:\n\\[\n\\begin{aligned}\n\\left(\\frac{\\partial V}{\\partial t} +\\mu ^{\\mathbb{P}} X_{t}\\frac{\\partial V}{\\partial X} +\\frac{1}{2} \\sigma _{t}^{2} X_{t}^{2}\\frac{\\partial ^{2} V}{\\partial X^{2}}\\right) dt+\\sigma _{t} X_{t}\\frac{\\partial V}{\\partial X} dW_{t}^{\\mathbb{P}} & =\\theta _{1}\\left( \\mu ^{\\mathbb{P}} X_{t} dt+\\sigma _{t} X_{t} dW_{t}^{\\mathbb{P}}\\right)\\\\\n& +\\theta _{2}( r_{f}( t) B_{f}( t) dt) +\\theta _{3}( r_{c}( t) B_{c}( t) dt)\n\\end{aligned}\n\\]\nThe perfect collateral condition implies that the collateral held at any time equals the mark-to-market(MtM) value of the derivative. So, \\(B_c(t) = V(t)\\). So, we have:\n\\[\n\\begin{aligned}\n\\left(\\frac{\\partial V}{\\partial t} +\\mu ^{\\mathbb{P}} X_{t}\\frac{\\partial V}{\\partial X} +\\frac{1}{2} \\sigma _{t}^{2} X_{t}^{2}\\frac{\\partial ^{2} V}{\\partial X^{2}}\\right) dt+\\sigma _{t} X_{t}\\frac{\\partial V}{\\partial X} dW_{t}^{\\mathbb{P}} & =\\theta _{1}\\left( \\mu ^{\\mathbb{P}} X_{t} dt+\\sigma _{t} X_{t} dW_{t}^{\\mathbb{P}}\\right)\\\\\n& +\\theta _{2}( r_{f}( t) B_{f}( t) dt) +\\theta _{3}( r_{c}( t) V( t) dt)\n\\end{aligned}\n\\tag{5}\\]\nSetting \\(\\theta_3(t) = 1\\) in Equation 1, we get :\n\\[\n\\begin{align*}\n\\theta_2(t)B_f(t) = \\theta_1(t)X(t)\n\\end{align*}\n\\tag{6}\\]\nSubstituting Equation 6 in Equation 5, we get:\n\\[\n\\begin{align*}\n\\left(\\frac{\\partial V}{\\partial t} +\\mu ^{\\mathbb{P}} X_{t}\\frac{\\partial V}{\\partial X} +\\frac{1}{2} \\sigma _{t}^{2} X_{t}^{2}\\frac{\\partial ^{2} V}{\\partial X^{2}}\\right) dt+\\sigma _{t} X_{t}\\frac{\\partial V}{\\partial X} dW_{t}^{\\mathbb{P}} & =\\theta _{1}\\left( \\mu ^{\\mathbb{P}} X_{t} dt+\\sigma _{t} X_{t} dW_{t}^{\\mathbb{P}}\\right)\\\\\n& -\\theta _{1}( r_{f}( t) X( t) dt) +( r_{c}( t) V( t) dt)\n\\end{align*}\n\\]\nRe-arranging the terms, we get:\n\\[\n\\begin{align*}\n\\left(\\frac{\\partial V}{\\partial t} -\\mu ^{\\mathbb{P}} X_{t}\\left( \\theta _{1} -\\frac{\\partial V}{\\partial X}\\right) +r_{f}( t) \\theta _{1}( t) X( t) +\\frac{1}{2} \\sigma _{t}^{2} X_{t}^{2}\\frac{\\partial ^{2} V}{\\partial X^{2}}\\right) dt & =\\sigma _{t} X_{t}\\left( \\theta _{1}( t) -\\frac{\\partial V}{\\partial X}\\right) dW_{t}^{\\mathbb{P}}\\\\\n& +( r_{c}( t) V( t) dt)\n\\end{align*}\n\\]\nSetting \\(\\theta_(t) = \\frac{\\partial V(t)}{\\partial X}\\), we get:\n\\[\n\\begin{align*}\n\\left(\\frac{\\partial V}{\\partial t} +r_{f}( t) X( t)\\frac{\\partial V}{\\partial X} +\\frac{1}{2} \\sigma _{t}^{2} X_{t}^{2}\\frac{\\partial ^{2} V}{\\partial X^{2}}\\right) dt & =r_{c}( t) V( t) dt\n\\end{align*}\n\\]\nor equivalently:\n\\[\n\\begin{align*}\n\\left(\\frac{\\partial V}{\\partial t} +r_{f}( t) X( t)\\frac{\\partial V}{\\partial X} +\\frac{1}{2} \\sigma _{t}^{2} X_{t}^{2}\\frac{\\partial ^{2} V}{\\partial X^{2}}\\right) & =r_{c}( t) V( t)\n\\end{align*}\n\\tag{7}\\]\nThis is the pricing PDE. Applying Feynman-Kac, the solution to this PDE for the boundary condition:\n\\[\nV(T,x) = g(x)\n\\]\nhas the stochastic representation:\n\\[\nV(t,x) = \\mathbb{E}^{\\mathbb{Q}^f}[e^{-\\int_t^T r_c(t) dt } g(X_T)|\\mathcal{F}_t]\n\\tag{8}\\]\nwhere \\(\\mathbb{Q}^f\\) is the measure associated with the funding account numeraire \\(B_f(t)\\) and the underlying risky asset has the dynamics:\n\\[\ndX_t = r_f(t)X(t)dt+ \\sigma(t)X(t)dW^{\\mathbb{Q}^f}(t)\n\\]"
  },
  {
    "objectID": "posts/python-built-in-types/index.html",
    "href": "posts/python-built-in-types/index.html",
    "title": "Python lists, dicts, tuples",
    "section": "",
    "text": "Python dicts are a collection of key-value pairs implemented as hash tables. dicts can be updated in place and dictionaries can grow and shrink as needed."
  },
  {
    "objectID": "posts/python-built-in-types/index.html#dict-in-python",
    "href": "posts/python-built-in-types/index.html#dict-in-python",
    "title": "Python lists, dicts, tuples",
    "section": "",
    "text": "Python dicts are a collection of key-value pairs implemented as hash tables. dicts can be updated in place and dictionaries can grow and shrink as needed."
  },
  {
    "objectID": "posts/python-built-in-types/index.html#flattening-a-dict-of-dicts",
    "href": "posts/python-built-in-types/index.html#flattening-a-dict-of-dicts",
    "title": "Python lists, dicts, tuples",
    "section": "Flattening a dict of dicts",
    "text": "Flattening a dict of dicts\n\nquote_types = {\n    'Bids' : {\n        1 : [10, 45],\n        2 : [25, 47.5],\n        3 : [30, 49.5]\n    },\n    'Offers' : {\n        1 : [30, 50.5],\n        2 : [25, 52.5],\n        3 : [10, 55]\n    }\n}\n\ndict_of_height_3 ={\n    'a' : {\n        'b' :{\n            'c' : 1,\n            'd' : 2,\n        },\n        'e' : {\n            'f' : 3,\n            'g' : 4,\n        }\n    },\n    'h' : {\n        'i' : {\n            'j' : 5,\n            'k' : 6,\n        },\n        'l' : {\n            'm' : 7,\n            'n' : 8,\n        },\n    }\n}\n\ndef flatten_dict(d : dict, parent_key = '', sep = '_'):\n    result = {}\n    for k,v in d.items():\n        if (type(v) is dict):\n            # Recursively flatten the child element\n            child_flat_dict = flatten_dict(v, parent_key=str(k))\n\n            # We now have a dict-of-dicts of height 2\n            for child_k, child_v in child_flat_dict.items():\n                key = parent_key + sep + child_k if parent_key &gt; '' else child_k\n                result[key] = child_v\n        else:\n            key = parent_key + sep + str(k)\n            result[key] = v\n            \n    return result\n\nprint(\"flattening quotes\\n\")\nflatten_dict(quote_types)\n\nflattening quotes\n\n\n\n{'Bids_1': [10, 45],\n 'Bids_2': [25, 47.5],\n 'Bids_3': [30, 49.5],\n 'Offers_1': [30, 50.5],\n 'Offers_2': [25, 52.5],\n 'Offers_3': [10, 55]}\n\n\n\nprint(\"dict_of_height_3\\n\")\nflatten_dict(dict_of_height_3)\n\ndict_of_height_3\n\n\n\n{'a_b_c': 1,\n 'a_b_d': 2,\n 'a_e_f': 3,\n 'a_e_g': 4,\n 'h_i_j': 5,\n 'h_i_k': 6,\n 'h_l_m': 7,\n 'h_l_n': 8}"
  },
  {
    "objectID": "posts/python-built-in-types/index.html#list-in-python",
    "href": "posts/python-built-in-types/index.html#list-in-python",
    "title": "Python lists, dicts, tuples",
    "section": "list() in Python",
    "text": "list() in Python\nlists are mutable sequences typically used to store collections of homogenous items.\nlist.append(x:Any)-&gt;None adds a single-item to the end of the list, in-place. list.extend(Iterable)-&gt;None extends the list in-place by appending all items from the iterable, and returns None.\nlist.insert(i,x)-&gt;None inserts an element x at the given index i. list.remove(x) removes the first item from the list who value is equal to x. list.pop([i]) removes the item at the given position in the list and returns it. If no index is specified, list.pop() removes and returns the last element in the list."
  },
  {
    "objectID": "posts/python-built-in-types/index.html#reverse-a-list",
    "href": "posts/python-built-in-types/index.html#reverse-a-list",
    "title": "Python lists, dicts, tuples",
    "section": "Reverse a list",
    "text": "Reverse a list\n\nfrom typing import List\nl = [1, 2, 3, 4, 5]\n\nl.reverse()  # reverse in place\nprint(l)\n\n[5, 4, 3, 2, 1]\n\n\n\n# recursive solution\ndef reverse(l : List, acc : List = []) -&gt; List:\n    if(len(l) == 0):\n        return acc\n    \n    if(len(l) == 1):\n        l.extend(acc)\n        return l\n    \n    new_acc = [l[0]]\n    new_acc.extend(acc)\n    return reverse(l[1:], new_acc)\n\ndef reverse_iter(l : List) -&gt; List:\n    result = []\n    for element in l:\n        result.insert(0, element)\n\n    return result\n\nitems = [2, 17, 42, 15, 3]\nreverse(items)\n\n[3, 15, 42, 17, 2]"
  },
  {
    "objectID": "posts/python-built-in-types/index.html#determine-if-the-list-is-a-palindrome",
    "href": "posts/python-built-in-types/index.html#determine-if-the-list-is-a-palindrome",
    "title": "Python lists, dicts, tuples",
    "section": "Determine if the list is a palindrome",
    "text": "Determine if the list is a palindrome\n\nfrom typing import List\ndef is_palindrome(l : List) -&gt; bool:\n    n = len(l)\n    i = 0\n    j = n - 1\n\n    while(i &lt;= j):\n        if(l[i] != l[j]):\n            return False\n        \n        i += 1\n        j = n - i - 1\n\n    return True\n\nprint(is_palindrome([1, 2, 3, 2, 1]))\nprint(is_palindrome([1, 2, 2, 1]))\n\nTrue\nTrue"
  },
  {
    "objectID": "posts/python-built-in-types/index.html#flatten-a-nested-list",
    "href": "posts/python-built-in-types/index.html#flatten-a-nested-list",
    "title": "Python lists, dicts, tuples",
    "section": "Flatten a nested list",
    "text": "Flatten a nested list\n\ndef flatten_list(l : List):\n    result = []\n    for element in l:\n        if (type(element) is list):\n            simple_list = flatten_list(element)\n            result.extend(simple_list)\n        else:\n            result.append(element)\n    return result\n\nflatten_list(['a', ['b', ['c', 'd'], 'e']])\n\n['a', 'b', 'c', 'd', 'e']"
  },
  {
    "objectID": "posts/python-built-in-types/index.html#eliminate-consecutive-duplicates-of-list-elements",
    "href": "posts/python-built-in-types/index.html#eliminate-consecutive-duplicates-of-list-elements",
    "title": "Python lists, dicts, tuples",
    "section": "Eliminate consecutive duplicates of list elements",
    "text": "Eliminate consecutive duplicates of list elements\nAlways use key in my_dict directly instead of key in my_dict.keys(), if you want to check the existence of a key in a dict. That will use the dictionary’s \\(O(1)\\) hashing rather than \\(O(n)\\). my_dict.keys() returns a list of keys.\n\nfrom typing import List\n\n# Remove duplicates from a nested-list while preserving the\n# the structure\ndef array_unique(l : List, unique_elements : dict={}) -&gt; (List,dict):\n    result = []\n    for element in l:\n        if type(element) is list:\n            # get the list of unique children and append it to result\n            child_list, unique_elements = array_unique(element, unique_elements=unique_elements)\n            result.append(child_list)\n        else:\n            if element in unique_elements:\n                continue\n            else:\n                result.append(element)\n                unique_elements[element] = True\n\n    return result, unique_elements\n\nmy_array = [1, [1, 2, [1, 2, 3], 4, 5], [5, 6], 7]\nresult, _ = array_unique(my_array)\nresult\n\n[1, [2, [3], 4, 5], [6], 7]"
  },
  {
    "objectID": "posts/python-built-in-types/index.html#list-comprehensions",
    "href": "posts/python-built-in-types/index.html#list-comprehensions",
    "title": "Python lists, dicts, tuples",
    "section": "List comprehensions",
    "text": "List comprehensions\n\nsquares = [x**2 for x in range(5)]\nprint(squares)\ncombs = [(x,y,z) for x in range(2) for y in range(2) for z in range(2)]\nprint(combs)\n\n[0, 1, 4, 9, 16]\n[(0, 0, 0), (0, 0, 1), (0, 1, 0), (0, 1, 1), (1, 0, 0), (1, 0, 1), (1, 1, 0), (1, 1, 1)]"
  },
  {
    "objectID": "posts/python-built-in-types/index.html#nested-list-comprehensions",
    "href": "posts/python-built-in-types/index.html#nested-list-comprehensions",
    "title": "Python lists, dicts, tuples",
    "section": "Nested List comprehensions",
    "text": "Nested List comprehensions\n\nmatrix = [\n    [1, 2, 3, 4],\n    [5, 6, 7, 8],\n    [9, 10, 11, 12],\n]\n\n# Take the transpose of a matrix\n[[row[i] for row in matrix]for i in range(4)]\n\n[[1, 5, 9], [2, 6, 10], [3, 7, 11], [4, 8, 12]]"
  },
  {
    "objectID": "posts/python-built-in-types/index.html#tuples-in-python",
    "href": "posts/python-built-in-types/index.html#tuples-in-python",
    "title": "Python lists, dicts, tuples",
    "section": "tuples in Python",
    "text": "tuples in Python\nlists are mutable wherease tuples are immutable types. The contents of a tuple cannot be modified at run-time. They usually store a heterogenous collection of items."
  },
  {
    "objectID": "posts/python-built-in-types/index.html#sets-in-python",
    "href": "posts/python-built-in-types/index.html#sets-in-python",
    "title": "Python lists, dicts, tuples",
    "section": "sets in Python",
    "text": "sets in Python\nPython also includes a data-type for sets. A set is an unordered collection with no duplicate elements. Basic uses include membership testing and eliminating duplicate entries. Set objects also support mathematical operations such as union, intersection, difference and symmetric difference.\nCurly braces or set() is used to create sets.\n\na = set('abracadabra')\nb = set('alcazam')\n\nprint(a)\nprint(a - b)\nprint(a | b)\nprint(a & b)\n\n{'a', 'd', 'c', 'b', 'r'}\n{'d', 'b', 'r'}\n{'m', 'a', 'd', 'c', 'z', 'l', 'b', 'r'}\n{'c', 'a'}"
  },
  {
    "objectID": "posts/python-built-in-types/index.html#python-3.8-walrus-operator",
    "href": "posts/python-built-in-types/index.html#python-3.8-walrus-operator",
    "title": "Python lists, dicts, tuples",
    "section": "Python 3.8 walrus := operator",
    "text": "Python 3.8 walrus := operator\n:= assigns a value to a variable and simultaneous returns the value. For example:\n\nmy_list = [1, 2, 3, 4, 5]\n\nif (n := len(my_list)):\n    print(f\"The list has non-zero length = {n}\")\n\nThe list has non-zero length = 5\n\n\nAnother motivating use-case is when looping over fixed-length blocks in a protocol parser.\n# Loop over fixed length blocks\nwhile (block := f.read(256)) != '':\n    process(block)"
  },
  {
    "objectID": "posts/singular-value-decomposition/index.html",
    "href": "posts/singular-value-decomposition/index.html",
    "title": "Singular Value Decomposition(SVD)",
    "section": "",
    "text": "Rectangular matrices do not have eigenvalues. However, we might look at the eigenvalues of the symmetric, positive semidefinite square Gram matrix \\(K=AA^T\\). Perhaps the eigenvalues of \\(K\\) might form an important role for general matrices. They were first studied by the German mathematician Erhard Schmidt in early days of the 20th century.\nSince \\(K=AA^T\\) is necessarily positive semi-definite, its eigenvalues are necessarily non-negative, \\(\\lambda_i \\geq 0\\), which justifies the positivity of the singular values of \\(A\\) - independently of whether \\(A\\) itself has positive, negative or even complex eigenvalues, or is rectangular and has no eigenvalues at all. I will follow the standard convention, and always label the singular values in decreasing order, so that \\(\\sigma_1 \\geq \\sigma_2 \\geq \\ldots \\geq \\sigma_r\\).\nIn the special case of symmetric matrices, there is a direct connection between their singular values and their (necessarily real) eigenvalues.\nProof.\nWhen \\(A\\) is symmetric, \\(K=A^T A = A^2\\). So, if\n\\[\nA \\mathbf{v} = \\lambda \\mathbf{v}\n\\]\nthen\n\\[\nK \\mathbf{v} = A^2 \\mathbf{v} = A(A \\mathbf{v}) = A(\\lambda \\mathbf{v}) = \\lambda A \\mathbf{v} = \\lambda^2 \\mathbf{v}\n\\]\nThus, every eigenvector \\(\\mathbf{v}\\) of \\(A\\) is also an eigenvector of \\(K\\) with eigenvalue \\(\\lambda^2\\). So, the eigenvector basis of \\(A\\) is also an eigenvector basis for \\(K\\), and forms a complete system of singular vectors for \\(A\\). \\(\\blacksquare\\)"
  },
  {
    "objectID": "posts/singular-value-decomposition/index.html#svd-factorization",
    "href": "posts/singular-value-decomposition/index.html#svd-factorization",
    "title": "Singular Value Decomposition(SVD)",
    "section": "SVD Factorization",
    "text": "SVD Factorization\nThe generalization of the spectral theorem to non-symmetric matrices is known as the singular value decomposition, commonly abbreviated SVD. Unlike the former, which applies to only symmetric matrices, every nonzero matrix possesses a SVD factorization.\n\nTheorem 1 (SVD Factorization) Every non-zero real \\(m \\times n\\) matrix \\(A\\) of rank \\(r &gt; 0\\) can be factored:\n\\[ A = U \\Sigma V^T \\]\ninto the product of an \\(m \\times r\\) matrix \\(U\\), the \\(r \\times r\\) diagonal matrix \\(\\Sigma = diag(\\sigma_1,\\ldots,\\sigma_r)\\) and an \\(r \\times n\\) matrix \\(V^T\\), such that \\(U\\) and \\(V\\) are orthonormal matrices.\n\nProof.\nLet’s begin by writing the desired factorization as \\(AQ = P \\Sigma\\). The individual columns"
  },
  {
    "objectID": "posts/template-programming/index.html",
    "href": "posts/template-programming/index.html",
    "title": "Template programming",
    "section": "",
    "text": "C++11 introduced variadic templates which permit functions to accept a variable number of arguments. They also permit template types such as std::tuple that can hold a variable number of elements. The main language mechanism enabling variadic templates is parameter packs, which hold an arbitrary number of values or types. Some things are easier to do with parameter packs - for instance passing the values they comprise to a function. Other tasks are a bit trickier to accomplish, such as iterating over a parameter pack or extracting specific elements. However, these things can generally be accomplished through various idioms, some more unwieldy then others.\nBetween C++11 and C++20, the language gained several improvements to variadic templates. Improvements to other features, such as concepts and lambdas, have also created new options for manipulating parameter packs in C++20. Ideally, cataloging these tricks make it easier for people to do what they need with variadic templates."
  },
  {
    "objectID": "posts/template-programming/index.html#an-overview-of-variadic-templates",
    "href": "posts/template-programming/index.html#an-overview-of-variadic-templates",
    "title": "Template programming",
    "section": "An overview of variadic templates",
    "text": "An overview of variadic templates\nA template parameter pack is a template parameter that accepts zero or more template arguments. A function parameter pack is a function parameter that accepts zero or more function arguments. A variadic template is template that captures a parameter pack in its template arguments or function arguments. A parameter pack is captured by introducing an identifier prefixed by an ellipsis, as in ...X. Once captured, a parameter pack can later be used in a pattern expanded by an ellipsis (...), generally to the right of the pattern, as in X.... Pack expansion is conceptually equivalent to having one copy of the pattern for each element of the parameter pack.\n#include &lt;iostream&gt;\n\ntemplate &lt;typename T&gt;\nT sum(T x){\n    return x;\n}\n\ntemplate &lt;typename T, typename... Args&gt;\nT sum(T x, Args... args){\n    return x + sum&lt;Args...&gt;(args...);\n}\n\nint main()\n{   \n    double result = sum(1.0, 2.0, 3.0, 4.0, 5.0);\n    std::cout &lt;&lt; \"result = \" &lt;&lt;  result;\n    return 0;\n}\nCompiler Explorer\nThe sum() function takes one or more arguments. The first argument is always captured by the parameter x and the rest of the arguments are captured by the pack ...args on line 9."
  },
  {
    "objectID": "posts/template-programming/index.html#expanding-parameter-packs",
    "href": "posts/template-programming/index.html#expanding-parameter-packs",
    "title": "Template programming",
    "section": "Expanding parameter packs",
    "text": "Expanding parameter packs\nWhen using a variadic template, we often use a recursive logic with two overloads : one for the general case and one for ending the recursion. For instance:\n#include &lt;iostream&gt;\n\ntemplate &lt;typename T&gt;\nT min(T a, T b)\n{\n    return a &lt; b ? a : b;\n}\n\ntemplate &lt;typename T, typename... Args&gt;\nT min(T first, Args... rest){\n    return min(first, min(rest...));\n}\n\nint main()\n{\n    int a = 2, b = 3, c = 4, d = 5;\n    int minValue {0};\n    minValue = min(a, b);\n    minValue = min(a, b, c);\n    minValue = min(a, b, c, d);\n    return 0;\n}\nCompiler Explorer\nThe below code snip is a minimalistic example of tuple. The first class is the primary template. The primary template tuple has two member variables : first of type Type and rest of type Types... . This means that a template of N elements will contain the first element, and another tuple; this second tuple in turn contains the second element and yet another tuple; so on and so forth.\nA captured parameter pack must be used in a pattern that is expanded with an ellipsis (...). A pattern is a set of tokens containing the identifiers of one or more parameter packs. On line 11, we capture a parameter pack rest consisting of a sequence of values rest[i] each of type Types[i] for the i-th position in parameter pack Types. On line 13, we expand the pattern rest.\n// Variadic class templates and parameter pack expansion\n#include &lt;functional&gt;\n#include &lt;utility&gt;\n#include &lt;iostream&gt;\n\ntemplate &lt;typename Type, typename... Types&gt;\nstruct tuple{\n    Type first_;\n    tuple&lt;Types...&gt; rest_;\n\n    tuple(Type first, Types... rest) \n        : first_(first)\n        , rest_(rest...)\n        {}\n};\n\ntemplate &lt;typename T&gt;\nstruct tuple&lt;T&gt;{\n    T first_;\n\n    tuple(T first) : first_(first) {}\n};\n\nint main()\n{   \n    tuple&lt;double, double, double&gt; x1(3.0, 4.0, 5.0);\n    return 0;\n}\nCompiler Explorer\nWhen a pattern contains more than one parameter pack, all packs must have the same length. This length determines the number of times the pattern is conceptually replicated in the expansion, once for each position in the expanded pack(s). Consider the following code snippet:\n// An example with two parameter packs\n#include &lt;iostream&gt;\n#include &lt;type_traits&gt;\n#include &lt;tuple&gt;\n\ntemplate &lt;std::same_as&lt;char&gt;... C&gt;\nvoid expand(C... c)\n{\n    std::tuple&lt;C...&gt; tpl(c...);\n\n    const char msg[] = { C(std::toupper(c))..., '\\0' };\n    //Do something\n}\nint main()\n{   \n    expand('t','e','m','p','l','a','t','e','s');\n    return 0;\n}\nOn line 7, tuple&lt;C...&gt; expands the pack C in the template-argument list, while tpl(c...) expands c in an initializer list (which, not to be confused with std::initializer_list is the C++ grammar for comma-separated lists of expressions passed as arguments to function calls and constructors).\nOn line 9, we expand the pattern C(std::toupper(c)) in another initializer list. This is an example of a pattern with two packs, C and c, both of which have the same length and are expanded in lockstep. (std::toupper() returns an int rather than a char so requires a cast).\n\nsizeof...(pack)\nThe number of arguments in a parameter pack can be retrieved at compile-time with the sizeof... operator. This operator returns a constexpr value of the std::size_t type. Let’s see this in action:\n#include &lt;iostream&gt;\n#include &lt;array&gt;\ntemplate &lt;typename... Args&gt;\nconstexpr auto get_type_sizes(Args... args){\n    return std::array&lt;std::size_t, sizeof...(Args)&gt;{sizeof(args)...};\n}\n\nint main()\n{\n    auto sizes = get_type_sizes&lt;char, int, long, double&gt;('a', 2, 3L, 3.14);\n    return 0;\n}\nCompiler Explorer\nIn this snippet, sizeof...(Args) evaluates to \\(4\\) at compile-time, while sizeof(args)... is expanded to the following comma-separated pack of arguments: sizeof(char), sizeof(int), sizeof(long) and sizeof(double).\nIn most cases, an expanded pattern is conceptually equivalent to the number of copies of the pattern equal to the size of the parameter pack. Unless otherwise noted, a pattern is expanded by appending an ellipsis (...). Here is a list of contexts in which a pattern can be expanded:\n\nInside template parameters and function parameters, a pack expansion behaves like a comma separated list of patterns. An example in template parameters is the expansion of T in inner here:\n\ntemplate &lt;typename... T&gt;\nstruct outer{\n    template &lt;T... args&gt;\n    struct inner{};\n};\n\nouter&lt;int, double, char[5]&gt; a{};\nAn example in function parameters is the expansion of Args..., when you call foo:\ntemplate &lt;typename... Args&gt;\nvoid foo(Args... args){}\n\nfoo(42);\nfoo(42, 'a');\n\nIn template argument lists as in std::tuple&lt;C...&gt;, the pack expands to the equivalent of a comma separated list of template arguments.\nIn function argument lists when a captured parameter pack appears inside the parenthesis of a function call. The largest expression to the left of the ellipsis (...) is the pattern that is expanded.\n\ntemplate&lt;typename T&gt;\nT step_it(T value){\n    return value + 1;\n}\nT sum(T x){\n    return x;\n}\n\nT sum(T first, T... args){\n    return (first + sum(args...));\n}\n\ntemplate &lt;typename... T&gt;\nvoid do_sums(T... args)\n{\n    auto s1 = sum(args...); \n    // sum(1, 2, 3, 4)\n\n    auto s2 = sum(42, args...);\n    // sum(42, 1, 2, 3, 4)\n\n    auto s3 = sum(step_it(args)...);\n    // sum(2, 3, 4, 5)\n}\n\ndo_sums(1, 2, 3, 4);\n\nIn base specifier lists, to specify one base class for each member of a type parameter pack e.g.:\n\ntemplate &lt;typename Base...&gt;\nstruct MyStruct : Base...{\n    MyStruct();\n};\n\nWhen initializing base classes in a mem-initializer list in a class constructor, the pack expansion initializes a list of base classes based on a type parameter pack:\n\ntemplate&lt;typename... Base&gt;\nstruct MyStruct: Base...{\n    /* Default c'ctor */\n    MyStruct() : Base...() {}\n\n    MyStruct(const Base&... args) : Base{args}... {}\n};\n\nIn initializer lists, the pack exmpansion is conceptually equivlent to a comma-separated list of instances of the pattern.\n\n#include &lt;iostream&gt;\n#include &lt;array&gt;\n\ntemplate&lt;typename... Args&gt;\nstruct sum_wrapper{\n    sum_wrapper(Args... args){\n        result = (... + args);\n    }\n    std::common_type_t&lt;Args...&gt; result;\n};\n\ntemplate&lt;typename... T&gt;\nvoid parenthesized(T... args){\n    std::array&lt;std::common_type_t&lt;T...&gt;,sizeof...(T)&gt; arr {args...};\n    //std::array&lt;int, 4&gt; {1, 2, 3, 4}\n\n    sum_wrapper sw1(args...);\n    //value = 1 + 2 + 3 + 4\n\n    sum_wrapper sw2(++args...);\n    //value = 2 + 3 + 4 + 5\n}\n\nint main()\n{\n    parenthesized(1, 2, 3, 4);\n    return 0;\n}\nCompiler Explorer\n\nIn the context of deriving from a pack of base classes, it is useful to introduce names from the base classes into the definition of the derived class. Therefore, a pack expansion may also appear in a using declaration.\n\n#include &lt;iostream&gt;\n#include &lt;array&gt;\n\nstruct A{\n    void execute() { std::cout &lt;&lt; \"A::execute()\\n\"; }\n};\n\nstruct B{\n    void execute() { std::cout &lt;&lt; \"B::execute()\\n\"; }\n};\n\nstruct C{\n    void execute() { std::cout &lt;&lt; \"C::execute()\\n\"; }\n};\n\ntemplate&lt;typename... Bases&gt;\nstruct X : public Bases...\n{\n    X(Bases const& ... args) : Bases(args)... {}\n    using Bases::execute...;\n    // Conceptually equivalent to\n    // using A::f;\n    // using B::f;\n    // using C::f;\n};\n\nint main()\n{\n    A a; B b; C c; X x(a, b, c);\n    x.A::execute();\n    x.B::execute();\n    x.C::execute();\n\n    \n    return 0;\n}\nCompiler Explorer\n\nLambda Captures - The capture clause of a lambda expression may contain a pack expansion.\n\n#include &lt;iostream&gt;\n\ntemplate&lt;typename... Args&gt;\nstd::common_type_t&lt;Args...&gt; add(Args... args){\n    return (... + args);\n}\n\ntemplate&lt;typename... T&gt;\nvoid captures(T... args){\n    auto l = [args...]{\n        return add(args...);\n    };\n\n    l();\n}\n\nint main()\n{\n    captures(1, 2, 3, 4);\n    return 0;\n}\n\nFold expressions - These are similar to left fold and right fold in functional programming.\n\ntemplate&lt;typename... T&gt;\nint sum(T... args){\n    return (args + ...);\n}\nA pattern may itself contain an expanded parameter pack, in which case there is no need for the inner and outer packs to contain the same number of elements. The expanded inner pack simply becomes a part of the pattern around the outer pack. For example:\n#include &lt;iostream&gt;\n\ntemplate&lt;typename... Args&gt;\nstd::common_type_t&lt;Args...&gt; sum(Args... il){\n    return (... + il);\n}\n\ntemplate&lt;int... N&gt;\nstruct Nested_sum{\n\n    template&lt;typename... Args&gt;\n    int nested_sum(Args... args){\n        return sum(sum(N...,args)...);\n    }\n};\nint main()\n{\n    Nested_sum&lt;1,2&gt; ns{};\n    int result = ns.nested_sum(100, 200);\n    // Equivalent to : sum(sum(1, 2, 100), sum(1, 2, 200))\n    return 0;\n}\nCompiler Explorer"
  },
  {
    "objectID": "posts/template-programming/index.html#implementing-getn-for-the-tuple",
    "href": "posts/template-programming/index.html#implementing-getn-for-the-tuple",
    "title": "Template programming",
    "section": "Implementing get<N> for the tuple",
    "text": "Implementing get&lt;N&gt; for the tuple\nWe can implement get&lt;N&gt; that takes a tuple as an argument and returns a reference to the element at the index n. Its prototype could look like the following:\ntemplate &lt;int n, typename... Ts&gt;\ntypename nth_type&lt;n, Ts...&gt;::value_type& get(tuple&lt;Ts...&gt;& t);\nThe template arguments are the index and a parameter pack of the tuple types. Its implementation, however, requires some helper types. First, we need to know what the type of the element is at the n-th index. This can be done with the help of the following nth_type variadic class template:\ntemplate&lt;int n, typename T, typename... Ts&gt;\nstruct nth_type : nth_type&lt;n-1,Ts...&gt;{\n};\n\ntemplate&lt;typename T, typename... Ts&gt;\nstruct nth_type&lt;0,T,Ts...&gt;{\n    using value_type = T;\n};\nAgain, we have a primary template that uses recursive inheritance, and the specialization for the index 0 (which is the head of the list of templates). This type is only used as a mechanism for determining the type of a tuple element. We need another variadic class template for retrieving the value.\ntemplate&lt;int n&gt;\nstruct getter{\n    template&lt;typename... Ts&gt;\n    static typename nth_type&lt;n, Ts...&gt;::value_type&\n    get(tuple&lt;Ts...&gt;& t){\n        return getter&lt;n-1&gt;::get(t.rest_);\n    }\n};\n\ntemplate&lt;&gt;\nstruct getter&lt;0&gt;{\n    template&lt;typename T, typename... Ts&gt;\n    static T& get(tuple&lt;T, Ts...&gt;& t){\n        return t.first_;\n    }\n};\nWith all these defined, we can now provide an implementation for the helper variadic function template get. This implementation relies on the getter class template and calls the get variadic function template.\ntemplate&lt;int n, typename... Ts&gt;\ntypename nth_type&lt;n, Ts...&gt;::value_type &\nget(tuple&lt;Ts...&gt;& t){\n    return getter&lt;n&gt;::get(t);\n}\nCompiler Explorer\nAnalysing the example above in cppinsights.io will be very illuminating. Here’s the listing:\n/*************************************************************************************\n * NOTE: This an educational hand-rolled transformation. Things can be incorrect or  *\n * buggy.                                                                            *\n *************************************************************************************/\n#include &lt;iostream&gt;\n\ntemplate&lt;typename T, typename ... Ts&gt;\nstruct tuple\n{\n  T first_;\n  tuple&lt;Ts...&gt; rest_;\n  inline tuple(T first, Ts... rest)\n  : first_{first}\n  , rest_{tuple&lt;Ts...&gt;(rest... )}\n  {\n  }\n  \n};\n\n/* First instantiated from: insights.cpp:6 */\n#ifdef INSIGHTS_USE_TEMPLATE\ntemplate&lt;&gt;\nstruct tuple&lt;int, double&gt;\n{\n  int first_;\n  tuple&lt;double&gt; rest_;\n  inline tuple(int first, double __rest1)\n  : first_{first}\n  , rest_{tuple&lt;double&gt;(__rest1)}\n  {\n  }\n  \n};\n\n#endif\n/* First instantiated from: insights.cpp:6 */\n#ifdef INSIGHTS_USE_TEMPLATE\ntemplate&lt;&gt;\nstruct tuple&lt;double&gt;\n{\n  double first_;\n  inline tuple(double first)\n  : first_{first}\n  {\n  }\n  \n};\n\n#endif\n/* First instantiated from: insights.cpp:53 */\n#ifdef INSIGHTS_USE_TEMPLATE\ntemplate&lt;&gt;\nstruct tuple&lt;char, int, double&gt;\n{\n  char first_;\n  tuple&lt;int, double&gt; rest_;\n  inline tuple(char first, int __rest1, double __rest2)\n  : first_{first}\n  , rest_{tuple&lt;int, double&gt;(__rest1, __rest2)}\n  {\n  }\n  \n};\n\n#endif\n\ntemplate&lt;typename T&gt;\nstruct tuple&lt;T&gt;\n{\n  T first_;\n  inline tuple(T first)\n  : first_(first)\n  {\n  }\n  \n};\nThe tuple&lt;char, int, double&gt; contains an int and a tuple&lt;int, double&gt;, which contains a int and tuple&lt;double&gt;, which in turn contains a double value.\nNext, we have the nth_type class template, for which, again, we have a primary template and several specializations, as follows:\n\ntemplate&lt;int n, typename T, typename ... Ts&gt;\nstruct nth_type : public nth_type&lt;n - 1, Ts...&gt;\n{\n};\n\n/* First instantiated from: insights.cpp:19 */\n#ifdef INSIGHTS_USE_TEMPLATE\ntemplate&lt;&gt;\nstruct nth_type&lt;1, int, double&gt; : public nth_type&lt;0, double&gt;\n{\n};\n\n#endif\n/* First instantiated from: insights.cpp:19 */\n#ifdef INSIGHTS_USE_TEMPLATE\ntemplate&lt;&gt;\nstruct nth_type&lt;0, double&gt;\n{\n  using value_type = double;\n};\n\n#endif\n/* First instantiated from: insights.cpp:45 */\n#ifdef INSIGHTS_USE_TEMPLATE\ntemplate&lt;&gt;\nstruct nth_type&lt;2, char, int, double&gt; : public nth_type&lt;1, int, double&gt;\n{\n};\n\n#endif\n\ntemplate&lt;typename T, typename ... Ts&gt;\nstruct nth_type&lt;0, T, Ts...&gt;\n{\n  using value_type = T;\n};\nThe nth_type&lt;2, char, int, double&gt; specialization is derived from nth_type&lt;1, int, double&gt; which in turn is derived from nth_type&lt;0, double&gt;, which is the last class in the base hierarchy.\nThe nth_type structure is used as the return type in the getter helper class template, which is instantiated as follows:\n/* First instantiated from: insights.cpp:32 */\n#ifdef INSIGHTS_USE_TEMPLATE\ntemplate&lt;&gt;\nstruct getter&lt;1&gt;\n{\n  template&lt;typename ... Ts&gt;\n  static inline typename nth_type&lt;1, Ts...&gt;::value_type & get(tuple&lt;Ts...&gt; & t);\n  \n  /* First instantiated from: insights.cpp:32 */\n  #ifdef INSIGHTS_USE_TEMPLATE\n  template&lt;&gt;\n  static inline typename nth_type&lt;1, int, double&gt;::value_type & get&lt;int, double&gt;(tuple&lt;int, double&gt; & t)\n  {\n    return getter&lt;0&gt;::get(t.rest_);\n  }\n  #endif\n  \n};\n\n#endif\n/* First instantiated from: insights.cpp:47 */\n#ifdef INSIGHTS_USE_TEMPLATE\ntemplate&lt;&gt;\nstruct getter&lt;2&gt;\n{\n  template&lt;typename ... Ts&gt;\n  static inline typename nth_type&lt;2, Ts...&gt;::value_type & get(tuple&lt;Ts...&gt; & t);\n  \n  /* First instantiated from: insights.cpp:47 */\n  #ifdef INSIGHTS_USE_TEMPLATE\n  template&lt;&gt;\n  static inline typename nth_type&lt;2, char, int, double&gt;::value_type & get&lt;char, int, double&gt;(tuple&lt;char, int, double&gt; & t)\n  {\n    return getter&lt;1&gt;::get(t.rest_);\n  }\n  #endif\n  \n};\n\n#endif\n\ntemplate&lt;&gt;\nstruct getter&lt;0&gt;\n{\n  template&lt;typename T, typename ... Ts&gt;\n  static inline T & get(tuple&lt;T, Ts...&gt; & t)\n  {\n    return t.first_;\n  }\n  \n  /* First instantiated from: insights.cpp:32 */\n  #ifdef INSIGHTS_USE_TEMPLATE\n  template&lt;&gt;\n  static inline double & get&lt;double&gt;(tuple&lt;double&gt; & t)\n  {\n    return t.first_;\n  }\n  #endif\n  \n};\nWe see the use of the keyword typename to prefix the nth_type&lt;N, Ts...&gt;::value_type which is a dependent type. In C++ 20, this is however no longer necessary.\nBecause implementing variadic templates is often verbose and can be cumbersome, the C++17 added fold expressions."
  },
  {
    "objectID": "posts/template-programming/index.html#fold-expressions",
    "href": "posts/template-programming/index.html#fold-expressions",
    "title": "Template programming",
    "section": "Fold Expressions",
    "text": "Fold Expressions\nA special form of pack expansions is folds introduced in C++17. Above, we showed a function sum that summed a set of integers. This function can be implemented far more concisely with a fold:\nint sum(auto... i){\n    return (... + i);\n}\nLet \\(p_1,\\ldots,p_n\\) be the instances of the parameter pack \\(p\\). Let \\(\\bigoplus\\) stand for any binary operator in the C++ grammar.\nA binary left fold has the form \\((e \\bigoplus \\ldots \\bigoplus p)\\) and is equivalent to \\((((e \\bigoplus p_1) \\bigoplus p_2)\\ldots ) \\bigoplus p_n\\).\nA unary left fold has the form \\((\\ldots \\bigoplus p)\\) and is equivalent to \\((((p_1 \\bigoplus p_2)\\bigoplus p_3) \\ldots )\\bigoplus p_n\\).\nA binary right fold has the form \\((p \\bigoplus \\ldots \\bigoplus e)\\) and is equivalent to \\(p_1 \\bigoplus (\\ldots (p_{n-1} \\bigoplus (p_n \\bigoplus e)))\\).\nA binary right fold has the form \\((p \\bigoplus \\ldots \\bigoplus p_n)\\) and is equivalent to \\(p_1 \\bigoplus (p_2 \\bigoplus (\\ldots \\bigoplus p_n))\\).\nIn the above expressions, \\(e\\) stands for the initial value."
  },
  {
    "objectID": "posts/template-programming/index.html#idioms",
    "href": "posts/template-programming/index.html#idioms",
    "title": "Template programming",
    "section": "Idioms",
    "text": "Idioms\nBelow is a collection of idioms for working with parameter packs."
  },
  {
    "objectID": "posts/thread-safe-queues/index.html",
    "href": "posts/thread-safe-queues/index.html",
    "title": "A thread-safe queue implementation",
    "section": "",
    "text": "In the producer-consumer problem, we have two classes of threads, producers and consumers and a buffer containing a fixed number of slots. A producer thread attempts to put something into the next empty buffer slot, a consumer thread attempts to take something out of the next occupied buffer slot. The synchronization conditions are that producers cannot proceed unless there are empty slots and consumers cannot proceed unless there are occupied slots. The problem occurs because of the different rates at which producers deposit and consumers exhaust data.\nThis is a classic, but frequently occurring synchronization problem. For example, the heart of the implementation of UNIX pipes is an instance of this problem."
  },
  {
    "objectID": "posts/thread-safe-queues/index.html#producer-consumer-problem",
    "href": "posts/thread-safe-queues/index.html#producer-consumer-problem",
    "title": "A thread-safe queue implementation",
    "section": "",
    "text": "In the producer-consumer problem, we have two classes of threads, producers and consumers and a buffer containing a fixed number of slots. A producer thread attempts to put something into the next empty buffer slot, a consumer thread attempts to take something out of the next occupied buffer slot. The synchronization conditions are that producers cannot proceed unless there are empty slots and consumers cannot proceed unless there are occupied slots. The problem occurs because of the different rates at which producers deposit and consumers exhaust data.\nThis is a classic, but frequently occurring synchronization problem. For example, the heart of the implementation of UNIX pipes is an instance of this problem."
  },
  {
    "objectID": "posts/thread-safe-queues/index.html#ring-buffer",
    "href": "posts/thread-safe-queues/index.html#ring-buffer",
    "title": "A thread-safe queue implementation",
    "section": "Ring buffer",
    "text": "Ring buffer\nConsider a single, fixed-size buffer as if it were connected end-to-end, such that the oldest entry is processed first. This is a circular FIFO queue.\nWhat do we use SPSC FIFO queues for? In the industry, you often have a pipeline of processes. For example, you have one thread reading from sockets, another thread that handles the messages from the sockets and maybe processes them and produces a result and a third thread writes a response to the network. Those can be connected by SPSC FIFO queues. There’s a couple of advantages to this. All these advantages and disadvantages are subject to measurement, so always measure. It may improve the throughput over just a single thread doing all \\(3\\) of these operations, in fact, I’ll be surprised if it didn’t. It also should improve the resiliency of the application to spikes in message traffic. Some of the disadvantages are that you have to manage 3 threads and it probably uses more memory, because each of the FIFO queues needs place to store its messages.\nWe all have come across circular FIFO queues. We usually have two cursors - rear and front. Items are pushed to the rear of the queue and popped off the front of the queue.\n\n\n\nCircular FIFO Queue\n\n\nWhen we push(42) into the FIFO queue, the rear cursor is incremented and each time we pop(), the front cursor is incremented. When the front cursor and the rear cursor are no longer equal, the FIFO queue is no longer empty. Eventually, we push so many values in, that the FIFO queue fills up. At this point, the rear cursor is capacity greater than the front cursor.\nThe FIFO queue empty and queue full conditions use the remainder operator %. Division uses \\(20\\) to \\(30\\) cycles so it is a bit expensive. Another approach is to constrain the buffer size to an integral power of \\(2\\), and use the bitwise & operator and that’s a \\(1\\) cycle operation.\n\nImplementation notes\n#include &lt;iostream&gt;\n#include &lt;queue&gt;\n#include &lt;thread&gt;\n#include &lt;array&gt;\n#include &lt;numeric&gt;\n#include &lt;memory&gt;\n#include &lt;condition_variable&gt;\n#include &lt;mutex&gt;\n#include &lt;shared_mutex&gt;\n\nnamespace dev {\n    template&lt;typename T&gt;\n    class ring_buffer {\n    private:\n        enum {min_capacity = 128};\n        T* ring;\n        int m_front;\n        int m_rear;\n        int m_capacity;\n\n    public:\n        /* Default constructor*/\n        ring_buffer() \n            : m_front{0}\n            , m_rear{0}\n            , ring{nullptr}\n            , m_capacity{0}\n        { \n            ring = static_cast&lt;T*&gt;(operator new(min_capacity));\n            m_capacity = min_capacity;\n        }\n\n        ring_buffer(int capacity)\n            : m_front{ 0 }\n            , m_rear{ 0 }\n            , ring{ nullptr }\n            , m_capacity{ 0 }\n        {\n            ring = static_cast&lt;T*&gt;(operator new(capacity));\n            m_capacity = capacity;\n        }\n\n        /* Copy constructor - Perform a deep copy */\n        ring_buffer(const ring_buffer&lt;T&gt;& other)\n            : m_front{ 0 }\n            , m_rear{ 0 }\n            , ring{ nullptr }\n            , m_capacity{ 0 }\n        {\n            /* Allocation */\n            ring = static_cast&lt;T*&gt;(operator new(other.m_capacity));\n\n            m_capacity = other.m_capacity;\n\n            /* Construction */\n            for (int i{0}; i &lt; other.size(); ++i)\n            {\n                new (&ring[i]) T(other[i]);\n            }\n        }\n\n        /* Swap */\n        friend void swap(ring_buffer&lt;T&gt;& lhs, ring_buffer&lt;T&gt;& rhs)\n        {\n            std::swap(lhs.m_front, rhs.m_front);\n            std::swap(lhs.m_rear, rhs.m_rear);\n            std::swap(lhs.m_capacity, rhs.m_capacity);\n            std::swap(lhs.ring, rhs.ring);\n        }\n\n        /* Copy assignment */\n        ring_buffer&lt;T&gt;& operator=(const ring_buffer&lt;T&gt;& other)\n        {\n            ring_buffer&lt;T&gt; temp{ other };  //Copy-construct\n            swap(*this, temp);\n            return *this;\n        }\n\n        T& front() {\n            if (empty())\n                throw std::exception(\"buffer is empty!\");\n\n            return ring[m_front % m_capacity];\n        }\n\n        T& back() {\n            if (empty())\n                throw std::exception(\"buffer is empty!\");\n\n            return ring[(m_rear - 1) % m_capacity];\n        }\n\n        T& operator[](int i) const {\n            if (empty())\n                throw std::exception(\"buffer is empty!\");\n\n            return ring[(m_front + i) % m_capacity];\n        }\n\n        bool empty() const {\n            return m_front == m_rear;\n        }\n\n        bool full() const {\n            return size() == capacity();\n        }\n\n        void push(const T& value) {\n            if (full())\n                throw std::exception(\"buffer is full!\");\n\n            new (&ring[m_rear % m_capacity]) T(value);\n            std::cout &lt;&lt; \"\\n\" &lt;&lt; \"pushed \" &lt;&lt; value &lt;&lt; \" to buffer\";\n            ++m_rear;\n        }\n\n        void push(T&& value) {\n            if (full())\n                throw std::exception(\"buffer is full!\");\n\n            new (&ring[m_rear % m_capacity]) T(std::move(value));\n            std::cout &lt;&lt; \"\\n\" &lt;&lt; \"pushed \" &lt;&lt; value &lt;&lt; \" to buffer\";\n            ++m_rear;\n        }\n\n        void pop() {\n            if (empty())\n                throw std::exception(\"buffer is empty!\");\n\n            T value = front();\n            ring[m_front % m_capacity].~T();\n            std::cout &lt;&lt; \"\\n\" &lt;&lt; \"popped \" &lt;&lt; value &lt;&lt; \" off buffer\";\n            ++m_front;\n        }\n\n        int capacity() const{\n            return m_capacity;\n        }\n\n        int size() const {\n            return (m_rear - m_front);\n        }\n\n        void print() {\n            for (int i{ 0 };i &lt; size();++i) {\n                std::cout &lt;&lt; \"\\n\" &lt;&lt; \"ring[\" &lt;&lt; i &lt;&lt; \"] = \" &lt;&lt; (*this)[i];\n            }\n        }\n    };\n}\nRunning the above code-snippet, we find that there are several occassions when there are buffer overflows or underflows, and there are also data races."
  },
  {
    "objectID": "posts/thread-safe-queues/index.html#building-a-thread-safe-queue-using-condition-variables",
    "href": "posts/thread-safe-queues/index.html#building-a-thread-safe-queue-using-condition-variables",
    "title": "A thread-safe queue implementation",
    "section": "Building a thread-safe queue using condition variables",
    "text": "Building a thread-safe queue using condition variables\nYou essentially have three groups of operations : those that query the state of the whole queue(empty() and size()), those that query the elements of the queue(front() and back()) and those that modify the queue (push(), pop() and emplace()). This is the same as we’ve seen for the stack container adapter, and we have the same issues regarding race conditions inherent in the interface. Consequently, we need to combine front() and pop() into a single function call, much as you combined pop() and top() for the stack.\nnamespace dev {\n    template&lt;typename T&gt;\n    class threadsafe_ring_buffer {\n    public:\n        threadsafe_ring_buffer() : m_ring_buffer{ring_buffer&lt;T&gt;()}\n        {}\n\n        threadsafe_ring_buffer(int capacity) : m_ring_buffer{ring_buffer&lt;T&gt;(capacity)}\n        {}\n\n        threadsafe_ring_buffer(const threadsafe_ring_buffer&lt;T&gt;& other)\n        {\n            std::shared_lock&lt;std::shared_mutex&gt; lck(mtx);\n            m_ring_buffer = other.m_ring_buffer;\n        }\n        threadsafe_ring_buffer&lt;T&gt;& operator=(const threadsafe_ring_buffer&lt;T&gt;& other) = delete;\n\n        void wait_and_push(T new_value) {\n            std::unique_lock&lt;std::shared_mutex&gt; lck(mtx);\n            queue_not_full_cond.wait(lck, [this]() {return !m_ring_buffer.full();});\n            m_ring_buffer.push(new_value);\n            queue_not_empty_cond.notify_one();\n        }\n\n        bool try_push(T new_value) {\n            std::unique_lock&lt;std::shared_mutex&gt; lck(mtx);\n            if (!m_ring_buffer.full())\n                return false;\n\n            m_ring_buffer.push(new_value);\n            return true;\n        }\n\n        void wait_and_pop(T& value) {\n            std::unique_lock&lt;std::shared_mutex&gt; lck(mtx);\n            queue_not_empty_cond.wait(lck, [this]() { return !m_ring_buffer.empty();});\n            value = m_ring_buffer.front();\n            m_ring_buffer.pop();\n            queue_not_full_cond.notify_one();\n        }\n\n        void try_pop(T& value) {\n            std::unique_lock&lt;std::shared_mutex&gt; lck(mtx);\n            if (m_ring_buffer.empty())\n                return false;\n\n            value = m_ring_buffer.front();\n            m_ring_buffer.pop();\n            return true;\n        }\n\n        std::shared_ptr&lt;T&gt; wait_and_pop() {\n            std::unique_lock&lt;std::shared_mutex&gt; lck(mtx);\n            queue_not_empty_cond.wait([this]() { return !empty(); });\n            std::shared_ptr&lt;T&gt; result{ std::make_shared&lt;T&gt;(m_ring_buffer.front()) };\n            m_ring_buffer.pop();\n            return result;\n        }\n\n        std::shared_ptr&lt;T&gt; try_pop() {\n            std::unique_lock&lt;std::shared_mutex&gt; lck(mtx);\n            if (m_ring_buffer.empty())\n                return nullptr;\n\n            std::shared_ptr&lt;T&gt; result{ std::make_shared&lt;T&gt;(m_ring_buffer.front()) };\n            m_ring_buffer.pop();\n            return result;\n        }\n\n        bool empty() const {\n            std::shared_lock&lt;std::shared_mutex&gt; lck(mtx);\n            return m_ring_buffer.empty();\n        }\n\n        bool full() const {\n            std::shared_lock&lt;std::shared_mutex&gt; lck(mtx);\n            return m_ring_buffer.full();\n        }\n\n        int size() const {\n            std::shared_lock&lt;std::shared_mutex&gt; lck(mtx);\n            return m_ring_buffer.size();\n        }\n\n        int capacity() const {\n            std::shared_lock&lt;std::shared_mutex&gt; lck(mtx);\n            return m_ring_buffer.capacity();\n        }\n\n    private:\n        ring_buffer&lt;T&gt; m_ring_buffer;\n        mutable std::shared_mutex mtx;\n        std::condition_variable_any queue_not_empty_cond;\n        std::condition_variable_any queue_not_full_cond;\n    };\n}\n\nint main()\n{\n    dev::threadsafe_ring_buffer&lt;int&gt; buffer(64);\n\n    std::thread producer(\n        [&]() {\n            for (int i{ 1 };i &lt;= 1000;++i)\n            {\n                try {\n                    buffer.wait_and_push(i);\n                }\n                catch (std::exception e) {\n                    std::cout &lt;&lt; \"\\n\" &lt;&lt; \"buffer full!\";\n                }\n            }\n        }\n    );\n\n    std::thread consumer(\n        [&]() {\n            for (int i{ 1 };i &lt;= 1000;++i)\n            {\n                try {\n                    int value;\n                    buffer.wait_and_pop(value);\n                    std::this_thread::sleep_for(std::chrono::microseconds(1));\n                }\n                catch (std::exception e) {\n                    std::cout &lt;&lt; \"\\n\" &lt;&lt; \"buffer empty!\";\n                }\n            }\n        }\n    );\n\n    producer.join();\n    consumer.join();\n    \n    std::cout &lt;&lt; \"\\nFinished execution\";\n}"
  },
  {
    "objectID": "posts/thread-safe-queues/index.html#semaphores",
    "href": "posts/thread-safe-queues/index.html#semaphores",
    "title": "A thread-safe queue implementation",
    "section": "Semaphores",
    "text": "Semaphores\nC++20 introduces new synchronization primitives to write multi-threaded applications .\nA semaphore is a counter that manages the numberof permits available for accessing a share resource. Semaphores can be classified into two main types:\n\nBinary Semaphore. It has only \\(2\\) states: \\(0\\) and \\(1\\). Event though a binary semaphore is conceptually like a mutex, there are some differences between a binary semaphore and a mutex, that we’ll explore later.\nCounting Semaphore. It can have a value greater than \\(1\\) and is used to control access to a resource that has a limited number of instances.\n\nC++20 implements both binary and counting semaphores.\n\nBinary Semaphores\nA binary semaphore is a synchronization primitive that can be used to control access to a shared resource. It has two states: \\(0\\) and \\(1\\). A semaphore with a value of \\(0\\) indicates that the resource is unavailable, while a semaphore with a value of \\(1\\) indicates that the resource is available.\nThe most significant difference between mutexes and semaphores is that threads that have acquired a mutex have exclusive ownership of it. Only the thread owning the mutex can release it. Semaphores can be signaled by any thread. A mutex is a locking mechanism for a critical section, whereas a semaphore is more like a signaling mechanism. For this reason, semaphores are commonly used for signaling rather than for mutual exlusion.\nIn C++20, std::binary_semaphore is an alias for the specialization of std::counting_semaphore with LeastMaxValue being \\(1\\).\nBinary semaphores must be initialized with either \\(1\\) or \\(0\\) as follows:\nstd::binary_semaphore smphr1{ 0 };\nstd::binary_semaphore smphr2{ 1 };\nIf the initial value is 0, acquiring the semaphore will block the thread trying to acquire it, and before it can be acquired, it must be released by another thread. Acquiring the semaphore decreases the counter, and releasing it increases the counter.\n\n\nCounting semaphores\nA counting semaphore allows access to a shared resource by more than one thread. The counter can be initialized to an arbitrary number, and it will be decreased every time a thread acquires the semaphore.\nWe can design a thread-safe queue using semaphores instead of condition variables to synchronize access to the queue.\nWe code up an unbounded queue implemented as a circular queue with doubling.\n#include &lt;iostream&gt;\n#include &lt;shared_mutex&gt;\n#include &lt;semaphore&gt;\n\nnamespace dev {\n    /* \n    A queue implements a first-in-first-out data-structure allowing \n    enqueuing (adding) items to the rear and dequeuing(removing)\n    them from the front.\n\n    My implementation uses a circular queue with doubling - the simplest\n    and reasonably efficient choice.\n\n    The interface design conforms to the standard library std::queue&lt;T&gt;\n    specification.\n    */\n    template&lt;typename T&gt;\n    class queue {\n    private:\n        enum{min_capacity = 8};\n        T* m_ring_buffer;\n        int m_front;\n        int m_rear;\n        int m_capacity;\n\n    public:\n        using value_type = T;\n        using reference = T&;\n\n        /* Constructors */\n\n        // Default constructor\n        queue() : queue(min_capacity){}\n\n        // Parametrized Constructor\n        queue(int capacity)\n            : m_ring_buffer{ nullptr }\n            , m_front{ 0 }\n            , m_rear{ 0 }\n            , m_capacity{ 0 }\n        {\n            m_ring_buffer = static_cast&lt;T*&gt;(operator new(capacity * sizeof(T)));\n            m_capacity = capacity;\n        }\n\n        /* Destructor */\n        ~queue() {\n            clear();\n            operator delete(m_ring_buffer);\n        }\n\n        /* Copy constructor \n        * Perform a deep-copy of the contents of the queue\n        */\n        queue(const queue& other) \n            : queue(other.m_capacity) // Allocation step\n        {\n            /* Call the copy constructor of T \n            * placing it directly into the pre-allocated\n            * storage at memory address &m_ring_buffer[i]\n            */\n            for (int i{ 0 };i &lt; other.size();++i) {\n                new (&m_ring_buffer[i]) T(other[i]);\n                ++m_rear;\n            }\n        }\n\n        /* Swap the contents of lhs and rhs member-by-member */\n        friend void swap(queue& lhs, queue& rhs) {\n            std::swap(lhs.m_ring_buffer, rhs.m_ring_buffer);\n            std::swap(lhs.m_front, rhs.m_front);\n            std::swap(lhs.m_rear, rhs.m_rear);\n            std::swap(lhs.m_capacity, rhs.m_capacity);\n        }\n\n        /* Copy-assignment */\n        queue& operator=(const queue& other) {\n            queue temp{ other };    // Copy-construct\n            swap(*this, temp);      // and swap idiom\n            return (*this);\n        }\n\n        /* Move constructor */\n        queue(queue&& other)\n            : m_ring_buffer{ std::move(other.m_ring_buffer) }\n            , m_front{ std::move(other.m_front) }\n            , m_rear{ std::move(other.m_rear) }\n            , m_capacity{ std::move(other.m_capacity) }\n        {\n            other.m_ring_buffer = nullptr;\n        }\n\n        /* Move assignment */\n        queue& operator=(queue&& other) {\n            queue temp{ std::move(other) };\n            std::swap(*this, temp);\n            return (*this);\n        }\n\n        /* Capacity*/\n\n        /* Checks whether the queue is empty */\n        bool empty()\n        {\n            return (m_rear == m_front);\n        }\n\n        bool full() {\n            return (m_rear == m_front + m_capacity);\n        }\n\n        /* Returns the number of elements in the queue*/\n        int size() const {\n            return (m_rear - m_front);\n        }\n\n        int capacity() const {\n            return m_capacity;\n        }\n\n        /* Modifiers */\n\n        /* Double the capacity of the queue */\n        void resize()\n        {\n            std::cout &lt;&lt; \"\\n\" &lt;&lt; \"Resizing the queue from \" &lt;&lt; m_capacity \n                &lt;&lt; \" to \" &lt;&lt; 2 * m_capacity &lt;&lt; \" elements.\";\n\n            // 1. Allocation step\n            T* new_array = static_cast&lt;T*&gt;(operator new(2 * m_capacity * sizeof(T)));\n\n            std::cout &lt;&lt; \"\\n\" &lt;&lt; \"Allocation complete.\";\n\n            // 2. Copy over the elements of the queue to the newly\n            // allocated storage.\n            int new_size = size();\n            for (int i{ 0 };i &lt; new_size;++i) {\n                new (&new_array[i]) T(std::move(m_ring_buffer[(i + m_front) % m_capacity]));\n            }\n\n            std::cout &lt;&lt; \"\\n\" &lt;&lt; \"Copy-construction complete\";\n\n            // 3. Destroy the old array\n            clear();\n            operator delete(m_ring_buffer);\n            \n            std::cout &lt;&lt; \"\\n\" &lt;&lt; \"Destruction of old array complete\";\n            \n            // Re-wire m_ring_buffer, set front, rear and capacity\n            m_ring_buffer = new_array;\n            m_front = 0;\n            m_rear = new_size;\n            m_capacity *= 2;\n        }\n\n        /* Push the given value to the end of the queue */\n        void push(const T& value) {\n            std::cout &lt;&lt; \"\\n\" &lt;&lt; \"Pushing \" &lt;&lt; value &lt;&lt; \" to the queue\";\n            if (full())\n                resize();\n            new (&m_ring_buffer[(m_rear % m_capacity)]) T(value);\n            std::cout &lt;&lt; \"\\n\" &lt;&lt; \"Pushed \" &lt;&lt; value &lt;&lt; \" to the queue\";\n            m_rear++;\n        }\n\n        void push(T&& value) {\n            std::cout &lt;&lt; \"\\n\" &lt;&lt; \"Pushing \" &lt;&lt; value &lt;&lt; \" to the queue\";\n            if (full())\n                resize();\n            new(&m_ring_buffer[(m_rear % m_capacity)]) T(std::move(value));\n            m_rear++;\n        }\n\n        /* Removes an element from the front of the queue */\n        void pop() {\n            m_ring_buffer[m_front % m_capacity].~T();\n            m_front++;\n        }\n\n        /* Element access */\n\n        T& operator[](int i) {\n            return m_ring_buffer[(m_front + i) % m_capacity];\n        }\n\n        T& operator[](int i) const {\n            return m_ring_buffer[(m_front + i) % m_capacity];\n        }\n\n        /* Returns a reference to the first element in the queue */\n        T& front() {\n            return m_ring_buffer[m_front % m_capacity];\n        }\n\n        /* Return a reference to the last element in the queue */\n        T& back() {\n            return m_ring_buffer[(m_rear - 1) % m_capacity];\n        }\n\n    private:\n        /* Helper function to clear the queue */\n        void clear() {\n            for (int i{ 0 }; i &lt; size(); ++i) {\n                m_ring_buffer[(m_front + i) % m_capacity].~T();\n            }\n        }\n    };\n}\n\nint main()\n{\n    dev::queue&lt;double&gt; q;\n    std::cout &lt;&lt; \"\\n\" &lt;&lt; \"Queue capacity = \" &lt;&lt; q.capacity();\n    \n    for (double i{ 1.0 };i &lt;= 10.0;i++)\n        q.push(i);\n    \n    std::cout &lt;&lt; \"\\n\" &lt;&lt; \"Queue capacity = \" &lt;&lt; q.capacity();\n}\nPlay on Compiler Explorer\nNext, we code up the semaphore_queue class that uses semaphores instead of condition variables as the synchronization mechanism."
  },
  {
    "objectID": "posts/thread-safe-queues/index.html#spmc-queues-and-coding-up-a-threadpool",
    "href": "posts/thread-safe-queues/index.html#spmc-queues-and-coding-up-a-threadpool",
    "title": "A thread-safe queue implementation",
    "section": "SPMC queues and coding up a ThreadPool",
    "text": "SPMC queues and coding up a ThreadPool\nA thread-pool is a group of pre-instantiated, idle threads which stand ready to be given work. These are preferred over instantiating new threads for each task whenever there are a large number of short tasks to be done rather than a small number of long ones. This prevents having to incur the overhead of creating a thread a large number of times and starvation of threads.\nThe ThreadPool class has a container for the worker threads as one of its member-variables.\nWhen a thread-pool is handed a Task, it is added to a SPMC queue. If a thread from the ThreadPool is idle, it can pop() the next task off the TaskQueue and executes it. Once the execution is complete, the thread hands itself back to the pool to be put into the container for reuse and until the queue_not_empty_cond condition is met, and the cycle repeats."
  },
  {
    "objectID": "posts/tridiagonal-systems/index.html",
    "href": "posts/tridiagonal-systems/index.html",
    "title": "Tridiagonal Systems",
    "section": "",
    "text": "The special case of a system of linear equations that is tridiagonal, that is, has non-zero elements only on the diagonal plus or minus one column, is one that occurs frequently. Also common are systems that are band-diagonal, with non-zero elements only along a few diagonal lines adjacent to the main diagonal (above and below).\nFor triadiagonal sets, the procedures \\(LU\\)-decomposition, forward- and back- substitution each take only \\(O(n)\\) operations and the whole solution can be coded very concisely. In this blog post, I am going to explore solving triadiagonal matrix systems. I closely follow Daniel Duffy’s exposition in Chapter 13 of his excellent book Financial Instrument Pricing using C++.\nLet \\(A\\) be a \\(m \\times n\\) general banded matrix with \\(kl\\) subdiagonals and \\(ku\\) superdiagonals. Then, \\(a_{ij}=0\\), when \\(|i - j| &gt; kl + ku + 1\\). All non-zero elements are positioned on the main diagonal, \\(kl\\) subdiagonals below it and \\(ku\\) superdiagonals above it.\n\nA diagonal matrix is a \\(n \\times n\\) band matrix with \\(kl = ku = 0\\).\nA Toeplitz matrix is a \\(n \\times n\\) band matrix \\(T_n=[t_{k,j};k,j=0,1,\\ldots,n-1]\\) where \\(t_{k,j}=t_{k-j}\\). That is, a matrix of the form: \\[\nT_n = \\begin{bmatrix}\nt_0 & t_{-1} & t_{-2} & \\ldots & t_{-(n-1)}\\\\\nt_1 & t_0 & t_{-1} & \\ldots & t_{-(n-2)}\\\\\nt_2 & t_1 & t_{0} & \\ldots & t_{-(n-3)}\\\\\n\\vdots & & & \\ddots & \\\\\nt_{n-1} & t_{n-2} & t_{n-3} & \\ldots & t_{0}\n\\end{bmatrix}\n\\]\nA tridiagonal (Jacobi) matrix is a \\(n \\times n\\) band matrix of width three \\(kl = ku = 1\\). \\[\n\\begin{bmatrix}\nb_0 & c_0 & 0 & \\ldots \\\\\na_1 & b_1 & c_1 & \\ldots \\\\\n0 & a_2 & b_2 & \\ldots \\\\\n& & & \\ldots \\\\\n& & & \\ldots & a_{n-2} & b_{n-2} & c_{n-2}\\\\\n& & & \\ldots & 0 & a_{n-1} & b_{n-1}\n\\end{bmatrix}\n\\]\n\nConsider a two-point boundary value problem on the interval \\((0,1)\\) with Dirichlet boundary conditions:\n\\[\n\\begin{align*}\n\\frac{d^2 u}{d x^2} &= f(x), \\quad 0 &lt; x &lt; 1\\\\\nu(0) &= \\phi, \\\\\nu(1) &= \\psi\n\\end{align*}\n\\tag{1}\\]\nWe approximate the solution \\(u\\) by creating a discrete mesh of points defined by \\(\\{x_j\\}\\), \\(j=0,\\ldots,N\\) where \\(N\\) is a positive integer. At each interior mesh point the second derivative in the Equation 1 can be approximated by a second-order divided difference. The corresponding discrete scheme is:\n\\[\n\\begin{matrix}\nU_0 &- 2U_1 &+ U_2 & & & & & & & &= h^2 f_1 \\\\\n& U_1 &- 2U_2 &+ U_3  & & & & & & &= h^2 f_2 \\\\\n& & U_2 &- 2U_3 &+ U_4 & & & & & &= h^2 f_3 \\\\\n& &     &       &      & \\ldots & & & & & \\vdots \\\\\n& &     &       &      & \\ldots & U_{N-3} &- 2U_{N-2} &+ U_{N-1} &  &= h^2 f_{N-2}\\\\\n& &     &       &      & \\ldots &  & U_{N-2} &-2 U_{N-1} &+ U_N &= h^2 f_{N-1}\\\\\n\\end{matrix}\n\\]\nSince \\(U_0 = \\phi\\) and \\(U_N = \\psi\\), we have \\(N-1\\) equations in \\({N-1}\\) unknowns. These can be arranged in the matrix form as:\n\\[\n\\begin{bmatrix}\n-2 & 1\\\\\n1  &-2 & 1  &   & \\ldots &   &    &  \\\\\n   & 1 &-2  & 1 & \\ldots &   &    &  \\\\\n   &   &    &   & \\ldots &   &    &  \\\\\n   &   &    &   & \\ldots & 1 & -2 & 1 \\\\\n   &   &    &   & \\ldots &   &  1 & -2\n\\end{bmatrix}\\begin{bmatrix}\nU_1 \\\\\nU_2 \\\\\n\\vdots\\\\\nU_{N-2} \\\\\nU_{N-1}\n\\end{bmatrix} = \\begin{bmatrix}\nh^2 f_1 - \\phi\\\\\nh^2 f_2 \\\\\n\\vdots\\\\\nh^2 f_{N-2} \\\\\nh^2 f_{N-1} - \\psi\n\\end{bmatrix}\n\\]\nor in matrix form \\(AU=F\\)."
  },
  {
    "objectID": "posts/tridiagonal-systems/index.html#introduction",
    "href": "posts/tridiagonal-systems/index.html#introduction",
    "title": "Tridiagonal Systems",
    "section": "",
    "text": "The special case of a system of linear equations that is tridiagonal, that is, has non-zero elements only on the diagonal plus or minus one column, is one that occurs frequently. Also common are systems that are band-diagonal, with non-zero elements only along a few diagonal lines adjacent to the main diagonal (above and below).\nFor triadiagonal sets, the procedures \\(LU\\)-decomposition, forward- and back- substitution each take only \\(O(n)\\) operations and the whole solution can be coded very concisely. In this blog post, I am going to explore solving triadiagonal matrix systems. I closely follow Daniel Duffy’s exposition in Chapter 13 of his excellent book Financial Instrument Pricing using C++.\nLet \\(A\\) be a \\(m \\times n\\) general banded matrix with \\(kl\\) subdiagonals and \\(ku\\) superdiagonals. Then, \\(a_{ij}=0\\), when \\(|i - j| &gt; kl + ku + 1\\). All non-zero elements are positioned on the main diagonal, \\(kl\\) subdiagonals below it and \\(ku\\) superdiagonals above it.\n\nA diagonal matrix is a \\(n \\times n\\) band matrix with \\(kl = ku = 0\\).\nA Toeplitz matrix is a \\(n \\times n\\) band matrix \\(T_n=[t_{k,j};k,j=0,1,\\ldots,n-1]\\) where \\(t_{k,j}=t_{k-j}\\). That is, a matrix of the form: \\[\nT_n = \\begin{bmatrix}\nt_0 & t_{-1} & t_{-2} & \\ldots & t_{-(n-1)}\\\\\nt_1 & t_0 & t_{-1} & \\ldots & t_{-(n-2)}\\\\\nt_2 & t_1 & t_{0} & \\ldots & t_{-(n-3)}\\\\\n\\vdots & & & \\ddots & \\\\\nt_{n-1} & t_{n-2} & t_{n-3} & \\ldots & t_{0}\n\\end{bmatrix}\n\\]\nA tridiagonal (Jacobi) matrix is a \\(n \\times n\\) band matrix of width three \\(kl = ku = 1\\). \\[\n\\begin{bmatrix}\nb_0 & c_0 & 0 & \\ldots \\\\\na_1 & b_1 & c_1 & \\ldots \\\\\n0 & a_2 & b_2 & \\ldots \\\\\n& & & \\ldots \\\\\n& & & \\ldots & a_{n-2} & b_{n-2} & c_{n-2}\\\\\n& & & \\ldots & 0 & a_{n-1} & b_{n-1}\n\\end{bmatrix}\n\\]\n\nConsider a two-point boundary value problem on the interval \\((0,1)\\) with Dirichlet boundary conditions:\n\\[\n\\begin{align*}\n\\frac{d^2 u}{d x^2} &= f(x), \\quad 0 &lt; x &lt; 1\\\\\nu(0) &= \\phi, \\\\\nu(1) &= \\psi\n\\end{align*}\n\\tag{1}\\]\nWe approximate the solution \\(u\\) by creating a discrete mesh of points defined by \\(\\{x_j\\}\\), \\(j=0,\\ldots,N\\) where \\(N\\) is a positive integer. At each interior mesh point the second derivative in the Equation 1 can be approximated by a second-order divided difference. The corresponding discrete scheme is:\n\\[\n\\begin{matrix}\nU_0 &- 2U_1 &+ U_2 & & & & & & & &= h^2 f_1 \\\\\n& U_1 &- 2U_2 &+ U_3  & & & & & & &= h^2 f_2 \\\\\n& & U_2 &- 2U_3 &+ U_4 & & & & & &= h^2 f_3 \\\\\n& &     &       &      & \\ldots & & & & & \\vdots \\\\\n& &     &       &      & \\ldots & U_{N-3} &- 2U_{N-2} &+ U_{N-1} &  &= h^2 f_{N-2}\\\\\n& &     &       &      & \\ldots &  & U_{N-2} &-2 U_{N-1} &+ U_N &= h^2 f_{N-1}\\\\\n\\end{matrix}\n\\]\nSince \\(U_0 = \\phi\\) and \\(U_N = \\psi\\), we have \\(N-1\\) equations in \\({N-1}\\) unknowns. These can be arranged in the matrix form as:\n\\[\n\\begin{bmatrix}\n-2 & 1\\\\\n1  &-2 & 1  &   & \\ldots &   &    &  \\\\\n   & 1 &-2  & 1 & \\ldots &   &    &  \\\\\n   &   &    &   & \\ldots &   &    &  \\\\\n   &   &    &   & \\ldots & 1 & -2 & 1 \\\\\n   &   &    &   & \\ldots &   &  1 & -2\n\\end{bmatrix}\\begin{bmatrix}\nU_1 \\\\\nU_2 \\\\\n\\vdots\\\\\nU_{N-2} \\\\\nU_{N-1}\n\\end{bmatrix} = \\begin{bmatrix}\nh^2 f_1 - \\phi\\\\\nh^2 f_2 \\\\\n\\vdots\\\\\nh^2 f_{N-2} \\\\\nh^2 f_{N-1} - \\psi\n\\end{bmatrix}\n\\]\nor in matrix form \\(AU=F\\)."
  },
  {
    "objectID": "posts/tridiagonal-systems/index.html#thomas-algorithm",
    "href": "posts/tridiagonal-systems/index.html#thomas-algorithm",
    "title": "Tridiagonal Systems",
    "section": "Thomas Algorithm",
    "text": "Thomas Algorithm\nThe Thomas algorithm is an efficient way of solving tridiagonal matrix systems. It is based on \\(LU\\)-decomposition in which the matrix system \\(Ax=r\\) is written as \\(LUx=r\\), where \\(L\\) is a lower-triangular matrix and \\(U\\) is an upper triangular matrix. The system can be efficiently solved by setting \\(Ux=\\rho\\) and then solving first \\(L\\rho=r\\) and then \\(Ux=\\rho\\) for \\(x\\). The Thomas algorithm consists of two steps. In step 1, decomposing the matrix \\(M = LU\\) and solving \\(L\\rho=r\\) are accomplished in a single downwards sweep, taking us straight from \\(Ax=r\\) to \\(Ux=\\rho\\). In step 2, the equation \\(Ux = \\rho\\) is solved for \\(x\\) in an upward sweep.\n\nStage 1\nIn the first stage, the matrix equation \\(Ax=r\\) is converted to the form \\(Ux=\\rho\\). Initially, the matrix equation looks like this:\n\\[\n\\begin{bmatrix}\n{\\color{blue}b_1} & {\\color{blue}c_1} & 0 & 0 & 0 & 0\\\\\n{\\color{blue}a_2} & {\\color{blue}b_2} & {\\color{blue}c_2} & 0 & 0 & 0\\\\\n0 & {\\color{blue}a_3} & {\\color{blue}b_3} & {\\color{blue}c_3} & 0 & 0\\\\\n0 & 0 & {\\color{blue}a_4} & {\\color{blue}b_4} & {\\color{blue}c_4} & 0\\\\\n0 & 0 & 0 & {\\color{blue}a_5} & {\\color{blue}b_5} & {\\color{blue}c_5}\\\\\n0 & 0 & 0 & 0 & a_6 & b_6\n\\end{bmatrix} \\begin{bmatrix}\nx_1 \\\\\nx_2 \\\\\nx_3 \\\\\nx_4 \\\\\nx_5 \\\\\nx_6\n\\end{bmatrix} =\n\\begin{bmatrix}\n{\\color{blue}r_1} \\\\\n{\\color{blue}r_2} \\\\\n{\\color{blue}r_3} \\\\\n{\\color{blue}r_4} \\\\\n{\\color{blue}r_5} \\\\\n{\\color{blue}r_6}\n\\end{bmatrix}\n\\]\nRow \\(1\\):\n\\[\n{\\color{blue}b_1} x_1 + {\\color{blue}c_1} x_2 = {\\color{blue}r_1}\n\\]\nDividing throughout by \\(\\color{blue}b_1\\),\n\\[\nx_1 + {\\color{blue}\\frac{c_1}{b_1}} x_2 = {\\color{blue}\\frac{r_1}{b_1}}\n\\]\nRewrite:\n\\[\nx_1 + {\\color{red}\\gamma_1} x_2 = {\\color{red}\\rho_1}, \\quad {\\color{red}\\gamma_1} = {\\color{blue}\\frac{c_1}{b_1}}, \\quad {\\color{red}\\rho_1} = {\\color{blue}\\frac{r_1}{b_1}}\n\\]\n\\[\n\\begin{bmatrix}\n{\\color{red}1} & {\\color{red}\\gamma_1} & 0 & 0 & 0 & 0\\\\\n{\\color{blue}a_2} & {\\color{blue}b_2} & {\\color{blue}c_2} & 0 & 0 & 0\\\\\n0 & {\\color{blue}a_3} & {\\color{blue}b_3} & {\\color{blue}c_3} & 0 & 0\\\\\n0 & 0 & {\\color{blue}a_4} & {\\color{blue}b_4} & {\\color{blue}c_4} & 0\\\\\n0 & 0 & 0 & {\\color{blue}a_5} & {\\color{blue}b_5} & {\\color{blue}c_5}\\\\\n0 & 0 & 0 & 0 & a_6 & b_6\n\\end{bmatrix} \\begin{bmatrix}\nx_1 \\\\\nx_2 \\\\\nx_3 \\\\\nx_4 \\\\\nx_5 \\\\\nx_6\n\\end{bmatrix} =\n\\begin{bmatrix}\n{\\color{red}\\rho_1} \\\\\n{\\color{blue}r_2} \\\\\n{\\color{blue}r_3} \\\\\n{\\color{blue}r_4} \\\\\n{\\color{blue}r_5} \\\\\n{\\color{blue}r_6}\n\\end{bmatrix}\n\\]\nRow \\(2\\):\n\\[\n{\\color{blue}a_2} x_1 + {\\color{blue}b_2} x_2 + {\\color{blue}c_2} x_3 = {\\color{blue}r_2}\n\\]\nUse \\(a_2\\) times row \\(1\\) of the matrix to eliminate the first term\n\\[\na_2(x_1 + {\\color{red}\\gamma_1}x_2 = {\\color{red}\\rho_1})\n\\]\n\\[\n\\begin{array}{c|cccc}\n\\text{Row 2} & a_2 x_1 &+ b_2 x_2 &+ c_2 x_3 &= r_2\\\\\na_2 \\times \\text{Row 1} & a_2 x_1 &+ a_2 \\gamma_1 x_2 & &= a_2\\rho_1\\\\\n\\hline\n\\text{New Row 2} & & (b_2 - a_2 \\gamma_1) x_2 &+ c_2 x_3  &= r_2 - a_2 \\rho_1\n\\end{array}\n\\]\nDividing throughout by \\((b_2 - a_2 \\gamma_1)\\), we get:\n\\[\nx_2 + \\frac{c_2}{b_2 - a_2 \\gamma_1}x_3 = \\frac{(r_2 - a_2 \\rho_1)}{(b_2 - a_2 \\gamma_1)}\n\\]\nWe can rewrite this as:\n\\[\nx_2 + \\gamma_2 x_3 = \\rho_2, \\quad \\gamma_2 = \\frac{c_2}{b_2 - a_2 \\gamma_1}, \\quad \\rho_2 = \\frac{(r_2 - a_2 \\rho_1)}{(b_2 - a_2 \\gamma_1)}\n\\]\n\\[\n\\begin{bmatrix}\n1 & \\gamma_1 & 0 & 0 & 0 & 0\\\\\n0 & 1 & \\gamma_2 & 0 & 0 & 0\\\\\n0 & a_3 & b_3 & c_3 & 0 & 0\\\\\n0 & 0 & a_4 & b_4 & c_4 & 0\\\\\n0 & 0 & 0 & a_5 & b_5 & c_5\\\\\n0 & 0 & 0 & 0 & a_6 & b_6\n\\end{bmatrix} \\begin{bmatrix}\nx_1 \\\\\nx_2 \\\\\nx_3 \\\\\nx_4 \\\\\nx_5 \\\\\nx_6\n\\end{bmatrix} =\n\\begin{bmatrix}\n\\rho_1 \\\\\n\\rho_2 \\\\\nr_3 \\\\\nr_4 \\\\\nr_5 \\\\\nr_6\n\\end{bmatrix}\n\\]\nRow \\(3\\):\n\\[\na_3 x_2 + b_3 x_3 + c_3 x_4 = r_3\n\\]\nUse \\(a_3\\) times row \\(2\\) of the matrix to eliminate the first term:\n\\[\n\\begin{array}{c|cccc}\n\\text{Row 3} & a_3 x_2 &+ b_3 x_3 &+ c_3 x_4 &= r_3\\\\\na_3 \\times \\text{Row 2} & a_3 x_2 &+ a_3 \\gamma_2 x_3 & &= a_3\\rho_2\\\\\n\\hline\n\\text{New Row 3} & & (b_3 - a_3 \\gamma_2) x_3 &+ c_3 x_4  &= r_3 - a_3 \\rho_2\n\\end{array}\n\\]\nDividing throughout by \\((b_3 - a_3 \\gamma_2)\\), we have:\n\\[\nx_3 + \\frac{c_3}{b_3 - a_3 \\gamma_2} x_4 = \\frac{r_3 - a_3\\rho_2}{b_3 - a_3 \\gamma_2}\n\\]\nWe can rewrite this as:\n\\[\nx_3 + \\gamma_3 x_4 = \\rho_3, \\quad  \\gamma_3 = \\frac{c_3}{b_3 - a_3 \\gamma_2}, \\quad \\rho_3=\\frac{r_3 - a_3 \\rho_2}{b_3 - a_3 \\gamma_2}\n\\]\nContinuing in this fashion, we get:\n\\[\n\\begin{bmatrix}\n1 & \\gamma_1 & 0 & 0 & 0 & 0\\\\\n0 & 1 & \\gamma_2 & 0 & 0 & 0\\\\\n0 & 1 & 1 & \\gamma_3 & 0 & 0\\\\\n0 & 0 & 0 & 1 & \\gamma_4 & 0\\\\\n0 & 0 & 0 & 0 & 1 & \\gamma_5\\\\\n0 & 0 & 0 & 0 & a_6 & b_6\n\\end{bmatrix} \\begin{bmatrix}\nx_1 \\\\\nx_2 \\\\\nx_3 \\\\\nx_4 \\\\\nx_5 \\\\\nx_6\n\\end{bmatrix} =\n\\begin{bmatrix}\n\\rho_1 \\\\\n\\rho_2 \\\\\n\\rho_3 \\\\\n\\rho_4 \\\\\n\\rho_5 \\\\\nr_6\n\\end{bmatrix}\n\\]\nRow \\(6\\):\n\\[\na_6 x_5 + a_6 x_6 = r_6\n\\]\nUse \\(a_6\\) times row 5 of the matrix:\n\\[a_6(x_5 + \\gamma_5 x_6 = \\rho_5)\\]\n\\[\n\\begin{array}{c|cccc}\n\\text{Row 6} & a_6 x_5 &+ b_6 x_6 &= r_6\\\\\na_6 \\times \\text{Row 5} & a_6 x_5 &+ a_6 \\gamma_5 x_6  &= a_6\\rho_5\\\\\n\\hline\n\\text{New Row 3} & & (b_6 - a_6 \\gamma_5) x_6  &= r_6 - a_6 \\rho_5\n\\end{array}\n\\]\nDividing throughout by \\((b_6 - a_6 \\gamma_5)\\), we can rewrite:\n\\[\nx_6 = \\rho_6, \\quad \\rho_6 = \\frac{r_6 - a_6 \\rho_5}{b_6 - a_6 \\gamma_5}\n\\]\n\\[\n\\begin{bmatrix}\n1 & \\gamma_1 & 0 & 0 & 0 & 0\\\\\n0 & 1 & \\gamma_2 & 0 & 0 & 0\\\\\n0 & 1 & 1 & \\gamma_3 & 0 & 0\\\\\n0 & 0 & 0 & 1 & \\gamma_4 & 0\\\\\n0 & 0 & 0 & 0 & 1 & \\gamma_5\\\\\n0 & 0 & 0 & 0 & 0 & 1\n\\end{bmatrix} \\begin{bmatrix}\nx_1 \\\\\nx_2 \\\\\nx_3 \\\\\nx_4 \\\\\nx_5 \\\\\nx_6\n\\end{bmatrix} =\n\\begin{bmatrix}\n\\rho_1 \\\\\n\\rho_2 \\\\\n\\rho_3 \\\\\n\\rho_4 \\\\\n\\rho_5 \\\\\n\\rho_6\n\\end{bmatrix}\n\\]\nThese steps may be summarized as compute the following sequences:\n\\[\n\\gamma_1 = \\frac{c_1}{b_1}, \\quad \\rho_1 = \\frac{r_1}{b_1}\n\\]\nAnd \\[\\gamma_j = \\frac{c_j}{b_j - a_j \\gamma_{j-1}}, \\quad \\rho_j = \\frac{r_j - a_j \\rho_{j-1}}{b_j - a_j \\gamma_{j-1}}\\]\nfor \\(j=2:6\\).\nAt this point, the matrix has been reduced to the upper diagonal form, so our equations are of the form \\(Ux = \\rho\\).\n\n\nStage 2\nThe matrix is now in a form which is trivial to solve for \\(x\\). We start with the last row and work our way up. The final equation is already solved.\n\\[\nx_6 = \\rho_6\n\\]\n\\[\n\\begin{bmatrix}\n1 & \\gamma_1 & 0 & 0 & 0 & 0\\\\\n0 & 1 & \\gamma_2 & 0 & 0 & 0\\\\\n0 & 1 & 1 & \\gamma_3 & 0 & 0\\\\\n0 & 0 & 0 & 1 & \\gamma_4 & 0\\\\\n0 & 0 & 0 & 0 & 1 & \\gamma_5\\\\\n0 & 0 & 0 & 0 & 0 & 1\n\\end{bmatrix} \\begin{bmatrix}\nx_1 \\\\\nx_2 \\\\\nx_3 \\\\\nx_4 \\\\\nx_5 \\\\\nx_6\n\\end{bmatrix} =\n\\begin{bmatrix}\n\\rho_1 \\\\\n\\rho_2 \\\\\n\\rho_3 \\\\\n\\rho_4 \\\\\n\\rho_5 \\\\\n\\rho_6\n\\end{bmatrix}\n\\]\nRow \\(5\\): \\[\nx_5 + \\gamma_5 x_6 = \\rho_5\n\\]\nRearrange to get:\n\\[\nx_5 = \\rho_5 - \\gamma_5 x_6\n\\]\nRow \\(4\\):\n\\[\nx_4 + \\gamma_4 x_5 = \\rho_4\n\\]\nRearrange to get:\n\\[\nx_4 = \\rho_4 - \\gamma_4 x_5\n\\]\nContinuing in this fashion, we find that, \\(x_6 = \\rho_6\\) and\n\\[\nx_j = \\rho_j - \\gamma_j x_{j+1}\n\\]\nfor all \\(j=1:5\\)."
  },
  {
    "objectID": "posts/tridiagonal-systems/index.html#computational-solution",
    "href": "posts/tridiagonal-systems/index.html#computational-solution",
    "title": "Tridiagonal Systems",
    "section": "Computational Solution",
    "text": "Computational Solution\nLet’s quickly code up the algorithm in Julia.\n\nfunction thomasAlgorithm(a, b, c, r)\n    N = size(a)[1]\n\n    # Stage 1\n    γ = Array{Float64,1}(undef,N)\n    ρ = Array{Float64,1}(undef,N)\n    u = Array{Float64,1}(undef,N)\n\n    γ[1] = c[1]/b[1]\n    ρ[1] = r[1]/b[1]\n\n    for j=2:N\n        γ[j] = c[j]/(b[j] - a[j] * γ[j-1])\n        ρ[j] = (r[j] - a[j] * ρ[j-1])/(b[j] - a[j] * γ[j-1])\n    end\n\n    # Stage 2\n    u[N] =  ρ[N]\n\n    for j=reverse(1:N-1)\n        u[j] = ρ[j] - γ[j] * u[j+1]\n    end\n\n    return u\nend\n\n# Test Case\n\na = Array{Float64,1}([0, 2, 2, 2])\nb = Array{Float64,1}([3, 3, 3, 3])\nc = Array{Float64,1}([2, 2, 2, 0])\nr = Array{Float64,1}([12, 17, 14, 7])\nu = thomasAlgorithm(a, b, c, r)\n\nprint(u)\n\n[2.0, 3.0, 1.9999999999999996, 1.0000000000000004]\n\n\nHere is an implementation in modern C++:\n#include &lt;iostream&gt;\n#include &lt;memory&gt;\n#include &lt;functional&gt;\n#include &lt;concepts&gt;\n\ntemplate &lt;typename T&gt;\nconcept Real = std::integral&lt;T&gt; || std::floating_point&lt;T&gt;;\n\ntemplate &lt;typename T&gt;\nrequires Real&lt;T&gt;\nusing Function = std::function&lt;void(std::vector&lt;T&gt;, std::vector&lt;T&gt;, std::vector&lt;T&gt;, std::vector&lt;T&gt;, std::vector&lt;T&gt;&)&gt;;\n\ntemplate &lt;typename T&gt;\nrequires Real&lt;T&gt;\nvoid thomasAlgorithm(\n      std::vector&lt;T&gt; a\n    , std::vector&lt;T&gt; b\n    , std::vector&lt;T&gt; c\n    , std::vector&lt;T&gt; r\n    , std::vector&lt;T&gt;&x \n    ){\n    //Stage-1\n    int N = a.size();\n    std::vector&lt;T&gt; gamma(N);\n    std::vector&lt;T&gt; rho(N);\n    x = std::vector&lt;T&gt;(N);\n\n    gamma[0] = c[0]/b[0]; \n    rho[0] = r[0]/b[0];\n\n    for(int j{1}; j &lt; N; ++j)\n    {\n        gamma[j] = c[j]/(b[j] - a[j] * gamma[j-1]);\n        rho[j] = (r[j] - a[j] * rho[j-1])/(b[j] - a[j] * gamma[j-1]);\n    }\n\n    //Stage-2\n    x[N-1] = rho[N-1];\n    for(int j{N-2}; j &gt;= 0; j--)\n    {\n        x[j] = rho[j] - gamma[j] * x[j+1];\n    }\n}\n\ntemplate &lt;typename T&gt;\nrequires Real&lt;T&gt;\nclass LUTridiagonalSolver{\n    private:\n        std::vector&lt;T&gt; m_a;\n        std::vector&lt;T&gt; m_b;\n        std::vector&lt;T&gt; m_c;\n        std::vector&lt;T&gt; m_r;\n        std::vector&lt;T&gt; m_x;\n        Function&lt;T&gt; m_LUTridiagonalSolverStrategy;\n    \n    public:\n        LUTridiagonalSolver() = default;\n        LUTridiagonalSolver(\n              std::vector&lt;T&gt; a\n            , std::vector&lt;T&gt; b\n            , std::vector&lt;T&gt; c\n            , std::vector&lt;T&gt; r\n            , Function&lt;T&gt; solver) \n            : m_a {std::move(a)}\n            , m_b {std::move(b)}\n            , m_c {std::move(c)}\n            , m_r {std::move(r)}\n            , m_LUTridiagonalSolverStrategy {solver} \n            {}\n\n        std::vector&lt;T&gt; solve(){\n            m_LUTridiagonalSolverStrategy(m_a, m_b, m_c, m_r, m_x);\n            return m_x;\n        }\n\n        LUTridiagonalSolver(const LUTridiagonalSolver& ) = delete;\n        LUTridiagonalSolver operator=(LUTridiagonalSolver& ) = delete;\n        ~LUTridiagonalSolver(){}\n};\n\nint main()\n{\n    std::vector&lt;double&gt; a{0, 2, 2, 2};\n    std::vector&lt;double&gt; b{3, 3, 3, 3};\n    std::vector&lt;double&gt; c{2, 2, 2, 0};\n    std::vector&lt;double&gt; r{12, 17, 14, 7};\n\n    LUTridiagonalSolver&lt;double&gt; solver(a, b, c, r, thomasAlgorithm&lt;double&gt;);\n    std::vector&lt;double&gt; u = solver.solve();\n    return 0;\n}\nCompiler Explorer"
  },
  {
    "objectID": "posts/tridiagonal-systems/index.html#deriving-the-one-dimensional-heat-equation",
    "href": "posts/tridiagonal-systems/index.html#deriving-the-one-dimensional-heat-equation",
    "title": "Tridiagonal Systems",
    "section": "Deriving the one-dimensional Heat equation",
    "text": "Deriving the one-dimensional Heat equation\nConsider a slender homogenous rod, lying along the \\(x\\)-axis and insulated, so that no heat can escape across its longitudinal surface. In addition, we make the simplifying assumption that the temperature in the rod is constant on each cross-section perpendicular to the \\(x\\)-axis, and thus that the flow of heat in the rod takes place only in the \\(x\\)-direction.\nConsider a small segment of the rod at position \\(x\\) of length \\(\\Delta x\\).\nThe thermal energy in this segment at time \\(t\\) is:\n\\[\nE(x,x+\\Delta x, t) \\approx u(x,t) s \\rho \\Delta x\n\\]\nwhere \\(s\\) is the constant of specific heat i.e. amount of heat required to raise one unit of mass by one unit of temperature, \\(\\rho\\) is the mass density.\nFourier’s law of heat conduction quantifies the idea that heat flows from warmer to colder regions and states that the (rightward) heat flux density \\(\\phi(x,t)\\) (the flow of heat energy per unit area per unit time, SI units \\(J/s/m^2\\)) at any point is:\n\\[\n\\phi(x,t) = -K_0 u_x (x, t)\n\\]\nwhere \\(K_0\\) is the thermal conductivity of the rod. The negative sign shows that the heat flows from higher temperature regions to colder temperature regions.\nAppealing to the law of conservation of energy:\n\\[\n\\begin{align*}\n\\underbrace{\\frac{\\partial}{\\partial t}(u(x,t) s \\rho \\Delta x)}_{\\text{Heat flux through segment}} = \\underbrace{(-K_0 u_x(x, t))}_{\\text{Flux in}} - \\underbrace{(- K_0 u_x(x + \\Delta x,t))}_{\\text{Flux out}}\n\\end{align*}\n\\tag{2}\\]\nDividing throughout by \\(\\Delta x\\) we have:\n\\[\n\\begin{align*}\nu_t(x,t) \\approx \\frac{K_0}{s \\rho } \\frac{u_x(x+\\Delta x, t) - u_x(x,t)}{\\Delta x}\n\\end{align*}\n\\]\nLetting \\(\\Delta x \\to 0\\) improves the approximation and leads to the heat equation:\n\\[\nu_t=c^2 u_{xx}\n\\]\nwhere \\(c^2 = \\frac{K_0}{\\rho s}\\) is called the thermal diffusivity."
  },
  {
    "objectID": "posts/tridiagonal-systems/index.html#the-crank-nicolson-and-theta-methods",
    "href": "posts/tridiagonal-systems/index.html#the-crank-nicolson-and-theta-methods",
    "title": "Tridiagonal Systems",
    "section": "The Crank-Nicolson and Theta methods",
    "text": "The Crank-Nicolson and Theta methods\nConsider the initial boundary value problem for the \\(1\\)d-heat equation:\n\\[\n\\begin{align*}\nu_t &= a^2 u_{xx}, \\quad & 0 &lt; x &lt; L, t&gt;0\\\\\nu(x,0) &= f(x), \\quad 0 \\leq x \\leq L \\\\\nu(0,t) &= A, \\\\\nu(L,t) &= B\n\\end{align*}\n\\]\nIn this case, we can assume without the loss of generality that \\(L = 1\\). Here, \\(a\\), \\(A\\) and \\(B\\) are constants.\nWe find a solution to this system in the case when \\(A = B = 0\\) and \\(a = 1\\) by the method of the separation of variables. In this case, the analytical solution is:\n\\[\nu(x,t) = \\frac{8}{\\pi^2}\\sum_{n=1}^{\\infty}\\frac{1}{n^2}\\sin\\left(\\frac{n\\pi}{2}\\right)\\sin(n\\pi x)\\exp(-n^2 \\pi^2 t)\n\\]\nand we are going to use this solution as a benchmark against which the numerical solutions can be compared.\nWe can discretize a parabolic PDE in the space dimension (using centered difference schemes) while keeping the time variable continuous. We examine the following initial boundary value problem for the \\(1\\)d-heat equation on the unit interval with zero Dirichlet boundary conditions.\nThe problem is:\n\\[\n\\begin{align*}\nu_t &= u_{xx}, \\quad & 0 &lt; x &lt; 1, t&gt;0\\\\\nu(x,0) &= f(x), \\quad 0 \\leq x \\leq 1 \\\\\nu(0,t) &= u(1,t) = 0\n\\end{align*}\n\\tag{3}\\]\nWe partition the space interval \\((0,1)\\) into \\(J\\) subintervals and we approximate Equation 3 by the semi-discrete scheme:\n\\[\n\\begin{align*}\n\\frac{dU_j}{dt} &= \\frac{1}{h^2}(U_{j+1} - 2U_j + U_{j-1}), \\quad 1 \\leq j \\leq J-1 \\\\\nU_0(t) &= U_J(t) = 0, \\quad t &gt; 0 \\\\\nU_j(0) &= f(x_j)\n\\end{align*}\n\\]\nwhere \\(h = 1/J\\) is the constant mesh size. The \\(U_j\\)’s are functions of time \\(t\\). So, we define the following vectors:\n\\[\n\\begin{align*}\nU(t) &= (U_1(t),U_2(t),\\ldots,U_J(t))^T \\\\\nU^0 &= (f(x_1),f(x_2),\\ldots,f(x_{J-1}))^T\n\\end{align*}\n\\]\nThen, we can rewrite the system Equation 3 as a system of ordinary differential equations:\n\\[\n\\begin{align*}\n\\frac{dU}{dt} &= AU\\\\\nU(0) &= U^0\n\\end{align*}\n\\tag{4}\\]\nwhere the matrix \\(A\\) is given by:\n\\[\nA = \\frac{1}{h^2}\\begin{bmatrix}\n-2 & 1 & 0 & \\ldots \\\\\n1  &-2 & 1 & \\ldots \\\\\n0  & 1 & -2 & \\ldots \\\\\n   &   &    & \\ldots \\\\\n      &   &    & \\ldots & 1 & -2 & 1\\\\\n      &   &    & \\ldots & 0 & 1  & -2\\\\\n\\end{bmatrix}\n\\]\nThere are many discretization schemes. I plan to explore various finite difference schemes and their application to derivatives pricing in future posts. For now, I will concentrate on the one-step explicit and implicit methods to discretise the system of ODEs(Equation 4) as:\n\\[\n\\begin{align*}\n\\frac{U^{n+1 - U^n}}{\\Delta t} &= \\theta AU^{n+1} + (1-\\theta)AU^{n}, \\quad 0 \\leq n \\leq N-1, 0 \\leq \\theta \\leq 1 \\\\\nU^{0} &= U(0)\n\\end{align*}\n\\tag{5}\\]\nIn this case, \\(\\Delta t\\) is the constant mesh size in time.\nWe can rewrite Equation 5 in the equivalent form:\n\\[\n\\begin{align*}\nU^{n+1} - U^{n} &= \\theta \\Delta t A U^{n+1} + \\Delta t (I- \\theta)AU^{n} \\\\\n[I - \\Delta t A]U^{n+1} &= (\\Delta t (1 - \\theta) + 1)AU^n\n\\end{align*}\n\\tag{6}\\]\nor formally as:\n\\[\n\\begin{align*}\nU^{n+1} = [1-\\Delta t \\theta A]^{-1} (I + \\Delta t(I - \\theta)) A U^n\n\\end{align*}\n\\tag{7}\\]\nwhere \\(I\\) is the identity matrix.\nSome special cases of \\(\\theta\\) are:\n\\[\n\\begin{align*}\n\\theta &= 1, \\quad \\text{Implicit Euler Scheme}\\\\\n\\theta &= 0, \\quad \\text{Explicit Euler Scheme}\\\\\n\\theta &= 1/2,\\quad \\text{Crank-Nicolson Scheme}\n\\end{align*}\n\\tag{8}\\]\nWhen the schemes are implicit, we can solve the system of equations (Equation 5) at each time level \\(n+1\\) using the Thomas algorithm. No matrix inversion is needed in the case of explicit schemes. The formulation (Equation 4) is called the method of lines and it corresponds to semi-discretization of the PDE in the space direction while keeping the time variable continuous (I will explore MOL in future posts).\nWe can write the scheme (Equation 6 - Equation 8) in the component form:\n\\[\n\\begin{align*}\n\\frac{U^{n+1}j - U^{n}j}{\\Delta t} = \\theta(U^{n+1}_{j+1}-2U^{n+1}_j + U^{n+1}_{j-1})/h^2 + (1-\\theta)(U^{n}_{j+1}-2U^{n}_j + U^{n}_{j-1})/h^2\n\\end{align*}\n\\tag{9}\\]\nor equivalently:\n\\[\n\\begin{align*}\n{U^{n+1}j - U^{n}_j} &= \\lambda\\theta(U^{n+1}_{j+1}-2U^{n+1}_j + U^{n+1}_{j-1})/h^2 \\\\&+ (1-\\theta)(U^{n}_{j+1}-2U^{n}_j + U^{n}_{j-1})\n\\end{align*}\n\\]\nwhere \\(\\lambda = \\Delta t/h^2\\).\nFinally:\n\\[\n\\begin{align*}\n-\\lambda \\theta U^{n+1}_{j+1} + (1+2\\lambda \\theta)U_j^{n+1} - \\lambda \\theta U^{n+1}_{j-1} \\\\= \\lambda (1-\\theta)U^{n}_{j+1}+(1-2\\lambda(1-\\theta))U^{n}_j + \\lambda(1-\\theta)U^{n}_{j-1}\n\\end{align*}\n\\tag{10}\\]\nThe system (Equation 10) is tridiagonal and we can apply the Thomas algorithm to solve it. In the case of the explicit Euler scheme \\((\\theta = 0)\\), these algorithms are not needed, because the solution at time level \\(n+1\\) can be explicitly computed:\n\\[\n\\begin{align*}\nU^{n+1}_j = \\lambda U^{n}_{j+1} + (1-2\\lambda)U^{n}_j +\\lambda U^{n}_{j-1}\n\\end{align*}\n\\tag{11}\\]\n\nComputational Solution\nI implemented the algorithm in Equation 10. This is a one-step marching scheme called BTCS(Backward in Time, Centered in Space) that computes the solution at time level \\(n+1\\) in terms of the solution at time \\(n\\). Since there are three unknowns to be computed at each time level \\(n+1\\), we need to use the Thomas algorithm. The main steps in the algorithm are:\n\nChoose input parameters and generate meshes\nDefine the initial solution and the boundary conditions\nCompute the solution at each time upto and including expiration."
  },
  {
    "objectID": "posts/unique_ptr/index.html",
    "href": "posts/unique_ptr/index.html",
    "title": "unique_ptr - A custom implementation",
    "section": "",
    "text": "In this post, I try to write a simple homegrown version of std::unique_ptr&lt;T&gt;. This post is partly inspired by the fantastic book C++ Memory Management by Patrice Roy. Tghe toy examples in this book are very instructive and I highly reckon you order a copy. Our goal is just to build intuition for the kind of code required to write such a type, and not to try and replace the standard library facilities.\nThe std::unique_ptr&lt;T&gt; smart pointer type models unqiue(sole) ownership of the resource semantics.\nstruct X{};\n\nstd::unique_ptr&lt;X&gt; p1 = std::make_unique&lt;X&gt;();  \n//std::unique_ptr&lt;X&gt; p2(p1);      // Error when calling copy constructor, \n                                  // p1 is the exclusive owner\nstd::unique_ptr enforces exclusive ownership using the fact, that it is not copy-constructible or copy-assignable. Note however, that it doesn’t prevent you from writing deliberately hostile code. The below code is compiles perfectly well and is valid C++.\nint* p = new int(10);\n\nstd::unique_ptr&lt;int&gt; p1(p);  \nstd::unique_ptr&lt;int&gt; p2(p);      \nThe copy constructor and the copy assignment operator of std::unique_ptr&lt;T&gt; are marked delete. It is however, move constructible and move-assignable."
  },
  {
    "objectID": "posts/unique_ptr/index.html#references",
    "href": "posts/unique_ptr/index.html#references",
    "title": "unique_ptr - A custom implementation",
    "section": "References",
    "text": "References\n\n\nC++ Memory Management by Patrice Roy*."
  },
  {
    "objectID": "posts/make-shared-and-make-unique/index.html",
    "href": "posts/make-shared-and-make-unique/index.html",
    "title": "A note on make_shared<T>(Args&&...) and make_unique<T>(Args&&...)",
    "section": "",
    "text": "A note on make_unique&lt;T&gt;(Args&&...)\nSince C++14, unique_ptr&lt;T&gt; has been accpompanied by the factory function make_unique&lt;T&gt;(Args&&...) that perfectly forwards its arguments to the constructor of T. Why standard library implementors provide a separate factory function make_unique&lt;T&gt;(Args&&...), when the constructor unique_ptr&lt;T&gt;(T*) does the same job?\nstd::unique_ptr&lt;T&gt; models ownership of the resource semantics. Calling unique_ptr&lt;T&gt;(T*) makes the client code responsible for supplying a pre-existing T object whose address is passed as an argument.\nConsider the following code snippet:\n#include&lt;iostream&gt;\n#include&lt;memory&gt;\n\ntemplate&lt;typename T&gt;\nclass pair_allocator{\n    private:\n    std::unique_ptr&lt;T&gt; p1;\n    std::unique_ptr&lt;T&gt; p2;\n\n    public:\n    pair_allocator() = default;\n    pair_allocator(T x, T y)\n    : p1(new T(x))\n    , p2(new T(y))\n    {}\n\n    ~pair_allocator() = default;\n};\nWe know that, the member subobjects of a C++ object are constructed in the order of their declaration. So, p1 is constructed before p2. Also, the allocation and construction operation new T(x) precedes the construction of p1. new T(y) precedes the construction of p2.\nDenoting \\(A:=\\) new T(x), \\(B:=\\) Construction of p1, \\(C:=\\) new T(y), \\(D:=\\) Construction of p2.\nIf we see the rules laid out above, we could have the operations in the following order: \\(A \\rightarrow B \\rightarrow C \\rightarrow D\\), but we could also have \\(A \\rightarrow C \\rightarrow B \\rightarrow D\\) or \\(C \\rightarrow A \\rightarrow B \\rightarrow D\\), in which case the two calls to new T(...) occur prior to the construction of p1 and p2. If this happens, then an exception thrown by the second call to new T(...) would lead to a memory leak, because we fail to release the memory allocated by the first call to new T().\nThe factory function make_unique&lt;T&gt;(Args&&...) is a wrapper over the operations new T() and unique__ptr&lt;T&gt;(), and so if the second call to new T() fails, the object p1 goes out of scope, its destructor ~unique_ptr&lt;T&gt;() in turn calls operator delete T, destroying the T object and releasing the memory held by T.\nIf we modify the above snippet as:\n#include&lt;iostream&gt;\n#include&lt;memory&gt;\n\ntemplate&lt;typename T&gt;\nclass pair_allocator{\n    private:\n    std::unique_ptr&lt;T&gt; p1;\n    std::unique_ptr&lt;T&gt; p2;\n\n    public:\n    pair_allocator() = default;\n    pair_allocator(T x, T y)\n    : p1(make_unique&lt;T&gt;(x))\n    , p2(make_unique&lt;T&gt;(y))\n    {}\n\n    ~pair_allocator() = default;\n};\nIn this instance, the client code will never find itself with floating results from calls to new. make_unique&lt;T&gt; is therefore a security feature that prevents client code being exposed to ownerless resources.\n\n\nA note on make_shared&lt;T&gt;(Args&&...)\nIn modern C++, it is recommended practice to replace this:\nstd::shared_ptr&lt;T&gt; p(\n    new T{ /* ... constructor args ... */ }\n);\nwith\nstd::shared_ptr&lt;T&gt; p = std::make_shared&lt;T&gt;( \n    /* ... constructor args ... */\n)\nOne might wonder, why this is recommended practice? To understand why the factory function make_shared&lt;T&gt;(/* ... ctor args ...*/) is preferred to the constructor shared_ptr&lt;T&gt;( new T( /*... ctor args ...*/) ), we need to realize that with the shared_ptr&lt;T&gt;(T*) constructor, the client code is reponsible for the construction of the T object (pointee), and is then given to shared_ptr&lt;T&gt; under construction, which takes ownership of the pointer and allocates a shared counter separately. So, there are two separate allocations (the T object and the counter), probably on different cache lines.\n\n\n\n\n\n\nNote\n\n\n\nThe cache memory usually keeps 64-byte lines of memory. A cache line is also the smallest fundamental unit of data transfer between the CPU cache and the main memory. On most architectures, a cache line is 64 bytes or 128 bytes.\n\n\nNow, if we go through make_shared&lt;T&gt;(), this factory function is responsible for allocating both the T object and the counter, perfectly forwarding the constructor arguments received by the function to the constructor of T. Since, the same function performs both allocations, it can fuse them into a single allocation of a memory block that contains both the T object and the shared counter, putting them both on the same cache line. This can lead to enhanced performance characteristics, if a single thread tries to read from both the pointers (T* and the counter) in a short span of time.\nIn most libraries, the factory function make_shared&lt;T&gt; is implemented as:\ntemplate&lt;typename T, typename... Args&gt;\nstd::shared_ptr&lt;T&gt; make_shared(Args&&... args){\n    return std::shared_ptr(\n        new T(std::forward&lt;T&gt;(args)...)\n    );\n}"
  },
  {
    "objectID": "roadmap.html#books",
    "href": "roadmap.html#books",
    "title": "C++ Roadmap",
    "section": "Books",
    "text": "Books\n\nFundamentals.\n\nBeginning C++23 from Beginner to Pro, by Ivor Horton and Peter Van Weert\nC++ Move Semantics by Nicolai M. Josuttis.\nConcurrency in Action by Anthony Williams.\n\n\n\nSpecialized books.\n\nGeneric programming.\n\nTemplate Metaprogramming with C++ by Mariuz Bancilla.\n\n\n\nMemory Management.\n\nC++ Memory Management by Patrice Roy.\n\n\n\nMultithreaded and asynchronous programming.\n\nAsynchronous Programming with C++ by Javier Reguera-Salgado and Juan Antonio Rufes."
  },
  {
    "objectID": "roadmap.html#technical-interviews.",
    "href": "roadmap.html#technical-interviews.",
    "title": "C++ Roadmap",
    "section": "Technical Interviews.",
    "text": "Technical Interviews.\n\ngetcracked.io"
  },
  {
    "objectID": "roadmap.html#technical-interviews",
    "href": "roadmap.html#technical-interviews",
    "title": "C++ Roadmap",
    "section": "Technical Interviews",
    "text": "Technical Interviews\n\ngetcracked.io - One of the best collections of clever C++ interview puzzles maintained and updated by CodingJesus that truly test C++, OS and computer architecture concepts at deeper-level."
  },
  {
    "objectID": "roadmap.html#blog-rolls",
    "href": "roadmap.html#blog-rolls",
    "title": "C++ Roadmap",
    "section": "Blog-rolls",
    "text": "Blog-rolls"
  },
  {
    "objectID": "roadmap.html#blog-rolls-worth-reading",
    "href": "roadmap.html#blog-rolls-worth-reading",
    "title": "C++ Roadmap",
    "section": "Blog-rolls worth reading",
    "text": "Blog-rolls worth reading\n\ncppstories - Excellent blog worth following for explorative learning with really cool toy examples by Bartlomiej Filipek (or Bartek) from Krakow, Poland"
  },
  {
    "objectID": "posts/custom-iterators/index.html#stdinput_or_output_iterator",
    "href": "posts/custom-iterators/index.html#stdinput_or_output_iterator",
    "title": "Custom iterators and Iterator concepts",
    "section": "std::input_or_output_iterator",
    "text": "std::input_or_output_iterator\nThe input_or_output_iterator is the basis of the iterator concept taxonomy. It only requires that an iterator type It supports the operations for dereferencing and incrementing the iterator."
  },
  {
    "objectID": "posts/custom-iterators/index.html#stdoutput_iterator",
    "href": "posts/custom-iterators/index.html#stdoutput_iterator",
    "title": "Custom iterators and Iterator concepts",
    "section": "std::output_iterator",
    "text": "std::output_iterator\nstd::output_iterator concept models the idea of a write-only iterator. E.g. such an iterator can be used to write to the standard output stream. Hence, they can only be dereferenced on the left-hand side of an assignment operator.\nSince, they are single pass, we don’t even need to implement an equality comparison operator, because they don’t have an end iterator or sentinel value to compare against.\n#include &lt;cstddef&gt;\n#include &lt;iterator&gt;\n#include &lt;concepts&gt;\n\ntemplate&lt;typename T&gt;\nstruct SimpleOutputIterator {\n    using difference_type = std::ptrdiff_t;\n    using value_type = T;\n    using pointer = T*;\n\n    pointer m_buffer_ptr;\n\n    // Default constructor\n    SimpleOutputIterator() = default;\n\n    // Constructor\n    SimpleOutputIterator(pointer start)\n        : m_buffer_ptr{start} {}\n\n    // Dereference operator\n    T& operator*() {\n        return *m_buffer_ptr;\n    }\n\n    // Pre-increment\n    SimpleOutputIterator& operator++() {\n        ++m_buffer_ptr;\n        return (*this);\n    }\n\n    // Post-increment\n    SimpleOutputIterator operator++(int) {\n        auto tmp = *this;\n        ++(*this);\n        return tmp;\n    }\n\n};\n\nstatic_assert(std::output_iterator&lt;SimpleOutputIterator&lt;int&gt;, int&gt;);\n\n\nint main(){\n    return 0;\n}\nCompiler Explorer"
  },
  {
    "objectID": "posts/custom-iterators/index.html#stdinput_iterator",
    "href": "posts/custom-iterators/index.html#stdinput_iterator",
    "title": "Custom iterators and Iterator concepts",
    "section": "std::input_iterator",
    "text": "std::input_iterator\nstd::input_iterator concept models the idea of a read-only iterator. Such an iterator, for example, can be used read packets data from a network socket.\nInput iterators are also single-pass, because once you’ve read a byte of data from a network socket, you can’t read it again. They must also be comparable to some sentinel value such as EOF, \\0, to signal the end of data etc.\nHowever, the equality comparison operator bool operator==(It, Sen) is only used by the algorithm operating on the container, and therefore it’s the responsibility of the algorithm writer to supply an implementation of bool operator==(It, Sen). This definition is not required in the container implementation.\n#include &lt;cstddef&gt;\n#include &lt;iterator&gt;\n#include &lt;concepts&gt;\n\ntemplate&lt;typename T&gt;\nstruct SimpleInputIterator {\n    using difference_type = std::ptrdiff_t;\n    using value_type = T;\n    using pointer = T*;\n    using reference = T&;\n\n    pointer m_socket_fd;\n\n    // Default constructor\n    SimpleInputIterator() = default;\n\n    // Constructor\n    SimpleInputIterator(pointer start)\n        : m_socket_fd{start} {}\n\n    // Dereference operator\n    const T& operator*() const {\n        return *m_socket_fd;\n    }\n\n    // Pre-increment\n    SimpleInputIterator& operator++() {\n        ++m_socket_fd;\n        return (*this);\n    }\n\n    // Post-increment\n    SimpleInputIterator operator++(int) {\n        auto tmp = *this;\n        ++(*this);\n        return tmp;\n    }\n\n};\n\nstatic_assert(std::input_iterator&lt;SimpleInputIterator&lt;int&gt;&gt;);\n\n\nint main(){\n    return 0;\n}\nCompiler Explorer"
  },
  {
    "objectID": "posts/custom-iterators/index.html#stdforward_iterator",
    "href": "posts/custom-iterators/index.html#stdforward_iterator",
    "title": "Custom iterators and Iterator concepts",
    "section": "std::forward_iterator",
    "text": "std::forward_iterator\nstd::forward_iterator requires that the iterator type be an input (read-only) iterator and also be std::incrementable.\nstd::input_iterator only requires the iterator be std::weakly_incrementable. So while it supports the increment operator++(), if i and j are two instances of the iterator type It, i == j does not imply ++i == ++j. That is, algorithms on weakly-incrementable types must be single-pass algorithms.\nstd::incrementable concept informally means that i == j \\(\\implies\\) ++i == ++j. Algorithms on incrementable types are multi-pass algorithms.\nYou might use an iterator satisfying std::forward_iterator concept to traverse through a std::forward_list (a singly linked-list).\n#include &lt;cstddef&gt;\n#include &lt;iterator&gt;\n#include &lt;concepts&gt;\n\ntemplate &lt;typename T&gt;\nstruct list_node {\n    T m_data;\n    list_node* m_next;\n};\n\ntemplate &lt;typename T&gt;\nstruct SimpleForwardIterator {\n    using difference_type = std::ptrdiff_t;\n    using value_type = T; // The value type is T, not list_node&lt;T&gt;\n    using pointer = T*;\n    using reference = T&;\n\n    list_node&lt;T&gt;* m_node_ptr;\n\n    // Default constructor\n    SimpleForwardIterator() = default;\n\n    // Constructor\n    SimpleForwardIterator(list_node&lt;T&gt;* start)\n        : m_node_ptr{start} {}\n\n    // Dereference operator\n    reference operator*() const {\n        return m_node_ptr-&gt;m_data; // Return the data stored in the node\n    }\n\n    // Pre-increment\n    SimpleForwardIterator& operator++() {\n        m_node_ptr = m_node_ptr-&gt;m_next;\n        return *this;\n    }\n\n    // Post-increment\n    SimpleForwardIterator operator++(int) {\n        auto tmp = *this;\n        ++(*this);\n        return tmp;\n    }\n\n    // Equality comparison\n    bool operator==(const SimpleForwardIterator& other) const {\n        return m_node_ptr == other.m_node_ptr;\n    }\n\n    // Inequality comparison\n    bool operator!=(const SimpleForwardIterator& other) const {\n        return !(*this == other);\n    }\n};\n\nstatic_assert(std::forward_iterator&lt;SimpleForwardIterator&lt;int&gt;&gt;);\n\nint main() {\n    return 0;\n}\nCompiler Explorer"
  },
  {
    "objectID": "posts/custom-iterators/index.html#references",
    "href": "posts/custom-iterators/index.html#references",
    "title": "Custom iterators and Iterator concepts",
    "section": "References",
    "text": "References\n\n\ncpp iterators in depth by Braden Hitchcock."
  },
  {
    "objectID": "posts/custom-iterators/index.html#stdbidirectional_iterator",
    "href": "posts/custom-iterators/index.html#stdbidirectional_iterator",
    "title": "Custom iterators and Iterator concepts",
    "section": "std::bidirectional_iterator",
    "text": "std::bidirectional_iterator\nA std::list is a doubly linked that supports both traversals in the forward as well as reverse direction. When we want to be able to move forward and backwards across our collection, we must implement an iterator satisfying std::bidirectional_iterator concept.\nYou need to implement pre-increment, post-increment, pre-decrement and post-decrement operations.\n#include &lt;cstddef&gt;\n#include &lt;iterator&gt;\n#include &lt;concepts&gt;\n\ntemplate &lt;typename T&gt;\nstruct list_node {\n    T m_data;\n    list_node* m_next;\n    list_node* m_prev;\n};\n\ntemplate &lt;typename T&gt;\nstruct SimpleBidirectionalIterator {\n    using difference_type = std::ptrdiff_t;\n    using value_type = T; // The value type is T, not list_node&lt;T&gt;\n    using pointer = T*;\n    using reference = T&;\n\n    list_node&lt;T&gt;* m_node_ptr;\n\n    // Default constructor\n    SimpleBidirectionalIterator() = default;\n\n    // Constructor\n    SimpleBidirectionalIterator(list_node&lt;T&gt;* start)\n        : m_node_ptr{start} {}\n\n    // Dereference operator\n    reference operator*() const {\n        return m_node_ptr-&gt;m_data; // Return the data stored in the node\n    }\n\n    // Pre-increment\n    SimpleBidirectionalIterator& operator++() {\n        m_node_ptr = m_node_ptr-&gt;m_next;\n        return *this;\n    }\n\n    // Post-increment\n    SimpleBidirectionalIterator operator++(int) {\n        auto tmp = *this;\n        ++(*this);\n        return tmp;\n    }\n\n    // Pre-decrement\n    SimpleBidirectionalIterator& operator--(){\n        m_node_ptr = m_node_ptr-&gt;m_prev;\n        return *this;\n    }\n\n    // Post-decrement\n    SimpleBidirectionalIterator operator--(int){\n        auto tmp = *this;\n        --(*this);\n        return tmp;\n    }\n\n    // Equality comparison\n    bool operator==(const SimpleBidirectionalIterator& other) const {\n        return m_node_ptr == other.m_node_ptr;\n    }\n\n    // Inequality comparison\n    bool operator!=(const SimpleBidirectionalIterator& other) const {\n        return !(*this == other);\n    }\n};\n\nstatic_assert(std::bidirectional_iterator&lt;SimpleBidirectionalIterator&lt;int&gt;&gt;);\n\nint main() {\n    return 0;\n}\nCompiler Explorer"
  },
  {
    "objectID": "posts/custom-iterators/index.html#stdrandom_access_iterator",
    "href": "posts/custom-iterators/index.html#stdrandom_access_iterator",
    "title": "Custom iterators and Iterator concepts",
    "section": "std::random_access_iterator",
    "text": "std::random_access_iterator\nContainers such as std::vector&lt;T&gt; and std::array&lt;T,N&gt; are a collection of elements that are stored contiguously in memory. Hence, the element at index i can be accessed in \\(O(1)\\) constant-time.\nWhat if I want to code up an iterator for jumping around the collection? Such an iterator must satisfy the std::random_access_iterator concept. The std::random_access_iterator concept requires that advancement with +=, -=, + and -, computation of distance between two elements and element access using the indexing operator [] be constant-time operations.\n#include &lt;cstddef&gt;\n#include &lt;iterator&gt;\n#include &lt;concepts&gt;\n\ntemplate &lt;typename T&gt;\nstruct SimpleRandomAccessIterator {\n    using difference_type = std::ptrdiff_t;\n    using value_type = T;\n    using pointer = T*;\n    using reference = T&;\n\n    T* m_raw_data_ptr;\n\n    // Default constructor\n    SimpleRandomAccessIterator() = default;\n\n    // Constructor\n    SimpleRandomAccessIterator(T* start)\n        : m_raw_data_ptr{start} {}\n\n    // Dereference operator\n    reference operator*() const {\n        return *m_raw_data_ptr;\n    }\n\n    // Pre-increment\n    SimpleRandomAccessIterator& operator++() {\n        ++m_raw_data_ptr;\n        return *this;\n    }\n\n    // Post-increment\n    SimpleRandomAccessIterator operator++(int) {\n        auto tmp = *this;\n        ++(*this);\n        return tmp;\n    }\n\n    // Pre-decrement\n    SimpleRandomAccessIterator& operator--() {\n        --m_raw_data_ptr;\n        return *this;\n    }\n\n    // Post-decrement\n    SimpleRandomAccessIterator operator--(int) {\n        auto tmp = *this;\n        --(*this);\n        return tmp;\n    }\n\n    // Array subscript operator\n    reference operator[](difference_type n) const {\n        return m_raw_data_ptr[n];\n    }\n\n    // Compound addition\n    SimpleRandomAccessIterator& operator+=(difference_type n) {\n        m_raw_data_ptr += n;\n        return *this;\n    }\n\n    // Compound subtraction\n    SimpleRandomAccessIterator& operator-=(difference_type n) {\n        m_raw_data_ptr -= n;\n        return *this;\n    }\n\n    // Addition\n    SimpleRandomAccessIterator operator+(difference_type n) const {\n        return SimpleRandomAccessIterator(m_raw_data_ptr + n);\n    }\n\n    // Subtraction\n    SimpleRandomAccessIterator operator-(difference_type n) const {\n        return SimpleRandomAccessIterator(m_raw_data_ptr - n);\n    }\n\n    // Distance between iterators\n    difference_type operator-(const SimpleRandomAccessIterator& other) const {\n        return m_raw_data_ptr - other.m_raw_data_ptr;\n    }\n\n    // Equality comparison\n    bool operator==(const SimpleRandomAccessIterator& other) const {\n        return m_raw_data_ptr == other.m_raw_data_ptr;\n    }\n\n    // Inequality comparison\n    bool operator!=(const SimpleRandomAccessIterator& other) const {\n        return !(*this == other);\n    }\n\n    // Relational operators\n    bool operator&lt;(const SimpleRandomAccessIterator& other) const {\n        return m_raw_data_ptr &lt; other.m_raw_data_ptr;\n    }\n\n    bool operator&lt;=(const SimpleRandomAccessIterator& other) const {\n        return m_raw_data_ptr &lt;= other.m_raw_data_ptr;\n    }\n\n    bool operator&gt;(const SimpleRandomAccessIterator& other) const {\n        return m_raw_data_ptr &gt; other.m_raw_data_ptr;\n    }\n\n    bool operator&gt;=(const SimpleRandomAccessIterator& other) const {\n        return m_raw_data_ptr &gt;= other.m_raw_data_ptr;\n    }\n\n    // Friend operator+ for n + iterator\n    template &lt;typename U&gt;\n    friend SimpleRandomAccessIterator&lt;U&gt; operator+(\n        typename SimpleRandomAccessIterator&lt;U&gt;::difference_type n,\n        const SimpleRandomAccessIterator&lt;U&gt;& it\n    ) {\n        return SimpleRandomAccessIterator&lt;U&gt;(it.m_raw_data_ptr + n);\n    }\n};\n\nstatic_assert(std::random_access_iterator&lt;SimpleRandomAccessIterator&lt;int&gt;&gt;);\n\nint main() {\n    return 0;\n}\nCompiler Explorer"
  },
  {
    "objectID": "sell_side_quant_critical_path.html",
    "href": "sell_side_quant_critical_path.html",
    "title": "Sell-side quant",
    "section": "",
    "text": "Sell-side quant interviews test fluid intelligence, the ability to use logic and intuition to crack quant puzzles. The bar for these interviews is certainly high, there is almost zero tolerance for mistakes. Most interviews consist of four stages:\n\nGeneral brain-teasers and puzzles\nMath puzzles\nProgramming/Algorithmic thinking skills (C++ language features, STL, Python)\nDeal Economics\n\nI suggest a critical path for learning basic financial mathematics and topics useful for front-office desk-quant roles.\n\n\n\nQuantNet run by Andy Nguyen\nquant.stackexchange.com\nWilmott Forums\n\nQuantNet is an extremely useful forum for aspirants looking to apply to a top school or break into the field. The collective knowledge and network connections on this website go a long way in reducing the information assymetry. QN also publishes university rankings each year, offering detailed insights into placement and admission stats.\n\n\n\n\n\n\nUnderstanding Analysis(UA) by Stephen Abbott\nLinear Algebra Done Right(LADR), by Sheldon Axler\nIntroduction to Probability, by Joe Blitzstein\nVector calculus, S.J. Colley\nLinear Analysis, by Kreider, Kuller, Ostberg and Perkins(KKOP)\n\nHere are my unofficial solutions to Stephen Abbott’s Understanding Analysis.\nKKOP was suggested to me by Daniel Duffy, it remains, to date, a favorite introductory text on differential equations.\n\n\n\n\nAn introduction to Partial Differential Equations, Strauss\nNumerical methods for Computational finance, Daniel Duffy\nProbability Foundations, lectures taught by Dr. Krishna Jagannathan\n\n\n\n\n\nA first course in Stochastic Calculus by Louis Pierre Arguin\nInterest Rate Models, theory and practice by Brigo and Mercurio\n\nI really like LP’s book, for it, interleaves rigor and intuition, written by a trader, quant.\n\n\n\n\n\nChase the devil"
  },
  {
    "objectID": "sell_side_quant_critical_path.html#fundamentals",
    "href": "sell_side_quant_critical_path.html#fundamentals",
    "title": "Sell-side quant critical path",
    "section": "",
    "text": "Understanding Analysis(UA) by Stephen Abbott\nLinear Algebra Done Right(LADR), by Sheldon Axler\nIntroduction to Probability, by Joe Blitzstein\nVector calculus, S.J. Colley\nLinear Analysis, by Kreider, Kuller, Ostberg and Perkins(KKOP)\n\nHere are my unofficial solutions to Stephen Abbott’s Understanding Analysis.\nKKOP was suggested to me by Daniel Duffy, it remains, to date, a favorite introductory text on differential equations."
  },
  {
    "objectID": "sell_side_quant_critical_path.html#intermediate",
    "href": "sell_side_quant_critical_path.html#intermediate",
    "title": "Sell-side quant critical path",
    "section": "",
    "text": "An introduction to Partial Differential Equations, Strauss\nNumerical methods for Computational finance, Daniel Duffy\nProbability Foundations, lectures taught by Dr. Krishna Jagannathan"
  },
  {
    "objectID": "sell_side_quant_critical_path.html#stochastic-calculus",
    "href": "sell_side_quant_critical_path.html#stochastic-calculus",
    "title": "Sell-side quant critical path",
    "section": "",
    "text": "A first course in Stochastic Calculus by Louis Pierre Arguin"
  },
  {
    "objectID": "sell_side_quant_critical_path.html#stochastic-calculus-and-interest-rate-modeling",
    "href": "sell_side_quant_critical_path.html#stochastic-calculus-and-interest-rate-modeling",
    "title": "Sell-side quant critical path",
    "section": "",
    "text": "A first course in Stochastic Calculus by Louis Pierre Arguin\nInterest Rate Models, theory and practice by Brigo and Mercurio\n\nI really like LP’s book, for it, interleaves rigor and intuition, written by a trader, quant."
  },
  {
    "objectID": "sell_side_quant_critical_path.html#quant-forums",
    "href": "sell_side_quant_critical_path.html#quant-forums",
    "title": "Sell-side quant",
    "section": "",
    "text": "QuantNet run by Andy Nguyen\nquant.stackexchange.com\nWilmott Forums\n\nQuantNet is an extremely useful forum for aspirants looking to apply to a top school or break into the field. The collective knowledge and network connections on this website go a long way in reducing the information assymetry. QN also publishes university rankings each year, offering detailed insights into placement and admission stats."
  },
  {
    "objectID": "sell_side_quant_critical_path.html#books",
    "href": "sell_side_quant_critical_path.html#books",
    "title": "Sell-side quant",
    "section": "",
    "text": "Understanding Analysis(UA) by Stephen Abbott\nLinear Algebra Done Right(LADR), by Sheldon Axler\nIntroduction to Probability, by Joe Blitzstein\nVector calculus, S.J. Colley\nLinear Analysis, by Kreider, Kuller, Ostberg and Perkins(KKOP)\n\nHere are my unofficial solutions to Stephen Abbott’s Understanding Analysis.\nKKOP was suggested to me by Daniel Duffy, it remains, to date, a favorite introductory text on differential equations.\n\n\n\n\nAn introduction to Partial Differential Equations, Strauss\nNumerical methods for Computational finance, Daniel Duffy\nProbability Foundations, lectures taught by Dr. Krishna Jagannathan\n\n\n\n\n\nA first course in Stochastic Calculus by Louis Pierre Arguin\nInterest Rate Models, theory and practice by Brigo and Mercurio\n\nI really like LP’s book, for it, interleaves rigor and intuition, written by a trader, quant."
  },
  {
    "objectID": "sell_side_quant_critical_path.html#blog-rolls",
    "href": "sell_side_quant_critical_path.html#blog-rolls",
    "title": "Sell-side quant",
    "section": "",
    "text": "Chase the devil"
  }
]