<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.3.450">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">

<meta name="author" content="Quasar">
<meta name="dcterms.date" content="2024-12-01">

<title>quantdev.blog - A gentle introduction to the Girsanov Theorem - Back to the basics</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
/* CSS for syntax highlighting */
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
  }
pre.numberSource { margin-left: 3em;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
</style>


<script src="../../site_libs/quarto-nav/quarto-nav.js"></script>
<script src="../../site_libs/quarto-nav/headroom.min.js"></script>
<script src="../../site_libs/clipboard/clipboard.min.js"></script>
<script src="../../site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="../../site_libs/quarto-search/fuse.min.js"></script>
<script src="../../site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="../../">
<script src="../../site_libs/quarto-html/quarto.js"></script>
<script src="../../site_libs/quarto-html/popper.min.js"></script>
<script src="../../site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="../../site_libs/quarto-html/anchor.min.js"></script>
<link href="../../site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="../../site_libs/quarto-html/quarto-syntax-highlighting.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="../../site_libs/bootstrap/bootstrap.min.js"></script>
<link href="../../site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="../../site_libs/bootstrap/bootstrap.min.css" rel="stylesheet" id="quarto-bootstrap" data-mode="light">
<script id="quarto-search-options" type="application/json">{
  "location": "navbar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "end",
  "type": "overlay",
  "limit": 20,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit",
    "search-label": "Search"
  }
}</script>
<style>
  @import url('https://fonts.googleapis.com/css2?family=Inter:wght@400;800&display=swap');
  @import url('https://fonts.googleapis.com/css2?family=EB+Garamond:ital,wght@0,400..800;1,400..800&display=swap');
  @import url('https://fonts.googleapis.com/css2?family=Fira+Code:wght@300..700&display=swap');
  @import url('https://fonts.googleapis.com/css2?family=Roboto:ital,wght@0,100;0,300;0,400;0,500;0,700;0,900;1,100;1,300;1,400;1,500;1,700;1,900&display=swap');
  @import url('https://fonts.googleapis.com/css2?family=Roboto:ital,wght@0,100;0,300;0,400;0,500;0,700;0,900;1,100;1,300;1,400;1,500;1,700;1,900&family=Source+Code+Pro:ital,wght@0,200..900;1,200..900&display=swap');
  @import url('https://fonts.googleapis.com/css2?family=Open+Sans:ital,wght@0,300..800;1,300..800&display=swap');
  @import url('https://fonts.googleapis.com/css2?family=JetBrains+Mono:ital,wght@0,100..800;1,100..800&display=swap')
</style>
<script async="" src="https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js?client=ca-pub-9993009899870547" crossorigin="anonymous"></script>

  <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
  <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js" type="text/javascript"></script>

<link rel="stylesheet" href="../../styles.css">
</head>

<body class="nav-fixed">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
    <nav class="navbar navbar-expand-lg navbar-dark ">
      <div class="navbar-container container-fluid">
      <div class="navbar-brand-container">
    <a class="navbar-brand" href="../../index.html">
    <span class="navbar-title">quantdev.blog</span>
    </a>
  </div>
            <div id="quarto-search" class="" title="Search"></div>
          <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbarCollapse" aria-controls="navbarCollapse" aria-expanded="false" aria-label="Toggle navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
  <span class="navbar-toggler-icon"></span>
</button>
          <div class="collapse navbar-collapse" id="navbarCollapse">
            <ul class="navbar-nav navbar-nav-scroll ms-auto">
  <li class="nav-item">
    <a class="nav-link" href="../../about.html" rel="" target="">
 <span class="menu-text">About</span></a>
  </li>  
  <li class="nav-item compact">
    <a class="nav-link" href="https://github.com/" rel="" target=""><i class="bi bi-github" role="img">
</i> 
 <span class="menu-text"></span></a>
  </li>  
  <li class="nav-item compact">
    <a class="nav-link" href="https://twitter.com" rel="" target=""><i class="bi bi-twitter" role="img">
</i> 
 <span class="menu-text"></span></a>
  </li>  
  <li class="nav-item compact">
    <a class="nav-link" href="../../index.xml" rel="" target=""><i class="bi bi-rss" role="img">
</i> 
 <span class="menu-text"></span></a>
  </li>  
</ul>
            <div class="quarto-navbar-tools">
</div>
          </div> <!-- /navcollapse -->
      </div> <!-- /container-fluid -->
    </nav>
</header>
<!-- content -->
<header id="title-block-header" class="quarto-title-block default page-columns page-full">
  <div class="quarto-title-banner page-columns page-full">
    <div class="quarto-title column-body">
      <h1 class="title">A gentle introduction to the Girsanov Theorem - Back to the basics</h1>
                                <div class="quarto-categories">
                <div class="quarto-category">Stochastic Calculus</div>
              </div>
                  </div>
  </div>
    
  
  <div class="quarto-title-meta">

      <div>
      <div class="quarto-title-meta-heading">Author</div>
      <div class="quarto-title-meta-contents">
               <p>Quasar </p>
            </div>
    </div>
      
      <div>
      <div class="quarto-title-meta-heading">Published</div>
      <div class="quarto-title-meta-contents">
        <p class="date">December 1, 2024</p>
      </div>
    </div>
    
      
    </div>
    
  
  </header><div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article page-navbar">
<!-- sidebar -->
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
        <nav id="TOC" role="doc-toc" class="toc-active">
    <h2 id="toc-title">On this page</h2>
   
  <ul>
  <li><a href="#introduction" id="toc-introduction" class="nav-link active" data-scroll-target="#introduction">Introduction</a></li>
  <li><a href="#change-of-probability." id="toc-change-of-probability." class="nav-link" data-scroll-target="#change-of-probability.">Change of Probability.</a>
  <ul class="collapse">
  <li><a href="#change-of-probability-for-a-random-variable." id="toc-change-of-probability-for-a-random-variable." class="nav-link" data-scroll-target="#change-of-probability-for-a-random-variable.">Change of Probability for a Random Variable.</a></li>
  <li><a href="#change-of-probability-measure" id="toc-change-of-probability-measure" class="nav-link" data-scroll-target="#change-of-probability-measure">Change of probability measure</a></li>
  <li><a href="#the-cameron-martin-theorem." id="toc-the-cameron-martin-theorem." class="nav-link" data-scroll-target="#the-cameron-martin-theorem.">The Cameron-Martin Theorem.</a></li>
  </ul></li>
  </ul>
</nav>
    </div>
<!-- main -->
<main class="content quarto-banner-title-block" id="quarto-document-content">




<section id="introduction" class="level1">
<h1>Introduction</h1>
<p>One of the most popular technical tools in financial engineering is the Girsanov theorem. In this blog-post, I intend to provide the dear reader a beginner-friendly introduction and an intuitive gut feel for these tools.</p>
<p>The change of measure technique was used by <a href="https://en.wikipedia.org/wiki/H%C3%A9lyette_Geman">Heylette Geman</a>, <a href="https://en.wikipedia.org/wiki/Nicole_El_Karoui">Nicole El Karoui</a> and <a href="">Jean-Charles Rochet</a> in their seminal note <a href="https://www.cambridge.org/core/journals/journal-of-applied-probability/article/abs/changes-of-numeraire-changes-of-probability-measure-and-option-pricing/EA730D6C18D56426D491B6A25563C0B3">Changes of Numeraire, Changes of Probability Measure and Option Pricing</a>.</p>
<div id="2118a150" class="cell" data-execution_count="1">
<div class="sourceCode cell-code" id="cb1"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb1-1"><a href="#cb1-1"></a><span class="op">%</span>load_ext itikz</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
</section>
<section id="change-of-probability." class="level1">
<h1>Change of Probability.</h1>
<section id="change-of-probability-for-a-random-variable." class="level2">
<h2 class="anchored" data-anchor-id="change-of-probability-for-a-random-variable.">Change of Probability for a Random Variable.</h2>
<p>Consider a random variable <span class="math inline">\(X\)</span> defined on a sample space <span class="math inline">\(\Omega\)</span> having zero mean. We want to change the mean of <span class="math inline">\(X\)</span> so that <span class="math inline">\(\mu\neq 0\)</span>. Of course, it is easy to change the mean of a random variable: If <span class="math inline">\(X\)</span> has mean <span class="math inline">\(0\)</span>, then the random variable <span class="math inline">\(X+\mu\)</span> has mean <span class="math inline">\(\mu\)</span>. However, it might be that the variable <span class="math inline">\(X+\mu\)</span> does not share the same possible values as <span class="math inline">\(X\)</span>. For example, take <span class="math inline">\(X\)</span> to be a uniform random variable on <span class="math inline">\([-1,1]\)</span>. While <span class="math inline">\(X+1\)</span> has mean <span class="math inline">\(1\)</span>, the density of <span class="math inline">\(X+1\)</span> would be non-zero on <span class="math inline">\([0,2]\)</span> instead of <span class="math inline">\([-1,1]\)</span>.</p>
<p>Our goal is to find a good way to change the underlying probability <span class="math inline">\(\mathbb{P}\)</span>, and thus the distribution of <span class="math inline">\(X\)</span>, so that the set of outcomes is unchanged. If <span class="math inline">\(X\)</span> is a discrete random variable, say with <span class="math inline">\(\mathbb{P}(X=-1)=\mathbb{P}(X=1)=1/2\)</span>, we can change the probability in order to change the mean easily. It suffices to take <span class="math inline">\(\tilde{\mathbb{P}}\)</span> so that <span class="math inline">\(\tilde{\mathbb{P}}(X=1)=p\)</span> and <span class="math inline">\(\mathbb{P}(X=-1)=1-p\)</span> for some appropriate <span class="math inline">\(0\leq p\leq1\)</span>.</p>
<p>If <span class="math inline">\(X\)</span> is a continuous random variable, with a PDF <span class="math inline">\(f_{X}\)</span>, the probabilities can be changed by modifying the PDF. Consider the a new PDF:</p>
<p><span class="math display">\[\begin{aligned}
\tilde{f}_{X}(x) &amp; =f_{X}(x)g(x)
\end{aligned}\]</span></p>
<p>for some function <span class="math inline">\(g(x)&gt;0\)</span> such that <span class="math inline">\(\int f(x)g(x)dx=1\)</span>. Clearly, <span class="math inline">\(f_{X}(x)g(x)\)</span> is also a PDF and <span class="math inline">\(f_{X}(x)&gt;0\)</span> if and only if <span class="math inline">\(f_{X}(x)g(x)&gt;0\)</span>, so that the possible values of <span class="math inline">\(X\)</span> are unchanged. A convenient (and important!) choice of function <span class="math inline">\(g\)</span> is:</p>
<p><span id="eq-change-of-probability-of-an-rv"><span class="math display">\[\begin{aligned}
g(x) &amp; =\frac{e^{ax}}{\int_{\mathbf{R}}e^{ax}f_{X}(x)dx}=\frac{e^{ax}}{\mathbb{E}[e^{aX}]},\quad a\in\mathbf{R}
\end{aligned} \tag{1}\]</span></span></p>
<p>assuming <span class="math inline">\(X\)</span> has a well-defined MGF. Here <span class="math inline">\(a\)</span> is a parameter that can be tuned to fit to a specific mean. The normalization factor in the denominator is the MGF of <span class="math inline">\(X\)</span>. It ensures that <span class="math inline">\(f_{X}(x)g(x)\)</span> is a PDF. Note that if <span class="math inline">\(a&gt;0\)</span>, the function <span class="math inline">\(g\)</span> gives a bigger weight to large values of <span class="math inline">\(X\)</span>. We say that <span class="math inline">\(g\)</span> is biased towards the large values.</p>
<div id="exm-biasing-a-uniform-random-variable" class="theorem example">
<p><span class="theorem-title"><strong>Example 1 (Biasing a uniform random variable) </strong></span>Let <span class="math inline">\(X\)</span> be a uniform random variable on <span class="math inline">\([0,1]\)</span> defined on <span class="math inline">\((\Omega,\mathcal{F},\mathbb{P})\)</span>. Clearly, <span class="math inline">\(\mathbb{E}[X]=1/2\)</span>. How can we change the PDF of <span class="math inline">\(X\)</span> so that the possible values are still <span class="math inline">\([0,1]\)</span>, but the mean is <span class="math inline">\(1/4\)</span>. We have that the PDF is <span class="math inline">\(f_{X}(x)=1\)</span> if <span class="math inline">\(x\in[0,1]\)</span> and <span class="math inline">\(0\)</span> elsewhere. Therefore, the mean with the new PDF with parameter <span class="math inline">\(a\)</span> as in the <a href="#eq-change-of-probability-of-an-rv">Equation&nbsp;1</a> is:</p>
<p><span class="math display">\[\begin{aligned}
\tilde{\mathbb{E}}[X] &amp; =\int_{0}^{1}x\tilde{f}(x)dx\\
&amp; =\int_{0}^{1}\frac{xe^{ax}}{\mathbb{E}[e^{aX}]}dx\\
&amp; =\frac{a}{e^{a}-1}\int_{0}^{1}xe^{ax}dx\\
&amp; =\frac{a}{e^{a}-1}\left(\left[x\frac{e^{ax}}{a}\right]_{0}^{1}-\frac{1}{a}\int_{0}^{1}e^{ax}dx\right)\\
&amp; =\frac{a}{e^{a}-1}\left(\frac{e^{a}}{a}-\frac{1}{a}\frac{e^{a}-1}{a}\right)\\
&amp; =\frac{e^{a}}{e^{a}-1}-\frac{1}{a}
\end{aligned}\]</span></p>
<p>For <span class="math inline">\(\tilde{\mathbb{E}[X]}\)</span>to be equal to <span class="math inline">\(1/4\)</span>, we get numerically <span class="math inline">\(a\approx-3.6\)</span>. Note that the possible values of <span class="math inline">\(X\)</span> remain the same under the new probability. However, the new distribution is no longer uniform! It has bias towards values closer to zero, as it should.</p>
</div>
<div id="exm-biasing-a-gaussian-random-variable" class="theorem example">
<p><span class="theorem-title"><strong>Example 2 (Biasing a Gaussian random variable.) </strong></span>Let <span class="math inline">\(X\)</span> be a Gaussian random variable with mean <span class="math inline">\(\mu\)</span> and variance <span class="math inline">\(\sigma^{2}\)</span>. How can we change the PDF of <span class="math inline">\(X\)</span> to have mean <span class="math inline">\(0\)</span>? Going back to <a href="#eq-change-of-probability-of-an-rv">Equation&nbsp;1</a>, the mean <span class="math inline">\(\mu\)</span> under the new PDF with parameter <span class="math inline">\(a\)</span> is:</p>
<p><span class="math display">\[\begin{aligned}
\tilde{\mathbb{E}}[X] &amp; =\int_{-\infty}^{\infty}x\tilde{f}(x)dx\\
&amp; =\int_{-\infty}^{\infty}xg(x)f(x)dx\\
&amp; =\int_{-\infty}^{\infty}x\cdot\frac{e^{ax}}{\mathbb{E}[e^{aX}]}\frac{1}{\sqrt{2\pi}\sigma}e^{-\frac{1}{2}\left(\frac{x-\mu}{\sigma}\right)^{2}}dx\\
&amp; =\frac{1}{e^{\mu a+\frac{1}{2}a^{2}\sigma^{2}}}\frac{1}{\sqrt{2\pi}\sigma}\int_{-\infty}^{\infty}x\cdot\exp\left[-\frac{1}{2}\left(\frac{x^{2}-2\mu x+\mu^{2}-2a\sigma^{2}x}{\sigma^{2}}\right)\right]dx\\
&amp; =\frac{1}{e^{\mu a+\frac{1}{2}a^{2}\sigma^{2}}}\frac{1}{\sqrt{2\pi}\sigma}\int_{-\infty}^{\infty}x\cdot\exp\left[-\frac{1}{2}\left(\frac{x^{2}-2(\mu+a\sigma^{2})x+(\mu+a\sigma^{2})^{2}-2\mu a\sigma^{2}-a^{2}\sigma^{4}}{\sigma^{2}}\right)\right]dx\\
&amp; =\frac{e^{\mu a+a^{2}\sigma^{2}/2}}{e^{\mu a+\frac{1}{2}a^{2}\sigma^{2}}}\frac{1}{\sqrt{2\pi}\sigma}\int_{-\infty}^{\infty}x\exp\left[-\frac{1}{2}\left(\frac{x-(\mu+a\sigma^{2})}{\sigma}\right)^{2}\right]dx\\
&amp; =\frac{1}{\sqrt{2\pi}\sigma}\int_{-\infty}^{\infty}x\exp\left[-\frac{1}{2}\left(\frac{x-(\mu+a\sigma^{2})}{\sigma}\right)^{2}\right]dx
\end{aligned}\]</span></p>
<p>For the specific choice of the parameter <span class="math inline">\(a=\mu/\sigma^{2}\)</span>, we recover the PDF of a Gaussian random variable with mean <span class="math inline">\(0\)</span>. But, we can deduce more. The new PDF is also Gaussian. This was not the case for uniform random variables. In fact, the new PDF is exactly the same as the one of <span class="math inline">\(X-\mu\)</span>. For if, <span class="math inline">\(a=\mu/\sigma^{2}\)</span>, we have:</p>
<p><span class="math display">\[\begin{aligned}
\tilde{\mathbb{E}}[X] &amp; =\frac{1}{\sqrt{2\pi}\sigma}\int_{-\infty}^{\infty}x\exp\left[-\frac{x^{2}}{2\sigma^{2}}\right]dx
\end{aligned}\]</span></p>
<p>and observe that if <span class="math inline">\(Y=X-\mu\)</span>, then:</p>
<p><span class="math display">\[\begin{aligned}
F_{Y}(x) &amp; =\mathbb{P}(X-\mu&lt;x)\\
&amp; =\mathbb{P}(X\leq x+\mu)\\
&amp; =F_{X}(x+\mu)\\
\frac{d}{dx}(F_{Y}(x)) &amp; =\frac{d}{dx}(F_{X}(x+\mu))\\
f_{Y}(x) &amp; =f_{X}(x+\mu)\cdot\frac{d}{dx}(x+\mu)\\
f_{Y}(x) &amp; =f_{X}(x+\mu)\\
&amp; =\frac{1}{\sqrt{2\pi}\sigma}\exp\left[-\frac{1}{2}\left(\frac{x+\mu-\mu}{\sigma}\right)^{2}\right]\\
&amp; =\frac{1}{\sqrt{2\pi}\sigma}\exp\left[-\frac{x^{2}}{2\sigma^{2}}\right]
\end{aligned}\]</span></p>
<p>In other words:</p>
<p><em>For Gaussians, changing the mean by recentering is equivalent to changing the probability as in</em> <a href="#eq-change-of-probability-of-an-rv">Equation&nbsp;1</a>.</p>
<section id="visualization" class="level3 unnumbered">
<h3 class="unnumbered anchored" data-anchor-id="visualization">Visualization</h3>
<p>Let <span class="math inline">\(X\)</span> be gaussian with mean <span class="math inline">\(\mu=1\)</span> and variance <span class="math inline">\(\sigma^2 = 1\)</span>. The PDF of <span class="math inline">\(X\)</span> is:</p>
<div id="4e6f4ec4" class="cell" data-execution_count="2">
<details>
<summary>Show the code</summary>
<div class="sourceCode cell-code" id="cb2"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb2-1"><a href="#cb2-1"></a><span class="op">%%</span>itikz <span class="op">--</span>temp<span class="op">-</span><span class="bu">dir</span> <span class="op">--</span>tex<span class="op">-</span>packages<span class="op">=</span>tikz,pgfplots <span class="op">--</span>tikz<span class="op">-</span>libraries<span class="op">=</span>arrows <span class="op">--</span>implicit<span class="op">-</span>standalone</span>
<span id="cb2-2"><a href="#cb2-2"></a>\begin{tikzpicture}[scale<span class="op">=</span><span class="fl">1.5</span>]</span>
<span id="cb2-3"><a href="#cb2-3"></a>\begin{axis}[xlabel <span class="op">=</span> $x$, ylabel<span class="op">=</span>{$f_X(x)$}, title<span class="op">=</span>{The PDF of $X \sim \mathcal{N}<span class="op">^</span>{P}(\mu<span class="op">=</span><span class="dv">1</span>,\sigma<span class="op">^</span><span class="dv">2</span><span class="op">=</span><span class="dv">1</span>)$},domain<span class="op">=-</span><span class="dv">3</span>:<span class="dv">3</span>]</span>
<span id="cb2-4"><a href="#cb2-4"></a>\addplot[color<span class="op">=</span>black,samples<span class="op">=</span><span class="dv">100</span>]{<span class="dv">1</span><span class="op">/</span>(sqrt(<span class="dv">2</span><span class="op">*</span><span class="fl">3.14</span>))<span class="op">*</span>exp(<span class="op">-</span><span class="fl">0.5</span><span class="op">*</span>((x<span class="op">-</span><span class="dv">1</span>)<span class="op">*</span>(x<span class="op">-</span><span class="dv">1</span>))}<span class="op">;</span></span>
<span id="cb2-5"><a href="#cb2-5"></a>\end{axis}</span>
<span id="cb2-6"><a href="#cb2-6"></a>\end{tikzpicture}</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-display" data-execution_count="2">
<p><img src="index_files/figure-html/cell-3-output-1.svg" class="img-fluid"></p>
</div>
</div>
<p>I choose <span class="math inline">\(g(x) = \frac{e^{ax}}{\mathbb{E}[e^{aX}]} = \frac{e^{ax}}{e^{\mu a + \frac{1}{2}a^2 \sigma^2}}\)</span>, <span class="math inline">\(\mu=1\)</span>, <span class="math inline">\(\sigma^2 = 1\)</span> and set the value of the parameter <span class="math inline">\(a = \frac{\mu}{\sigma^2} = -1\)</span>.</p>
<div id="219bcbad" class="cell" data-execution_count="3">
<details>
<summary>Show the code</summary>
<div class="sourceCode cell-code" id="cb3"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb3-1"><a href="#cb3-1"></a><span class="op">%%</span>itikz <span class="op">--</span>temp<span class="op">-</span><span class="bu">dir</span> <span class="op">--</span>tex<span class="op">-</span>packages<span class="op">=</span>tikz,pgfplots <span class="op">--</span>tikz<span class="op">-</span>libraries<span class="op">=</span>arrows <span class="op">--</span>implicit<span class="op">-</span>standalone</span>
<span id="cb3-2"><a href="#cb3-2"></a>\begin{tikzpicture}[scale<span class="op">=</span><span class="fl">1.5</span>]</span>
<span id="cb3-3"><a href="#cb3-3"></a>\begin{axis}[xlabel <span class="op">=</span> $x$, ylabel<span class="op">=</span>{$g(x)$}, title<span class="op">=</span>{The density scaling $g(x)<span class="op">=</span>\frac{e<span class="op">^</span>{ax}}{E[e<span class="op">^</span>{ax}]}$, <span class="cf">with</span> parameter value $a<span class="op">=-</span>\frac{\mu}{\sigma<span class="op">^</span><span class="dv">2</span>}$},domain<span class="op">=-</span><span class="dv">3</span>:<span class="dv">3</span>]</span>
<span id="cb3-4"><a href="#cb3-4"></a>\addplot[color<span class="op">=</span>black,samples<span class="op">=</span><span class="dv">100</span>]{exp(<span class="op">-</span>x)<span class="op">/</span>exp(<span class="op">-</span><span class="fl">0.5</span>)}<span class="op">;</span></span>
<span id="cb3-5"><a href="#cb3-5"></a>\end{axis}</span>
<span id="cb3-6"><a href="#cb3-6"></a>\end{tikzpicture}</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-display" data-execution_count="3">
<p><img src="index_files/figure-html/cell-4-output-1.svg" class="img-fluid"></p>
</div>
</div>
<p>The new density <span class="math inline">\(\tilde{f}_X(x)\)</span> obtained multiplying <span class="math inline">\(f_X(x)\)</span> by the weights <span class="math inline">\(g(x)\)</span> is the same as a gaussian centered at <span class="math inline">\(0\)</span> with variance <span class="math inline">\(1\)</span> :</p>
<div id="348fa58c" class="cell" data-execution_count="4">
<details>
<summary>Show the code</summary>
<div class="sourceCode cell-code" id="cb4"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb4-1"><a href="#cb4-1"></a><span class="op">%%</span>itikz <span class="op">--</span>temp<span class="op">-</span><span class="bu">dir</span> <span class="op">--</span>tex<span class="op">-</span>packages<span class="op">=</span>tikz,pgfplots <span class="op">--</span>tikz<span class="op">-</span>libraries<span class="op">=</span>arrows <span class="op">--</span>implicit<span class="op">-</span>standalone</span>
<span id="cb4-2"><a href="#cb4-2"></a>\begin{tikzpicture}[scale<span class="op">=</span><span class="fl">1.5</span>]</span>
<span id="cb4-3"><a href="#cb4-3"></a>\begin{axis}[xlabel <span class="op">=</span> $x$, ylabel<span class="op">=</span>{$\tilde{f}_X(x)$}, title<span class="op">=</span>{The new PDF of $X$, after multiplying the density ${f}_X(x)$ by weights $g(x)$.},domain<span class="op">=-</span><span class="dv">3</span>:<span class="dv">3</span>]</span>
<span id="cb4-4"><a href="#cb4-4"></a>\addplot[color<span class="op">=</span>black,samples<span class="op">=</span><span class="dv">100</span>]{<span class="dv">1</span><span class="op">/</span>(sqrt(<span class="dv">2</span><span class="op">*</span><span class="fl">3.14</span>))<span class="op">*</span>exp(<span class="op">-</span><span class="fl">0.5</span><span class="op">*</span>(x<span class="op">*</span>x))}<span class="op">;</span></span>
<span id="cb4-5"><a href="#cb4-5"></a>\end{axis}</span>
<span id="cb4-6"><a href="#cb4-6"></a>\end{tikzpicture}</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-display" data-execution_count="4">
<p><img src="index_files/figure-html/cell-5-output-1.svg" class="img-fluid"></p>
</div>
</div>
</section>
</div>
<p>This is a very special property of the Gaussian distribution. The exponential and Poisson distributions have a similar property.</p>
<p>Intuitively, if we have a brownian motion with a drift <span class="math inline">\(dX_t = \mu dt + dB_t\)</span>, we can apply this idea to each time-slice <span class="math inline">\((X_t - X_s)\)</span> of the process, we can recenter the gaussians to have mean <span class="math inline">\(0\)</span>, so the paths are driftless and it has the same distribution as a standard brownian motion.</p>
</section>
<section id="change-of-probability-measure" class="level2">
<h2 class="anchored" data-anchor-id="change-of-probability-measure">Change of probability measure</h2>
<p><a href="#exm-biasing-a-gaussian-random-variable">Example&nbsp;2</a> is very important and we will state it as a theorem. Before doing so, we notice that the change of PDF (<a href="#eq-change-of-probability-of-an-rv">Equation&nbsp;1</a>) can be expressed more generally by changing the underlying probability measure(length, area, weights) <span class="math inline">\(\mathbb{P}\)</span> on the sample space <span class="math inline">\(\Omega\)</span> on which the random variables are defined. More precisely, let <span class="math inline">\((\Omega,\mathcal{F},\mathbb{P})\)</span> be a probability space, and let <span class="math inline">\(X\)</span> be a random variable defined on <span class="math inline">\(\Omega\)</span>. We define a new probability <span class="math inline">\(\tilde{\mathbb{P}}\)</span> on <span class="math inline">\(\Omega\)</span> as follows:</p>
<p>If <span class="math inline">\(\mathcal{E}\)</span> is an event in <span class="math inline">\(\mathcal{F}\)</span>, then:</p>
<p><span class="math display">\[\begin{aligned}
\mathbb{\tilde{P}}(\mathcal{E}) &amp; =\mathbb{\tilde{E}}[1_{\mathcal{E}}]=\int_{\mathbf{R}}1_{\mathcal{E}}\cdot\tilde{f}(x)dx\nonumber \\
&amp; =\int_{\mathbf{R}}1_{\mathcal{E}}\cdot g(x)f_{X}(x)dx\nonumber \\
&amp; =\int_{\mathbf{R}}1_{\mathcal{E}}\cdot\frac{e^{ax}}{\mathbb{E}[e^{aX}]}f_{X}(x)dx\nonumber \\
&amp; =\mathbb{E}\left[1_{\mathcal{E}}\frac{e^{aX}}{\mathbb{E}[e^{aX}]}\right]
\end{aligned}\]</span></p>
<p>Intuitively, we are changing the probability of each outcome <span class="math inline">\(\omega\in\mathcal{E}\)</span>, by the factor</p>
<p><span id="eq-girsanov-probability-scaling"><span class="math display">\[
\begin{aligned}
\frac{e^{aX(\omega)}}{\mathbb{E}[e^{aX}]}
\end{aligned}
\tag{2}\]</span></span></p>
<p>In other words, if <span class="math inline">\(a&gt;0\)</span>, the outcomes <span class="math inline">\(\omega\)</span> for which <span class="math inline">\(X\)</span> has large values are favored. Note that equation (<a href="#eq-change-of-probability-of-an-rv">Equation&nbsp;1</a>) for the PDF is recovered, since for any function <span class="math inline">\(h\)</span> of <span class="math inline">\(X\)</span>, we have:</p>
<p><span class="math display">\[\begin{aligned}
\tilde{\mathbb{E}}[h(X)] &amp; =\mathbb{E}\left[\frac{e^{aX}}{\mathbb{E}[e^{aX}]}h(X)\right]\\
&amp; =\int_{\mathbf{R}}h(x)\frac{e^{ax}}{\mathbb{E}[e^{aX}]}f_{X}(x)dx
\end{aligned}\]</span></p>
<p>In this setting, the above example becomes the preliminary version of the Cameron-Martin-Girsanov theorem:</p>
<div id="thm-change-of-probability-for-a-random-variable" class="theorem">
<p><span class="theorem-title"><strong>Theorem 1 (Change of probability for a random variable) </strong></span>Let <span class="math inline">\(X\)</span> be a Gaussian random variable with mean <span class="math inline">\(\mu\)</span> and variance <span class="math inline">\(\sigma^{2}\)</span> defined on <span class="math inline">\((\Omega,\mathcal{F},\mathbb{P})\)</span>. Then, under the probability <span class="math inline">\(\mathbb{\tilde{P}}\)</span> given by:</p>
<p><span id="eq-preliminary-version-girsanov-theorem"><span class="math display">\[\begin{aligned}
\mathbb{\tilde{P}}(\mathcal{E}) &amp; =\mathbb{E}\left[1_{\mathcal{E}}e^{-\frac{\mu}{\sigma^{2}}X+\frac{1}{2}\frac{\mu^{2}}{\sigma^{2}}}\right],\quad\mathcal{E}\in\mathcal{F}
\end{aligned} \tag{3}\]</span></span></p>
<p>the random variable <span class="math inline">\(X\)</span> is Gaussian with mean <span class="math inline">\(0\)</span> and variance <span class="math inline">\(\sigma^{2}\)</span>.</p>
<p>Moreover, since <span class="math inline">\(X\)</span> can be written as <span class="math inline">\(X=Y+\mu\)</span> where <span class="math inline">\(Y\)</span> is Gaussian with mean <span class="math inline">\(0\)</span> and variance <span class="math inline">\(\sigma^{2}\)</span> under <span class="math inline">\(\mathbb{P}\)</span>, we have that <span class="math inline">\(\mathbb{\tilde{P}}\)</span> can be written as:</p>
<p><span id="eq-preliminary-version-girsanov-theorem-II"><span class="math display">\[\begin{aligned}
\mathbb{\tilde{P}}(\mathcal{E}) &amp; =\mathbb{E}\left[1_{\mathcal{E}}e^{-\frac{\mu}{\sigma^{2}}Y-\frac{1}{2}\frac{\mu^{2}}{\sigma^{2}}}\right],\quad\mathcal{E}\in\mathcal{F}
\end{aligned} \tag{4}\]</span></span></p>
</div>
<p>It is good to pause for a second and look at the signs in the exponential of equations (<a href="#eq-preliminary-version-girsanov-theorem">Equation&nbsp;3</a>) and (<a href="#eq-preliminary-version-girsanov-theorem-II">Equation&nbsp;4</a>). The signs in the exponential might be very confusing and is the source of many mistakes in the Cameron-Martin-Girsanov theorem. A good trick is to say that, if we want to remove <span class="math inline">\(\mu\)</span>, then the sign in front of <span class="math inline">\(X\)</span> or <span class="math inline">\(Y\)</span> must be negative. Then, we add the exponential factor needed for <span class="math inline">\(\tilde{\mathbb{P}}\)</span> to be a probability. This is given by the MGF of <span class="math inline">\(X\)</span> or <span class="math inline">\(Y\)</span> depending on how we want to express it.</p>
<p>The probabilities <span class="math inline">\(\mathbb{P}\)</span> and <span class="math inline">\(\tilde{\mathbb{P}}\)</span>, as defined in the equation (<a href="#eq-preliminary-version-girsanov-theorem">Equation&nbsp;3</a>) are obviously not equal since they differ by a factor in (<a href="#eq-girsanov-probability-scaling">Equation&nbsp;2</a>). However, they share some similarities. Most notably, if <span class="math inline">\(\mathcal{E}\)</span> is an event of positive <span class="math inline">\(\mathbb{P}\)</span>-probability, <span class="math inline">\(\mathbb{P}(\mathcal{E})&gt;0\)</span>, then we must have <span class="math inline">\(\tilde{\mathbb{P}}(\mathcal{E})&gt;0\)</span>, since the factor in () is always strictly positive. The converse is also true: if <span class="math inline">\(\mathcal{E}\)</span> is an event of positive <span class="math inline">\(\tilde{\mathbb{P}}\)</span>-probability, <span class="math inline">\(\tilde{\mathbb{P}}(\mathcal{E})&gt;0\)</span>, then we must have that <span class="math inline">\(\mathbb{P}(\mathcal{E})&gt;0\)</span>. This is because the factor in (<a href="#eq-girsanov-probability-scaling">Equation&nbsp;2</a>) can be inverted, being strictly positive. More precisely, we have:</p>
<p><span class="math display">\[\begin{aligned}
\mathbb{P}(\mathcal{E}) &amp; =\mathbb{E}[1_{\mathcal{E}}]\\
&amp; =\mathbb{E}\left[1_{\mathcal{E}}\frac{e^{aX(\omega)}}{\mathbb{E}[e^{aX}]}\left(\frac{e^{aX(\omega)}}{\mathbb{E}[e^{aX}]}\right)^{-1}\right]\\
&amp; =\tilde{\mathbb{E}}\left[1_{\mathcal{E}}\left(\frac{e^{aX(\omega)}}{\mathbb{E}[e^{aX}]}\right)^{-1}\right]
\end{aligned}\]</span></p>
<p>The factor <span class="math inline">\(\left(\frac{e^{aX(\omega)}}{\mathbb{E}[e^{aX}]}\right)^{-1}\)</span> is also strictly positive, proving the claim. To sum it all up, the probabilities <span class="math inline">\(\mathbb{P}\)</span> and <span class="math inline">\(\tilde{\mathbb{P}}\)</span> essentially share the same possible outcomes. Such probability measures are said to be equivalent measures.</p>
<div id="def-equivalent-probability-measures" class="theorem definition">
<p><span class="theorem-title"><strong>Definition 1 </strong></span>Consider the two probabilities <span class="math inline">\(\mathbb{P}\)</span> and <span class="math inline">\(\tilde{\mathbb{P}}\)</span> on <span class="math inline">\((\Omega,\mathcal{F})\)</span>. They are said to be equivalent, if for any event <span class="math inline">\(\mathcal{E}\in\mathcal{F}\)</span>, we have <span class="math inline">\(\mathbb{P}(\mathcal{E})&gt;0\)</span> if and only if <span class="math inline">\(\mathbb{P}(\mathcal{E})&gt;0\)</span>. Thus, <span class="math inline">\(\mathbb{P}\)</span> and <span class="math inline">\(\tilde{\mathbb{P}}\)</span> agree on the null sets. If <span class="math inline">\(A\in\mathcal{F}\)</span> is such that <span class="math inline">\(\mathbb{P}(A)=0\)</span>, then <span class="math inline">\(\mathbb{\tilde{P}}(A)=0\)</span> and vice-versa.</p>
</div>
<p>Keep in mind that two probabilities that are equivalent might still be very far from being equal!</p>
</section>
<section id="the-cameron-martin-theorem." class="level2">
<h2 class="anchored" data-anchor-id="the-cameron-martin-theorem.">The Cameron-Martin Theorem.</h2>
<div id="thm-girsanov-theorem-for-constant-drift-case" class="theorem">
<p><span class="theorem-title"><strong>Theorem 2 (Cameron-Martin Theorem for constant drift.) </strong></span>Let <span class="math inline">\((\tilde{B(t)},t\in[0,T])\)</span> be a <span class="math inline">\(\mathbb{P}-\)</span>Brownian motion with constant drift <span class="math inline">\(\theta\)</span> defined on <span class="math inline">\((\Omega,\mathcal{F},\mathbb{P})\)</span>. Consider the probability <span class="math inline">\(\tilde{\mathbb{P}}\)</span>on <span class="math inline">\(\Omega\)</span> given by:</p>
<p><span id="eq-girsanov-theorem-constant-drift-case"><span class="math display">\[\begin{aligned}
\tilde{\mathbb{P}}(\mathcal{E}) &amp; =\mathbb{E}\left[e^{-\theta\tilde{B}(T)+\frac{\theta^{2}}{2}T}1_{\mathcal{E}}\right],\quad\mathcal{E}\in\mathcal{F}
\end{aligned} \tag{5}\]</span></span></p>
<p>Then, the process <span class="math inline">\((\tilde{B}(t),t\in[0,T])\)</span> under <span class="math inline">\(\mathbb{\tilde{P}}\)</span>is distributed like a standard brownian motion. Moreover, since we can write <span class="math inline">\(\tilde{B_{t}}=\theta t+B_{t}\)</span> for some standard brownian motion <span class="math inline">\((B_{t},t\in[0,T])\)</span> on <span class="math inline">\((\Omega,\mathcal{F},\mathbb{P})\)</span>, the probability <span class="math inline">\(\tilde{\mathbb{P}}\)</span> can also be written as:</p>
<p><span id="eq-girsanov-theorem-constant-drift-case-II"><span class="math display">\[\begin{aligned}
\tilde{\mathbb{P}}(\mathcal{E}) &amp; =\mathbb{E}\left[e^{-\theta B(T)-\frac{\theta^{2}}{2}T}1_{\mathcal{E}}\right]
\end{aligned} \tag{6}\]</span></span></p>
</div>
<p>It is a good idea to pause again and look at the signs in the exponential in equations (<a href="#eq-girsanov-theorem-constant-drift-case">Equation&nbsp;5</a>) and (<a href="#eq-girsanov-theorem-constant-drift-case-II">Equation&nbsp;6</a>). They behave the same way as in <a href="#thm-change-of-probability-for-a-random-variable">Theorem&nbsp;1</a>. There is a minus sign in front of <span class="math inline">\(B_{T}\)</span> to remove the drift. Before proving the theorem, we make some important remarks.</p>
<p>(1) <strong>The end-point</strong>. Note that only the endpoint <span class="math inline">\(\tilde{B}(T)\)</span> of the Brownian motion is involved in the change of probability. In particular, <span class="math inline">\(T\)</span> cannot be <span class="math inline">\(+\infty\)</span>. The Cameron-Martin theorem can only be applied on a finite interval.</p>
<p>(2) <strong>A martingale.</strong> The factor <span class="math inline">\(M_{T}=e^{-\theta B(T)-\frac{\theta^{2}}{2}T}=e^{-\theta\tilde{B}(T)+\frac{1}{2}\theta^{2}T}\)</span> involved in the change of probability is the end-point of a <span class="math inline">\(\mathbb{P}-\)</span>martingale, that is, it is a martingale under the original probability <span class="math inline">\(\mathbb{P}\)</span>. To see this:</p>
<p><span class="math display">\[\begin{aligned}
\mathbb{E}[M_{T}|\mathcal{F}_{t}] &amp; =\mathbb{E}\left[e^{-\theta B(T)-\frac{1}{2}\theta^{2}T}|\mathcal{F}_{t}\right]\\
&amp; =e^{-\theta B(t)}\mathbb{E}\left[e^{-\theta(B(T)-B(t))}|\mathcal{F}_{t}\right]e^{-\frac{\theta^{2}}{2}T}\\
&amp; \{\text{Using }B(T)-B(t)\perp\mathcal{F}_{t}\}\\
&amp; =e^{-\theta B(t)}\mathbb{E}\left[e^{-\theta(B(T)-B(t))}\right]e^{-\frac{\theta^{2}}{2}T}\\
&amp; =e^{-\theta B(t)}e^{\frac{\theta^{2}}{2}(T-t)}e^{-\frac{\theta^{2}}{2}T}\\
&amp; =e^{-\theta B(t)-\frac{\theta^{2}}{2}t}
\end{aligned}\]</span></p>
<p>In fact, since <span class="math inline">\(B(t)\)</span> is a <span class="math inline">\(\mathbb{P}\)</span>-standard Brownian motion, <span class="math inline">\(M(t)=e^{-\theta B(t)-\frac{\theta^{2}}{2}t}\)</span> is a geometric brownian motion.</p>
<p>Interestingly, the drift of <span class="math inline">\(\tilde{B}(t)\)</span> becomes the volatility factor in <span class="math inline">\(M_{T}\)</span>! <span class="math inline">\(\mathbb{E}[M_{T}^{2}]=\mathbb{E}[e^{-2\theta B(T)-\theta^{2}T}]=e^{-\theta^{2}T}\cdot\mathbb{E}[e^{-2\theta B(T)}]=e^{-\theta^{2}T}\cdot e^{2\theta^{2}T}=e^{\theta^{2}T}\)</span>.</p>
<p>The fact that <span class="math inline">\(M(t)\)</span> is a martingale is very helpful in calculations. Indeed, suppose we want to compute the expectation of a function <span class="math inline">\(F(\tilde{B}(s))\)</span> of a Brownian motion with drift at time <span class="math inline">\(s&lt;T\)</span>. Then, we have by <a href="#thm-girsanov-theorem-for-constant-drift-case">Theorem&nbsp;2</a>:</p>
<p><span class="math display">\[\begin{aligned}
\mathbb{E}[F(\tilde{B}(s))] &amp; =\mathbb{E}[M_{T}M_{T}^{-1}F(\tilde{B}(s))]\\
&amp; =\tilde{\mathbb{E}}[M_{T}^{-1}F(\tilde{B}(s))]\\
&amp; =\tilde{\mathbb{E}}[e^{\theta\tilde{B}(T)-\frac{1}{2}\theta^{2}T}F(\tilde{B}(s))]
\end{aligned}\]</span></p>
<p>Now, we know that under <span class="math inline">\(\tilde{\mathbb{P}}\)</span>probability, <span class="math inline">\((\tilde{B}(t),t\in[0,T])\)</span> is a standard brownian motion, or <span class="math inline">\(\tilde{\mathbb{P}}\)</span>-standard brownian motion for short. Therefore, the process <span class="math inline">\(e^{\theta\tilde{B}(t)-\frac{1}{2}\theta^{2}t}\)</span> is a martingale under the new probability measure <span class="math inline">\(\tilde{\mathbb{P}}\)</span>, or a <span class="math inline">\(\tilde{\mathbb{P}}\)</span>-martingale for short. By conditioning over <span class="math inline">\(\mathcal{F}_{s}\)</span> and applying the martingale property, we get:</p>
<p><span class="math display">\[\begin{aligned}
\mathbb{E}\left[F(\tilde{B}_{s})\right] &amp; =\tilde{\mathbb{E}}[e^{\theta\tilde{B}(T)-\frac{1}{2}\theta^{2}T}F(\tilde{B}(s))]\\
&amp; =\tilde{\mathbb{E}}[\tilde{\mathbb{E}}[e^{\theta\tilde{B}(T)-\frac{1}{2}\theta^{2}T}F(\tilde{B}(s))|\mathcal{F}_{s}]]\\
&amp; =\tilde{\mathbb{E}}[e^{\theta\tilde{B}(s)-\frac{1}{2}\theta^{2}s}F(\tilde{B}(s))]\\
&amp; =\mathbb{E}[e^{\theta B(s)-\frac{1}{2}\theta^{2}s}F(B(s))]
\end{aligned}\]</span></p>
<p>The last equality may seem wrong as removed all the tildes. It is not! It holds because <span class="math inline">\((\tilde{B}(t))\)</span> under <span class="math inline">\(\tilde{\mathbb{P}}\)</span> has the same distribution as <span class="math inline">\((B(t))\)</span> under <span class="math inline">\(\mathbb{P}\)</span>: a standard brownian motion. Of course, it would be possible to directly evaluate <span class="math inline">\(\mathbb{E}[F(\tilde{B}(s))]\)</span> here as we know the distribution of a Brownian motion with drift. However, when the function will involve more than one point (such as the maximum of the path), the Cameron-Martin theorem is a powerful tool to evaluate expectations.</p>
<p>(3) <strong>The paths with or without the drift are the same.</strong> Let <span class="math inline">\((B(t),t\leq T)\)</span> be a standard Brownian motion defined on <span class="math inline">\((\Omega,\mathcal{F},\mathbb{P})\)</span>. Heuristically, it is fruitful to think of the sample space of <span class="math inline">\(\Omega\)</span> as the different continuous paths of Brownian motion. Since, the change of probability from <span class="math inline">\(\mathbb{P}\)</span> to <span class="math inline">\(\tilde{\mathbb{P}}\)</span>simply changes the relative weights of the paths (and this change of weight is never zero, similarly to equation (<a href="#eq:girsanov-probability-scaling" data-reference-type="ref" data-reference="eq:girsanov-probability-scaling">[eq:girsanov-probability-scaling]</a>) for a single random variable), the theorem suggests that the paths of a standard Brownian motion and those of a Brownian motion with a constant drift <span class="math inline">\(\theta\)</span> (with volatility <span class="math inline">\(1\)</span>) are essentially the same.</p>
<p>The form of the factor <span class="math inline">\(M_{T}=e^{-\theta\tilde{B}_{T}+\theta^{2}T}\)</span> can be easily understood at the heuristic level. For each outcome <span class="math inline">\(\omega\)</span>, it is proportional to <span class="math inline">\(e^{-\theta\tilde{B}_{T}(\omega)}\)</span> (The term <span class="math inline">\(e^{(\theta^{2}/2)T}\)</span> is simply to ensure that <span class="math inline">\(\mathbb{P}(\Omega)=1\)</span>) Therefore, the factor <span class="math inline">\(M_{T}\)</span> penalizes the paths for which <span class="math inline">\(\tilde{B}_{T}(\omega)\)</span> is large and positive (if <span class="math inline">\(\theta&gt;0\)</span>). In particular, it is conceivable that the Brownian motion with positive drift is reduced to standard Brownian motion under the new probability.</p>
<p>(4) <strong>Changing the volatility.</strong> What about the volatility? Is it possible to change the probability <span class="math inline">\(\mathbb{P}\)</span> to <span class="math inline">\(\tilde{\mathbb{P}}\)</span> in such a way that the Brownian motion under <span class="math inline">\(\mathbb{P}\)</span> has volatility <span class="math inline">\(\sigma\neq1\)</span> under <span class="math inline">\(\tilde{\mathbb{P}}\)</span>? The answer is no! The paths of the Brownian motions with different volatilities are inherently different. Indeed, it suffices to compute the quadratic variation. If <span class="math inline">\((B_{t}:t\in[0,T])\)</span> has volatility <span class="math inline">\(1\)</span> and <span class="math inline">\((\tilde{B_{t}},t\in[0,T])\)</span> has volatility <span class="math inline">\(2\)</span>. then the following convergence holds for <span class="math inline">\(\omega\)</span> in a set of probability one (for a partition fine enough, say <span class="math inline">\(t_{j+1}-t_{j}=2^{-n}\)</span>. Then <span class="math inline">\(B_{t}=\int1\cdot dB_{t}\)</span> and <span class="math inline">\(\tilde{B_{t}}=\int2\cdot dB_{t}\)</span></p>
<p><span class="math display">\[\begin{aligned}
\lim_{n\to\infty}\sum_{j=0}^{n-1}(B_{t_{j+1}}(\omega)-B_{t_{j}}(\omega))^{2} &amp; =\int_{0}^{T}1^{2}\cdot ds=T
\end{aligned}\]</span></p>
<p><span class="math display">\[\begin{aligned}
\lim_{n\to\infty}\sum_{j=0}^{n-1}(\tilde{B}_{t_{j+1}}(\omega)-\tilde{B}_{t_{j}}(\omega))^{2} &amp; =\int_{0}^{T}2^{2}\cdot ds=4T
\end{aligned}\]</span></p>
<p>In other words, the distribution of the standard brownian motion on <span class="math inline">\([0,T]\)</span> is supported on paths whose quadratic variation is <span class="math inline">\(T\)</span>, whereas the distribution of <span class="math inline">\((\tilde{B}_{t},t\geq0)\)</span> is supported on paths where the quadratic variation is <span class="math inline">\(4T\)</span>. These paths are very different. We conclude that the distributions of the two processes are not equivalent. Hence, a change of probability from <span class="math inline">\(\mathbb{P}\)</span> to <span class="math inline">\(\mathbb{\tilde{P}}\)</span> is not possible. In fact, we say that they are mutually singular, meaning the set of paths on which they are supported are disjoint.</p>
<p><em>Proof.</em></p>
<p>Let <span class="math inline">\((\tilde{B}_{t}:t\in[0,T])\)</span> be a Brownian motion with constant drift <span class="math inline">\(\theta\)</span> defined on <span class="math inline">\((\Omega,\mathcal{F},\mathbb{P})\)</span>. Thus, <span class="math inline">\(\tilde{B}_{t}=\theta t+B_{t}\)</span>.</p>
<p><strong>Claim</strong>. <span class="math inline">\(\tilde{B}_{t}\)</span> is a <span class="math inline">\(\mathbb{\tilde{P}}\)</span>-martingale.</p>
<p>Let</p>
<p><span class="math display">\[\begin{aligned}
M_{t} &amp; =f(t,B_{t})=\exp(-\theta B_{t}-(\theta^{2}/2)t)
\end{aligned}\]</span></p>
<p>So:</p>
<p><span class="math display">\[\begin{aligned}
dM_{t} &amp; =-\frac{\theta^{2}}{2}M_{t}dt-\theta M_{t}dB_{t}+\frac{1}{2}\theta^{2}M(t)dt\\
&amp; =-\theta M_{t}dB_{t}
\end{aligned}\]</span></p>
<p>Consider the product <span class="math inline">\((M_{t}\tilde{B}_{t})\)</span>. We have:</p>
<p><span class="math display">\[\begin{aligned}
d(M_{t}\tilde{B}_{t}) &amp; =\tilde{B}_{t}dM_{t}+M_{t}d\tilde{B}_{t}+dM_{t}\cdot d\tilde{B}_{t}\\
&amp; =-\tilde{B}_{t}\theta M_{t}dB_{t}+M_{t}(\theta dt+dB_{t})-\theta M_{t}dB_{t}(\theta dt+dB_{t})\\
&amp; =-\tilde{B}_{t}\theta M_{t}dB_{t}+\theta M_{t}dt+M_{t}dB_{t}-\theta M_{t}dt\\
&amp; =(-\tilde{B}_{t}\theta+1)M_{t}dB_{t}
\end{aligned}\]</span></p>
<p>Thus, by the properties of Ito integral,<span class="math inline">\(M_{t}\tilde{B}_{t}\)</span> is a martingale under <span class="math inline">\(\mathbb{P}\)</span>. By the abstract Bayes formula (<a href="#th:abstract-bayes-formula" data-reference-type="ref" data-reference="th:abstract-bayes-formula">[th:abstract-bayes-formula]</a>):</p>
<p><span class="math display">\[\begin{aligned}
\tilde{\mathbb{E}}[\tilde{B}_{t}|\mathcal{F}_{s}] &amp; =\frac{1}{M_{s}}\mathbb{E}[M_{t}\tilde{B}_{t}|\mathcal{F}_{s}]\\
&amp; =\frac{1}{M_{s}}\cdot M_{s}\tilde{B}_{s}\\
&amp; =\tilde{B}_{s}
\end{aligned}\]</span></p>
<p>Thus, <span class="math inline">\(\tilde{B}_{t}\)</span> is a <span class="math inline">\(\tilde{\mathbb{P}}\)</span>-martingale.</p>
<p><strong>Claim</strong>. Our claim is that under the <span class="math inline">\(\tilde{\mathbb{P}}\)</span> measure, <span class="math inline">\(\tilde{B}_{t}\sim\mathcal{N}^{\mathbb{\tilde{P}}}(0,t)\)</span> and to do this we rely on the the moment-generating function.</p>
<p>By definition, for a constant <span class="math inline">\(\Psi\)</span>:</p>
<p><span class="math display">\[\begin{aligned}
M_{\tilde{B}_{t}}(\Psi) &amp; =\tilde{\mathbb{E}}\left[\exp\left(\Psi\tilde{B}_{t}\right)\right]\\
&amp; =\mathbb{E}\left[M_{T}\exp\left(\Psi\tilde{B}_{t}\right)\right]\\
&amp; =\mathbb{E}\left[\exp\left(-\theta\tilde{B}_{T}+\frac{\theta^{2}}{2}T+\Psi\tilde{B}_{t}\right)\right]\\
&amp; =\mathbb{E}\left[\exp\left(-\theta(\theta T+B_{T})+\frac{\theta^{2}}{2}T+\Psi(\theta t+B_{t})\right)\right]\\
&amp; =\mathbb{E}\left[\exp\left(-\theta B_{T}-\frac{\theta^{2}}{2}T+\Psi\theta t+\Psi B_{t})\right)\right]\\
&amp; =\mathbb{E}\left[\exp\left(-\theta(B_{T}-B_{t})-\frac{\theta^{2}}{2}T+\Psi\theta t+(\Psi-\theta)B_{t})\right)\right]\\
&amp; =\exp\left(-\frac{\theta^{2}}{2}T+\Psi\theta t\right)\mathbb{E}\left(-\theta(B_{T}-B_{t})\right)\mathbb{E}\left((\Psi-\theta)B_{t}\right)\\
&amp; =\exp\left(-\frac{\theta^{2}}{2}T+\Psi\theta t\right)\exp\left[\frac{1}{2}\theta^{2}(T-t)\right]\exp\left[\frac{1}{2}(\Psi-\theta)^{2}t\right]\\
&amp; =\exp\left[-\frac{1}{2}\left(\theta^{2}-2\Psi\theta-(\Psi-\theta)^{2}\right)t\right]\\
&amp; =\exp\left[-\frac{1}{2}\left(\theta^{2}-2\Psi\theta-(\Psi^{2}-2\Psi\theta+\theta^{2}\right)t\right]\\
&amp; =\exp(-\Psi^{2}t)
\end{aligned}\]</span></p>
<p>Thus, <span class="math inline">\(\tilde{B}_{t}\sim\mathcal{N}^{\tilde{\mathbb{P}}}(0,t)\)</span>.</p>
<p><strong>Claim</strong>. Finally, to show that <span class="math inline">\(\tilde{B}_{t}\)</span> is indeed a <span class="math inline">\(\mathbb{\tilde{P}}-\)</span>standard brownian motion, we have the following:</p>
<p>(a) <span class="math inline">\(\tilde{B}_{0}=\theta(0)+B_{0}=0\)</span> and <span class="math inline">\(\tilde{B}_{t}\)</span> has almost surely continuous paths.</p>
<p>(b) We would like to prove that, for <span class="math inline">\(s&lt;t\)</span>, <span class="math inline">\(\tilde{B}_{t}-\tilde{B}_{s}\sim\mathcal{N}^{\tilde{\mathbb{P}}}(0,t-s)\)</span>. We have:</p>
<p><span class="math display">\[\begin{aligned}
\mathbb{E}[\tilde{B}_{t}-\tilde{B}_{s}] &amp; =\tilde{\mathbb{E}}[\tilde{B}_{t}]-\tilde{\mathbb{E}}[B_{s}]\\
&amp; =0
\end{aligned}\]</span></p>
<p>And,</p>
<p><span class="math display">\[\begin{aligned}
\tilde{\mathbb{E}}[(\tilde{B}_{t}-\tilde{B}_{s})^{2}] &amp; =\tilde{\mathbb{E}}[\tilde{B}_{t}^{2}-2\tilde{B}_{t}\tilde{B}_{s}+\tilde{B}_{s}^{2}]\\
&amp; =\tilde{\mathbb{E}}[B_{t}^{2}]-2\tilde{\mathbb{E}}[\tilde{B}_{t}\tilde{B}_{s}]+\tilde{\mathbb{E}}[\tilde{B}_{s}^{2}]\\
&amp; =t+s-2\tilde{\mathbb{E}}[\tilde{B}_{t}\tilde{B}_{s}]
\end{aligned}\]</span></p>
<p>(c) The non-overlapping increments of a <span class="math inline">\(\tilde{\mathbb{P}}\)</span>-martingale are independent. To see this, suppose <span class="math inline">\(t_{1}\leq t_{2}\leq t_{3}\)</span>:</p>
<p><span class="math display">\[\begin{aligned}
\tilde{\mathbb{E}}[(B_{t_{3}}-B_{t_{2}})(B_{t_{2}}-B_{t_{1}})] &amp; =\tilde{\mathbb{E}}[\tilde{\mathbb{E}}[(B_{t_{3}}-B_{t_{2}})(B_{t_{2}}-B_{t_{1}})|\mathcal{F}_{t_{2}}]]\\
&amp; =\tilde{\mathbb{E}}[(B_{t_{2}}-B_{t_{1}})\tilde{\mathbb{E}}[(B_{t_{3}}-B_{t_{2}})|\mathcal{F}_{t_{2}}]]\\
&amp; =\tilde{\mathbb{E}}[(B_{t_{2}}-B_{t_{1}})(B_{t_{2}}-B_{t_{2}})]]=0
\end{aligned}\]</span></p>
<p>Also, the covariance</p>
<p><span class="math display">\[\begin{aligned}
\tilde{\mathbb{E}}[\tilde{B}_{t}\tilde{B}_{s}] &amp; =\tilde{\mathbb{E}}[(\tilde{B}_{t}-\tilde{B}_{s})\tilde{B}_{s}]+\tilde{\mathbb{E}}[\tilde{B}_{s}^{2}]\\
&amp; =0+s
\end{aligned}\]</span></p>
<p>So, <span class="math inline">\(\mathbb{E}[(\tilde{B}_{t}-\tilde{B}_{s})^{2}]=t+s-2s=t-s\)</span>.</p>
<p>Consequently, <span class="math inline">\(\tilde{B}_{t}\)</span> is a <span class="math inline">\(\tilde{\mathbb{P}}\)</span>-standard brownian motion.</p>


</section>
</section>

</main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const isCodeAnnotation = (el) => {
    for (const clz of el.classList) {
      if (clz.startsWith('code-annotation-')) {                     
        return true;
      }
    }
    return false;
  }
  const clipboard = new window.ClipboardJS('.code-copy-button', {
    text: function(trigger) {
      const codeEl = trigger.previousElementSibling.cloneNode(true);
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
    }
  });
  clipboard.on('success', function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Copied!");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  });
  function tippyHover(el, contentFn) {
    const config = {
      allowHTML: true,
      content: contentFn,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start'
    };
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      return note.innerHTML;
    });
  }
      let selectedAnnoteEl;
      const selectorForAnnotation = ( cell, annotation) => {
        let cellAttr = 'data-code-cell="' + cell + '"';
        let lineAttr = 'data-code-annotation="' +  annotation + '"';
        const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
        return selector;
      }
      const selectCodeLines = (annoteEl) => {
        const doc = window.document;
        const targetCell = annoteEl.getAttribute("data-target-cell");
        const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
        const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
        const lines = annoteSpan.getAttribute("data-code-lines").split(",");
        const lineIds = lines.map((line) => {
          return targetCell + "-" + line;
        })
        let top = null;
        let height = null;
        let parent = null;
        if (lineIds.length > 0) {
            //compute the position of the single el (top and bottom and make a div)
            const el = window.document.getElementById(lineIds[0]);
            top = el.offsetTop;
            height = el.offsetHeight;
            parent = el.parentElement.parentElement;
          if (lineIds.length > 1) {
            const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
            const bottom = lastEl.offsetTop + lastEl.offsetHeight;
            height = bottom - top;
          }
          if (top !== null && height !== null && parent !== null) {
            // cook up a div (if necessary) and position it 
            let div = window.document.getElementById("code-annotation-line-highlight");
            if (div === null) {
              div = window.document.createElement("div");
              div.setAttribute("id", "code-annotation-line-highlight");
              div.style.position = 'absolute';
              parent.appendChild(div);
            }
            div.style.top = top - 2 + "px";
            div.style.height = height + 4 + "px";
            let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
            if (gutterDiv === null) {
              gutterDiv = window.document.createElement("div");
              gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
              gutterDiv.style.position = 'absolute';
              const codeCell = window.document.getElementById(targetCell);
              const gutter = codeCell.querySelector('.code-annotation-gutter');
              gutter.appendChild(gutterDiv);
            }
            gutterDiv.style.top = top - 2 + "px";
            gutterDiv.style.height = height + 4 + "px";
          }
          selectedAnnoteEl = annoteEl;
        }
      };
      const unselectCodeLines = () => {
        const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
        elementsIds.forEach((elId) => {
          const div = window.document.getElementById(elId);
          if (div) {
            div.remove();
          }
        });
        selectedAnnoteEl = undefined;
      };
      // Attach click handler to the DT
      const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
      for (const annoteDlNode of annoteDls) {
        annoteDlNode.addEventListener('click', (event) => {
          const clickedEl = event.target;
          if (clickedEl !== selectedAnnoteEl) {
            unselectCodeLines();
            const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
            if (activeEl) {
              activeEl.classList.remove('code-annotation-active');
            }
            selectCodeLines(clickedEl);
            clickedEl.classList.add('code-annotation-active');
          } else {
            // Unselect the line
            unselectCodeLines();
            clickedEl.classList.remove('code-annotation-active');
          }
        });
      }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
});
</script>
<script src="https://giscus.app/client.js" data-repo="quasar-chunawala/quantdev" data-repo-id="R_kgDOL2t5-A" data-category="General" data-category-id="DIC_kwDOL2t5-M4ClndQ" data-mapping="title" data-reactions-enabled="1" data-emit-metadata="0" data-input-position="top" data-theme="light" data-lang="en" crossorigin="anonymous" async="">
</script>
</div> <!-- /content -->



</body></html>