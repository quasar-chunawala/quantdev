<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.6.39">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">

<meta name="author" content="Quasar">
<meta name="dcterms.date" content="2024-05-28">

<title>Coding a neural network layer – quantdev.blog</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
/* CSS for syntax highlighting */
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { display: inline-block; text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
  }
pre.numberSource { margin-left: 3em;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
</style>


<script src="../../site_libs/quarto-nav/quarto-nav.js"></script>
<script src="../../site_libs/quarto-nav/headroom.min.js"></script>
<script src="../../site_libs/clipboard/clipboard.min.js"></script>
<script src="../../site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="../../site_libs/quarto-search/fuse.min.js"></script>
<script src="../../site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="../../">
<script src="../../site_libs/quarto-html/quarto.js"></script>
<script src="../../site_libs/quarto-html/popper.min.js"></script>
<script src="../../site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="../../site_libs/quarto-html/anchor.min.js"></script>
<link href="../../site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="../../site_libs/quarto-html/quarto-syntax-highlighting-d129a44951930463e8a313df5966fbea.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="../../site_libs/bootstrap/bootstrap.min.js"></script>
<link href="../../site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="../../site_libs/bootstrap/bootstrap-52232225ae3909a0ea66e9fd7c84c945.min.css" rel="stylesheet" append-hash="true" id="quarto-bootstrap" data-mode="light">
<script id="quarto-search-options" type="application/json">{
  "location": "navbar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "end",
  "type": "overlay",
  "limit": 50,
  "keyboard-shortcut": [
    "f",
    "/",
    "s"
  ],
  "show-item-context": false,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-text-placeholder": "",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit",
    "search-label": "Search"
  }
}</script>
<style>
  @import url('https://fonts.googleapis.com/css2?family=Inter:wght@400;800&display=swap');
  @import url('https://fonts.googleapis.com/css2?family=EB+Garamond:ital,wght@0,400..800;1,400..800&display=swap');
  @import url('https://fonts.googleapis.com/css2?family=Fira+Code:wght@300..700&display=swap');
  @import url('https://fonts.googleapis.com/css2?family=Roboto:ital,wght@0,100;0,300;0,400;0,500;0,700;0,900;1,100;1,300;1,400;1,500;1,700;1,900&display=swap');
  @import url('https://fonts.googleapis.com/css2?family=Roboto:ital,wght@0,100;0,300;0,400;0,500;0,700;0,900;1,100;1,300;1,400;1,500;1,700;1,900&family=Source+Code+Pro:ital,wght@0,200..900;1,200..900&display=swap');
  @import url('https://fonts.googleapis.com/css2?family=Open+Sans:ital,wght@0,300..800;1,300..800&display=swap');
  @import url('https://fonts.googleapis.com/css2?family=JetBrains+Mono:ital,wght@0,100..800;1,100..800&display=swap')
</style>
<script async="" src="https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js?client=ca-pub-9993009899870547" crossorigin="anonymous"></script>

  <script src="https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js?features=es6"></script>
  <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js" type="text/javascript"></script>

<script type="text/javascript">
const typesetMath = (el) => {
  if (window.MathJax) {
    // MathJax Typeset
    window.MathJax.typeset([el]);
  } else if (window.katex) {
    // KaTeX Render
    var mathElements = el.getElementsByClassName("math");
    var macros = [];
    for (var i = 0; i < mathElements.length; i++) {
      var texText = mathElements[i].firstChild;
      if (mathElements[i].tagName == "SPAN") {
        window.katex.render(texText.data, mathElements[i], {
          displayMode: mathElements[i].classList.contains('display'),
          throwOnError: false,
          macros: macros,
          fleqn: false
        });
      }
    }
  }
}
window.Quarto = {
  typesetMath
};
</script>

<link rel="stylesheet" href="../../styles.css">
</head>

<body class="nav-fixed">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top quarto-banner">
    <nav class="navbar navbar-expand-lg " data-bs-theme="dark">
      <div class="navbar-container container-fluid">
      <div class="navbar-brand-container mx-auto">
    <a class="navbar-brand" href="../../index.html">
    <span class="navbar-title">quantdev.blog</span>
    </a>
  </div>
            <div id="quarto-search" class="" title="Search"></div>
          <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbarCollapse" aria-controls="navbarCollapse" role="menu" aria-expanded="false" aria-label="Toggle navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
  <span class="navbar-toggler-icon"></span>
</button>
          <div class="collapse navbar-collapse" id="navbarCollapse">
            <ul class="navbar-nav navbar-nav-scroll ms-auto">
  <li class="nav-item">
    <a class="nav-link" href="../../about.html"> 
<span class="menu-text">About</span></a>
  </li>  
  <li class="nav-item compact">
    <a class="nav-link" href="https://github.com/"> <i class="bi bi-github" role="img">
</i> 
<span class="menu-text"></span></a>
  </li>  
  <li class="nav-item compact">
    <a class="nav-link" href="https://twitter.com"> <i class="bi bi-twitter" role="img">
</i> 
<span class="menu-text"></span></a>
  </li>  
  <li class="nav-item compact">
    <a class="nav-link" href="../../index.xml"> <i class="bi bi-rss" role="img">
</i> 
<span class="menu-text"></span></a>
  </li>  
</ul>
          </div> <!-- /navcollapse -->
            <div class="quarto-navbar-tools">
</div>
      </div> <!-- /container-fluid -->
    </nav>
</header>
<!-- content -->
<header id="title-block-header" class="quarto-title-block default page-columns page-full">
  <div class="quarto-title-banner page-columns page-full">
    <div class="quarto-title column-body">
      <div class="quarto-title-block"><div><h1 class="title">Coding a neural network layer</h1><button type="button" class="btn code-tools-button dropdown-toggle" id="quarto-code-tools-menu" data-bs-toggle="dropdown" aria-expanded="false"><i class="bi"></i> Code</button><ul class="dropdown-menu dropdown-menu-end" aria-labelelledby="quarto-code-tools-menu"><li><a id="quarto-show-all-code" class="dropdown-item" href="javascript:void(0)" role="button">Show All Code</a></li><li><a id="quarto-hide-all-code" class="dropdown-item" href="javascript:void(0)" role="button">Hide All Code</a></li><li><hr class="dropdown-divider"></li><li><a id="quarto-view-source" class="dropdown-item" href="javascript:void(0)" role="button">View Source</a></li></ul></div></div>
                                <div class="quarto-categories">
                <div class="quarto-category">Machine Learning</div>
              </div>
                  </div>
  </div>
    
  
  <div class="quarto-title-meta">

      <div>
      <div class="quarto-title-meta-heading">Author</div>
      <div class="quarto-title-meta-contents">
               <p>Quasar </p>
            </div>
    </div>
      
      <div>
      <div class="quarto-title-meta-heading">Published</div>
      <div class="quarto-title-meta-contents">
        <p class="date">May 28, 2024</p>
      </div>
    </div>
    
      
    </div>
    
  
  </header><div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article page-navbar">
<!-- sidebar -->
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
        <nav id="TOC" role="doc-toc" class="toc-active">
    <h2 id="toc-title">On this page</h2>
   
  <ul>
  <li><a href="#introduction" id="toc-introduction" class="nav-link active" data-scroll-target="#introduction">Introduction</a>
  <ul class="collapse">
  <li><a href="#activation-functions" id="toc-activation-functions" class="nav-link" data-scroll-target="#activation-functions">Activation functions</a></li>
  </ul></li>
  <li><a href="#coding-a-layer-with-3-neurons" id="toc-coding-a-layer-with-3-neurons" class="nav-link" data-scroll-target="#coding-a-layer-with-3-neurons">Coding a layer with 3-neurons</a></li>
  <li><a href="#a-layer-of-neurons-and-a-batch-of-data" id="toc-a-layer-of-neurons-and-a-batch-of-data" class="nav-link" data-scroll-target="#a-layer-of-neurons-and-a-batch-of-data">A layer of neurons and a batch of data</a></li>
  <li><a href="#adding-layers" id="toc-adding-layers" class="nav-link" data-scroll-target="#adding-layers">Adding Layers</a></li>
  <li><a href="#training-data" id="toc-training-data" class="nav-link" data-scroll-target="#training-data">Training Data</a></li>
  <li><a href="#dense-layer-class" id="toc-dense-layer-class" class="nav-link" data-scroll-target="#dense-layer-class">Dense Layer Class</a></li>
  <li><a href="#activation-functions-1" id="toc-activation-functions-1" class="nav-link" data-scroll-target="#activation-functions-1">Activation Functions</a>
  <ul class="collapse">
  <li><a href="#why-use-activation-functions" id="toc-why-use-activation-functions" class="nav-link" data-scroll-target="#why-use-activation-functions">Why use activation functions?</a></li>
  </ul></li>
  <li><a href="#relu-activation-in-a-pair-of-neurons" id="toc-relu-activation-in-a-pair-of-neurons" class="nav-link" data-scroll-target="#relu-activation-in-a-pair-of-neurons">ReLU Activation in a pair of Neurons</a></li>
  <li><a href="#relu-activation-in-hidden-layers" id="toc-relu-activation-in-hidden-layers" class="nav-link" data-scroll-target="#relu-activation-in-hidden-layers">ReLU Activation in hidden layers</a></li>
  <li><a href="#the-softmax-activation-function" id="toc-the-softmax-activation-function" class="nav-link" data-scroll-target="#the-softmax-activation-function">The Softmax Activation function</a></li>
  <li><a href="#the-output-layer" id="toc-the-output-layer" class="nav-link" data-scroll-target="#the-output-layer">The output layer</a>
  <ul class="collapse">
  <li><a href="#full-code-upto-this-point" id="toc-full-code-upto-this-point" class="nav-link" data-scroll-target="#full-code-upto-this-point">Full code upto this point</a></li>
  </ul></li>
  </ul>
</nav>
    </div>
<!-- main -->
<main class="content quarto-banner-title-block" id="quarto-document-content">





<section id="introduction" class="level2">
<h2 class="anchored" data-anchor-id="introduction">Introduction</h2>
<p>In 1943, McCulloch and Pitts introduced artificial intelligence to the world. Their idea was to develop an algorithmic approach to mimic the functionality of the human brain. Due to the structure of the brain consisting of a net of neurons, they introduced the so-called <em>artificial neurons</em> as building blocks.</p>
<p>In it’s most simple form, the neuron consists of :</p>
<ul>
<li>dendrites, which receive the information from other neurons</li>
<li>soma, which processes the information</li>
<li>synapse, transmits the output of this neuron</li>
<li>axon, point of connection to other neurons</li>
</ul>
<p>Consequently, a mathematical definition of an artificial neuron is as follows.</p>
<p><em>Definition.</em> An <em>artificial neuron</em> with weights <span class="math inline">\(w_1,\ldots,w_n \in \mathbf{R}\)</span>, bias <span class="math inline">\(b\in\mathbf{R}\)</span> and an activation function <span class="math inline">\(\rho:\mathbf{R} \to \mathbf{R}\)</span> is defined as the scalar-valued function <span class="math inline">\(f:\mathbf{R}^n \to \mathbf{R}\)</span> given by:</p>
<p><span class="math display">\[\begin{align*}
f(x_1,\ldots,x_n) = \rho \left(\sum_{i=1}^{n}w_i x_i + b\right) = \rho(\mathbf{w}^T \mathbf{x}+b) \tag{1}
\end{align*}\]</span></p>
<p>where <span class="math inline">\(\mathbf{w} = (w_1,\ldots,w_n)\)</span> and <span class="math inline">\(\mathbf{x}=(x_1,\ldots,x_n)\)</span>.</p>
<p>A single neuron by itself is useless, but when combined with hundreds or thousands(or many more) of other neurons, the interconnectivity can approximate any complex function and frequently outperforms any other machine learning methods.</p>
<div class="cell" data-execution_count="1">
<div class="sourceCode cell-code" id="cb1"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb1-1"><a href="#cb1-1"></a><span class="op">%</span>load_ext itikz</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="cell" data-execution_count="2">
<details class="code-fold">
<summary>Show the code</summary>
<div class="sourceCode cell-code" id="cb2"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb2-1"><a href="#cb2-1"></a><span class="op">%%</span>itikz <span class="op">--</span>temp<span class="op">-</span><span class="bu">dir</span> <span class="op">--</span>tex<span class="op">-</span>packages<span class="op">=</span>tikz <span class="op">--</span>tikz<span class="op">-</span>libraries<span class="op">=</span>arrows <span class="op">--</span>implicit<span class="op">-</span>standalone</span>
<span id="cb2-2"><a href="#cb2-2"></a>\begin{tikzpicture}</span>
<span id="cb2-3"><a href="#cb2-3"></a>\foreach \i <span class="kw">in</span> {<span class="dv">1</span>,<span class="dv">2</span>}</span>
<span id="cb2-4"><a href="#cb2-4"></a>{</span>
<span id="cb2-5"><a href="#cb2-5"></a>    \node[circle, </span>
<span id="cb2-6"><a href="#cb2-6"></a>        minimum size <span class="op">=</span> <span class="dv">15</span><span class="er">mm</span>,</span>
<span id="cb2-7"><a href="#cb2-7"></a>        fill<span class="op">=</span>red<span class="op">!</span><span class="dv">30</span></span>
<span id="cb2-8"><a href="#cb2-8"></a>        ] (Input<span class="op">-</span>\i) at (<span class="dv">0</span>,<span class="op">-</span>\i <span class="op">*</span> <span class="dv">2</span>) {\large $x_\i$}<span class="op">;</span></span>
<span id="cb2-9"><a href="#cb2-9"></a>}</span>
<span id="cb2-10"><a href="#cb2-10"></a>\foreach \i <span class="kw">in</span> {<span class="dv">1</span>,<span class="dv">2</span>,...,<span class="dv">5</span>}</span>
<span id="cb2-11"><a href="#cb2-11"></a>{</span>
<span id="cb2-12"><a href="#cb2-12"></a>    \node[circle, </span>
<span id="cb2-13"><a href="#cb2-13"></a>        minimum size <span class="op">=</span> <span class="dv">15</span><span class="er">mm</span>,</span>
<span id="cb2-14"><a href="#cb2-14"></a>        fill<span class="op">=</span>blue<span class="op">!</span><span class="dv">50</span>,</span>
<span id="cb2-15"><a href="#cb2-15"></a>        yshift<span class="op">=</span><span class="dv">30</span> mm</span>
<span id="cb2-16"><a href="#cb2-16"></a>        ] (Hidden1<span class="op">-</span>\i) at (<span class="fl">3.0</span>,<span class="op">-</span>\i <span class="op">*</span> <span class="dv">2</span>) {\large $h_\i<span class="op">^</span>{(<span class="dv">1</span>)}$}<span class="op">;</span></span>
<span id="cb2-17"><a href="#cb2-17"></a>        </span>
<span id="cb2-18"><a href="#cb2-18"></a>}</span>
<span id="cb2-19"><a href="#cb2-19"></a>\foreach \i <span class="kw">in</span> {<span class="dv">1</span>,<span class="dv">2</span>,...,<span class="dv">5</span>}</span>
<span id="cb2-20"><a href="#cb2-20"></a>{</span>
<span id="cb2-21"><a href="#cb2-21"></a>    \node[circle, </span>
<span id="cb2-22"><a href="#cb2-22"></a>        minimum size <span class="op">=</span> <span class="dv">15</span><span class="er">mm</span>,</span>
<span id="cb2-23"><a href="#cb2-23"></a>        fill<span class="op">=</span>blue<span class="op">!</span><span class="dv">50</span>,</span>
<span id="cb2-24"><a href="#cb2-24"></a>        yshift<span class="op">=</span><span class="dv">30</span> mm</span>
<span id="cb2-25"><a href="#cb2-25"></a>        ] (Hidden2<span class="op">-</span>\i) at (<span class="fl">6.0</span>,<span class="op">-</span>\i <span class="op">*</span> <span class="dv">2</span>) {\large $h_\i<span class="op">^</span>{(<span class="dv">2</span>)}$}<span class="op">;</span></span>
<span id="cb2-26"><a href="#cb2-26"></a>}</span>
<span id="cb2-27"><a href="#cb2-27"></a>\foreach \i <span class="kw">in</span> {<span class="dv">1</span>,<span class="dv">2</span>}</span>
<span id="cb2-28"><a href="#cb2-28"></a>{</span>
<span id="cb2-29"><a href="#cb2-29"></a>    \node[circle, </span>
<span id="cb2-30"><a href="#cb2-30"></a>        minimum size <span class="op">=</span> <span class="dv">15</span><span class="er">mm</span>,</span>
<span id="cb2-31"><a href="#cb2-31"></a>        fill<span class="op">=</span>green<span class="op">!</span><span class="dv">30</span>] (Output<span class="op">-</span>\i) at (<span class="fl">9.0</span>,<span class="op">-</span>\i <span class="op">*</span> <span class="dv">2</span>) {\large $\hat{y}_\i$}<span class="op">;</span></span>
<span id="cb2-32"><a href="#cb2-32"></a>}</span>
<span id="cb2-33"><a href="#cb2-33"></a></span>
<span id="cb2-34"><a href="#cb2-34"></a><span class="op">%</span> Connect neurons In<span class="op">-</span>Hidden1</span>
<span id="cb2-35"><a href="#cb2-35"></a>\foreach \i <span class="kw">in</span> {<span class="dv">1</span>,...,<span class="dv">2</span>}</span>
<span id="cb2-36"><a href="#cb2-36"></a>{</span>
<span id="cb2-37"><a href="#cb2-37"></a>    \foreach \j <span class="kw">in</span> {<span class="dv">1</span>,...,<span class="dv">5</span>}</span>
<span id="cb2-38"><a href="#cb2-38"></a>    {</span>
<span id="cb2-39"><a href="#cb2-39"></a>        \draw[<span class="op">-&gt;</span>, shorten <span class="op">&gt;=</span><span class="dv">1</span><span class="er">pt</span>] (Input<span class="op">-</span>\i) <span class="op">--</span> (Hidden1<span class="op">-</span>\j)<span class="op">;</span>   </span>
<span id="cb2-40"><a href="#cb2-40"></a>    }</span>
<span id="cb2-41"><a href="#cb2-41"></a>}</span>
<span id="cb2-42"><a href="#cb2-42"></a>\foreach \i <span class="kw">in</span> {<span class="dv">1</span>,...,<span class="dv">5</span>}</span>
<span id="cb2-43"><a href="#cb2-43"></a>{</span>
<span id="cb2-44"><a href="#cb2-44"></a>    \foreach \j <span class="kw">in</span> {<span class="dv">1</span>,...,<span class="dv">5</span>}</span>
<span id="cb2-45"><a href="#cb2-45"></a>    {</span>
<span id="cb2-46"><a href="#cb2-46"></a>        \draw[<span class="op">-&gt;</span>, shorten <span class="op">&gt;=</span><span class="dv">1</span><span class="er">pt</span>] (Hidden1<span class="op">-</span>\i) <span class="op">--</span> (Hidden2<span class="op">-</span>\j)<span class="op">;</span>   </span>
<span id="cb2-47"><a href="#cb2-47"></a>    }</span>
<span id="cb2-48"><a href="#cb2-48"></a>}</span>
<span id="cb2-49"><a href="#cb2-49"></a>\foreach \i <span class="kw">in</span> {<span class="dv">1</span>,...,<span class="dv">5</span>}</span>
<span id="cb2-50"><a href="#cb2-50"></a>{</span>
<span id="cb2-51"><a href="#cb2-51"></a>    \foreach \j <span class="kw">in</span> {<span class="dv">1</span>,<span class="dv">2</span>}</span>
<span id="cb2-52"><a href="#cb2-52"></a>    {</span>
<span id="cb2-53"><a href="#cb2-53"></a>        \draw[<span class="op">-&gt;</span>, shorten <span class="op">&gt;=</span><span class="dv">1</span><span class="er">pt</span>] (Hidden2<span class="op">-</span>\i) <span class="op">--</span> (Output<span class="op">-</span>\j)<span class="op">;</span>   </span>
<span id="cb2-54"><a href="#cb2-54"></a>    }</span>
<span id="cb2-55"><a href="#cb2-55"></a>}</span>
<span id="cb2-56"><a href="#cb2-56"></a>\end{tikzpicture}</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-display" data-execution_count="2">
<div>
<figure class="figure">
<p><img src="index_files/figure-html/cell-3-output-1.svg" class="img-fluid figure-img"></p>
</figure>
</div>
</div>
</div>
<p>Dense layers, the most common layers, consist of interconnected neurons. In a dense layer, each neuron of a given layer is connected to every neuron of the next layer, which means its output value becomes an input for the next neurons. Each connection between neurons has a weight associated with it, which is a trainable factor of how much of this input to use. Once all of the <span class="math inline">\(\text{inputs} \cdot \text{ weights}\)</span> flow into our neuron, they are summed and a bias, another trainable parameter is added.</p>
<p>Say, we have an input <span class="math inline">\(x_1\)</span> and weight <span class="math inline">\(w_1\)</span>, then the output <span class="math inline">\(y_1 = w_1 x_1\)</span> is a straight-line with slope <span class="math inline">\(w_1\)</span>.</p>
<div class="cell" data-execution_count="3">
<details class="code-fold">
<summary>Show the code</summary>
<div class="sourceCode cell-code" id="cb3"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb3-1"><a href="#cb3-1"></a><span class="op">%%</span>itikz <span class="op">--</span>temp<span class="op">-</span><span class="bu">dir</span> <span class="op">--</span>tex<span class="op">-</span>packages<span class="op">=</span>tikz,pgfplots <span class="op">--</span>tikz<span class="op">-</span>libraries<span class="op">=</span>arrows <span class="op">--</span>implicit<span class="op">-</span>standalone</span>
<span id="cb3-2"><a href="#cb3-2"></a>\begin{tikzpicture}[scale<span class="op">=</span><span class="fl">1.5</span>]</span>
<span id="cb3-3"><a href="#cb3-3"></a>\begin{axis}</span>
<span id="cb3-4"><a href="#cb3-4"></a>\addplot[color<span class="op">=</span>blue]{x}<span class="op">;</span></span>
<span id="cb3-5"><a href="#cb3-5"></a>\addlegendentry{\(f(x)<span class="op">=</span>x\)}</span>
<span id="cb3-6"><a href="#cb3-6"></a>\addplot[color<span class="op">=</span>red]{<span class="dv">2</span><span class="op">*</span>x}<span class="op">;</span></span>
<span id="cb3-7"><a href="#cb3-7"></a>\addlegendentry{\(f(x)<span class="op">=</span><span class="dv">2</span><span class="er">x</span>\)}</span>
<span id="cb3-8"><a href="#cb3-8"></a>\end{axis}</span>
<span id="cb3-9"><a href="#cb3-9"></a>\end{tikzpicture}</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-display" data-execution_count="3">
<div>
<figure class="figure">
<p><img src="index_files/figure-html/cell-4-output-1.svg" class="img-fluid figure-img"></p>
</figure>
</div>
</div>
</div>
<p>The bias offsets the overall function.</p>
<div class="cell" data-execution_count="4">
<details class="code-fold">
<summary>Show the code</summary>
<div class="sourceCode cell-code" id="cb4"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb4-1"><a href="#cb4-1"></a><span class="op">%%</span>itikz <span class="op">--</span>temp<span class="op">-</span><span class="bu">dir</span> <span class="op">--</span>tex<span class="op">-</span>packages<span class="op">=</span>tikz,pgfplots <span class="op">--</span>tikz<span class="op">-</span>libraries<span class="op">=</span>arrows <span class="op">--</span>implicit<span class="op">-</span>standalone</span>
<span id="cb4-2"><a href="#cb4-2"></a>\begin{tikzpicture}[scale<span class="op">=</span><span class="fl">1.5</span>]</span>
<span id="cb4-3"><a href="#cb4-3"></a>\begin{axis}</span>
<span id="cb4-4"><a href="#cb4-4"></a>\addplot[color<span class="op">=</span>black]{x<span class="op">+</span><span class="dv">1</span>}<span class="op">;</span></span>
<span id="cb4-5"><a href="#cb4-5"></a>\addlegendentry{\(f(x)<span class="op">=</span>x<span class="op">+</span><span class="dv">1</span>\)}</span>
<span id="cb4-6"><a href="#cb4-6"></a>\addplot[color<span class="op">=</span>gray]{x<span class="op">-</span><span class="dv">1</span>}<span class="op">;</span></span>
<span id="cb4-7"><a href="#cb4-7"></a>\addlegendentry{\(f(x)<span class="op">=</span>x<span class="op">-</span><span class="dv">1</span>\)}</span>
<span id="cb4-8"><a href="#cb4-8"></a>\end{axis}</span>
<span id="cb4-9"><a href="#cb4-9"></a>\end{tikzpicture}</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-display" data-execution_count="4">
<div>
<figure class="figure">
<p><img src="index_files/figure-html/cell-5-output-1.svg" class="img-fluid figure-img"></p>
</figure>
</div>
</div>
</div>
<section id="activation-functions" class="level3">
<h3 class="anchored" data-anchor-id="activation-functions">Activation functions</h3>
<p>Let us now look at some examples of activation functions.</p>
<p>The heaviside function is defined as:</p>
<p><span class="math display">\[\begin{align*}
\rho(x) &amp;=
\begin{cases}
1, &amp; x &gt; 0 \\
0, &amp; x \leq 0
\end{cases}
\end{align*}\]</span></p>
<p>The sigmoid function is defined as:</p>
<p><span class="math display">\[\begin{align*}
\rho(x) &amp;= \frac{1}{1+e^{-x}}
\end{align*}\]</span></p>
<div class="cell" data-execution_count="5">
<details class="code-fold">
<summary>Show the code</summary>
<div class="sourceCode cell-code" id="cb5"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb5-1"><a href="#cb5-1"></a><span class="op">%%</span>itikz <span class="op">--</span>temp<span class="op">-</span><span class="bu">dir</span> <span class="op">--</span>tex<span class="op">-</span>packages<span class="op">=</span>tikz,pgfplots <span class="op">--</span>tikz<span class="op">-</span>libraries<span class="op">=</span>arrows <span class="op">--</span>implicit<span class="op">-</span>standalone</span>
<span id="cb5-2"><a href="#cb5-2"></a>\begin{tikzpicture}[scale<span class="op">=</span><span class="fl">1.5</span>]</span>
<span id="cb5-3"><a href="#cb5-3"></a>\begin{axis}</span>
<span id="cb5-4"><a href="#cb5-4"></a>\addplot[color<span class="op">=</span>black]{<span class="dv">1</span><span class="op">/</span>(<span class="dv">1</span><span class="op">+</span>exp(<span class="op">-</span>x))}<span class="op">;</span></span>
<span id="cb5-5"><a href="#cb5-5"></a>\end{axis}</span>
<span id="cb5-6"><a href="#cb5-6"></a>\end{tikzpicture}</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-display" data-execution_count="5">
<div>
<figure class="figure">
<p><img src="index_files/figure-html/cell-6-output-1.svg" class="img-fluid figure-img"></p>
</figure>
</div>
</div>
</div>
<p>The Rectifiable Linear Unit (ReLU) function is defined as:</p>
<p><span class="math display">\[\begin{align*}
\rho(x) &amp;= \max(0,x)
\end{align*}\]</span></p>
<div class="cell" data-execution_count="6">
<details class="code-fold">
<summary>Show the code</summary>
<div class="sourceCode cell-code" id="cb6"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb6-1"><a href="#cb6-1"></a><span class="op">%%</span>itikz <span class="op">--</span>temp<span class="op">-</span><span class="bu">dir</span> <span class="op">--</span>tex<span class="op">-</span>packages<span class="op">=</span>tikz,pgfplots <span class="op">--</span>tikz<span class="op">-</span>libraries<span class="op">=</span>arrows <span class="op">--</span>implicit<span class="op">-</span>standalone</span>
<span id="cb6-2"><a href="#cb6-2"></a>\begin{tikzpicture}[scale<span class="op">=</span><span class="fl">1.5</span>]</span>
<span id="cb6-3"><a href="#cb6-3"></a>\begin{axis}</span>
<span id="cb6-4"><a href="#cb6-4"></a>\addplot[color<span class="op">=</span>black]{<span class="bu">max</span>(<span class="dv">0</span>,x)}<span class="op">;</span></span>
<span id="cb6-5"><a href="#cb6-5"></a>\end{axis}</span>
<span id="cb6-6"><a href="#cb6-6"></a>\end{tikzpicture}</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-display" data-execution_count="6">
<div>
<figure class="figure">
<p><img src="index_files/figure-html/cell-7-output-1.svg" class="img-fluid figure-img"></p>
</figure>
</div>
</div>
</div>
</section>
</section>
<section id="coding-a-layer-with-3-neurons" class="level2">
<h2 class="anchored" data-anchor-id="coding-a-layer-with-3-neurons">Coding a layer with 3-neurons</h2>
<p>Let’s code a simple layer with <span class="math inline">\(n=3\)</span> neurons.</p>
<div class="cell" data-execution_count="7">
<div class="sourceCode cell-code" id="cb7"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb7-1"><a href="#cb7-1"></a>inputs <span class="op">=</span> [<span class="dv">1</span>, <span class="dv">2</span>, <span class="dv">3</span>, <span class="fl">2.5</span>]</span>
<span id="cb7-2"><a href="#cb7-2"></a>weights <span class="op">=</span> [[<span class="fl">0.2</span>, <span class="fl">0.8</span>, <span class="op">-</span><span class="fl">0.5</span>, <span class="fl">1.0</span>], [<span class="fl">0.5</span>, <span class="op">-</span><span class="fl">0.91</span>, <span class="fl">0.26</span>, <span class="op">-</span><span class="fl">0.5</span>], [<span class="op">-</span><span class="fl">0.26</span>, <span class="op">-</span><span class="fl">0.27</span>, <span class="fl">0.17</span>, <span class="fl">0.87</span>]]</span>
<span id="cb7-3"><a href="#cb7-3"></a></span>
<span id="cb7-4"><a href="#cb7-4"></a>biases <span class="op">=</span> [<span class="dv">2</span>, <span class="dv">3</span>, <span class="fl">0.5</span>]</span>
<span id="cb7-5"><a href="#cb7-5"></a></span>
<span id="cb7-6"><a href="#cb7-6"></a><span class="co"># Output of the current layer</span></span>
<span id="cb7-7"><a href="#cb7-7"></a>layer_outputs <span class="op">=</span> []</span>
<span id="cb7-8"><a href="#cb7-8"></a></span>
<span id="cb7-9"><a href="#cb7-9"></a><span class="co"># For each neuron</span></span>
<span id="cb7-10"><a href="#cb7-10"></a><span class="cf">for</span> neuron_weights, neuron_bias <span class="kw">in</span> <span class="bu">zip</span>(weights, biases):</span>
<span id="cb7-11"><a href="#cb7-11"></a>    <span class="co"># zeroed output of the neuron</span></span>
<span id="cb7-12"><a href="#cb7-12"></a>    neuron_output <span class="op">=</span> <span class="fl">0.0</span></span>
<span id="cb7-13"><a href="#cb7-13"></a>    <span class="co"># for each input and weight to the neuron</span></span>
<span id="cb7-14"><a href="#cb7-14"></a>    <span class="cf">for</span> <span class="bu">input</span>, weight <span class="kw">in</span> <span class="bu">zip</span>(inputs, neuron_weights):</span>
<span id="cb7-15"><a href="#cb7-15"></a>        <span class="co"># multiply this input with the associated weight</span></span>
<span id="cb7-16"><a href="#cb7-16"></a>        <span class="co"># and add to the neuron's output variable</span></span>
<span id="cb7-17"><a href="#cb7-17"></a>        neuron_output <span class="op">+=</span> <span class="bu">input</span> <span class="op">*</span> weight</span>
<span id="cb7-18"><a href="#cb7-18"></a>    <span class="co"># Add bias</span></span>
<span id="cb7-19"><a href="#cb7-19"></a>    neuron_output <span class="op">+=</span> neuron_bias</span>
<span id="cb7-20"><a href="#cb7-20"></a>    <span class="co"># Put the neuron's result to the layer's output list</span></span>
<span id="cb7-21"><a href="#cb7-21"></a>    layer_outputs.append(neuron_output)</span>
<span id="cb7-22"><a href="#cb7-22"></a></span>
<span id="cb7-23"><a href="#cb7-23"></a><span class="bu">print</span>(layer_outputs)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>[4.8, 1.21, 2.385]</code></pre>
</div>
</div>
<p>We can achieve the same results as in our pure Python implementation of multiplying each component in our input vector <span class="math inline">\(\mathbf{x}\)</span> and weights vector <span class="math inline">\(\mathbf{w}\)</span> element-wise, by taking an inner product <span class="math inline">\(\mathbf{w} \cdot \mathbf{x}\)</span>.</p>
<div class="cell" data-execution_count="8">
<div class="sourceCode cell-code" id="cb9"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb9-1"><a href="#cb9-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb9-2"><a href="#cb9-2"></a></span>
<span id="cb9-3"><a href="#cb9-3"></a>inputs <span class="op">=</span> [<span class="dv">1</span>, <span class="dv">2</span>, <span class="dv">3</span>, <span class="fl">2.5</span>]</span>
<span id="cb9-4"><a href="#cb9-4"></a>weights <span class="op">=</span> [</span>
<span id="cb9-5"><a href="#cb9-5"></a>    [<span class="fl">0.2</span>, <span class="fl">0.8</span>, <span class="op">-</span><span class="fl">0.5</span>, <span class="fl">1.0</span>], </span>
<span id="cb9-6"><a href="#cb9-6"></a>    [<span class="fl">0.5</span>, <span class="op">-</span><span class="fl">0.91</span>, <span class="fl">0.26</span>, <span class="op">-</span><span class="fl">0.5</span>], </span>
<span id="cb9-7"><a href="#cb9-7"></a>    [<span class="op">-</span><span class="fl">0.26</span>, <span class="op">-</span><span class="fl">0.27</span>, <span class="fl">0.17</span>, <span class="fl">0.87</span>]</span>
<span id="cb9-8"><a href="#cb9-8"></a>]</span>
<span id="cb9-9"><a href="#cb9-9"></a></span>
<span id="cb9-10"><a href="#cb9-10"></a>biases <span class="op">=</span> [<span class="dv">2</span>, <span class="dv">3</span>, <span class="fl">0.5</span>]</span>
<span id="cb9-11"><a href="#cb9-11"></a></span>
<span id="cb9-12"><a href="#cb9-12"></a><span class="co"># Output of the current layer</span></span>
<span id="cb9-13"><a href="#cb9-13"></a>layer_outputs <span class="op">=</span> np.dot(weights, inputs) <span class="op">+</span> biases</span>
<span id="cb9-14"><a href="#cb9-14"></a></span>
<span id="cb9-15"><a href="#cb9-15"></a><span class="bu">print</span>(layer_outputs)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>[4.8   1.21  2.385]</code></pre>
</div>
</div>
<p>To train, neural networks tend to receive data in <em>batches</em>. So far, the example input data has only one sample (or observation) of various features called a feature set instance:</p>
<div class="sourceCode" id="cb11"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb11-1"><a href="#cb11-1"></a>sample <span class="op">=</span> [<span class="dv">1</span>, <span class="dv">2</span>, <span class="dv">3</span>, <span class="fl">2.5</span>]</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p>Often, neural networks expect to take in many <em>samples</em> at a time. One reason is its faster to train in batches in parallel processing. Also, if you fit on one sample at a time, you’re highly likely to keep fitting to that individual sample, rather than slowly producing general tweaks to the weights and biases that fit the entire dataset. Fitting or training in batches gives you a higher chance of making more meaningful changes to weights and biases.</p>
</section>
<section id="a-layer-of-neurons-and-a-batch-of-data" class="level2">
<h2 class="anchored" data-anchor-id="a-layer-of-neurons-and-a-batch-of-data">A layer of neurons and a batch of data</h2>
<p>Currently, the weights matrix looks as follows:</p>
<p><span class="math display">\[\begin{align*}
W = \begin{bmatrix}
0.2 &amp; 0.8 &amp; -0.5 &amp; 1.0 \\
0.5 &amp; -0.91 &amp; 0.26 &amp; -0.5 \\
-0.26 &amp; -0.27 &amp; 0.17 &amp; 0.87
\end{bmatrix}
\end{align*}\]</span></p>
<p>And say, that we have a batch of inputs:</p>
<p><span class="math display">\[\begin{align*}
X = \begin{bmatrix}
1.0 &amp; 2.0 &amp; 3.0 &amp; 3.5 \\
2.0 &amp; 5.0 &amp; -1.0 &amp; 2.0\\
-1.5 &amp; 2.7 &amp; 3.3 &amp; -0.8
\end{bmatrix}
\end{align*}\]</span></p>
<p>We need to take the inner products <span class="math inline">\((1.0, 2.0, 3.0, 3.5) \cdot (0.2, 0.8, -0.5, 1.0)\)</span>, <span class="math inline">\((2.0, 5.0, -1.0, 2.0) \cdot (0.2, 0.8, -0.5, 1.0)\)</span> and <span class="math inline">\((-1.5, 2.7, 3.3, -0.8) \cdot (0.2, 0.8, -0.5, 1.0)\)</span> for the first neuron.</p>
<p>We need to take the inner products <span class="math inline">\((1.0, 2.0, 3.0, 3.5) \cdot (0.5, -0.91, 0.26, -0.5)\)</span>, <span class="math inline">\((2.0, 5.0, -1.0, 2.0) \cdot (0.5, -0.91, 0.26, -0.5)\)</span> and <span class="math inline">\((-1.5, 2.7, 3.3, -0.8) \cdot (0.5, -0.91, 0.26, -0.5)\)</span> for the second neuron.</p>
<p>And so forth.</p>
<p>Consider the matrix product <span class="math inline">\(XW^T\)</span>:</p>
<p><span class="math display">\[\begin{align*}
XW^T &amp;= \begin{bmatrix}
1.0 &amp; 2.0 &amp; 3.0 &amp; 2.5 \\
2.0 &amp; 5.0 &amp; -1.0 &amp; 2.0\\
-1.5 &amp; 2.7 &amp; 3.3 &amp; -0.8
\end{bmatrix}
\begin{bmatrix}
0.2 &amp; 0.5 &amp; -0.26 \\
0.8 &amp; -0.91 &amp; -0.27 \\
-0.5 &amp; 0.26 &amp; 0.17 \\
1.0 &amp; -0.5 &amp; 0.87
\end{bmatrix}\\
&amp;= \begin{bmatrix}
2.8 &amp; -1.79 &amp; 1.885 \\
6.9 &amp; -4.81 &amp; -0.3 \\
-0.59 &amp; -1.949 &amp; -0.474
\end{bmatrix}
\end{align*}\]</span></p>
<div class="cell" data-execution_count="9">
<div class="sourceCode cell-code" id="cb12"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb12-1"><a href="#cb12-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb12-2"><a href="#cb12-2"></a></span>
<span id="cb12-3"><a href="#cb12-3"></a>X <span class="op">=</span> [</span>
<span id="cb12-4"><a href="#cb12-4"></a>    [<span class="fl">1.0</span>, <span class="fl">2.0</span>, <span class="fl">3.0</span>, <span class="fl">2.5</span>],</span>
<span id="cb12-5"><a href="#cb12-5"></a>    [<span class="fl">2.0</span>, <span class="fl">5.0</span>, <span class="op">-</span><span class="fl">1.0</span>, <span class="fl">2.0</span>],</span>
<span id="cb12-6"><a href="#cb12-6"></a>    [<span class="op">-</span><span class="fl">1.5</span>, <span class="fl">2.7</span>, <span class="fl">3.3</span>, <span class="op">-</span><span class="fl">0.8</span>]</span>
<span id="cb12-7"><a href="#cb12-7"></a>]</span>
<span id="cb12-8"><a href="#cb12-8"></a></span>
<span id="cb12-9"><a href="#cb12-9"></a>W <span class="op">=</span> [</span>
<span id="cb12-10"><a href="#cb12-10"></a>    [<span class="fl">0.2</span>, <span class="fl">0.8</span>, <span class="op">-</span><span class="fl">0.5</span>, <span class="fl">1.0</span>],</span>
<span id="cb12-11"><a href="#cb12-11"></a>    [<span class="fl">0.5</span>, <span class="op">-</span><span class="fl">0.91</span>, <span class="fl">0.26</span>, <span class="op">-</span><span class="fl">0.5</span>],</span>
<span id="cb12-12"><a href="#cb12-12"></a>    [<span class="op">-</span><span class="fl">0.26</span>, <span class="op">-</span><span class="fl">0.27</span>, <span class="fl">0.17</span>, <span class="fl">0.87</span>]</span>
<span id="cb12-13"><a href="#cb12-13"></a>]</span>
<span id="cb12-14"><a href="#cb12-14"></a></span>
<span id="cb12-15"><a href="#cb12-15"></a>np.dot(X,np.array(W).T)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="9">
<pre><code>array([[ 2.8  , -1.79 ,  1.885],
       [ 6.9  , -4.81 , -0.3  ],
       [-0.59 , -1.949, -0.474]])</code></pre>
</div>
</div>
<p>So, we can process a batch of inputs as:</p>
<div class="cell" data-execution_count="10">
<div class="sourceCode cell-code" id="cb14"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb14-1"><a href="#cb14-1"></a>layer_outputs <span class="op">=</span> np.dot(X,np.array(W).T) <span class="op">+</span> biases</span>
<span id="cb14-2"><a href="#cb14-2"></a><span class="bu">print</span>(layer_outputs)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>[[ 4.8    1.21   2.385]
 [ 8.9   -1.81   0.2  ]
 [ 1.41   1.051  0.026]]</code></pre>
</div>
</div>
<p>The second argument for <code>np.dot()</code> is going to be our transposed weights. Before, we were computing the neuron output using a single sample of data, but now we’ve taken a step forward where we model the layer behavior on a batch of data.</p>
</section>
<section id="adding-layers" class="level2">
<h2 class="anchored" data-anchor-id="adding-layers">Adding Layers</h2>
<p>The neural network we have built is becoming more respectable, but at the moment, we have only one layer. Neural networks become deep when they have <span class="math inline">\(2\)</span> or more <em>hidden layers</em>. At the moment, we have just one layer, which is effectively an output layer. Why we want two or more hidden layers will become apparent later on. Currently, we have no hidden layers. A hidden layer isn’t an input or output layer; as the scientist, you see the data as they are handed to the input layer and the resulting data from the output layer. Layers between these endpoints have values that we don’t necessarily deal with, and hence the name “hidden”. Don’t let this name convince you that you can’t access these values, though. You will often use them to diagnose issues or improve your neural network. To explore this concept, let’s add another layer to this neural network, and for now, let’s assume that these two layers that we’re going to have will be hidden layers, and we just coded our output layer yet.</p>
<p>Before we add another layer, let’s think about what’s coming. In the case of the first layer, we can see that we have an input with <span class="math inline">\(4\)</span> features.</p>
<div class="cell" data-execution_count="11">
<details class="code-fold">
<summary>Show the code</summary>
<div class="sourceCode cell-code" id="cb16"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb16-1"><a href="#cb16-1"></a><span class="op">%%</span>itikz <span class="op">--</span>temp<span class="op">-</span><span class="bu">dir</span> <span class="op">--</span>tex<span class="op">-</span>packages<span class="op">=</span>tikz <span class="op">--</span>tikz<span class="op">-</span>libraries<span class="op">=</span>arrows <span class="op">--</span>implicit<span class="op">-</span>standalone</span>
<span id="cb16-2"><a href="#cb16-2"></a>\begin{tikzpicture}</span>
<span id="cb16-3"><a href="#cb16-3"></a>\foreach \i <span class="kw">in</span> {<span class="dv">1</span>,<span class="dv">2</span>,...,<span class="dv">4</span>}</span>
<span id="cb16-4"><a href="#cb16-4"></a>{</span>
<span id="cb16-5"><a href="#cb16-5"></a>    \node[circle, </span>
<span id="cb16-6"><a href="#cb16-6"></a>        minimum size <span class="op">=</span> <span class="dv">15</span><span class="er">mm</span>,</span>
<span id="cb16-7"><a href="#cb16-7"></a>        fill<span class="op">=</span>red<span class="op">!</span><span class="dv">30</span></span>
<span id="cb16-8"><a href="#cb16-8"></a>        ] (Input<span class="op">-</span>\i) at (<span class="dv">0</span>,<span class="op">-</span>\i <span class="op">*</span> <span class="dv">2</span>) {\large $x_\i$}<span class="op">;</span></span>
<span id="cb16-9"><a href="#cb16-9"></a>}</span>
<span id="cb16-10"><a href="#cb16-10"></a>\foreach \i <span class="kw">in</span> {<span class="dv">1</span>,<span class="dv">2</span>,...,<span class="dv">3</span>}</span>
<span id="cb16-11"><a href="#cb16-11"></a>{</span>
<span id="cb16-12"><a href="#cb16-12"></a>    \node[circle, </span>
<span id="cb16-13"><a href="#cb16-13"></a>        minimum size <span class="op">=</span> <span class="dv">15</span><span class="er">mm</span>,</span>
<span id="cb16-14"><a href="#cb16-14"></a>        fill<span class="op">=</span>blue<span class="op">!</span><span class="dv">50</span>,</span>
<span id="cb16-15"><a href="#cb16-15"></a>        yshift<span class="op">=-</span><span class="dv">10</span> mm</span>
<span id="cb16-16"><a href="#cb16-16"></a>        ] (Hidden1<span class="op">-</span>\i) at (<span class="fl">3.0</span>,<span class="op">-</span>\i <span class="op">*</span> <span class="dv">2</span>) {\large $h_\i<span class="op">^</span>{(<span class="dv">1</span>)}$}<span class="op">;</span></span>
<span id="cb16-17"><a href="#cb16-17"></a>        </span>
<span id="cb16-18"><a href="#cb16-18"></a>}</span>
<span id="cb16-19"><a href="#cb16-19"></a></span>
<span id="cb16-20"><a href="#cb16-20"></a><span class="op">%</span> Connect neurons In<span class="op">-</span>Hidden1</span>
<span id="cb16-21"><a href="#cb16-21"></a>\foreach \i <span class="kw">in</span> {<span class="dv">1</span>,...,<span class="dv">4</span>}</span>
<span id="cb16-22"><a href="#cb16-22"></a>{</span>
<span id="cb16-23"><a href="#cb16-23"></a>    \foreach \j <span class="kw">in</span> {<span class="dv">1</span>,...,<span class="dv">3</span>}</span>
<span id="cb16-24"><a href="#cb16-24"></a>    {</span>
<span id="cb16-25"><a href="#cb16-25"></a>        \draw[<span class="op">-&gt;</span>, shorten <span class="op">&gt;=</span><span class="dv">1</span><span class="er">pt</span>] (Input<span class="op">-</span>\i) <span class="op">--</span> (Hidden1<span class="op">-</span>\j)<span class="op">;</span>   </span>
<span id="cb16-26"><a href="#cb16-26"></a>    }</span>
<span id="cb16-27"><a href="#cb16-27"></a>}</span>
<span id="cb16-28"><a href="#cb16-28"></a>\end{tikzpicture}</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-display" data-execution_count="11">
<div>
<figure class="figure">
<p><img src="index_files/figure-html/cell-12-output-1.svg" class="img-fluid figure-img"></p>
</figure>
</div>
</div>
</div>
<p>Samples(feature set data) get fed through the input, which does not change it in any way, to our first hidden layer, which we can see has <span class="math inline">\(3\)</span> sets of weights with <span class="math inline">\(4\)</span> values each.</p>
<p>Each of those <span class="math inline">\(3\)</span> unique weight sets is associated with its distinct neuron. Thus, since we have <span class="math inline">\(3\)</span> weight sets, we have <span class="math inline">\(3\)</span> neurons in the first hidden layer. Each neuron has a unique set of weights, of which we have <span class="math inline">\(4\)</span> (as there are <span class="math inline">\(4\)</span> inputs to this layer), which is why our initial weights have a shape of <span class="math inline">\((3,4)\)</span>.</p>
<p>Now we wish to add another layer. To do that, we must make sure that the expected input to that layer matches the previous layer’s output. We have set the number of neurons in a layer by setting how many weights and biases we have. The previous layer’s influence on weight sets for the current layer is that each weight set needs to have a separate weight per input. This means a distinct weight per neuron from the previous layer (or feature if we’re talking the input). The previous layer has <span class="math inline">\(3\)</span> weight sets and <span class="math inline">\(3\)</span> biases, so we know it has <span class="math inline">\(3\)</span> neurons. This then means, for the next layer, we can have as many weight sets as we want (because this is how many neurons this new layer will have), but each of those weight sets must have <span class="math inline">\(3\)</span> discrete weights.</p>
<p>To create this new layer, we are going to copy and paste our <code>weights</code> and <code>biases</code> to <code>weights2</code> and <code>biases2</code>, and change their values to new made up sets. Here’s an example:</p>
<div class="cell" data-execution_count="12">
<div class="sourceCode cell-code" id="cb17"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb17-1"><a href="#cb17-1"></a>inputs <span class="op">=</span> [</span>
<span id="cb17-2"><a href="#cb17-2"></a>    [<span class="dv">1</span>, <span class="dv">2</span>, <span class="dv">3</span>, <span class="fl">2.5</span>],</span>
<span id="cb17-3"><a href="#cb17-3"></a>    [<span class="fl">2.0</span>, <span class="fl">5.0</span>, <span class="op">-</span><span class="fl">1.0</span>, <span class="dv">2</span>],</span>
<span id="cb17-4"><a href="#cb17-4"></a>    [<span class="op">-</span><span class="fl">1.5</span>, <span class="fl">2.7</span>, <span class="fl">3.3</span>, <span class="op">-</span><span class="fl">0.8</span>]</span>
<span id="cb17-5"><a href="#cb17-5"></a>]</span>
<span id="cb17-6"><a href="#cb17-6"></a></span>
<span id="cb17-7"><a href="#cb17-7"></a>weights <span class="op">=</span> [</span>
<span id="cb17-8"><a href="#cb17-8"></a>    [<span class="fl">0.2</span>, <span class="fl">0.8</span>, <span class="op">-</span><span class="fl">0.5</span>, <span class="dv">1</span>],</span>
<span id="cb17-9"><a href="#cb17-9"></a>    [<span class="fl">0.5</span>, <span class="op">-</span><span class="fl">0.91</span>, <span class="fl">0.26</span>, <span class="op">-</span><span class="fl">0.5</span>],</span>
<span id="cb17-10"><a href="#cb17-10"></a>    [<span class="op">-</span><span class="fl">0.26</span>, <span class="op">-</span><span class="fl">0.27</span>, <span class="fl">0.17</span>, <span class="fl">0.87</span>]</span>
<span id="cb17-11"><a href="#cb17-11"></a>]</span>
<span id="cb17-12"><a href="#cb17-12"></a></span>
<span id="cb17-13"><a href="#cb17-13"></a>biases <span class="op">=</span> [<span class="dv">2</span>, <span class="dv">3</span>, <span class="fl">0.5</span>]</span>
<span id="cb17-14"><a href="#cb17-14"></a></span>
<span id="cb17-15"><a href="#cb17-15"></a>weights2 <span class="op">=</span> [</span>
<span id="cb17-16"><a href="#cb17-16"></a>    [<span class="fl">0.1</span>, <span class="op">-</span><span class="fl">0.14</span>, <span class="fl">0.5</span>],</span>
<span id="cb17-17"><a href="#cb17-17"></a>    [<span class="op">-</span><span class="fl">0.5</span>, <span class="fl">0.12</span>, <span class="op">-</span><span class="fl">0.33</span>],</span>
<span id="cb17-18"><a href="#cb17-18"></a>    [<span class="op">-</span><span class="fl">0.44</span>, <span class="fl">0.73</span>, <span class="op">-</span><span class="fl">0.13</span>]</span>
<span id="cb17-19"><a href="#cb17-19"></a>]</span>
<span id="cb17-20"><a href="#cb17-20"></a></span>
<span id="cb17-21"><a href="#cb17-21"></a>biases2 <span class="op">=</span> [<span class="op">-</span><span class="dv">1</span>, <span class="dv">2</span>, <span class="op">-</span><span class="fl">0.5</span>]</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>Next, we will now call the outputs <code>layer1_outputs</code>.</p>
<div class="cell" data-execution_count="13">
<div class="sourceCode cell-code" id="cb18"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb18-1"><a href="#cb18-1"></a>layer1_outputs <span class="op">=</span> np.dot(inputs, np.array(weights).T) <span class="op">+</span> biases</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>As previously stated, inputs to the layers are either inputs from the actual dataset you’re training with, or outputs from a previous layer. That’s why we defined <span class="math inline">\(2\)</span> versions of <code>weights</code> and <code>biases</code>, but only one of <code>inputs</code>.</p>
<div class="cell" data-execution_count="14">
<div class="sourceCode cell-code" id="cb19"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb19-1"><a href="#cb19-1"></a>layer2_outputs <span class="op">=</span> np.dot(layer1_outputs, np.array(weights2).T) <span class="op">+</span> biases2</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>At this point, our neural network could be visually represented as:</p>
<div class="cell" data-execution_count="15">
<details class="code-fold">
<summary>Show the code</summary>
<div class="sourceCode cell-code" id="cb20"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb20-1"><a href="#cb20-1"></a><span class="op">%%</span>itikz <span class="op">--</span>temp<span class="op">-</span><span class="bu">dir</span> <span class="op">--</span>tex<span class="op">-</span>packages<span class="op">=</span>tikz <span class="op">--</span>tikz<span class="op">-</span>libraries<span class="op">=</span>arrows <span class="op">--</span>implicit<span class="op">-</span>standalone</span>
<span id="cb20-2"><a href="#cb20-2"></a>\begin{tikzpicture}</span>
<span id="cb20-3"><a href="#cb20-3"></a>\foreach \i <span class="kw">in</span> {<span class="dv">1</span>,<span class="dv">2</span>,...,<span class="dv">4</span>}</span>
<span id="cb20-4"><a href="#cb20-4"></a>{</span>
<span id="cb20-5"><a href="#cb20-5"></a>    \node[circle, </span>
<span id="cb20-6"><a href="#cb20-6"></a>        minimum size <span class="op">=</span> <span class="dv">15</span><span class="er">mm</span>,</span>
<span id="cb20-7"><a href="#cb20-7"></a>        fill<span class="op">=</span>red<span class="op">!</span><span class="dv">30</span></span>
<span id="cb20-8"><a href="#cb20-8"></a>        ] (Input<span class="op">-</span>\i) at (<span class="dv">0</span>,<span class="op">-</span>\i <span class="op">*</span> <span class="dv">2</span>) {\large $x_\i$}<span class="op">;</span></span>
<span id="cb20-9"><a href="#cb20-9"></a>}</span>
<span id="cb20-10"><a href="#cb20-10"></a>\foreach \i <span class="kw">in</span> {<span class="dv">1</span>,<span class="dv">2</span>,...,<span class="dv">3</span>}</span>
<span id="cb20-11"><a href="#cb20-11"></a>{</span>
<span id="cb20-12"><a href="#cb20-12"></a>    \node[circle, </span>
<span id="cb20-13"><a href="#cb20-13"></a>        minimum size <span class="op">=</span> <span class="dv">15</span><span class="er">mm</span>,</span>
<span id="cb20-14"><a href="#cb20-14"></a>        fill<span class="op">=</span>blue<span class="op">!</span><span class="dv">50</span>,</span>
<span id="cb20-15"><a href="#cb20-15"></a>        yshift<span class="op">=-</span><span class="dv">10</span> mm</span>
<span id="cb20-16"><a href="#cb20-16"></a>        ] (Hidden1<span class="op">-</span>\i) at (<span class="fl">3.0</span>,<span class="op">-</span>\i <span class="op">*</span> <span class="dv">2</span>) {\large $h_\i<span class="op">^</span>{(<span class="dv">1</span>)}$}<span class="op">;</span></span>
<span id="cb20-17"><a href="#cb20-17"></a>        </span>
<span id="cb20-18"><a href="#cb20-18"></a>}</span>
<span id="cb20-19"><a href="#cb20-19"></a>\foreach \i <span class="kw">in</span> {<span class="dv">1</span>,<span class="dv">2</span>,...,<span class="dv">3</span>}</span>
<span id="cb20-20"><a href="#cb20-20"></a>{</span>
<span id="cb20-21"><a href="#cb20-21"></a>    \node[circle, </span>
<span id="cb20-22"><a href="#cb20-22"></a>        minimum size <span class="op">=</span> <span class="dv">15</span><span class="er">mm</span>,</span>
<span id="cb20-23"><a href="#cb20-23"></a>        fill<span class="op">=</span>blue<span class="op">!</span><span class="dv">50</span>,</span>
<span id="cb20-24"><a href="#cb20-24"></a>        yshift<span class="op">=-</span><span class="dv">10</span> mm</span>
<span id="cb20-25"><a href="#cb20-25"></a>        ] (Hidden2<span class="op">-</span>\i) at (<span class="fl">6.0</span>,<span class="op">-</span>\i <span class="op">*</span> <span class="dv">2</span>) {\large $h_\i<span class="op">^</span>{(<span class="dv">2</span>)}$}<span class="op">;</span></span>
<span id="cb20-26"><a href="#cb20-26"></a>        </span>
<span id="cb20-27"><a href="#cb20-27"></a>}</span>
<span id="cb20-28"><a href="#cb20-28"></a></span>
<span id="cb20-29"><a href="#cb20-29"></a><span class="op">%</span> Connect neurons In<span class="op">-</span>Hidden1</span>
<span id="cb20-30"><a href="#cb20-30"></a>\foreach \i <span class="kw">in</span> {<span class="dv">1</span>,...,<span class="dv">4</span>}</span>
<span id="cb20-31"><a href="#cb20-31"></a>{</span>
<span id="cb20-32"><a href="#cb20-32"></a>    \foreach \j <span class="kw">in</span> {<span class="dv">1</span>,...,<span class="dv">3</span>}</span>
<span id="cb20-33"><a href="#cb20-33"></a>    {</span>
<span id="cb20-34"><a href="#cb20-34"></a>        \draw[<span class="op">-&gt;</span>, shorten <span class="op">&gt;=</span><span class="dv">1</span><span class="er">pt</span>] (Input<span class="op">-</span>\i) <span class="op">--</span> (Hidden1<span class="op">-</span>\j)<span class="op">;</span>   </span>
<span id="cb20-35"><a href="#cb20-35"></a>    }</span>
<span id="cb20-36"><a href="#cb20-36"></a>}</span>
<span id="cb20-37"><a href="#cb20-37"></a><span class="op">%</span> Connect neurons Hidden1<span class="op">-</span>Hidden2</span>
<span id="cb20-38"><a href="#cb20-38"></a>\foreach \i <span class="kw">in</span> {<span class="dv">1</span>,...,<span class="dv">3</span>}</span>
<span id="cb20-39"><a href="#cb20-39"></a>{</span>
<span id="cb20-40"><a href="#cb20-40"></a>    \foreach \j <span class="kw">in</span> {<span class="dv">1</span>,...,<span class="dv">3</span>}</span>
<span id="cb20-41"><a href="#cb20-41"></a>    {</span>
<span id="cb20-42"><a href="#cb20-42"></a>        \draw[<span class="op">-&gt;</span>, shorten <span class="op">&gt;=</span><span class="dv">1</span><span class="er">pt</span>] (Hidden1<span class="op">-</span>\i) <span class="op">--</span> (Hidden2<span class="op">-</span>\j)<span class="op">;</span>   </span>
<span id="cb20-43"><a href="#cb20-43"></a>    }</span>
<span id="cb20-44"><a href="#cb20-44"></a>}</span>
<span id="cb20-45"><a href="#cb20-45"></a>\end{tikzpicture}</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-display" data-execution_count="15">
<div>
<figure class="figure">
<p><img src="index_files/figure-html/cell-16-output-1.svg" class="img-fluid figure-img"></p>
</figure>
</div>
</div>
</div>
</section>
<section id="training-data" class="level2">
<h2 class="anchored" data-anchor-id="training-data">Training Data</h2>
<p>Next, rather than hand-typing in random data, we’ll use a function that can create non-linear data. What do we mean by non-linear? Linear data can be fit or represented by a straight line. Non-linear data cannot be represented well by a straight line.</p>
<p>We shall use the python package <code>nnfs</code> to create data. You can install it with</p>
<pre><code>pip install nnfs</code></pre>
<p>You typically don’t generate training data from a package like <code>nnfs</code> for your neural networks. Generating a dataset this way is purely for convenience at this stage. I shall also use this package to ensure repeatability.</p>
<div class="cell" data-execution_count="16">
<div class="sourceCode cell-code" id="cb22"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb22-1"><a href="#cb22-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb22-2"><a href="#cb22-2"></a><span class="im">import</span> nnfs</span>
<span id="cb22-3"><a href="#cb22-3"></a></span>
<span id="cb22-4"><a href="#cb22-4"></a>nnfs.init()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>The <code>nnfs.init()</code> does three things: it sets the random seed to <span class="math inline">\(0\)</span> by default, creates a <code>float32</code> dtype default and overrides the original dot product from <code>numpy</code>. All of these are meant to ensure repeatable results for following along.</p>
<div class="cell" data-execution_count="17">
<div class="sourceCode cell-code" id="cb23"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb23-1"><a href="#cb23-1"></a><span class="im">from</span> nnfs.datasets <span class="im">import</span> spiral_data</span>
<span id="cb23-2"><a href="#cb23-2"></a><span class="im">import</span> matplotlib.pyplot <span class="im">as</span> plt</span>
<span id="cb23-3"><a href="#cb23-3"></a></span>
<span id="cb23-4"><a href="#cb23-4"></a>X, y <span class="op">=</span> spiral_data(samples<span class="op">=</span><span class="dv">100</span>, classes<span class="op">=</span><span class="dv">3</span>)</span>
<span id="cb23-5"><a href="#cb23-5"></a></span>
<span id="cb23-6"><a href="#cb23-6"></a>plt.scatter(X[:,<span class="dv">0</span>], X[:,<span class="dv">1</span>])</span>
<span id="cb23-7"><a href="#cb23-7"></a>plt.show()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="index_files/figure-html/cell-18-output-1.png" width="590" height="411" class="figure-img"></p>
</figure>
</div>
</div>
</div>
<p>The <code>spiral_data</code> function allows us to create a dataset with as many classes as we want. The function has parameters to choose the number of classes and the number of points/observations per class in the resulting non-linear dataset.</p>
<p>If you trace from the center, you can determine all <span class="math inline">\(3\)</span> classes separately, but this is a very challenging problem for a machine learning classifier to solve. Adding color to the chart makes this more clear:</p>
<div class="cell" data-execution_count="18">
<div class="sourceCode cell-code" id="cb24"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb24-1"><a href="#cb24-1"></a>plt.scatter(X[:,<span class="dv">0</span>],X[:,<span class="dv">1</span>],c<span class="op">=</span>y,cmap<span class="op">=</span><span class="st">'brg'</span>)</span>
<span id="cb24-2"><a href="#cb24-2"></a>plt.show()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="index_files/figure-html/cell-19-output-1.png" width="590" height="411" class="figure-img"></p>
</figure>
</div>
</div>
</div>
<p>Keep in mind that the neural network will not be aware of the color differences as the data have no class encodings. This is only made as an instruction for you. In the data above, each dot is an observation, that is, it’s coordinates are the samples that form the dataset. The classification for the dot has to do with which spiral it is a part of, depicted by red, blue or green color.</p>
</section>
<section id="dense-layer-class" class="level2">
<h2 class="anchored" data-anchor-id="dense-layer-class">Dense Layer Class</h2>
<p>Now that we no longer need to hand-type our data, we should create something similar for our various types of neural network layers. So far, we’ve only used what’s called a <strong>dense</strong> or <strong>fully-connected</strong> layer. These layers are commonly referred to as dense layers in papers, literature and code, but you will see them called fully-connected or fc for short in the code I write. Our dense layer class begins with two methods:</p>
<div class="cell" data-execution_count="19">
<div class="sourceCode cell-code" id="cb25"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb25-1"><a href="#cb25-1"></a><span class="kw">class</span> DenseLayer:</span>
<span id="cb25-2"><a href="#cb25-2"></a>    <span class="kw">def</span> <span class="fu">__init__</span>(<span class="va">self</span>, n_inputs, n_neurons):</span>
<span id="cb25-3"><a href="#cb25-3"></a>        <span class="co"># Initialize weights and biases</span></span>
<span id="cb25-4"><a href="#cb25-4"></a>        <span class="cf">pass</span> <span class="co"># using pass statement as a placeholder</span></span>
<span id="cb25-5"><a href="#cb25-5"></a></span>
<span id="cb25-6"><a href="#cb25-6"></a>    <span class="co"># Forward pass</span></span>
<span id="cb25-7"><a href="#cb25-7"></a>    <span class="kw">def</span> forward(<span class="va">self</span>, inputs):</span>
<span id="cb25-8"><a href="#cb25-8"></a>        <span class="co"># Calculate output values from inputs, weights and biases</span></span>
<span id="cb25-9"><a href="#cb25-9"></a>        <span class="cf">pass</span> <span class="co"># using pass statement as a placeholder</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>Weights are often initialized randomly for a model, but not always. If you wish to load a pre-trained model, you will initialize the parameters to whatever that pretrained model finished with. It’s also possible that, even for a new model, you have some other initialization rules besides random. From now, we’ll stick with random initialization. Next, we have the <code>forward</code> method. When we pass data through a model from beginning to end, this is called a <strong>forward</strong> pass. Just like everything else, this is not the only way to do things. You can have the data loop back around and do other interesting things. We’ll keep it usual and perform a regular forward pass.</p>
<p>To continue the <code>LayerDense</code> class code, let’s add the random initialization of weights and biases:</p>
<div class="sourceCode" id="cb26"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb26-1"><a href="#cb26-1"></a><span class="co">#Layer initialization</span></span>
<span id="cb26-2"><a href="#cb26-2"></a><span class="kw">def</span> <span class="fu">__init__</span>(<span class="va">self</span>,n_inputs, n_neurons):</span>
<span id="cb26-3"><a href="#cb26-3"></a>    <span class="va">self</span>.weights <span class="op">=</span> <span class="fl">0.01</span> <span class="op">*</span> np.random.randn(n_inputs,n_neurons)</span>
<span id="cb26-4"><a href="#cb26-4"></a>    <span class="va">self</span>.biases <span class="op">=</span> np.zeros((<span class="dv">1</span>,n_neurons))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p>Here, we are setting the weights to be random and the biases to be <span class="math inline">\(0\)</span>. Note that, we are initializing weights to be a matrix of dimensions <span class="math inline">\(n_{inputs} \times n_{neurons}\)</span>, rather than <span class="math inline">\(n_{neurons} \times n_{inputs}\)</span>. We’re doing this ahead instead of transposing everytime we perform a forward pass, as explained in the previous chapter.</p>
<p>We initialize the biases to zero, because with many samples containing values of <span class="math inline">\(0\)</span>, it will ensure that a neuron fires initially. The most common initialization for biases is zero. This will vary depending on our use-case and is just one of the many things we can tweak when trying to improve results. One situation where we might want to try something else is with what’s called <em>dead neurons</em>.</p>
<p>Imagine our step function again:</p>
<p><span class="math display">\[\begin{align*}
y = \begin{cases}
1, &amp; x &gt; 0\\
0, &amp; x \leq 0
\end{cases}
\end{align*}\]</span></p>
<p>It’s possible for <span class="math inline">\(\text{weights} \cdot \text{inputs} + \text{biases}\)</span> not to meet the threshold of the step function, which means the neuron will output a zero. On its own, this is not a big issue, but it becomes a problem if this happens to this neuron for every one of the input samples (it’ll become clear why once we learn about backpropogation). So, then this neuron’s <span class="math inline">\(0\)</span> output is the input to another neuron. Any weight multiplied by zero will be zero. With an increasing number of neurons outputting <span class="math inline">\(0\)</span>, more inputs to the next neurons will be zeros, rendering the network essentially non-trainable or <em>dead</em>.</p>
<p>On to our <code>forward</code> method now.</p>
<div class="cell" data-execution_count="20">
<div class="sourceCode cell-code" id="cb27"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb27-1"><a href="#cb27-1"></a><span class="kw">class</span> DenseLayer:</span>
<span id="cb27-2"><a href="#cb27-2"></a>    <span class="kw">def</span> <span class="fu">__init__</span>(<span class="va">self</span>, n_inputs, n_neurons):</span>
<span id="cb27-3"><a href="#cb27-3"></a>        <span class="va">self</span>.weights <span class="op">=</span> <span class="fl">0.01</span> <span class="op">*</span> np.random.randn(n_inputs,n_neurons)</span>
<span id="cb27-4"><a href="#cb27-4"></a>        <span class="va">self</span>.biases <span class="op">=</span> np.zeros((<span class="dv">1</span>,n_neurons))</span>
<span id="cb27-5"><a href="#cb27-5"></a></span>
<span id="cb27-6"><a href="#cb27-6"></a>    <span class="kw">def</span> forward(<span class="va">self</span>,inputs):</span>
<span id="cb27-7"><a href="#cb27-7"></a>        <span class="va">self</span>.output <span class="op">=</span> np.dot(inputs,<span class="va">self</span>.weights) <span class="op">+</span> <span class="va">self</span>.biases</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>We are now ready to make use of this new class instead of hardcoded calculations, so let’s generate some data using the discussed dataset creation method and use our new layer to perform a forward pass:</p>
<div class="cell" data-execution_count="21">
<div class="sourceCode cell-code" id="cb28"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb28-1"><a href="#cb28-1"></a><span class="co"># Create dataset</span></span>
<span id="cb28-2"><a href="#cb28-2"></a>X, y <span class="op">=</span> spiral_data(samples<span class="op">=</span><span class="dv">100</span>, classes<span class="op">=</span><span class="dv">3</span>)</span>
<span id="cb28-3"><a href="#cb28-3"></a></span>
<span id="cb28-4"><a href="#cb28-4"></a><span class="co"># Create a dense layer with 2 input features and 3 output values</span></span>
<span id="cb28-5"><a href="#cb28-5"></a>dense1 <span class="op">=</span> DenseLayer(<span class="dv">2</span>, <span class="dv">3</span>)</span>
<span id="cb28-6"><a href="#cb28-6"></a></span>
<span id="cb28-7"><a href="#cb28-7"></a><span class="co"># Perform a forward pass of our training data through this layer</span></span>
<span id="cb28-8"><a href="#cb28-8"></a>dense1.forward(X)</span>
<span id="cb28-9"><a href="#cb28-9"></a></span>
<span id="cb28-10"><a href="#cb28-10"></a><span class="co"># Let's see the output of the first few samples</span></span>
<span id="cb28-11"><a href="#cb28-11"></a><span class="bu">print</span>(dense1.output[:<span class="dv">5</span>])</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>[[ 0.00000000e+00  0.00000000e+00  0.00000000e+00]
 [-1.11171044e-04 -5.11007493e-05 -1.12099799e-04]
 [ 2.99257295e-06 -2.69126613e-04 -1.45165104e-04]
 [ 8.95101766e-05 -4.30442247e-04 -1.68079801e-04]
 [-3.49893759e-04 -3.07208364e-04 -4.33002861e-04]]</code></pre>
</div>
</div>
</section>
<section id="activation-functions-1" class="level2">
<h2 class="anchored" data-anchor-id="activation-functions-1">Activation Functions</h2>
<p>We use activation functions because if the activation function itself is non-linear, it allows for neural networks with two or more layers to map non-linear functions. We’ll see how this works. In general, your neural network will have <span class="math inline">\(2\)</span> types of activation functions. The first will be the activation function used in hidden layers, and the second will be used in the output layer. Usually, the activation function used for hidden neurons will be all the same for all of them, but it doesn’t have to.</p>
<section id="why-use-activation-functions" class="level3">
<h3 class="anchored" data-anchor-id="why-use-activation-functions">Why use activation functions?</h3>
<p>Let’s discuss why we use activation functions in the first place? In most cases, for a neural network to fit a non-linear function, we need it to contain two or more hidden layers and we need those hidden layers to use a non-linear activation function.</p>
<p>While there are certainly problems in life that are linear in nature, for example, trying to figure out the cost of some number of shirts, and we know the cost of an individual shirt, then the equation to calculate the price of any number of those products is a linear equation; other problems in life are not so simple.</p>
<p>Many interesting and hard problems are non-linear. The main attraction of neural networks has to do with their ability to solve non-linear problems. If we allow only linear activation functions in a neural network, the output will just be a linear transformation of the input, which is not enough to form a universal function approximator.</p>
<p>For simplicity, suppose a neural network has <span class="math inline">\(2\)</span> hidden layers with <span class="math inline">\(1\)</span> neuron each.</p>
<div class="cell" data-execution_count="22">
<details class="code-fold">
<summary>Show the code</summary>
<div class="sourceCode cell-code" id="cb30"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb30-1"><a href="#cb30-1"></a><span class="op">%%</span>itikz <span class="op">--</span>temp<span class="op">-</span><span class="bu">dir</span> <span class="op">--</span>tex<span class="op">-</span>packages<span class="op">=</span>tikz <span class="op">--</span>tikz<span class="op">-</span>libraries<span class="op">=</span>arrows <span class="op">--</span>implicit<span class="op">-</span>standalone</span>
<span id="cb30-2"><a href="#cb30-2"></a>\begin{tikzpicture}[scale<span class="op">=</span><span class="fl">1.5</span>]</span>
<span id="cb30-3"><a href="#cb30-3"></a>    \node[circle, </span>
<span id="cb30-4"><a href="#cb30-4"></a>        minimum size <span class="op">=</span> <span class="dv">15</span><span class="er">mm</span>,</span>
<span id="cb30-5"><a href="#cb30-5"></a>        fill<span class="op">=</span>red<span class="op">!</span><span class="dv">30</span></span>
<span id="cb30-6"><a href="#cb30-6"></a>        ] (Input) at (<span class="dv">0</span>,<span class="dv">0</span>) {\large $x_1$}<span class="op">;</span></span>
<span id="cb30-7"><a href="#cb30-7"></a></span>
<span id="cb30-8"><a href="#cb30-8"></a>    \node[circle, </span>
<span id="cb30-9"><a href="#cb30-9"></a>        minimum size <span class="op">=</span> <span class="dv">15</span><span class="er">mm</span>,</span>
<span id="cb30-10"><a href="#cb30-10"></a>        fill<span class="op">=</span>blue<span class="op">!</span><span class="dv">50</span></span>
<span id="cb30-11"><a href="#cb30-11"></a>        ] (Hidden1) at (<span class="fl">3.0</span>,<span class="dv">0</span>) {\large $h_1<span class="op">^</span>{(<span class="dv">1</span>)}$}<span class="op">;</span></span>
<span id="cb30-12"><a href="#cb30-12"></a>        </span>
<span id="cb30-13"><a href="#cb30-13"></a></span>
<span id="cb30-14"><a href="#cb30-14"></a>    \node[circle, </span>
<span id="cb30-15"><a href="#cb30-15"></a>        minimum size <span class="op">=</span> <span class="dv">15</span><span class="er">mm</span>,</span>
<span id="cb30-16"><a href="#cb30-16"></a>        fill<span class="op">=</span>blue<span class="op">!</span><span class="dv">50</span></span>
<span id="cb30-17"><a href="#cb30-17"></a>        ] (Hidden2) at (<span class="fl">6.0</span>,<span class="dv">0</span>) {\large $h_1<span class="op">^</span>{(<span class="dv">2</span>)}$}<span class="op">;</span></span>
<span id="cb30-18"><a href="#cb30-18"></a></span>
<span id="cb30-19"><a href="#cb30-19"></a>    \node[circle, </span>
<span id="cb30-20"><a href="#cb30-20"></a>        minimum size <span class="op">=</span> <span class="dv">15</span><span class="er">mm</span>,</span>
<span id="cb30-21"><a href="#cb30-21"></a>        fill<span class="op">=</span>red<span class="op">!</span><span class="dv">30</span></span>
<span id="cb30-22"><a href="#cb30-22"></a>        ] (Output) at (<span class="fl">9.0</span>,<span class="dv">0</span>) {\large $\hat{y}_1$}<span class="op">;</span>        </span>
<span id="cb30-23"><a href="#cb30-23"></a>        </span>
<span id="cb30-24"><a href="#cb30-24"></a></span>
<span id="cb30-25"><a href="#cb30-25"></a>    \draw[<span class="op">-&gt;</span>, shorten <span class="op">&gt;=</span><span class="dv">1</span><span class="er">pt</span>] (Input) <span class="op">--</span> (Hidden1) node [midway,above] {\large $w_1$}<span class="op">;</span></span>
<span id="cb30-26"><a href="#cb30-26"></a>    \draw[<span class="op">-&gt;</span>, shorten <span class="op">&gt;=</span><span class="dv">1</span><span class="er">pt</span>] (Hidden1) <span class="op">--</span> (Hidden2) node [midway,above]  {\large $w_2$}<span class="op">;</span></span>
<span id="cb30-27"><a href="#cb30-27"></a>    \draw[<span class="op">-&gt;</span>, shorten <span class="op">&gt;=</span><span class="dv">1</span><span class="er">pt</span>] (Hidden2) <span class="op">--</span> (Output)<span class="op">;</span></span>
<span id="cb30-28"><a href="#cb30-28"></a>    \draw[<span class="op">-&gt;</span>, shorten <span class="op">&gt;=</span><span class="dv">1</span><span class="er">pt</span>] (<span class="fl">3.0</span>, <span class="op">-</span><span class="fl">2.0</span>) node [below] {\large $b_1$} <span class="op">--</span> (Hidden1)<span class="op">;</span></span>
<span id="cb30-29"><a href="#cb30-29"></a>    \draw[<span class="op">-&gt;</span>, shorten <span class="op">&gt;=</span><span class="dv">1</span><span class="er">pt</span>] (<span class="fl">6.0</span>, <span class="op">-</span><span class="fl">2.0</span>) node [below] {\large $b_2$} <span class="op">--</span> (Hidden2)<span class="op">;</span></span>
<span id="cb30-30"><a href="#cb30-30"></a>\end{tikzpicture}</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-display" data-execution_count="22">
<div>
<figure class="figure">
<p><img src="index_files/figure-html/cell-23-output-1.svg" class="img-fluid figure-img"></p>
</figure>
</div>
</div>
</div>
<p><span class="math display">\[\begin{align*}
\hat{y}_1 &amp;= h_1^{(2)} \\
&amp;= w_2 h_1^{(1)} + b_2 \\
&amp;= w_2 (w_1 x_1 + b_1) + b_2 \\
&amp;= w_2 w_1 x_1 + (w_2 b_1 + b_2)
\end{align*}\]</span></p>
<p>So, <span class="math inline">\(\hat{y}_1\)</span> is a linear function of the inputs, no matter, what values we choose for weights and biases.</p>
<p>The composition of linear functions is linear. No matter what we do, however many layers we have, or neurons we have in each layer, this network can only model linear functions.</p>
</section>
</section>
<section id="relu-activation-in-a-pair-of-neurons" class="level2">
<h2 class="anchored" data-anchor-id="relu-activation-in-a-pair-of-neurons">ReLU Activation in a pair of Neurons</h2>
<p>It is less obvious how, with a barely non-linear activation function, like the rectified linear activation function, we can suddenly model non-linear relationships and functions. Let’s start with a single neuron. We’ll begin with both a weight of zero and a bias of zero:</p>
<div class="cell" data-execution_count="23">
<details class="code-fold">
<summary>Show the code</summary>
<div class="sourceCode cell-code" id="cb31"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb31-1"><a href="#cb31-1"></a><span class="op">%%</span>itikz <span class="op">--</span>temp<span class="op">-</span><span class="bu">dir</span> <span class="op">--</span>tex<span class="op">-</span>packages<span class="op">=</span>tikz <span class="op">--</span>tikz<span class="op">-</span>libraries<span class="op">=</span>arrows <span class="op">--</span>implicit<span class="op">-</span>standalone</span>
<span id="cb31-2"><a href="#cb31-2"></a>\begin{tikzpicture}[scale<span class="op">=</span><span class="fl">1.5</span>]</span>
<span id="cb31-3"><a href="#cb31-3"></a>    \node[circle, </span>
<span id="cb31-4"><a href="#cb31-4"></a>        minimum size <span class="op">=</span> <span class="dv">15</span><span class="er">mm</span>,</span>
<span id="cb31-5"><a href="#cb31-5"></a>        draw<span class="op">=</span>blue</span>
<span id="cb31-6"><a href="#cb31-6"></a>        ] (Input) at (<span class="dv">0</span>,<span class="dv">0</span>) {}<span class="op">;</span></span>
<span id="cb31-7"><a href="#cb31-7"></a>    </span>
<span id="cb31-8"><a href="#cb31-8"></a>    \node[] (w) at (<span class="op">-</span><span class="dv">3</span>,<span class="dv">0</span>) {}<span class="op">;</span></span>
<span id="cb31-9"><a href="#cb31-9"></a>    \node[] (b) at (<span class="dv">0</span>,<span class="op">-</span><span class="dv">2</span>) {}<span class="op">;</span></span>
<span id="cb31-10"><a href="#cb31-10"></a></span>
<span id="cb31-11"><a href="#cb31-11"></a>    \draw[<span class="op">-&gt;</span>, shorten <span class="op">&gt;=</span><span class="dv">1</span><span class="er">pt</span>] (w) <span class="op">--</span> (Input) node [midway,above] {\large $<span class="fl">0.00</span>$}<span class="op">;</span></span>
<span id="cb31-12"><a href="#cb31-12"></a>    \draw[<span class="op">-&gt;</span>, shorten <span class="op">&gt;=</span><span class="dv">1</span><span class="er">pt</span>] (b) node [below] {\large $<span class="fl">0.00</span>$} <span class="op">--</span> (Input)<span class="op">;</span></span>
<span id="cb31-13"><a href="#cb31-13"></a>\end{tikzpicture}</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-display" data-execution_count="23">
<div>
<figure class="figure">
<p><img src="index_files/figure-html/cell-24-output-1.svg" class="img-fluid figure-img"></p>
</figure>
</div>
</div>
</div>
<p>In this case, no matter what input we pass, the output of this neuron will always be <span class="math inline">\(0\)</span>, because the weight is <span class="math inline">\(0\)</span> and the bias is <span class="math inline">\(0\)</span>.</p>
<div class="cell" data-execution_count="24">
<details class="code-fold">
<summary>Show the code</summary>
<div class="sourceCode cell-code" id="cb32"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb32-1"><a href="#cb32-1"></a><span class="op">%%</span>itikz <span class="op">--</span>temp<span class="op">-</span><span class="bu">dir</span> <span class="op">--</span>tex<span class="op">-</span>packages<span class="op">=</span>tikz,pgfplots <span class="op">--</span>tikz<span class="op">-</span>libraries<span class="op">=</span>arrows <span class="op">--</span>implicit<span class="op">-</span>standalone</span>
<span id="cb32-2"><a href="#cb32-2"></a>\begin{tikzpicture}[scale<span class="op">=</span><span class="fl">1.5</span>]</span>
<span id="cb32-3"><a href="#cb32-3"></a>\begin{axis}[grid]</span>
<span id="cb32-4"><a href="#cb32-4"></a>\addplot[color<span class="op">=</span>blue,thick]{<span class="dv">0</span>}<span class="op">;</span></span>
<span id="cb32-5"><a href="#cb32-5"></a>\end{axis}</span>
<span id="cb32-6"><a href="#cb32-6"></a>\end{tikzpicture}</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-display" data-execution_count="24">
<div>
<figure class="figure">
<p><img src="index_files/figure-html/cell-25-output-1.svg" class="img-fluid figure-img"></p>
</figure>
</div>
</div>
</div>
<p>Let’s set the weight to be <span class="math inline">\(1.00\)</span>.</p>
<div class="cell" data-execution_count="25">
<details class="code-fold">
<summary>Show the code</summary>
<div class="sourceCode cell-code" id="cb33"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb33-1"><a href="#cb33-1"></a><span class="op">%%</span>itikz <span class="op">--</span>temp<span class="op">-</span><span class="bu">dir</span> <span class="op">--</span>tex<span class="op">-</span>packages<span class="op">=</span>tikz <span class="op">--</span>tikz<span class="op">-</span>libraries<span class="op">=</span>arrows <span class="op">--</span>implicit<span class="op">-</span>standalone</span>
<span id="cb33-2"><a href="#cb33-2"></a>\begin{tikzpicture}[scale<span class="op">=</span><span class="fl">1.5</span>]</span>
<span id="cb33-3"><a href="#cb33-3"></a>    \node[circle, </span>
<span id="cb33-4"><a href="#cb33-4"></a>        minimum size <span class="op">=</span> <span class="dv">15</span><span class="er">mm</span>,</span>
<span id="cb33-5"><a href="#cb33-5"></a>        draw<span class="op">=</span>blue</span>
<span id="cb33-6"><a href="#cb33-6"></a>        ] (Input) at (<span class="dv">0</span>,<span class="dv">0</span>) {}<span class="op">;</span></span>
<span id="cb33-7"><a href="#cb33-7"></a>    </span>
<span id="cb33-8"><a href="#cb33-8"></a>    \node[] (w) at (<span class="op">-</span><span class="dv">3</span>,<span class="dv">0</span>) {}<span class="op">;</span></span>
<span id="cb33-9"><a href="#cb33-9"></a>    \node[] (b) at (<span class="dv">0</span>,<span class="op">-</span><span class="dv">2</span>) {}<span class="op">;</span></span>
<span id="cb33-10"><a href="#cb33-10"></a></span>
<span id="cb33-11"><a href="#cb33-11"></a>    \draw[<span class="op">-&gt;</span>, shorten <span class="op">&gt;=</span><span class="dv">1</span><span class="er">pt</span>] (w) <span class="op">--</span> (Input) node [midway,above] {\large $<span class="fl">1.00</span>$}<span class="op">;</span></span>
<span id="cb33-12"><a href="#cb33-12"></a>    \draw[<span class="op">-&gt;</span>, shorten <span class="op">&gt;=</span><span class="dv">1</span><span class="er">pt</span>] (b) node [below] {\large $<span class="fl">0.00</span>$} <span class="op">--</span> (Input)<span class="op">;</span></span>
<span id="cb33-13"><a href="#cb33-13"></a>\end{tikzpicture}</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-display" data-execution_count="25">
<div>
<figure class="figure">
<p><img src="index_files/figure-html/cell-26-output-1.svg" class="img-fluid figure-img"></p>
</figure>
</div>
</div>
</div>
<p>Now, it just looks like the basic rectified linear function. No surprises yet!</p>
<div class="cell" data-execution_count="26">
<details class="code-fold">
<summary>Show the code</summary>
<div class="sourceCode cell-code" id="cb34"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb34-1"><a href="#cb34-1"></a><span class="op">%%</span>itikz <span class="op">--</span>temp<span class="op">-</span><span class="bu">dir</span> <span class="op">--</span>tex<span class="op">-</span>packages<span class="op">=</span>tikz,pgfplots <span class="op">--</span>tikz<span class="op">-</span>libraries<span class="op">=</span>arrows <span class="op">--</span>implicit<span class="op">-</span>standalone</span>
<span id="cb34-2"><a href="#cb34-2"></a>\begin{tikzpicture}[scale<span class="op">=</span><span class="fl">1.5</span>]</span>
<span id="cb34-3"><a href="#cb34-3"></a>\begin{axis}[grid,ymin<span class="op">=-</span><span class="fl">2.0</span>,ymax<span class="op">=</span><span class="fl">2.0</span>,xmin<span class="op">=-</span><span class="fl">2.0</span>,xmax<span class="op">=</span><span class="fl">2.0</span>]</span>
<span id="cb34-4"><a href="#cb34-4"></a>\addplot[color<span class="op">=</span>blue,thick]{<span class="bu">max</span>(x,<span class="dv">0</span>)}<span class="op">;</span></span>
<span id="cb34-5"><a href="#cb34-5"></a>\end{axis}</span>
<span id="cb34-6"><a href="#cb34-6"></a>\end{tikzpicture}</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-display" data-execution_count="26">
<div>
<figure class="figure">
<p><img src="index_files/figure-html/cell-27-output-1.svg" class="img-fluid figure-img"></p>
</figure>
</div>
</div>
</div>
<p>Now, let’s set the bias to <span class="math inline">\(0.50\)</span>:</p>
<div class="cell" data-execution_count="27">
<details class="code-fold">
<summary>Show the code</summary>
<div class="sourceCode cell-code" id="cb35"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb35-1"><a href="#cb35-1"></a><span class="op">%%</span>itikz <span class="op">--</span>temp<span class="op">-</span><span class="bu">dir</span> <span class="op">--</span>tex<span class="op">-</span>packages<span class="op">=</span>tikz <span class="op">--</span>tikz<span class="op">-</span>libraries<span class="op">=</span>arrows <span class="op">--</span>implicit<span class="op">-</span>standalone</span>
<span id="cb35-2"><a href="#cb35-2"></a>\begin{tikzpicture}[scale<span class="op">=</span><span class="fl">1.5</span>]</span>
<span id="cb35-3"><a href="#cb35-3"></a>    \node[circle, </span>
<span id="cb35-4"><a href="#cb35-4"></a>        minimum size <span class="op">=</span> <span class="dv">15</span><span class="er">mm</span>,</span>
<span id="cb35-5"><a href="#cb35-5"></a>        draw<span class="op">=</span>blue</span>
<span id="cb35-6"><a href="#cb35-6"></a>        ] (Input) at (<span class="dv">0</span>,<span class="dv">0</span>) {}<span class="op">;</span></span>
<span id="cb35-7"><a href="#cb35-7"></a>    </span>
<span id="cb35-8"><a href="#cb35-8"></a>    \node[] (w) at (<span class="op">-</span><span class="dv">3</span>,<span class="dv">0</span>) {}<span class="op">;</span></span>
<span id="cb35-9"><a href="#cb35-9"></a>    \node[] (b) at (<span class="dv">0</span>,<span class="op">-</span><span class="dv">2</span>) {}<span class="op">;</span></span>
<span id="cb35-10"><a href="#cb35-10"></a></span>
<span id="cb35-11"><a href="#cb35-11"></a>    \draw[<span class="op">-&gt;</span>, shorten <span class="op">&gt;=</span><span class="dv">1</span><span class="er">pt</span>] (w) <span class="op">--</span> (Input) node [midway,above] {\large $<span class="fl">1.00</span>$}<span class="op">;</span></span>
<span id="cb35-12"><a href="#cb35-12"></a>    \draw[<span class="op">-&gt;</span>, shorten <span class="op">&gt;=</span><span class="dv">1</span><span class="er">pt</span>] (b) node [below] {\large $<span class="fl">0.50</span>$} <span class="op">--</span> (Input)<span class="op">;</span></span>
<span id="cb35-13"><a href="#cb35-13"></a>\end{tikzpicture}</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-display" data-execution_count="27">
<div>
<figure class="figure">
<p><img src="index_files/figure-html/cell-28-output-1.svg" class="img-fluid figure-img"></p>
</figure>
</div>
</div>
</div>
<p>We can see that in this case, with a single neuron, the bias offsets the overall function’s activation point horizontally.</p>
<div class="cell" data-execution_count="28">
<details class="code-fold">
<summary>Show the code</summary>
<div class="sourceCode cell-code" id="cb36"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb36-1"><a href="#cb36-1"></a><span class="op">%%</span>itikz <span class="op">--</span>temp<span class="op">-</span><span class="bu">dir</span> <span class="op">--</span>tex<span class="op">-</span>packages<span class="op">=</span>tikz,pgfplots <span class="op">--</span>tikz<span class="op">-</span>libraries<span class="op">=</span>arrows <span class="op">--</span>implicit<span class="op">-</span>standalone</span>
<span id="cb36-2"><a href="#cb36-2"></a>\begin{tikzpicture}[scale<span class="op">=</span><span class="fl">1.5</span>]</span>
<span id="cb36-3"><a href="#cb36-3"></a>\begin{axis}[grid,ymin<span class="op">=-</span><span class="fl">2.0</span>,ymax<span class="op">=</span><span class="fl">2.0</span>,xmin<span class="op">=-</span><span class="fl">2.0</span>,xmax<span class="op">=</span><span class="fl">2.0</span>]</span>
<span id="cb36-4"><a href="#cb36-4"></a>\addplot[color<span class="op">=</span>blue,thick,samples<span class="op">=</span><span class="dv">100</span>]{<span class="bu">max</span>(x<span class="op">+</span><span class="fl">0.50</span>,<span class="dv">0</span>)}<span class="op">;</span></span>
<span id="cb36-5"><a href="#cb36-5"></a>\end{axis}</span>
<span id="cb36-6"><a href="#cb36-6"></a>\end{tikzpicture}</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-display" data-execution_count="28">
<div>
<figure class="figure">
<p><img src="index_files/figure-html/cell-29-output-1.svg" class="img-fluid figure-img"></p>
</figure>
</div>
</div>
</div>
<p>By increasing bias, we’re making this neuron activate earlier. What happens when we negate the weight to <span class="math inline">\(-1.0\)</span>?</p>
<div class="cell" data-execution_count="29">
<details class="code-fold">
<summary>Show the code</summary>
<div class="sourceCode cell-code" id="cb37"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb37-1"><a href="#cb37-1"></a><span class="op">%%</span>itikz <span class="op">--</span>temp<span class="op">-</span><span class="bu">dir</span> <span class="op">--</span>tex<span class="op">-</span>packages<span class="op">=</span>tikz <span class="op">--</span>tikz<span class="op">-</span>libraries<span class="op">=</span>arrows <span class="op">--</span>implicit<span class="op">-</span>standalone</span>
<span id="cb37-2"><a href="#cb37-2"></a>\begin{tikzpicture}[scale<span class="op">=</span><span class="fl">1.5</span>]</span>
<span id="cb37-3"><a href="#cb37-3"></a>    \node[circle, </span>
<span id="cb37-4"><a href="#cb37-4"></a>        minimum size <span class="op">=</span> <span class="dv">15</span><span class="er">mm</span>,</span>
<span id="cb37-5"><a href="#cb37-5"></a>        draw<span class="op">=</span>blue</span>
<span id="cb37-6"><a href="#cb37-6"></a>        ] (Input) at (<span class="dv">0</span>,<span class="dv">0</span>) {}<span class="op">;</span></span>
<span id="cb37-7"><a href="#cb37-7"></a>    </span>
<span id="cb37-8"><a href="#cb37-8"></a>    \node[] (w) at (<span class="op">-</span><span class="dv">3</span>,<span class="dv">0</span>) {}<span class="op">;</span></span>
<span id="cb37-9"><a href="#cb37-9"></a>    \node[] (b) at (<span class="dv">0</span>,<span class="op">-</span><span class="dv">2</span>) {}<span class="op">;</span></span>
<span id="cb37-10"><a href="#cb37-10"></a></span>
<span id="cb37-11"><a href="#cb37-11"></a>    \draw[<span class="op">-&gt;</span>, shorten <span class="op">&gt;=</span><span class="dv">1</span><span class="er">pt</span>] (w) <span class="op">--</span> (Input) node [midway,above] {\large $<span class="op">-</span><span class="fl">1.00</span>$}<span class="op">;</span></span>
<span id="cb37-12"><a href="#cb37-12"></a>    \draw[<span class="op">-&gt;</span>, shorten <span class="op">&gt;=</span><span class="dv">1</span><span class="er">pt</span>] (b) node [below] {\large $<span class="fl">0.50</span>$} <span class="op">--</span> (Input)<span class="op">;</span></span>
<span id="cb37-13"><a href="#cb37-13"></a>\end{tikzpicture}</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-display" data-execution_count="29">
<div>
<figure class="figure">
<p><img src="index_files/figure-html/cell-30-output-1.svg" class="img-fluid figure-img"></p>
</figure>
</div>
</div>
</div>
<p>With a negative weight and this single neuron, the function has become a question of when this neuron <em>deactivates</em>.</p>
<div class="cell" data-execution_count="30">
<details class="code-fold">
<summary>Show the code</summary>
<div class="sourceCode cell-code" id="cb38"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb38-1"><a href="#cb38-1"></a><span class="op">%%</span>itikz <span class="op">--</span>temp<span class="op">-</span><span class="bu">dir</span> <span class="op">--</span>tex<span class="op">-</span>packages<span class="op">=</span>tikz,pgfplots <span class="op">--</span>tikz<span class="op">-</span>libraries<span class="op">=</span>arrows <span class="op">--</span>implicit<span class="op">-</span>standalone</span>
<span id="cb38-2"><a href="#cb38-2"></a>\begin{tikzpicture}[scale<span class="op">=</span><span class="fl">1.5</span>]</span>
<span id="cb38-3"><a href="#cb38-3"></a>\begin{axis}[grid,ymin<span class="op">=-</span><span class="fl">2.0</span>,ymax<span class="op">=</span><span class="fl">2.0</span>,xmin<span class="op">=-</span><span class="fl">2.0</span>,xmax<span class="op">=</span><span class="fl">2.0</span>]</span>
<span id="cb38-4"><a href="#cb38-4"></a>\addplot[color<span class="op">=</span>blue,thick,samples<span class="op">=</span><span class="dv">100</span>]{<span class="bu">max</span>(<span class="op">-</span>x<span class="op">+</span><span class="fl">0.50</span>,<span class="dv">0</span>)}<span class="op">;</span></span>
<span id="cb38-5"><a href="#cb38-5"></a>\end{axis}</span>
<span id="cb38-6"><a href="#cb38-6"></a>\end{tikzpicture}</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-display" data-execution_count="30">
<div>
<figure class="figure">
<p><img src="index_files/figure-html/cell-31-output-1.svg" class="img-fluid figure-img"></p>
</figure>
</div>
</div>
</div>
<p>What happens if modify the weight to <span class="math inline">\(-2.00\)</span>?</p>
<div class="cell" data-execution_count="31">
<details class="code-fold">
<summary>Show the code</summary>
<div class="sourceCode cell-code" id="cb39"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb39-1"><a href="#cb39-1"></a><span class="op">%%</span>itikz <span class="op">--</span>temp<span class="op">-</span><span class="bu">dir</span> <span class="op">--</span>tex<span class="op">-</span>packages<span class="op">=</span>tikz <span class="op">--</span>tikz<span class="op">-</span>libraries<span class="op">=</span>arrows <span class="op">--</span>implicit<span class="op">-</span>standalone</span>
<span id="cb39-2"><a href="#cb39-2"></a>\begin{tikzpicture}[scale<span class="op">=</span><span class="fl">1.5</span>]</span>
<span id="cb39-3"><a href="#cb39-3"></a>    \node[circle, </span>
<span id="cb39-4"><a href="#cb39-4"></a>        minimum size <span class="op">=</span> <span class="dv">15</span><span class="er">mm</span>,</span>
<span id="cb39-5"><a href="#cb39-5"></a>        draw<span class="op">=</span>blue</span>
<span id="cb39-6"><a href="#cb39-6"></a>        ] (Input) at (<span class="dv">0</span>,<span class="dv">0</span>) {}<span class="op">;</span></span>
<span id="cb39-7"><a href="#cb39-7"></a>    </span>
<span id="cb39-8"><a href="#cb39-8"></a>    \node[] (w) at (<span class="op">-</span><span class="dv">3</span>,<span class="dv">0</span>) {}<span class="op">;</span></span>
<span id="cb39-9"><a href="#cb39-9"></a>    \node[] (b) at (<span class="dv">0</span>,<span class="op">-</span><span class="dv">2</span>) {}<span class="op">;</span></span>
<span id="cb39-10"><a href="#cb39-10"></a></span>
<span id="cb39-11"><a href="#cb39-11"></a>    \draw[<span class="op">-&gt;</span>, shorten <span class="op">&gt;=</span><span class="dv">1</span><span class="er">pt</span>] (w) <span class="op">--</span> (Input) node [midway,above] {\large $<span class="op">-</span><span class="fl">2.00</span>$}<span class="op">;</span></span>
<span id="cb39-12"><a href="#cb39-12"></a>    \draw[<span class="op">-&gt;</span>, shorten <span class="op">&gt;=</span><span class="dv">1</span><span class="er">pt</span>] (b) node [below] {\large $<span class="fl">0.50</span>$} <span class="op">--</span> (Input)<span class="op">;</span></span>
<span id="cb39-13"><a href="#cb39-13"></a>\end{tikzpicture}</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-display" data-execution_count="31">
<div>
<figure class="figure">
<p><img src="index_files/figure-html/cell-32-output-1.svg" class="img-fluid figure-img"></p>
</figure>
</div>
</div>
</div>
<p>The neuron now deactivates at <span class="math inline">\(0.25\)</span>.</p>
<div class="cell" data-execution_count="32">
<details class="code-fold">
<summary>Show the code</summary>
<div class="sourceCode cell-code" id="cb40"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb40-1"><a href="#cb40-1"></a><span class="op">%%</span>itikz <span class="op">--</span>temp<span class="op">-</span><span class="bu">dir</span> <span class="op">--</span>tex<span class="op">-</span>packages<span class="op">=</span>tikz,pgfplots <span class="op">--</span>tikz<span class="op">-</span>libraries<span class="op">=</span>arrows <span class="op">--</span>implicit<span class="op">-</span>standalone</span>
<span id="cb40-2"><a href="#cb40-2"></a>\begin{tikzpicture}[scale<span class="op">=</span><span class="fl">1.5</span>]</span>
<span id="cb40-3"><a href="#cb40-3"></a>\begin{axis}[grid,ymin<span class="op">=-</span><span class="fl">2.0</span>,ymax<span class="op">=</span><span class="fl">2.0</span>,xmin<span class="op">=-</span><span class="fl">2.0</span>,xmax<span class="op">=</span><span class="fl">2.0</span>]</span>
<span id="cb40-4"><a href="#cb40-4"></a>\addplot[color<span class="op">=</span>blue,thick,samples<span class="op">=</span><span class="dv">100</span>]{<span class="bu">max</span>(<span class="op">-</span><span class="dv">2</span><span class="op">*</span>x<span class="op">+</span><span class="fl">0.50</span>,<span class="dv">0</span>)}<span class="op">;</span></span>
<span id="cb40-5"><a href="#cb40-5"></a>\end{axis}</span>
<span id="cb40-6"><a href="#cb40-6"></a>\end{tikzpicture}</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-display" data-execution_count="32">
<div>
<figure class="figure">
<p><img src="index_files/figure-html/cell-33-output-1.svg" class="img-fluid figure-img"></p>
</figure>
</div>
</div>
</div>
<p>Upto this point, we’ve seen how we can use the bias to offset the function horizontally, and the weight to influence the slope of the activation. Moreover, we’re also able to control whether the function is one for determining where the neuron activates or deactivates. What happens when we have, rather than just one neuron, a pair of neurons? For example, let’s pretend that we have two hidden layers of <span class="math inline">\(1\)</span> neuron each. Thinking back to the <span class="math inline">\(y=x\)</span> activation function, we unsurprisingly discovered that a linear activation function produced linear results no matter what chain of neurons we made. Let’s see what happens with the rectified linear function for the activation.</p>
<p>We’ll begin with the last values for the first neuron and a weight of <span class="math inline">\(1.00\)</span> and a bias of <span class="math inline">\(0.00\)</span> for the second neuron.</p>
<div class="cell" data-execution_count="33">
<details class="code-fold">
<summary>Show the code</summary>
<div class="sourceCode cell-code" id="cb41"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb41-1"><a href="#cb41-1"></a><span class="op">%%</span>itikz <span class="op">--</span>temp<span class="op">-</span><span class="bu">dir</span> <span class="op">--</span>tex<span class="op">-</span>packages<span class="op">=</span>tikz <span class="op">--</span>tikz<span class="op">-</span>libraries<span class="op">=</span>arrows <span class="op">--</span>implicit<span class="op">-</span>standalone</span>
<span id="cb41-2"><a href="#cb41-2"></a>\begin{tikzpicture}[scale<span class="op">=</span><span class="fl">1.5</span>]</span>
<span id="cb41-3"><a href="#cb41-3"></a>    \node[circle, </span>
<span id="cb41-4"><a href="#cb41-4"></a>        minimum size <span class="op">=</span> <span class="dv">15</span><span class="er">mm</span>,</span>
<span id="cb41-5"><a href="#cb41-5"></a>        draw<span class="op">=</span>blue</span>
<span id="cb41-6"><a href="#cb41-6"></a>        ] (Input) at (<span class="dv">0</span>,<span class="dv">0</span>) {}<span class="op">;</span></span>
<span id="cb41-7"><a href="#cb41-7"></a></span>
<span id="cb41-8"><a href="#cb41-8"></a>    \node[circle, </span>
<span id="cb41-9"><a href="#cb41-9"></a>        minimum size <span class="op">=</span> <span class="dv">15</span><span class="er">mm</span>,</span>
<span id="cb41-10"><a href="#cb41-10"></a>        draw<span class="op">=</span>blue</span>
<span id="cb41-11"><a href="#cb41-11"></a>        ] (Hidden1) at (<span class="dv">3</span>,<span class="dv">0</span>) {}<span class="op">;</span></span>
<span id="cb41-12"><a href="#cb41-12"></a>    </span>
<span id="cb41-13"><a href="#cb41-13"></a>    \node[] (w1) at (<span class="op">-</span><span class="dv">3</span>,<span class="dv">0</span>) {}<span class="op">;</span></span>
<span id="cb41-14"><a href="#cb41-14"></a>    \node[] (b1) at (<span class="dv">0</span>,<span class="op">-</span><span class="dv">2</span>) {}<span class="op">;</span></span>
<span id="cb41-15"><a href="#cb41-15"></a>    \node[] (b2) at (<span class="dv">3</span>,<span class="op">-</span><span class="dv">2</span>) {}<span class="op">;</span></span>
<span id="cb41-16"><a href="#cb41-16"></a></span>
<span id="cb41-17"><a href="#cb41-17"></a>    \draw[<span class="op">-&gt;</span>, shorten <span class="op">&gt;=</span><span class="dv">1</span><span class="er">pt</span>] (w1) <span class="op">--</span> (Input) node [midway,above] {\large $<span class="op">-</span><span class="fl">1.00</span>$}<span class="op">;</span></span>
<span id="cb41-18"><a href="#cb41-18"></a>    \draw[<span class="op">-&gt;</span>, shorten <span class="op">&gt;=</span><span class="dv">1</span><span class="er">pt</span>] (b1) node [below] {\large $<span class="fl">0.50</span>$} <span class="op">--</span> (Input)<span class="op">;</span></span>
<span id="cb41-19"><a href="#cb41-19"></a>    \draw[<span class="op">-&gt;</span>, shorten <span class="op">&gt;=</span><span class="dv">1</span><span class="er">pt</span>] (Input) <span class="op">--</span> (Hidden1) node [midway,above] {\large $<span class="fl">1.00</span>$}<span class="op">;</span></span>
<span id="cb41-20"><a href="#cb41-20"></a>    \draw[<span class="op">-&gt;</span>, shorten <span class="op">&gt;=</span><span class="dv">1</span><span class="er">pt</span>] (b2) node [below] {\large $<span class="fl">0.00</span>$} <span class="op">--</span> (Hidden1)<span class="op">;</span></span>
<span id="cb41-21"><a href="#cb41-21"></a>\end{tikzpicture}</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-display" data-execution_count="33">
<div>
<figure class="figure">
<p><img src="index_files/figure-html/cell-34-output-1.svg" class="img-fluid figure-img"></p>
</figure>
</div>
</div>
</div>
<p>As we can see so far, there’s no change. This is because the second neuron’s bias is doing no offsetting, and the second neuron’s weight is just multiplying the output by <span class="math inline">\(1\)</span>, so there’s no change. Let’s try to adjust the second neuron’s bias now:</p>
<div class="cell" data-execution_count="34">
<details class="code-fold">
<summary>Show the code</summary>
<div class="sourceCode cell-code" id="cb42"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb42-1"><a href="#cb42-1"></a><span class="op">%%</span>itikz <span class="op">--</span>temp<span class="op">-</span><span class="bu">dir</span> <span class="op">--</span>tex<span class="op">-</span>packages<span class="op">=</span>tikz,pgfplots <span class="op">--</span>tikz<span class="op">-</span>libraries<span class="op">=</span>arrows <span class="op">--</span>implicit<span class="op">-</span>standalone</span>
<span id="cb42-2"><a href="#cb42-2"></a>\begin{tikzpicture}[scale<span class="op">=</span><span class="fl">1.5</span>]</span>
<span id="cb42-3"><a href="#cb42-3"></a>\begin{axis}[grid,ymin<span class="op">=-</span><span class="dv">1</span>,ymax<span class="op">=</span><span class="dv">6</span>,ytick<span class="op">=</span>{<span class="op">-</span><span class="dv">1</span>,<span class="dv">0</span>,...,<span class="dv">6</span>}]</span>
<span id="cb42-4"><a href="#cb42-4"></a>\addplot[color<span class="op">=</span>blue,thick,samples<span class="op">=</span><span class="dv">100</span>]{<span class="bu">max</span>(<span class="bu">max</span>(<span class="op">-</span>x<span class="op">+</span><span class="fl">0.50</span>,<span class="dv">0</span>),<span class="dv">0</span>)}<span class="op">;</span></span>
<span id="cb42-5"><a href="#cb42-5"></a>\end{axis}</span>
<span id="cb42-6"><a href="#cb42-6"></a>\end{tikzpicture}</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-display" data-execution_count="34">
<div>
<figure class="figure">
<p><img src="index_files/figure-html/cell-35-output-1.svg" class="img-fluid figure-img"></p>
</figure>
</div>
</div>
</div>
<p>Let’s try to adjust the second neuron’s bias now:</p>
<div class="cell" data-execution_count="35">
<details class="code-fold">
<summary>Show the code</summary>
<div class="sourceCode cell-code" id="cb43"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb43-1"><a href="#cb43-1"></a><span class="op">%%</span>itikz <span class="op">--</span>temp<span class="op">-</span><span class="bu">dir</span> <span class="op">--</span>tex<span class="op">-</span>packages<span class="op">=</span>tikz <span class="op">--</span>tikz<span class="op">-</span>libraries<span class="op">=</span>arrows <span class="op">--</span>implicit<span class="op">-</span>standalone</span>
<span id="cb43-2"><a href="#cb43-2"></a>\begin{tikzpicture}[scale<span class="op">=</span><span class="fl">1.5</span>]</span>
<span id="cb43-3"><a href="#cb43-3"></a>    \node[circle, </span>
<span id="cb43-4"><a href="#cb43-4"></a>        minimum size <span class="op">=</span> <span class="dv">15</span><span class="er">mm</span>,</span>
<span id="cb43-5"><a href="#cb43-5"></a>        draw<span class="op">=</span>blue</span>
<span id="cb43-6"><a href="#cb43-6"></a>        ] (Input) at (<span class="dv">0</span>,<span class="dv">0</span>) {}<span class="op">;</span></span>
<span id="cb43-7"><a href="#cb43-7"></a></span>
<span id="cb43-8"><a href="#cb43-8"></a>    \node[circle, </span>
<span id="cb43-9"><a href="#cb43-9"></a>        minimum size <span class="op">=</span> <span class="dv">15</span><span class="er">mm</span>,</span>
<span id="cb43-10"><a href="#cb43-10"></a>        draw<span class="op">=</span>blue</span>
<span id="cb43-11"><a href="#cb43-11"></a>        ] (Hidden1) at (<span class="dv">3</span>,<span class="dv">0</span>) {}<span class="op">;</span></span>
<span id="cb43-12"><a href="#cb43-12"></a>    </span>
<span id="cb43-13"><a href="#cb43-13"></a>    \node[] (w1) at (<span class="op">-</span><span class="dv">3</span>,<span class="dv">0</span>) {}<span class="op">;</span></span>
<span id="cb43-14"><a href="#cb43-14"></a>    \node[] (b1) at (<span class="dv">0</span>,<span class="op">-</span><span class="dv">2</span>) {}<span class="op">;</span></span>
<span id="cb43-15"><a href="#cb43-15"></a>    \node[] (b2) at (<span class="dv">3</span>,<span class="op">-</span><span class="dv">2</span>) {}<span class="op">;</span></span>
<span id="cb43-16"><a href="#cb43-16"></a></span>
<span id="cb43-17"><a href="#cb43-17"></a>    \draw[<span class="op">-&gt;</span>, shorten <span class="op">&gt;=</span><span class="dv">1</span><span class="er">pt</span>] (w1) <span class="op">--</span> (Input) node [midway,above] {\large $<span class="op">-</span><span class="fl">1.00</span>$}<span class="op">;</span></span>
<span id="cb43-18"><a href="#cb43-18"></a>    \draw[<span class="op">-&gt;</span>, shorten <span class="op">&gt;=</span><span class="dv">1</span><span class="er">pt</span>] (b1) node [below] {\large $<span class="fl">0.50</span>$} <span class="op">--</span> (Input)<span class="op">;</span></span>
<span id="cb43-19"><a href="#cb43-19"></a>    \draw[<span class="op">-&gt;</span>, shorten <span class="op">&gt;=</span><span class="dv">1</span><span class="er">pt</span>] (Input) <span class="op">--</span> (Hidden1) node [midway,above] {\large $<span class="fl">1.00</span>$}<span class="op">;</span></span>
<span id="cb43-20"><a href="#cb43-20"></a>    \draw[<span class="op">-&gt;</span>, shorten <span class="op">&gt;=</span><span class="dv">1</span><span class="er">pt</span>] (b2) node [below] {\large $<span class="fl">1.00</span>$} <span class="op">--</span> (Hidden1)<span class="op">;</span></span>
<span id="cb43-21"><a href="#cb43-21"></a>\end{tikzpicture}</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-display" data-execution_count="35">
<div>
<figure class="figure">
<p><img src="index_files/figure-html/cell-36-output-1.svg" class="img-fluid figure-img"></p>
</figure>
</div>
</div>
</div>
<p>Now, we see some fairly interesting behavior. The bias of the second neuron indeed shifted the overall function but, rather than shifting it horizontally, it shifted vertically.</p>
<div class="cell" data-execution_count="36">
<details class="code-fold">
<summary>Show the code</summary>
<div class="sourceCode cell-code" id="cb44"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb44-1"><a href="#cb44-1"></a><span class="op">%%</span>itikz <span class="op">--</span>temp<span class="op">-</span><span class="bu">dir</span> <span class="op">--</span>tex<span class="op">-</span>packages<span class="op">=</span>tikz,pgfplots <span class="op">--</span>tikz<span class="op">-</span>libraries<span class="op">=</span>arrows <span class="op">--</span>implicit<span class="op">-</span>standalone</span>
<span id="cb44-2"><a href="#cb44-2"></a>\begin{tikzpicture}[scale<span class="op">=</span><span class="fl">1.5</span>]</span>
<span id="cb44-3"><a href="#cb44-3"></a>\begin{axis}[grid,ymin<span class="op">=-</span><span class="dv">1</span>,ymax<span class="op">=</span><span class="dv">6</span>,ytick<span class="op">=</span>{<span class="op">-</span><span class="dv">1</span>,<span class="dv">0</span>,...,<span class="dv">6</span>}]</span>
<span id="cb44-4"><a href="#cb44-4"></a>\addplot[color<span class="op">=</span>blue,thick,samples<span class="op">=</span><span class="dv">100</span>]{<span class="bu">max</span>(<span class="bu">max</span>(<span class="op">-</span>x<span class="op">+</span><span class="fl">0.50</span>,<span class="dv">0</span>)<span class="op">+</span><span class="fl">1.00</span>,<span class="dv">0</span>)}<span class="op">;</span></span>
<span id="cb44-5"><a href="#cb44-5"></a>\end{axis}</span>
<span id="cb44-6"><a href="#cb44-6"></a>\end{tikzpicture}</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-display" data-execution_count="36">
<div>
<figure class="figure">
<p><img src="index_files/figure-html/cell-37-output-1.svg" class="img-fluid figure-img"></p>
</figure>
</div>
</div>
</div>
<p>What then might happen, if we make the <span class="math inline">\(2\)</span>nd neuron’s weight <span class="math inline">\(-2\)</span> rather than <span class="math inline">\(1\)</span>?</p>
<div class="cell" data-execution_count="37">
<details class="code-fold">
<summary>Show the code</summary>
<div class="sourceCode cell-code" id="cb45"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb45-1"><a href="#cb45-1"></a><span class="op">%%</span>itikz <span class="op">--</span>temp<span class="op">-</span><span class="bu">dir</span> <span class="op">--</span>tex<span class="op">-</span>packages<span class="op">=</span>tikz <span class="op">--</span>tikz<span class="op">-</span>libraries<span class="op">=</span>arrows <span class="op">--</span>implicit<span class="op">-</span>standalone</span>
<span id="cb45-2"><a href="#cb45-2"></a>\begin{tikzpicture}[scale<span class="op">=</span><span class="fl">1.5</span>]</span>
<span id="cb45-3"><a href="#cb45-3"></a>    \node[circle, </span>
<span id="cb45-4"><a href="#cb45-4"></a>        minimum size <span class="op">=</span> <span class="dv">15</span><span class="er">mm</span>,</span>
<span id="cb45-5"><a href="#cb45-5"></a>        draw<span class="op">=</span>blue</span>
<span id="cb45-6"><a href="#cb45-6"></a>        ] (Input) at (<span class="dv">0</span>,<span class="dv">0</span>) {}<span class="op">;</span></span>
<span id="cb45-7"><a href="#cb45-7"></a></span>
<span id="cb45-8"><a href="#cb45-8"></a>    \node[circle, </span>
<span id="cb45-9"><a href="#cb45-9"></a>        minimum size <span class="op">=</span> <span class="dv">15</span><span class="er">mm</span>,</span>
<span id="cb45-10"><a href="#cb45-10"></a>        draw<span class="op">=</span>blue</span>
<span id="cb45-11"><a href="#cb45-11"></a>        ] (Hidden1) at (<span class="dv">3</span>,<span class="dv">0</span>) {}<span class="op">;</span></span>
<span id="cb45-12"><a href="#cb45-12"></a>    </span>
<span id="cb45-13"><a href="#cb45-13"></a>    \node[] (w1) at (<span class="op">-</span><span class="dv">3</span>,<span class="dv">0</span>) {}<span class="op">;</span></span>
<span id="cb45-14"><a href="#cb45-14"></a>    \node[] (b1) at (<span class="dv">0</span>,<span class="op">-</span><span class="dv">2</span>) {}<span class="op">;</span></span>
<span id="cb45-15"><a href="#cb45-15"></a>    \node[] (b2) at (<span class="dv">3</span>,<span class="op">-</span><span class="dv">2</span>) {}<span class="op">;</span></span>
<span id="cb45-16"><a href="#cb45-16"></a></span>
<span id="cb45-17"><a href="#cb45-17"></a>    \draw[<span class="op">-&gt;</span>, shorten <span class="op">&gt;=</span><span class="dv">1</span><span class="er">pt</span>] (w1) <span class="op">--</span> (Input) node [midway,above] {\large $<span class="op">-</span><span class="fl">1.00</span>$}<span class="op">;</span></span>
<span id="cb45-18"><a href="#cb45-18"></a>    \draw[<span class="op">-&gt;</span>, shorten <span class="op">&gt;=</span><span class="dv">1</span><span class="er">pt</span>] (b1) node [below] {\large $<span class="fl">0.50</span>$} <span class="op">--</span> (Input)<span class="op">;</span></span>
<span id="cb45-19"><a href="#cb45-19"></a>    \draw[<span class="op">-&gt;</span>, shorten <span class="op">&gt;=</span><span class="dv">1</span><span class="er">pt</span>] (Input) <span class="op">--</span> (Hidden1) node [midway,above] {\large $<span class="op">-</span><span class="fl">2.00</span>$}<span class="op">;</span></span>
<span id="cb45-20"><a href="#cb45-20"></a>    \draw[<span class="op">-&gt;</span>, shorten <span class="op">&gt;=</span><span class="dv">1</span><span class="er">pt</span>] (b2) node [below] {\large $<span class="fl">1.00</span>$} <span class="op">--</span> (Hidden1)<span class="op">;</span></span>
<span id="cb45-21"><a href="#cb45-21"></a>\end{tikzpicture}</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-display" data-execution_count="37">
<div>
<figure class="figure">
<p><img src="index_files/figure-html/cell-38-output-1.svg" class="img-fluid figure-img"></p>
</figure>
</div>
</div>
</div>
<p>Something exciting has occurred! What we have here is a neuron that has both an activation and a deactivation point. Now, the output after these two neurons will be variable, so long as it is inside of some specific range. So, basically if both neurons are activated then we actually sort of see this influence on the value. Otherwise, if both neurons aren’t activated, then the output is just a static value.</p>
<div class="cell" data-execution_count="38">
<details class="code-fold">
<summary>Show the code</summary>
<div class="sourceCode cell-code" id="cb46"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb46-1"><a href="#cb46-1"></a><span class="op">%%</span>itikz <span class="op">--</span>temp<span class="op">-</span><span class="bu">dir</span> <span class="op">--</span>tex<span class="op">-</span>packages<span class="op">=</span>tikz,pgfplots <span class="op">--</span>tikz<span class="op">-</span>libraries<span class="op">=</span>arrows <span class="op">--</span>implicit<span class="op">-</span>standalone</span>
<span id="cb46-2"><a href="#cb46-2"></a>\begin{tikzpicture}[scale<span class="op">=</span><span class="fl">1.5</span>]</span>
<span id="cb46-3"><a href="#cb46-3"></a>\begin{axis}[grid,ymin<span class="op">=-</span><span class="dv">1</span>,ymax<span class="op">=</span><span class="dv">2</span>,ytick<span class="op">=</span>{<span class="op">-</span><span class="dv">1</span>,<span class="dv">0</span>,...,<span class="dv">2</span>},xmin<span class="op">=-</span><span class="dv">2</span>,xmax<span class="op">=</span><span class="dv">2</span>]</span>
<span id="cb46-4"><a href="#cb46-4"></a>\addplot[color<span class="op">=</span>blue,thick,samples<span class="op">=</span><span class="dv">500</span>]{<span class="bu">max</span>(<span class="op">-</span><span class="fl">2.0</span><span class="op">*</span><span class="bu">max</span>(<span class="op">-</span>x<span class="op">+</span><span class="fl">0.50</span>,<span class="dv">0</span>)<span class="op">+</span><span class="fl">1.00</span>,<span class="dv">0</span>)}<span class="op">;</span></span>
<span id="cb46-5"><a href="#cb46-5"></a>\end{axis}</span>
<span id="cb46-6"><a href="#cb46-6"></a>\end{tikzpicture}</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-display" data-execution_count="38">
<div>
<figure class="figure">
<p><img src="index_files/figure-html/cell-39-output-1.svg" class="img-fluid figure-img"></p>
</figure>
</div>
</div>
</div>
<p>So, when we are below the activation of the first neuron, the output will be the bias of the second neuron <span class="math inline">\(1.00\)</span>.</p>
<div class="cell" data-execution_count="39">
<details class="code-fold">
<summary>Show the code</summary>
<div class="sourceCode cell-code" id="cb47"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb47-1"><a href="#cb47-1"></a><span class="op">%%</span>itikz <span class="op">--</span>temp<span class="op">-</span><span class="bu">dir</span> <span class="op">--</span>tex<span class="op">-</span>packages<span class="op">=</span>tikz <span class="op">--</span>tikz<span class="op">-</span>libraries<span class="op">=</span>arrows <span class="op">--</span>implicit<span class="op">-</span>standalone</span>
<span id="cb47-2"><a href="#cb47-2"></a>\begin{tikzpicture}[scale<span class="op">=</span><span class="fl">1.5</span>]</span>
<span id="cb47-3"><a href="#cb47-3"></a>    \node[circle, </span>
<span id="cb47-4"><a href="#cb47-4"></a>        minimum size <span class="op">=</span> <span class="dv">15</span><span class="er">mm</span>,</span>
<span id="cb47-5"><a href="#cb47-5"></a>        draw<span class="op">=</span>blue</span>
<span id="cb47-6"><a href="#cb47-6"></a>        ] (Input) at (<span class="dv">0</span>,<span class="dv">0</span>) {}<span class="op">;</span></span>
<span id="cb47-7"><a href="#cb47-7"></a></span>
<span id="cb47-8"><a href="#cb47-8"></a>    \node[circle, </span>
<span id="cb47-9"><a href="#cb47-9"></a>        minimum size <span class="op">=</span> <span class="dv">15</span><span class="er">mm</span>,</span>
<span id="cb47-10"><a href="#cb47-10"></a>        draw<span class="op">=</span>blue,</span>
<span id="cb47-11"><a href="#cb47-11"></a>        fill<span class="op">=</span>green</span>
<span id="cb47-12"><a href="#cb47-12"></a>        ] (Hidden1) at (<span class="dv">3</span>,<span class="dv">0</span>) {}<span class="op">;</span></span>
<span id="cb47-13"><a href="#cb47-13"></a>    </span>
<span id="cb47-14"><a href="#cb47-14"></a>    \node[] (w1) at (<span class="op">-</span><span class="dv">3</span>,<span class="dv">0</span>) {}<span class="op">;</span></span>
<span id="cb47-15"><a href="#cb47-15"></a>    \node[] (b1) at (<span class="dv">0</span>,<span class="op">-</span><span class="dv">2</span>) {}<span class="op">;</span></span>
<span id="cb47-16"><a href="#cb47-16"></a>    \node[] (b2) at (<span class="dv">3</span>,<span class="op">-</span><span class="dv">2</span>) {}<span class="op">;</span></span>
<span id="cb47-17"><a href="#cb47-17"></a></span>
<span id="cb47-18"><a href="#cb47-18"></a>    \draw[<span class="op">-&gt;</span>, shorten <span class="op">&gt;=</span><span class="dv">1</span><span class="er">pt</span>] (w1) node [left] {\large $<span class="fl">0.50</span>$} <span class="op">--</span> (Input) node [midway,above] {\large $<span class="op">-</span><span class="fl">1.00</span>$}<span class="op">;</span></span>
<span id="cb47-19"><a href="#cb47-19"></a>    \draw[<span class="op">-&gt;</span>, shorten <span class="op">&gt;=</span><span class="dv">1</span><span class="er">pt</span>] (b1) node [below] {\large $<span class="fl">0.50</span>$} <span class="op">--</span> (Input)<span class="op">;</span></span>
<span id="cb47-20"><a href="#cb47-20"></a>    \draw[<span class="op">-&gt;</span>, shorten <span class="op">&gt;=</span><span class="dv">1</span><span class="er">pt</span>] (Input) <span class="op">--</span> (Hidden1) node [midway,above] {\large $<span class="op">-</span><span class="fl">2.00</span>$}<span class="op">;</span></span>
<span id="cb47-21"><a href="#cb47-21"></a>    \draw[<span class="op">-&gt;</span>, shorten <span class="op">&gt;=</span><span class="dv">1</span><span class="er">pt</span>] (b2) node [below] {\large $<span class="fl">1.00</span>$} <span class="op">--</span> (Hidden1)<span class="op">;</span></span>
<span id="cb47-22"><a href="#cb47-22"></a>    \draw[<span class="op">-&gt;</span>, shorten <span class="op">&gt;=</span><span class="dv">1</span><span class="er">pt</span>] (Hidden1) <span class="op">--</span> (<span class="dv">6</span>,<span class="dv">0</span>) node [right] {$<span class="fl">1.00</span>$}<span class="op">;</span></span>
<span id="cb47-23"><a href="#cb47-23"></a>\end{tikzpicture}</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-display" data-execution_count="39">
<div>
<figure class="figure">
<p><img src="index_files/figure-html/cell-40-output-1.svg" class="img-fluid figure-img"></p>
</figure>
</div>
</div>
</div>
<p>The second neuron is activated if it’s input is smaller than <span class="math inline">\(0.50\)</span>.</p>
<p>Consider what happens when the input to the first neuron is <span class="math inline">\(0.00, -0.10, \ldots\)</span>. The output of the first neuron is <span class="math inline">\(0.50, 0.60, \ldots\)</span> which implies that the second neuron is deactivated, so the output of the second neuron is simply zero.</p>
<div class="cell" data-execution_count="40">
<details class="code-fold">
<summary>Show the code</summary>
<div class="sourceCode cell-code" id="cb48"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb48-1"><a href="#cb48-1"></a><span class="op">%%</span>itikz <span class="op">--</span>temp<span class="op">-</span><span class="bu">dir</span> <span class="op">--</span>tex<span class="op">-</span>packages<span class="op">=</span>tikz <span class="op">--</span>tikz<span class="op">-</span>libraries<span class="op">=</span>arrows <span class="op">--</span>implicit<span class="op">-</span>standalone</span>
<span id="cb48-2"><a href="#cb48-2"></a>\begin{tikzpicture}[scale<span class="op">=</span><span class="fl">1.5</span>]</span>
<span id="cb48-3"><a href="#cb48-3"></a>    \node[circle, </span>
<span id="cb48-4"><a href="#cb48-4"></a>        minimum size <span class="op">=</span> <span class="dv">15</span><span class="er">mm</span>,</span>
<span id="cb48-5"><a href="#cb48-5"></a>        draw<span class="op">=</span>blue,</span>
<span id="cb48-6"><a href="#cb48-6"></a>        fill<span class="op">=</span>green</span>
<span id="cb48-7"><a href="#cb48-7"></a>        ] (Input) at (<span class="dv">0</span>,<span class="dv">0</span>) {}<span class="op">;</span></span>
<span id="cb48-8"><a href="#cb48-8"></a></span>
<span id="cb48-9"><a href="#cb48-9"></a>    \node[circle, </span>
<span id="cb48-10"><a href="#cb48-10"></a>        minimum size <span class="op">=</span> <span class="dv">15</span><span class="er">mm</span>,</span>
<span id="cb48-11"><a href="#cb48-11"></a>        draw<span class="op">=</span>blue</span>
<span id="cb48-12"><a href="#cb48-12"></a>        ] (Hidden1) at (<span class="dv">3</span>,<span class="dv">0</span>) {}<span class="op">;</span></span>
<span id="cb48-13"><a href="#cb48-13"></a>    </span>
<span id="cb48-14"><a href="#cb48-14"></a>    \node[] (w1) at (<span class="op">-</span><span class="dv">3</span>,<span class="dv">0</span>) {}<span class="op">;</span></span>
<span id="cb48-15"><a href="#cb48-15"></a>    \node[] (b1) at (<span class="dv">0</span>,<span class="op">-</span><span class="dv">2</span>) {}<span class="op">;</span></span>
<span id="cb48-16"><a href="#cb48-16"></a>    \node[] (b2) at (<span class="dv">3</span>,<span class="op">-</span><span class="dv">2</span>) {}<span class="op">;</span></span>
<span id="cb48-17"><a href="#cb48-17"></a></span>
<span id="cb48-18"><a href="#cb48-18"></a>    \draw[<span class="op">-&gt;</span>, shorten <span class="op">&gt;=</span><span class="dv">1</span><span class="er">pt</span>] (w1) node [left] {\large $<span class="fl">0.50</span>$} <span class="op">--</span> (Input) node [midway,above] {\large $<span class="op">-</span><span class="fl">1.00</span>$}<span class="op">;</span></span>
<span id="cb48-19"><a href="#cb48-19"></a>    \draw[<span class="op">-&gt;</span>, shorten <span class="op">&gt;=</span><span class="dv">1</span><span class="er">pt</span>] (b1) node [below] {\large $<span class="fl">0.50</span>$} <span class="op">--</span> (Input)<span class="op">;</span></span>
<span id="cb48-20"><a href="#cb48-20"></a>    \draw[<span class="op">-&gt;</span>, shorten <span class="op">&gt;=</span><span class="dv">1</span><span class="er">pt</span>] (Input) <span class="op">--</span> (Hidden1) node [midway,above] {\large $<span class="op">-</span><span class="fl">2.00</span>$}<span class="op">;</span></span>
<span id="cb48-21"><a href="#cb48-21"></a>    \draw[<span class="op">-&gt;</span>, shorten <span class="op">&gt;=</span><span class="dv">1</span><span class="er">pt</span>] (b2) node [below] {\large $<span class="fl">1.00</span>$} <span class="op">--</span> (Hidden1)<span class="op">;</span></span>
<span id="cb48-22"><a href="#cb48-22"></a>    \draw[<span class="op">-&gt;</span>, shorten <span class="op">&gt;=</span><span class="dv">1</span><span class="er">pt</span>] (Hidden1) <span class="op">--</span> (<span class="dv">6</span>,<span class="dv">0</span>) node [right] {$<span class="fl">0.00</span>$}<span class="op">;</span></span>
<span id="cb48-23"><a href="#cb48-23"></a>\end{tikzpicture}</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-display" data-execution_count="40">
<div>
<figure class="figure">
<p><img src="index_files/figure-html/cell-41-output-1.svg" class="img-fluid figure-img"></p>
</figure>
</div>
</div>
</div>
</section>
<section id="relu-activation-in-hidden-layers" class="level2">
<h2 class="anchored" data-anchor-id="relu-activation-in-hidden-layers">ReLU Activation in hidden layers</h2>
<p>Let’s now take this concept and use it to fit to a sine wave-like function using two hidden layers of <span class="math inline">\(8\)</span> neurons each and we can hand-tune the values to fit the curve. We’ll do this by working with <span class="math inline">\(1\)</span> pair of neurons at a time, which means <span class="math inline">\(1\)</span> neuron from each layer individually. For simplicity, we are also going to assume that the layers are not densely connected, and each neuron from the first hidden layer connects to only one neuron from the second hidden layer. That’s usually not the case with the real models, but we want this simplification for the purpose of this demo. Additionally, this example model takes a single value as an input, the input to the sine function, and outputs a single value like the sine function. The output layer uses the linear activation function and the hidden layers will use the rectified linear activation function.</p>
<p>To start, we’ll set all weights to <span class="math inline">\(0\)</span> and work with the first pair of neurons:</p>
<div class="cell" data-execution_count="41">
<details class="code-fold">
<summary>Show the code</summary>
<div class="sourceCode cell-code" id="cb49"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb49-1"><a href="#cb49-1"></a><span class="op">%%</span>itikz <span class="op">--</span>temp<span class="op">-</span><span class="bu">dir</span> <span class="op">--</span>tex<span class="op">-</span>packages<span class="op">=</span>tikz <span class="op">--</span>tikz<span class="op">-</span>libraries<span class="op">=</span>arrows <span class="op">--</span>implicit<span class="op">-</span>standalone</span>
<span id="cb49-2"><a href="#cb49-2"></a>\begin{tikzpicture}</span>
<span id="cb49-3"><a href="#cb49-3"></a></span>
<span id="cb49-4"><a href="#cb49-4"></a>\node[circle, </span>
<span id="cb49-5"><a href="#cb49-5"></a>    minimum size <span class="op">=</span> <span class="dv">15</span><span class="er">mm</span>,</span>
<span id="cb49-6"><a href="#cb49-6"></a>    fill<span class="op">=</span>red<span class="op">!</span><span class="dv">30</span></span>
<span id="cb49-7"><a href="#cb49-7"></a>    ] (Input) at (<span class="dv">0</span>,<span class="dv">0</span>) {\large $x_1$}<span class="op">;</span></span>
<span id="cb49-8"><a href="#cb49-8"></a></span>
<span id="cb49-9"><a href="#cb49-9"></a>\foreach \i <span class="kw">in</span> {<span class="dv">1</span>,<span class="dv">2</span>,...,<span class="dv">8</span>}</span>
<span id="cb49-10"><a href="#cb49-10"></a>{</span>
<span id="cb49-11"><a href="#cb49-11"></a>    \node[circle, </span>
<span id="cb49-12"><a href="#cb49-12"></a>        minimum size <span class="op">=</span> <span class="dv">15</span><span class="er">mm</span>,</span>
<span id="cb49-13"><a href="#cb49-13"></a>        fill<span class="op">=</span>blue<span class="op">!</span><span class="dv">50</span>,</span>
<span id="cb49-14"><a href="#cb49-14"></a>        yshift<span class="op">=</span><span class="dv">90</span> mm</span>
<span id="cb49-15"><a href="#cb49-15"></a>        ] (Hidden1<span class="op">-</span>\i) at (<span class="fl">3.0</span>,<span class="op">-</span>\i <span class="op">*</span> <span class="dv">2</span>) {\large $h_\i<span class="op">^</span>{(<span class="dv">1</span>)}$}<span class="op">;</span></span>
<span id="cb49-16"><a href="#cb49-16"></a>        </span>
<span id="cb49-17"><a href="#cb49-17"></a>}</span>
<span id="cb49-18"><a href="#cb49-18"></a>\foreach \i <span class="kw">in</span> {<span class="dv">1</span>,<span class="dv">2</span>,...,<span class="dv">8</span>}</span>
<span id="cb49-19"><a href="#cb49-19"></a>{</span>
<span id="cb49-20"><a href="#cb49-20"></a>    \node[circle, </span>
<span id="cb49-21"><a href="#cb49-21"></a>        minimum size <span class="op">=</span> <span class="dv">15</span><span class="er">mm</span>,</span>
<span id="cb49-22"><a href="#cb49-22"></a>        fill<span class="op">=</span>blue<span class="op">!</span><span class="dv">50</span>,</span>
<span id="cb49-23"><a href="#cb49-23"></a>        yshift<span class="op">=</span><span class="dv">90</span> mm</span>
<span id="cb49-24"><a href="#cb49-24"></a>        ] (Hidden2<span class="op">-</span>\i) at (<span class="fl">6.0</span>,<span class="op">-</span>\i <span class="op">*</span> <span class="dv">2</span>) {\large $h_\i<span class="op">^</span>{(<span class="dv">2</span>)}$}<span class="op">;</span></span>
<span id="cb49-25"><a href="#cb49-25"></a>        </span>
<span id="cb49-26"><a href="#cb49-26"></a>}</span>
<span id="cb49-27"><a href="#cb49-27"></a></span>
<span id="cb49-28"><a href="#cb49-28"></a>\node[circle, </span>
<span id="cb49-29"><a href="#cb49-29"></a>    minimum size <span class="op">=</span> <span class="dv">15</span><span class="er">mm</span>,</span>
<span id="cb49-30"><a href="#cb49-30"></a>    fill<span class="op">=</span>red<span class="op">!</span><span class="dv">30</span></span>
<span id="cb49-31"><a href="#cb49-31"></a>    ] (Output) at (<span class="dv">9</span>,<span class="dv">0</span>) {\large $\hat{y}_1$}<span class="op">;</span></span>
<span id="cb49-32"><a href="#cb49-32"></a></span>
<span id="cb49-33"><a href="#cb49-33"></a><span class="op">%</span> Connect neurons In<span class="op">-</span>Hidden1</span>
<span id="cb49-34"><a href="#cb49-34"></a>\foreach \j <span class="kw">in</span> {<span class="dv">2</span>,...,<span class="dv">8</span>}</span>
<span id="cb49-35"><a href="#cb49-35"></a>{</span>
<span id="cb49-36"><a href="#cb49-36"></a>    \draw[<span class="op">-&gt;</span>, shorten <span class="op">&gt;=</span><span class="dv">1</span><span class="er">pt</span>] (Input) <span class="op">--</span> (Hidden1<span class="op">-</span>\j)<span class="op">;</span>   </span>
<span id="cb49-37"><a href="#cb49-37"></a>}</span>
<span id="cb49-38"><a href="#cb49-38"></a><span class="op">%</span> Connect neurons Hidden1<span class="op">-</span>Hidden2</span>
<span id="cb49-39"><a href="#cb49-39"></a>\foreach \i <span class="kw">in</span> {<span class="dv">2</span>,...,<span class="dv">8</span>}</span>
<span id="cb49-40"><a href="#cb49-40"></a>{</span>
<span id="cb49-41"><a href="#cb49-41"></a>    </span>
<span id="cb49-42"><a href="#cb49-42"></a>        \draw[<span class="op">-&gt;</span>, shorten <span class="op">&gt;=</span><span class="dv">1</span><span class="er">pt</span>] (Hidden1<span class="op">-</span>\i) <span class="op">--</span> (Hidden2<span class="op">-</span>\i)<span class="op">;</span>   </span>
<span id="cb49-43"><a href="#cb49-43"></a>    </span>
<span id="cb49-44"><a href="#cb49-44"></a>}</span>
<span id="cb49-45"><a href="#cb49-45"></a></span>
<span id="cb49-46"><a href="#cb49-46"></a>\foreach \i <span class="kw">in</span> {<span class="dv">2</span>,...,<span class="dv">8</span>}</span>
<span id="cb49-47"><a href="#cb49-47"></a>{</span>
<span id="cb49-48"><a href="#cb49-48"></a>    </span>
<span id="cb49-49"><a href="#cb49-49"></a>        \draw[<span class="op">-&gt;</span>, shorten <span class="op">&gt;=</span><span class="dv">1</span><span class="er">pt</span>] (Hidden2<span class="op">-</span>\i) <span class="op">--</span> (Output)<span class="op">;</span>   </span>
<span id="cb49-50"><a href="#cb49-50"></a>}</span>
<span id="cb49-51"><a href="#cb49-51"></a>\draw[<span class="op">-&gt;</span>, shorten <span class="op">&gt;=</span><span class="dv">1</span><span class="er">pt</span>] (Input) <span class="op">--</span> node [midway] {$<span class="fl">0.00</span>$} (Hidden1<span class="op">-</span><span class="dv">1</span>)<span class="op">;</span>   </span>
<span id="cb49-52"><a href="#cb49-52"></a>\draw[<span class="op">-&gt;</span>, shorten <span class="op">&gt;=</span><span class="dv">1</span><span class="er">pt</span>] (Hidden1<span class="op">-</span><span class="dv">1</span>) <span class="op">--</span> node [midway] {$<span class="fl">0.00</span>$} (Hidden2<span class="op">-</span><span class="dv">1</span>)<span class="op">;</span> </span>
<span id="cb49-53"><a href="#cb49-53"></a>\draw[<span class="op">-&gt;</span>, shorten <span class="op">&gt;=</span><span class="dv">1</span><span class="er">pt</span>] (Hidden2<span class="op">-</span><span class="dv">1</span>) <span class="op">--</span> node [midway] {$<span class="fl">0.00</span>$} (Output)<span class="op">;</span> </span>
<span id="cb49-54"><a href="#cb49-54"></a>\draw[<span class="op">-&gt;</span>, shorten <span class="op">&gt;=</span><span class="dv">1</span><span class="er">pt</span>] (<span class="dv">6</span>,<span class="dv">6</span>) node [below] {$<span class="fl">0.00</span>$} <span class="op">--</span>  (Hidden2<span class="op">-</span><span class="dv">1</span>)<span class="op">;</span> </span>
<span id="cb49-55"><a href="#cb49-55"></a>\draw[<span class="op">-&gt;</span>, shorten <span class="op">&gt;=</span><span class="dv">1</span><span class="er">pt</span>] (<span class="dv">3</span>,<span class="dv">6</span>) node [below] {$<span class="fl">0.00</span>$} <span class="op">--</span>  (Hidden1<span class="op">-</span><span class="dv">1</span>)<span class="op">;</span> </span>
<span id="cb49-56"><a href="#cb49-56"></a>\end{tikzpicture}</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-display" data-execution_count="41">
<div>
<figure class="figure">
<p><img src="index_files/figure-html/cell-42-output-1.svg" class="img-fluid figure-img"></p>
</figure>
</div>
</div>
</div>
<p>Next, we can set the weight for the hidden layer neurons and the output neuron to <span class="math inline">\(1.00\)</span>, and we can see how this impacts the output:</p>
<div class="cell" data-execution_count="42">
<details class="code-fold">
<summary>Show the code</summary>
<div class="sourceCode cell-code" id="cb50"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb50-1"><a href="#cb50-1"></a><span class="op">%%</span>itikz <span class="op">--</span>temp<span class="op">-</span><span class="bu">dir</span> <span class="op">--</span>tex<span class="op">-</span>packages<span class="op">=</span>tikz <span class="op">--</span>tikz<span class="op">-</span>libraries<span class="op">=</span>arrows <span class="op">--</span>implicit<span class="op">-</span>standalone</span>
<span id="cb50-2"><a href="#cb50-2"></a>\begin{tikzpicture}</span>
<span id="cb50-3"><a href="#cb50-3"></a></span>
<span id="cb50-4"><a href="#cb50-4"></a>\node[circle, </span>
<span id="cb50-5"><a href="#cb50-5"></a>    minimum size <span class="op">=</span> <span class="dv">15</span><span class="er">mm</span>,</span>
<span id="cb50-6"><a href="#cb50-6"></a>    fill<span class="op">=</span>red<span class="op">!</span><span class="dv">30</span></span>
<span id="cb50-7"><a href="#cb50-7"></a>    ] (Input) at (<span class="dv">0</span>,<span class="dv">0</span>) {\large $x_1$}<span class="op">;</span></span>
<span id="cb50-8"><a href="#cb50-8"></a></span>
<span id="cb50-9"><a href="#cb50-9"></a>\foreach \i <span class="kw">in</span> {<span class="dv">1</span>,<span class="dv">2</span>,...,<span class="dv">8</span>}</span>
<span id="cb50-10"><a href="#cb50-10"></a>{</span>
<span id="cb50-11"><a href="#cb50-11"></a>    \node[circle, </span>
<span id="cb50-12"><a href="#cb50-12"></a>        minimum size <span class="op">=</span> <span class="dv">15</span><span class="er">mm</span>,</span>
<span id="cb50-13"><a href="#cb50-13"></a>        fill<span class="op">=</span>blue<span class="op">!</span><span class="dv">50</span>,</span>
<span id="cb50-14"><a href="#cb50-14"></a>        yshift<span class="op">=</span><span class="dv">90</span> mm</span>
<span id="cb50-15"><a href="#cb50-15"></a>        ] (Hidden1<span class="op">-</span>\i) at (<span class="fl">3.0</span>,<span class="op">-</span>\i <span class="op">*</span> <span class="dv">2</span>) {\large $h_\i<span class="op">^</span>{(<span class="dv">1</span>)}$}<span class="op">;</span></span>
<span id="cb50-16"><a href="#cb50-16"></a>        </span>
<span id="cb50-17"><a href="#cb50-17"></a>}</span>
<span id="cb50-18"><a href="#cb50-18"></a>\foreach \i <span class="kw">in</span> {<span class="dv">1</span>,<span class="dv">2</span>,...,<span class="dv">8</span>}</span>
<span id="cb50-19"><a href="#cb50-19"></a>{</span>
<span id="cb50-20"><a href="#cb50-20"></a>    \node[circle, </span>
<span id="cb50-21"><a href="#cb50-21"></a>        minimum size <span class="op">=</span> <span class="dv">15</span><span class="er">mm</span>,</span>
<span id="cb50-22"><a href="#cb50-22"></a>        fill<span class="op">=</span>blue<span class="op">!</span><span class="dv">50</span>,</span>
<span id="cb50-23"><a href="#cb50-23"></a>        yshift<span class="op">=</span><span class="dv">90</span> mm</span>
<span id="cb50-24"><a href="#cb50-24"></a>        ] (Hidden2<span class="op">-</span>\i) at (<span class="fl">6.0</span>,<span class="op">-</span>\i <span class="op">*</span> <span class="dv">2</span>) {\large $h_\i<span class="op">^</span>{(<span class="dv">2</span>)}$}<span class="op">;</span></span>
<span id="cb50-25"><a href="#cb50-25"></a>        </span>
<span id="cb50-26"><a href="#cb50-26"></a>}</span>
<span id="cb50-27"><a href="#cb50-27"></a></span>
<span id="cb50-28"><a href="#cb50-28"></a>\node[circle, </span>
<span id="cb50-29"><a href="#cb50-29"></a>    minimum size <span class="op">=</span> <span class="dv">15</span><span class="er">mm</span>,</span>
<span id="cb50-30"><a href="#cb50-30"></a>    fill<span class="op">=</span>red<span class="op">!</span><span class="dv">30</span></span>
<span id="cb50-31"><a href="#cb50-31"></a>    ] (Output) at (<span class="dv">9</span>,<span class="dv">0</span>) {\large $\hat{y}_1$}<span class="op">;</span></span>
<span id="cb50-32"><a href="#cb50-32"></a></span>
<span id="cb50-33"><a href="#cb50-33"></a><span class="op">%</span> Connect neurons In<span class="op">-</span>Hidden1</span>
<span id="cb50-34"><a href="#cb50-34"></a>\foreach \j <span class="kw">in</span> {<span class="dv">2</span>,...,<span class="dv">8</span>}</span>
<span id="cb50-35"><a href="#cb50-35"></a>{</span>
<span id="cb50-36"><a href="#cb50-36"></a>    \draw[<span class="op">-&gt;</span>, shorten <span class="op">&gt;=</span><span class="dv">1</span><span class="er">pt</span>] (Input) <span class="op">--</span> (Hidden1<span class="op">-</span>\j)<span class="op">;</span>   </span>
<span id="cb50-37"><a href="#cb50-37"></a>}</span>
<span id="cb50-38"><a href="#cb50-38"></a><span class="op">%</span> Connect neurons Hidden1<span class="op">-</span>Hidden2</span>
<span id="cb50-39"><a href="#cb50-39"></a>\foreach \i <span class="kw">in</span> {<span class="dv">2</span>,...,<span class="dv">8</span>}</span>
<span id="cb50-40"><a href="#cb50-40"></a>{</span>
<span id="cb50-41"><a href="#cb50-41"></a>    </span>
<span id="cb50-42"><a href="#cb50-42"></a>        \draw[<span class="op">-&gt;</span>, shorten <span class="op">&gt;=</span><span class="dv">1</span><span class="er">pt</span>] (Hidden1<span class="op">-</span>\i) <span class="op">--</span> (Hidden2<span class="op">-</span>\i)<span class="op">;</span>   </span>
<span id="cb50-43"><a href="#cb50-43"></a>    </span>
<span id="cb50-44"><a href="#cb50-44"></a>}</span>
<span id="cb50-45"><a href="#cb50-45"></a></span>
<span id="cb50-46"><a href="#cb50-46"></a>\foreach \i <span class="kw">in</span> {<span class="dv">2</span>,...,<span class="dv">8</span>}</span>
<span id="cb50-47"><a href="#cb50-47"></a>{</span>
<span id="cb50-48"><a href="#cb50-48"></a>    </span>
<span id="cb50-49"><a href="#cb50-49"></a>        \draw[<span class="op">-&gt;</span>, shorten <span class="op">&gt;=</span><span class="dv">1</span><span class="er">pt</span>] (Hidden2<span class="op">-</span>\i) <span class="op">--</span> (Output)<span class="op">;</span>   </span>
<span id="cb50-50"><a href="#cb50-50"></a>}</span>
<span id="cb50-51"><a href="#cb50-51"></a>\draw[<span class="op">-&gt;</span>, shorten <span class="op">&gt;=</span><span class="dv">1</span><span class="er">pt</span>] (Input) <span class="op">--</span> node [midway] {$<span class="fl">1.00</span>$} (Hidden1<span class="op">-</span><span class="dv">1</span>)<span class="op">;</span>   </span>
<span id="cb50-52"><a href="#cb50-52"></a>\draw[<span class="op">-&gt;</span>, shorten <span class="op">&gt;=</span><span class="dv">1</span><span class="er">pt</span>] (Hidden1<span class="op">-</span><span class="dv">1</span>) <span class="op">--</span> node [midway,above] {$<span class="fl">1.00</span>$} (Hidden2<span class="op">-</span><span class="dv">1</span>)<span class="op">;</span> </span>
<span id="cb50-53"><a href="#cb50-53"></a>\draw[<span class="op">-&gt;</span>, shorten <span class="op">&gt;=</span><span class="dv">1</span><span class="er">pt</span>] (Hidden2<span class="op">-</span><span class="dv">1</span>) <span class="op">--</span> node [midway] {$<span class="fl">1.00</span>$} (Output)<span class="op">;</span> </span>
<span id="cb50-54"><a href="#cb50-54"></a>\draw[<span class="op">-&gt;</span>, shorten <span class="op">&gt;=</span><span class="dv">1</span><span class="er">pt</span>] (<span class="dv">6</span>,<span class="dv">6</span>) node [below] {$<span class="fl">0.00</span>$} <span class="op">--</span>  (Hidden2<span class="op">-</span><span class="dv">1</span>)<span class="op">;</span> </span>
<span id="cb50-55"><a href="#cb50-55"></a>\draw[<span class="op">-&gt;</span>, shorten <span class="op">&gt;=</span><span class="dv">1</span><span class="er">pt</span>] (<span class="dv">3</span>,<span class="dv">6</span>) node [below] {$<span class="fl">0.00</span>$} <span class="op">--</span>  (Hidden1<span class="op">-</span><span class="dv">1</span>)<span class="op">;</span> </span>
<span id="cb50-56"><a href="#cb50-56"></a>\end{tikzpicture}</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-display" data-execution_count="42">
<div>
<figure class="figure">
<p><img src="index_files/figure-html/cell-43-output-1.svg" class="img-fluid figure-img"></p>
</figure>
</div>
</div>
</div>
<p>The output is:</p>
<div class="cell" data-execution_count="43">
<details class="code-fold">
<summary>Show the code</summary>
<div class="sourceCode cell-code" id="cb51"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb51-1"><a href="#cb51-1"></a><span class="op">%%</span>itikz <span class="op">--</span>temp<span class="op">-</span><span class="bu">dir</span> <span class="op">--</span>tex<span class="op">-</span>packages<span class="op">=</span>tikz,pgfplots <span class="op">--</span>tikz<span class="op">-</span>libraries<span class="op">=</span>arrows <span class="op">--</span>implicit<span class="op">-</span>standalone</span>
<span id="cb51-2"><a href="#cb51-2"></a>\begin{tikzpicture}[scale<span class="op">=</span><span class="fl">1.5</span>]</span>
<span id="cb51-3"><a href="#cb51-3"></a>\begin{axis}[grid,ymin<span class="op">=-</span><span class="dv">2</span>,ymax<span class="op">=</span><span class="dv">2</span>,ytick<span class="op">=</span>{<span class="op">-</span><span class="dv">2</span>,<span class="op">-</span><span class="dv">1</span>,...,<span class="dv">2</span>},xmin<span class="op">=</span><span class="dv">0</span>,xmax<span class="op">=</span><span class="dv">1</span>]</span>
<span id="cb51-4"><a href="#cb51-4"></a>\addplot[color<span class="op">=</span>blue,thick,samples<span class="op">=</span><span class="dv">1000</span>]{<span class="bu">max</span>(<span class="bu">max</span>(x,<span class="dv">0</span>),<span class="dv">0</span>)}<span class="op">;</span></span>
<span id="cb51-5"><a href="#cb51-5"></a>\addplot[color<span class="op">=</span>green,samples<span class="op">=</span><span class="dv">1000</span>,domain<span class="op">=</span><span class="dv">0</span>:<span class="dv">1</span>]{sin(deg(<span class="dv">2</span><span class="op">*</span><span class="fl">3.14</span><span class="op">*</span>x))}<span class="op">;</span></span>
<span id="cb51-6"><a href="#cb51-6"></a>\end{axis}</span>
<span id="cb51-7"><a href="#cb51-7"></a>\end{tikzpicture}</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-display" data-execution_count="43">
<div>
<figure class="figure">
<p><img src="index_files/figure-html/cell-44-output-1.svg" class="img-fluid figure-img"></p>
</figure>
</div>
</div>
</div>
<p>We can increase the slope of the output by adjusting the weight of the first neuron of the first layer to <span class="math inline">\(6.00\)</span>.</p>
<div class="cell" data-execution_count="44">
<details class="code-fold">
<summary>Show the code</summary>
<div class="sourceCode cell-code" id="cb52"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb52-1"><a href="#cb52-1"></a><span class="op">%%</span>itikz <span class="op">--</span>temp<span class="op">-</span><span class="bu">dir</span> <span class="op">--</span>tex<span class="op">-</span>packages<span class="op">=</span>tikz <span class="op">--</span>tikz<span class="op">-</span>libraries<span class="op">=</span>arrows <span class="op">--</span>implicit<span class="op">-</span>standalone</span>
<span id="cb52-2"><a href="#cb52-2"></a>\begin{tikzpicture}</span>
<span id="cb52-3"><a href="#cb52-3"></a></span>
<span id="cb52-4"><a href="#cb52-4"></a>\node[circle, </span>
<span id="cb52-5"><a href="#cb52-5"></a>    minimum size <span class="op">=</span> <span class="dv">15</span><span class="er">mm</span>,</span>
<span id="cb52-6"><a href="#cb52-6"></a>    fill<span class="op">=</span>red<span class="op">!</span><span class="dv">30</span></span>
<span id="cb52-7"><a href="#cb52-7"></a>    ] (Input) at (<span class="dv">0</span>,<span class="dv">0</span>) {\large $x_1$}<span class="op">;</span></span>
<span id="cb52-8"><a href="#cb52-8"></a></span>
<span id="cb52-9"><a href="#cb52-9"></a>\foreach \i <span class="kw">in</span> {<span class="dv">1</span>,<span class="dv">2</span>,...,<span class="dv">8</span>}</span>
<span id="cb52-10"><a href="#cb52-10"></a>{</span>
<span id="cb52-11"><a href="#cb52-11"></a>    \node[circle, </span>
<span id="cb52-12"><a href="#cb52-12"></a>        minimum size <span class="op">=</span> <span class="dv">15</span><span class="er">mm</span>,</span>
<span id="cb52-13"><a href="#cb52-13"></a>        fill<span class="op">=</span>blue<span class="op">!</span><span class="dv">50</span>,</span>
<span id="cb52-14"><a href="#cb52-14"></a>        yshift<span class="op">=</span><span class="dv">90</span> mm</span>
<span id="cb52-15"><a href="#cb52-15"></a>        ] (Hidden1<span class="op">-</span>\i) at (<span class="fl">3.0</span>,<span class="op">-</span>\i <span class="op">*</span> <span class="dv">2</span>) {\large $h_\i<span class="op">^</span>{(<span class="dv">1</span>)}$}<span class="op">;</span></span>
<span id="cb52-16"><a href="#cb52-16"></a>        </span>
<span id="cb52-17"><a href="#cb52-17"></a>}</span>
<span id="cb52-18"><a href="#cb52-18"></a>\foreach \i <span class="kw">in</span> {<span class="dv">1</span>,<span class="dv">2</span>,...,<span class="dv">8</span>}</span>
<span id="cb52-19"><a href="#cb52-19"></a>{</span>
<span id="cb52-20"><a href="#cb52-20"></a>    \node[circle, </span>
<span id="cb52-21"><a href="#cb52-21"></a>        minimum size <span class="op">=</span> <span class="dv">15</span><span class="er">mm</span>,</span>
<span id="cb52-22"><a href="#cb52-22"></a>        fill<span class="op">=</span>blue<span class="op">!</span><span class="dv">50</span>,</span>
<span id="cb52-23"><a href="#cb52-23"></a>        yshift<span class="op">=</span><span class="dv">90</span> mm</span>
<span id="cb52-24"><a href="#cb52-24"></a>        ] (Hidden2<span class="op">-</span>\i) at (<span class="fl">6.0</span>,<span class="op">-</span>\i <span class="op">*</span> <span class="dv">2</span>) {\large $h_\i<span class="op">^</span>{(<span class="dv">2</span>)}$}<span class="op">;</span></span>
<span id="cb52-25"><a href="#cb52-25"></a>        </span>
<span id="cb52-26"><a href="#cb52-26"></a>}</span>
<span id="cb52-27"><a href="#cb52-27"></a></span>
<span id="cb52-28"><a href="#cb52-28"></a>\node[circle, </span>
<span id="cb52-29"><a href="#cb52-29"></a>    minimum size <span class="op">=</span> <span class="dv">15</span><span class="er">mm</span>,</span>
<span id="cb52-30"><a href="#cb52-30"></a>    fill<span class="op">=</span>red<span class="op">!</span><span class="dv">30</span></span>
<span id="cb52-31"><a href="#cb52-31"></a>    ] (Output) at (<span class="dv">9</span>,<span class="dv">0</span>) {\large $\hat{y}_1$}<span class="op">;</span></span>
<span id="cb52-32"><a href="#cb52-32"></a></span>
<span id="cb52-33"><a href="#cb52-33"></a><span class="op">%</span> Connect neurons In<span class="op">-</span>Hidden1</span>
<span id="cb52-34"><a href="#cb52-34"></a>\foreach \j <span class="kw">in</span> {<span class="dv">2</span>,...,<span class="dv">8</span>}</span>
<span id="cb52-35"><a href="#cb52-35"></a>{</span>
<span id="cb52-36"><a href="#cb52-36"></a>    \draw[<span class="op">-&gt;</span>, shorten <span class="op">&gt;=</span><span class="dv">1</span><span class="er">pt</span>] (Input) <span class="op">--</span> (Hidden1<span class="op">-</span>\j)<span class="op">;</span>   </span>
<span id="cb52-37"><a href="#cb52-37"></a>}</span>
<span id="cb52-38"><a href="#cb52-38"></a><span class="op">%</span> Connect neurons Hidden1<span class="op">-</span>Hidden2</span>
<span id="cb52-39"><a href="#cb52-39"></a>\foreach \i <span class="kw">in</span> {<span class="dv">2</span>,...,<span class="dv">8</span>}</span>
<span id="cb52-40"><a href="#cb52-40"></a>{</span>
<span id="cb52-41"><a href="#cb52-41"></a>    </span>
<span id="cb52-42"><a href="#cb52-42"></a>        \draw[<span class="op">-&gt;</span>, shorten <span class="op">&gt;=</span><span class="dv">1</span><span class="er">pt</span>] (Hidden1<span class="op">-</span>\i) <span class="op">--</span> (Hidden2<span class="op">-</span>\i)<span class="op">;</span>   </span>
<span id="cb52-43"><a href="#cb52-43"></a>    </span>
<span id="cb52-44"><a href="#cb52-44"></a>}</span>
<span id="cb52-45"><a href="#cb52-45"></a></span>
<span id="cb52-46"><a href="#cb52-46"></a>\foreach \i <span class="kw">in</span> {<span class="dv">2</span>,...,<span class="dv">8</span>}</span>
<span id="cb52-47"><a href="#cb52-47"></a>{</span>
<span id="cb52-48"><a href="#cb52-48"></a>    </span>
<span id="cb52-49"><a href="#cb52-49"></a>        \draw[<span class="op">-&gt;</span>, shorten <span class="op">&gt;=</span><span class="dv">1</span><span class="er">pt</span>] (Hidden2<span class="op">-</span>\i) <span class="op">--</span> (Output)<span class="op">;</span>   </span>
<span id="cb52-50"><a href="#cb52-50"></a>}</span>
<span id="cb52-51"><a href="#cb52-51"></a>\draw[<span class="op">-&gt;</span>, shorten <span class="op">&gt;=</span><span class="dv">1</span><span class="er">pt</span>] (Input) <span class="op">--</span> node [midway] {$<span class="fl">6.00</span>$} (Hidden1<span class="op">-</span><span class="dv">1</span>)<span class="op">;</span>   </span>
<span id="cb52-52"><a href="#cb52-52"></a>\draw[<span class="op">-&gt;</span>, shorten <span class="op">&gt;=</span><span class="dv">1</span><span class="er">pt</span>] (Hidden1<span class="op">-</span><span class="dv">1</span>) <span class="op">--</span> node [midway,above] {$<span class="fl">1.00</span>$} (Hidden2<span class="op">-</span><span class="dv">1</span>)<span class="op">;</span> </span>
<span id="cb52-53"><a href="#cb52-53"></a>\draw[<span class="op">-&gt;</span>, shorten <span class="op">&gt;=</span><span class="dv">1</span><span class="er">pt</span>] (Hidden2<span class="op">-</span><span class="dv">1</span>) <span class="op">--</span> node [midway] {$<span class="fl">1.00</span>$} (Output)<span class="op">;</span> </span>
<span id="cb52-54"><a href="#cb52-54"></a>\draw[<span class="op">-&gt;</span>, shorten <span class="op">&gt;=</span><span class="dv">1</span><span class="er">pt</span>] (<span class="dv">6</span>,<span class="dv">6</span>) node [below] {$<span class="fl">0.00</span>$} <span class="op">--</span>  (Hidden2<span class="op">-</span><span class="dv">1</span>)<span class="op">;</span> </span>
<span id="cb52-55"><a href="#cb52-55"></a>\draw[<span class="op">-&gt;</span>, shorten <span class="op">&gt;=</span><span class="dv">1</span><span class="er">pt</span>] (<span class="dv">3</span>,<span class="dv">6</span>) node [below] {$<span class="fl">0.00</span>$} <span class="op">--</span>  (Hidden1<span class="op">-</span><span class="dv">1</span>)<span class="op">;</span> </span>
<span id="cb52-56"><a href="#cb52-56"></a>\end{tikzpicture}</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-display" data-execution_count="44">
<div>
<figure class="figure">
<p><img src="index_files/figure-html/cell-45-output-1.svg" class="img-fluid figure-img"></p>
</figure>
</div>
</div>
</div>
<p>We can now see, for example, that the initial slope of this function is what we’d like, but we have a problem.</p>
<div class="cell" data-execution_count="45">
<details class="code-fold">
<summary>Show the code</summary>
<div class="sourceCode cell-code" id="cb53"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb53-1"><a href="#cb53-1"></a><span class="op">%%</span>itikz <span class="op">--</span>temp<span class="op">-</span><span class="bu">dir</span> <span class="op">--</span>tex<span class="op">-</span>packages<span class="op">=</span>tikz,pgfplots <span class="op">--</span>tikz<span class="op">-</span>libraries<span class="op">=</span>arrows <span class="op">--</span>implicit<span class="op">-</span>standalone</span>
<span id="cb53-2"><a href="#cb53-2"></a>\begin{tikzpicture}[scale<span class="op">=</span><span class="fl">1.5</span>]</span>
<span id="cb53-3"><a href="#cb53-3"></a>\begin{axis}[grid,ymin<span class="op">=-</span><span class="dv">2</span>,ymax<span class="op">=</span><span class="dv">2</span>,ytick<span class="op">=</span>{<span class="op">-</span><span class="dv">2</span>,<span class="op">-</span><span class="dv">1</span>,...,<span class="dv">2</span>},xmin<span class="op">=</span><span class="dv">0</span>,xmax<span class="op">=</span><span class="dv">1</span>]</span>
<span id="cb53-4"><a href="#cb53-4"></a>\addplot[color<span class="op">=</span>blue,thick,samples<span class="op">=</span><span class="dv">1000</span>]{<span class="bu">max</span>(<span class="bu">max</span>(<span class="dv">6</span><span class="op">*</span>x,<span class="dv">0</span>),<span class="dv">0</span>)}<span class="op">;</span></span>
<span id="cb53-5"><a href="#cb53-5"></a>\addplot[color<span class="op">=</span>green,samples<span class="op">=</span><span class="dv">1000</span>,domain<span class="op">=</span><span class="dv">0</span>:<span class="dv">1</span>]{sin(deg(<span class="dv">2</span><span class="op">*</span><span class="fl">3.14</span><span class="op">*</span>x))}<span class="op">;</span></span>
<span id="cb53-6"><a href="#cb53-6"></a>\end{axis}</span>
<span id="cb53-7"><a href="#cb53-7"></a>\end{tikzpicture}</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-display" data-execution_count="45">
<div>
<figure class="figure">
<p><img src="index_files/figure-html/cell-46-output-1.svg" class="img-fluid figure-img"></p>
</figure>
</div>
</div>
</div>
<p>Currently, this function never ends because this neuron pair never <em>deactivates</em>. We can visually see where we’d like the deactivation to occur. It’s where the red fitment line diverges from our green sine wave. So now, while we have the correct slope, we need to set this spot as our deactivation point. To do that, we start by increasing the bias for the second neuron of the hidden layer to <span class="math inline">\(0.70\)</span>.</p>
<div class="cell" data-execution_count="46">
<details class="code-fold">
<summary>Show the code</summary>
<div class="sourceCode cell-code" id="cb54"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb54-1"><a href="#cb54-1"></a><span class="op">%%</span>itikz <span class="op">--</span>temp<span class="op">-</span><span class="bu">dir</span> <span class="op">--</span>tex<span class="op">-</span>packages<span class="op">=</span>tikz <span class="op">--</span>tikz<span class="op">-</span>libraries<span class="op">=</span>arrows <span class="op">--</span>implicit<span class="op">-</span>standalone</span>
<span id="cb54-2"><a href="#cb54-2"></a>\begin{tikzpicture}</span>
<span id="cb54-3"><a href="#cb54-3"></a></span>
<span id="cb54-4"><a href="#cb54-4"></a>\node[circle, </span>
<span id="cb54-5"><a href="#cb54-5"></a>    minimum size <span class="op">=</span> <span class="dv">15</span><span class="er">mm</span>,</span>
<span id="cb54-6"><a href="#cb54-6"></a>    fill<span class="op">=</span>red<span class="op">!</span><span class="dv">30</span></span>
<span id="cb54-7"><a href="#cb54-7"></a>    ] (Input) at (<span class="dv">0</span>,<span class="dv">0</span>) {\large $x_1$}<span class="op">;</span></span>
<span id="cb54-8"><a href="#cb54-8"></a></span>
<span id="cb54-9"><a href="#cb54-9"></a>\foreach \i <span class="kw">in</span> {<span class="dv">1</span>,<span class="dv">2</span>,...,<span class="dv">8</span>}</span>
<span id="cb54-10"><a href="#cb54-10"></a>{</span>
<span id="cb54-11"><a href="#cb54-11"></a>    \node[circle, </span>
<span id="cb54-12"><a href="#cb54-12"></a>        minimum size <span class="op">=</span> <span class="dv">15</span><span class="er">mm</span>,</span>
<span id="cb54-13"><a href="#cb54-13"></a>        fill<span class="op">=</span>blue<span class="op">!</span><span class="dv">50</span>,</span>
<span id="cb54-14"><a href="#cb54-14"></a>        yshift<span class="op">=</span><span class="dv">90</span> mm</span>
<span id="cb54-15"><a href="#cb54-15"></a>        ] (Hidden1<span class="op">-</span>\i) at (<span class="fl">3.0</span>,<span class="op">-</span>\i <span class="op">*</span> <span class="dv">2</span>) {\large $h_\i<span class="op">^</span>{(<span class="dv">1</span>)}$}<span class="op">;</span></span>
<span id="cb54-16"><a href="#cb54-16"></a>        </span>
<span id="cb54-17"><a href="#cb54-17"></a>}</span>
<span id="cb54-18"><a href="#cb54-18"></a>\foreach \i <span class="kw">in</span> {<span class="dv">1</span>,<span class="dv">2</span>,...,<span class="dv">8</span>}</span>
<span id="cb54-19"><a href="#cb54-19"></a>{</span>
<span id="cb54-20"><a href="#cb54-20"></a>    \node[circle, </span>
<span id="cb54-21"><a href="#cb54-21"></a>        minimum size <span class="op">=</span> <span class="dv">15</span><span class="er">mm</span>,</span>
<span id="cb54-22"><a href="#cb54-22"></a>        fill<span class="op">=</span>blue<span class="op">!</span><span class="dv">50</span>,</span>
<span id="cb54-23"><a href="#cb54-23"></a>        yshift<span class="op">=</span><span class="dv">90</span> mm</span>
<span id="cb54-24"><a href="#cb54-24"></a>        ] (Hidden2<span class="op">-</span>\i) at (<span class="fl">6.0</span>,<span class="op">-</span>\i <span class="op">*</span> <span class="dv">2</span>) {\large $h_\i<span class="op">^</span>{(<span class="dv">2</span>)}$}<span class="op">;</span></span>
<span id="cb54-25"><a href="#cb54-25"></a>        </span>
<span id="cb54-26"><a href="#cb54-26"></a>}</span>
<span id="cb54-27"><a href="#cb54-27"></a></span>
<span id="cb54-28"><a href="#cb54-28"></a>\node[circle, </span>
<span id="cb54-29"><a href="#cb54-29"></a>    minimum size <span class="op">=</span> <span class="dv">15</span><span class="er">mm</span>,</span>
<span id="cb54-30"><a href="#cb54-30"></a>    fill<span class="op">=</span>red<span class="op">!</span><span class="dv">30</span></span>
<span id="cb54-31"><a href="#cb54-31"></a>    ] (Output) at (<span class="dv">9</span>,<span class="dv">0</span>) {\large $\hat{y}_1$}<span class="op">;</span></span>
<span id="cb54-32"><a href="#cb54-32"></a></span>
<span id="cb54-33"><a href="#cb54-33"></a><span class="op">%</span> Connect neurons In<span class="op">-</span>Hidden1</span>
<span id="cb54-34"><a href="#cb54-34"></a>\foreach \j <span class="kw">in</span> {<span class="dv">2</span>,...,<span class="dv">8</span>}</span>
<span id="cb54-35"><a href="#cb54-35"></a>{</span>
<span id="cb54-36"><a href="#cb54-36"></a>    \draw[<span class="op">-&gt;</span>, shorten <span class="op">&gt;=</span><span class="dv">1</span><span class="er">pt</span>] (Input) <span class="op">--</span> (Hidden1<span class="op">-</span>\j)<span class="op">;</span>   </span>
<span id="cb54-37"><a href="#cb54-37"></a>}</span>
<span id="cb54-38"><a href="#cb54-38"></a><span class="op">%</span> Connect neurons Hidden1<span class="op">-</span>Hidden2</span>
<span id="cb54-39"><a href="#cb54-39"></a>\foreach \i <span class="kw">in</span> {<span class="dv">2</span>,...,<span class="dv">8</span>}</span>
<span id="cb54-40"><a href="#cb54-40"></a>{</span>
<span id="cb54-41"><a href="#cb54-41"></a>    </span>
<span id="cb54-42"><a href="#cb54-42"></a>        \draw[<span class="op">-&gt;</span>, shorten <span class="op">&gt;=</span><span class="dv">1</span><span class="er">pt</span>] (Hidden1<span class="op">-</span>\i) <span class="op">--</span> (Hidden2<span class="op">-</span>\i)<span class="op">;</span>   </span>
<span id="cb54-43"><a href="#cb54-43"></a>    </span>
<span id="cb54-44"><a href="#cb54-44"></a>}</span>
<span id="cb54-45"><a href="#cb54-45"></a></span>
<span id="cb54-46"><a href="#cb54-46"></a>\foreach \i <span class="kw">in</span> {<span class="dv">2</span>,...,<span class="dv">8</span>}</span>
<span id="cb54-47"><a href="#cb54-47"></a>{</span>
<span id="cb54-48"><a href="#cb54-48"></a>    </span>
<span id="cb54-49"><a href="#cb54-49"></a>        \draw[<span class="op">-&gt;</span>, shorten <span class="op">&gt;=</span><span class="dv">1</span><span class="er">pt</span>] (Hidden2<span class="op">-</span>\i) <span class="op">--</span> (Output)<span class="op">;</span>   </span>
<span id="cb54-50"><a href="#cb54-50"></a>}</span>
<span id="cb54-51"><a href="#cb54-51"></a>\draw[<span class="op">-&gt;</span>, shorten <span class="op">&gt;=</span><span class="dv">1</span><span class="er">pt</span>] (Input) <span class="op">--</span> node [midway] {$<span class="fl">6.00</span>$} (Hidden1<span class="op">-</span><span class="dv">1</span>)<span class="op">;</span>   </span>
<span id="cb54-52"><a href="#cb54-52"></a>\draw[<span class="op">-&gt;</span>, shorten <span class="op">&gt;=</span><span class="dv">1</span><span class="er">pt</span>] (Hidden1<span class="op">-</span><span class="dv">1</span>) <span class="op">--</span> node [midway,above] {$<span class="fl">1.00</span>$} (Hidden2<span class="op">-</span><span class="dv">1</span>)<span class="op">;</span> </span>
<span id="cb54-53"><a href="#cb54-53"></a>\draw[<span class="op">-&gt;</span>, shorten <span class="op">&gt;=</span><span class="dv">1</span><span class="er">pt</span>] (Hidden2<span class="op">-</span><span class="dv">1</span>) <span class="op">--</span> node [midway] {$<span class="fl">1.00</span>$} (Output)<span class="op">;</span> </span>
<span id="cb54-54"><a href="#cb54-54"></a>\draw[<span class="op">-&gt;</span>, shorten <span class="op">&gt;=</span><span class="dv">1</span><span class="er">pt</span>] (<span class="dv">6</span>,<span class="dv">6</span>) node [below] {$<span class="fl">0.70</span>$} <span class="op">--</span>  (Hidden2<span class="op">-</span><span class="dv">1</span>)<span class="op">;</span> </span>
<span id="cb54-55"><a href="#cb54-55"></a>\draw[<span class="op">-&gt;</span>, shorten <span class="op">&gt;=</span><span class="dv">1</span><span class="er">pt</span>] (<span class="dv">3</span>,<span class="dv">6</span>) node [below] {$<span class="fl">0.00</span>$} <span class="op">--</span>  (Hidden1<span class="op">-</span><span class="dv">1</span>)<span class="op">;</span> </span>
<span id="cb54-56"><a href="#cb54-56"></a>\end{tikzpicture}</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-display" data-execution_count="46">
<div>
<figure class="figure">
<p><img src="index_files/figure-html/cell-47-output-1.svg" class="img-fluid figure-img"></p>
</figure>
</div>
</div>
</div>
<p>Recall, that this offsets the overall function vertically:</p>
<div class="cell" data-execution_count="47">
<details class="code-fold">
<summary>Show the code</summary>
<div class="sourceCode cell-code" id="cb55"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb55-1"><a href="#cb55-1"></a><span class="op">%%</span>itikz <span class="op">--</span>temp<span class="op">-</span><span class="bu">dir</span> <span class="op">--</span>tex<span class="op">-</span>packages<span class="op">=</span>tikz,pgfplots <span class="op">--</span>tikz<span class="op">-</span>libraries<span class="op">=</span>arrows <span class="op">--</span>implicit<span class="op">-</span>standalone</span>
<span id="cb55-2"><a href="#cb55-2"></a>\begin{tikzpicture}[scale<span class="op">=</span><span class="fl">1.5</span>]</span>
<span id="cb55-3"><a href="#cb55-3"></a>\begin{axis}[grid,ymin<span class="op">=-</span><span class="dv">2</span>,ymax<span class="op">=</span><span class="dv">2</span>,ytick<span class="op">=</span>{<span class="op">-</span><span class="dv">2</span>,<span class="op">-</span><span class="dv">1</span>,...,<span class="dv">2</span>},xmin<span class="op">=</span><span class="dv">0</span>,xmax<span class="op">=</span><span class="dv">1</span>]</span>
<span id="cb55-4"><a href="#cb55-4"></a>\addplot[color<span class="op">=</span>blue,thick,samples<span class="op">=</span><span class="dv">1000</span>]{<span class="bu">max</span>(<span class="bu">max</span>(<span class="dv">6</span><span class="op">*</span>x,<span class="dv">0</span>)<span class="op">+</span><span class="fl">0.70</span>,<span class="dv">0</span>)}<span class="op">;</span></span>
<span id="cb55-5"><a href="#cb55-5"></a>\addplot[color<span class="op">=</span>green,samples<span class="op">=</span><span class="dv">1000</span>,domain<span class="op">=</span><span class="dv">0</span>:<span class="dv">1</span>]{sin(deg(<span class="dv">2</span><span class="op">*</span><span class="fl">3.14</span><span class="op">*</span>x))}<span class="op">;</span></span>
<span id="cb55-6"><a href="#cb55-6"></a>\end{axis}</span>
<span id="cb55-7"><a href="#cb55-7"></a>\end{tikzpicture}</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-display" data-execution_count="47">
<div>
<figure class="figure">
<p><img src="index_files/figure-html/cell-48-output-1.svg" class="img-fluid figure-img"></p>
</figure>
</div>
</div>
</div>
<p>Now, we can set the weight for the second neuron to <span class="math inline">\(-1\)</span>, causing a deactivation point to occur, atleast horizontally, where we want it.</p>
<div class="cell" data-execution_count="48">
<details class="code-fold">
<summary>Show the code</summary>
<div class="sourceCode cell-code" id="cb56"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb56-1"><a href="#cb56-1"></a><span class="op">%%</span>itikz <span class="op">--</span>temp<span class="op">-</span><span class="bu">dir</span> <span class="op">--</span>tex<span class="op">-</span>packages<span class="op">=</span>tikz <span class="op">--</span>tikz<span class="op">-</span>libraries<span class="op">=</span>arrows <span class="op">--</span>implicit<span class="op">-</span>standalone</span>
<span id="cb56-2"><a href="#cb56-2"></a>\begin{tikzpicture}</span>
<span id="cb56-3"><a href="#cb56-3"></a></span>
<span id="cb56-4"><a href="#cb56-4"></a>\node[circle, </span>
<span id="cb56-5"><a href="#cb56-5"></a>    minimum size <span class="op">=</span> <span class="dv">15</span><span class="er">mm</span>,</span>
<span id="cb56-6"><a href="#cb56-6"></a>    fill<span class="op">=</span>red<span class="op">!</span><span class="dv">30</span></span>
<span id="cb56-7"><a href="#cb56-7"></a>    ] (Input) at (<span class="dv">0</span>,<span class="dv">0</span>) {\large $x_1$}<span class="op">;</span></span>
<span id="cb56-8"><a href="#cb56-8"></a></span>
<span id="cb56-9"><a href="#cb56-9"></a>\foreach \i <span class="kw">in</span> {<span class="dv">1</span>,<span class="dv">2</span>,...,<span class="dv">8</span>}</span>
<span id="cb56-10"><a href="#cb56-10"></a>{</span>
<span id="cb56-11"><a href="#cb56-11"></a>    \node[circle, </span>
<span id="cb56-12"><a href="#cb56-12"></a>        minimum size <span class="op">=</span> <span class="dv">15</span><span class="er">mm</span>,</span>
<span id="cb56-13"><a href="#cb56-13"></a>        fill<span class="op">=</span>blue<span class="op">!</span><span class="dv">50</span>,</span>
<span id="cb56-14"><a href="#cb56-14"></a>        yshift<span class="op">=</span><span class="dv">90</span> mm</span>
<span id="cb56-15"><a href="#cb56-15"></a>        ] (Hidden1<span class="op">-</span>\i) at (<span class="fl">3.0</span>,<span class="op">-</span>\i <span class="op">*</span> <span class="dv">2</span>) {\large $h_\i<span class="op">^</span>{(<span class="dv">1</span>)}$}<span class="op">;</span></span>
<span id="cb56-16"><a href="#cb56-16"></a>        </span>
<span id="cb56-17"><a href="#cb56-17"></a>}</span>
<span id="cb56-18"><a href="#cb56-18"></a>\foreach \i <span class="kw">in</span> {<span class="dv">1</span>,<span class="dv">2</span>,...,<span class="dv">8</span>}</span>
<span id="cb56-19"><a href="#cb56-19"></a>{</span>
<span id="cb56-20"><a href="#cb56-20"></a>    \node[circle, </span>
<span id="cb56-21"><a href="#cb56-21"></a>        minimum size <span class="op">=</span> <span class="dv">15</span><span class="er">mm</span>,</span>
<span id="cb56-22"><a href="#cb56-22"></a>        fill<span class="op">=</span>blue<span class="op">!</span><span class="dv">50</span>,</span>
<span id="cb56-23"><a href="#cb56-23"></a>        yshift<span class="op">=</span><span class="dv">90</span> mm</span>
<span id="cb56-24"><a href="#cb56-24"></a>        ] (Hidden2<span class="op">-</span>\i) at (<span class="fl">6.0</span>,<span class="op">-</span>\i <span class="op">*</span> <span class="dv">2</span>) {\large $h_\i<span class="op">^</span>{(<span class="dv">2</span>)}$}<span class="op">;</span></span>
<span id="cb56-25"><a href="#cb56-25"></a>        </span>
<span id="cb56-26"><a href="#cb56-26"></a>}</span>
<span id="cb56-27"><a href="#cb56-27"></a></span>
<span id="cb56-28"><a href="#cb56-28"></a>\node[circle, </span>
<span id="cb56-29"><a href="#cb56-29"></a>    minimum size <span class="op">=</span> <span class="dv">15</span><span class="er">mm</span>,</span>
<span id="cb56-30"><a href="#cb56-30"></a>    fill<span class="op">=</span>red<span class="op">!</span><span class="dv">30</span></span>
<span id="cb56-31"><a href="#cb56-31"></a>    ] (Output) at (<span class="dv">9</span>,<span class="dv">0</span>) {\large $\hat{y}_1$}<span class="op">;</span></span>
<span id="cb56-32"><a href="#cb56-32"></a></span>
<span id="cb56-33"><a href="#cb56-33"></a><span class="op">%</span> Connect neurons In<span class="op">-</span>Hidden1</span>
<span id="cb56-34"><a href="#cb56-34"></a>\foreach \j <span class="kw">in</span> {<span class="dv">2</span>,...,<span class="dv">8</span>}</span>
<span id="cb56-35"><a href="#cb56-35"></a>{</span>
<span id="cb56-36"><a href="#cb56-36"></a>    \draw[<span class="op">-&gt;</span>, shorten <span class="op">&gt;=</span><span class="dv">1</span><span class="er">pt</span>] (Input) <span class="op">--</span> (Hidden1<span class="op">-</span>\j)<span class="op">;</span>   </span>
<span id="cb56-37"><a href="#cb56-37"></a>}</span>
<span id="cb56-38"><a href="#cb56-38"></a><span class="op">%</span> Connect neurons Hidden1<span class="op">-</span>Hidden2</span>
<span id="cb56-39"><a href="#cb56-39"></a>\foreach \i <span class="kw">in</span> {<span class="dv">2</span>,...,<span class="dv">8</span>}</span>
<span id="cb56-40"><a href="#cb56-40"></a>{</span>
<span id="cb56-41"><a href="#cb56-41"></a>    </span>
<span id="cb56-42"><a href="#cb56-42"></a>        \draw[<span class="op">-&gt;</span>, shorten <span class="op">&gt;=</span><span class="dv">1</span><span class="er">pt</span>] (Hidden1<span class="op">-</span>\i) <span class="op">--</span> (Hidden2<span class="op">-</span>\i)<span class="op">;</span>   </span>
<span id="cb56-43"><a href="#cb56-43"></a>    </span>
<span id="cb56-44"><a href="#cb56-44"></a>}</span>
<span id="cb56-45"><a href="#cb56-45"></a></span>
<span id="cb56-46"><a href="#cb56-46"></a>\foreach \i <span class="kw">in</span> {<span class="dv">2</span>,...,<span class="dv">8</span>}</span>
<span id="cb56-47"><a href="#cb56-47"></a>{</span>
<span id="cb56-48"><a href="#cb56-48"></a>    </span>
<span id="cb56-49"><a href="#cb56-49"></a>        \draw[<span class="op">-&gt;</span>, shorten <span class="op">&gt;=</span><span class="dv">1</span><span class="er">pt</span>] (Hidden2<span class="op">-</span>\i) <span class="op">--</span> (Output)<span class="op">;</span>   </span>
<span id="cb56-50"><a href="#cb56-50"></a>}</span>
<span id="cb56-51"><a href="#cb56-51"></a>\draw[<span class="op">-&gt;</span>, shorten <span class="op">&gt;=</span><span class="dv">1</span><span class="er">pt</span>] (Input) <span class="op">--</span> node [midway] {$<span class="fl">6.00</span>$} (Hidden1<span class="op">-</span><span class="dv">1</span>)<span class="op">;</span>   </span>
<span id="cb56-52"><a href="#cb56-52"></a>\draw[<span class="op">-&gt;</span>, shorten <span class="op">&gt;=</span><span class="dv">1</span><span class="er">pt</span>] (Hidden1<span class="op">-</span><span class="dv">1</span>) <span class="op">--</span> node [midway,above] {$<span class="op">-</span><span class="fl">1.00</span>$} (Hidden2<span class="op">-</span><span class="dv">1</span>)<span class="op">;</span> </span>
<span id="cb56-53"><a href="#cb56-53"></a>\draw[<span class="op">-&gt;</span>, shorten <span class="op">&gt;=</span><span class="dv">1</span><span class="er">pt</span>] (Hidden2<span class="op">-</span><span class="dv">1</span>) <span class="op">--</span> node [midway] {$<span class="fl">1.00</span>$} (Output)<span class="op">;</span> </span>
<span id="cb56-54"><a href="#cb56-54"></a>\draw[<span class="op">-&gt;</span>, shorten <span class="op">&gt;=</span><span class="dv">1</span><span class="er">pt</span>] (<span class="dv">6</span>,<span class="dv">6</span>) node [below] {$<span class="fl">0.70</span>$} <span class="op">--</span>  (Hidden2<span class="op">-</span><span class="dv">1</span>)<span class="op">;</span> </span>
<span id="cb56-55"><a href="#cb56-55"></a>\draw[<span class="op">-&gt;</span>, shorten <span class="op">&gt;=</span><span class="dv">1</span><span class="er">pt</span>] (<span class="dv">3</span>,<span class="dv">6</span>) node [below] {$<span class="fl">0.00</span>$} <span class="op">--</span>  (Hidden1<span class="op">-</span><span class="dv">1</span>)<span class="op">;</span> </span>
<span id="cb56-56"><a href="#cb56-56"></a>\end{tikzpicture}</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-display" data-execution_count="48">
<div>
<figure class="figure">
<p><img src="index_files/figure-html/cell-49-output-1.svg" class="img-fluid figure-img"></p>
</figure>
</div>
</div>
</div>
<p>We get:</p>
<div class="cell" data-execution_count="49">
<details class="code-fold">
<summary>Show the code</summary>
<div class="sourceCode cell-code" id="cb57"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb57-1"><a href="#cb57-1"></a><span class="op">%%</span>itikz <span class="op">--</span>temp<span class="op">-</span><span class="bu">dir</span> <span class="op">--</span>tex<span class="op">-</span>packages<span class="op">=</span>tikz,pgfplots <span class="op">--</span>tikz<span class="op">-</span>libraries<span class="op">=</span>arrows <span class="op">--</span>implicit<span class="op">-</span>standalone</span>
<span id="cb57-2"><a href="#cb57-2"></a>\begin{tikzpicture}[scale<span class="op">=</span><span class="fl">1.5</span>]</span>
<span id="cb57-3"><a href="#cb57-3"></a>\begin{axis}[grid,ymin<span class="op">=-</span><span class="dv">2</span>,ymax<span class="op">=</span><span class="dv">2</span>,ytick<span class="op">=</span>{<span class="op">-</span><span class="dv">2</span>,<span class="op">-</span><span class="dv">1</span>,...,<span class="dv">2</span>},xmin<span class="op">=</span><span class="dv">0</span>,xmax<span class="op">=</span><span class="dv">1</span>]</span>
<span id="cb57-4"><a href="#cb57-4"></a>\addplot[color<span class="op">=</span>blue,thick,samples<span class="op">=</span><span class="dv">1000</span>]{<span class="bu">max</span>(<span class="op">-</span><span class="bu">max</span>(<span class="dv">6</span><span class="op">*</span>x,<span class="dv">0</span>)<span class="op">+</span><span class="fl">0.70</span>,<span class="dv">0</span>)}<span class="op">;</span></span>
<span id="cb57-5"><a href="#cb57-5"></a>\addplot[color<span class="op">=</span>green,samples<span class="op">=</span><span class="dv">1000</span>,domain<span class="op">=</span><span class="dv">0</span>:<span class="dv">1</span>]{sin(deg(<span class="dv">2</span><span class="op">*</span><span class="fl">3.14</span><span class="op">*</span>x))}<span class="op">;</span></span>
<span id="cb57-6"><a href="#cb57-6"></a>\end{axis}</span>
<span id="cb57-7"><a href="#cb57-7"></a>\end{tikzpicture}</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-display" data-execution_count="49">
<div>
<figure class="figure">
<p><img src="index_files/figure-html/cell-50-output-1.svg" class="img-fluid figure-img"></p>
</figure>
</div>
</div>
</div>
<p>Now, we’d like to flip this slope back. How might we flip the output of these two neurons?</p>
<div class="cell" data-execution_count="50">
<details class="code-fold">
<summary>Show the code</summary>
<div class="sourceCode cell-code" id="cb58"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb58-1"><a href="#cb58-1"></a><span class="op">%%</span>itikz <span class="op">--</span>temp<span class="op">-</span><span class="bu">dir</span> <span class="op">--</span>tex<span class="op">-</span>packages<span class="op">=</span>tikz <span class="op">--</span>tikz<span class="op">-</span>libraries<span class="op">=</span>arrows <span class="op">--</span>implicit<span class="op">-</span>standalone</span>
<span id="cb58-2"><a href="#cb58-2"></a>\begin{tikzpicture}</span>
<span id="cb58-3"><a href="#cb58-3"></a></span>
<span id="cb58-4"><a href="#cb58-4"></a>\node[circle, </span>
<span id="cb58-5"><a href="#cb58-5"></a>    minimum size <span class="op">=</span> <span class="dv">15</span><span class="er">mm</span>,</span>
<span id="cb58-6"><a href="#cb58-6"></a>    fill<span class="op">=</span>red<span class="op">!</span><span class="dv">30</span></span>
<span id="cb58-7"><a href="#cb58-7"></a>    ] (Input) at (<span class="dv">0</span>,<span class="dv">0</span>) {\large $x_1$}<span class="op">;</span></span>
<span id="cb58-8"><a href="#cb58-8"></a></span>
<span id="cb58-9"><a href="#cb58-9"></a>\foreach \i <span class="kw">in</span> {<span class="dv">1</span>,<span class="dv">2</span>,...,<span class="dv">8</span>}</span>
<span id="cb58-10"><a href="#cb58-10"></a>{</span>
<span id="cb58-11"><a href="#cb58-11"></a>    \node[circle, </span>
<span id="cb58-12"><a href="#cb58-12"></a>        minimum size <span class="op">=</span> <span class="dv">15</span><span class="er">mm</span>,</span>
<span id="cb58-13"><a href="#cb58-13"></a>        fill<span class="op">=</span>blue<span class="op">!</span><span class="dv">50</span>,</span>
<span id="cb58-14"><a href="#cb58-14"></a>        yshift<span class="op">=</span><span class="dv">90</span> mm</span>
<span id="cb58-15"><a href="#cb58-15"></a>        ] (Hidden1<span class="op">-</span>\i) at (<span class="fl">3.0</span>,<span class="op">-</span>\i <span class="op">*</span> <span class="dv">2</span>) {\large $h_\i<span class="op">^</span>{(<span class="dv">1</span>)}$}<span class="op">;</span></span>
<span id="cb58-16"><a href="#cb58-16"></a>        </span>
<span id="cb58-17"><a href="#cb58-17"></a>}</span>
<span id="cb58-18"><a href="#cb58-18"></a>\foreach \i <span class="kw">in</span> {<span class="dv">1</span>,<span class="dv">2</span>,...,<span class="dv">8</span>}</span>
<span id="cb58-19"><a href="#cb58-19"></a>{</span>
<span id="cb58-20"><a href="#cb58-20"></a>    \node[circle, </span>
<span id="cb58-21"><a href="#cb58-21"></a>        minimum size <span class="op">=</span> <span class="dv">15</span><span class="er">mm</span>,</span>
<span id="cb58-22"><a href="#cb58-22"></a>        fill<span class="op">=</span>blue<span class="op">!</span><span class="dv">50</span>,</span>
<span id="cb58-23"><a href="#cb58-23"></a>        yshift<span class="op">=</span><span class="dv">90</span> mm</span>
<span id="cb58-24"><a href="#cb58-24"></a>        ] (Hidden2<span class="op">-</span>\i) at (<span class="fl">6.0</span>,<span class="op">-</span>\i <span class="op">*</span> <span class="dv">2</span>) {\large $h_\i<span class="op">^</span>{(<span class="dv">2</span>)}$}<span class="op">;</span></span>
<span id="cb58-25"><a href="#cb58-25"></a>        </span>
<span id="cb58-26"><a href="#cb58-26"></a>}</span>
<span id="cb58-27"><a href="#cb58-27"></a></span>
<span id="cb58-28"><a href="#cb58-28"></a>\node[circle, </span>
<span id="cb58-29"><a href="#cb58-29"></a>    minimum size <span class="op">=</span> <span class="dv">15</span><span class="er">mm</span>,</span>
<span id="cb58-30"><a href="#cb58-30"></a>    fill<span class="op">=</span>red<span class="op">!</span><span class="dv">30</span></span>
<span id="cb58-31"><a href="#cb58-31"></a>    ] (Output) at (<span class="dv">9</span>,<span class="dv">0</span>) {\large $\hat{y}_1$}<span class="op">;</span></span>
<span id="cb58-32"><a href="#cb58-32"></a></span>
<span id="cb58-33"><a href="#cb58-33"></a><span class="op">%</span> Connect neurons In<span class="op">-</span>Hidden1</span>
<span id="cb58-34"><a href="#cb58-34"></a>\foreach \j <span class="kw">in</span> {<span class="dv">2</span>,...,<span class="dv">8</span>}</span>
<span id="cb58-35"><a href="#cb58-35"></a>{</span>
<span id="cb58-36"><a href="#cb58-36"></a>    \draw[<span class="op">-&gt;</span>, shorten <span class="op">&gt;=</span><span class="dv">1</span><span class="er">pt</span>] (Input) <span class="op">--</span> (Hidden1<span class="op">-</span>\j)<span class="op">;</span>   </span>
<span id="cb58-37"><a href="#cb58-37"></a>}</span>
<span id="cb58-38"><a href="#cb58-38"></a><span class="op">%</span> Connect neurons Hidden1<span class="op">-</span>Hidden2</span>
<span id="cb58-39"><a href="#cb58-39"></a>\foreach \i <span class="kw">in</span> {<span class="dv">2</span>,...,<span class="dv">8</span>}</span>
<span id="cb58-40"><a href="#cb58-40"></a>{</span>
<span id="cb58-41"><a href="#cb58-41"></a>    </span>
<span id="cb58-42"><a href="#cb58-42"></a>        \draw[<span class="op">-&gt;</span>, shorten <span class="op">&gt;=</span><span class="dv">1</span><span class="er">pt</span>] (Hidden1<span class="op">-</span>\i) <span class="op">--</span> (Hidden2<span class="op">-</span>\i)<span class="op">;</span>   </span>
<span id="cb58-43"><a href="#cb58-43"></a>    </span>
<span id="cb58-44"><a href="#cb58-44"></a>}</span>
<span id="cb58-45"><a href="#cb58-45"></a></span>
<span id="cb58-46"><a href="#cb58-46"></a>\foreach \i <span class="kw">in</span> {<span class="dv">2</span>,...,<span class="dv">8</span>}</span>
<span id="cb58-47"><a href="#cb58-47"></a>{</span>
<span id="cb58-48"><a href="#cb58-48"></a>    </span>
<span id="cb58-49"><a href="#cb58-49"></a>        \draw[<span class="op">-&gt;</span>, shorten <span class="op">&gt;=</span><span class="dv">1</span><span class="er">pt</span>] (Hidden2<span class="op">-</span>\i) <span class="op">--</span> (Output)<span class="op">;</span>   </span>
<span id="cb58-50"><a href="#cb58-50"></a>}</span>
<span id="cb58-51"><a href="#cb58-51"></a>\draw[<span class="op">-&gt;</span>, shorten <span class="op">&gt;=</span><span class="dv">1</span><span class="er">pt</span>] (Input) <span class="op">--</span> node [midway] {$<span class="fl">6.00</span>$} (Hidden1<span class="op">-</span><span class="dv">1</span>)<span class="op">;</span>   </span>
<span id="cb58-52"><a href="#cb58-52"></a>\draw[<span class="op">-&gt;</span>, shorten <span class="op">&gt;=</span><span class="dv">1</span><span class="er">pt</span>] (Hidden1<span class="op">-</span><span class="dv">1</span>) <span class="op">--</span> node [midway,above] {$<span class="op">-</span><span class="fl">1.00</span>$} (Hidden2<span class="op">-</span><span class="dv">1</span>)<span class="op">;</span> </span>
<span id="cb58-53"><a href="#cb58-53"></a>\draw[<span class="op">-&gt;</span>, shorten <span class="op">&gt;=</span><span class="dv">1</span><span class="er">pt</span>] (Hidden2<span class="op">-</span><span class="dv">1</span>) <span class="op">--</span> node [midway] {$<span class="op">-</span><span class="fl">1.00</span>$} (Output)<span class="op">;</span> </span>
<span id="cb58-54"><a href="#cb58-54"></a>\draw[<span class="op">-&gt;</span>, shorten <span class="op">&gt;=</span><span class="dv">1</span><span class="er">pt</span>] (<span class="dv">6</span>,<span class="dv">6</span>) node [below] {$<span class="fl">0.70</span>$} <span class="op">--</span>  (Hidden2<span class="op">-</span><span class="dv">1</span>)<span class="op">;</span> </span>
<span id="cb58-55"><a href="#cb58-55"></a>\draw[<span class="op">-&gt;</span>, shorten <span class="op">&gt;=</span><span class="dv">1</span><span class="er">pt</span>] (<span class="dv">3</span>,<span class="dv">6</span>) node [below] {$<span class="fl">0.00</span>$} <span class="op">--</span>  (Hidden1<span class="op">-</span><span class="dv">1</span>)<span class="op">;</span> </span>
<span id="cb58-56"><a href="#cb58-56"></a>\end{tikzpicture}</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-display" data-execution_count="50">
<div>
<figure class="figure">
<p><img src="index_files/figure-html/cell-51-output-1.svg" class="img-fluid figure-img"></p>
</figure>
</div>
</div>
</div>
<p>It seems like we can take the weights of the connection to the output neuron, which is currently <span class="math inline">\(1.0\)</span> and just flip it to a <span class="math inline">\(-1\)</span>, and that flips the function:</p>
<div class="cell" data-execution_count="51">
<details class="code-fold">
<summary>Show the code</summary>
<div class="sourceCode cell-code" id="cb59"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb59-1"><a href="#cb59-1"></a><span class="op">%%</span>itikz <span class="op">--</span>temp<span class="op">-</span><span class="bu">dir</span> <span class="op">--</span>tex<span class="op">-</span>packages<span class="op">=</span>tikz,pgfplots <span class="op">--</span>tikz<span class="op">-</span>libraries<span class="op">=</span>arrows <span class="op">--</span>implicit<span class="op">-</span>standalone</span>
<span id="cb59-2"><a href="#cb59-2"></a>\begin{tikzpicture}[scale<span class="op">=</span><span class="fl">1.5</span>]</span>
<span id="cb59-3"><a href="#cb59-3"></a>\begin{axis}[grid,ymin<span class="op">=-</span><span class="dv">2</span>,ymax<span class="op">=</span><span class="dv">2</span>,ytick<span class="op">=</span>{<span class="op">-</span><span class="dv">2</span>,<span class="op">-</span><span class="dv">1</span>,...,<span class="dv">2</span>},xmin<span class="op">=</span><span class="dv">0</span>,xmax<span class="op">=</span><span class="dv">1</span>]</span>
<span id="cb59-4"><a href="#cb59-4"></a>\addplot[color<span class="op">=</span>blue,thick,samples<span class="op">=</span><span class="dv">1000</span>]{<span class="op">-</span><span class="bu">max</span>(<span class="op">-</span><span class="bu">max</span>(<span class="dv">6</span><span class="op">*</span>x,<span class="dv">0</span>)<span class="op">+</span><span class="fl">0.70</span>,<span class="dv">0</span>)}<span class="op">;</span></span>
<span id="cb59-5"><a href="#cb59-5"></a>\addplot[color<span class="op">=</span>green,samples<span class="op">=</span><span class="dv">1000</span>,domain<span class="op">=</span><span class="dv">0</span>:<span class="dv">1</span>]{sin(deg(<span class="dv">2</span><span class="op">*</span><span class="fl">3.14</span><span class="op">*</span>x))}<span class="op">;</span></span>
<span id="cb59-6"><a href="#cb59-6"></a>\end{axis}</span>
<span id="cb59-7"><a href="#cb59-7"></a>\end{tikzpicture}</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-display" data-execution_count="51">
<div>
<figure class="figure">
<p><img src="index_files/figure-html/cell-52-output-1.svg" class="img-fluid figure-img"></p>
</figure>
</div>
</div>
</div>
<p>We’re certainly getting closer to making this first section fit how we want. Now, all we need to do is offset this up a bit. For this hand-optimized example, we’re going to use the first <span class="math inline">\(7\)</span> pairs of neurons in the hidden layers to create the sine wave’s shape.</p>
<div class="cell" data-execution_count="52">
<details class="code-fold">
<summary>Show the code</summary>
<div class="sourceCode cell-code" id="cb60"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb60-1"><a href="#cb60-1"></a><span class="op">%%</span>itikz <span class="op">--</span>temp<span class="op">-</span><span class="bu">dir</span> <span class="op">--</span>tex<span class="op">-</span>packages<span class="op">=</span>tikz <span class="op">--</span>tikz<span class="op">-</span>libraries<span class="op">=</span>arrows <span class="op">--</span>implicit<span class="op">-</span>standalone</span>
<span id="cb60-2"><a href="#cb60-2"></a>\begin{tikzpicture}</span>
<span id="cb60-3"><a href="#cb60-3"></a></span>
<span id="cb60-4"><a href="#cb60-4"></a>\node[circle, </span>
<span id="cb60-5"><a href="#cb60-5"></a>    minimum size <span class="op">=</span> <span class="dv">15</span><span class="er">mm</span>,</span>
<span id="cb60-6"><a href="#cb60-6"></a>    fill<span class="op">=</span>red<span class="op">!</span><span class="dv">30</span></span>
<span id="cb60-7"><a href="#cb60-7"></a>    ] (Input) at (<span class="dv">0</span>,<span class="dv">0</span>) {\large $x_1$}<span class="op">;</span></span>
<span id="cb60-8"><a href="#cb60-8"></a></span>
<span id="cb60-9"><a href="#cb60-9"></a>\foreach \i <span class="kw">in</span> {<span class="dv">1</span>,<span class="dv">2</span>,...,<span class="dv">8</span>}</span>
<span id="cb60-10"><a href="#cb60-10"></a>{</span>
<span id="cb60-11"><a href="#cb60-11"></a>    \node[circle, </span>
<span id="cb60-12"><a href="#cb60-12"></a>        minimum size <span class="op">=</span> <span class="dv">15</span><span class="er">mm</span>,</span>
<span id="cb60-13"><a href="#cb60-13"></a>        fill<span class="op">=</span>blue<span class="op">!</span><span class="dv">50</span>,</span>
<span id="cb60-14"><a href="#cb60-14"></a>        yshift<span class="op">=</span><span class="dv">90</span> mm</span>
<span id="cb60-15"><a href="#cb60-15"></a>        ] (Hidden1<span class="op">-</span>\i) at (<span class="fl">3.0</span>,<span class="op">-</span>\i <span class="op">*</span> <span class="dv">2</span>) {\large $h_\i<span class="op">^</span>{(<span class="dv">1</span>)}$}<span class="op">;</span></span>
<span id="cb60-16"><a href="#cb60-16"></a>        </span>
<span id="cb60-17"><a href="#cb60-17"></a>}</span>
<span id="cb60-18"><a href="#cb60-18"></a>\foreach \i <span class="kw">in</span> {<span class="dv">1</span>,<span class="dv">2</span>,...,<span class="dv">8</span>}</span>
<span id="cb60-19"><a href="#cb60-19"></a>{</span>
<span id="cb60-20"><a href="#cb60-20"></a>    \node[circle, </span>
<span id="cb60-21"><a href="#cb60-21"></a>        minimum size <span class="op">=</span> <span class="dv">15</span><span class="er">mm</span>,</span>
<span id="cb60-22"><a href="#cb60-22"></a>        fill<span class="op">=</span>blue<span class="op">!</span><span class="dv">50</span>,</span>
<span id="cb60-23"><a href="#cb60-23"></a>        yshift<span class="op">=</span><span class="dv">90</span> mm</span>
<span id="cb60-24"><a href="#cb60-24"></a>        ] (Hidden2<span class="op">-</span>\i) at (<span class="fl">6.0</span>,<span class="op">-</span>\i <span class="op">*</span> <span class="dv">2</span>) {\large $h_\i<span class="op">^</span>{(<span class="dv">2</span>)}$}<span class="op">;</span></span>
<span id="cb60-25"><a href="#cb60-25"></a>        </span>
<span id="cb60-26"><a href="#cb60-26"></a>}</span>
<span id="cb60-27"><a href="#cb60-27"></a></span>
<span id="cb60-28"><a href="#cb60-28"></a>\node[circle, </span>
<span id="cb60-29"><a href="#cb60-29"></a>    minimum size <span class="op">=</span> <span class="dv">15</span><span class="er">mm</span>,</span>
<span id="cb60-30"><a href="#cb60-30"></a>    fill<span class="op">=</span>red<span class="op">!</span><span class="dv">30</span></span>
<span id="cb60-31"><a href="#cb60-31"></a>    ] (Output) at (<span class="dv">9</span>,<span class="dv">0</span>) {\large $\hat{y}_1$}<span class="op">;</span></span>
<span id="cb60-32"><a href="#cb60-32"></a></span>
<span id="cb60-33"><a href="#cb60-33"></a><span class="op">%</span> Connect neurons In<span class="op">-</span>Hidden1</span>
<span id="cb60-34"><a href="#cb60-34"></a>\foreach \j <span class="kw">in</span> {<span class="dv">2</span>,...,<span class="dv">7</span>}</span>
<span id="cb60-35"><a href="#cb60-35"></a>{</span>
<span id="cb60-36"><a href="#cb60-36"></a>    \draw[<span class="op">-&gt;</span>, shorten <span class="op">&gt;=</span><span class="dv">1</span><span class="er">pt</span>] (Input) <span class="op">--</span> (Hidden1<span class="op">-</span>\j)<span class="op">;</span>   </span>
<span id="cb60-37"><a href="#cb60-37"></a>}</span>
<span id="cb60-38"><a href="#cb60-38"></a><span class="op">%</span> Connect neurons Hidden1<span class="op">-</span>Hidden2</span>
<span id="cb60-39"><a href="#cb60-39"></a>\foreach \i <span class="kw">in</span> {<span class="dv">2</span>,...,<span class="dv">7</span>}</span>
<span id="cb60-40"><a href="#cb60-40"></a>{</span>
<span id="cb60-41"><a href="#cb60-41"></a>    </span>
<span id="cb60-42"><a href="#cb60-42"></a>        \draw[<span class="op">-&gt;</span>, shorten <span class="op">&gt;=</span><span class="dv">1</span><span class="er">pt</span>] (Hidden1<span class="op">-</span>\i) <span class="op">--</span> (Hidden2<span class="op">-</span>\i)<span class="op">;</span>   </span>
<span id="cb60-43"><a href="#cb60-43"></a>    </span>
<span id="cb60-44"><a href="#cb60-44"></a>}</span>
<span id="cb60-45"><a href="#cb60-45"></a></span>
<span id="cb60-46"><a href="#cb60-46"></a>\foreach \i <span class="kw">in</span> {<span class="dv">2</span>,...,<span class="dv">7</span>}</span>
<span id="cb60-47"><a href="#cb60-47"></a>{</span>
<span id="cb60-48"><a href="#cb60-48"></a>    </span>
<span id="cb60-49"><a href="#cb60-49"></a>        \draw[<span class="op">-&gt;</span>, shorten <span class="op">&gt;=</span><span class="dv">1</span><span class="er">pt</span>] (Hidden2<span class="op">-</span>\i) <span class="op">--</span> (Output)<span class="op">;</span>   </span>
<span id="cb60-50"><a href="#cb60-50"></a>}</span>
<span id="cb60-51"><a href="#cb60-51"></a>\draw[<span class="op">-&gt;</span>, shorten <span class="op">&gt;=</span><span class="dv">1</span><span class="er">pt</span>] (Input) <span class="op">--</span> node [midway] {$<span class="fl">6.00</span>$} (Hidden1<span class="op">-</span><span class="dv">1</span>)<span class="op">;</span>   </span>
<span id="cb60-52"><a href="#cb60-52"></a>\draw[<span class="op">-&gt;</span>, shorten <span class="op">&gt;=</span><span class="dv">1</span><span class="er">pt</span>] (Hidden1<span class="op">-</span><span class="dv">1</span>) <span class="op">--</span> node [midway,above] {$<span class="op">-</span><span class="fl">1.00</span>$} (Hidden2<span class="op">-</span><span class="dv">1</span>)<span class="op">;</span> </span>
<span id="cb60-53"><a href="#cb60-53"></a>\draw[<span class="op">-&gt;</span>, shorten <span class="op">&gt;=</span><span class="dv">1</span><span class="er">pt</span>] (Hidden2<span class="op">-</span><span class="dv">1</span>) <span class="op">--</span> node [midway] {$<span class="op">-</span><span class="fl">1.00</span>$} (Output)<span class="op">;</span> </span>
<span id="cb60-54"><a href="#cb60-54"></a>\draw[<span class="op">-&gt;</span>, shorten <span class="op">&gt;=</span><span class="dv">1</span><span class="er">pt</span>] (<span class="dv">6</span>,<span class="dv">6</span>) node [below] {$<span class="fl">0.70</span>$} <span class="op">--</span>  (Hidden2<span class="op">-</span><span class="dv">1</span>)<span class="op">;</span> </span>
<span id="cb60-55"><a href="#cb60-55"></a>\draw[<span class="op">-&gt;</span>, shorten <span class="op">&gt;=</span><span class="dv">1</span><span class="er">pt</span>] (<span class="dv">3</span>,<span class="dv">6</span>) node [below] {$<span class="fl">0.00</span>$} <span class="op">--</span>  (Hidden1<span class="op">-</span><span class="dv">1</span>)<span class="op">;</span> </span>
<span id="cb60-56"><a href="#cb60-56"></a></span>
<span id="cb60-57"><a href="#cb60-57"></a>\draw[<span class="op">-&gt;</span>, shorten <span class="op">&gt;=</span><span class="dv">1</span><span class="er">pt</span>] (Input) <span class="op">--</span> node [midway] {$<span class="fl">0.00</span>$} (Hidden1<span class="op">-</span><span class="dv">8</span>)<span class="op">;</span> </span>
<span id="cb60-58"><a href="#cb60-58"></a>\draw[<span class="op">-&gt;</span>, shorten <span class="op">&gt;=</span><span class="dv">1</span><span class="er">pt</span>] (<span class="dv">3</span>,<span class="op">-</span><span class="dv">9</span>) node [below] {$<span class="fl">0.00</span>$} <span class="op">--</span>  (Hidden1<span class="op">-</span><span class="dv">8</span>)<span class="op">;</span> </span>
<span id="cb60-59"><a href="#cb60-59"></a>\draw[<span class="op">-&gt;</span>, shorten <span class="op">&gt;=</span><span class="dv">1</span><span class="er">pt</span>] (Hidden1<span class="op">-</span><span class="dv">8</span>) <span class="op">--</span> node [midway,above] {$<span class="fl">0.00</span>$} (Hidden2<span class="op">-</span><span class="dv">8</span>)<span class="op">;</span> </span>
<span id="cb60-60"><a href="#cb60-60"></a>\draw[<span class="op">-&gt;</span>, shorten <span class="op">&gt;=</span><span class="dv">1</span><span class="er">pt</span>] (<span class="dv">6</span>,<span class="op">-</span><span class="dv">9</span>) node [below] {$<span class="fl">1.00</span>$} <span class="op">--</span>  (Hidden2<span class="op">-</span><span class="dv">8</span>)<span class="op">;</span> </span>
<span id="cb60-61"><a href="#cb60-61"></a>\draw[<span class="op">-&gt;</span>, shorten <span class="op">&gt;=</span><span class="dv">1</span><span class="er">pt</span>] (Hidden2<span class="op">-</span><span class="dv">8</span>) <span class="op">--</span> node [midway] {$<span class="fl">0.70</span>$} (Output)<span class="op">;</span> </span>
<span id="cb60-62"><a href="#cb60-62"></a>\end{tikzpicture}</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-display" data-execution_count="52">
<div>
<figure class="figure">
<p><img src="index_files/figure-html/cell-53-output-1.svg" class="img-fluid figure-img"></p>
</figure>
</div>
</div>
</div>
<p>If we set the bias of the second neuron in the bottom pair to <span class="math inline">\(1.0\)</span> and the weight to the output neuron to <span class="math inline">\(0.70\)</span>, we can vertically shift the line like so:</p>
<div class="cell" data-execution_count="53">
<details class="code-fold">
<summary>Show the code</summary>
<div class="sourceCode cell-code" id="cb61"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb61-1"><a href="#cb61-1"></a><span class="op">%%</span>itikz <span class="op">--</span>temp<span class="op">-</span><span class="bu">dir</span> <span class="op">--</span>tex<span class="op">-</span>packages<span class="op">=</span>tikz,pgfplots <span class="op">--</span>tikz<span class="op">-</span>libraries<span class="op">=</span>arrows <span class="op">--</span>implicit<span class="op">-</span>standalone</span>
<span id="cb61-2"><a href="#cb61-2"></a>\begin{tikzpicture}[scale<span class="op">=</span><span class="fl">1.5</span>]</span>
<span id="cb61-3"><a href="#cb61-3"></a>\begin{axis}[grid,ymin<span class="op">=-</span><span class="dv">2</span>,ymax<span class="op">=</span><span class="dv">2</span>,ytick<span class="op">=</span>{<span class="op">-</span><span class="dv">2</span>,<span class="op">-</span><span class="dv">1</span>,...,<span class="dv">2</span>},xmin<span class="op">=</span><span class="dv">0</span>,xmax<span class="op">=</span><span class="dv">1</span>]</span>
<span id="cb61-4"><a href="#cb61-4"></a>\addplot[color<span class="op">=</span>blue,thick,samples<span class="op">=</span><span class="dv">1000</span>]{<span class="op">-</span><span class="bu">max</span>(<span class="op">-</span><span class="bu">max</span>(<span class="dv">6</span><span class="op">*</span>x,<span class="dv">0</span>)<span class="op">+</span><span class="fl">0.70</span>,<span class="dv">0</span>))<span class="op">+</span><span class="fl">0.70</span>}<span class="op">;</span></span>
<span id="cb61-5"><a href="#cb61-5"></a>\addplot[color<span class="op">=</span>green,samples<span class="op">=</span><span class="dv">1000</span>,domain<span class="op">=</span><span class="dv">0</span>:<span class="dv">1</span>]{sin(deg(<span class="dv">2</span><span class="op">*</span><span class="fl">3.14</span><span class="op">*</span>x))}<span class="op">;</span></span>
<span id="cb61-6"><a href="#cb61-6"></a>\end{axis}</span>
<span id="cb61-7"><a href="#cb61-7"></a>\end{tikzpicture}</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-display" data-execution_count="53">
<div>
<figure class="figure">
<p><img src="index_files/figure-html/cell-54-output-1.svg" class="img-fluid figure-img"></p>
</figure>
</div>
</div>
</div>
<p>At this point, we have completed the first section with an “area of effect” being the first upward section of the sine wave. We can start on the next section that we wish to do. We can start on the next section that we wish to do. We can start by setting all weights for this second pair of neurons to <span class="math inline">\(1\)</span> including the output neuron.</p>
<div class="cell" data-execution_count="54">
<details class="code-fold">
<summary>Show the code</summary>
<div class="sourceCode cell-code" id="cb62"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb62-1"><a href="#cb62-1"></a><span class="op">%%</span>itikz <span class="op">--</span>temp<span class="op">-</span><span class="bu">dir</span> <span class="op">--</span>tex<span class="op">-</span>packages<span class="op">=</span>tikz <span class="op">--</span>tikz<span class="op">-</span>libraries<span class="op">=</span>arrows <span class="op">--</span>implicit<span class="op">-</span>standalone</span>
<span id="cb62-2"><a href="#cb62-2"></a>\begin{tikzpicture}</span>
<span id="cb62-3"><a href="#cb62-3"></a></span>
<span id="cb62-4"><a href="#cb62-4"></a>\node[circle, </span>
<span id="cb62-5"><a href="#cb62-5"></a>    minimum size <span class="op">=</span> <span class="dv">15</span><span class="er">mm</span>,</span>
<span id="cb62-6"><a href="#cb62-6"></a>    fill<span class="op">=</span>red<span class="op">!</span><span class="dv">30</span></span>
<span id="cb62-7"><a href="#cb62-7"></a>    ] (Input) at (<span class="dv">0</span>,<span class="dv">0</span>) {\large $x_1$}<span class="op">;</span></span>
<span id="cb62-8"><a href="#cb62-8"></a></span>
<span id="cb62-9"><a href="#cb62-9"></a>\foreach \i <span class="kw">in</span> {<span class="dv">1</span>,<span class="dv">2</span>,...,<span class="dv">8</span>}</span>
<span id="cb62-10"><a href="#cb62-10"></a>{</span>
<span id="cb62-11"><a href="#cb62-11"></a>    \node[circle, </span>
<span id="cb62-12"><a href="#cb62-12"></a>        minimum size <span class="op">=</span> <span class="dv">15</span><span class="er">mm</span>,</span>
<span id="cb62-13"><a href="#cb62-13"></a>        fill<span class="op">=</span>blue<span class="op">!</span><span class="dv">50</span>,</span>
<span id="cb62-14"><a href="#cb62-14"></a>        yshift<span class="op">=</span><span class="dv">90</span> mm</span>
<span id="cb62-15"><a href="#cb62-15"></a>        ] (Hidden1<span class="op">-</span>\i) at (<span class="fl">3.0</span>,<span class="op">-</span>\i <span class="op">*</span> <span class="dv">2</span>) {\large $h_\i<span class="op">^</span>{(<span class="dv">1</span>)}$}<span class="op">;</span></span>
<span id="cb62-16"><a href="#cb62-16"></a>        </span>
<span id="cb62-17"><a href="#cb62-17"></a>}</span>
<span id="cb62-18"><a href="#cb62-18"></a>\foreach \i <span class="kw">in</span> {<span class="dv">1</span>,<span class="dv">2</span>,...,<span class="dv">8</span>}</span>
<span id="cb62-19"><a href="#cb62-19"></a>{</span>
<span id="cb62-20"><a href="#cb62-20"></a>    \node[circle, </span>
<span id="cb62-21"><a href="#cb62-21"></a>        minimum size <span class="op">=</span> <span class="dv">15</span><span class="er">mm</span>,</span>
<span id="cb62-22"><a href="#cb62-22"></a>        fill<span class="op">=</span>blue<span class="op">!</span><span class="dv">50</span>,</span>
<span id="cb62-23"><a href="#cb62-23"></a>        yshift<span class="op">=</span><span class="dv">90</span> mm</span>
<span id="cb62-24"><a href="#cb62-24"></a>        ] (Hidden2<span class="op">-</span>\i) at (<span class="fl">6.0</span>,<span class="op">-</span>\i <span class="op">*</span> <span class="dv">2</span>) {\large $h_\i<span class="op">^</span>{(<span class="dv">2</span>)}$}<span class="op">;</span></span>
<span id="cb62-25"><a href="#cb62-25"></a>        </span>
<span id="cb62-26"><a href="#cb62-26"></a>}</span>
<span id="cb62-27"><a href="#cb62-27"></a></span>
<span id="cb62-28"><a href="#cb62-28"></a>\node[circle, </span>
<span id="cb62-29"><a href="#cb62-29"></a>    minimum size <span class="op">=</span> <span class="dv">15</span><span class="er">mm</span>,</span>
<span id="cb62-30"><a href="#cb62-30"></a>    fill<span class="op">=</span>red<span class="op">!</span><span class="dv">30</span></span>
<span id="cb62-31"><a href="#cb62-31"></a>    ] (Output) at (<span class="dv">9</span>,<span class="dv">0</span>) {\large $\hat{y}_1$}<span class="op">;</span></span>
<span id="cb62-32"><a href="#cb62-32"></a></span>
<span id="cb62-33"><a href="#cb62-33"></a><span class="op">%</span> Connect neurons In<span class="op">-</span>Hidden1</span>
<span id="cb62-34"><a href="#cb62-34"></a>\foreach \j <span class="kw">in</span> {<span class="dv">3</span>,...,<span class="dv">7</span>}</span>
<span id="cb62-35"><a href="#cb62-35"></a>{</span>
<span id="cb62-36"><a href="#cb62-36"></a>    \draw[<span class="op">-&gt;</span>, shorten <span class="op">&gt;=</span><span class="dv">1</span><span class="er">pt</span>] (Input) <span class="op">--</span> (Hidden1<span class="op">-</span>\j)<span class="op">;</span>   </span>
<span id="cb62-37"><a href="#cb62-37"></a>}</span>
<span id="cb62-38"><a href="#cb62-38"></a><span class="op">%</span> Connect neurons Hidden1<span class="op">-</span>Hidden2</span>
<span id="cb62-39"><a href="#cb62-39"></a>\foreach \i <span class="kw">in</span> {<span class="dv">3</span>,...,<span class="dv">7</span>}</span>
<span id="cb62-40"><a href="#cb62-40"></a>{</span>
<span id="cb62-41"><a href="#cb62-41"></a>    </span>
<span id="cb62-42"><a href="#cb62-42"></a>        \draw[<span class="op">-&gt;</span>, shorten <span class="op">&gt;=</span><span class="dv">1</span><span class="er">pt</span>] (Hidden1<span class="op">-</span>\i) <span class="op">--</span> (Hidden2<span class="op">-</span>\i)<span class="op">;</span>   </span>
<span id="cb62-43"><a href="#cb62-43"></a>    </span>
<span id="cb62-44"><a href="#cb62-44"></a>}</span>
<span id="cb62-45"><a href="#cb62-45"></a></span>
<span id="cb62-46"><a href="#cb62-46"></a>\foreach \i <span class="kw">in</span> {<span class="dv">3</span>,...,<span class="dv">7</span>}</span>
<span id="cb62-47"><a href="#cb62-47"></a>{</span>
<span id="cb62-48"><a href="#cb62-48"></a>    </span>
<span id="cb62-49"><a href="#cb62-49"></a>        \draw[<span class="op">-&gt;</span>, shorten <span class="op">&gt;=</span><span class="dv">1</span><span class="er">pt</span>] (Hidden2<span class="op">-</span>\i) <span class="op">--</span> (Output)<span class="op">;</span>   </span>
<span id="cb62-50"><a href="#cb62-50"></a>}</span>
<span id="cb62-51"><a href="#cb62-51"></a>\draw[<span class="op">-&gt;</span>, shorten <span class="op">&gt;=</span><span class="dv">1</span><span class="er">pt</span>] (Input) <span class="op">--</span> node [midway] {$<span class="fl">6.00</span>$} (Hidden1<span class="op">-</span><span class="dv">1</span>)<span class="op">;</span>   </span>
<span id="cb62-52"><a href="#cb62-52"></a>\draw[<span class="op">-&gt;</span>, shorten <span class="op">&gt;=</span><span class="dv">1</span><span class="er">pt</span>] (Hidden1<span class="op">-</span><span class="dv">1</span>) <span class="op">--</span> node [midway,above] {$<span class="op">-</span><span class="fl">1.00</span>$} (Hidden2<span class="op">-</span><span class="dv">1</span>)<span class="op">;</span> </span>
<span id="cb62-53"><a href="#cb62-53"></a>\draw[<span class="op">-&gt;</span>, shorten <span class="op">&gt;=</span><span class="dv">1</span><span class="er">pt</span>] (Hidden2<span class="op">-</span><span class="dv">1</span>) <span class="op">--</span> node [midway] {$<span class="op">-</span><span class="fl">1.00</span>$} (Output)<span class="op">;</span> </span>
<span id="cb62-54"><a href="#cb62-54"></a>\draw[<span class="op">-&gt;</span>, shorten <span class="op">&gt;=</span><span class="dv">1</span><span class="er">pt</span>] (<span class="dv">6</span>,<span class="dv">6</span>) node [below] {$<span class="fl">0.70</span>$} <span class="op">--</span>  (Hidden2<span class="op">-</span><span class="dv">1</span>)<span class="op">;</span> </span>
<span id="cb62-55"><a href="#cb62-55"></a>\draw[<span class="op">-&gt;</span>, shorten <span class="op">&gt;=</span><span class="dv">1</span><span class="er">pt</span>] (<span class="dv">3</span>,<span class="dv">6</span>) node [below] {$<span class="fl">0.00</span>$} <span class="op">--</span>  (Hidden1<span class="op">-</span><span class="dv">1</span>)<span class="op">;</span> </span>
<span id="cb62-56"><a href="#cb62-56"></a></span>
<span id="cb62-57"><a href="#cb62-57"></a>\draw[<span class="op">-&gt;</span>, shorten <span class="op">&gt;=</span><span class="dv">1</span><span class="er">pt</span>] (Input) <span class="op">--</span> node [midway] {$<span class="fl">0.00</span>$} (Hidden1<span class="op">-</span><span class="dv">8</span>)<span class="op">;</span> </span>
<span id="cb62-58"><a href="#cb62-58"></a>\draw[<span class="op">-&gt;</span>, shorten <span class="op">&gt;=</span><span class="dv">1</span><span class="er">pt</span>] (<span class="dv">3</span>,<span class="op">-</span><span class="dv">9</span>) node [below] {$<span class="fl">0.00</span>$} <span class="op">--</span>  (Hidden1<span class="op">-</span><span class="dv">8</span>)<span class="op">;</span> </span>
<span id="cb62-59"><a href="#cb62-59"></a>\draw[<span class="op">-&gt;</span>, shorten <span class="op">&gt;=</span><span class="dv">1</span><span class="er">pt</span>] (Hidden1<span class="op">-</span><span class="dv">8</span>) <span class="op">--</span> node [midway,above] {$<span class="fl">0.00</span>$} (Hidden2<span class="op">-</span><span class="dv">8</span>)<span class="op">;</span> </span>
<span id="cb62-60"><a href="#cb62-60"></a>\draw[<span class="op">-&gt;</span>, shorten <span class="op">&gt;=</span><span class="dv">1</span><span class="er">pt</span>] (<span class="dv">6</span>,<span class="op">-</span><span class="dv">9</span>) node [below] {$<span class="fl">1.00</span>$} <span class="op">--</span>  (Hidden2<span class="op">-</span><span class="dv">8</span>)<span class="op">;</span> </span>
<span id="cb62-61"><a href="#cb62-61"></a>\draw[<span class="op">-&gt;</span>, shorten <span class="op">&gt;=</span><span class="dv">1</span><span class="er">pt</span>] (Hidden2<span class="op">-</span><span class="dv">8</span>) <span class="op">--</span> node [midway] {$<span class="fl">0.70</span>$} (Output)<span class="op">;</span> </span>
<span id="cb62-62"><a href="#cb62-62"></a></span>
<span id="cb62-63"><a href="#cb62-63"></a>\draw[<span class="op">-&gt;</span>, shorten <span class="op">&gt;=</span><span class="dv">1</span><span class="er">pt</span>] (Input) <span class="op">--</span> node [midway] {$<span class="fl">1.00</span>$} (Hidden1<span class="op">-</span><span class="dv">2</span>)<span class="op">;</span> </span>
<span id="cb62-64"><a href="#cb62-64"></a>\draw[<span class="op">-&gt;</span>, shorten <span class="op">&gt;=</span><span class="dv">1</span><span class="er">pt</span>] (<span class="dv">3</span>,<span class="dv">4</span>) node [below] {$<span class="fl">0.00</span>$} <span class="op">--</span>  (Hidden1<span class="op">-</span><span class="dv">2</span>)<span class="op">;</span> </span>
<span id="cb62-65"><a href="#cb62-65"></a>\draw[<span class="op">-&gt;</span>, shorten <span class="op">&gt;=</span><span class="dv">1</span><span class="er">pt</span>] (Hidden1<span class="op">-</span><span class="dv">2</span>) <span class="op">--</span> node [midway,above] {$<span class="fl">1.00</span>$} (Hidden2<span class="op">-</span><span class="dv">2</span>)<span class="op">;</span> </span>
<span id="cb62-66"><a href="#cb62-66"></a>\draw[<span class="op">-&gt;</span>, shorten <span class="op">&gt;=</span><span class="dv">1</span><span class="er">pt</span>] (<span class="dv">6</span>,<span class="dv">4</span>) node [below] {$<span class="fl">0.00</span>$} <span class="op">--</span>  (Hidden2<span class="op">-</span><span class="dv">2</span>)<span class="op">;</span> </span>
<span id="cb62-67"><a href="#cb62-67"></a>\draw[<span class="op">-&gt;</span>, shorten <span class="op">&gt;=</span><span class="dv">1</span><span class="er">pt</span>] (Hidden2<span class="op">-</span><span class="dv">2</span>) <span class="op">--</span> node [midway] {$<span class="fl">1.00</span>$} (Output)<span class="op">;</span> </span>
<span id="cb62-68"><a href="#cb62-68"></a>\end{tikzpicture}</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-display" data-execution_count="54">
<div>
<figure class="figure">
<p><img src="index_files/figure-html/cell-55-output-1.svg" class="img-fluid figure-img"></p>
</figure>
</div>
</div>
</div>
<p>At this point, this second pair of neurons activation is beginning too soon, which is impacting the area of effect of the top pair we already aligned.</p>
<div class="cell" data-execution_count="55">
<details class="code-fold">
<summary>Show the code</summary>
<div class="sourceCode cell-code" id="cb63"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb63-1"><a href="#cb63-1"></a><span class="op">%%</span>itikz <span class="op">--</span>temp<span class="op">-</span><span class="bu">dir</span> <span class="op">--</span>tex<span class="op">-</span>packages<span class="op">=</span>tikz,pgfplots <span class="op">--</span>tikz<span class="op">-</span>libraries<span class="op">=</span>arrows <span class="op">--</span>implicit<span class="op">-</span>standalone</span>
<span id="cb63-2"><a href="#cb63-2"></a>\begin{tikzpicture}[scale<span class="op">=</span><span class="fl">1.5</span>]</span>
<span id="cb63-3"><a href="#cb63-3"></a>\begin{axis}[grid,ymin<span class="op">=-</span><span class="dv">2</span>,ymax<span class="op">=</span><span class="dv">2</span>,ytick<span class="op">=</span>{<span class="op">-</span><span class="dv">2</span>,<span class="op">-</span><span class="dv">1</span>,...,<span class="dv">2</span>},xmin<span class="op">=</span><span class="dv">0</span>,xmax<span class="op">=</span><span class="dv">1</span>]</span>
<span id="cb63-4"><a href="#cb63-4"></a>\addplot[color<span class="op">=</span>blue,thick,samples<span class="op">=</span><span class="dv">1000</span>]{<span class="op">-</span><span class="bu">max</span>(<span class="op">-</span><span class="bu">max</span>(<span class="dv">6</span><span class="op">*</span>x,<span class="dv">0</span>)<span class="op">+</span><span class="fl">0.70</span>,<span class="dv">0</span>))<span class="op">+</span><span class="fl">0.70</span><span class="op">+</span><span class="bu">max</span>(<span class="bu">max</span>(x,<span class="dv">0</span>),<span class="dv">0</span>)}<span class="op">;</span></span>
<span id="cb63-5"><a href="#cb63-5"></a>\addplot[color<span class="op">=</span>green,samples<span class="op">=</span><span class="dv">1000</span>,domain<span class="op">=</span><span class="dv">0</span>:<span class="dv">1</span>]{sin(deg(<span class="dv">2</span><span class="op">*</span><span class="fl">3.14</span><span class="op">*</span>x))}<span class="op">;</span></span>
<span id="cb63-6"><a href="#cb63-6"></a>\end{axis}</span>
<span id="cb63-7"><a href="#cb63-7"></a>\end{tikzpicture}</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-display" data-execution_count="55">
<div>
<figure class="figure">
<p><img src="index_files/figure-html/cell-56-output-1.svg" class="img-fluid figure-img"></p>
</figure>
</div>
</div>
</div>
<p>To fix this, we want this second pair to start influencing the output where the first pair deactivates, so we want to adjust the function horizontally. As you can recall from earlier, we adjust the first neuron’s bias in this neuron pair to achieve this. Also, to modify the slope, we’ll set the weight coming into that first neuron for the second pair, setting it to <span class="math inline">\(3.50\)</span>.</p>
<div class="cell" data-execution_count="56">
<details class="code-fold">
<summary>Show the code</summary>
<div class="sourceCode cell-code" id="cb64"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb64-1"><a href="#cb64-1"></a><span class="op">%%</span>itikz <span class="op">--</span>temp<span class="op">-</span><span class="bu">dir</span> <span class="op">--</span>tex<span class="op">-</span>packages<span class="op">=</span>tikz <span class="op">--</span>tikz<span class="op">-</span>libraries<span class="op">=</span>arrows <span class="op">--</span>implicit<span class="op">-</span>standalone</span>
<span id="cb64-2"><a href="#cb64-2"></a>\begin{tikzpicture}</span>
<span id="cb64-3"><a href="#cb64-3"></a></span>
<span id="cb64-4"><a href="#cb64-4"></a>\node[circle, </span>
<span id="cb64-5"><a href="#cb64-5"></a>    minimum size <span class="op">=</span> <span class="dv">15</span><span class="er">mm</span>,</span>
<span id="cb64-6"><a href="#cb64-6"></a>    fill<span class="op">=</span>red<span class="op">!</span><span class="dv">30</span></span>
<span id="cb64-7"><a href="#cb64-7"></a>    ] (Input) at (<span class="dv">0</span>,<span class="dv">0</span>) {\large $x_1$}<span class="op">;</span></span>
<span id="cb64-8"><a href="#cb64-8"></a></span>
<span id="cb64-9"><a href="#cb64-9"></a>\foreach \i <span class="kw">in</span> {<span class="dv">1</span>,<span class="dv">2</span>,...,<span class="dv">8</span>}</span>
<span id="cb64-10"><a href="#cb64-10"></a>{</span>
<span id="cb64-11"><a href="#cb64-11"></a>    \node[circle, </span>
<span id="cb64-12"><a href="#cb64-12"></a>        minimum size <span class="op">=</span> <span class="dv">15</span><span class="er">mm</span>,</span>
<span id="cb64-13"><a href="#cb64-13"></a>        fill<span class="op">=</span>blue<span class="op">!</span><span class="dv">50</span>,</span>
<span id="cb64-14"><a href="#cb64-14"></a>        yshift<span class="op">=</span><span class="dv">90</span> mm</span>
<span id="cb64-15"><a href="#cb64-15"></a>        ] (Hidden1<span class="op">-</span>\i) at (<span class="fl">3.0</span>,<span class="op">-</span>\i <span class="op">*</span> <span class="dv">2</span>) {\large $h_\i<span class="op">^</span>{(<span class="dv">1</span>)}$}<span class="op">;</span></span>
<span id="cb64-16"><a href="#cb64-16"></a>        </span>
<span id="cb64-17"><a href="#cb64-17"></a>}</span>
<span id="cb64-18"><a href="#cb64-18"></a>\foreach \i <span class="kw">in</span> {<span class="dv">1</span>,<span class="dv">2</span>,...,<span class="dv">8</span>}</span>
<span id="cb64-19"><a href="#cb64-19"></a>{</span>
<span id="cb64-20"><a href="#cb64-20"></a>    \node[circle, </span>
<span id="cb64-21"><a href="#cb64-21"></a>        minimum size <span class="op">=</span> <span class="dv">15</span><span class="er">mm</span>,</span>
<span id="cb64-22"><a href="#cb64-22"></a>        fill<span class="op">=</span>blue<span class="op">!</span><span class="dv">50</span>,</span>
<span id="cb64-23"><a href="#cb64-23"></a>        yshift<span class="op">=</span><span class="dv">90</span> mm</span>
<span id="cb64-24"><a href="#cb64-24"></a>        ] (Hidden2<span class="op">-</span>\i) at (<span class="fl">6.0</span>,<span class="op">-</span>\i <span class="op">*</span> <span class="dv">2</span>) {\large $h_\i<span class="op">^</span>{(<span class="dv">2</span>)}$}<span class="op">;</span></span>
<span id="cb64-25"><a href="#cb64-25"></a>        </span>
<span id="cb64-26"><a href="#cb64-26"></a>}</span>
<span id="cb64-27"><a href="#cb64-27"></a></span>
<span id="cb64-28"><a href="#cb64-28"></a>\node[circle, </span>
<span id="cb64-29"><a href="#cb64-29"></a>    minimum size <span class="op">=</span> <span class="dv">15</span><span class="er">mm</span>,</span>
<span id="cb64-30"><a href="#cb64-30"></a>    fill<span class="op">=</span>red<span class="op">!</span><span class="dv">30</span></span>
<span id="cb64-31"><a href="#cb64-31"></a>    ] (Output) at (<span class="dv">9</span>,<span class="dv">0</span>) {\large $\hat{y}_1$}<span class="op">;</span></span>
<span id="cb64-32"><a href="#cb64-32"></a></span>
<span id="cb64-33"><a href="#cb64-33"></a><span class="op">%</span> Connect neurons In<span class="op">-</span>Hidden1</span>
<span id="cb64-34"><a href="#cb64-34"></a>\foreach \j <span class="kw">in</span> {<span class="dv">3</span>,...,<span class="dv">7</span>}</span>
<span id="cb64-35"><a href="#cb64-35"></a>{</span>
<span id="cb64-36"><a href="#cb64-36"></a>    \draw[<span class="op">-&gt;</span>, shorten <span class="op">&gt;=</span><span class="dv">1</span><span class="er">pt</span>] (Input) <span class="op">--</span> (Hidden1<span class="op">-</span>\j)<span class="op">;</span>   </span>
<span id="cb64-37"><a href="#cb64-37"></a>}</span>
<span id="cb64-38"><a href="#cb64-38"></a><span class="op">%</span> Connect neurons Hidden1<span class="op">-</span>Hidden2</span>
<span id="cb64-39"><a href="#cb64-39"></a>\foreach \i <span class="kw">in</span> {<span class="dv">3</span>,...,<span class="dv">7</span>}</span>
<span id="cb64-40"><a href="#cb64-40"></a>{</span>
<span id="cb64-41"><a href="#cb64-41"></a>    </span>
<span id="cb64-42"><a href="#cb64-42"></a>        \draw[<span class="op">-&gt;</span>, shorten <span class="op">&gt;=</span><span class="dv">1</span><span class="er">pt</span>] (Hidden1<span class="op">-</span>\i) <span class="op">--</span> (Hidden2<span class="op">-</span>\i)<span class="op">;</span>   </span>
<span id="cb64-43"><a href="#cb64-43"></a>    </span>
<span id="cb64-44"><a href="#cb64-44"></a>}</span>
<span id="cb64-45"><a href="#cb64-45"></a></span>
<span id="cb64-46"><a href="#cb64-46"></a>\foreach \i <span class="kw">in</span> {<span class="dv">3</span>,...,<span class="dv">7</span>}</span>
<span id="cb64-47"><a href="#cb64-47"></a>{</span>
<span id="cb64-48"><a href="#cb64-48"></a>    </span>
<span id="cb64-49"><a href="#cb64-49"></a>        \draw[<span class="op">-&gt;</span>, shorten <span class="op">&gt;=</span><span class="dv">1</span><span class="er">pt</span>] (Hidden2<span class="op">-</span>\i) <span class="op">--</span> (Output)<span class="op">;</span>   </span>
<span id="cb64-50"><a href="#cb64-50"></a>}</span>
<span id="cb64-51"><a href="#cb64-51"></a>\draw[<span class="op">-&gt;</span>, shorten <span class="op">&gt;=</span><span class="dv">1</span><span class="er">pt</span>] (Input) <span class="op">--</span> node [midway] {$<span class="fl">6.00</span>$} (Hidden1<span class="op">-</span><span class="dv">1</span>)<span class="op">;</span>   </span>
<span id="cb64-52"><a href="#cb64-52"></a>\draw[<span class="op">-&gt;</span>, shorten <span class="op">&gt;=</span><span class="dv">1</span><span class="er">pt</span>] (Hidden1<span class="op">-</span><span class="dv">1</span>) <span class="op">--</span> node [midway,above] {$<span class="op">-</span><span class="fl">1.00</span>$} (Hidden2<span class="op">-</span><span class="dv">1</span>)<span class="op">;</span> </span>
<span id="cb64-53"><a href="#cb64-53"></a>\draw[<span class="op">-&gt;</span>, shorten <span class="op">&gt;=</span><span class="dv">1</span><span class="er">pt</span>] (Hidden2<span class="op">-</span><span class="dv">1</span>) <span class="op">--</span> node [midway] {$<span class="op">-</span><span class="fl">1.00</span>$} (Output)<span class="op">;</span> </span>
<span id="cb64-54"><a href="#cb64-54"></a>\draw[<span class="op">-&gt;</span>, shorten <span class="op">&gt;=</span><span class="dv">1</span><span class="er">pt</span>] (<span class="dv">6</span>,<span class="dv">6</span>) node [below] {$<span class="fl">0.70</span>$} <span class="op">--</span>  (Hidden2<span class="op">-</span><span class="dv">1</span>)<span class="op">;</span> </span>
<span id="cb64-55"><a href="#cb64-55"></a>\draw[<span class="op">-&gt;</span>, shorten <span class="op">&gt;=</span><span class="dv">1</span><span class="er">pt</span>] (<span class="dv">3</span>,<span class="dv">6</span>) node [below] {$<span class="fl">0.00</span>$} <span class="op">--</span>  (Hidden1<span class="op">-</span><span class="dv">1</span>)<span class="op">;</span> </span>
<span id="cb64-56"><a href="#cb64-56"></a></span>
<span id="cb64-57"><a href="#cb64-57"></a>\draw[<span class="op">-&gt;</span>, shorten <span class="op">&gt;=</span><span class="dv">1</span><span class="er">pt</span>] (Input) <span class="op">--</span> node [midway] {$<span class="fl">0.00</span>$} (Hidden1<span class="op">-</span><span class="dv">8</span>)<span class="op">;</span> </span>
<span id="cb64-58"><a href="#cb64-58"></a>\draw[<span class="op">-&gt;</span>, shorten <span class="op">&gt;=</span><span class="dv">1</span><span class="er">pt</span>] (<span class="dv">3</span>,<span class="op">-</span><span class="dv">9</span>) node [below] {$<span class="fl">0.00</span>$} <span class="op">--</span>  (Hidden1<span class="op">-</span><span class="dv">8</span>)<span class="op">;</span> </span>
<span id="cb64-59"><a href="#cb64-59"></a>\draw[<span class="op">-&gt;</span>, shorten <span class="op">&gt;=</span><span class="dv">1</span><span class="er">pt</span>] (Hidden1<span class="op">-</span><span class="dv">8</span>) <span class="op">--</span> node [midway,above] {$<span class="fl">0.00</span>$} (Hidden2<span class="op">-</span><span class="dv">8</span>)<span class="op">;</span> </span>
<span id="cb64-60"><a href="#cb64-60"></a>\draw[<span class="op">-&gt;</span>, shorten <span class="op">&gt;=</span><span class="dv">1</span><span class="er">pt</span>] (<span class="dv">6</span>,<span class="op">-</span><span class="dv">9</span>) node [below] {$<span class="fl">1.00</span>$} <span class="op">--</span>  (Hidden2<span class="op">-</span><span class="dv">8</span>)<span class="op">;</span> </span>
<span id="cb64-61"><a href="#cb64-61"></a>\draw[<span class="op">-&gt;</span>, shorten <span class="op">&gt;=</span><span class="dv">1</span><span class="er">pt</span>] (Hidden2<span class="op">-</span><span class="dv">8</span>) <span class="op">--</span> node [midway] {$<span class="fl">0.70</span>$} (Output)<span class="op">;</span> </span>
<span id="cb64-62"><a href="#cb64-62"></a></span>
<span id="cb64-63"><a href="#cb64-63"></a>\draw[<span class="op">-&gt;</span>, shorten <span class="op">&gt;=</span><span class="dv">1</span><span class="er">pt</span>] (Input) <span class="op">--</span> node [midway] {$<span class="fl">3.50</span>$} (Hidden1<span class="op">-</span><span class="dv">2</span>)<span class="op">;</span> </span>
<span id="cb64-64"><a href="#cb64-64"></a>\draw[<span class="op">-&gt;</span>, shorten <span class="op">&gt;=</span><span class="dv">1</span><span class="er">pt</span>] (<span class="dv">3</span>,<span class="dv">4</span>) node [below] {$<span class="op">-</span><span class="fl">0.42</span>$} <span class="op">--</span>  (Hidden1<span class="op">-</span><span class="dv">2</span>)<span class="op">;</span> </span>
<span id="cb64-65"><a href="#cb64-65"></a>\draw[<span class="op">-&gt;</span>, shorten <span class="op">&gt;=</span><span class="dv">1</span><span class="er">pt</span>] (Hidden1<span class="op">-</span><span class="dv">2</span>) <span class="op">--</span> node [midway,above] {$<span class="fl">1.00</span>$} (Hidden2<span class="op">-</span><span class="dv">2</span>)<span class="op">;</span> </span>
<span id="cb64-66"><a href="#cb64-66"></a>\draw[<span class="op">-&gt;</span>, shorten <span class="op">&gt;=</span><span class="dv">1</span><span class="er">pt</span>] (<span class="dv">6</span>,<span class="dv">4</span>) node [below] {$<span class="fl">0.00</span>$} <span class="op">--</span>  (Hidden2<span class="op">-</span><span class="dv">2</span>)<span class="op">;</span> </span>
<span id="cb64-67"><a href="#cb64-67"></a>\draw[<span class="op">-&gt;</span>, shorten <span class="op">&gt;=</span><span class="dv">1</span><span class="er">pt</span>] (Hidden2<span class="op">-</span><span class="dv">2</span>) <span class="op">--</span> node [midway] {$<span class="fl">1.00</span>$} (Output)<span class="op">;</span> </span>
<span id="cb64-68"><a href="#cb64-68"></a>\end{tikzpicture}</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-display" data-execution_count="56">
<div>
<figure class="figure">
<p><img src="index_files/figure-html/cell-57-output-1.svg" class="img-fluid figure-img"></p>
</figure>
</div>
</div>
</div>
<p>After these adjustments:</p>
<div class="cell" data-execution_count="57">
<details class="code-fold">
<summary>Show the code</summary>
<div class="sourceCode cell-code" id="cb65"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb65-1"><a href="#cb65-1"></a><span class="op">%%</span>itikz <span class="op">--</span>temp<span class="op">-</span><span class="bu">dir</span> <span class="op">--</span>tex<span class="op">-</span>packages<span class="op">=</span>tikz,pgfplots <span class="op">--</span>tikz<span class="op">-</span>libraries<span class="op">=</span>arrows <span class="op">--</span>implicit<span class="op">-</span>standalone</span>
<span id="cb65-2"><a href="#cb65-2"></a>\begin{tikzpicture}[scale<span class="op">=</span><span class="fl">1.5</span>]</span>
<span id="cb65-3"><a href="#cb65-3"></a>\begin{axis}[grid,ymin<span class="op">=-</span><span class="dv">2</span>,ymax<span class="op">=</span><span class="dv">2</span>,ytick<span class="op">=</span>{<span class="op">-</span><span class="dv">2</span>,<span class="op">-</span><span class="dv">1</span>,...,<span class="dv">2</span>},xmin<span class="op">=</span><span class="dv">0</span>,xmax<span class="op">=</span><span class="dv">1</span>]</span>
<span id="cb65-4"><a href="#cb65-4"></a>\addplot[color<span class="op">=</span>blue,thick,samples<span class="op">=</span><span class="dv">1000</span>]{<span class="op">-</span><span class="bu">max</span>(<span class="op">-</span><span class="bu">max</span>(<span class="dv">6</span><span class="op">*</span>x,<span class="dv">0</span>)<span class="op">+</span><span class="fl">0.70</span>,<span class="dv">0</span>))<span class="op">+</span><span class="fl">0.70</span><span class="op">+</span><span class="bu">max</span>(<span class="bu">max</span>(<span class="fl">3.50</span><span class="op">*</span>x <span class="op">-</span> <span class="fl">0.42</span>,<span class="dv">0</span>),<span class="dv">0</span>)}<span class="op">;</span></span>
<span id="cb65-5"><a href="#cb65-5"></a>\addplot[color<span class="op">=</span>green,samples<span class="op">=</span><span class="dv">1000</span>,domain<span class="op">=</span><span class="dv">0</span>:<span class="dv">1</span>]{sin(deg(<span class="dv">2</span><span class="op">*</span><span class="fl">3.14</span><span class="op">*</span>x))}<span class="op">;</span></span>
<span id="cb65-6"><a href="#cb65-6"></a>\end{axis}</span>
<span id="cb65-7"><a href="#cb65-7"></a>\end{tikzpicture}</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-display" data-execution_count="57">
<div>
<figure class="figure">
<p><img src="index_files/figure-html/cell-58-output-1.svg" class="img-fluid figure-img"></p>
</figure>
</div>
</div>
</div>
<p>We will now use the same methodology as we did with the first pair of neurons to set the deactivation point. We set the weight for the second neuron in the hidden layer pair to <span class="math inline">\(-1.00\)</span> and the bias to <span class="math inline">\(0.27\)</span>.</p>
<div class="cell" data-execution_count="58">
<details class="code-fold">
<summary>Show the code</summary>
<div class="sourceCode cell-code" id="cb66"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb66-1"><a href="#cb66-1"></a><span class="op">%%</span>itikz <span class="op">--</span>temp<span class="op">-</span><span class="bu">dir</span> <span class="op">--</span>tex<span class="op">-</span>packages<span class="op">=</span>tikz <span class="op">--</span>tikz<span class="op">-</span>libraries<span class="op">=</span>arrows <span class="op">--</span>implicit<span class="op">-</span>standalone</span>
<span id="cb66-2"><a href="#cb66-2"></a>\begin{tikzpicture}</span>
<span id="cb66-3"><a href="#cb66-3"></a></span>
<span id="cb66-4"><a href="#cb66-4"></a>\node[circle, </span>
<span id="cb66-5"><a href="#cb66-5"></a>    minimum size <span class="op">=</span> <span class="dv">15</span><span class="er">mm</span>,</span>
<span id="cb66-6"><a href="#cb66-6"></a>    fill<span class="op">=</span>red<span class="op">!</span><span class="dv">30</span></span>
<span id="cb66-7"><a href="#cb66-7"></a>    ] (Input) at (<span class="dv">0</span>,<span class="dv">0</span>) {\large $x_1$}<span class="op">;</span></span>
<span id="cb66-8"><a href="#cb66-8"></a></span>
<span id="cb66-9"><a href="#cb66-9"></a>\foreach \i <span class="kw">in</span> {<span class="dv">1</span>,<span class="dv">2</span>,...,<span class="dv">8</span>}</span>
<span id="cb66-10"><a href="#cb66-10"></a>{</span>
<span id="cb66-11"><a href="#cb66-11"></a>    \node[circle, </span>
<span id="cb66-12"><a href="#cb66-12"></a>        minimum size <span class="op">=</span> <span class="dv">15</span><span class="er">mm</span>,</span>
<span id="cb66-13"><a href="#cb66-13"></a>        fill<span class="op">=</span>blue<span class="op">!</span><span class="dv">50</span>,</span>
<span id="cb66-14"><a href="#cb66-14"></a>        yshift<span class="op">=</span><span class="dv">90</span> mm</span>
<span id="cb66-15"><a href="#cb66-15"></a>        ] (Hidden1<span class="op">-</span>\i) at (<span class="fl">3.0</span>,<span class="op">-</span>\i <span class="op">*</span> <span class="dv">2</span>) {\large $h_\i<span class="op">^</span>{(<span class="dv">1</span>)}$}<span class="op">;</span></span>
<span id="cb66-16"><a href="#cb66-16"></a>        </span>
<span id="cb66-17"><a href="#cb66-17"></a>}</span>
<span id="cb66-18"><a href="#cb66-18"></a>\foreach \i <span class="kw">in</span> {<span class="dv">1</span>,<span class="dv">2</span>,...,<span class="dv">8</span>}</span>
<span id="cb66-19"><a href="#cb66-19"></a>{</span>
<span id="cb66-20"><a href="#cb66-20"></a>    \node[circle, </span>
<span id="cb66-21"><a href="#cb66-21"></a>        minimum size <span class="op">=</span> <span class="dv">15</span><span class="er">mm</span>,</span>
<span id="cb66-22"><a href="#cb66-22"></a>        fill<span class="op">=</span>blue<span class="op">!</span><span class="dv">50</span>,</span>
<span id="cb66-23"><a href="#cb66-23"></a>        yshift<span class="op">=</span><span class="dv">90</span> mm</span>
<span id="cb66-24"><a href="#cb66-24"></a>        ] (Hidden2<span class="op">-</span>\i) at (<span class="fl">6.0</span>,<span class="op">-</span>\i <span class="op">*</span> <span class="dv">2</span>) {\large $h_\i<span class="op">^</span>{(<span class="dv">2</span>)}$}<span class="op">;</span></span>
<span id="cb66-25"><a href="#cb66-25"></a>        </span>
<span id="cb66-26"><a href="#cb66-26"></a>}</span>
<span id="cb66-27"><a href="#cb66-27"></a></span>
<span id="cb66-28"><a href="#cb66-28"></a>\node[circle, </span>
<span id="cb66-29"><a href="#cb66-29"></a>    minimum size <span class="op">=</span> <span class="dv">15</span><span class="er">mm</span>,</span>
<span id="cb66-30"><a href="#cb66-30"></a>    fill<span class="op">=</span>red<span class="op">!</span><span class="dv">30</span></span>
<span id="cb66-31"><a href="#cb66-31"></a>    ] (Output) at (<span class="dv">9</span>,<span class="dv">0</span>) {\large $\hat{y}_1$}<span class="op">;</span></span>
<span id="cb66-32"><a href="#cb66-32"></a></span>
<span id="cb66-33"><a href="#cb66-33"></a><span class="op">%</span> Connect neurons In<span class="op">-</span>Hidden1</span>
<span id="cb66-34"><a href="#cb66-34"></a>\foreach \j <span class="kw">in</span> {<span class="dv">3</span>,...,<span class="dv">7</span>}</span>
<span id="cb66-35"><a href="#cb66-35"></a>{</span>
<span id="cb66-36"><a href="#cb66-36"></a>    \draw[<span class="op">-&gt;</span>, shorten <span class="op">&gt;=</span><span class="dv">1</span><span class="er">pt</span>] (Input) <span class="op">--</span> (Hidden1<span class="op">-</span>\j)<span class="op">;</span>   </span>
<span id="cb66-37"><a href="#cb66-37"></a>}</span>
<span id="cb66-38"><a href="#cb66-38"></a><span class="op">%</span> Connect neurons Hidden1<span class="op">-</span>Hidden2</span>
<span id="cb66-39"><a href="#cb66-39"></a>\foreach \i <span class="kw">in</span> {<span class="dv">3</span>,...,<span class="dv">7</span>}</span>
<span id="cb66-40"><a href="#cb66-40"></a>{</span>
<span id="cb66-41"><a href="#cb66-41"></a>    </span>
<span id="cb66-42"><a href="#cb66-42"></a>        \draw[<span class="op">-&gt;</span>, shorten <span class="op">&gt;=</span><span class="dv">1</span><span class="er">pt</span>] (Hidden1<span class="op">-</span>\i) <span class="op">--</span> (Hidden2<span class="op">-</span>\i)<span class="op">;</span>   </span>
<span id="cb66-43"><a href="#cb66-43"></a>    </span>
<span id="cb66-44"><a href="#cb66-44"></a>}</span>
<span id="cb66-45"><a href="#cb66-45"></a></span>
<span id="cb66-46"><a href="#cb66-46"></a>\foreach \i <span class="kw">in</span> {<span class="dv">3</span>,...,<span class="dv">7</span>}</span>
<span id="cb66-47"><a href="#cb66-47"></a>{</span>
<span id="cb66-48"><a href="#cb66-48"></a>    </span>
<span id="cb66-49"><a href="#cb66-49"></a>        \draw[<span class="op">-&gt;</span>, shorten <span class="op">&gt;=</span><span class="dv">1</span><span class="er">pt</span>] (Hidden2<span class="op">-</span>\i) <span class="op">--</span> (Output)<span class="op">;</span>   </span>
<span id="cb66-50"><a href="#cb66-50"></a>}</span>
<span id="cb66-51"><a href="#cb66-51"></a>\draw[<span class="op">-&gt;</span>, shorten <span class="op">&gt;=</span><span class="dv">1</span><span class="er">pt</span>] (Input) <span class="op">--</span> node [midway] {$<span class="fl">6.00</span>$} (Hidden1<span class="op">-</span><span class="dv">1</span>)<span class="op">;</span>   </span>
<span id="cb66-52"><a href="#cb66-52"></a>\draw[<span class="op">-&gt;</span>, shorten <span class="op">&gt;=</span><span class="dv">1</span><span class="er">pt</span>] (Hidden1<span class="op">-</span><span class="dv">1</span>) <span class="op">--</span> node [midway,above] {$<span class="op">-</span><span class="fl">1.00</span>$} (Hidden2<span class="op">-</span><span class="dv">1</span>)<span class="op">;</span> </span>
<span id="cb66-53"><a href="#cb66-53"></a>\draw[<span class="op">-&gt;</span>, shorten <span class="op">&gt;=</span><span class="dv">1</span><span class="er">pt</span>] (Hidden2<span class="op">-</span><span class="dv">1</span>) <span class="op">--</span> node [midway] {$<span class="op">-</span><span class="fl">1.00</span>$} (Output)<span class="op">;</span> </span>
<span id="cb66-54"><a href="#cb66-54"></a>\draw[<span class="op">-&gt;</span>, shorten <span class="op">&gt;=</span><span class="dv">1</span><span class="er">pt</span>] (<span class="dv">6</span>,<span class="dv">6</span>) node [below] {$<span class="fl">0.70</span>$} <span class="op">--</span>  (Hidden2<span class="op">-</span><span class="dv">1</span>)<span class="op">;</span> </span>
<span id="cb66-55"><a href="#cb66-55"></a>\draw[<span class="op">-&gt;</span>, shorten <span class="op">&gt;=</span><span class="dv">1</span><span class="er">pt</span>] (<span class="dv">3</span>,<span class="dv">6</span>) node [below] {$<span class="fl">0.00</span>$} <span class="op">--</span>  (Hidden1<span class="op">-</span><span class="dv">1</span>)<span class="op">;</span> </span>
<span id="cb66-56"><a href="#cb66-56"></a></span>
<span id="cb66-57"><a href="#cb66-57"></a>\draw[<span class="op">-&gt;</span>, shorten <span class="op">&gt;=</span><span class="dv">1</span><span class="er">pt</span>] (Input) <span class="op">--</span> node [midway] {$<span class="fl">0.00</span>$} (Hidden1<span class="op">-</span><span class="dv">8</span>)<span class="op">;</span> </span>
<span id="cb66-58"><a href="#cb66-58"></a>\draw[<span class="op">-&gt;</span>, shorten <span class="op">&gt;=</span><span class="dv">1</span><span class="er">pt</span>] (<span class="dv">3</span>,<span class="op">-</span><span class="dv">9</span>) node [below] {$<span class="fl">0.00</span>$} <span class="op">--</span>  (Hidden1<span class="op">-</span><span class="dv">8</span>)<span class="op">;</span> </span>
<span id="cb66-59"><a href="#cb66-59"></a>\draw[<span class="op">-&gt;</span>, shorten <span class="op">&gt;=</span><span class="dv">1</span><span class="er">pt</span>] (Hidden1<span class="op">-</span><span class="dv">8</span>) <span class="op">--</span> node [midway,above] {$<span class="fl">0.00</span>$} (Hidden2<span class="op">-</span><span class="dv">8</span>)<span class="op">;</span> </span>
<span id="cb66-60"><a href="#cb66-60"></a>\draw[<span class="op">-&gt;</span>, shorten <span class="op">&gt;=</span><span class="dv">1</span><span class="er">pt</span>] (<span class="dv">6</span>,<span class="op">-</span><span class="dv">9</span>) node [below] {$<span class="fl">1.00</span>$} <span class="op">--</span>  (Hidden2<span class="op">-</span><span class="dv">8</span>)<span class="op">;</span> </span>
<span id="cb66-61"><a href="#cb66-61"></a>\draw[<span class="op">-&gt;</span>, shorten <span class="op">&gt;=</span><span class="dv">1</span><span class="er">pt</span>] (Hidden2<span class="op">-</span><span class="dv">8</span>) <span class="op">--</span> node [midway] {$<span class="fl">0.70</span>$} (Output)<span class="op">;</span> </span>
<span id="cb66-62"><a href="#cb66-62"></a></span>
<span id="cb66-63"><a href="#cb66-63"></a>\draw[<span class="op">-&gt;</span>, shorten <span class="op">&gt;=</span><span class="dv">1</span><span class="er">pt</span>] (Input) <span class="op">--</span> node [midway] {$<span class="fl">3.50</span>$} (Hidden1<span class="op">-</span><span class="dv">2</span>)<span class="op">;</span> </span>
<span id="cb66-64"><a href="#cb66-64"></a>\draw[<span class="op">-&gt;</span>, shorten <span class="op">&gt;=</span><span class="dv">1</span><span class="er">pt</span>] (<span class="dv">3</span>,<span class="dv">4</span>) node [below] {$<span class="op">-</span><span class="fl">0.42</span>$} <span class="op">--</span>  (Hidden1<span class="op">-</span><span class="dv">2</span>)<span class="op">;</span> </span>
<span id="cb66-65"><a href="#cb66-65"></a>\draw[<span class="op">-&gt;</span>, shorten <span class="op">&gt;=</span><span class="dv">1</span><span class="er">pt</span>] (Hidden1<span class="op">-</span><span class="dv">2</span>) <span class="op">--</span> node [midway,above] {$<span class="op">-</span><span class="fl">1.00</span>$} (Hidden2<span class="op">-</span><span class="dv">2</span>)<span class="op">;</span> </span>
<span id="cb66-66"><a href="#cb66-66"></a>\draw[<span class="op">-&gt;</span>, shorten <span class="op">&gt;=</span><span class="dv">1</span><span class="er">pt</span>] (<span class="dv">6</span>,<span class="dv">4</span>) node [below] {$<span class="fl">0.27</span>$} <span class="op">--</span>  (Hidden2<span class="op">-</span><span class="dv">2</span>)<span class="op">;</span> </span>
<span id="cb66-67"><a href="#cb66-67"></a>\draw[<span class="op">-&gt;</span>, shorten <span class="op">&gt;=</span><span class="dv">1</span><span class="er">pt</span>] (Hidden2<span class="op">-</span><span class="dv">2</span>) <span class="op">--</span> node [midway] {$<span class="fl">1.00</span>$} (Output)<span class="op">;</span> </span>
<span id="cb66-68"><a href="#cb66-68"></a>\end{tikzpicture}</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-display" data-execution_count="58">
<div>
<figure class="figure">
<p><img src="index_files/figure-html/cell-59-output-1.svg" class="img-fluid figure-img"></p>
</figure>
</div>
</div>
</div>
<p>This results in:</p>
<div class="cell" data-execution_count="59">
<details class="code-fold">
<summary>Show the code</summary>
<div class="sourceCode cell-code" id="cb67"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb67-1"><a href="#cb67-1"></a><span class="op">%%</span>itikz <span class="op">--</span>temp<span class="op">-</span><span class="bu">dir</span> <span class="op">--</span>tex<span class="op">-</span>packages<span class="op">=</span>tikz,pgfplots <span class="op">--</span>tikz<span class="op">-</span>libraries<span class="op">=</span>arrows <span class="op">--</span>implicit<span class="op">-</span>standalone</span>
<span id="cb67-2"><a href="#cb67-2"></a>\begin{tikzpicture}[scale<span class="op">=</span><span class="fl">1.5</span>]</span>
<span id="cb67-3"><a href="#cb67-3"></a>\begin{axis}[grid,ymin<span class="op">=-</span><span class="dv">2</span>,ymax<span class="op">=</span><span class="dv">2</span>,ytick<span class="op">=</span>{<span class="op">-</span><span class="dv">2</span>,<span class="op">-</span><span class="dv">1</span>,...,<span class="dv">2</span>},xmin<span class="op">=</span><span class="dv">0</span>,xmax<span class="op">=</span><span class="dv">1</span>]</span>
<span id="cb67-4"><a href="#cb67-4"></a>\addplot[color<span class="op">=</span>blue,thick,samples<span class="op">=</span><span class="dv">1000</span>]{<span class="op">-</span><span class="bu">max</span>(<span class="op">-</span><span class="bu">max</span>(<span class="dv">6</span><span class="op">*</span>x,<span class="dv">0</span>)<span class="op">+</span><span class="fl">0.70</span>,<span class="dv">0</span>))<span class="op">+</span><span class="fl">0.70</span><span class="op">+</span><span class="bu">max</span>(<span class="op">-</span><span class="bu">max</span>(<span class="fl">3.50</span><span class="op">*</span>x <span class="op">-</span> <span class="fl">0.42</span>,<span class="dv">0</span>)<span class="op">+</span><span class="fl">0.27</span>,<span class="dv">0</span>)}<span class="op">;</span></span>
<span id="cb67-5"><a href="#cb67-5"></a>\addplot[color<span class="op">=</span>green,samples<span class="op">=</span><span class="dv">1000</span>,domain<span class="op">=</span><span class="dv">0</span>:<span class="dv">1</span>]{sin(deg(<span class="dv">2</span><span class="op">*</span><span class="fl">3.14</span><span class="op">*</span>x))}<span class="op">;</span></span>
<span id="cb67-6"><a href="#cb67-6"></a>\end{axis}</span>
<span id="cb67-7"><a href="#cb67-7"></a>\end{tikzpicture}</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-display" data-execution_count="59">
<div>
<figure class="figure">
<p><img src="index_files/figure-html/cell-60-output-1.svg" class="img-fluid figure-img"></p>
</figure>
</div>
</div>
</div>
<p>Then, we can flip this section’s function again the same way we did with the first one, by setting the weight to the output neuron from <span class="math inline">\(1.0\)</span> to <span class="math inline">\(-1.0\)</span>.</p>
<div class="cell" data-execution_count="60">
<details class="code-fold">
<summary>Show the code</summary>
<div class="sourceCode cell-code" id="cb68"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb68-1"><a href="#cb68-1"></a><span class="op">%%</span>itikz <span class="op">--</span>temp<span class="op">-</span><span class="bu">dir</span> <span class="op">--</span>tex<span class="op">-</span>packages<span class="op">=</span>tikz <span class="op">--</span>tikz<span class="op">-</span>libraries<span class="op">=</span>arrows <span class="op">--</span>implicit<span class="op">-</span>standalone</span>
<span id="cb68-2"><a href="#cb68-2"></a>\begin{tikzpicture}</span>
<span id="cb68-3"><a href="#cb68-3"></a></span>
<span id="cb68-4"><a href="#cb68-4"></a>\node[circle, </span>
<span id="cb68-5"><a href="#cb68-5"></a>    minimum size <span class="op">=</span> <span class="dv">15</span><span class="er">mm</span>,</span>
<span id="cb68-6"><a href="#cb68-6"></a>    fill<span class="op">=</span>red<span class="op">!</span><span class="dv">30</span></span>
<span id="cb68-7"><a href="#cb68-7"></a>    ] (Input) at (<span class="dv">0</span>,<span class="dv">0</span>) {\large $x_1$}<span class="op">;</span></span>
<span id="cb68-8"><a href="#cb68-8"></a></span>
<span id="cb68-9"><a href="#cb68-9"></a>\foreach \i <span class="kw">in</span> {<span class="dv">1</span>,<span class="dv">2</span>,...,<span class="dv">8</span>}</span>
<span id="cb68-10"><a href="#cb68-10"></a>{</span>
<span id="cb68-11"><a href="#cb68-11"></a>    \node[circle, </span>
<span id="cb68-12"><a href="#cb68-12"></a>        minimum size <span class="op">=</span> <span class="dv">15</span><span class="er">mm</span>,</span>
<span id="cb68-13"><a href="#cb68-13"></a>        fill<span class="op">=</span>blue<span class="op">!</span><span class="dv">50</span>,</span>
<span id="cb68-14"><a href="#cb68-14"></a>        yshift<span class="op">=</span><span class="dv">90</span> mm</span>
<span id="cb68-15"><a href="#cb68-15"></a>        ] (Hidden1<span class="op">-</span>\i) at (<span class="fl">3.0</span>,<span class="op">-</span>\i <span class="op">*</span> <span class="dv">2</span>) {\large $h_\i<span class="op">^</span>{(<span class="dv">1</span>)}$}<span class="op">;</span></span>
<span id="cb68-16"><a href="#cb68-16"></a>        </span>
<span id="cb68-17"><a href="#cb68-17"></a>}</span>
<span id="cb68-18"><a href="#cb68-18"></a>\foreach \i <span class="kw">in</span> {<span class="dv">1</span>,<span class="dv">2</span>,...,<span class="dv">8</span>}</span>
<span id="cb68-19"><a href="#cb68-19"></a>{</span>
<span id="cb68-20"><a href="#cb68-20"></a>    \node[circle, </span>
<span id="cb68-21"><a href="#cb68-21"></a>        minimum size <span class="op">=</span> <span class="dv">15</span><span class="er">mm</span>,</span>
<span id="cb68-22"><a href="#cb68-22"></a>        fill<span class="op">=</span>blue<span class="op">!</span><span class="dv">50</span>,</span>
<span id="cb68-23"><a href="#cb68-23"></a>        yshift<span class="op">=</span><span class="dv">90</span> mm</span>
<span id="cb68-24"><a href="#cb68-24"></a>        ] (Hidden2<span class="op">-</span>\i) at (<span class="fl">6.0</span>,<span class="op">-</span>\i <span class="op">*</span> <span class="dv">2</span>) {\large $h_\i<span class="op">^</span>{(<span class="dv">2</span>)}$}<span class="op">;</span></span>
<span id="cb68-25"><a href="#cb68-25"></a>        </span>
<span id="cb68-26"><a href="#cb68-26"></a>}</span>
<span id="cb68-27"><a href="#cb68-27"></a></span>
<span id="cb68-28"><a href="#cb68-28"></a>\node[circle, </span>
<span id="cb68-29"><a href="#cb68-29"></a>    minimum size <span class="op">=</span> <span class="dv">15</span><span class="er">mm</span>,</span>
<span id="cb68-30"><a href="#cb68-30"></a>    fill<span class="op">=</span>red<span class="op">!</span><span class="dv">30</span></span>
<span id="cb68-31"><a href="#cb68-31"></a>    ] (Output) at (<span class="dv">9</span>,<span class="dv">0</span>) {\large $\hat{y}_1$}<span class="op">;</span></span>
<span id="cb68-32"><a href="#cb68-32"></a></span>
<span id="cb68-33"><a href="#cb68-33"></a><span class="op">%</span> Connect neurons In<span class="op">-</span>Hidden1</span>
<span id="cb68-34"><a href="#cb68-34"></a>\foreach \j <span class="kw">in</span> {<span class="dv">3</span>,...,<span class="dv">7</span>}</span>
<span id="cb68-35"><a href="#cb68-35"></a>{</span>
<span id="cb68-36"><a href="#cb68-36"></a>    \draw[<span class="op">-&gt;</span>, shorten <span class="op">&gt;=</span><span class="dv">1</span><span class="er">pt</span>] (Input) <span class="op">--</span> (Hidden1<span class="op">-</span>\j)<span class="op">;</span>   </span>
<span id="cb68-37"><a href="#cb68-37"></a>}</span>
<span id="cb68-38"><a href="#cb68-38"></a><span class="op">%</span> Connect neurons Hidden1<span class="op">-</span>Hidden2</span>
<span id="cb68-39"><a href="#cb68-39"></a>\foreach \i <span class="kw">in</span> {<span class="dv">3</span>,...,<span class="dv">7</span>}</span>
<span id="cb68-40"><a href="#cb68-40"></a>{</span>
<span id="cb68-41"><a href="#cb68-41"></a>    </span>
<span id="cb68-42"><a href="#cb68-42"></a>        \draw[<span class="op">-&gt;</span>, shorten <span class="op">&gt;=</span><span class="dv">1</span><span class="er">pt</span>] (Hidden1<span class="op">-</span>\i) <span class="op">--</span> (Hidden2<span class="op">-</span>\i)<span class="op">;</span>   </span>
<span id="cb68-43"><a href="#cb68-43"></a>    </span>
<span id="cb68-44"><a href="#cb68-44"></a>}</span>
<span id="cb68-45"><a href="#cb68-45"></a></span>
<span id="cb68-46"><a href="#cb68-46"></a>\foreach \i <span class="kw">in</span> {<span class="dv">3</span>,...,<span class="dv">7</span>}</span>
<span id="cb68-47"><a href="#cb68-47"></a>{</span>
<span id="cb68-48"><a href="#cb68-48"></a>    </span>
<span id="cb68-49"><a href="#cb68-49"></a>        \draw[<span class="op">-&gt;</span>, shorten <span class="op">&gt;=</span><span class="dv">1</span><span class="er">pt</span>] (Hidden2<span class="op">-</span>\i) <span class="op">--</span> (Output)<span class="op">;</span>   </span>
<span id="cb68-50"><a href="#cb68-50"></a>}</span>
<span id="cb68-51"><a href="#cb68-51"></a>\draw[<span class="op">-&gt;</span>, shorten <span class="op">&gt;=</span><span class="dv">1</span><span class="er">pt</span>] (Input) <span class="op">--</span> node [midway] {$<span class="fl">6.00</span>$} (Hidden1<span class="op">-</span><span class="dv">1</span>)<span class="op">;</span>   </span>
<span id="cb68-52"><a href="#cb68-52"></a>\draw[<span class="op">-&gt;</span>, shorten <span class="op">&gt;=</span><span class="dv">1</span><span class="er">pt</span>] (Hidden1<span class="op">-</span><span class="dv">1</span>) <span class="op">--</span> node [midway,above] {$<span class="op">-</span><span class="fl">1.00</span>$} (Hidden2<span class="op">-</span><span class="dv">1</span>)<span class="op">;</span> </span>
<span id="cb68-53"><a href="#cb68-53"></a>\draw[<span class="op">-&gt;</span>, shorten <span class="op">&gt;=</span><span class="dv">1</span><span class="er">pt</span>] (Hidden2<span class="op">-</span><span class="dv">1</span>) <span class="op">--</span> node [midway] {$<span class="op">-</span><span class="fl">1.00</span>$} (Output)<span class="op">;</span> </span>
<span id="cb68-54"><a href="#cb68-54"></a>\draw[<span class="op">-&gt;</span>, shorten <span class="op">&gt;=</span><span class="dv">1</span><span class="er">pt</span>] (<span class="dv">6</span>,<span class="dv">6</span>) node [below] {$<span class="fl">0.70</span>$} <span class="op">--</span>  (Hidden2<span class="op">-</span><span class="dv">1</span>)<span class="op">;</span> </span>
<span id="cb68-55"><a href="#cb68-55"></a>\draw[<span class="op">-&gt;</span>, shorten <span class="op">&gt;=</span><span class="dv">1</span><span class="er">pt</span>] (<span class="dv">3</span>,<span class="dv">6</span>) node [below] {$<span class="fl">0.00</span>$} <span class="op">--</span>  (Hidden1<span class="op">-</span><span class="dv">1</span>)<span class="op">;</span> </span>
<span id="cb68-56"><a href="#cb68-56"></a></span>
<span id="cb68-57"><a href="#cb68-57"></a>\draw[<span class="op">-&gt;</span>, shorten <span class="op">&gt;=</span><span class="dv">1</span><span class="er">pt</span>] (Input) <span class="op">--</span> node [midway] {$<span class="fl">0.00</span>$} (Hidden1<span class="op">-</span><span class="dv">8</span>)<span class="op">;</span> </span>
<span id="cb68-58"><a href="#cb68-58"></a>\draw[<span class="op">-&gt;</span>, shorten <span class="op">&gt;=</span><span class="dv">1</span><span class="er">pt</span>] (<span class="dv">3</span>,<span class="op">-</span><span class="dv">9</span>) node [below] {$<span class="fl">0.00</span>$} <span class="op">--</span>  (Hidden1<span class="op">-</span><span class="dv">8</span>)<span class="op">;</span> </span>
<span id="cb68-59"><a href="#cb68-59"></a>\draw[<span class="op">-&gt;</span>, shorten <span class="op">&gt;=</span><span class="dv">1</span><span class="er">pt</span>] (Hidden1<span class="op">-</span><span class="dv">8</span>) <span class="op">--</span> node [midway,above] {$<span class="fl">0.00</span>$} (Hidden2<span class="op">-</span><span class="dv">8</span>)<span class="op">;</span> </span>
<span id="cb68-60"><a href="#cb68-60"></a>\draw[<span class="op">-&gt;</span>, shorten <span class="op">&gt;=</span><span class="dv">1</span><span class="er">pt</span>] (<span class="dv">6</span>,<span class="op">-</span><span class="dv">9</span>) node [below] {$<span class="fl">1.00</span>$} <span class="op">--</span>  (Hidden2<span class="op">-</span><span class="dv">8</span>)<span class="op">;</span> </span>
<span id="cb68-61"><a href="#cb68-61"></a>\draw[<span class="op">-&gt;</span>, shorten <span class="op">&gt;=</span><span class="dv">1</span><span class="er">pt</span>] (Hidden2<span class="op">-</span><span class="dv">8</span>) <span class="op">--</span> node [midway] {$<span class="fl">0.70</span>$} (Output)<span class="op">;</span> </span>
<span id="cb68-62"><a href="#cb68-62"></a></span>
<span id="cb68-63"><a href="#cb68-63"></a>\draw[<span class="op">-&gt;</span>, shorten <span class="op">&gt;=</span><span class="dv">1</span><span class="er">pt</span>] (Input) <span class="op">--</span> node [midway] {$<span class="fl">3.50</span>$} (Hidden1<span class="op">-</span><span class="dv">2</span>)<span class="op">;</span> </span>
<span id="cb68-64"><a href="#cb68-64"></a>\draw[<span class="op">-&gt;</span>, shorten <span class="op">&gt;=</span><span class="dv">1</span><span class="er">pt</span>] (<span class="dv">3</span>,<span class="dv">4</span>) node [below] {$<span class="op">-</span><span class="fl">0.42</span>$} <span class="op">--</span>  (Hidden1<span class="op">-</span><span class="dv">2</span>)<span class="op">;</span> </span>
<span id="cb68-65"><a href="#cb68-65"></a>\draw[<span class="op">-&gt;</span>, shorten <span class="op">&gt;=</span><span class="dv">1</span><span class="er">pt</span>] (Hidden1<span class="op">-</span><span class="dv">2</span>) <span class="op">--</span> node [midway,above] {$<span class="op">-</span><span class="fl">1.00</span>$} (Hidden2<span class="op">-</span><span class="dv">2</span>)<span class="op">;</span> </span>
<span id="cb68-66"><a href="#cb68-66"></a>\draw[<span class="op">-&gt;</span>, shorten <span class="op">&gt;=</span><span class="dv">1</span><span class="er">pt</span>] (<span class="dv">6</span>,<span class="dv">4</span>) node [below] {$<span class="fl">0.27</span>$} <span class="op">--</span>  (Hidden2<span class="op">-</span><span class="dv">2</span>)<span class="op">;</span> </span>
<span id="cb68-67"><a href="#cb68-67"></a>\draw[<span class="op">-&gt;</span>, shorten <span class="op">&gt;=</span><span class="dv">1</span><span class="er">pt</span>] (Hidden2<span class="op">-</span><span class="dv">2</span>) <span class="op">--</span> node [midway] {$<span class="op">-</span><span class="fl">1.00</span>$} (Output)<span class="op">;</span> </span>
<span id="cb68-68"><a href="#cb68-68"></a>\end{tikzpicture}</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-display" data-execution_count="60">
<div>
<figure class="figure">
<p><img src="index_files/figure-html/cell-61-output-1.svg" class="img-fluid figure-img"></p>
</figure>
</div>
</div>
</div>
<p>Consequently, we have:</p>
<div class="cell" data-execution_count="61">
<details class="code-fold">
<summary>Show the code</summary>
<div class="sourceCode cell-code" id="cb69"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb69-1"><a href="#cb69-1"></a><span class="op">%%</span>itikz <span class="op">--</span>temp<span class="op">-</span><span class="bu">dir</span> <span class="op">--</span>tex<span class="op">-</span>packages<span class="op">=</span>tikz,pgfplots <span class="op">--</span>tikz<span class="op">-</span>libraries<span class="op">=</span>arrows <span class="op">--</span>implicit<span class="op">-</span>standalone</span>
<span id="cb69-2"><a href="#cb69-2"></a>\begin{tikzpicture}[scale<span class="op">=</span><span class="fl">1.5</span>]</span>
<span id="cb69-3"><a href="#cb69-3"></a>\begin{axis}[grid,ymin<span class="op">=-</span><span class="dv">2</span>,ymax<span class="op">=</span><span class="dv">2</span>,ytick<span class="op">=</span>{<span class="op">-</span><span class="dv">2</span>,<span class="op">-</span><span class="dv">1</span>,...,<span class="dv">2</span>},xmin<span class="op">=</span><span class="dv">0</span>,xmax<span class="op">=</span><span class="dv">1</span>]</span>
<span id="cb69-4"><a href="#cb69-4"></a>\addplot[color<span class="op">=</span>blue,thick,samples<span class="op">=</span><span class="dv">1000</span>]{<span class="op">-</span><span class="bu">max</span>(<span class="op">-</span><span class="bu">max</span>(<span class="dv">6</span><span class="op">*</span>x,<span class="dv">0</span>)<span class="op">+</span><span class="fl">0.70</span>,<span class="dv">0</span>))<span class="op">+</span><span class="fl">0.70</span><span class="op">-</span><span class="bu">max</span>(<span class="op">-</span><span class="bu">max</span>(<span class="fl">3.50</span><span class="op">*</span>x <span class="op">-</span> <span class="fl">0.42</span>,<span class="dv">0</span>)<span class="op">+</span><span class="fl">0.27</span>,<span class="dv">0</span>)}<span class="op">;</span></span>
<span id="cb69-5"><a href="#cb69-5"></a>\addplot[color<span class="op">=</span>green,samples<span class="op">=</span><span class="dv">1000</span>,domain<span class="op">=</span><span class="dv">0</span>:<span class="dv">1</span>]{sin(deg(<span class="dv">2</span><span class="op">*</span><span class="fl">3.14</span><span class="op">*</span>x))}<span class="op">;</span></span>
<span id="cb69-6"><a href="#cb69-6"></a>\end{axis}</span>
<span id="cb69-7"><a href="#cb69-7"></a>\end{tikzpicture}</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-display" data-execution_count="61">
<div>
<figure class="figure">
<p><img src="index_files/figure-html/cell-62-output-1.svg" class="img-fluid figure-img"></p>
</figure>
</div>
</div>
</div>
<p>And again, just like the first pair, we use the bottom pair to fix the vertical offset.</p>
<div class="cell" data-execution_count="62">
<details class="code-fold">
<summary>Show the code</summary>
<div class="sourceCode cell-code" id="cb70"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb70-1"><a href="#cb70-1"></a><span class="op">%%</span>itikz <span class="op">--</span>temp<span class="op">-</span><span class="bu">dir</span> <span class="op">--</span>tex<span class="op">-</span>packages<span class="op">=</span>tikz <span class="op">--</span>tikz<span class="op">-</span>libraries<span class="op">=</span>arrows <span class="op">--</span>implicit<span class="op">-</span>standalone</span>
<span id="cb70-2"><a href="#cb70-2"></a>\begin{tikzpicture}</span>
<span id="cb70-3"><a href="#cb70-3"></a></span>
<span id="cb70-4"><a href="#cb70-4"></a>\node[circle, </span>
<span id="cb70-5"><a href="#cb70-5"></a>    minimum size <span class="op">=</span> <span class="dv">15</span><span class="er">mm</span>,</span>
<span id="cb70-6"><a href="#cb70-6"></a>    fill<span class="op">=</span>red<span class="op">!</span><span class="dv">30</span></span>
<span id="cb70-7"><a href="#cb70-7"></a>    ] (Input) at (<span class="dv">0</span>,<span class="dv">0</span>) {\large $x_1$}<span class="op">;</span></span>
<span id="cb70-8"><a href="#cb70-8"></a></span>
<span id="cb70-9"><a href="#cb70-9"></a>\foreach \i <span class="kw">in</span> {<span class="dv">1</span>,<span class="dv">2</span>,...,<span class="dv">8</span>}</span>
<span id="cb70-10"><a href="#cb70-10"></a>{</span>
<span id="cb70-11"><a href="#cb70-11"></a>    \node[circle, </span>
<span id="cb70-12"><a href="#cb70-12"></a>        minimum size <span class="op">=</span> <span class="dv">15</span><span class="er">mm</span>,</span>
<span id="cb70-13"><a href="#cb70-13"></a>        fill<span class="op">=</span>blue<span class="op">!</span><span class="dv">50</span>,</span>
<span id="cb70-14"><a href="#cb70-14"></a>        yshift<span class="op">=</span><span class="dv">90</span> mm</span>
<span id="cb70-15"><a href="#cb70-15"></a>        ] (Hidden1<span class="op">-</span>\i) at (<span class="fl">3.0</span>,<span class="op">-</span>\i <span class="op">*</span> <span class="dv">2</span>) {\large $h_\i<span class="op">^</span>{(<span class="dv">1</span>)}$}<span class="op">;</span></span>
<span id="cb70-16"><a href="#cb70-16"></a>        </span>
<span id="cb70-17"><a href="#cb70-17"></a>}</span>
<span id="cb70-18"><a href="#cb70-18"></a>\foreach \i <span class="kw">in</span> {<span class="dv">1</span>,<span class="dv">2</span>,...,<span class="dv">8</span>}</span>
<span id="cb70-19"><a href="#cb70-19"></a>{</span>
<span id="cb70-20"><a href="#cb70-20"></a>    \node[circle, </span>
<span id="cb70-21"><a href="#cb70-21"></a>        minimum size <span class="op">=</span> <span class="dv">15</span><span class="er">mm</span>,</span>
<span id="cb70-22"><a href="#cb70-22"></a>        fill<span class="op">=</span>blue<span class="op">!</span><span class="dv">50</span>,</span>
<span id="cb70-23"><a href="#cb70-23"></a>        yshift<span class="op">=</span><span class="dv">90</span> mm</span>
<span id="cb70-24"><a href="#cb70-24"></a>        ] (Hidden2<span class="op">-</span>\i) at (<span class="fl">6.0</span>,<span class="op">-</span>\i <span class="op">*</span> <span class="dv">2</span>) {\large $h_\i<span class="op">^</span>{(<span class="dv">2</span>)}$}<span class="op">;</span></span>
<span id="cb70-25"><a href="#cb70-25"></a>        </span>
<span id="cb70-26"><a href="#cb70-26"></a>}</span>
<span id="cb70-27"><a href="#cb70-27"></a></span>
<span id="cb70-28"><a href="#cb70-28"></a>\node[circle, </span>
<span id="cb70-29"><a href="#cb70-29"></a>    minimum size <span class="op">=</span> <span class="dv">15</span><span class="er">mm</span>,</span>
<span id="cb70-30"><a href="#cb70-30"></a>    fill<span class="op">=</span>red<span class="op">!</span><span class="dv">30</span></span>
<span id="cb70-31"><a href="#cb70-31"></a>    ] (Output) at (<span class="dv">9</span>,<span class="dv">0</span>) {\large $\hat{y}_1$}<span class="op">;</span></span>
<span id="cb70-32"><a href="#cb70-32"></a></span>
<span id="cb70-33"><a href="#cb70-33"></a><span class="op">%</span> Connect neurons In<span class="op">-</span>Hidden1</span>
<span id="cb70-34"><a href="#cb70-34"></a>\foreach \j <span class="kw">in</span> {<span class="dv">3</span>,...,<span class="dv">7</span>}</span>
<span id="cb70-35"><a href="#cb70-35"></a>{</span>
<span id="cb70-36"><a href="#cb70-36"></a>    \draw[<span class="op">-&gt;</span>, shorten <span class="op">&gt;=</span><span class="dv">1</span><span class="er">pt</span>] (Input) <span class="op">--</span> (Hidden1<span class="op">-</span>\j)<span class="op">;</span>   </span>
<span id="cb70-37"><a href="#cb70-37"></a>}</span>
<span id="cb70-38"><a href="#cb70-38"></a><span class="op">%</span> Connect neurons Hidden1<span class="op">-</span>Hidden2</span>
<span id="cb70-39"><a href="#cb70-39"></a>\foreach \i <span class="kw">in</span> {<span class="dv">3</span>,...,<span class="dv">7</span>}</span>
<span id="cb70-40"><a href="#cb70-40"></a>{</span>
<span id="cb70-41"><a href="#cb70-41"></a>    </span>
<span id="cb70-42"><a href="#cb70-42"></a>        \draw[<span class="op">-&gt;</span>, shorten <span class="op">&gt;=</span><span class="dv">1</span><span class="er">pt</span>] (Hidden1<span class="op">-</span>\i) <span class="op">--</span> (Hidden2<span class="op">-</span>\i)<span class="op">;</span>   </span>
<span id="cb70-43"><a href="#cb70-43"></a>    </span>
<span id="cb70-44"><a href="#cb70-44"></a>}</span>
<span id="cb70-45"><a href="#cb70-45"></a></span>
<span id="cb70-46"><a href="#cb70-46"></a>\foreach \i <span class="kw">in</span> {<span class="dv">3</span>,...,<span class="dv">7</span>}</span>
<span id="cb70-47"><a href="#cb70-47"></a>{</span>
<span id="cb70-48"><a href="#cb70-48"></a>    </span>
<span id="cb70-49"><a href="#cb70-49"></a>        \draw[<span class="op">-&gt;</span>, shorten <span class="op">&gt;=</span><span class="dv">1</span><span class="er">pt</span>] (Hidden2<span class="op">-</span>\i) <span class="op">--</span> (Output)<span class="op">;</span>   </span>
<span id="cb70-50"><a href="#cb70-50"></a>}</span>
<span id="cb70-51"><a href="#cb70-51"></a>\draw[<span class="op">-&gt;</span>, shorten <span class="op">&gt;=</span><span class="dv">1</span><span class="er">pt</span>] (Input) <span class="op">--</span> node [midway] {$<span class="fl">6.00</span>$} (Hidden1<span class="op">-</span><span class="dv">1</span>)<span class="op">;</span>   </span>
<span id="cb70-52"><a href="#cb70-52"></a>\draw[<span class="op">-&gt;</span>, shorten <span class="op">&gt;=</span><span class="dv">1</span><span class="er">pt</span>] (Hidden1<span class="op">-</span><span class="dv">1</span>) <span class="op">--</span> node [midway,above] {$<span class="op">-</span><span class="fl">1.00</span>$} (Hidden2<span class="op">-</span><span class="dv">1</span>)<span class="op">;</span> </span>
<span id="cb70-53"><a href="#cb70-53"></a>\draw[<span class="op">-&gt;</span>, shorten <span class="op">&gt;=</span><span class="dv">1</span><span class="er">pt</span>] (Hidden2<span class="op">-</span><span class="dv">1</span>) <span class="op">--</span> node [midway] {$<span class="op">-</span><span class="fl">1.00</span>$} (Output)<span class="op">;</span> </span>
<span id="cb70-54"><a href="#cb70-54"></a>\draw[<span class="op">-&gt;</span>, shorten <span class="op">&gt;=</span><span class="dv">1</span><span class="er">pt</span>] (<span class="dv">6</span>,<span class="dv">6</span>) node [below] {$<span class="fl">0.70</span>$} <span class="op">--</span>  (Hidden2<span class="op">-</span><span class="dv">1</span>)<span class="op">;</span> </span>
<span id="cb70-55"><a href="#cb70-55"></a>\draw[<span class="op">-&gt;</span>, shorten <span class="op">&gt;=</span><span class="dv">1</span><span class="er">pt</span>] (<span class="dv">3</span>,<span class="dv">6</span>) node [below] {$<span class="fl">0.00</span>$} <span class="op">--</span>  (Hidden1<span class="op">-</span><span class="dv">1</span>)<span class="op">;</span> </span>
<span id="cb70-56"><a href="#cb70-56"></a></span>
<span id="cb70-57"><a href="#cb70-57"></a>\draw[<span class="op">-&gt;</span>, shorten <span class="op">&gt;=</span><span class="dv">1</span><span class="er">pt</span>] (Input) <span class="op">--</span> node [midway] {$<span class="fl">0.00</span>$} (Hidden1<span class="op">-</span><span class="dv">8</span>)<span class="op">;</span> </span>
<span id="cb70-58"><a href="#cb70-58"></a>\draw[<span class="op">-&gt;</span>, shorten <span class="op">&gt;=</span><span class="dv">1</span><span class="er">pt</span>] (<span class="dv">3</span>,<span class="op">-</span><span class="dv">9</span>) node [below] {$<span class="fl">0.00</span>$} <span class="op">--</span>  (Hidden1<span class="op">-</span><span class="dv">8</span>)<span class="op">;</span> </span>
<span id="cb70-59"><a href="#cb70-59"></a>\draw[<span class="op">-&gt;</span>, shorten <span class="op">&gt;=</span><span class="dv">1</span><span class="er">pt</span>] (Hidden1<span class="op">-</span><span class="dv">8</span>) <span class="op">--</span> node [midway,above] {$<span class="fl">0.00</span>$} (Hidden2<span class="op">-</span><span class="dv">8</span>)<span class="op">;</span> </span>
<span id="cb70-60"><a href="#cb70-60"></a>\draw[<span class="op">-&gt;</span>, shorten <span class="op">&gt;=</span><span class="dv">1</span><span class="er">pt</span>] (<span class="dv">6</span>,<span class="op">-</span><span class="dv">9</span>) node [below] {$<span class="fl">1.00</span>$} <span class="op">--</span>  (Hidden2<span class="op">-</span><span class="dv">8</span>)<span class="op">;</span> </span>
<span id="cb70-61"><a href="#cb70-61"></a>\draw[<span class="op">-&gt;</span>, shorten <span class="op">&gt;=</span><span class="dv">1</span><span class="er">pt</span>] (Hidden2<span class="op">-</span><span class="dv">8</span>) <span class="op">--</span> node [midway] {$<span class="fl">0.97</span>$} (Output)<span class="op">;</span> </span>
<span id="cb70-62"><a href="#cb70-62"></a></span>
<span id="cb70-63"><a href="#cb70-63"></a>\draw[<span class="op">-&gt;</span>, shorten <span class="op">&gt;=</span><span class="dv">1</span><span class="er">pt</span>] (Input) <span class="op">--</span> node [midway] {$<span class="fl">3.50</span>$} (Hidden1<span class="op">-</span><span class="dv">2</span>)<span class="op">;</span> </span>
<span id="cb70-64"><a href="#cb70-64"></a>\draw[<span class="op">-&gt;</span>, shorten <span class="op">&gt;=</span><span class="dv">1</span><span class="er">pt</span>] (<span class="dv">3</span>,<span class="dv">4</span>) node [below] {$<span class="op">-</span><span class="fl">0.42</span>$} <span class="op">--</span>  (Hidden1<span class="op">-</span><span class="dv">2</span>)<span class="op">;</span> </span>
<span id="cb70-65"><a href="#cb70-65"></a>\draw[<span class="op">-&gt;</span>, shorten <span class="op">&gt;=</span><span class="dv">1</span><span class="er">pt</span>] (Hidden1<span class="op">-</span><span class="dv">2</span>) <span class="op">--</span> node [midway,above] {$<span class="op">-</span><span class="fl">1.00</span>$} (Hidden2<span class="op">-</span><span class="dv">2</span>)<span class="op">;</span> </span>
<span id="cb70-66"><a href="#cb70-66"></a>\draw[<span class="op">-&gt;</span>, shorten <span class="op">&gt;=</span><span class="dv">1</span><span class="er">pt</span>] (<span class="dv">6</span>,<span class="dv">4</span>) node [below] {$<span class="fl">0.27</span>$} <span class="op">--</span>  (Hidden2<span class="op">-</span><span class="dv">2</span>)<span class="op">;</span> </span>
<span id="cb70-67"><a href="#cb70-67"></a>\draw[<span class="op">-&gt;</span>, shorten <span class="op">&gt;=</span><span class="dv">1</span><span class="er">pt</span>] (Hidden2<span class="op">-</span><span class="dv">2</span>) <span class="op">--</span> node [midway] {$<span class="op">-</span><span class="fl">1.00</span>$} (Output)<span class="op">;</span> </span>
<span id="cb70-68"><a href="#cb70-68"></a>\end{tikzpicture}</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-display" data-execution_count="62">
<div>
<figure class="figure">
<p><img src="index_files/figure-html/cell-63-output-1.svg" class="img-fluid figure-img"></p>
</figure>
</div>
</div>
</div>
<p>We get:</p>
<div class="cell" data-execution_count="63">
<details class="code-fold">
<summary>Show the code</summary>
<div class="sourceCode cell-code" id="cb71"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb71-1"><a href="#cb71-1"></a><span class="op">%%</span>itikz <span class="op">--</span>temp<span class="op">-</span><span class="bu">dir</span> <span class="op">--</span>tex<span class="op">-</span>packages<span class="op">=</span>tikz,pgfplots <span class="op">--</span>tikz<span class="op">-</span>libraries<span class="op">=</span>arrows <span class="op">--</span>implicit<span class="op">-</span>standalone</span>
<span id="cb71-2"><a href="#cb71-2"></a>\begin{tikzpicture}[scale<span class="op">=</span><span class="fl">1.5</span>]</span>
<span id="cb71-3"><a href="#cb71-3"></a>\begin{axis}[grid,ymin<span class="op">=-</span><span class="dv">2</span>,ymax<span class="op">=</span><span class="dv">2</span>,ytick<span class="op">=</span>{<span class="op">-</span><span class="dv">2</span>,<span class="op">-</span><span class="dv">1</span>,...,<span class="dv">2</span>},xmin<span class="op">=</span><span class="dv">0</span>,xmax<span class="op">=</span><span class="dv">1</span>]</span>
<span id="cb71-4"><a href="#cb71-4"></a>\addplot[color<span class="op">=</span>blue,thick,samples<span class="op">=</span><span class="dv">1000</span>]{<span class="op">-</span><span class="bu">max</span>(<span class="op">-</span><span class="bu">max</span>(<span class="dv">6</span><span class="op">*</span>x,<span class="dv">0</span>)<span class="op">+</span><span class="fl">0.70</span>,<span class="dv">0</span>))<span class="op">+</span><span class="fl">0.97</span><span class="op">-</span><span class="bu">max</span>(<span class="op">-</span><span class="bu">max</span>(<span class="fl">3.50</span><span class="op">*</span>x <span class="op">-</span> <span class="fl">0.42</span>,<span class="dv">0</span>)<span class="op">+</span><span class="fl">0.27</span>,<span class="dv">0</span>)}<span class="op">;</span></span>
<span id="cb71-5"><a href="#cb71-5"></a>\addplot[color<span class="op">=</span>green,samples<span class="op">=</span><span class="dv">1000</span>,domain<span class="op">=</span><span class="dv">0</span>:<span class="dv">1</span>]{sin(deg(<span class="dv">2</span><span class="op">*</span><span class="fl">3.14</span><span class="op">*</span>x))}<span class="op">;</span></span>
<span id="cb71-6"><a href="#cb71-6"></a>\end{axis}</span>
<span id="cb71-7"><a href="#cb71-7"></a>\end{tikzpicture}</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-display" data-execution_count="63">
<div>
<figure class="figure">
<p><img src="index_files/figure-html/cell-64-output-1.svg" class="img-fluid figure-img"></p>
</figure>
</div>
</div>
</div>
<p>We then just continue this methodology. It should begin to make more sense to you now, how more neurons can enable more unique areas of effect, why we need two or more hidden layers, and why we need nonlinear activation functions to map nonlinear problems.</p>
<p>We can write a <code>ReLUActivation</code> class to represent the ReLU activation function:</p>
<div class="cell" data-execution_count="64">
<div class="sourceCode cell-code" id="cb72"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb72-1"><a href="#cb72-1"></a><span class="kw">class</span> ReLUActivation:</span>
<span id="cb72-2"><a href="#cb72-2"></a></span>
<span id="cb72-3"><a href="#cb72-3"></a>    <span class="co"># Forward pass</span></span>
<span id="cb72-4"><a href="#cb72-4"></a>    <span class="kw">def</span> forward(<span class="va">self</span>, inputs):</span>
<span id="cb72-5"><a href="#cb72-5"></a>        <span class="co"># Calculate output values from the inputs</span></span>
<span id="cb72-6"><a href="#cb72-6"></a>        <span class="va">self</span>.output <span class="op">=</span> np.maximum(<span class="dv">0</span>, inputs)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>Let’s apply this activation function to the <code>DenseLayer</code>’s outputs in our code:</p>
<div class="cell" data-execution_count="65">
<div class="sourceCode cell-code" id="cb73"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb73-1"><a href="#cb73-1"></a><span class="im">from</span> nnfs.datasets <span class="im">import</span> spiral_data</span>
<span id="cb73-2"><a href="#cb73-2"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb73-3"><a href="#cb73-3"></a></span>
<span id="cb73-4"><a href="#cb73-4"></a><span class="co"># Create dataset</span></span>
<span id="cb73-5"><a href="#cb73-5"></a>X, y <span class="op">=</span> spiral_data(samples<span class="op">=</span><span class="dv">100</span>, classes<span class="op">=</span><span class="dv">3</span>)</span>
<span id="cb73-6"><a href="#cb73-6"></a></span>
<span id="cb73-7"><a href="#cb73-7"></a><span class="co"># Create Dense layer with 2 input features and 3 output values</span></span>
<span id="cb73-8"><a href="#cb73-8"></a>dense1 <span class="op">=</span> DenseLayer(<span class="dv">2</span>, <span class="dv">3</span>)</span>
<span id="cb73-9"><a href="#cb73-9"></a></span>
<span id="cb73-10"><a href="#cb73-10"></a><span class="co"># Create ReLU activation function (to be used with the DenseLayer)</span></span>
<span id="cb73-11"><a href="#cb73-11"></a>activation1 <span class="op">=</span> ReLUActivation()</span>
<span id="cb73-12"><a href="#cb73-12"></a></span>
<span id="cb73-13"><a href="#cb73-13"></a><span class="co"># Make a forward pass of our training data through this layer</span></span>
<span id="cb73-14"><a href="#cb73-14"></a>dense1.forward(X)</span>
<span id="cb73-15"><a href="#cb73-15"></a></span>
<span id="cb73-16"><a href="#cb73-16"></a><span class="co"># Forward pass through our activation function</span></span>
<span id="cb73-17"><a href="#cb73-17"></a><span class="co"># Takes in output from the previous layer</span></span>
<span id="cb73-18"><a href="#cb73-18"></a>activation1.forward(dense1.output)</span>
<span id="cb73-19"><a href="#cb73-19"></a></span>
<span id="cb73-20"><a href="#cb73-20"></a><span class="co"># Let's see output of the first few samples</span></span>
<span id="cb73-21"><a href="#cb73-21"></a><span class="bu">print</span>(activation1.output[:<span class="dv">5</span>])</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>[[0.0000000e+00 0.0000000e+00 0.0000000e+00]
 [1.3520580e-04 1.8173116e-05 0.0000000e+00]
 [2.3245417e-04 0.0000000e+00 0.0000000e+00]
 [3.8226307e-04 0.0000000e+00 0.0000000e+00]
 [5.7436468e-04 0.0000000e+00 0.0000000e+00]]</code></pre>
</div>
</div>
<p>As we can see, negative values have been clipped (modified to zero). That’s all there is to the rectified linear activation function used in the hidden layer. Let’s talk about the activation function that we are going to use on the output of the last layer.</p>
</section>
<section id="the-softmax-activation-function" class="level2">
<h2 class="anchored" data-anchor-id="the-softmax-activation-function">The Softmax Activation function</h2>
<p>In our case, we’re looking to get this model to be a classifier, so we want an activation function meant for classification. One of these is the softmax activation function. First, why are we bothering with another activation function? It just depends on what our overall goals are.</p>
<p>The rectified linear unit is unbounded, not normalized with other units and exclusive. “Not normalized” implies the values can be anything, an output of <code>[12,99,318]</code> is without context, and exclusive means each output is independent of others. To address this lack of context, the softmax activation function on the output data can take in non-normalized, or uncalibrated, inputs and produce a normalized distribution of probabilities for our classes. In the case of classification, what we want to see is a prediction of which class the network thinks the input represents. This distribution returned by the softmax activation function represents confidence scores in our overarching algorithm/program that uses this network. For example, if our network has a confidence distirbution for two classes <span class="math inline">\([0.45,0.55]\)</span>, the prediction is the <span class="math inline">\(2\)</span>nd class, but the confidence in this prediction isn’t very high.</p>
<p>Maybe our program wouldn’t act in this case, since it’s not very confident.</p>
<p>The softmax function takes as input a vector of <span class="math inline">\(L\)</span> real numbers and normalizes it into a probability distribution consisting of <span class="math inline">\(L\)</span> probabilities proportional to the exponentials of the input numbers.</p>
<p><em>Definition</em>. The standard(unit) <strong>softmax</strong> function <span class="math inline">\(\sigma:\mathbf{R}^L \to (0,1)^L\)</span> takes a vector <span class="math inline">\(\mathbf{z}=(z_1,\ldots,z_l)\in\mathbf{R}^L\)</span> and computes each component of the vector <span class="math inline">\(\sigma(\mathbf{z})\in(0,1)^L\)</span> with:</p>
<p><span class="math display">\[\begin{align*}
\sigma(\mathbf{z})_i = \frac{e^{z_{i}}}{\sum_{l=1}^{L}e^{z_{l}}}
\end{align*}\]</span></p>
<p>That might look daunting, but it’s easy to follow. Suppose the example outputs from a neural network layer are:</p>
<div class="cell" data-execution_count="66">
<div class="sourceCode cell-code" id="cb75"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb75-1"><a href="#cb75-1"></a>layer_outputs <span class="op">=</span> [<span class="fl">4.80</span>, <span class="fl">1.21</span>, <span class="fl">2.385</span>]</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>Then, the normalized values are:</p>
<div class="cell" data-execution_count="67">
<div class="sourceCode cell-code" id="cb76"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb76-1"><a href="#cb76-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb76-2"><a href="#cb76-2"></a></span>
<span id="cb76-3"><a href="#cb76-3"></a>norm_values <span class="op">=</span> np.exp(layer_outputs)<span class="op">/</span>np.<span class="bu">sum</span>(np.exp(layer_outputs))</span>
<span id="cb76-4"><a href="#cb76-4"></a><span class="bu">print</span>(norm_values)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>[0.89528266 0.02470831 0.08000903]</code></pre>
</div>
</div>
<p>To train in batches, we need to convert this functionality to accept layer outputs in batches. Do this is easy:</p>
<div class="cell" data-execution_count="68">
<div class="sourceCode cell-code" id="cb78"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb78-1"><a href="#cb78-1"></a>layer_outputs <span class="op">=</span> np.random.randn(<span class="dv">100</span>,<span class="dv">3</span>)</span>
<span id="cb78-2"><a href="#cb78-2"></a>norm_values <span class="op">=</span> np.exp(layer_outputs)<span class="op">/</span>np.<span class="bu">sum</span>(np.exp(layer_outputs),axis<span class="op">=</span><span class="dv">1</span>,keepdims<span class="op">=</span><span class="va">True</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>We can now write a <code>SoftmaxActivation</code> class as:</p>
<div class="cell" data-execution_count="69">
<div class="sourceCode cell-code" id="cb79"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb79-1"><a href="#cb79-1"></a><span class="co"># Softmax activation</span></span>
<span id="cb79-2"><a href="#cb79-2"></a><span class="kw">class</span> SoftmaxActivation:</span>
<span id="cb79-3"><a href="#cb79-3"></a></span>
<span id="cb79-4"><a href="#cb79-4"></a>    <span class="co"># Forward pass</span></span>
<span id="cb79-5"><a href="#cb79-5"></a>    <span class="kw">def</span> forward(<span class="va">self</span>, inputs):</span>
<span id="cb79-6"><a href="#cb79-6"></a>        exp_values <span class="op">=</span> np.exp(inputs <span class="op">-</span> np.<span class="bu">max</span>(inputs, axis<span class="op">=</span><span class="dv">1</span>, keepdims<span class="op">=</span><span class="va">True</span>))</span>
<span id="cb79-7"><a href="#cb79-7"></a>        probabilities <span class="op">=</span> exp_values <span class="op">/</span> np.<span class="bu">sum</span>(exp_values, axis<span class="op">=</span><span class="dv">1</span>, keepdims<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb79-8"><a href="#cb79-8"></a>        <span class="va">self</span>.output <span class="op">=</span> probabilities</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>We also included a subtraction of the largest of the inputs before we do the exponentiation. This does not affect the output of the softmax function, since:</p>
<p><span class="math display">\[\begin{align*}
\frac{e^{z_{i}-||\mathbf{z}||}}{\sum_{l=1}^{L}e^{z_{l}-||\mathbf{z}||}} = \frac{e^{-||\mathbf{z}||}\cdot e^{z_{i}}}{e^{-||\mathbf{z}||}\cdot \sum_{l=1}^{L}e^{z_{l}}} = \sigma(\mathbf{z})_i
\end{align*}\]</span></p>
<p>There are two main pervasive challenges with neural networks : dead neurons and very large numbers (referred to as exploding values). Dead neurons and enormous numbers can wreak havoc down the line and render a network useless over time.</p>
</section>
<section id="the-output-layer" class="level2">
<h2 class="anchored" data-anchor-id="the-output-layer">The output layer</h2>
<p>Now, we can add another <code>DenseLayer</code> as the output layer, setting it to contain as many inputs as the previous layer outputs and as many outputs as our data includes classes. Then, we can apply the softmax function to the output of this new layer.</p>
<section id="full-code-upto-this-point" class="level3">
<h3 class="anchored" data-anchor-id="full-code-upto-this-point">Full code upto this point</h3>
<div class="cell" data-execution_count="70">
<div class="sourceCode cell-code" id="cb80"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb80-1"><a href="#cb80-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb80-2"><a href="#cb80-2"></a><span class="im">import</span> nnfs</span>
<span id="cb80-3"><a href="#cb80-3"></a><span class="im">from</span> nnfs.datasets <span class="im">import</span> spiral_data</span>
<span id="cb80-4"><a href="#cb80-4"></a></span>
<span id="cb80-5"><a href="#cb80-5"></a><span class="kw">class</span> DenseLayer:</span>
<span id="cb80-6"><a href="#cb80-6"></a></span>
<span id="cb80-7"><a href="#cb80-7"></a>    <span class="kw">def</span> <span class="fu">__init__</span>(<span class="va">self</span>, n_inputs, n_neurons):</span>
<span id="cb80-8"><a href="#cb80-8"></a>        <span class="co"># Initialize all weights and biases</span></span>
<span id="cb80-9"><a href="#cb80-9"></a>        <span class="va">self</span>.weights <span class="op">=</span> <span class="fl">0.01</span> <span class="op">*</span> np.random.randn(n_inputs,n_neurons)</span>
<span id="cb80-10"><a href="#cb80-10"></a>        <span class="va">self</span>.biases <span class="op">=</span> np.zeros((<span class="dv">1</span>,n_neurons))</span>
<span id="cb80-11"><a href="#cb80-11"></a>    </span>
<span id="cb80-12"><a href="#cb80-12"></a>    <span class="kw">def</span> forward(<span class="va">self</span>, inputs):</span>
<span id="cb80-13"><a href="#cb80-13"></a>        <span class="va">self</span>.output <span class="op">=</span> np.dot(inputs,<span class="va">self</span>.weights) <span class="op">+</span> <span class="va">self</span>.biases</span>
<span id="cb80-14"><a href="#cb80-14"></a></span>
<span id="cb80-15"><a href="#cb80-15"></a><span class="kw">class</span> ReLUActivation:</span>
<span id="cb80-16"><a href="#cb80-16"></a></span>
<span id="cb80-17"><a href="#cb80-17"></a>    <span class="co"># Forward pass</span></span>
<span id="cb80-18"><a href="#cb80-18"></a>    <span class="kw">def</span> forward(<span class="va">self</span>, inputs):</span>
<span id="cb80-19"><a href="#cb80-19"></a>        <span class="va">self</span>.output <span class="op">=</span> np.maximum(inputs, <span class="dv">0</span>)</span>
<span id="cb80-20"><a href="#cb80-20"></a></span>
<span id="cb80-21"><a href="#cb80-21"></a><span class="kw">class</span> SoftmaxActivation:</span>
<span id="cb80-22"><a href="#cb80-22"></a></span>
<span id="cb80-23"><a href="#cb80-23"></a>    <span class="co"># Forward pass</span></span>
<span id="cb80-24"><a href="#cb80-24"></a>    <span class="kw">def</span> forward(<span class="va">self</span>,inputs):</span>
<span id="cb80-25"><a href="#cb80-25"></a>        exp_values <span class="op">=</span> np.exp(inputs <span class="op">-</span> np.<span class="bu">max</span>(inputs, axis<span class="op">=</span><span class="dv">1</span>, keepdims<span class="op">=</span><span class="va">True</span>))</span>
<span id="cb80-26"><a href="#cb80-26"></a>        probabilities <span class="op">=</span> exp_values <span class="op">/</span> np.<span class="bu">sum</span>(exp_values, axis<span class="op">=</span><span class="dv">1</span>, keepdims<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb80-27"><a href="#cb80-27"></a>        <span class="va">self</span>.output <span class="op">=</span> probabilities</span>
<span id="cb80-28"><a href="#cb80-28"></a></span>
<span id="cb80-29"><a href="#cb80-29"></a><span class="co"># Create dataset</span></span>
<span id="cb80-30"><a href="#cb80-30"></a>X, y <span class="op">=</span> spiral_data(samples<span class="op">=</span><span class="dv">100</span>, classes<span class="op">=</span><span class="dv">3</span>)</span>
<span id="cb80-31"><a href="#cb80-31"></a></span>
<span id="cb80-32"><a href="#cb80-32"></a><span class="co"># Create a DenseLayer with 2 input features and 3 neurons</span></span>
<span id="cb80-33"><a href="#cb80-33"></a>dense1 <span class="op">=</span> DenseLayer(<span class="dv">2</span>, <span class="dv">3</span>)</span>
<span id="cb80-34"><a href="#cb80-34"></a></span>
<span id="cb80-35"><a href="#cb80-35"></a><span class="co"># Create ReLU Activation (to be used with DenseLayer)</span></span>
<span id="cb80-36"><a href="#cb80-36"></a>activation1 <span class="op">=</span> ReLUActivation()</span>
<span id="cb80-37"><a href="#cb80-37"></a></span>
<span id="cb80-38"><a href="#cb80-38"></a><span class="co"># Create a second DenseLayer with 3 input features and 3 output values</span></span>
<span id="cb80-39"><a href="#cb80-39"></a>dense2 <span class="op">=</span> DenseLayer(<span class="dv">3</span>, <span class="dv">3</span>)</span>
<span id="cb80-40"><a href="#cb80-40"></a></span>
<span id="cb80-41"><a href="#cb80-41"></a><span class="co"># Create Softmax activation to be used with the output layer</span></span>
<span id="cb80-42"><a href="#cb80-42"></a>activation2 <span class="op">=</span> SoftmaxActivation()</span>
<span id="cb80-43"><a href="#cb80-43"></a></span>
<span id="cb80-44"><a href="#cb80-44"></a><span class="co"># Make a forward pass of our training data through this layer</span></span>
<span id="cb80-45"><a href="#cb80-45"></a>dense1.forward(X)</span>
<span id="cb80-46"><a href="#cb80-46"></a></span>
<span id="cb80-47"><a href="#cb80-47"></a><span class="co"># Make a forward pass through the activation function </span></span>
<span id="cb80-48"><a href="#cb80-48"></a><span class="co"># It takes the output of the first dense layer</span></span>
<span id="cb80-49"><a href="#cb80-49"></a>activation1.forward(dense1.output)</span>
<span id="cb80-50"><a href="#cb80-50"></a></span>
<span id="cb80-51"><a href="#cb80-51"></a><span class="co"># Make a forward pass through the second DenseLayer</span></span>
<span id="cb80-52"><a href="#cb80-52"></a><span class="co"># It takes outputs of the activation function of the first layer</span></span>
<span id="cb80-53"><a href="#cb80-53"></a><span class="co"># as inputs</span></span>
<span id="cb80-54"><a href="#cb80-54"></a>dense2.forward(activation1.output)</span>
<span id="cb80-55"><a href="#cb80-55"></a></span>
<span id="cb80-56"><a href="#cb80-56"></a><span class="co"># Make a forward pass through activation function</span></span>
<span id="cb80-57"><a href="#cb80-57"></a><span class="co"># It takes outputs of the second dense layer</span></span>
<span id="cb80-58"><a href="#cb80-58"></a>activation2.forward(dense2.output)</span>
<span id="cb80-59"><a href="#cb80-59"></a></span>
<span id="cb80-60"><a href="#cb80-60"></a><span class="co"># Let's see output of the first few examples</span></span>
<span id="cb80-61"><a href="#cb80-61"></a><span class="bu">print</span>(activation2.output[:<span class="dv">5</span>])</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>[[0.33333334 0.33333334 0.33333334]
 [0.33333322 0.3333335  0.33333322]
 [0.3333332  0.3333332  0.3333336 ]
 [0.3333332  0.3333336  0.3333332 ]
 [0.33333287 0.33333436 0.33333275]]</code></pre>
</div>
</div>
<p>We’ve completed what we need for forward-passing data through the model.</p>
<p>Our example model is currently random. To remedy this, we need a way to calculate how wrong the neural network is at current predictions and begin adjusting weights and biases to decrease error over time. Thus, our next step is to quantify how wrong the model is through what’s defined as a <strong>loss function</strong>.</p>


<!-- -->

</section>
</section>

</main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const isCodeAnnotation = (el) => {
    for (const clz of el.classList) {
      if (clz.startsWith('code-annotation-')) {                     
        return true;
      }
    }
    return false;
  }
  const onCopySuccess = function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Copied!");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  }
  const getTextToCopy = function(trigger) {
      const codeEl = trigger.previousElementSibling.cloneNode(true);
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
  }
  const clipboard = new window.ClipboardJS('.code-copy-button:not([data-in-quarto-modal])', {
    text: getTextToCopy
  });
  clipboard.on('success', onCopySuccess);
  if (window.document.getElementById('quarto-embedded-source-code-modal')) {
    const clipboardModal = new window.ClipboardJS('.code-copy-button[data-in-quarto-modal]', {
      text: getTextToCopy,
      container: window.document.getElementById('quarto-embedded-source-code-modal')
    });
    clipboardModal.on('success', onCopySuccess);
  }
  const viewSource = window.document.getElementById('quarto-view-source') ||
                     window.document.getElementById('quarto-code-tools-source');
  if (viewSource) {
    const sourceUrl = viewSource.getAttribute("data-quarto-source-url");
    viewSource.addEventListener("click", function(e) {
      if (sourceUrl) {
        // rstudio viewer pane
        if (/\bcapabilities=\b/.test(window.location)) {
          window.open(sourceUrl);
        } else {
          window.location.href = sourceUrl;
        }
      } else {
        const modal = new bootstrap.Modal(document.getElementById('quarto-embedded-source-code-modal'));
        modal.show();
      }
      return false;
    });
  }
  function toggleCodeHandler(show) {
    return function(e) {
      const detailsSrc = window.document.querySelectorAll(".cell > details > .sourceCode");
      for (let i=0; i<detailsSrc.length; i++) {
        const details = detailsSrc[i].parentElement;
        if (show) {
          details.open = true;
        } else {
          details.removeAttribute("open");
        }
      }
      const cellCodeDivs = window.document.querySelectorAll(".cell > .sourceCode");
      const fromCls = show ? "hidden" : "unhidden";
      const toCls = show ? "unhidden" : "hidden";
      for (let i=0; i<cellCodeDivs.length; i++) {
        const codeDiv = cellCodeDivs[i];
        if (codeDiv.classList.contains(fromCls)) {
          codeDiv.classList.remove(fromCls);
          codeDiv.classList.add(toCls);
        } 
      }
      return false;
    }
  }
  const hideAllCode = window.document.getElementById("quarto-hide-all-code");
  if (hideAllCode) {
    hideAllCode.addEventListener("click", toggleCodeHandler(false));
  }
  const showAllCode = window.document.getElementById("quarto-show-all-code");
  if (showAllCode) {
    showAllCode.addEventListener("click", toggleCodeHandler(true));
  }
    var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
    var mailtoRegex = new RegExp(/^mailto:/);
      var filterRegex = new RegExp('/' + window.location.host + '/');
    var isInternal = (href) => {
        return filterRegex.test(href) || localhostRegex.test(href) || mailtoRegex.test(href);
    }
    // Inspect non-navigation links and adorn them if external
 	var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item):not(.quarto-navigation-tool):not(.about-link)');
    for (var i=0; i<links.length; i++) {
      const link = links[i];
      if (!isInternal(link.href)) {
        // undo the damage that might have been done by quarto-nav.js in the case of
        // links that we want to consider external
        if (link.dataset.originalHref !== undefined) {
          link.href = link.dataset.originalHref;
        }
      }
    }
  function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
    const config = {
      allowHTML: true,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start',
    };
    if (contentFn) {
      config.content = contentFn;
    }
    if (onTriggerFn) {
      config.onTrigger = onTriggerFn;
    }
    if (onUntriggerFn) {
      config.onUntrigger = onUntriggerFn;
    }
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      if (note) {
        return note.innerHTML;
      } else {
        return "";
      }
    });
  }
  const xrefs = window.document.querySelectorAll('a.quarto-xref');
  const processXRef = (id, note) => {
    // Strip column container classes
    const stripColumnClz = (el) => {
      el.classList.remove("page-full", "page-columns");
      if (el.children) {
        for (const child of el.children) {
          stripColumnClz(child);
        }
      }
    }
    stripColumnClz(note)
    if (id === null || id.startsWith('sec-')) {
      // Special case sections, only their first couple elements
      const container = document.createElement("div");
      if (note.children && note.children.length > 2) {
        container.appendChild(note.children[0].cloneNode(true));
        for (let i = 1; i < note.children.length; i++) {
          const child = note.children[i];
          if (child.tagName === "P" && child.innerText === "") {
            continue;
          } else {
            container.appendChild(child.cloneNode(true));
            break;
          }
        }
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(container);
        }
        return container.innerHTML
      } else {
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(note);
        }
        return note.innerHTML;
      }
    } else {
      // Remove any anchor links if they are present
      const anchorLink = note.querySelector('a.anchorjs-link');
      if (anchorLink) {
        anchorLink.remove();
      }
      if (window.Quarto?.typesetMath) {
        window.Quarto.typesetMath(note);
      }
      if (note.classList.contains("callout")) {
        return note.outerHTML;
      } else {
        return note.innerHTML;
      }
    }
  }
  for (var i=0; i<xrefs.length; i++) {
    const xref = xrefs[i];
    tippyHover(xref, undefined, function(instance) {
      instance.disable();
      let url = xref.getAttribute('href');
      let hash = undefined; 
      if (url.startsWith('#')) {
        hash = url;
      } else {
        try { hash = new URL(url).hash; } catch {}
      }
      if (hash) {
        const id = hash.replace(/^#\/?/, "");
        const note = window.document.getElementById(id);
        if (note !== null) {
          try {
            const html = processXRef(id, note.cloneNode(true));
            instance.setContent(html);
          } finally {
            instance.enable();
            instance.show();
          }
        } else {
          // See if we can fetch this
          fetch(url.split('#')[0])
          .then(res => res.text())
          .then(html => {
            const parser = new DOMParser();
            const htmlDoc = parser.parseFromString(html, "text/html");
            const note = htmlDoc.getElementById(id);
            if (note !== null) {
              const html = processXRef(id, note);
              instance.setContent(html);
            } 
          }).finally(() => {
            instance.enable();
            instance.show();
          });
        }
      } else {
        // See if we can fetch a full url (with no hash to target)
        // This is a special case and we should probably do some content thinning / targeting
        fetch(url)
        .then(res => res.text())
        .then(html => {
          const parser = new DOMParser();
          const htmlDoc = parser.parseFromString(html, "text/html");
          const note = htmlDoc.querySelector('main.content');
          if (note !== null) {
            // This should only happen for chapter cross references
            // (since there is no id in the URL)
            // remove the first header
            if (note.children.length > 0 && note.children[0].tagName === "HEADER") {
              note.children[0].remove();
            }
            const html = processXRef(null, note);
            instance.setContent(html);
          } 
        }).finally(() => {
          instance.enable();
          instance.show();
        });
      }
    }, function(instance) {
    });
  }
      let selectedAnnoteEl;
      const selectorForAnnotation = ( cell, annotation) => {
        let cellAttr = 'data-code-cell="' + cell + '"';
        let lineAttr = 'data-code-annotation="' +  annotation + '"';
        const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
        return selector;
      }
      const selectCodeLines = (annoteEl) => {
        const doc = window.document;
        const targetCell = annoteEl.getAttribute("data-target-cell");
        const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
        const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
        const lines = annoteSpan.getAttribute("data-code-lines").split(",");
        const lineIds = lines.map((line) => {
          return targetCell + "-" + line;
        })
        let top = null;
        let height = null;
        let parent = null;
        if (lineIds.length > 0) {
            //compute the position of the single el (top and bottom and make a div)
            const el = window.document.getElementById(lineIds[0]);
            top = el.offsetTop;
            height = el.offsetHeight;
            parent = el.parentElement.parentElement;
          if (lineIds.length > 1) {
            const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
            const bottom = lastEl.offsetTop + lastEl.offsetHeight;
            height = bottom - top;
          }
          if (top !== null && height !== null && parent !== null) {
            // cook up a div (if necessary) and position it 
            let div = window.document.getElementById("code-annotation-line-highlight");
            if (div === null) {
              div = window.document.createElement("div");
              div.setAttribute("id", "code-annotation-line-highlight");
              div.style.position = 'absolute';
              parent.appendChild(div);
            }
            div.style.top = top - 2 + "px";
            div.style.height = height + 4 + "px";
            div.style.left = 0;
            let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
            if (gutterDiv === null) {
              gutterDiv = window.document.createElement("div");
              gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
              gutterDiv.style.position = 'absolute';
              const codeCell = window.document.getElementById(targetCell);
              const gutter = codeCell.querySelector('.code-annotation-gutter');
              gutter.appendChild(gutterDiv);
            }
            gutterDiv.style.top = top - 2 + "px";
            gutterDiv.style.height = height + 4 + "px";
          }
          selectedAnnoteEl = annoteEl;
        }
      };
      const unselectCodeLines = () => {
        const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
        elementsIds.forEach((elId) => {
          const div = window.document.getElementById(elId);
          if (div) {
            div.remove();
          }
        });
        selectedAnnoteEl = undefined;
      };
        // Handle positioning of the toggle
    window.addEventListener(
      "resize",
      throttle(() => {
        elRect = undefined;
        if (selectedAnnoteEl) {
          selectCodeLines(selectedAnnoteEl);
        }
      }, 10)
    );
    function throttle(fn, ms) {
    let throttle = false;
    let timer;
      return (...args) => {
        if(!throttle) { // first call gets through
            fn.apply(this, args);
            throttle = true;
        } else { // all the others get throttled
            if(timer) clearTimeout(timer); // cancel #2
            timer = setTimeout(() => {
              fn.apply(this, args);
              timer = throttle = false;
            }, ms);
        }
      };
    }
      // Attach click handler to the DT
      const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
      for (const annoteDlNode of annoteDls) {
        annoteDlNode.addEventListener('click', (event) => {
          const clickedEl = event.target;
          if (clickedEl !== selectedAnnoteEl) {
            unselectCodeLines();
            const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
            if (activeEl) {
              activeEl.classList.remove('code-annotation-active');
            }
            selectCodeLines(clickedEl);
            clickedEl.classList.add('code-annotation-active');
          } else {
            // Unselect the line
            unselectCodeLines();
            clickedEl.classList.remove('code-annotation-active');
          }
        });
      }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
});
</script>
<script src="https://giscus.app/client.js" data-repo="quasar-chunawala/quantdev" data-repo-id="R_kgDOL2t5-A" data-category="General" data-category-id="DIC_kwDOL2t5-M4ClndQ" data-mapping="title" data-reactions-enabled="1" data-emit-metadata="0" data-input-position="top" data-theme="light" data-lang="en" crossorigin="anonymous" async="">
</script>
<input type="hidden" id="giscus-base-theme" value="light">
<input type="hidden" id="giscus-alt-theme" value="dark"><div class="modal fade" id="quarto-embedded-source-code-modal" tabindex="-1" aria-labelledby="quarto-embedded-source-code-modal-label" aria-hidden="true"><div class="modal-dialog modal-dialog-scrollable"><div class="modal-content"><div class="modal-header"><h5 class="modal-title" id="quarto-embedded-source-code-modal-label">Source Code</h5><button class="btn-close" data-bs-dismiss="modal"></button></div><div class="modal-body"><div class="">
<div class="sourceCode" id="cb82" data-shortcodes="false"><pre class="sourceCode numberSource markdown number-lines code-with-copy"><code class="sourceCode markdown"><span id="cb82-1"><a href="#cb82-1"></a><span class="co">---</span></span>
<span id="cb82-2"><a href="#cb82-2"></a><span class="an">title:</span><span class="co"> "Coding a neural network layer"</span></span>
<span id="cb82-3"><a href="#cb82-3"></a><span class="an">author:</span><span class="co"> "Quasar"</span></span>
<span id="cb82-4"><a href="#cb82-4"></a><span class="an">date:</span><span class="co"> "2024-05-28"</span></span>
<span id="cb82-5"><a href="#cb82-5"></a><span class="an">categories:</span><span class="co"> [Machine Learning]      </span></span>
<span id="cb82-6"><a href="#cb82-6"></a><span class="an">image:</span><span class="co"> "image.jpg"</span></span>
<span id="cb82-7"><a href="#cb82-7"></a><span class="an">toc:</span><span class="co"> true</span></span>
<span id="cb82-8"><a href="#cb82-8"></a><span class="an">toc-depth:</span><span class="co"> 3</span></span>
<span id="cb82-9"><a href="#cb82-9"></a><span class="co">---</span></span>
<span id="cb82-10"><a href="#cb82-10"></a></span>
<span id="cb82-11"><a href="#cb82-11"></a><span class="fu">## Introduction</span></span>
<span id="cb82-12"><a href="#cb82-12"></a></span>
<span id="cb82-13"><a href="#cb82-13"></a>In 1943, McCulloch and Pitts introduced artificial intelligence to the world. Their idea was to develop an algorithmic approach to mimic the functionality of the human brain. Due to the structure of the brain consisting of a net of neurons, they introduced the so-called *artificial neurons* as building blocks.</span>
<span id="cb82-14"><a href="#cb82-14"></a></span>
<span id="cb82-15"><a href="#cb82-15"></a> In it's most simple form, the neuron consists of :</span>
<span id="cb82-16"><a href="#cb82-16"></a></span>
<span id="cb82-17"><a href="#cb82-17"></a><span class="ss">- </span>dendrites, which receive the information from other neurons</span>
<span id="cb82-18"><a href="#cb82-18"></a><span class="ss">- </span>soma, which processes the information</span>
<span id="cb82-19"><a href="#cb82-19"></a><span class="ss">- </span>synapse, transmits the output of this neuron</span>
<span id="cb82-20"><a href="#cb82-20"></a><span class="ss">- </span>axon, point of connection to other neurons</span>
<span id="cb82-21"><a href="#cb82-21"></a></span>
<span id="cb82-22"><a href="#cb82-22"></a>Consequently, a mathematical definition of an artificial neuron is as follows. </span>
<span id="cb82-23"><a href="#cb82-23"></a></span>
<span id="cb82-24"><a href="#cb82-24"></a>*Definition.* An *artificial neuron* with weights $w_1,\ldots,w_n \in \mathbf{R}$, bias $b\in\mathbf{R}$ and an activation function $\rho:\mathbf{R} \to \mathbf{R}$ is defined as the scalar-valued function $f:\mathbf{R}^n \to \mathbf{R}$ given by:</span>
<span id="cb82-25"><a href="#cb82-25"></a></span>
<span id="cb82-26"><a href="#cb82-26"></a>\begin{align*}</span>
<span id="cb82-27"><a href="#cb82-27"></a>f(x_1,\ldots,x_n) = \rho \left(\sum_{i=1}^{n}w_i x_i + b\right) = \rho(\mathbf{w}^T \mathbf{x}+b) \tag{1}</span>
<span id="cb82-28"><a href="#cb82-28"></a>\end{align*}</span>
<span id="cb82-29"><a href="#cb82-29"></a></span>
<span id="cb82-30"><a href="#cb82-30"></a>where $\mathbf{w} = (w_1,\ldots,w_n)$ and $\mathbf{x}=(x_1,\ldots,x_n)$.</span>
<span id="cb82-31"><a href="#cb82-31"></a></span>
<span id="cb82-32"><a href="#cb82-32"></a>A single neuron by itself is useless, but when combined with hundreds or thousands(or many more) of other neurons, the interconnectivity can approximate any complex function and frequently outperforms any other machine learning methods.</span>
<span id="cb82-33"><a href="#cb82-33"></a></span>
<span id="cb82-36"><a href="#cb82-36"></a><span class="in">```{python}</span></span>
<span id="cb82-37"><a href="#cb82-37"></a><span class="op">%</span>load_ext itikz</span>
<span id="cb82-38"><a href="#cb82-38"></a><span class="in">```</span></span>
<span id="cb82-39"><a href="#cb82-39"></a></span>
<span id="cb82-42"><a href="#cb82-42"></a><span class="in">```{python}</span></span>
<span id="cb82-43"><a href="#cb82-43"></a><span class="co"># | code-fold: true</span></span>
<span id="cb82-44"><a href="#cb82-44"></a><span class="co"># | code-summary: "Show the code"</span></span>
<span id="cb82-45"><a href="#cb82-45"></a><span class="op">%%</span>itikz <span class="op">--</span>temp<span class="op">-</span><span class="bu">dir</span> <span class="op">--</span>tex<span class="op">-</span>packages<span class="op">=</span>tikz <span class="op">--</span>tikz<span class="op">-</span>libraries<span class="op">=</span>arrows <span class="op">--</span>implicit<span class="op">-</span>standalone</span>
<span id="cb82-46"><a href="#cb82-46"></a>\begin{tikzpicture}</span>
<span id="cb82-47"><a href="#cb82-47"></a>\foreach \i <span class="kw">in</span> {<span class="dv">1</span>,<span class="dv">2</span>}</span>
<span id="cb82-48"><a href="#cb82-48"></a>{</span>
<span id="cb82-49"><a href="#cb82-49"></a>    \node[circle, </span>
<span id="cb82-50"><a href="#cb82-50"></a>        minimum size <span class="op">=</span> <span class="dv">15</span><span class="er">mm</span>,</span>
<span id="cb82-51"><a href="#cb82-51"></a>        fill<span class="op">=</span>red<span class="op">!</span><span class="dv">30</span></span>
<span id="cb82-52"><a href="#cb82-52"></a>        ] (Input<span class="op">-</span>\i) at (<span class="dv">0</span>,<span class="op">-</span>\i <span class="op">*</span> <span class="dv">2</span>) {\large $x_\i$}<span class="op">;</span></span>
<span id="cb82-53"><a href="#cb82-53"></a>}</span>
<span id="cb82-54"><a href="#cb82-54"></a>\foreach \i <span class="kw">in</span> {<span class="dv">1</span>,<span class="dv">2</span>,...,<span class="dv">5</span>}</span>
<span id="cb82-55"><a href="#cb82-55"></a>{</span>
<span id="cb82-56"><a href="#cb82-56"></a>    \node[circle, </span>
<span id="cb82-57"><a href="#cb82-57"></a>        minimum size <span class="op">=</span> <span class="dv">15</span><span class="er">mm</span>,</span>
<span id="cb82-58"><a href="#cb82-58"></a>        fill<span class="op">=</span>blue<span class="op">!</span><span class="dv">50</span>,</span>
<span id="cb82-59"><a href="#cb82-59"></a>        yshift<span class="op">=</span><span class="dv">30</span> mm</span>
<span id="cb82-60"><a href="#cb82-60"></a>        ] (Hidden1<span class="op">-</span>\i) at (<span class="fl">3.0</span>,<span class="op">-</span>\i <span class="op">*</span> <span class="dv">2</span>) {\large $h_\i<span class="op">^</span>{(<span class="dv">1</span>)}$}<span class="op">;</span></span>
<span id="cb82-61"><a href="#cb82-61"></a>        </span>
<span id="cb82-62"><a href="#cb82-62"></a>}</span>
<span id="cb82-63"><a href="#cb82-63"></a>\foreach \i <span class="kw">in</span> {<span class="dv">1</span>,<span class="dv">2</span>,...,<span class="dv">5</span>}</span>
<span id="cb82-64"><a href="#cb82-64"></a>{</span>
<span id="cb82-65"><a href="#cb82-65"></a>    \node[circle, </span>
<span id="cb82-66"><a href="#cb82-66"></a>        minimum size <span class="op">=</span> <span class="dv">15</span><span class="er">mm</span>,</span>
<span id="cb82-67"><a href="#cb82-67"></a>        fill<span class="op">=</span>blue<span class="op">!</span><span class="dv">50</span>,</span>
<span id="cb82-68"><a href="#cb82-68"></a>        yshift<span class="op">=</span><span class="dv">30</span> mm</span>
<span id="cb82-69"><a href="#cb82-69"></a>        ] (Hidden2<span class="op">-</span>\i) at (<span class="fl">6.0</span>,<span class="op">-</span>\i <span class="op">*</span> <span class="dv">2</span>) {\large $h_\i<span class="op">^</span>{(<span class="dv">2</span>)}$}<span class="op">;</span></span>
<span id="cb82-70"><a href="#cb82-70"></a>}</span>
<span id="cb82-71"><a href="#cb82-71"></a>\foreach \i <span class="kw">in</span> {<span class="dv">1</span>,<span class="dv">2</span>}</span>
<span id="cb82-72"><a href="#cb82-72"></a>{</span>
<span id="cb82-73"><a href="#cb82-73"></a>    \node[circle, </span>
<span id="cb82-74"><a href="#cb82-74"></a>        minimum size <span class="op">=</span> <span class="dv">15</span><span class="er">mm</span>,</span>
<span id="cb82-75"><a href="#cb82-75"></a>        fill<span class="op">=</span>green<span class="op">!</span><span class="dv">30</span>] (Output<span class="op">-</span>\i) at (<span class="fl">9.0</span>,<span class="op">-</span>\i <span class="op">*</span> <span class="dv">2</span>) {\large $\hat{y}_\i$}<span class="op">;</span></span>
<span id="cb82-76"><a href="#cb82-76"></a>}</span>
<span id="cb82-77"><a href="#cb82-77"></a></span>
<span id="cb82-78"><a href="#cb82-78"></a><span class="op">%</span> Connect neurons In<span class="op">-</span>Hidden1</span>
<span id="cb82-79"><a href="#cb82-79"></a>\foreach \i <span class="kw">in</span> {<span class="dv">1</span>,...,<span class="dv">2</span>}</span>
<span id="cb82-80"><a href="#cb82-80"></a>{</span>
<span id="cb82-81"><a href="#cb82-81"></a>    \foreach \j <span class="kw">in</span> {<span class="dv">1</span>,...,<span class="dv">5</span>}</span>
<span id="cb82-82"><a href="#cb82-82"></a>    {</span>
<span id="cb82-83"><a href="#cb82-83"></a>        \draw[<span class="op">-&gt;</span>, shorten <span class="op">&gt;=</span><span class="dv">1</span><span class="er">pt</span>] (Input<span class="op">-</span>\i) <span class="op">--</span> (Hidden1<span class="op">-</span>\j)<span class="op">;</span>   </span>
<span id="cb82-84"><a href="#cb82-84"></a>    }</span>
<span id="cb82-85"><a href="#cb82-85"></a>}</span>
<span id="cb82-86"><a href="#cb82-86"></a>\foreach \i <span class="kw">in</span> {<span class="dv">1</span>,...,<span class="dv">5</span>}</span>
<span id="cb82-87"><a href="#cb82-87"></a>{</span>
<span id="cb82-88"><a href="#cb82-88"></a>    \foreach \j <span class="kw">in</span> {<span class="dv">1</span>,...,<span class="dv">5</span>}</span>
<span id="cb82-89"><a href="#cb82-89"></a>    {</span>
<span id="cb82-90"><a href="#cb82-90"></a>        \draw[<span class="op">-&gt;</span>, shorten <span class="op">&gt;=</span><span class="dv">1</span><span class="er">pt</span>] (Hidden1<span class="op">-</span>\i) <span class="op">--</span> (Hidden2<span class="op">-</span>\j)<span class="op">;</span>   </span>
<span id="cb82-91"><a href="#cb82-91"></a>    }</span>
<span id="cb82-92"><a href="#cb82-92"></a>}</span>
<span id="cb82-93"><a href="#cb82-93"></a>\foreach \i <span class="kw">in</span> {<span class="dv">1</span>,...,<span class="dv">5</span>}</span>
<span id="cb82-94"><a href="#cb82-94"></a>{</span>
<span id="cb82-95"><a href="#cb82-95"></a>    \foreach \j <span class="kw">in</span> {<span class="dv">1</span>,<span class="dv">2</span>}</span>
<span id="cb82-96"><a href="#cb82-96"></a>    {</span>
<span id="cb82-97"><a href="#cb82-97"></a>        \draw[<span class="op">-&gt;</span>, shorten <span class="op">&gt;=</span><span class="dv">1</span><span class="er">pt</span>] (Hidden2<span class="op">-</span>\i) <span class="op">--</span> (Output<span class="op">-</span>\j)<span class="op">;</span>   </span>
<span id="cb82-98"><a href="#cb82-98"></a>    }</span>
<span id="cb82-99"><a href="#cb82-99"></a>}</span>
<span id="cb82-100"><a href="#cb82-100"></a>\end{tikzpicture}</span>
<span id="cb82-101"><a href="#cb82-101"></a><span class="in">```</span></span>
<span id="cb82-102"><a href="#cb82-102"></a></span>
<span id="cb82-103"><a href="#cb82-103"></a>Dense layers, the most common layers, consist of interconnected neurons. In a dense layer, each neuron of a given layer is connected to every neuron of the next layer, which means its output value becomes an input for the next neurons. Each connection between neurons has a weight associated with it, which is a trainable factor of how much of this input to use. Once all of the $\text{inputs} \cdot \text{ weights}$ flow into our neuron, they are summed and a bias, another trainable parameter is added.</span>
<span id="cb82-104"><a href="#cb82-104"></a></span>
<span id="cb82-105"><a href="#cb82-105"></a>Say, we have an input $x_1$ and weight $w_1$, then the output $y_1 = w_1 x_1$ is a straight-line with slope $w_1$. </span>
<span id="cb82-106"><a href="#cb82-106"></a></span>
<span id="cb82-109"><a href="#cb82-109"></a><span class="in">```{python}</span></span>
<span id="cb82-110"><a href="#cb82-110"></a><span class="co"># | code-fold: true</span></span>
<span id="cb82-111"><a href="#cb82-111"></a><span class="co"># | code-summary: "Show the code"</span></span>
<span id="cb82-112"><a href="#cb82-112"></a><span class="op">%%</span>itikz <span class="op">--</span>temp<span class="op">-</span><span class="bu">dir</span> <span class="op">--</span>tex<span class="op">-</span>packages<span class="op">=</span>tikz,pgfplots <span class="op">--</span>tikz<span class="op">-</span>libraries<span class="op">=</span>arrows <span class="op">--</span>implicit<span class="op">-</span>standalone</span>
<span id="cb82-113"><a href="#cb82-113"></a>\begin{tikzpicture}[scale<span class="op">=</span><span class="fl">1.5</span>]</span>
<span id="cb82-114"><a href="#cb82-114"></a>\begin{axis}</span>
<span id="cb82-115"><a href="#cb82-115"></a>\addplot[color<span class="op">=</span>blue]{x}<span class="op">;</span></span>
<span id="cb82-116"><a href="#cb82-116"></a>\addlegendentry{\(f(x)<span class="op">=</span>x\)}</span>
<span id="cb82-117"><a href="#cb82-117"></a>\addplot[color<span class="op">=</span>red]{<span class="dv">2</span><span class="op">*</span>x}<span class="op">;</span></span>
<span id="cb82-118"><a href="#cb82-118"></a>\addlegendentry{\(f(x)<span class="op">=</span><span class="dv">2</span><span class="er">x</span>\)}</span>
<span id="cb82-119"><a href="#cb82-119"></a>\end{axis}</span>
<span id="cb82-120"><a href="#cb82-120"></a>\end{tikzpicture}</span>
<span id="cb82-121"><a href="#cb82-121"></a><span class="in">```</span></span>
<span id="cb82-122"><a href="#cb82-122"></a></span>
<span id="cb82-123"><a href="#cb82-123"></a>The bias offsets the overall function. </span>
<span id="cb82-124"><a href="#cb82-124"></a></span>
<span id="cb82-127"><a href="#cb82-127"></a><span class="in">```{python}</span></span>
<span id="cb82-128"><a href="#cb82-128"></a><span class="co"># | code-fold: true</span></span>
<span id="cb82-129"><a href="#cb82-129"></a><span class="co"># | code-summary: "Show the code"</span></span>
<span id="cb82-130"><a href="#cb82-130"></a><span class="op">%%</span>itikz <span class="op">--</span>temp<span class="op">-</span><span class="bu">dir</span> <span class="op">--</span>tex<span class="op">-</span>packages<span class="op">=</span>tikz,pgfplots <span class="op">--</span>tikz<span class="op">-</span>libraries<span class="op">=</span>arrows <span class="op">--</span>implicit<span class="op">-</span>standalone</span>
<span id="cb82-131"><a href="#cb82-131"></a>\begin{tikzpicture}[scale<span class="op">=</span><span class="fl">1.5</span>]</span>
<span id="cb82-132"><a href="#cb82-132"></a>\begin{axis}</span>
<span id="cb82-133"><a href="#cb82-133"></a>\addplot[color<span class="op">=</span>black]{x<span class="op">+</span><span class="dv">1</span>}<span class="op">;</span></span>
<span id="cb82-134"><a href="#cb82-134"></a>\addlegendentry{\(f(x)<span class="op">=</span>x<span class="op">+</span><span class="dv">1</span>\)}</span>
<span id="cb82-135"><a href="#cb82-135"></a>\addplot[color<span class="op">=</span>gray]{x<span class="op">-</span><span class="dv">1</span>}<span class="op">;</span></span>
<span id="cb82-136"><a href="#cb82-136"></a>\addlegendentry{\(f(x)<span class="op">=</span>x<span class="op">-</span><span class="dv">1</span>\)}</span>
<span id="cb82-137"><a href="#cb82-137"></a>\end{axis}</span>
<span id="cb82-138"><a href="#cb82-138"></a>\end{tikzpicture}</span>
<span id="cb82-139"><a href="#cb82-139"></a><span class="in">```</span></span>
<span id="cb82-140"><a href="#cb82-140"></a></span>
<span id="cb82-141"><a href="#cb82-141"></a><span class="fu">### Activation functions</span></span>
<span id="cb82-142"><a href="#cb82-142"></a></span>
<span id="cb82-143"><a href="#cb82-143"></a>Let us now look at some examples of activation functions. </span>
<span id="cb82-144"><a href="#cb82-144"></a></span>
<span id="cb82-145"><a href="#cb82-145"></a>The heaviside function is defined as:</span>
<span id="cb82-146"><a href="#cb82-146"></a></span>
<span id="cb82-147"><a href="#cb82-147"></a>\begin{align*}</span>
<span id="cb82-148"><a href="#cb82-148"></a>\rho(x) &amp;= </span>
<span id="cb82-149"><a href="#cb82-149"></a>\begin{cases}</span>
<span id="cb82-150"><a href="#cb82-150"></a>1, &amp; x &gt; 0 <span class="sc">\\</span></span>
<span id="cb82-151"><a href="#cb82-151"></a>0, &amp; x \leq 0</span>
<span id="cb82-152"><a href="#cb82-152"></a>\end{cases}</span>
<span id="cb82-153"><a href="#cb82-153"></a>\end{align*}</span>
<span id="cb82-154"><a href="#cb82-154"></a></span>
<span id="cb82-155"><a href="#cb82-155"></a>The sigmoid function is defined as:</span>
<span id="cb82-156"><a href="#cb82-156"></a></span>
<span id="cb82-157"><a href="#cb82-157"></a>\begin{align*}</span>
<span id="cb82-158"><a href="#cb82-158"></a>\rho(x) &amp;= \frac{1}{1+e^{-x}}</span>
<span id="cb82-159"><a href="#cb82-159"></a>\end{align*}</span>
<span id="cb82-160"><a href="#cb82-160"></a></span>
<span id="cb82-163"><a href="#cb82-163"></a><span class="in">```{python}</span></span>
<span id="cb82-164"><a href="#cb82-164"></a><span class="co"># | code-fold: true</span></span>
<span id="cb82-165"><a href="#cb82-165"></a><span class="co"># | code-summary: "Show the code"</span></span>
<span id="cb82-166"><a href="#cb82-166"></a><span class="op">%%</span>itikz <span class="op">--</span>temp<span class="op">-</span><span class="bu">dir</span> <span class="op">--</span>tex<span class="op">-</span>packages<span class="op">=</span>tikz,pgfplots <span class="op">--</span>tikz<span class="op">-</span>libraries<span class="op">=</span>arrows <span class="op">--</span>implicit<span class="op">-</span>standalone</span>
<span id="cb82-167"><a href="#cb82-167"></a>\begin{tikzpicture}[scale<span class="op">=</span><span class="fl">1.5</span>]</span>
<span id="cb82-168"><a href="#cb82-168"></a>\begin{axis}</span>
<span id="cb82-169"><a href="#cb82-169"></a>\addplot[color<span class="op">=</span>black]{<span class="dv">1</span><span class="op">/</span>(<span class="dv">1</span><span class="op">+</span>exp(<span class="op">-</span>x))}<span class="op">;</span></span>
<span id="cb82-170"><a href="#cb82-170"></a>\end{axis}</span>
<span id="cb82-171"><a href="#cb82-171"></a>\end{tikzpicture}</span>
<span id="cb82-172"><a href="#cb82-172"></a><span class="in">```</span></span>
<span id="cb82-173"><a href="#cb82-173"></a></span>
<span id="cb82-174"><a href="#cb82-174"></a>The Rectifiable Linear Unit (ReLU) function is defined as:</span>
<span id="cb82-175"><a href="#cb82-175"></a></span>
<span id="cb82-176"><a href="#cb82-176"></a>\begin{align*}</span>
<span id="cb82-177"><a href="#cb82-177"></a>\rho(x) &amp;= \max(0,x)</span>
<span id="cb82-178"><a href="#cb82-178"></a>\end{align*}</span>
<span id="cb82-179"><a href="#cb82-179"></a></span>
<span id="cb82-182"><a href="#cb82-182"></a><span class="in">```{python}</span></span>
<span id="cb82-183"><a href="#cb82-183"></a><span class="co"># | code-fold: true</span></span>
<span id="cb82-184"><a href="#cb82-184"></a><span class="co"># | code-summary: "Show the code"</span></span>
<span id="cb82-185"><a href="#cb82-185"></a><span class="op">%%</span>itikz <span class="op">--</span>temp<span class="op">-</span><span class="bu">dir</span> <span class="op">--</span>tex<span class="op">-</span>packages<span class="op">=</span>tikz,pgfplots <span class="op">--</span>tikz<span class="op">-</span>libraries<span class="op">=</span>arrows <span class="op">--</span>implicit<span class="op">-</span>standalone</span>
<span id="cb82-186"><a href="#cb82-186"></a>\begin{tikzpicture}[scale<span class="op">=</span><span class="fl">1.5</span>]</span>
<span id="cb82-187"><a href="#cb82-187"></a>\begin{axis}</span>
<span id="cb82-188"><a href="#cb82-188"></a>\addplot[color<span class="op">=</span>black]{<span class="bu">max</span>(<span class="dv">0</span>,x)}<span class="op">;</span></span>
<span id="cb82-189"><a href="#cb82-189"></a>\end{axis}</span>
<span id="cb82-190"><a href="#cb82-190"></a>\end{tikzpicture}</span>
<span id="cb82-191"><a href="#cb82-191"></a><span class="in">```</span></span>
<span id="cb82-192"><a href="#cb82-192"></a></span>
<span id="cb82-193"><a href="#cb82-193"></a><span class="fu">## Coding a layer with 3-neurons</span></span>
<span id="cb82-194"><a href="#cb82-194"></a></span>
<span id="cb82-195"><a href="#cb82-195"></a>Let's code a simple layer with $n=3$ neurons.</span>
<span id="cb82-196"><a href="#cb82-196"></a></span>
<span id="cb82-199"><a href="#cb82-199"></a><span class="in">```{python}</span></span>
<span id="cb82-200"><a href="#cb82-200"></a>inputs <span class="op">=</span> [<span class="dv">1</span>, <span class="dv">2</span>, <span class="dv">3</span>, <span class="fl">2.5</span>]</span>
<span id="cb82-201"><a href="#cb82-201"></a>weights <span class="op">=</span> [[<span class="fl">0.2</span>, <span class="fl">0.8</span>, <span class="op">-</span><span class="fl">0.5</span>, <span class="fl">1.0</span>], [<span class="fl">0.5</span>, <span class="op">-</span><span class="fl">0.91</span>, <span class="fl">0.26</span>, <span class="op">-</span><span class="fl">0.5</span>], [<span class="op">-</span><span class="fl">0.26</span>, <span class="op">-</span><span class="fl">0.27</span>, <span class="fl">0.17</span>, <span class="fl">0.87</span>]]</span>
<span id="cb82-202"><a href="#cb82-202"></a></span>
<span id="cb82-203"><a href="#cb82-203"></a>biases <span class="op">=</span> [<span class="dv">2</span>, <span class="dv">3</span>, <span class="fl">0.5</span>]</span>
<span id="cb82-204"><a href="#cb82-204"></a></span>
<span id="cb82-205"><a href="#cb82-205"></a><span class="co"># Output of the current layer</span></span>
<span id="cb82-206"><a href="#cb82-206"></a>layer_outputs <span class="op">=</span> []</span>
<span id="cb82-207"><a href="#cb82-207"></a></span>
<span id="cb82-208"><a href="#cb82-208"></a><span class="co"># For each neuron</span></span>
<span id="cb82-209"><a href="#cb82-209"></a><span class="cf">for</span> neuron_weights, neuron_bias <span class="kw">in</span> <span class="bu">zip</span>(weights, biases):</span>
<span id="cb82-210"><a href="#cb82-210"></a>    <span class="co"># zeroed output of the neuron</span></span>
<span id="cb82-211"><a href="#cb82-211"></a>    neuron_output <span class="op">=</span> <span class="fl">0.0</span></span>
<span id="cb82-212"><a href="#cb82-212"></a>    <span class="co"># for each input and weight to the neuron</span></span>
<span id="cb82-213"><a href="#cb82-213"></a>    <span class="cf">for</span> <span class="bu">input</span>, weight <span class="kw">in</span> <span class="bu">zip</span>(inputs, neuron_weights):</span>
<span id="cb82-214"><a href="#cb82-214"></a>        <span class="co"># multiply this input with the associated weight</span></span>
<span id="cb82-215"><a href="#cb82-215"></a>        <span class="co"># and add to the neuron's output variable</span></span>
<span id="cb82-216"><a href="#cb82-216"></a>        neuron_output <span class="op">+=</span> <span class="bu">input</span> <span class="op">*</span> weight</span>
<span id="cb82-217"><a href="#cb82-217"></a>    <span class="co"># Add bias</span></span>
<span id="cb82-218"><a href="#cb82-218"></a>    neuron_output <span class="op">+=</span> neuron_bias</span>
<span id="cb82-219"><a href="#cb82-219"></a>    <span class="co"># Put the neuron's result to the layer's output list</span></span>
<span id="cb82-220"><a href="#cb82-220"></a>    layer_outputs.append(neuron_output)</span>
<span id="cb82-221"><a href="#cb82-221"></a></span>
<span id="cb82-222"><a href="#cb82-222"></a><span class="bu">print</span>(layer_outputs)</span>
<span id="cb82-223"><a href="#cb82-223"></a><span class="in">```</span></span>
<span id="cb82-224"><a href="#cb82-224"></a></span>
<span id="cb82-225"><a href="#cb82-225"></a>We can achieve the same results as in our pure Python implementation of multiplying each component in our input vector $\mathbf{x}$ and weights vector $\mathbf{w}$ element-wise, by taking an inner product $\mathbf{w} \cdot \mathbf{x}$. </span>
<span id="cb82-226"><a href="#cb82-226"></a></span>
<span id="cb82-229"><a href="#cb82-229"></a><span class="in">```{python}</span></span>
<span id="cb82-230"><a href="#cb82-230"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb82-231"><a href="#cb82-231"></a></span>
<span id="cb82-232"><a href="#cb82-232"></a>inputs <span class="op">=</span> [<span class="dv">1</span>, <span class="dv">2</span>, <span class="dv">3</span>, <span class="fl">2.5</span>]</span>
<span id="cb82-233"><a href="#cb82-233"></a>weights <span class="op">=</span> [</span>
<span id="cb82-234"><a href="#cb82-234"></a>    [<span class="fl">0.2</span>, <span class="fl">0.8</span>, <span class="op">-</span><span class="fl">0.5</span>, <span class="fl">1.0</span>], </span>
<span id="cb82-235"><a href="#cb82-235"></a>    [<span class="fl">0.5</span>, <span class="op">-</span><span class="fl">0.91</span>, <span class="fl">0.26</span>, <span class="op">-</span><span class="fl">0.5</span>], </span>
<span id="cb82-236"><a href="#cb82-236"></a>    [<span class="op">-</span><span class="fl">0.26</span>, <span class="op">-</span><span class="fl">0.27</span>, <span class="fl">0.17</span>, <span class="fl">0.87</span>]</span>
<span id="cb82-237"><a href="#cb82-237"></a>]</span>
<span id="cb82-238"><a href="#cb82-238"></a></span>
<span id="cb82-239"><a href="#cb82-239"></a>biases <span class="op">=</span> [<span class="dv">2</span>, <span class="dv">3</span>, <span class="fl">0.5</span>]</span>
<span id="cb82-240"><a href="#cb82-240"></a></span>
<span id="cb82-241"><a href="#cb82-241"></a><span class="co"># Output of the current layer</span></span>
<span id="cb82-242"><a href="#cb82-242"></a>layer_outputs <span class="op">=</span> np.dot(weights, inputs) <span class="op">+</span> biases</span>
<span id="cb82-243"><a href="#cb82-243"></a></span>
<span id="cb82-244"><a href="#cb82-244"></a><span class="bu">print</span>(layer_outputs)</span>
<span id="cb82-245"><a href="#cb82-245"></a><span class="in">```</span></span>
<span id="cb82-246"><a href="#cb82-246"></a></span>
<span id="cb82-247"><a href="#cb82-247"></a>To train, neural networks tend to receive data in *batches*. So far, the example input data has only one sample (or observation) of various features called a feature set instance:</span>
<span id="cb82-248"><a href="#cb82-248"></a></span>
<span id="cb82-249"><a href="#cb82-249"></a><span class="in">```python</span></span>
<span id="cb82-250"><a href="#cb82-250"></a>sample <span class="op">=</span> [<span class="dv">1</span>, <span class="dv">2</span>, <span class="dv">3</span>, <span class="fl">2.5</span>]</span>
<span id="cb82-251"><a href="#cb82-251"></a><span class="in">```</span></span>
<span id="cb82-252"><a href="#cb82-252"></a></span>
<span id="cb82-253"><a href="#cb82-253"></a>Often, neural networks expect to take in many *samples* at a time. One reason is its faster to train in batches in parallel processing. Also, if you fit on one sample at a time, you're highly likely to keep fitting to that individual sample, rather than slowly producing general tweaks to the weights and biases that fit the entire dataset. Fitting or training in batches gives you a higher chance of making more meaningful changes to weights and biases.</span>
<span id="cb82-254"><a href="#cb82-254"></a></span>
<span id="cb82-255"><a href="#cb82-255"></a><span class="fu">## A layer of neurons and a batch of data</span></span>
<span id="cb82-256"><a href="#cb82-256"></a></span>
<span id="cb82-257"><a href="#cb82-257"></a>Currently, the weights matrix looks as follows:</span>
<span id="cb82-258"><a href="#cb82-258"></a></span>
<span id="cb82-259"><a href="#cb82-259"></a>\begin{align*}</span>
<span id="cb82-260"><a href="#cb82-260"></a>W = \begin{bmatrix}</span>
<span id="cb82-261"><a href="#cb82-261"></a>0.2 &amp; 0.8 &amp; -0.5 &amp; 1.0 <span class="sc">\\</span></span>
<span id="cb82-262"><a href="#cb82-262"></a>0.5 &amp; -0.91 &amp; 0.26 &amp; -0.5 <span class="sc">\\</span></span>
<span id="cb82-263"><a href="#cb82-263"></a>-0.26 &amp; -0.27 &amp; 0.17 &amp; 0.87</span>
<span id="cb82-264"><a href="#cb82-264"></a>\end{bmatrix}</span>
<span id="cb82-265"><a href="#cb82-265"></a>\end{align*}</span>
<span id="cb82-266"><a href="#cb82-266"></a></span>
<span id="cb82-267"><a href="#cb82-267"></a>And say, that we have a batch of inputs:</span>
<span id="cb82-268"><a href="#cb82-268"></a></span>
<span id="cb82-269"><a href="#cb82-269"></a>\begin{align*}</span>
<span id="cb82-270"><a href="#cb82-270"></a>X = \begin{bmatrix}</span>
<span id="cb82-271"><a href="#cb82-271"></a>1.0 &amp; 2.0 &amp; 3.0 &amp; 3.5 <span class="sc">\\</span></span>
<span id="cb82-272"><a href="#cb82-272"></a>2.0 &amp; 5.0 &amp; -1.0 &amp; 2.0<span class="sc">\\</span></span>
<span id="cb82-273"><a href="#cb82-273"></a>-1.5 &amp; 2.7 &amp; 3.3 &amp; -0.8</span>
<span id="cb82-274"><a href="#cb82-274"></a>\end{bmatrix}</span>
<span id="cb82-275"><a href="#cb82-275"></a>\end{align*}</span>
<span id="cb82-276"><a href="#cb82-276"></a></span>
<span id="cb82-277"><a href="#cb82-277"></a>We need to take the inner products $(1.0, 2.0, 3.0, 3.5) \cdot (0.2, 0.8, -0.5, 1.0)$, $(2.0, 5.0, -1.0, 2.0) \cdot (0.2, 0.8, -0.5, 1.0)$ and $(-1.5, 2.7, 3.3, -0.8) \cdot (0.2, 0.8, -0.5, 1.0)$ for the first neuron.</span>
<span id="cb82-278"><a href="#cb82-278"></a></span>
<span id="cb82-279"><a href="#cb82-279"></a>We need to take the inner products $(1.0, 2.0, 3.0, 3.5) \cdot (0.5, -0.91, 0.26, -0.5)$, $(2.0, 5.0, -1.0, 2.0) \cdot (0.5, -0.91, 0.26, -0.5)$ and $(-1.5, 2.7, 3.3, -0.8) \cdot (0.5, -0.91, 0.26, -0.5)$ for the second neuron.</span>
<span id="cb82-280"><a href="#cb82-280"></a></span>
<span id="cb82-281"><a href="#cb82-281"></a>And so forth. </span>
<span id="cb82-282"><a href="#cb82-282"></a></span>
<span id="cb82-283"><a href="#cb82-283"></a>Consider the matrix product $XW^T$:</span>
<span id="cb82-284"><a href="#cb82-284"></a></span>
<span id="cb82-285"><a href="#cb82-285"></a>\begin{align*}</span>
<span id="cb82-286"><a href="#cb82-286"></a>XW^T &amp;= \begin{bmatrix}</span>
<span id="cb82-287"><a href="#cb82-287"></a>1.0 &amp; 2.0 &amp; 3.0 &amp; 2.5 <span class="sc">\\</span></span>
<span id="cb82-288"><a href="#cb82-288"></a>2.0 &amp; 5.0 &amp; -1.0 &amp; 2.0<span class="sc">\\</span></span>
<span id="cb82-289"><a href="#cb82-289"></a>-1.5 &amp; 2.7 &amp; 3.3 &amp; -0.8</span>
<span id="cb82-290"><a href="#cb82-290"></a>\end{bmatrix} </span>
<span id="cb82-291"><a href="#cb82-291"></a>\begin{bmatrix}</span>
<span id="cb82-292"><a href="#cb82-292"></a>0.2 &amp; 0.5 &amp; -0.26 <span class="sc">\\</span></span>
<span id="cb82-293"><a href="#cb82-293"></a>0.8 &amp; -0.91 &amp; -0.27 <span class="sc">\\</span></span>
<span id="cb82-294"><a href="#cb82-294"></a>-0.5 &amp; 0.26 &amp; 0.17 <span class="sc">\\</span></span>
<span id="cb82-295"><a href="#cb82-295"></a>1.0 &amp; -0.5 &amp; 0.87</span>
<span id="cb82-296"><a href="#cb82-296"></a>\end{bmatrix}<span class="sc">\\</span></span>
<span id="cb82-297"><a href="#cb82-297"></a>&amp;= \begin{bmatrix}</span>
<span id="cb82-298"><a href="#cb82-298"></a>2.8 &amp; -1.79 &amp; 1.885 <span class="sc">\\</span></span>
<span id="cb82-299"><a href="#cb82-299"></a>6.9 &amp; -4.81 &amp; -0.3 <span class="sc">\\</span></span>
<span id="cb82-300"><a href="#cb82-300"></a>-0.59 &amp; -1.949 &amp; -0.474</span>
<span id="cb82-301"><a href="#cb82-301"></a>\end{bmatrix}</span>
<span id="cb82-302"><a href="#cb82-302"></a>\end{align*}</span>
<span id="cb82-303"><a href="#cb82-303"></a></span>
<span id="cb82-306"><a href="#cb82-306"></a><span class="in">```{python}</span></span>
<span id="cb82-307"><a href="#cb82-307"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb82-308"><a href="#cb82-308"></a></span>
<span id="cb82-309"><a href="#cb82-309"></a>X <span class="op">=</span> [</span>
<span id="cb82-310"><a href="#cb82-310"></a>    [<span class="fl">1.0</span>, <span class="fl">2.0</span>, <span class="fl">3.0</span>, <span class="fl">2.5</span>],</span>
<span id="cb82-311"><a href="#cb82-311"></a>    [<span class="fl">2.0</span>, <span class="fl">5.0</span>, <span class="op">-</span><span class="fl">1.0</span>, <span class="fl">2.0</span>],</span>
<span id="cb82-312"><a href="#cb82-312"></a>    [<span class="op">-</span><span class="fl">1.5</span>, <span class="fl">2.7</span>, <span class="fl">3.3</span>, <span class="op">-</span><span class="fl">0.8</span>]</span>
<span id="cb82-313"><a href="#cb82-313"></a>]</span>
<span id="cb82-314"><a href="#cb82-314"></a></span>
<span id="cb82-315"><a href="#cb82-315"></a>W <span class="op">=</span> [</span>
<span id="cb82-316"><a href="#cb82-316"></a>    [<span class="fl">0.2</span>, <span class="fl">0.8</span>, <span class="op">-</span><span class="fl">0.5</span>, <span class="fl">1.0</span>],</span>
<span id="cb82-317"><a href="#cb82-317"></a>    [<span class="fl">0.5</span>, <span class="op">-</span><span class="fl">0.91</span>, <span class="fl">0.26</span>, <span class="op">-</span><span class="fl">0.5</span>],</span>
<span id="cb82-318"><a href="#cb82-318"></a>    [<span class="op">-</span><span class="fl">0.26</span>, <span class="op">-</span><span class="fl">0.27</span>, <span class="fl">0.17</span>, <span class="fl">0.87</span>]</span>
<span id="cb82-319"><a href="#cb82-319"></a>]</span>
<span id="cb82-320"><a href="#cb82-320"></a></span>
<span id="cb82-321"><a href="#cb82-321"></a>np.dot(X,np.array(W).T)</span>
<span id="cb82-322"><a href="#cb82-322"></a><span class="in">```</span></span>
<span id="cb82-323"><a href="#cb82-323"></a></span>
<span id="cb82-324"><a href="#cb82-324"></a>So, we can process a batch of inputs as:</span>
<span id="cb82-325"><a href="#cb82-325"></a></span>
<span id="cb82-328"><a href="#cb82-328"></a><span class="in">```{python}</span></span>
<span id="cb82-329"><a href="#cb82-329"></a>layer_outputs <span class="op">=</span> np.dot(X,np.array(W).T) <span class="op">+</span> biases</span>
<span id="cb82-330"><a href="#cb82-330"></a><span class="bu">print</span>(layer_outputs)</span>
<span id="cb82-331"><a href="#cb82-331"></a><span class="in">```</span></span>
<span id="cb82-332"><a href="#cb82-332"></a></span>
<span id="cb82-333"><a href="#cb82-333"></a>The second argument for <span class="in">`np.dot()`</span> is going to be our transposed weights. Before, we were computing the neuron output using a single sample of data, but now we've taken a step forward where we model the layer behavior on a batch of data.</span>
<span id="cb82-334"><a href="#cb82-334"></a></span>
<span id="cb82-335"><a href="#cb82-335"></a><span class="fu">## Adding Layers</span></span>
<span id="cb82-336"><a href="#cb82-336"></a></span>
<span id="cb82-337"><a href="#cb82-337"></a>The neural network we have built is becoming more respectable, but at the moment, we have only one layer. Neural networks become deep when they have $2$ or more *hidden layers*. At the moment, we have just one layer, which is effectively an output layer. Why we want two or more hidden layers will become apparent later on. Currently, we have no hidden layers. A hidden layer isn't an input or output layer; as the scientist, you see the data as they are handed to the input layer and the resulting data from the output layer. Layers between these endpoints have values that we don't necessarily deal with, and hence the name "hidden". Don't let this name convince you that you can't access these values, though. You will often use them to diagnose issues or improve your neural network. To explore this concept, let's add another layer to this neural network, and for now, let's assume that these two layers that we're going to have will be hidden layers, and we just coded our output layer yet. </span>
<span id="cb82-338"><a href="#cb82-338"></a></span>
<span id="cb82-339"><a href="#cb82-339"></a>Before we add another layer, let's think about what's coming. In the case of the first layer, we can see that we have an input with $4$ features. </span>
<span id="cb82-340"><a href="#cb82-340"></a></span>
<span id="cb82-343"><a href="#cb82-343"></a><span class="in">```{python}</span></span>
<span id="cb82-344"><a href="#cb82-344"></a><span class="co"># | code-fold: true</span></span>
<span id="cb82-345"><a href="#cb82-345"></a><span class="co"># | code-summary: "Show the code"</span></span>
<span id="cb82-346"><a href="#cb82-346"></a><span class="op">%%</span>itikz <span class="op">--</span>temp<span class="op">-</span><span class="bu">dir</span> <span class="op">--</span>tex<span class="op">-</span>packages<span class="op">=</span>tikz <span class="op">--</span>tikz<span class="op">-</span>libraries<span class="op">=</span>arrows <span class="op">--</span>implicit<span class="op">-</span>standalone</span>
<span id="cb82-347"><a href="#cb82-347"></a>\begin{tikzpicture}</span>
<span id="cb82-348"><a href="#cb82-348"></a>\foreach \i <span class="kw">in</span> {<span class="dv">1</span>,<span class="dv">2</span>,...,<span class="dv">4</span>}</span>
<span id="cb82-349"><a href="#cb82-349"></a>{</span>
<span id="cb82-350"><a href="#cb82-350"></a>    \node[circle, </span>
<span id="cb82-351"><a href="#cb82-351"></a>        minimum size <span class="op">=</span> <span class="dv">15</span><span class="er">mm</span>,</span>
<span id="cb82-352"><a href="#cb82-352"></a>        fill<span class="op">=</span>red<span class="op">!</span><span class="dv">30</span></span>
<span id="cb82-353"><a href="#cb82-353"></a>        ] (Input<span class="op">-</span>\i) at (<span class="dv">0</span>,<span class="op">-</span>\i <span class="op">*</span> <span class="dv">2</span>) {\large $x_\i$}<span class="op">;</span></span>
<span id="cb82-354"><a href="#cb82-354"></a>}</span>
<span id="cb82-355"><a href="#cb82-355"></a>\foreach \i <span class="kw">in</span> {<span class="dv">1</span>,<span class="dv">2</span>,...,<span class="dv">3</span>}</span>
<span id="cb82-356"><a href="#cb82-356"></a>{</span>
<span id="cb82-357"><a href="#cb82-357"></a>    \node[circle, </span>
<span id="cb82-358"><a href="#cb82-358"></a>        minimum size <span class="op">=</span> <span class="dv">15</span><span class="er">mm</span>,</span>
<span id="cb82-359"><a href="#cb82-359"></a>        fill<span class="op">=</span>blue<span class="op">!</span><span class="dv">50</span>,</span>
<span id="cb82-360"><a href="#cb82-360"></a>        yshift<span class="op">=-</span><span class="dv">10</span> mm</span>
<span id="cb82-361"><a href="#cb82-361"></a>        ] (Hidden1<span class="op">-</span>\i) at (<span class="fl">3.0</span>,<span class="op">-</span>\i <span class="op">*</span> <span class="dv">2</span>) {\large $h_\i<span class="op">^</span>{(<span class="dv">1</span>)}$}<span class="op">;</span></span>
<span id="cb82-362"><a href="#cb82-362"></a>        </span>
<span id="cb82-363"><a href="#cb82-363"></a>}</span>
<span id="cb82-364"><a href="#cb82-364"></a></span>
<span id="cb82-365"><a href="#cb82-365"></a><span class="op">%</span> Connect neurons In<span class="op">-</span>Hidden1</span>
<span id="cb82-366"><a href="#cb82-366"></a>\foreach \i <span class="kw">in</span> {<span class="dv">1</span>,...,<span class="dv">4</span>}</span>
<span id="cb82-367"><a href="#cb82-367"></a>{</span>
<span id="cb82-368"><a href="#cb82-368"></a>    \foreach \j <span class="kw">in</span> {<span class="dv">1</span>,...,<span class="dv">3</span>}</span>
<span id="cb82-369"><a href="#cb82-369"></a>    {</span>
<span id="cb82-370"><a href="#cb82-370"></a>        \draw[<span class="op">-&gt;</span>, shorten <span class="op">&gt;=</span><span class="dv">1</span><span class="er">pt</span>] (Input<span class="op">-</span>\i) <span class="op">--</span> (Hidden1<span class="op">-</span>\j)<span class="op">;</span>   </span>
<span id="cb82-371"><a href="#cb82-371"></a>    }</span>
<span id="cb82-372"><a href="#cb82-372"></a>}</span>
<span id="cb82-373"><a href="#cb82-373"></a>\end{tikzpicture}</span>
<span id="cb82-374"><a href="#cb82-374"></a><span class="in">```</span></span>
<span id="cb82-375"><a href="#cb82-375"></a></span>
<span id="cb82-376"><a href="#cb82-376"></a>Samples(feature set data) get fed through the input, which does not change it in any way, to our first hidden layer, which we can see has $3$ sets of weights with $4$ values each. </span>
<span id="cb82-377"><a href="#cb82-377"></a></span>
<span id="cb82-378"><a href="#cb82-378"></a>Each of those $3$ unique weight sets is associated with its distinct neuron. Thus, since we have $3$ weight sets, we have $3$ neurons in the first hidden layer. Each neuron has a unique set of weights, of which we have $4$ (as there are $4$ inputs to this layer), which is why our initial weights have a shape of $(3,4)$.</span>
<span id="cb82-379"><a href="#cb82-379"></a></span>
<span id="cb82-380"><a href="#cb82-380"></a>Now we wish to add another layer. To do that, we must make sure that the expected input to that layer matches the previous layer's output. We have set the number of neurons in a layer by setting how many weights and biases we have. The previous layer's influence on weight sets for the current layer is that each weight set needs to have a separate weight per input. This means a distinct weight per neuron from the previous layer (or feature if we're talking the input). The previous layer has $3$ weight sets and $3$ biases, so we know it has $3$ neurons. This then means, for the next layer, we can have as many weight sets as we want (because this is how many neurons this new layer will have), but each of those weight sets must have $3$ discrete weights. </span>
<span id="cb82-381"><a href="#cb82-381"></a></span>
<span id="cb82-382"><a href="#cb82-382"></a>To create this new layer, we are going to copy and paste our <span class="in">`weights`</span> and <span class="in">`biases`</span> to <span class="in">`weights2`</span> and <span class="in">`biases2`</span>, and change their values to new made up sets. Here's an example:</span>
<span id="cb82-383"><a href="#cb82-383"></a></span>
<span id="cb82-386"><a href="#cb82-386"></a><span class="in">```{python}</span></span>
<span id="cb82-387"><a href="#cb82-387"></a>inputs <span class="op">=</span> [</span>
<span id="cb82-388"><a href="#cb82-388"></a>    [<span class="dv">1</span>, <span class="dv">2</span>, <span class="dv">3</span>, <span class="fl">2.5</span>],</span>
<span id="cb82-389"><a href="#cb82-389"></a>    [<span class="fl">2.0</span>, <span class="fl">5.0</span>, <span class="op">-</span><span class="fl">1.0</span>, <span class="dv">2</span>],</span>
<span id="cb82-390"><a href="#cb82-390"></a>    [<span class="op">-</span><span class="fl">1.5</span>, <span class="fl">2.7</span>, <span class="fl">3.3</span>, <span class="op">-</span><span class="fl">0.8</span>]</span>
<span id="cb82-391"><a href="#cb82-391"></a>]</span>
<span id="cb82-392"><a href="#cb82-392"></a></span>
<span id="cb82-393"><a href="#cb82-393"></a>weights <span class="op">=</span> [</span>
<span id="cb82-394"><a href="#cb82-394"></a>    [<span class="fl">0.2</span>, <span class="fl">0.8</span>, <span class="op">-</span><span class="fl">0.5</span>, <span class="dv">1</span>],</span>
<span id="cb82-395"><a href="#cb82-395"></a>    [<span class="fl">0.5</span>, <span class="op">-</span><span class="fl">0.91</span>, <span class="fl">0.26</span>, <span class="op">-</span><span class="fl">0.5</span>],</span>
<span id="cb82-396"><a href="#cb82-396"></a>    [<span class="op">-</span><span class="fl">0.26</span>, <span class="op">-</span><span class="fl">0.27</span>, <span class="fl">0.17</span>, <span class="fl">0.87</span>]</span>
<span id="cb82-397"><a href="#cb82-397"></a>]</span>
<span id="cb82-398"><a href="#cb82-398"></a></span>
<span id="cb82-399"><a href="#cb82-399"></a>biases <span class="op">=</span> [<span class="dv">2</span>, <span class="dv">3</span>, <span class="fl">0.5</span>]</span>
<span id="cb82-400"><a href="#cb82-400"></a></span>
<span id="cb82-401"><a href="#cb82-401"></a>weights2 <span class="op">=</span> [</span>
<span id="cb82-402"><a href="#cb82-402"></a>    [<span class="fl">0.1</span>, <span class="op">-</span><span class="fl">0.14</span>, <span class="fl">0.5</span>],</span>
<span id="cb82-403"><a href="#cb82-403"></a>    [<span class="op">-</span><span class="fl">0.5</span>, <span class="fl">0.12</span>, <span class="op">-</span><span class="fl">0.33</span>],</span>
<span id="cb82-404"><a href="#cb82-404"></a>    [<span class="op">-</span><span class="fl">0.44</span>, <span class="fl">0.73</span>, <span class="op">-</span><span class="fl">0.13</span>]</span>
<span id="cb82-405"><a href="#cb82-405"></a>]</span>
<span id="cb82-406"><a href="#cb82-406"></a></span>
<span id="cb82-407"><a href="#cb82-407"></a>biases2 <span class="op">=</span> [<span class="op">-</span><span class="dv">1</span>, <span class="dv">2</span>, <span class="op">-</span><span class="fl">0.5</span>]</span>
<span id="cb82-408"><a href="#cb82-408"></a><span class="in">```</span></span>
<span id="cb82-409"><a href="#cb82-409"></a></span>
<span id="cb82-410"><a href="#cb82-410"></a>Next, we will now call the outputs <span class="in">`layer1_outputs`</span>. </span>
<span id="cb82-411"><a href="#cb82-411"></a></span>
<span id="cb82-414"><a href="#cb82-414"></a><span class="in">```{python}</span></span>
<span id="cb82-415"><a href="#cb82-415"></a>layer1_outputs <span class="op">=</span> np.dot(inputs, np.array(weights).T) <span class="op">+</span> biases</span>
<span id="cb82-416"><a href="#cb82-416"></a><span class="in">```</span></span>
<span id="cb82-417"><a href="#cb82-417"></a></span>
<span id="cb82-418"><a href="#cb82-418"></a>As previously stated, inputs to the layers are either inputs from the actual dataset you're training with, or outputs from a previous layer. That's why we defined $2$ versions of <span class="in">`weights`</span> and <span class="in">`biases`</span>, but only one of <span class="in">`inputs`</span>. </span>
<span id="cb82-419"><a href="#cb82-419"></a></span>
<span id="cb82-422"><a href="#cb82-422"></a><span class="in">```{python}</span></span>
<span id="cb82-423"><a href="#cb82-423"></a>layer2_outputs <span class="op">=</span> np.dot(layer1_outputs, np.array(weights2).T) <span class="op">+</span> biases2</span>
<span id="cb82-424"><a href="#cb82-424"></a><span class="in">```</span></span>
<span id="cb82-425"><a href="#cb82-425"></a></span>
<span id="cb82-426"><a href="#cb82-426"></a>At this point, our neural network could be visually represented as:</span>
<span id="cb82-427"><a href="#cb82-427"></a></span>
<span id="cb82-430"><a href="#cb82-430"></a><span class="in">```{python}</span></span>
<span id="cb82-431"><a href="#cb82-431"></a><span class="co"># | code-fold: true</span></span>
<span id="cb82-432"><a href="#cb82-432"></a><span class="co"># | code-summary: "Show the code"</span></span>
<span id="cb82-433"><a href="#cb82-433"></a><span class="op">%%</span>itikz <span class="op">--</span>temp<span class="op">-</span><span class="bu">dir</span> <span class="op">--</span>tex<span class="op">-</span>packages<span class="op">=</span>tikz <span class="op">--</span>tikz<span class="op">-</span>libraries<span class="op">=</span>arrows <span class="op">--</span>implicit<span class="op">-</span>standalone</span>
<span id="cb82-434"><a href="#cb82-434"></a>\begin{tikzpicture}</span>
<span id="cb82-435"><a href="#cb82-435"></a>\foreach \i <span class="kw">in</span> {<span class="dv">1</span>,<span class="dv">2</span>,...,<span class="dv">4</span>}</span>
<span id="cb82-436"><a href="#cb82-436"></a>{</span>
<span id="cb82-437"><a href="#cb82-437"></a>    \node[circle, </span>
<span id="cb82-438"><a href="#cb82-438"></a>        minimum size <span class="op">=</span> <span class="dv">15</span><span class="er">mm</span>,</span>
<span id="cb82-439"><a href="#cb82-439"></a>        fill<span class="op">=</span>red<span class="op">!</span><span class="dv">30</span></span>
<span id="cb82-440"><a href="#cb82-440"></a>        ] (Input<span class="op">-</span>\i) at (<span class="dv">0</span>,<span class="op">-</span>\i <span class="op">*</span> <span class="dv">2</span>) {\large $x_\i$}<span class="op">;</span></span>
<span id="cb82-441"><a href="#cb82-441"></a>}</span>
<span id="cb82-442"><a href="#cb82-442"></a>\foreach \i <span class="kw">in</span> {<span class="dv">1</span>,<span class="dv">2</span>,...,<span class="dv">3</span>}</span>
<span id="cb82-443"><a href="#cb82-443"></a>{</span>
<span id="cb82-444"><a href="#cb82-444"></a>    \node[circle, </span>
<span id="cb82-445"><a href="#cb82-445"></a>        minimum size <span class="op">=</span> <span class="dv">15</span><span class="er">mm</span>,</span>
<span id="cb82-446"><a href="#cb82-446"></a>        fill<span class="op">=</span>blue<span class="op">!</span><span class="dv">50</span>,</span>
<span id="cb82-447"><a href="#cb82-447"></a>        yshift<span class="op">=-</span><span class="dv">10</span> mm</span>
<span id="cb82-448"><a href="#cb82-448"></a>        ] (Hidden1<span class="op">-</span>\i) at (<span class="fl">3.0</span>,<span class="op">-</span>\i <span class="op">*</span> <span class="dv">2</span>) {\large $h_\i<span class="op">^</span>{(<span class="dv">1</span>)}$}<span class="op">;</span></span>
<span id="cb82-449"><a href="#cb82-449"></a>        </span>
<span id="cb82-450"><a href="#cb82-450"></a>}</span>
<span id="cb82-451"><a href="#cb82-451"></a>\foreach \i <span class="kw">in</span> {<span class="dv">1</span>,<span class="dv">2</span>,...,<span class="dv">3</span>}</span>
<span id="cb82-452"><a href="#cb82-452"></a>{</span>
<span id="cb82-453"><a href="#cb82-453"></a>    \node[circle, </span>
<span id="cb82-454"><a href="#cb82-454"></a>        minimum size <span class="op">=</span> <span class="dv">15</span><span class="er">mm</span>,</span>
<span id="cb82-455"><a href="#cb82-455"></a>        fill<span class="op">=</span>blue<span class="op">!</span><span class="dv">50</span>,</span>
<span id="cb82-456"><a href="#cb82-456"></a>        yshift<span class="op">=-</span><span class="dv">10</span> mm</span>
<span id="cb82-457"><a href="#cb82-457"></a>        ] (Hidden2<span class="op">-</span>\i) at (<span class="fl">6.0</span>,<span class="op">-</span>\i <span class="op">*</span> <span class="dv">2</span>) {\large $h_\i<span class="op">^</span>{(<span class="dv">2</span>)}$}<span class="op">;</span></span>
<span id="cb82-458"><a href="#cb82-458"></a>        </span>
<span id="cb82-459"><a href="#cb82-459"></a>}</span>
<span id="cb82-460"><a href="#cb82-460"></a></span>
<span id="cb82-461"><a href="#cb82-461"></a><span class="op">%</span> Connect neurons In<span class="op">-</span>Hidden1</span>
<span id="cb82-462"><a href="#cb82-462"></a>\foreach \i <span class="kw">in</span> {<span class="dv">1</span>,...,<span class="dv">4</span>}</span>
<span id="cb82-463"><a href="#cb82-463"></a>{</span>
<span id="cb82-464"><a href="#cb82-464"></a>    \foreach \j <span class="kw">in</span> {<span class="dv">1</span>,...,<span class="dv">3</span>}</span>
<span id="cb82-465"><a href="#cb82-465"></a>    {</span>
<span id="cb82-466"><a href="#cb82-466"></a>        \draw[<span class="op">-&gt;</span>, shorten <span class="op">&gt;=</span><span class="dv">1</span><span class="er">pt</span>] (Input<span class="op">-</span>\i) <span class="op">--</span> (Hidden1<span class="op">-</span>\j)<span class="op">;</span>   </span>
<span id="cb82-467"><a href="#cb82-467"></a>    }</span>
<span id="cb82-468"><a href="#cb82-468"></a>}</span>
<span id="cb82-469"><a href="#cb82-469"></a><span class="op">%</span> Connect neurons Hidden1<span class="op">-</span>Hidden2</span>
<span id="cb82-470"><a href="#cb82-470"></a>\foreach \i <span class="kw">in</span> {<span class="dv">1</span>,...,<span class="dv">3</span>}</span>
<span id="cb82-471"><a href="#cb82-471"></a>{</span>
<span id="cb82-472"><a href="#cb82-472"></a>    \foreach \j <span class="kw">in</span> {<span class="dv">1</span>,...,<span class="dv">3</span>}</span>
<span id="cb82-473"><a href="#cb82-473"></a>    {</span>
<span id="cb82-474"><a href="#cb82-474"></a>        \draw[<span class="op">-&gt;</span>, shorten <span class="op">&gt;=</span><span class="dv">1</span><span class="er">pt</span>] (Hidden1<span class="op">-</span>\i) <span class="op">--</span> (Hidden2<span class="op">-</span>\j)<span class="op">;</span>   </span>
<span id="cb82-475"><a href="#cb82-475"></a>    }</span>
<span id="cb82-476"><a href="#cb82-476"></a>}</span>
<span id="cb82-477"><a href="#cb82-477"></a>\end{tikzpicture}</span>
<span id="cb82-478"><a href="#cb82-478"></a><span class="in">```</span></span>
<span id="cb82-479"><a href="#cb82-479"></a></span>
<span id="cb82-480"><a href="#cb82-480"></a><span class="fu">## Training Data</span></span>
<span id="cb82-481"><a href="#cb82-481"></a></span>
<span id="cb82-482"><a href="#cb82-482"></a>Next, rather than hand-typing in random data, we'll use a function that can create non-linear data. What do we mean by non-linear? Linear data can be fit or represented by a straight line. Non-linear data cannot be represented well by a straight line. </span>
<span id="cb82-483"><a href="#cb82-483"></a></span>
<span id="cb82-484"><a href="#cb82-484"></a>We shall use the python package <span class="in">`nnfs`</span> to create data. You can install it with</span>
<span id="cb82-485"><a href="#cb82-485"></a></span>
<span id="cb82-486"><a href="#cb82-486"></a><span class="in">```</span></span>
<span id="cb82-487"><a href="#cb82-487"></a><span class="in">pip install nnfs</span></span>
<span id="cb82-488"><a href="#cb82-488"></a><span class="in">```</span></span>
<span id="cb82-489"><a href="#cb82-489"></a></span>
<span id="cb82-490"><a href="#cb82-490"></a>You typically don't generate training data from a package like <span class="in">`nnfs`</span> for your neural networks. Generating a dataset this way is purely for convenience at this stage. I shall also use this package to ensure repeatability.</span>
<span id="cb82-491"><a href="#cb82-491"></a></span>
<span id="cb82-494"><a href="#cb82-494"></a><span class="in">```{python}</span></span>
<span id="cb82-495"><a href="#cb82-495"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb82-496"><a href="#cb82-496"></a><span class="im">import</span> nnfs</span>
<span id="cb82-497"><a href="#cb82-497"></a></span>
<span id="cb82-498"><a href="#cb82-498"></a>nnfs.init()</span>
<span id="cb82-499"><a href="#cb82-499"></a><span class="in">```</span></span>
<span id="cb82-500"><a href="#cb82-500"></a></span>
<span id="cb82-501"><a href="#cb82-501"></a>The <span class="in">`nnfs.init()`</span> does three things: it sets the random seed to $0$ by default, creates a <span class="in">`float32`</span> dtype default and overrides the original dot product from <span class="in">`numpy`</span>. All of these are meant to ensure repeatable results for following along. </span>
<span id="cb82-502"><a href="#cb82-502"></a></span>
<span id="cb82-505"><a href="#cb82-505"></a><span class="in">```{python}</span></span>
<span id="cb82-506"><a href="#cb82-506"></a><span class="im">from</span> nnfs.datasets <span class="im">import</span> spiral_data</span>
<span id="cb82-507"><a href="#cb82-507"></a><span class="im">import</span> matplotlib.pyplot <span class="im">as</span> plt</span>
<span id="cb82-508"><a href="#cb82-508"></a></span>
<span id="cb82-509"><a href="#cb82-509"></a>X, y <span class="op">=</span> spiral_data(samples<span class="op">=</span><span class="dv">100</span>, classes<span class="op">=</span><span class="dv">3</span>)</span>
<span id="cb82-510"><a href="#cb82-510"></a></span>
<span id="cb82-511"><a href="#cb82-511"></a>plt.scatter(X[:, <span class="dv">0</span>], X[:, <span class="dv">1</span>])</span>
<span id="cb82-512"><a href="#cb82-512"></a>plt.show()</span>
<span id="cb82-513"><a href="#cb82-513"></a><span class="in">```</span></span>
<span id="cb82-514"><a href="#cb82-514"></a></span>
<span id="cb82-515"><a href="#cb82-515"></a>The <span class="in">`spiral_data`</span> function allows us to create a dataset with as many classes as we want. The function has parameters to choose the number of classes and the number of points/observations per class in the resulting non-linear dataset. </span>
<span id="cb82-516"><a href="#cb82-516"></a></span>
<span id="cb82-517"><a href="#cb82-517"></a>If you trace from the center, you can determine all $3$ classes separately, but this is a very challenging problem for a machine learning classifier to solve. Adding color to the chart makes this more clear:</span>
<span id="cb82-518"><a href="#cb82-518"></a></span>
<span id="cb82-521"><a href="#cb82-521"></a><span class="in">```{python}</span></span>
<span id="cb82-522"><a href="#cb82-522"></a>plt.scatter(X[:,<span class="dv">0</span>],X[:,<span class="dv">1</span>],c<span class="op">=</span>y,cmap<span class="op">=</span><span class="st">'brg'</span>)</span>
<span id="cb82-523"><a href="#cb82-523"></a>plt.show()</span>
<span id="cb82-524"><a href="#cb82-524"></a><span class="in">```</span></span>
<span id="cb82-525"><a href="#cb82-525"></a></span>
<span id="cb82-526"><a href="#cb82-526"></a>Keep in mind that the neural network will not be aware of the color differences as the data have no class encodings. This is only made as an instruction for you. In the data above, each dot is an observation, that is, it's coordinates are the samples that form the dataset. The classification for the dot has to do with which spiral it is a part of, depicted by red, blue or green color. </span>
<span id="cb82-527"><a href="#cb82-527"></a></span>
<span id="cb82-528"><a href="#cb82-528"></a><span class="fu">## Dense Layer Class</span></span>
<span id="cb82-529"><a href="#cb82-529"></a></span>
<span id="cb82-530"><a href="#cb82-530"></a>Now that we no longer need to hand-type our data, we should create something similar for our various types of neural network layers. So far, we've only used what's called a **dense** or **fully-connected** layer. These layers are commonly referred to as dense layers in papers, literature and code, but you will see them called fully-connected or fc for short in the code I write. Our dense layer class begins with two methods:</span>
<span id="cb82-531"><a href="#cb82-531"></a></span>
<span id="cb82-534"><a href="#cb82-534"></a><span class="in">```{python}</span></span>
<span id="cb82-535"><a href="#cb82-535"></a><span class="kw">class</span> DenseLayer:</span>
<span id="cb82-536"><a href="#cb82-536"></a>    <span class="kw">def</span> <span class="fu">__init__</span>(<span class="va">self</span>, n_inputs, n_neurons):</span>
<span id="cb82-537"><a href="#cb82-537"></a>        <span class="co"># Initialize weights and biases</span></span>
<span id="cb82-538"><a href="#cb82-538"></a>        <span class="cf">pass</span> <span class="co"># using pass statement as a placeholder</span></span>
<span id="cb82-539"><a href="#cb82-539"></a></span>
<span id="cb82-540"><a href="#cb82-540"></a>    <span class="co"># Forward pass</span></span>
<span id="cb82-541"><a href="#cb82-541"></a>    <span class="kw">def</span> forward(<span class="va">self</span>, inputs):</span>
<span id="cb82-542"><a href="#cb82-542"></a>        <span class="co"># Calculate output values from inputs, weights and biases</span></span>
<span id="cb82-543"><a href="#cb82-543"></a>        <span class="cf">pass</span> <span class="co"># using pass statement as a placeholder</span></span>
<span id="cb82-544"><a href="#cb82-544"></a><span class="in">```</span></span>
<span id="cb82-545"><a href="#cb82-545"></a></span>
<span id="cb82-546"><a href="#cb82-546"></a>Weights are often initialized randomly for a model, but not always. If you wish to load a pre-trained model, you will initialize the parameters to whatever that pretrained model finished with. It's also possible that, even for a new model, you have some other initialization rules besides random. From now, we'll stick with random initialization. Next, we have the <span class="in">`forward`</span> method. When we pass data through a model from beginning to end, this is called a **forward** pass. Just like everything else, this is not the only way to do things. You can have the data loop back around and do other interesting things. We'll keep it usual and perform a regular forward pass.</span>
<span id="cb82-547"><a href="#cb82-547"></a></span>
<span id="cb82-548"><a href="#cb82-548"></a>To continue the <span class="in">`LayerDense`</span> class code, let's add the random initialization of weights and biases:</span>
<span id="cb82-549"><a href="#cb82-549"></a></span>
<span id="cb82-550"><a href="#cb82-550"></a><span class="in">```python</span></span>
<span id="cb82-551"><a href="#cb82-551"></a><span class="co">#Layer initialization</span></span>
<span id="cb82-552"><a href="#cb82-552"></a><span class="kw">def</span> <span class="fu">__init__</span>(<span class="va">self</span>,n_inputs, n_neurons):</span>
<span id="cb82-553"><a href="#cb82-553"></a>    <span class="va">self</span>.weights <span class="op">=</span> <span class="fl">0.01</span> <span class="op">*</span> np.random.randn(n_inputs,n_neurons)</span>
<span id="cb82-554"><a href="#cb82-554"></a>    <span class="va">self</span>.biases <span class="op">=</span> np.zeros((<span class="dv">1</span>,n_neurons))</span>
<span id="cb82-555"><a href="#cb82-555"></a><span class="in">```</span></span>
<span id="cb82-556"><a href="#cb82-556"></a></span>
<span id="cb82-557"><a href="#cb82-557"></a>Here, we are setting the weights to be random and the biases to be $0$. Note that, we are initializing weights to be a matrix of dimensions $n_{inputs} \times n_{neurons}$, rather than $n_{neurons} \times n_{inputs}$. We're doing this ahead instead of transposing everytime we perform a forward pass, as explained in the previous chapter. </span>
<span id="cb82-558"><a href="#cb82-558"></a></span>
<span id="cb82-559"><a href="#cb82-559"></a>We initialize the biases to zero, because with many samples containing values of $0$, it will ensure that a neuron fires initially. The most common initialization for biases is zero. This will vary depending on our use-case and is just one of the many things we can tweak when trying to improve results. One situation where we might want to try something else is with what's called *dead neurons*. </span>
<span id="cb82-560"><a href="#cb82-560"></a></span>
<span id="cb82-561"><a href="#cb82-561"></a>Imagine our step function again:</span>
<span id="cb82-562"><a href="#cb82-562"></a></span>
<span id="cb82-563"><a href="#cb82-563"></a>\begin{align*}</span>
<span id="cb82-564"><a href="#cb82-564"></a>y = \begin{cases}</span>
<span id="cb82-565"><a href="#cb82-565"></a>1, &amp; x &gt; 0<span class="sc">\\</span></span>
<span id="cb82-566"><a href="#cb82-566"></a>0, &amp; x \leq 0</span>
<span id="cb82-567"><a href="#cb82-567"></a>\end{cases}</span>
<span id="cb82-568"><a href="#cb82-568"></a>\end{align*}</span>
<span id="cb82-569"><a href="#cb82-569"></a></span>
<span id="cb82-570"><a href="#cb82-570"></a>It's possible for $\text{weights} \cdot \text{inputs} + \text{biases}$ not to meet the threshold of the step function, which means the neuron will output a zero. On its own, this is not a big issue, but it becomes a problem if this happens to this neuron for every one of the input samples (it'll become clear why once we learn about backpropogation). So, then this neuron's $0$ output is the input to another neuron. Any weight multiplied by zero will be zero. With an increasing number of neurons outputting $0$, more inputs to the next neurons will be zeros, rendering the network essentially non-trainable or *dead*. </span>
<span id="cb82-571"><a href="#cb82-571"></a></span>
<span id="cb82-572"><a href="#cb82-572"></a>On to our <span class="in">`forward`</span> method now. </span>
<span id="cb82-573"><a href="#cb82-573"></a></span>
<span id="cb82-576"><a href="#cb82-576"></a><span class="in">```{python}</span></span>
<span id="cb82-577"><a href="#cb82-577"></a><span class="kw">class</span> DenseLayer:</span>
<span id="cb82-578"><a href="#cb82-578"></a>    <span class="kw">def</span> <span class="fu">__init__</span>(<span class="va">self</span>, n_inputs, n_neurons):</span>
<span id="cb82-579"><a href="#cb82-579"></a>        <span class="va">self</span>.weights <span class="op">=</span> <span class="fl">0.01</span> <span class="op">*</span> np.random.randn(n_inputs,n_neurons)</span>
<span id="cb82-580"><a href="#cb82-580"></a>        <span class="va">self</span>.biases <span class="op">=</span> np.zeros((<span class="dv">1</span>,n_neurons))</span>
<span id="cb82-581"><a href="#cb82-581"></a></span>
<span id="cb82-582"><a href="#cb82-582"></a>    <span class="kw">def</span> forward(<span class="va">self</span>,inputs):</span>
<span id="cb82-583"><a href="#cb82-583"></a>        <span class="va">self</span>.output <span class="op">=</span> np.dot(inputs,<span class="va">self</span>.weights) <span class="op">+</span> <span class="va">self</span>.biases</span>
<span id="cb82-584"><a href="#cb82-584"></a><span class="in">```</span></span>
<span id="cb82-585"><a href="#cb82-585"></a></span>
<span id="cb82-586"><a href="#cb82-586"></a>We are now ready to make use of this new class instead of hardcoded calculations, so let's generate some data using the discussed dataset creation method and use our new layer to perform a forward pass:</span>
<span id="cb82-587"><a href="#cb82-587"></a></span>
<span id="cb82-590"><a href="#cb82-590"></a><span class="in">```{python}</span></span>
<span id="cb82-591"><a href="#cb82-591"></a><span class="co"># Create dataset</span></span>
<span id="cb82-592"><a href="#cb82-592"></a>X, y <span class="op">=</span> spiral_data(samples<span class="op">=</span><span class="dv">100</span>, classes<span class="op">=</span><span class="dv">3</span>)</span>
<span id="cb82-593"><a href="#cb82-593"></a></span>
<span id="cb82-594"><a href="#cb82-594"></a><span class="co"># Create a dense layer with 2 input features and 3 output values</span></span>
<span id="cb82-595"><a href="#cb82-595"></a>dense1 <span class="op">=</span> DenseLayer(<span class="dv">2</span>, <span class="dv">3</span>)</span>
<span id="cb82-596"><a href="#cb82-596"></a></span>
<span id="cb82-597"><a href="#cb82-597"></a><span class="co"># Perform a forward pass of our training data through this layer</span></span>
<span id="cb82-598"><a href="#cb82-598"></a>dense1.forward(X)</span>
<span id="cb82-599"><a href="#cb82-599"></a></span>
<span id="cb82-600"><a href="#cb82-600"></a><span class="co"># Let's see the output of the first few samples</span></span>
<span id="cb82-601"><a href="#cb82-601"></a><span class="bu">print</span>(dense1.output[:<span class="dv">5</span>])</span>
<span id="cb82-602"><a href="#cb82-602"></a><span class="in">```</span></span>
<span id="cb82-603"><a href="#cb82-603"></a></span>
<span id="cb82-604"><a href="#cb82-604"></a><span class="fu">## Activation Functions</span></span>
<span id="cb82-605"><a href="#cb82-605"></a></span>
<span id="cb82-606"><a href="#cb82-606"></a>We use activation functions because if the activation function itself is non-linear, it allows for neural networks with two or more layers to map non-linear functions. We'll see how this works. In general, your neural network will have $2$ types of activation functions. The first will be the activation function used in hidden layers, and the second will be used in the output layer. Usually, the activation function used for hidden neurons will be all the same for all of them, but it doesn't have to.</span>
<span id="cb82-607"><a href="#cb82-607"></a></span>
<span id="cb82-608"><a href="#cb82-608"></a><span class="fu">### Why use activation functions?</span></span>
<span id="cb82-609"><a href="#cb82-609"></a></span>
<span id="cb82-610"><a href="#cb82-610"></a>Let's discuss why we use activation functions in the first place? In most cases, for a neural network to fit a non-linear function, we need it to contain two or more hidden layers and we need those hidden layers to use a non-linear activation function.</span>
<span id="cb82-611"><a href="#cb82-611"></a></span>
<span id="cb82-612"><a href="#cb82-612"></a>While there are certainly problems in life that are linear in nature, for example, trying to figure out the cost of some number of shirts, and we know the cost of an individual shirt, then the equation to calculate the price of any number of those products is a linear equation; other problems in life are not so simple. </span>
<span id="cb82-613"><a href="#cb82-613"></a></span>
<span id="cb82-614"><a href="#cb82-614"></a>Many interesting and hard problems are non-linear. The main attraction of neural networks has to do with their ability to solve non-linear problems. If we allow only linear activation functions in a neural network, the output will just be a linear transformation of the input, which is not enough to form a universal function approximator. </span>
<span id="cb82-615"><a href="#cb82-615"></a></span>
<span id="cb82-616"><a href="#cb82-616"></a>For simplicity, suppose a neural network has $2$ hidden layers with $1$ neuron each. </span>
<span id="cb82-617"><a href="#cb82-617"></a></span>
<span id="cb82-620"><a href="#cb82-620"></a><span class="in">```{python}</span></span>
<span id="cb82-621"><a href="#cb82-621"></a><span class="co"># | code-fold: true</span></span>
<span id="cb82-622"><a href="#cb82-622"></a><span class="co"># | code-summary: "Show the code"</span></span>
<span id="cb82-623"><a href="#cb82-623"></a><span class="op">%%</span>itikz <span class="op">--</span>temp<span class="op">-</span><span class="bu">dir</span> <span class="op">--</span>tex<span class="op">-</span>packages<span class="op">=</span>tikz <span class="op">--</span>tikz<span class="op">-</span>libraries<span class="op">=</span>arrows <span class="op">--</span>implicit<span class="op">-</span>standalone</span>
<span id="cb82-624"><a href="#cb82-624"></a>\begin{tikzpicture}[scale<span class="op">=</span><span class="fl">1.5</span>]</span>
<span id="cb82-625"><a href="#cb82-625"></a>    \node[circle, </span>
<span id="cb82-626"><a href="#cb82-626"></a>        minimum size <span class="op">=</span> <span class="dv">15</span><span class="er">mm</span>,</span>
<span id="cb82-627"><a href="#cb82-627"></a>        fill<span class="op">=</span>red<span class="op">!</span><span class="dv">30</span></span>
<span id="cb82-628"><a href="#cb82-628"></a>        ] (Input) at (<span class="dv">0</span>,<span class="dv">0</span>) {\large $x_1$}<span class="op">;</span></span>
<span id="cb82-629"><a href="#cb82-629"></a></span>
<span id="cb82-630"><a href="#cb82-630"></a>    \node[circle, </span>
<span id="cb82-631"><a href="#cb82-631"></a>        minimum size <span class="op">=</span> <span class="dv">15</span><span class="er">mm</span>,</span>
<span id="cb82-632"><a href="#cb82-632"></a>        fill<span class="op">=</span>blue<span class="op">!</span><span class="dv">50</span></span>
<span id="cb82-633"><a href="#cb82-633"></a>        ] (Hidden1) at (<span class="fl">3.0</span>,<span class="dv">0</span>) {\large $h_1<span class="op">^</span>{(<span class="dv">1</span>)}$}<span class="op">;</span></span>
<span id="cb82-634"><a href="#cb82-634"></a>        </span>
<span id="cb82-635"><a href="#cb82-635"></a></span>
<span id="cb82-636"><a href="#cb82-636"></a>    \node[circle, </span>
<span id="cb82-637"><a href="#cb82-637"></a>        minimum size <span class="op">=</span> <span class="dv">15</span><span class="er">mm</span>,</span>
<span id="cb82-638"><a href="#cb82-638"></a>        fill<span class="op">=</span>blue<span class="op">!</span><span class="dv">50</span></span>
<span id="cb82-639"><a href="#cb82-639"></a>        ] (Hidden2) at (<span class="fl">6.0</span>,<span class="dv">0</span>) {\large $h_1<span class="op">^</span>{(<span class="dv">2</span>)}$}<span class="op">;</span></span>
<span id="cb82-640"><a href="#cb82-640"></a></span>
<span id="cb82-641"><a href="#cb82-641"></a>    \node[circle, </span>
<span id="cb82-642"><a href="#cb82-642"></a>        minimum size <span class="op">=</span> <span class="dv">15</span><span class="er">mm</span>,</span>
<span id="cb82-643"><a href="#cb82-643"></a>        fill<span class="op">=</span>red<span class="op">!</span><span class="dv">30</span></span>
<span id="cb82-644"><a href="#cb82-644"></a>        ] (Output) at (<span class="fl">9.0</span>,<span class="dv">0</span>) {\large $\hat{y}_1$}<span class="op">;</span>        </span>
<span id="cb82-645"><a href="#cb82-645"></a>        </span>
<span id="cb82-646"><a href="#cb82-646"></a></span>
<span id="cb82-647"><a href="#cb82-647"></a>    \draw[<span class="op">-&gt;</span>, shorten <span class="op">&gt;=</span><span class="dv">1</span><span class="er">pt</span>] (Input) <span class="op">--</span> (Hidden1) node [midway,above] {\large $w_1$}<span class="op">;</span></span>
<span id="cb82-648"><a href="#cb82-648"></a>    \draw[<span class="op">-&gt;</span>, shorten <span class="op">&gt;=</span><span class="dv">1</span><span class="er">pt</span>] (Hidden1) <span class="op">--</span> (Hidden2) node [midway,above]  {\large $w_2$}<span class="op">;</span></span>
<span id="cb82-649"><a href="#cb82-649"></a>    \draw[<span class="op">-&gt;</span>, shorten <span class="op">&gt;=</span><span class="dv">1</span><span class="er">pt</span>] (Hidden2) <span class="op">--</span> (Output)<span class="op">;</span></span>
<span id="cb82-650"><a href="#cb82-650"></a>    \draw[<span class="op">-&gt;</span>, shorten <span class="op">&gt;=</span><span class="dv">1</span><span class="er">pt</span>] (<span class="fl">3.0</span>, <span class="op">-</span><span class="fl">2.0</span>) node [below] {\large $b_1$} <span class="op">--</span> (Hidden1)<span class="op">;</span></span>
<span id="cb82-651"><a href="#cb82-651"></a>    \draw[<span class="op">-&gt;</span>, shorten <span class="op">&gt;=</span><span class="dv">1</span><span class="er">pt</span>] (<span class="fl">6.0</span>, <span class="op">-</span><span class="fl">2.0</span>) node [below] {\large $b_2$} <span class="op">--</span> (Hidden2)<span class="op">;</span></span>
<span id="cb82-652"><a href="#cb82-652"></a>\end{tikzpicture}</span>
<span id="cb82-653"><a href="#cb82-653"></a><span class="in">```</span></span>
<span id="cb82-654"><a href="#cb82-654"></a></span>
<span id="cb82-655"><a href="#cb82-655"></a>\begin{align*}</span>
<span id="cb82-656"><a href="#cb82-656"></a>\hat{y}_1 &amp;= h_1^{(2)} <span class="sc">\\</span></span>
<span id="cb82-657"><a href="#cb82-657"></a>&amp;= w_2 h_1^{(1)} + b_2 <span class="sc">\\</span></span>
<span id="cb82-658"><a href="#cb82-658"></a>&amp;= w_2 (w_1 x_1 + b_1) + b_2 <span class="sc">\\</span></span>
<span id="cb82-659"><a href="#cb82-659"></a>&amp;= w_2 w_1 x_1 + (w_2 b_1 + b_2)</span>
<span id="cb82-660"><a href="#cb82-660"></a>\end{align*}</span>
<span id="cb82-661"><a href="#cb82-661"></a></span>
<span id="cb82-662"><a href="#cb82-662"></a>So, $\hat{y}_1$ is a linear function of the inputs, no matter, what values we choose for weights and biases.</span>
<span id="cb82-663"><a href="#cb82-663"></a></span>
<span id="cb82-664"><a href="#cb82-664"></a>The composition of linear functions is linear. No matter what we do, however many layers we have, or neurons we have in each layer, this network can only model linear functions.</span>
<span id="cb82-665"><a href="#cb82-665"></a></span>
<span id="cb82-666"><a href="#cb82-666"></a><span class="fu">## ReLU Activation in a pair of Neurons</span></span>
<span id="cb82-667"><a href="#cb82-667"></a></span>
<span id="cb82-668"><a href="#cb82-668"></a>It is less obvious how, with a barely non-linear activation function, like the rectified linear activation function, we can suddenly model non-linear relationships and functions. Let's start with a single neuron. We'll begin with both a weight of zero and a bias of zero:</span>
<span id="cb82-669"><a href="#cb82-669"></a></span>
<span id="cb82-672"><a href="#cb82-672"></a><span class="in">```{python}</span></span>
<span id="cb82-673"><a href="#cb82-673"></a><span class="co"># | code-fold: true</span></span>
<span id="cb82-674"><a href="#cb82-674"></a><span class="co"># | code-summary: "Show the code"</span></span>
<span id="cb82-675"><a href="#cb82-675"></a><span class="op">%%</span>itikz <span class="op">--</span>temp<span class="op">-</span><span class="bu">dir</span> <span class="op">--</span>tex<span class="op">-</span>packages<span class="op">=</span>tikz <span class="op">--</span>tikz<span class="op">-</span>libraries<span class="op">=</span>arrows <span class="op">--</span>implicit<span class="op">-</span>standalone</span>
<span id="cb82-676"><a href="#cb82-676"></a>\begin{tikzpicture}[scale<span class="op">=</span><span class="fl">1.5</span>]</span>
<span id="cb82-677"><a href="#cb82-677"></a>    \node[circle, </span>
<span id="cb82-678"><a href="#cb82-678"></a>        minimum size <span class="op">=</span> <span class="dv">15</span><span class="er">mm</span>,</span>
<span id="cb82-679"><a href="#cb82-679"></a>        draw<span class="op">=</span>blue</span>
<span id="cb82-680"><a href="#cb82-680"></a>        ] (Input) at (<span class="dv">0</span>,<span class="dv">0</span>) {}<span class="op">;</span></span>
<span id="cb82-681"><a href="#cb82-681"></a>    </span>
<span id="cb82-682"><a href="#cb82-682"></a>    \node[] (w) at (<span class="op">-</span><span class="dv">3</span>,<span class="dv">0</span>) {}<span class="op">;</span></span>
<span id="cb82-683"><a href="#cb82-683"></a>    \node[] (b) at (<span class="dv">0</span>,<span class="op">-</span><span class="dv">2</span>) {}<span class="op">;</span></span>
<span id="cb82-684"><a href="#cb82-684"></a></span>
<span id="cb82-685"><a href="#cb82-685"></a>    \draw[<span class="op">-&gt;</span>, shorten <span class="op">&gt;=</span><span class="dv">1</span><span class="er">pt</span>] (w) <span class="op">--</span> (Input) node [midway,above] {\large $<span class="fl">0.00</span>$}<span class="op">;</span></span>
<span id="cb82-686"><a href="#cb82-686"></a>    \draw[<span class="op">-&gt;</span>, shorten <span class="op">&gt;=</span><span class="dv">1</span><span class="er">pt</span>] (b) node [below] {\large $<span class="fl">0.00</span>$} <span class="op">--</span> (Input)<span class="op">;</span></span>
<span id="cb82-687"><a href="#cb82-687"></a>\end{tikzpicture}</span>
<span id="cb82-688"><a href="#cb82-688"></a><span class="in">```</span></span>
<span id="cb82-689"><a href="#cb82-689"></a></span>
<span id="cb82-690"><a href="#cb82-690"></a>In this case, no matter what input we pass, the output of this neuron will always be $0$, because the weight is $0$ and the bias is $0$. </span>
<span id="cb82-693"><a href="#cb82-693"></a><span class="in">```{python}</span></span>
<span id="cb82-694"><a href="#cb82-694"></a><span class="co"># | code-fold: true</span></span>
<span id="cb82-695"><a href="#cb82-695"></a><span class="co"># | code-summary: "Show the code"</span></span>
<span id="cb82-696"><a href="#cb82-696"></a><span class="op">%%</span>itikz <span class="op">--</span>temp<span class="op">-</span><span class="bu">dir</span> <span class="op">--</span>tex<span class="op">-</span>packages<span class="op">=</span>tikz,pgfplots <span class="op">--</span>tikz<span class="op">-</span>libraries<span class="op">=</span>arrows <span class="op">--</span>implicit<span class="op">-</span>standalone</span>
<span id="cb82-697"><a href="#cb82-697"></a>\begin{tikzpicture}[scale<span class="op">=</span><span class="fl">1.5</span>]</span>
<span id="cb82-698"><a href="#cb82-698"></a>\begin{axis}[grid]</span>
<span id="cb82-699"><a href="#cb82-699"></a>\addplot[color<span class="op">=</span>blue,thick]{<span class="dv">0</span>}<span class="op">;</span></span>
<span id="cb82-700"><a href="#cb82-700"></a>\end{axis}</span>
<span id="cb82-701"><a href="#cb82-701"></a>\end{tikzpicture}</span>
<span id="cb82-702"><a href="#cb82-702"></a><span class="in">```</span></span>
<span id="cb82-703"><a href="#cb82-703"></a></span>
<span id="cb82-704"><a href="#cb82-704"></a>Let's set the weight to be $1.00$. </span>
<span id="cb82-705"><a href="#cb82-705"></a></span>
<span id="cb82-708"><a href="#cb82-708"></a><span class="in">```{python}</span></span>
<span id="cb82-709"><a href="#cb82-709"></a><span class="co"># | code-fold: true</span></span>
<span id="cb82-710"><a href="#cb82-710"></a><span class="co"># | code-summary: "Show the code"</span></span>
<span id="cb82-711"><a href="#cb82-711"></a><span class="op">%%</span>itikz <span class="op">--</span>temp<span class="op">-</span><span class="bu">dir</span> <span class="op">--</span>tex<span class="op">-</span>packages<span class="op">=</span>tikz <span class="op">--</span>tikz<span class="op">-</span>libraries<span class="op">=</span>arrows <span class="op">--</span>implicit<span class="op">-</span>standalone</span>
<span id="cb82-712"><a href="#cb82-712"></a>\begin{tikzpicture}[scale<span class="op">=</span><span class="fl">1.5</span>]</span>
<span id="cb82-713"><a href="#cb82-713"></a>    \node[circle, </span>
<span id="cb82-714"><a href="#cb82-714"></a>        minimum size <span class="op">=</span> <span class="dv">15</span><span class="er">mm</span>,</span>
<span id="cb82-715"><a href="#cb82-715"></a>        draw<span class="op">=</span>blue</span>
<span id="cb82-716"><a href="#cb82-716"></a>        ] (Input) at (<span class="dv">0</span>,<span class="dv">0</span>) {}<span class="op">;</span></span>
<span id="cb82-717"><a href="#cb82-717"></a>    </span>
<span id="cb82-718"><a href="#cb82-718"></a>    \node[] (w) at (<span class="op">-</span><span class="dv">3</span>,<span class="dv">0</span>) {}<span class="op">;</span></span>
<span id="cb82-719"><a href="#cb82-719"></a>    \node[] (b) at (<span class="dv">0</span>,<span class="op">-</span><span class="dv">2</span>) {}<span class="op">;</span></span>
<span id="cb82-720"><a href="#cb82-720"></a></span>
<span id="cb82-721"><a href="#cb82-721"></a>    \draw[<span class="op">-&gt;</span>, shorten <span class="op">&gt;=</span><span class="dv">1</span><span class="er">pt</span>] (w) <span class="op">--</span> (Input) node [midway,above] {\large $<span class="fl">1.00</span>$}<span class="op">;</span></span>
<span id="cb82-722"><a href="#cb82-722"></a>    \draw[<span class="op">-&gt;</span>, shorten <span class="op">&gt;=</span><span class="dv">1</span><span class="er">pt</span>] (b) node [below] {\large $<span class="fl">0.00</span>$} <span class="op">--</span> (Input)<span class="op">;</span></span>
<span id="cb82-723"><a href="#cb82-723"></a>\end{tikzpicture}</span>
<span id="cb82-724"><a href="#cb82-724"></a><span class="in">```</span></span>
<span id="cb82-725"><a href="#cb82-725"></a></span>
<span id="cb82-726"><a href="#cb82-726"></a>Now, it just looks like the basic rectified linear function. No surprises yet! </span>
<span id="cb82-727"><a href="#cb82-727"></a></span>
<span id="cb82-730"><a href="#cb82-730"></a><span class="in">```{python}</span></span>
<span id="cb82-731"><a href="#cb82-731"></a><span class="co"># | code-fold: true</span></span>
<span id="cb82-732"><a href="#cb82-732"></a><span class="co"># | code-summary: "Show the code"</span></span>
<span id="cb82-733"><a href="#cb82-733"></a><span class="op">%%</span>itikz <span class="op">--</span>temp<span class="op">-</span><span class="bu">dir</span> <span class="op">--</span>tex<span class="op">-</span>packages<span class="op">=</span>tikz,pgfplots <span class="op">--</span>tikz<span class="op">-</span>libraries<span class="op">=</span>arrows <span class="op">--</span>implicit<span class="op">-</span>standalone</span>
<span id="cb82-734"><a href="#cb82-734"></a>\begin{tikzpicture}[scale<span class="op">=</span><span class="fl">1.5</span>]</span>
<span id="cb82-735"><a href="#cb82-735"></a>\begin{axis}[grid,ymin<span class="op">=-</span><span class="fl">2.0</span>,ymax<span class="op">=</span><span class="fl">2.0</span>,xmin<span class="op">=-</span><span class="fl">2.0</span>,xmax<span class="op">=</span><span class="fl">2.0</span>]</span>
<span id="cb82-736"><a href="#cb82-736"></a>\addplot[color<span class="op">=</span>blue,thick]{<span class="bu">max</span>(x,<span class="dv">0</span>)}<span class="op">;</span></span>
<span id="cb82-737"><a href="#cb82-737"></a>\end{axis}</span>
<span id="cb82-738"><a href="#cb82-738"></a>\end{tikzpicture}</span>
<span id="cb82-739"><a href="#cb82-739"></a><span class="in">```</span></span>
<span id="cb82-740"><a href="#cb82-740"></a></span>
<span id="cb82-741"><a href="#cb82-741"></a>Now, let's set the bias to $0.50$:</span>
<span id="cb82-742"><a href="#cb82-742"></a></span>
<span id="cb82-745"><a href="#cb82-745"></a><span class="in">```{python}</span></span>
<span id="cb82-746"><a href="#cb82-746"></a><span class="co"># | code-fold: true</span></span>
<span id="cb82-747"><a href="#cb82-747"></a><span class="co"># | code-summary: "Show the code"</span></span>
<span id="cb82-748"><a href="#cb82-748"></a><span class="op">%%</span>itikz <span class="op">--</span>temp<span class="op">-</span><span class="bu">dir</span> <span class="op">--</span>tex<span class="op">-</span>packages<span class="op">=</span>tikz <span class="op">--</span>tikz<span class="op">-</span>libraries<span class="op">=</span>arrows <span class="op">--</span>implicit<span class="op">-</span>standalone</span>
<span id="cb82-749"><a href="#cb82-749"></a>\begin{tikzpicture}[scale<span class="op">=</span><span class="fl">1.5</span>]</span>
<span id="cb82-750"><a href="#cb82-750"></a>    \node[circle, </span>
<span id="cb82-751"><a href="#cb82-751"></a>        minimum size <span class="op">=</span> <span class="dv">15</span><span class="er">mm</span>,</span>
<span id="cb82-752"><a href="#cb82-752"></a>        draw<span class="op">=</span>blue</span>
<span id="cb82-753"><a href="#cb82-753"></a>        ] (Input) at (<span class="dv">0</span>,<span class="dv">0</span>) {}<span class="op">;</span></span>
<span id="cb82-754"><a href="#cb82-754"></a>    </span>
<span id="cb82-755"><a href="#cb82-755"></a>    \node[] (w) at (<span class="op">-</span><span class="dv">3</span>,<span class="dv">0</span>) {}<span class="op">;</span></span>
<span id="cb82-756"><a href="#cb82-756"></a>    \node[] (b) at (<span class="dv">0</span>,<span class="op">-</span><span class="dv">2</span>) {}<span class="op">;</span></span>
<span id="cb82-757"><a href="#cb82-757"></a></span>
<span id="cb82-758"><a href="#cb82-758"></a>    \draw[<span class="op">-&gt;</span>, shorten <span class="op">&gt;=</span><span class="dv">1</span><span class="er">pt</span>] (w) <span class="op">--</span> (Input) node [midway,above] {\large $<span class="fl">1.00</span>$}<span class="op">;</span></span>
<span id="cb82-759"><a href="#cb82-759"></a>    \draw[<span class="op">-&gt;</span>, shorten <span class="op">&gt;=</span><span class="dv">1</span><span class="er">pt</span>] (b) node [below] {\large $<span class="fl">0.50</span>$} <span class="op">--</span> (Input)<span class="op">;</span></span>
<span id="cb82-760"><a href="#cb82-760"></a>\end{tikzpicture}</span>
<span id="cb82-761"><a href="#cb82-761"></a><span class="in">```</span></span>
<span id="cb82-762"><a href="#cb82-762"></a></span>
<span id="cb82-763"><a href="#cb82-763"></a>We can see that in this case, with a single neuron, the bias offsets the overall function's activation point horizontally.</span>
<span id="cb82-764"><a href="#cb82-764"></a></span>
<span id="cb82-767"><a href="#cb82-767"></a><span class="in">```{python}</span></span>
<span id="cb82-768"><a href="#cb82-768"></a><span class="co"># | code-fold: true</span></span>
<span id="cb82-769"><a href="#cb82-769"></a><span class="co"># | code-summary: "Show the code"</span></span>
<span id="cb82-770"><a href="#cb82-770"></a><span class="op">%%</span>itikz <span class="op">--</span>temp<span class="op">-</span><span class="bu">dir</span> <span class="op">--</span>tex<span class="op">-</span>packages<span class="op">=</span>tikz,pgfplots <span class="op">--</span>tikz<span class="op">-</span>libraries<span class="op">=</span>arrows <span class="op">--</span>implicit<span class="op">-</span>standalone</span>
<span id="cb82-771"><a href="#cb82-771"></a>\begin{tikzpicture}[scale<span class="op">=</span><span class="fl">1.5</span>]</span>
<span id="cb82-772"><a href="#cb82-772"></a>\begin{axis}[grid,ymin<span class="op">=-</span><span class="fl">2.0</span>,ymax<span class="op">=</span><span class="fl">2.0</span>,xmin<span class="op">=-</span><span class="fl">2.0</span>,xmax<span class="op">=</span><span class="fl">2.0</span>]</span>
<span id="cb82-773"><a href="#cb82-773"></a>\addplot[color<span class="op">=</span>blue,thick,samples<span class="op">=</span><span class="dv">100</span>]{<span class="bu">max</span>(x<span class="op">+</span><span class="fl">0.50</span>,<span class="dv">0</span>)}<span class="op">;</span></span>
<span id="cb82-774"><a href="#cb82-774"></a>\end{axis}</span>
<span id="cb82-775"><a href="#cb82-775"></a>\end{tikzpicture}</span>
<span id="cb82-776"><a href="#cb82-776"></a><span class="in">```</span></span>
<span id="cb82-777"><a href="#cb82-777"></a></span>
<span id="cb82-778"><a href="#cb82-778"></a>By increasing bias, we're making this neuron activate earlier. What happens when we negate the weight to $-1.0$?</span>
<span id="cb82-779"><a href="#cb82-779"></a></span>
<span id="cb82-782"><a href="#cb82-782"></a><span class="in">```{python}</span></span>
<span id="cb82-783"><a href="#cb82-783"></a><span class="co"># | code-fold: true</span></span>
<span id="cb82-784"><a href="#cb82-784"></a><span class="co"># | code-summary: "Show the code"</span></span>
<span id="cb82-785"><a href="#cb82-785"></a><span class="op">%%</span>itikz <span class="op">--</span>temp<span class="op">-</span><span class="bu">dir</span> <span class="op">--</span>tex<span class="op">-</span>packages<span class="op">=</span>tikz <span class="op">--</span>tikz<span class="op">-</span>libraries<span class="op">=</span>arrows <span class="op">--</span>implicit<span class="op">-</span>standalone</span>
<span id="cb82-786"><a href="#cb82-786"></a>\begin{tikzpicture}[scale<span class="op">=</span><span class="fl">1.5</span>]</span>
<span id="cb82-787"><a href="#cb82-787"></a>    \node[circle, </span>
<span id="cb82-788"><a href="#cb82-788"></a>        minimum size <span class="op">=</span> <span class="dv">15</span><span class="er">mm</span>,</span>
<span id="cb82-789"><a href="#cb82-789"></a>        draw<span class="op">=</span>blue</span>
<span id="cb82-790"><a href="#cb82-790"></a>        ] (Input) at (<span class="dv">0</span>,<span class="dv">0</span>) {}<span class="op">;</span></span>
<span id="cb82-791"><a href="#cb82-791"></a>    </span>
<span id="cb82-792"><a href="#cb82-792"></a>    \node[] (w) at (<span class="op">-</span><span class="dv">3</span>,<span class="dv">0</span>) {}<span class="op">;</span></span>
<span id="cb82-793"><a href="#cb82-793"></a>    \node[] (b) at (<span class="dv">0</span>,<span class="op">-</span><span class="dv">2</span>) {}<span class="op">;</span></span>
<span id="cb82-794"><a href="#cb82-794"></a></span>
<span id="cb82-795"><a href="#cb82-795"></a>    \draw[<span class="op">-&gt;</span>, shorten <span class="op">&gt;=</span><span class="dv">1</span><span class="er">pt</span>] (w) <span class="op">--</span> (Input) node [midway,above] {\large $<span class="op">-</span><span class="fl">1.00</span>$}<span class="op">;</span></span>
<span id="cb82-796"><a href="#cb82-796"></a>    \draw[<span class="op">-&gt;</span>, shorten <span class="op">&gt;=</span><span class="dv">1</span><span class="er">pt</span>] (b) node [below] {\large $<span class="fl">0.50</span>$} <span class="op">--</span> (Input)<span class="op">;</span></span>
<span id="cb82-797"><a href="#cb82-797"></a>\end{tikzpicture}</span>
<span id="cb82-798"><a href="#cb82-798"></a><span class="in">```</span></span>
<span id="cb82-799"><a href="#cb82-799"></a></span>
<span id="cb82-800"><a href="#cb82-800"></a>With a negative weight and this single neuron, the function has become a question of when this neuron *deactivates*. </span>
<span id="cb82-803"><a href="#cb82-803"></a><span class="in">```{python}</span></span>
<span id="cb82-804"><a href="#cb82-804"></a><span class="co"># | code-fold: true</span></span>
<span id="cb82-805"><a href="#cb82-805"></a><span class="co"># | code-summary: "Show the code"</span></span>
<span id="cb82-806"><a href="#cb82-806"></a><span class="op">%%</span>itikz <span class="op">--</span>temp<span class="op">-</span><span class="bu">dir</span> <span class="op">--</span>tex<span class="op">-</span>packages<span class="op">=</span>tikz,pgfplots <span class="op">--</span>tikz<span class="op">-</span>libraries<span class="op">=</span>arrows <span class="op">--</span>implicit<span class="op">-</span>standalone</span>
<span id="cb82-807"><a href="#cb82-807"></a>\begin{tikzpicture}[scale<span class="op">=</span><span class="fl">1.5</span>]</span>
<span id="cb82-808"><a href="#cb82-808"></a>\begin{axis}[grid,ymin<span class="op">=-</span><span class="fl">2.0</span>,ymax<span class="op">=</span><span class="fl">2.0</span>,xmin<span class="op">=-</span><span class="fl">2.0</span>,xmax<span class="op">=</span><span class="fl">2.0</span>]</span>
<span id="cb82-809"><a href="#cb82-809"></a>\addplot[color<span class="op">=</span>blue,thick,samples<span class="op">=</span><span class="dv">100</span>]{<span class="bu">max</span>(<span class="op">-</span>x<span class="op">+</span><span class="fl">0.50</span>,<span class="dv">0</span>)}<span class="op">;</span></span>
<span id="cb82-810"><a href="#cb82-810"></a>\end{axis}</span>
<span id="cb82-811"><a href="#cb82-811"></a>\end{tikzpicture}</span>
<span id="cb82-812"><a href="#cb82-812"></a><span class="in">```</span></span>
<span id="cb82-813"><a href="#cb82-813"></a></span>
<span id="cb82-814"><a href="#cb82-814"></a>What happens if modify the weight to $-2.00$? </span>
<span id="cb82-815"><a href="#cb82-815"></a></span>
<span id="cb82-818"><a href="#cb82-818"></a><span class="in">```{python}</span></span>
<span id="cb82-819"><a href="#cb82-819"></a><span class="co"># | code-fold: true</span></span>
<span id="cb82-820"><a href="#cb82-820"></a><span class="co"># | code-summary: "Show the code"</span></span>
<span id="cb82-821"><a href="#cb82-821"></a><span class="op">%%</span>itikz <span class="op">--</span>temp<span class="op">-</span><span class="bu">dir</span> <span class="op">--</span>tex<span class="op">-</span>packages<span class="op">=</span>tikz <span class="op">--</span>tikz<span class="op">-</span>libraries<span class="op">=</span>arrows <span class="op">--</span>implicit<span class="op">-</span>standalone</span>
<span id="cb82-822"><a href="#cb82-822"></a>\begin{tikzpicture}[scale<span class="op">=</span><span class="fl">1.5</span>]</span>
<span id="cb82-823"><a href="#cb82-823"></a>    \node[circle, </span>
<span id="cb82-824"><a href="#cb82-824"></a>        minimum size <span class="op">=</span> <span class="dv">15</span><span class="er">mm</span>,</span>
<span id="cb82-825"><a href="#cb82-825"></a>        draw<span class="op">=</span>blue</span>
<span id="cb82-826"><a href="#cb82-826"></a>        ] (Input) at (<span class="dv">0</span>,<span class="dv">0</span>) {}<span class="op">;</span></span>
<span id="cb82-827"><a href="#cb82-827"></a>    </span>
<span id="cb82-828"><a href="#cb82-828"></a>    \node[] (w) at (<span class="op">-</span><span class="dv">3</span>,<span class="dv">0</span>) {}<span class="op">;</span></span>
<span id="cb82-829"><a href="#cb82-829"></a>    \node[] (b) at (<span class="dv">0</span>,<span class="op">-</span><span class="dv">2</span>) {}<span class="op">;</span></span>
<span id="cb82-830"><a href="#cb82-830"></a></span>
<span id="cb82-831"><a href="#cb82-831"></a>    \draw[<span class="op">-&gt;</span>, shorten <span class="op">&gt;=</span><span class="dv">1</span><span class="er">pt</span>] (w) <span class="op">--</span> (Input) node [midway,above] {\large $<span class="op">-</span><span class="fl">2.00</span>$}<span class="op">;</span></span>
<span id="cb82-832"><a href="#cb82-832"></a>    \draw[<span class="op">-&gt;</span>, shorten <span class="op">&gt;=</span><span class="dv">1</span><span class="er">pt</span>] (b) node [below] {\large $<span class="fl">0.50</span>$} <span class="op">--</span> (Input)<span class="op">;</span></span>
<span id="cb82-833"><a href="#cb82-833"></a>\end{tikzpicture}</span>
<span id="cb82-834"><a href="#cb82-834"></a><span class="in">```</span></span>
<span id="cb82-835"><a href="#cb82-835"></a></span>
<span id="cb82-836"><a href="#cb82-836"></a>The neuron now deactivates at $0.25$. </span>
<span id="cb82-837"><a href="#cb82-837"></a></span>
<span id="cb82-840"><a href="#cb82-840"></a><span class="in">```{python}</span></span>
<span id="cb82-841"><a href="#cb82-841"></a><span class="co"># | code-fold: true</span></span>
<span id="cb82-842"><a href="#cb82-842"></a><span class="co"># | code-summary: "Show the code"</span></span>
<span id="cb82-843"><a href="#cb82-843"></a><span class="op">%%</span>itikz <span class="op">--</span>temp<span class="op">-</span><span class="bu">dir</span> <span class="op">--</span>tex<span class="op">-</span>packages<span class="op">=</span>tikz,pgfplots <span class="op">--</span>tikz<span class="op">-</span>libraries<span class="op">=</span>arrows <span class="op">--</span>implicit<span class="op">-</span>standalone</span>
<span id="cb82-844"><a href="#cb82-844"></a>\begin{tikzpicture}[scale<span class="op">=</span><span class="fl">1.5</span>]</span>
<span id="cb82-845"><a href="#cb82-845"></a>\begin{axis}[grid,ymin<span class="op">=-</span><span class="fl">2.0</span>,ymax<span class="op">=</span><span class="fl">2.0</span>,xmin<span class="op">=-</span><span class="fl">2.0</span>,xmax<span class="op">=</span><span class="fl">2.0</span>]</span>
<span id="cb82-846"><a href="#cb82-846"></a>\addplot[color<span class="op">=</span>blue,thick,samples<span class="op">=</span><span class="dv">100</span>]{<span class="bu">max</span>(<span class="op">-</span><span class="dv">2</span><span class="op">*</span>x<span class="op">+</span><span class="fl">0.50</span>,<span class="dv">0</span>)}<span class="op">;</span></span>
<span id="cb82-847"><a href="#cb82-847"></a>\end{axis}</span>
<span id="cb82-848"><a href="#cb82-848"></a>\end{tikzpicture}</span>
<span id="cb82-849"><a href="#cb82-849"></a><span class="in">```</span></span>
<span id="cb82-850"><a href="#cb82-850"></a></span>
<span id="cb82-851"><a href="#cb82-851"></a>Upto this point, we've seen how we can use the bias to offset the function horizontally, and the weight to influence the slope of the activation. Moreover, we're also able to control whether the function is one for determining where the neuron activates or deactivates. What happens when we have, rather than just one neuron, a pair of neurons? For example, let's pretend that we have two hidden layers of $1$ neuron each. Thinking back to the $y=x$ activation function, we unsurprisingly discovered that a linear activation function produced linear results no matter what chain of neurons we made. Let's see what happens with the rectified linear function for the activation. </span>
<span id="cb82-852"><a href="#cb82-852"></a></span>
<span id="cb82-853"><a href="#cb82-853"></a>We'll begin with the last values for the first neuron and a weight of $1.00$ and a bias of $0.00$ for the second neuron.</span>
<span id="cb82-854"><a href="#cb82-854"></a></span>
<span id="cb82-857"><a href="#cb82-857"></a><span class="in">```{python}</span></span>
<span id="cb82-858"><a href="#cb82-858"></a><span class="co"># | code-fold: true</span></span>
<span id="cb82-859"><a href="#cb82-859"></a><span class="co"># | code-summary: "Show the code"</span></span>
<span id="cb82-860"><a href="#cb82-860"></a><span class="op">%%</span>itikz <span class="op">--</span>temp<span class="op">-</span><span class="bu">dir</span> <span class="op">--</span>tex<span class="op">-</span>packages<span class="op">=</span>tikz <span class="op">--</span>tikz<span class="op">-</span>libraries<span class="op">=</span>arrows <span class="op">--</span>implicit<span class="op">-</span>standalone</span>
<span id="cb82-861"><a href="#cb82-861"></a>\begin{tikzpicture}[scale<span class="op">=</span><span class="fl">1.5</span>]</span>
<span id="cb82-862"><a href="#cb82-862"></a>    \node[circle, </span>
<span id="cb82-863"><a href="#cb82-863"></a>        minimum size <span class="op">=</span> <span class="dv">15</span><span class="er">mm</span>,</span>
<span id="cb82-864"><a href="#cb82-864"></a>        draw<span class="op">=</span>blue</span>
<span id="cb82-865"><a href="#cb82-865"></a>        ] (Input) at (<span class="dv">0</span>,<span class="dv">0</span>) {}<span class="op">;</span></span>
<span id="cb82-866"><a href="#cb82-866"></a></span>
<span id="cb82-867"><a href="#cb82-867"></a>    \node[circle, </span>
<span id="cb82-868"><a href="#cb82-868"></a>        minimum size <span class="op">=</span> <span class="dv">15</span><span class="er">mm</span>,</span>
<span id="cb82-869"><a href="#cb82-869"></a>        draw<span class="op">=</span>blue</span>
<span id="cb82-870"><a href="#cb82-870"></a>        ] (Hidden1) at (<span class="dv">3</span>,<span class="dv">0</span>) {}<span class="op">;</span></span>
<span id="cb82-871"><a href="#cb82-871"></a>    </span>
<span id="cb82-872"><a href="#cb82-872"></a>    \node[] (w1) at (<span class="op">-</span><span class="dv">3</span>,<span class="dv">0</span>) {}<span class="op">;</span></span>
<span id="cb82-873"><a href="#cb82-873"></a>    \node[] (b1) at (<span class="dv">0</span>,<span class="op">-</span><span class="dv">2</span>) {}<span class="op">;</span></span>
<span id="cb82-874"><a href="#cb82-874"></a>    \node[] (b2) at (<span class="dv">3</span>,<span class="op">-</span><span class="dv">2</span>) {}<span class="op">;</span></span>
<span id="cb82-875"><a href="#cb82-875"></a></span>
<span id="cb82-876"><a href="#cb82-876"></a>    \draw[<span class="op">-&gt;</span>, shorten <span class="op">&gt;=</span><span class="dv">1</span><span class="er">pt</span>] (w1) <span class="op">--</span> (Input) node [midway,above] {\large $<span class="op">-</span><span class="fl">1.00</span>$}<span class="op">;</span></span>
<span id="cb82-877"><a href="#cb82-877"></a>    \draw[<span class="op">-&gt;</span>, shorten <span class="op">&gt;=</span><span class="dv">1</span><span class="er">pt</span>] (b1) node [below] {\large $<span class="fl">0.50</span>$} <span class="op">--</span> (Input)<span class="op">;</span></span>
<span id="cb82-878"><a href="#cb82-878"></a>    \draw[<span class="op">-&gt;</span>, shorten <span class="op">&gt;=</span><span class="dv">1</span><span class="er">pt</span>] (Input) <span class="op">--</span> (Hidden1) node [midway,above] {\large $<span class="fl">1.00</span>$}<span class="op">;</span></span>
<span id="cb82-879"><a href="#cb82-879"></a>    \draw[<span class="op">-&gt;</span>, shorten <span class="op">&gt;=</span><span class="dv">1</span><span class="er">pt</span>] (b2) node [below] {\large $<span class="fl">0.00</span>$} <span class="op">--</span> (Hidden1)<span class="op">;</span></span>
<span id="cb82-880"><a href="#cb82-880"></a>\end{tikzpicture}</span>
<span id="cb82-881"><a href="#cb82-881"></a><span class="in">```</span></span>
<span id="cb82-882"><a href="#cb82-882"></a></span>
<span id="cb82-883"><a href="#cb82-883"></a>As we can see so far, there's no change. This is because the second neuron's bias is doing no offsetting, and the second neuron's weight is just multiplying the output by $1$, so there's no change. Let's try to adjust the second neuron's bias now:</span>
<span id="cb82-884"><a href="#cb82-884"></a></span>
<span id="cb82-887"><a href="#cb82-887"></a><span class="in">```{python}</span></span>
<span id="cb82-888"><a href="#cb82-888"></a><span class="co"># | code-fold: true</span></span>
<span id="cb82-889"><a href="#cb82-889"></a><span class="co"># | code-summary: "Show the code"</span></span>
<span id="cb82-890"><a href="#cb82-890"></a><span class="op">%%</span>itikz <span class="op">--</span>temp<span class="op">-</span><span class="bu">dir</span> <span class="op">--</span>tex<span class="op">-</span>packages<span class="op">=</span>tikz,pgfplots <span class="op">--</span>tikz<span class="op">-</span>libraries<span class="op">=</span>arrows <span class="op">--</span>implicit<span class="op">-</span>standalone</span>
<span id="cb82-891"><a href="#cb82-891"></a>\begin{tikzpicture}[scale<span class="op">=</span><span class="fl">1.5</span>]</span>
<span id="cb82-892"><a href="#cb82-892"></a>\begin{axis}[grid,ymin<span class="op">=-</span><span class="dv">1</span>,ymax<span class="op">=</span><span class="dv">6</span>,ytick<span class="op">=</span>{<span class="op">-</span><span class="dv">1</span>,<span class="dv">0</span>,...,<span class="dv">6</span>}]</span>
<span id="cb82-893"><a href="#cb82-893"></a>\addplot[color<span class="op">=</span>blue,thick,samples<span class="op">=</span><span class="dv">100</span>]{<span class="bu">max</span>(<span class="bu">max</span>(<span class="op">-</span>x<span class="op">+</span><span class="fl">0.50</span>,<span class="dv">0</span>),<span class="dv">0</span>)}<span class="op">;</span></span>
<span id="cb82-894"><a href="#cb82-894"></a>\end{axis}</span>
<span id="cb82-895"><a href="#cb82-895"></a>\end{tikzpicture}</span>
<span id="cb82-896"><a href="#cb82-896"></a><span class="in">```</span></span>
<span id="cb82-897"><a href="#cb82-897"></a></span>
<span id="cb82-898"><a href="#cb82-898"></a>Let's try to adjust the second neuron's bias now:</span>
<span id="cb82-899"><a href="#cb82-899"></a></span>
<span id="cb82-902"><a href="#cb82-902"></a><span class="in">```{python}</span></span>
<span id="cb82-903"><a href="#cb82-903"></a><span class="co"># | code-fold: true</span></span>
<span id="cb82-904"><a href="#cb82-904"></a><span class="co"># | code-summary: "Show the code"</span></span>
<span id="cb82-905"><a href="#cb82-905"></a><span class="op">%%</span>itikz <span class="op">--</span>temp<span class="op">-</span><span class="bu">dir</span> <span class="op">--</span>tex<span class="op">-</span>packages<span class="op">=</span>tikz <span class="op">--</span>tikz<span class="op">-</span>libraries<span class="op">=</span>arrows <span class="op">--</span>implicit<span class="op">-</span>standalone</span>
<span id="cb82-906"><a href="#cb82-906"></a>\begin{tikzpicture}[scale<span class="op">=</span><span class="fl">1.5</span>]</span>
<span id="cb82-907"><a href="#cb82-907"></a>    \node[circle, </span>
<span id="cb82-908"><a href="#cb82-908"></a>        minimum size <span class="op">=</span> <span class="dv">15</span><span class="er">mm</span>,</span>
<span id="cb82-909"><a href="#cb82-909"></a>        draw<span class="op">=</span>blue</span>
<span id="cb82-910"><a href="#cb82-910"></a>        ] (Input) at (<span class="dv">0</span>,<span class="dv">0</span>) {}<span class="op">;</span></span>
<span id="cb82-911"><a href="#cb82-911"></a></span>
<span id="cb82-912"><a href="#cb82-912"></a>    \node[circle, </span>
<span id="cb82-913"><a href="#cb82-913"></a>        minimum size <span class="op">=</span> <span class="dv">15</span><span class="er">mm</span>,</span>
<span id="cb82-914"><a href="#cb82-914"></a>        draw<span class="op">=</span>blue</span>
<span id="cb82-915"><a href="#cb82-915"></a>        ] (Hidden1) at (<span class="dv">3</span>,<span class="dv">0</span>) {}<span class="op">;</span></span>
<span id="cb82-916"><a href="#cb82-916"></a>    </span>
<span id="cb82-917"><a href="#cb82-917"></a>    \node[] (w1) at (<span class="op">-</span><span class="dv">3</span>,<span class="dv">0</span>) {}<span class="op">;</span></span>
<span id="cb82-918"><a href="#cb82-918"></a>    \node[] (b1) at (<span class="dv">0</span>,<span class="op">-</span><span class="dv">2</span>) {}<span class="op">;</span></span>
<span id="cb82-919"><a href="#cb82-919"></a>    \node[] (b2) at (<span class="dv">3</span>,<span class="op">-</span><span class="dv">2</span>) {}<span class="op">;</span></span>
<span id="cb82-920"><a href="#cb82-920"></a></span>
<span id="cb82-921"><a href="#cb82-921"></a>    \draw[<span class="op">-&gt;</span>, shorten <span class="op">&gt;=</span><span class="dv">1</span><span class="er">pt</span>] (w1) <span class="op">--</span> (Input) node [midway,above] {\large $<span class="op">-</span><span class="fl">1.00</span>$}<span class="op">;</span></span>
<span id="cb82-922"><a href="#cb82-922"></a>    \draw[<span class="op">-&gt;</span>, shorten <span class="op">&gt;=</span><span class="dv">1</span><span class="er">pt</span>] (b1) node [below] {\large $<span class="fl">0.50</span>$} <span class="op">--</span> (Input)<span class="op">;</span></span>
<span id="cb82-923"><a href="#cb82-923"></a>    \draw[<span class="op">-&gt;</span>, shorten <span class="op">&gt;=</span><span class="dv">1</span><span class="er">pt</span>] (Input) <span class="op">--</span> (Hidden1) node [midway,above] {\large $<span class="fl">1.00</span>$}<span class="op">;</span></span>
<span id="cb82-924"><a href="#cb82-924"></a>    \draw[<span class="op">-&gt;</span>, shorten <span class="op">&gt;=</span><span class="dv">1</span><span class="er">pt</span>] (b2) node [below] {\large $<span class="fl">1.00</span>$} <span class="op">--</span> (Hidden1)<span class="op">;</span></span>
<span id="cb82-925"><a href="#cb82-925"></a>\end{tikzpicture}</span>
<span id="cb82-926"><a href="#cb82-926"></a><span class="in">```</span></span>
<span id="cb82-927"><a href="#cb82-927"></a></span>
<span id="cb82-928"><a href="#cb82-928"></a>Now, we see some fairly interesting behavior. The bias of the second neuron indeed shifted the overall function but, rather than shifting it horizontally, it shifted vertically.</span>
<span id="cb82-929"><a href="#cb82-929"></a></span>
<span id="cb82-932"><a href="#cb82-932"></a><span class="in">```{python}</span></span>
<span id="cb82-933"><a href="#cb82-933"></a><span class="co"># | code-fold: true</span></span>
<span id="cb82-934"><a href="#cb82-934"></a><span class="co"># | code-summary: "Show the code"</span></span>
<span id="cb82-935"><a href="#cb82-935"></a><span class="op">%%</span>itikz <span class="op">--</span>temp<span class="op">-</span><span class="bu">dir</span> <span class="op">--</span>tex<span class="op">-</span>packages<span class="op">=</span>tikz,pgfplots <span class="op">--</span>tikz<span class="op">-</span>libraries<span class="op">=</span>arrows <span class="op">--</span>implicit<span class="op">-</span>standalone</span>
<span id="cb82-936"><a href="#cb82-936"></a>\begin{tikzpicture}[scale<span class="op">=</span><span class="fl">1.5</span>]</span>
<span id="cb82-937"><a href="#cb82-937"></a>\begin{axis}[grid,ymin<span class="op">=-</span><span class="dv">1</span>,ymax<span class="op">=</span><span class="dv">6</span>,ytick<span class="op">=</span>{<span class="op">-</span><span class="dv">1</span>,<span class="dv">0</span>,...,<span class="dv">6</span>}]</span>
<span id="cb82-938"><a href="#cb82-938"></a>\addplot[color<span class="op">=</span>blue,thick,samples<span class="op">=</span><span class="dv">100</span>]{<span class="bu">max</span>(<span class="bu">max</span>(<span class="op">-</span>x<span class="op">+</span><span class="fl">0.50</span>,<span class="dv">0</span>)<span class="op">+</span><span class="fl">1.00</span>,<span class="dv">0</span>)}<span class="op">;</span></span>
<span id="cb82-939"><a href="#cb82-939"></a>\end{axis}</span>
<span id="cb82-940"><a href="#cb82-940"></a>\end{tikzpicture}</span>
<span id="cb82-941"><a href="#cb82-941"></a><span class="in">```</span></span>
<span id="cb82-942"><a href="#cb82-942"></a></span>
<span id="cb82-943"><a href="#cb82-943"></a>What then might happen, if we make the $2$nd neuron's weight $-2$ rather than $1$?</span>
<span id="cb82-944"><a href="#cb82-944"></a></span>
<span id="cb82-947"><a href="#cb82-947"></a><span class="in">```{python}</span></span>
<span id="cb82-948"><a href="#cb82-948"></a><span class="co"># | code-fold: true</span></span>
<span id="cb82-949"><a href="#cb82-949"></a><span class="co"># | code-summary: "Show the code"</span></span>
<span id="cb82-950"><a href="#cb82-950"></a><span class="op">%%</span>itikz <span class="op">--</span>temp<span class="op">-</span><span class="bu">dir</span> <span class="op">--</span>tex<span class="op">-</span>packages<span class="op">=</span>tikz <span class="op">--</span>tikz<span class="op">-</span>libraries<span class="op">=</span>arrows <span class="op">--</span>implicit<span class="op">-</span>standalone</span>
<span id="cb82-951"><a href="#cb82-951"></a>\begin{tikzpicture}[scale<span class="op">=</span><span class="fl">1.5</span>]</span>
<span id="cb82-952"><a href="#cb82-952"></a>    \node[circle, </span>
<span id="cb82-953"><a href="#cb82-953"></a>        minimum size <span class="op">=</span> <span class="dv">15</span><span class="er">mm</span>,</span>
<span id="cb82-954"><a href="#cb82-954"></a>        draw<span class="op">=</span>blue</span>
<span id="cb82-955"><a href="#cb82-955"></a>        ] (Input) at (<span class="dv">0</span>,<span class="dv">0</span>) {}<span class="op">;</span></span>
<span id="cb82-956"><a href="#cb82-956"></a></span>
<span id="cb82-957"><a href="#cb82-957"></a>    \node[circle, </span>
<span id="cb82-958"><a href="#cb82-958"></a>        minimum size <span class="op">=</span> <span class="dv">15</span><span class="er">mm</span>,</span>
<span id="cb82-959"><a href="#cb82-959"></a>        draw<span class="op">=</span>blue</span>
<span id="cb82-960"><a href="#cb82-960"></a>        ] (Hidden1) at (<span class="dv">3</span>,<span class="dv">0</span>) {}<span class="op">;</span></span>
<span id="cb82-961"><a href="#cb82-961"></a>    </span>
<span id="cb82-962"><a href="#cb82-962"></a>    \node[] (w1) at (<span class="op">-</span><span class="dv">3</span>,<span class="dv">0</span>) {}<span class="op">;</span></span>
<span id="cb82-963"><a href="#cb82-963"></a>    \node[] (b1) at (<span class="dv">0</span>,<span class="op">-</span><span class="dv">2</span>) {}<span class="op">;</span></span>
<span id="cb82-964"><a href="#cb82-964"></a>    \node[] (b2) at (<span class="dv">3</span>,<span class="op">-</span><span class="dv">2</span>) {}<span class="op">;</span></span>
<span id="cb82-965"><a href="#cb82-965"></a></span>
<span id="cb82-966"><a href="#cb82-966"></a>    \draw[<span class="op">-&gt;</span>, shorten <span class="op">&gt;=</span><span class="dv">1</span><span class="er">pt</span>] (w1) <span class="op">--</span> (Input) node [midway,above] {\large $<span class="op">-</span><span class="fl">1.00</span>$}<span class="op">;</span></span>
<span id="cb82-967"><a href="#cb82-967"></a>    \draw[<span class="op">-&gt;</span>, shorten <span class="op">&gt;=</span><span class="dv">1</span><span class="er">pt</span>] (b1) node [below] {\large $<span class="fl">0.50</span>$} <span class="op">--</span> (Input)<span class="op">;</span></span>
<span id="cb82-968"><a href="#cb82-968"></a>    \draw[<span class="op">-&gt;</span>, shorten <span class="op">&gt;=</span><span class="dv">1</span><span class="er">pt</span>] (Input) <span class="op">--</span> (Hidden1) node [midway,above] {\large $<span class="op">-</span><span class="fl">2.00</span>$}<span class="op">;</span></span>
<span id="cb82-969"><a href="#cb82-969"></a>    \draw[<span class="op">-&gt;</span>, shorten <span class="op">&gt;=</span><span class="dv">1</span><span class="er">pt</span>] (b2) node [below] {\large $<span class="fl">1.00</span>$} <span class="op">--</span> (Hidden1)<span class="op">;</span></span>
<span id="cb82-970"><a href="#cb82-970"></a>\end{tikzpicture}</span>
<span id="cb82-971"><a href="#cb82-971"></a><span class="in">```</span></span>
<span id="cb82-972"><a href="#cb82-972"></a></span>
<span id="cb82-973"><a href="#cb82-973"></a>Something exciting has occurred! What we have here is a neuron that has both an activation and a deactivation point. Now, the output after these two neurons will be variable, so long as it is inside of some specific range. So, basically if both neurons are activated then we actually sort of see this influence on the value. Otherwise, if both neurons aren't activated, then the output is just a static value. </span>
<span id="cb82-974"><a href="#cb82-974"></a></span>
<span id="cb82-977"><a href="#cb82-977"></a><span class="in">```{python}</span></span>
<span id="cb82-978"><a href="#cb82-978"></a><span class="co"># | code-fold: true</span></span>
<span id="cb82-979"><a href="#cb82-979"></a><span class="co"># | code-summary: "Show the code"</span></span>
<span id="cb82-980"><a href="#cb82-980"></a><span class="op">%%</span>itikz <span class="op">--</span>temp<span class="op">-</span><span class="bu">dir</span> <span class="op">--</span>tex<span class="op">-</span>packages<span class="op">=</span>tikz,pgfplots <span class="op">--</span>tikz<span class="op">-</span>libraries<span class="op">=</span>arrows <span class="op">--</span>implicit<span class="op">-</span>standalone</span>
<span id="cb82-981"><a href="#cb82-981"></a>\begin{tikzpicture}[scale<span class="op">=</span><span class="fl">1.5</span>]</span>
<span id="cb82-982"><a href="#cb82-982"></a>\begin{axis}[grid,ymin<span class="op">=-</span><span class="dv">1</span>,ymax<span class="op">=</span><span class="dv">2</span>,ytick<span class="op">=</span>{<span class="op">-</span><span class="dv">1</span>,<span class="dv">0</span>,...,<span class="dv">2</span>},xmin<span class="op">=-</span><span class="dv">2</span>,xmax<span class="op">=</span><span class="dv">2</span>]</span>
<span id="cb82-983"><a href="#cb82-983"></a>\addplot[color<span class="op">=</span>blue,thick,samples<span class="op">=</span><span class="dv">500</span>]{<span class="bu">max</span>(<span class="op">-</span><span class="fl">2.0</span><span class="op">*</span><span class="bu">max</span>(<span class="op">-</span>x<span class="op">+</span><span class="fl">0.50</span>,<span class="dv">0</span>)<span class="op">+</span><span class="fl">1.00</span>,<span class="dv">0</span>)}<span class="op">;</span></span>
<span id="cb82-984"><a href="#cb82-984"></a>\end{axis}</span>
<span id="cb82-985"><a href="#cb82-985"></a>\end{tikzpicture}</span>
<span id="cb82-986"><a href="#cb82-986"></a><span class="in">```</span></span>
<span id="cb82-987"><a href="#cb82-987"></a></span>
<span id="cb82-988"><a href="#cb82-988"></a>So, when we are below the activation of the first neuron, the output will be the bias of the second neuron $1.00$. </span>
<span id="cb82-989"><a href="#cb82-989"></a></span>
<span id="cb82-992"><a href="#cb82-992"></a><span class="in">```{python}</span></span>
<span id="cb82-993"><a href="#cb82-993"></a><span class="co"># | code-fold: true</span></span>
<span id="cb82-994"><a href="#cb82-994"></a><span class="co"># | code-summary: "Show the code"</span></span>
<span id="cb82-995"><a href="#cb82-995"></a><span class="op">%%</span>itikz <span class="op">--</span>temp<span class="op">-</span><span class="bu">dir</span> <span class="op">--</span>tex<span class="op">-</span>packages<span class="op">=</span>tikz <span class="op">--</span>tikz<span class="op">-</span>libraries<span class="op">=</span>arrows <span class="op">--</span>implicit<span class="op">-</span>standalone</span>
<span id="cb82-996"><a href="#cb82-996"></a>\begin{tikzpicture}[scale<span class="op">=</span><span class="fl">1.5</span>]</span>
<span id="cb82-997"><a href="#cb82-997"></a>    \node[circle, </span>
<span id="cb82-998"><a href="#cb82-998"></a>        minimum size <span class="op">=</span> <span class="dv">15</span><span class="er">mm</span>,</span>
<span id="cb82-999"><a href="#cb82-999"></a>        draw<span class="op">=</span>blue</span>
<span id="cb82-1000"><a href="#cb82-1000"></a>        ] (Input) at (<span class="dv">0</span>,<span class="dv">0</span>) {}<span class="op">;</span></span>
<span id="cb82-1001"><a href="#cb82-1001"></a></span>
<span id="cb82-1002"><a href="#cb82-1002"></a>    \node[circle, </span>
<span id="cb82-1003"><a href="#cb82-1003"></a>        minimum size <span class="op">=</span> <span class="dv">15</span><span class="er">mm</span>,</span>
<span id="cb82-1004"><a href="#cb82-1004"></a>        draw<span class="op">=</span>blue,</span>
<span id="cb82-1005"><a href="#cb82-1005"></a>        fill<span class="op">=</span>green</span>
<span id="cb82-1006"><a href="#cb82-1006"></a>        ] (Hidden1) at (<span class="dv">3</span>,<span class="dv">0</span>) {}<span class="op">;</span></span>
<span id="cb82-1007"><a href="#cb82-1007"></a>    </span>
<span id="cb82-1008"><a href="#cb82-1008"></a>    \node[] (w1) at (<span class="op">-</span><span class="dv">3</span>,<span class="dv">0</span>) {}<span class="op">;</span></span>
<span id="cb82-1009"><a href="#cb82-1009"></a>    \node[] (b1) at (<span class="dv">0</span>,<span class="op">-</span><span class="dv">2</span>) {}<span class="op">;</span></span>
<span id="cb82-1010"><a href="#cb82-1010"></a>    \node[] (b2) at (<span class="dv">3</span>,<span class="op">-</span><span class="dv">2</span>) {}<span class="op">;</span></span>
<span id="cb82-1011"><a href="#cb82-1011"></a></span>
<span id="cb82-1012"><a href="#cb82-1012"></a>    \draw[<span class="op">-&gt;</span>, shorten <span class="op">&gt;=</span><span class="dv">1</span><span class="er">pt</span>] (w1) node [left] {\large $<span class="fl">0.50</span>$} <span class="op">--</span> (Input) node [midway,above] {\large $<span class="op">-</span><span class="fl">1.00</span>$}<span class="op">;</span></span>
<span id="cb82-1013"><a href="#cb82-1013"></a>    \draw[<span class="op">-&gt;</span>, shorten <span class="op">&gt;=</span><span class="dv">1</span><span class="er">pt</span>] (b1) node [below] {\large $<span class="fl">0.50</span>$} <span class="op">--</span> (Input)<span class="op">;</span></span>
<span id="cb82-1014"><a href="#cb82-1014"></a>    \draw[<span class="op">-&gt;</span>, shorten <span class="op">&gt;=</span><span class="dv">1</span><span class="er">pt</span>] (Input) <span class="op">--</span> (Hidden1) node [midway,above] {\large $<span class="op">-</span><span class="fl">2.00</span>$}<span class="op">;</span></span>
<span id="cb82-1015"><a href="#cb82-1015"></a>    \draw[<span class="op">-&gt;</span>, shorten <span class="op">&gt;=</span><span class="dv">1</span><span class="er">pt</span>] (b2) node [below] {\large $<span class="fl">1.00</span>$} <span class="op">--</span> (Hidden1)<span class="op">;</span></span>
<span id="cb82-1016"><a href="#cb82-1016"></a>    \draw[<span class="op">-&gt;</span>, shorten <span class="op">&gt;=</span><span class="dv">1</span><span class="er">pt</span>] (Hidden1) <span class="op">--</span> (<span class="dv">6</span>,<span class="dv">0</span>) node [right] {$<span class="fl">1.00</span>$}<span class="op">;</span></span>
<span id="cb82-1017"><a href="#cb82-1017"></a>\end{tikzpicture}</span>
<span id="cb82-1018"><a href="#cb82-1018"></a><span class="in">```</span></span>
<span id="cb82-1019"><a href="#cb82-1019"></a></span>
<span id="cb82-1020"><a href="#cb82-1020"></a>The second neuron is activated if it's input is smaller than $0.50$. </span>
<span id="cb82-1021"><a href="#cb82-1021"></a></span>
<span id="cb82-1022"><a href="#cb82-1022"></a>Consider what happens when the input to the first neuron is $0.00, -0.10, \ldots$. The output of the first neuron is $0.50, 0.60, \ldots$ which implies that the second neuron is deactivated, so the output of the second neuron is simply zero. </span>
<span id="cb82-1023"><a href="#cb82-1023"></a></span>
<span id="cb82-1026"><a href="#cb82-1026"></a><span class="in">```{python}</span></span>
<span id="cb82-1027"><a href="#cb82-1027"></a><span class="co"># | code-fold: true</span></span>
<span id="cb82-1028"><a href="#cb82-1028"></a><span class="co"># | code-summary: "Show the code"</span></span>
<span id="cb82-1029"><a href="#cb82-1029"></a><span class="op">%%</span>itikz <span class="op">--</span>temp<span class="op">-</span><span class="bu">dir</span> <span class="op">--</span>tex<span class="op">-</span>packages<span class="op">=</span>tikz <span class="op">--</span>tikz<span class="op">-</span>libraries<span class="op">=</span>arrows <span class="op">--</span>implicit<span class="op">-</span>standalone</span>
<span id="cb82-1030"><a href="#cb82-1030"></a>\begin{tikzpicture}[scale<span class="op">=</span><span class="fl">1.5</span>]</span>
<span id="cb82-1031"><a href="#cb82-1031"></a>    \node[circle, </span>
<span id="cb82-1032"><a href="#cb82-1032"></a>        minimum size <span class="op">=</span> <span class="dv">15</span><span class="er">mm</span>,</span>
<span id="cb82-1033"><a href="#cb82-1033"></a>        draw<span class="op">=</span>blue,</span>
<span id="cb82-1034"><a href="#cb82-1034"></a>        fill<span class="op">=</span>green</span>
<span id="cb82-1035"><a href="#cb82-1035"></a>        ] (Input) at (<span class="dv">0</span>,<span class="dv">0</span>) {}<span class="op">;</span></span>
<span id="cb82-1036"><a href="#cb82-1036"></a></span>
<span id="cb82-1037"><a href="#cb82-1037"></a>    \node[circle, </span>
<span id="cb82-1038"><a href="#cb82-1038"></a>        minimum size <span class="op">=</span> <span class="dv">15</span><span class="er">mm</span>,</span>
<span id="cb82-1039"><a href="#cb82-1039"></a>        draw<span class="op">=</span>blue</span>
<span id="cb82-1040"><a href="#cb82-1040"></a>        ] (Hidden1) at (<span class="dv">3</span>,<span class="dv">0</span>) {}<span class="op">;</span></span>
<span id="cb82-1041"><a href="#cb82-1041"></a>    </span>
<span id="cb82-1042"><a href="#cb82-1042"></a>    \node[] (w1) at (<span class="op">-</span><span class="dv">3</span>,<span class="dv">0</span>) {}<span class="op">;</span></span>
<span id="cb82-1043"><a href="#cb82-1043"></a>    \node[] (b1) at (<span class="dv">0</span>,<span class="op">-</span><span class="dv">2</span>) {}<span class="op">;</span></span>
<span id="cb82-1044"><a href="#cb82-1044"></a>    \node[] (b2) at (<span class="dv">3</span>,<span class="op">-</span><span class="dv">2</span>) {}<span class="op">;</span></span>
<span id="cb82-1045"><a href="#cb82-1045"></a></span>
<span id="cb82-1046"><a href="#cb82-1046"></a>    \draw[<span class="op">-&gt;</span>, shorten <span class="op">&gt;=</span><span class="dv">1</span><span class="er">pt</span>] (w1) node [left] {\large $<span class="fl">0.50</span>$} <span class="op">--</span> (Input) node [midway,above] {\large $<span class="op">-</span><span class="fl">1.00</span>$}<span class="op">;</span></span>
<span id="cb82-1047"><a href="#cb82-1047"></a>    \draw[<span class="op">-&gt;</span>, shorten <span class="op">&gt;=</span><span class="dv">1</span><span class="er">pt</span>] (b1) node [below] {\large $<span class="fl">0.50</span>$} <span class="op">--</span> (Input)<span class="op">;</span></span>
<span id="cb82-1048"><a href="#cb82-1048"></a>    \draw[<span class="op">-&gt;</span>, shorten <span class="op">&gt;=</span><span class="dv">1</span><span class="er">pt</span>] (Input) <span class="op">--</span> (Hidden1) node [midway,above] {\large $<span class="op">-</span><span class="fl">2.00</span>$}<span class="op">;</span></span>
<span id="cb82-1049"><a href="#cb82-1049"></a>    \draw[<span class="op">-&gt;</span>, shorten <span class="op">&gt;=</span><span class="dv">1</span><span class="er">pt</span>] (b2) node [below] {\large $<span class="fl">1.00</span>$} <span class="op">--</span> (Hidden1)<span class="op">;</span></span>
<span id="cb82-1050"><a href="#cb82-1050"></a>    \draw[<span class="op">-&gt;</span>, shorten <span class="op">&gt;=</span><span class="dv">1</span><span class="er">pt</span>] (Hidden1) <span class="op">--</span> (<span class="dv">6</span>,<span class="dv">0</span>) node [right] {$<span class="fl">0.00</span>$}<span class="op">;</span></span>
<span id="cb82-1051"><a href="#cb82-1051"></a>\end{tikzpicture}</span>
<span id="cb82-1052"><a href="#cb82-1052"></a><span class="in">```</span></span>
<span id="cb82-1053"><a href="#cb82-1053"></a></span>
<span id="cb82-1054"><a href="#cb82-1054"></a><span class="fu">## ReLU Activation in hidden layers</span></span>
<span id="cb82-1055"><a href="#cb82-1055"></a></span>
<span id="cb82-1056"><a href="#cb82-1056"></a>Let's now take this concept and use it to fit to a sine wave-like function using two hidden layers of $8$ neurons each and we can hand-tune the values to fit the curve. We'll do this by working with $1$ pair of neurons at a time, which means $1$ neuron from each layer individually. For simplicity, we are also going to assume that the layers are not densely connected, and each neuron from the first hidden layer connects to only one neuron from the second hidden layer. That's usually not the case with the real models, but we want this simplification for the purpose of this demo. Additionally, this example model takes a single value as an input, the input to the sine function, and outputs a single value like the sine function. The output layer uses the linear activation function and the hidden layers will use the rectified linear activation function.</span>
<span id="cb82-1057"><a href="#cb82-1057"></a></span>
<span id="cb82-1058"><a href="#cb82-1058"></a>To start, we'll set all weights to $0$ and work with the first pair of neurons:</span>
<span id="cb82-1059"><a href="#cb82-1059"></a></span>
<span id="cb82-1062"><a href="#cb82-1062"></a><span class="in">```{python}</span></span>
<span id="cb82-1063"><a href="#cb82-1063"></a><span class="co"># | code-fold: true</span></span>
<span id="cb82-1064"><a href="#cb82-1064"></a><span class="co"># | code-summary: "Show the code"</span></span>
<span id="cb82-1065"><a href="#cb82-1065"></a><span class="op">%%</span>itikz <span class="op">--</span>temp<span class="op">-</span><span class="bu">dir</span> <span class="op">--</span>tex<span class="op">-</span>packages<span class="op">=</span>tikz <span class="op">--</span>tikz<span class="op">-</span>libraries<span class="op">=</span>arrows <span class="op">--</span>implicit<span class="op">-</span>standalone</span>
<span id="cb82-1066"><a href="#cb82-1066"></a>\begin{tikzpicture}</span>
<span id="cb82-1067"><a href="#cb82-1067"></a></span>
<span id="cb82-1068"><a href="#cb82-1068"></a>\node[circle, </span>
<span id="cb82-1069"><a href="#cb82-1069"></a>    minimum size <span class="op">=</span> <span class="dv">15</span><span class="er">mm</span>,</span>
<span id="cb82-1070"><a href="#cb82-1070"></a>    fill<span class="op">=</span>red<span class="op">!</span><span class="dv">30</span></span>
<span id="cb82-1071"><a href="#cb82-1071"></a>    ] (Input) at (<span class="dv">0</span>,<span class="dv">0</span>) {\large $x_1$}<span class="op">;</span></span>
<span id="cb82-1072"><a href="#cb82-1072"></a></span>
<span id="cb82-1073"><a href="#cb82-1073"></a>\foreach \i <span class="kw">in</span> {<span class="dv">1</span>,<span class="dv">2</span>,...,<span class="dv">8</span>}</span>
<span id="cb82-1074"><a href="#cb82-1074"></a>{</span>
<span id="cb82-1075"><a href="#cb82-1075"></a>    \node[circle, </span>
<span id="cb82-1076"><a href="#cb82-1076"></a>        minimum size <span class="op">=</span> <span class="dv">15</span><span class="er">mm</span>,</span>
<span id="cb82-1077"><a href="#cb82-1077"></a>        fill<span class="op">=</span>blue<span class="op">!</span><span class="dv">50</span>,</span>
<span id="cb82-1078"><a href="#cb82-1078"></a>        yshift<span class="op">=</span><span class="dv">90</span> mm</span>
<span id="cb82-1079"><a href="#cb82-1079"></a>        ] (Hidden1<span class="op">-</span>\i) at (<span class="fl">3.0</span>,<span class="op">-</span>\i <span class="op">*</span> <span class="dv">2</span>) {\large $h_\i<span class="op">^</span>{(<span class="dv">1</span>)}$}<span class="op">;</span></span>
<span id="cb82-1080"><a href="#cb82-1080"></a>        </span>
<span id="cb82-1081"><a href="#cb82-1081"></a>}</span>
<span id="cb82-1082"><a href="#cb82-1082"></a>\foreach \i <span class="kw">in</span> {<span class="dv">1</span>,<span class="dv">2</span>,...,<span class="dv">8</span>}</span>
<span id="cb82-1083"><a href="#cb82-1083"></a>{</span>
<span id="cb82-1084"><a href="#cb82-1084"></a>    \node[circle, </span>
<span id="cb82-1085"><a href="#cb82-1085"></a>        minimum size <span class="op">=</span> <span class="dv">15</span><span class="er">mm</span>,</span>
<span id="cb82-1086"><a href="#cb82-1086"></a>        fill<span class="op">=</span>blue<span class="op">!</span><span class="dv">50</span>,</span>
<span id="cb82-1087"><a href="#cb82-1087"></a>        yshift<span class="op">=</span><span class="dv">90</span> mm</span>
<span id="cb82-1088"><a href="#cb82-1088"></a>        ] (Hidden2<span class="op">-</span>\i) at (<span class="fl">6.0</span>,<span class="op">-</span>\i <span class="op">*</span> <span class="dv">2</span>) {\large $h_\i<span class="op">^</span>{(<span class="dv">2</span>)}$}<span class="op">;</span></span>
<span id="cb82-1089"><a href="#cb82-1089"></a>        </span>
<span id="cb82-1090"><a href="#cb82-1090"></a>}</span>
<span id="cb82-1091"><a href="#cb82-1091"></a></span>
<span id="cb82-1092"><a href="#cb82-1092"></a>\node[circle, </span>
<span id="cb82-1093"><a href="#cb82-1093"></a>    minimum size <span class="op">=</span> <span class="dv">15</span><span class="er">mm</span>,</span>
<span id="cb82-1094"><a href="#cb82-1094"></a>    fill<span class="op">=</span>red<span class="op">!</span><span class="dv">30</span></span>
<span id="cb82-1095"><a href="#cb82-1095"></a>    ] (Output) at (<span class="dv">9</span>,<span class="dv">0</span>) {\large $\hat{y}_1$}<span class="op">;</span></span>
<span id="cb82-1096"><a href="#cb82-1096"></a></span>
<span id="cb82-1097"><a href="#cb82-1097"></a><span class="op">%</span> Connect neurons In<span class="op">-</span>Hidden1</span>
<span id="cb82-1098"><a href="#cb82-1098"></a>\foreach \j <span class="kw">in</span> {<span class="dv">2</span>,...,<span class="dv">8</span>}</span>
<span id="cb82-1099"><a href="#cb82-1099"></a>{</span>
<span id="cb82-1100"><a href="#cb82-1100"></a>    \draw[<span class="op">-&gt;</span>, shorten <span class="op">&gt;=</span><span class="dv">1</span><span class="er">pt</span>] (Input) <span class="op">--</span> (Hidden1<span class="op">-</span>\j)<span class="op">;</span>   </span>
<span id="cb82-1101"><a href="#cb82-1101"></a>}</span>
<span id="cb82-1102"><a href="#cb82-1102"></a><span class="op">%</span> Connect neurons Hidden1<span class="op">-</span>Hidden2</span>
<span id="cb82-1103"><a href="#cb82-1103"></a>\foreach \i <span class="kw">in</span> {<span class="dv">2</span>,...,<span class="dv">8</span>}</span>
<span id="cb82-1104"><a href="#cb82-1104"></a>{</span>
<span id="cb82-1105"><a href="#cb82-1105"></a>    </span>
<span id="cb82-1106"><a href="#cb82-1106"></a>        \draw[<span class="op">-&gt;</span>, shorten <span class="op">&gt;=</span><span class="dv">1</span><span class="er">pt</span>] (Hidden1<span class="op">-</span>\i) <span class="op">--</span> (Hidden2<span class="op">-</span>\i)<span class="op">;</span>   </span>
<span id="cb82-1107"><a href="#cb82-1107"></a>    </span>
<span id="cb82-1108"><a href="#cb82-1108"></a>}</span>
<span id="cb82-1109"><a href="#cb82-1109"></a></span>
<span id="cb82-1110"><a href="#cb82-1110"></a>\foreach \i <span class="kw">in</span> {<span class="dv">2</span>,...,<span class="dv">8</span>}</span>
<span id="cb82-1111"><a href="#cb82-1111"></a>{</span>
<span id="cb82-1112"><a href="#cb82-1112"></a>    </span>
<span id="cb82-1113"><a href="#cb82-1113"></a>        \draw[<span class="op">-&gt;</span>, shorten <span class="op">&gt;=</span><span class="dv">1</span><span class="er">pt</span>] (Hidden2<span class="op">-</span>\i) <span class="op">--</span> (Output)<span class="op">;</span>   </span>
<span id="cb82-1114"><a href="#cb82-1114"></a>}</span>
<span id="cb82-1115"><a href="#cb82-1115"></a>\draw[<span class="op">-&gt;</span>, shorten <span class="op">&gt;=</span><span class="dv">1</span><span class="er">pt</span>] (Input) <span class="op">--</span> node [midway] {$<span class="fl">0.00</span>$} (Hidden1<span class="op">-</span><span class="dv">1</span>)<span class="op">;</span>   </span>
<span id="cb82-1116"><a href="#cb82-1116"></a>\draw[<span class="op">-&gt;</span>, shorten <span class="op">&gt;=</span><span class="dv">1</span><span class="er">pt</span>] (Hidden1<span class="op">-</span><span class="dv">1</span>) <span class="op">--</span> node [midway] {$<span class="fl">0.00</span>$} (Hidden2<span class="op">-</span><span class="dv">1</span>)<span class="op">;</span> </span>
<span id="cb82-1117"><a href="#cb82-1117"></a>\draw[<span class="op">-&gt;</span>, shorten <span class="op">&gt;=</span><span class="dv">1</span><span class="er">pt</span>] (Hidden2<span class="op">-</span><span class="dv">1</span>) <span class="op">--</span> node [midway] {$<span class="fl">0.00</span>$} (Output)<span class="op">;</span> </span>
<span id="cb82-1118"><a href="#cb82-1118"></a>\draw[<span class="op">-&gt;</span>, shorten <span class="op">&gt;=</span><span class="dv">1</span><span class="er">pt</span>] (<span class="dv">6</span>,<span class="dv">6</span>) node [below] {$<span class="fl">0.00</span>$} <span class="op">--</span>  (Hidden2<span class="op">-</span><span class="dv">1</span>)<span class="op">;</span> </span>
<span id="cb82-1119"><a href="#cb82-1119"></a>\draw[<span class="op">-&gt;</span>, shorten <span class="op">&gt;=</span><span class="dv">1</span><span class="er">pt</span>] (<span class="dv">3</span>,<span class="dv">6</span>) node [below] {$<span class="fl">0.00</span>$} <span class="op">--</span>  (Hidden1<span class="op">-</span><span class="dv">1</span>)<span class="op">;</span> </span>
<span id="cb82-1120"><a href="#cb82-1120"></a>\end{tikzpicture}</span>
<span id="cb82-1121"><a href="#cb82-1121"></a><span class="in">```</span></span>
<span id="cb82-1122"><a href="#cb82-1122"></a></span>
<span id="cb82-1123"><a href="#cb82-1123"></a>Next, we can set the weight for the hidden layer neurons and the output neuron to $1.00$, and we can see how this impacts the output:</span>
<span id="cb82-1124"><a href="#cb82-1124"></a></span>
<span id="cb82-1127"><a href="#cb82-1127"></a><span class="in">```{python}</span></span>
<span id="cb82-1128"><a href="#cb82-1128"></a><span class="co"># | code-fold: true</span></span>
<span id="cb82-1129"><a href="#cb82-1129"></a><span class="co"># | code-summary: "Show the code"</span></span>
<span id="cb82-1130"><a href="#cb82-1130"></a><span class="op">%%</span>itikz <span class="op">--</span>temp<span class="op">-</span><span class="bu">dir</span> <span class="op">--</span>tex<span class="op">-</span>packages<span class="op">=</span>tikz <span class="op">--</span>tikz<span class="op">-</span>libraries<span class="op">=</span>arrows <span class="op">--</span>implicit<span class="op">-</span>standalone</span>
<span id="cb82-1131"><a href="#cb82-1131"></a>\begin{tikzpicture}</span>
<span id="cb82-1132"><a href="#cb82-1132"></a></span>
<span id="cb82-1133"><a href="#cb82-1133"></a>\node[circle, </span>
<span id="cb82-1134"><a href="#cb82-1134"></a>    minimum size <span class="op">=</span> <span class="dv">15</span><span class="er">mm</span>,</span>
<span id="cb82-1135"><a href="#cb82-1135"></a>    fill<span class="op">=</span>red<span class="op">!</span><span class="dv">30</span></span>
<span id="cb82-1136"><a href="#cb82-1136"></a>    ] (Input) at (<span class="dv">0</span>,<span class="dv">0</span>) {\large $x_1$}<span class="op">;</span></span>
<span id="cb82-1137"><a href="#cb82-1137"></a></span>
<span id="cb82-1138"><a href="#cb82-1138"></a>\foreach \i <span class="kw">in</span> {<span class="dv">1</span>,<span class="dv">2</span>,...,<span class="dv">8</span>}</span>
<span id="cb82-1139"><a href="#cb82-1139"></a>{</span>
<span id="cb82-1140"><a href="#cb82-1140"></a>    \node[circle, </span>
<span id="cb82-1141"><a href="#cb82-1141"></a>        minimum size <span class="op">=</span> <span class="dv">15</span><span class="er">mm</span>,</span>
<span id="cb82-1142"><a href="#cb82-1142"></a>        fill<span class="op">=</span>blue<span class="op">!</span><span class="dv">50</span>,</span>
<span id="cb82-1143"><a href="#cb82-1143"></a>        yshift<span class="op">=</span><span class="dv">90</span> mm</span>
<span id="cb82-1144"><a href="#cb82-1144"></a>        ] (Hidden1<span class="op">-</span>\i) at (<span class="fl">3.0</span>,<span class="op">-</span>\i <span class="op">*</span> <span class="dv">2</span>) {\large $h_\i<span class="op">^</span>{(<span class="dv">1</span>)}$}<span class="op">;</span></span>
<span id="cb82-1145"><a href="#cb82-1145"></a>        </span>
<span id="cb82-1146"><a href="#cb82-1146"></a>}</span>
<span id="cb82-1147"><a href="#cb82-1147"></a>\foreach \i <span class="kw">in</span> {<span class="dv">1</span>,<span class="dv">2</span>,...,<span class="dv">8</span>}</span>
<span id="cb82-1148"><a href="#cb82-1148"></a>{</span>
<span id="cb82-1149"><a href="#cb82-1149"></a>    \node[circle, </span>
<span id="cb82-1150"><a href="#cb82-1150"></a>        minimum size <span class="op">=</span> <span class="dv">15</span><span class="er">mm</span>,</span>
<span id="cb82-1151"><a href="#cb82-1151"></a>        fill<span class="op">=</span>blue<span class="op">!</span><span class="dv">50</span>,</span>
<span id="cb82-1152"><a href="#cb82-1152"></a>        yshift<span class="op">=</span><span class="dv">90</span> mm</span>
<span id="cb82-1153"><a href="#cb82-1153"></a>        ] (Hidden2<span class="op">-</span>\i) at (<span class="fl">6.0</span>,<span class="op">-</span>\i <span class="op">*</span> <span class="dv">2</span>) {\large $h_\i<span class="op">^</span>{(<span class="dv">2</span>)}$}<span class="op">;</span></span>
<span id="cb82-1154"><a href="#cb82-1154"></a>        </span>
<span id="cb82-1155"><a href="#cb82-1155"></a>}</span>
<span id="cb82-1156"><a href="#cb82-1156"></a></span>
<span id="cb82-1157"><a href="#cb82-1157"></a>\node[circle, </span>
<span id="cb82-1158"><a href="#cb82-1158"></a>    minimum size <span class="op">=</span> <span class="dv">15</span><span class="er">mm</span>,</span>
<span id="cb82-1159"><a href="#cb82-1159"></a>    fill<span class="op">=</span>red<span class="op">!</span><span class="dv">30</span></span>
<span id="cb82-1160"><a href="#cb82-1160"></a>    ] (Output) at (<span class="dv">9</span>,<span class="dv">0</span>) {\large $\hat{y}_1$}<span class="op">;</span></span>
<span id="cb82-1161"><a href="#cb82-1161"></a></span>
<span id="cb82-1162"><a href="#cb82-1162"></a><span class="op">%</span> Connect neurons In<span class="op">-</span>Hidden1</span>
<span id="cb82-1163"><a href="#cb82-1163"></a>\foreach \j <span class="kw">in</span> {<span class="dv">2</span>,...,<span class="dv">8</span>}</span>
<span id="cb82-1164"><a href="#cb82-1164"></a>{</span>
<span id="cb82-1165"><a href="#cb82-1165"></a>    \draw[<span class="op">-&gt;</span>, shorten <span class="op">&gt;=</span><span class="dv">1</span><span class="er">pt</span>] (Input) <span class="op">--</span> (Hidden1<span class="op">-</span>\j)<span class="op">;</span>   </span>
<span id="cb82-1166"><a href="#cb82-1166"></a>}</span>
<span id="cb82-1167"><a href="#cb82-1167"></a><span class="op">%</span> Connect neurons Hidden1<span class="op">-</span>Hidden2</span>
<span id="cb82-1168"><a href="#cb82-1168"></a>\foreach \i <span class="kw">in</span> {<span class="dv">2</span>,...,<span class="dv">8</span>}</span>
<span id="cb82-1169"><a href="#cb82-1169"></a>{</span>
<span id="cb82-1170"><a href="#cb82-1170"></a>    </span>
<span id="cb82-1171"><a href="#cb82-1171"></a>        \draw[<span class="op">-&gt;</span>, shorten <span class="op">&gt;=</span><span class="dv">1</span><span class="er">pt</span>] (Hidden1<span class="op">-</span>\i) <span class="op">--</span> (Hidden2<span class="op">-</span>\i)<span class="op">;</span>   </span>
<span id="cb82-1172"><a href="#cb82-1172"></a>    </span>
<span id="cb82-1173"><a href="#cb82-1173"></a>}</span>
<span id="cb82-1174"><a href="#cb82-1174"></a></span>
<span id="cb82-1175"><a href="#cb82-1175"></a>\foreach \i <span class="kw">in</span> {<span class="dv">2</span>,...,<span class="dv">8</span>}</span>
<span id="cb82-1176"><a href="#cb82-1176"></a>{</span>
<span id="cb82-1177"><a href="#cb82-1177"></a>    </span>
<span id="cb82-1178"><a href="#cb82-1178"></a>        \draw[<span class="op">-&gt;</span>, shorten <span class="op">&gt;=</span><span class="dv">1</span><span class="er">pt</span>] (Hidden2<span class="op">-</span>\i) <span class="op">--</span> (Output)<span class="op">;</span>   </span>
<span id="cb82-1179"><a href="#cb82-1179"></a>}</span>
<span id="cb82-1180"><a href="#cb82-1180"></a>\draw[<span class="op">-&gt;</span>, shorten <span class="op">&gt;=</span><span class="dv">1</span><span class="er">pt</span>] (Input) <span class="op">--</span> node [midway] {$<span class="fl">1.00</span>$} (Hidden1<span class="op">-</span><span class="dv">1</span>)<span class="op">;</span>   </span>
<span id="cb82-1181"><a href="#cb82-1181"></a>\draw[<span class="op">-&gt;</span>, shorten <span class="op">&gt;=</span><span class="dv">1</span><span class="er">pt</span>] (Hidden1<span class="op">-</span><span class="dv">1</span>) <span class="op">--</span> node [midway,above] {$<span class="fl">1.00</span>$} (Hidden2<span class="op">-</span><span class="dv">1</span>)<span class="op">;</span> </span>
<span id="cb82-1182"><a href="#cb82-1182"></a>\draw[<span class="op">-&gt;</span>, shorten <span class="op">&gt;=</span><span class="dv">1</span><span class="er">pt</span>] (Hidden2<span class="op">-</span><span class="dv">1</span>) <span class="op">--</span> node [midway] {$<span class="fl">1.00</span>$} (Output)<span class="op">;</span> </span>
<span id="cb82-1183"><a href="#cb82-1183"></a>\draw[<span class="op">-&gt;</span>, shorten <span class="op">&gt;=</span><span class="dv">1</span><span class="er">pt</span>] (<span class="dv">6</span>,<span class="dv">6</span>) node [below] {$<span class="fl">0.00</span>$} <span class="op">--</span>  (Hidden2<span class="op">-</span><span class="dv">1</span>)<span class="op">;</span> </span>
<span id="cb82-1184"><a href="#cb82-1184"></a>\draw[<span class="op">-&gt;</span>, shorten <span class="op">&gt;=</span><span class="dv">1</span><span class="er">pt</span>] (<span class="dv">3</span>,<span class="dv">6</span>) node [below] {$<span class="fl">0.00</span>$} <span class="op">--</span>  (Hidden1<span class="op">-</span><span class="dv">1</span>)<span class="op">;</span> </span>
<span id="cb82-1185"><a href="#cb82-1185"></a>\end{tikzpicture}</span>
<span id="cb82-1186"><a href="#cb82-1186"></a><span class="in">```</span></span>
<span id="cb82-1187"><a href="#cb82-1187"></a></span>
<span id="cb82-1188"><a href="#cb82-1188"></a>The output is:</span>
<span id="cb82-1189"><a href="#cb82-1189"></a></span>
<span id="cb82-1192"><a href="#cb82-1192"></a><span class="in">```{python}</span></span>
<span id="cb82-1193"><a href="#cb82-1193"></a><span class="co"># | code-fold: true</span></span>
<span id="cb82-1194"><a href="#cb82-1194"></a><span class="co"># | code-summary: "Show the code"</span></span>
<span id="cb82-1195"><a href="#cb82-1195"></a><span class="op">%%</span>itikz <span class="op">--</span>temp<span class="op">-</span><span class="bu">dir</span> <span class="op">--</span>tex<span class="op">-</span>packages<span class="op">=</span>tikz,pgfplots <span class="op">--</span>tikz<span class="op">-</span>libraries<span class="op">=</span>arrows <span class="op">--</span>implicit<span class="op">-</span>standalone</span>
<span id="cb82-1196"><a href="#cb82-1196"></a>\begin{tikzpicture}[scale<span class="op">=</span><span class="fl">1.5</span>]</span>
<span id="cb82-1197"><a href="#cb82-1197"></a>\begin{axis}[grid,ymin<span class="op">=-</span><span class="dv">2</span>,ymax<span class="op">=</span><span class="dv">2</span>,ytick<span class="op">=</span>{<span class="op">-</span><span class="dv">2</span>,<span class="op">-</span><span class="dv">1</span>,...,<span class="dv">2</span>},xmin<span class="op">=</span><span class="dv">0</span>,xmax<span class="op">=</span><span class="dv">1</span>]</span>
<span id="cb82-1198"><a href="#cb82-1198"></a>\addplot[color<span class="op">=</span>blue,thick,samples<span class="op">=</span><span class="dv">1000</span>]{<span class="bu">max</span>(<span class="bu">max</span>(x,<span class="dv">0</span>),<span class="dv">0</span>)}<span class="op">;</span></span>
<span id="cb82-1199"><a href="#cb82-1199"></a>\addplot[color<span class="op">=</span>green,samples<span class="op">=</span><span class="dv">1000</span>,domain<span class="op">=</span><span class="dv">0</span>:<span class="dv">1</span>]{sin(deg(<span class="dv">2</span><span class="op">*</span><span class="fl">3.14</span><span class="op">*</span>x))}<span class="op">;</span></span>
<span id="cb82-1200"><a href="#cb82-1200"></a>\end{axis}</span>
<span id="cb82-1201"><a href="#cb82-1201"></a>\end{tikzpicture}</span>
<span id="cb82-1202"><a href="#cb82-1202"></a><span class="in">```</span></span>
<span id="cb82-1203"><a href="#cb82-1203"></a></span>
<span id="cb82-1204"><a href="#cb82-1204"></a>We can increase the slope of the output by adjusting the weight of the first neuron of the first layer to $6.00$. </span>
<span id="cb82-1205"><a href="#cb82-1205"></a></span>
<span id="cb82-1208"><a href="#cb82-1208"></a><span class="in">```{python}</span></span>
<span id="cb82-1209"><a href="#cb82-1209"></a><span class="co"># | code-fold: true</span></span>
<span id="cb82-1210"><a href="#cb82-1210"></a><span class="co"># | code-summary: "Show the code"</span></span>
<span id="cb82-1211"><a href="#cb82-1211"></a><span class="op">%%</span>itikz <span class="op">--</span>temp<span class="op">-</span><span class="bu">dir</span> <span class="op">--</span>tex<span class="op">-</span>packages<span class="op">=</span>tikz <span class="op">--</span>tikz<span class="op">-</span>libraries<span class="op">=</span>arrows <span class="op">--</span>implicit<span class="op">-</span>standalone</span>
<span id="cb82-1212"><a href="#cb82-1212"></a>\begin{tikzpicture}</span>
<span id="cb82-1213"><a href="#cb82-1213"></a></span>
<span id="cb82-1214"><a href="#cb82-1214"></a>\node[circle, </span>
<span id="cb82-1215"><a href="#cb82-1215"></a>    minimum size <span class="op">=</span> <span class="dv">15</span><span class="er">mm</span>,</span>
<span id="cb82-1216"><a href="#cb82-1216"></a>    fill<span class="op">=</span>red<span class="op">!</span><span class="dv">30</span></span>
<span id="cb82-1217"><a href="#cb82-1217"></a>    ] (Input) at (<span class="dv">0</span>,<span class="dv">0</span>) {\large $x_1$}<span class="op">;</span></span>
<span id="cb82-1218"><a href="#cb82-1218"></a></span>
<span id="cb82-1219"><a href="#cb82-1219"></a>\foreach \i <span class="kw">in</span> {<span class="dv">1</span>,<span class="dv">2</span>,...,<span class="dv">8</span>}</span>
<span id="cb82-1220"><a href="#cb82-1220"></a>{</span>
<span id="cb82-1221"><a href="#cb82-1221"></a>    \node[circle, </span>
<span id="cb82-1222"><a href="#cb82-1222"></a>        minimum size <span class="op">=</span> <span class="dv">15</span><span class="er">mm</span>,</span>
<span id="cb82-1223"><a href="#cb82-1223"></a>        fill<span class="op">=</span>blue<span class="op">!</span><span class="dv">50</span>,</span>
<span id="cb82-1224"><a href="#cb82-1224"></a>        yshift<span class="op">=</span><span class="dv">90</span> mm</span>
<span id="cb82-1225"><a href="#cb82-1225"></a>        ] (Hidden1<span class="op">-</span>\i) at (<span class="fl">3.0</span>,<span class="op">-</span>\i <span class="op">*</span> <span class="dv">2</span>) {\large $h_\i<span class="op">^</span>{(<span class="dv">1</span>)}$}<span class="op">;</span></span>
<span id="cb82-1226"><a href="#cb82-1226"></a>        </span>
<span id="cb82-1227"><a href="#cb82-1227"></a>}</span>
<span id="cb82-1228"><a href="#cb82-1228"></a>\foreach \i <span class="kw">in</span> {<span class="dv">1</span>,<span class="dv">2</span>,...,<span class="dv">8</span>}</span>
<span id="cb82-1229"><a href="#cb82-1229"></a>{</span>
<span id="cb82-1230"><a href="#cb82-1230"></a>    \node[circle, </span>
<span id="cb82-1231"><a href="#cb82-1231"></a>        minimum size <span class="op">=</span> <span class="dv">15</span><span class="er">mm</span>,</span>
<span id="cb82-1232"><a href="#cb82-1232"></a>        fill<span class="op">=</span>blue<span class="op">!</span><span class="dv">50</span>,</span>
<span id="cb82-1233"><a href="#cb82-1233"></a>        yshift<span class="op">=</span><span class="dv">90</span> mm</span>
<span id="cb82-1234"><a href="#cb82-1234"></a>        ] (Hidden2<span class="op">-</span>\i) at (<span class="fl">6.0</span>,<span class="op">-</span>\i <span class="op">*</span> <span class="dv">2</span>) {\large $h_\i<span class="op">^</span>{(<span class="dv">2</span>)}$}<span class="op">;</span></span>
<span id="cb82-1235"><a href="#cb82-1235"></a>        </span>
<span id="cb82-1236"><a href="#cb82-1236"></a>}</span>
<span id="cb82-1237"><a href="#cb82-1237"></a></span>
<span id="cb82-1238"><a href="#cb82-1238"></a>\node[circle, </span>
<span id="cb82-1239"><a href="#cb82-1239"></a>    minimum size <span class="op">=</span> <span class="dv">15</span><span class="er">mm</span>,</span>
<span id="cb82-1240"><a href="#cb82-1240"></a>    fill<span class="op">=</span>red<span class="op">!</span><span class="dv">30</span></span>
<span id="cb82-1241"><a href="#cb82-1241"></a>    ] (Output) at (<span class="dv">9</span>,<span class="dv">0</span>) {\large $\hat{y}_1$}<span class="op">;</span></span>
<span id="cb82-1242"><a href="#cb82-1242"></a></span>
<span id="cb82-1243"><a href="#cb82-1243"></a><span class="op">%</span> Connect neurons In<span class="op">-</span>Hidden1</span>
<span id="cb82-1244"><a href="#cb82-1244"></a>\foreach \j <span class="kw">in</span> {<span class="dv">2</span>,...,<span class="dv">8</span>}</span>
<span id="cb82-1245"><a href="#cb82-1245"></a>{</span>
<span id="cb82-1246"><a href="#cb82-1246"></a>    \draw[<span class="op">-&gt;</span>, shorten <span class="op">&gt;=</span><span class="dv">1</span><span class="er">pt</span>] (Input) <span class="op">--</span> (Hidden1<span class="op">-</span>\j)<span class="op">;</span>   </span>
<span id="cb82-1247"><a href="#cb82-1247"></a>}</span>
<span id="cb82-1248"><a href="#cb82-1248"></a><span class="op">%</span> Connect neurons Hidden1<span class="op">-</span>Hidden2</span>
<span id="cb82-1249"><a href="#cb82-1249"></a>\foreach \i <span class="kw">in</span> {<span class="dv">2</span>,...,<span class="dv">8</span>}</span>
<span id="cb82-1250"><a href="#cb82-1250"></a>{</span>
<span id="cb82-1251"><a href="#cb82-1251"></a>    </span>
<span id="cb82-1252"><a href="#cb82-1252"></a>        \draw[<span class="op">-&gt;</span>, shorten <span class="op">&gt;=</span><span class="dv">1</span><span class="er">pt</span>] (Hidden1<span class="op">-</span>\i) <span class="op">--</span> (Hidden2<span class="op">-</span>\i)<span class="op">;</span>   </span>
<span id="cb82-1253"><a href="#cb82-1253"></a>    </span>
<span id="cb82-1254"><a href="#cb82-1254"></a>}</span>
<span id="cb82-1255"><a href="#cb82-1255"></a></span>
<span id="cb82-1256"><a href="#cb82-1256"></a>\foreach \i <span class="kw">in</span> {<span class="dv">2</span>,...,<span class="dv">8</span>}</span>
<span id="cb82-1257"><a href="#cb82-1257"></a>{</span>
<span id="cb82-1258"><a href="#cb82-1258"></a>    </span>
<span id="cb82-1259"><a href="#cb82-1259"></a>        \draw[<span class="op">-&gt;</span>, shorten <span class="op">&gt;=</span><span class="dv">1</span><span class="er">pt</span>] (Hidden2<span class="op">-</span>\i) <span class="op">--</span> (Output)<span class="op">;</span>   </span>
<span id="cb82-1260"><a href="#cb82-1260"></a>}</span>
<span id="cb82-1261"><a href="#cb82-1261"></a>\draw[<span class="op">-&gt;</span>, shorten <span class="op">&gt;=</span><span class="dv">1</span><span class="er">pt</span>] (Input) <span class="op">--</span> node [midway] {$<span class="fl">6.00</span>$} (Hidden1<span class="op">-</span><span class="dv">1</span>)<span class="op">;</span>   </span>
<span id="cb82-1262"><a href="#cb82-1262"></a>\draw[<span class="op">-&gt;</span>, shorten <span class="op">&gt;=</span><span class="dv">1</span><span class="er">pt</span>] (Hidden1<span class="op">-</span><span class="dv">1</span>) <span class="op">--</span> node [midway,above] {$<span class="fl">1.00</span>$} (Hidden2<span class="op">-</span><span class="dv">1</span>)<span class="op">;</span> </span>
<span id="cb82-1263"><a href="#cb82-1263"></a>\draw[<span class="op">-&gt;</span>, shorten <span class="op">&gt;=</span><span class="dv">1</span><span class="er">pt</span>] (Hidden2<span class="op">-</span><span class="dv">1</span>) <span class="op">--</span> node [midway] {$<span class="fl">1.00</span>$} (Output)<span class="op">;</span> </span>
<span id="cb82-1264"><a href="#cb82-1264"></a>\draw[<span class="op">-&gt;</span>, shorten <span class="op">&gt;=</span><span class="dv">1</span><span class="er">pt</span>] (<span class="dv">6</span>,<span class="dv">6</span>) node [below] {$<span class="fl">0.00</span>$} <span class="op">--</span>  (Hidden2<span class="op">-</span><span class="dv">1</span>)<span class="op">;</span> </span>
<span id="cb82-1265"><a href="#cb82-1265"></a>\draw[<span class="op">-&gt;</span>, shorten <span class="op">&gt;=</span><span class="dv">1</span><span class="er">pt</span>] (<span class="dv">3</span>,<span class="dv">6</span>) node [below] {$<span class="fl">0.00</span>$} <span class="op">--</span>  (Hidden1<span class="op">-</span><span class="dv">1</span>)<span class="op">;</span> </span>
<span id="cb82-1266"><a href="#cb82-1266"></a>\end{tikzpicture}</span>
<span id="cb82-1267"><a href="#cb82-1267"></a><span class="in">```</span></span>
<span id="cb82-1268"><a href="#cb82-1268"></a></span>
<span id="cb82-1269"><a href="#cb82-1269"></a>We can now see, for example, that the initial slope of this function is what we'd like, but we have a problem. </span>
<span id="cb82-1270"><a href="#cb82-1270"></a></span>
<span id="cb82-1273"><a href="#cb82-1273"></a><span class="in">```{python}</span></span>
<span id="cb82-1274"><a href="#cb82-1274"></a><span class="co"># | code-fold: true</span></span>
<span id="cb82-1275"><a href="#cb82-1275"></a><span class="co"># | code-summary: "Show the code"</span></span>
<span id="cb82-1276"><a href="#cb82-1276"></a><span class="op">%%</span>itikz <span class="op">--</span>temp<span class="op">-</span><span class="bu">dir</span> <span class="op">--</span>tex<span class="op">-</span>packages<span class="op">=</span>tikz,pgfplots <span class="op">--</span>tikz<span class="op">-</span>libraries<span class="op">=</span>arrows <span class="op">--</span>implicit<span class="op">-</span>standalone</span>
<span id="cb82-1277"><a href="#cb82-1277"></a>\begin{tikzpicture}[scale<span class="op">=</span><span class="fl">1.5</span>]</span>
<span id="cb82-1278"><a href="#cb82-1278"></a>\begin{axis}[grid,ymin<span class="op">=-</span><span class="dv">2</span>,ymax<span class="op">=</span><span class="dv">2</span>,ytick<span class="op">=</span>{<span class="op">-</span><span class="dv">2</span>,<span class="op">-</span><span class="dv">1</span>,...,<span class="dv">2</span>},xmin<span class="op">=</span><span class="dv">0</span>,xmax<span class="op">=</span><span class="dv">1</span>]</span>
<span id="cb82-1279"><a href="#cb82-1279"></a>\addplot[color<span class="op">=</span>blue,thick,samples<span class="op">=</span><span class="dv">1000</span>]{<span class="bu">max</span>(<span class="bu">max</span>(<span class="dv">6</span><span class="op">*</span>x,<span class="dv">0</span>),<span class="dv">0</span>)}<span class="op">;</span></span>
<span id="cb82-1280"><a href="#cb82-1280"></a>\addplot[color<span class="op">=</span>green,samples<span class="op">=</span><span class="dv">1000</span>,domain<span class="op">=</span><span class="dv">0</span>:<span class="dv">1</span>]{sin(deg(<span class="dv">2</span><span class="op">*</span><span class="fl">3.14</span><span class="op">*</span>x))}<span class="op">;</span></span>
<span id="cb82-1281"><a href="#cb82-1281"></a>\end{axis}</span>
<span id="cb82-1282"><a href="#cb82-1282"></a>\end{tikzpicture}</span>
<span id="cb82-1283"><a href="#cb82-1283"></a><span class="in">```</span></span>
<span id="cb82-1284"><a href="#cb82-1284"></a></span>
<span id="cb82-1285"><a href="#cb82-1285"></a>Currently, this function never ends because this neuron pair never *deactivates*. We can visually see where we'd like the deactivation to occur. It's where the red fitment line diverges from our green sine wave. So now, while we have the correct slope, we need to set this spot as our deactivation point. To do that, we start by increasing the bias for the second neuron of the hidden layer to $0.70$. </span>
<span id="cb82-1286"><a href="#cb82-1286"></a></span>
<span id="cb82-1289"><a href="#cb82-1289"></a><span class="in">```{python}</span></span>
<span id="cb82-1290"><a href="#cb82-1290"></a><span class="co"># | code-fold: true</span></span>
<span id="cb82-1291"><a href="#cb82-1291"></a><span class="co"># | code-summary: "Show the code"</span></span>
<span id="cb82-1292"><a href="#cb82-1292"></a><span class="op">%%</span>itikz <span class="op">--</span>temp<span class="op">-</span><span class="bu">dir</span> <span class="op">--</span>tex<span class="op">-</span>packages<span class="op">=</span>tikz <span class="op">--</span>tikz<span class="op">-</span>libraries<span class="op">=</span>arrows <span class="op">--</span>implicit<span class="op">-</span>standalone</span>
<span id="cb82-1293"><a href="#cb82-1293"></a>\begin{tikzpicture}</span>
<span id="cb82-1294"><a href="#cb82-1294"></a></span>
<span id="cb82-1295"><a href="#cb82-1295"></a>\node[circle, </span>
<span id="cb82-1296"><a href="#cb82-1296"></a>    minimum size <span class="op">=</span> <span class="dv">15</span><span class="er">mm</span>,</span>
<span id="cb82-1297"><a href="#cb82-1297"></a>    fill<span class="op">=</span>red<span class="op">!</span><span class="dv">30</span></span>
<span id="cb82-1298"><a href="#cb82-1298"></a>    ] (Input) at (<span class="dv">0</span>,<span class="dv">0</span>) {\large $x_1$}<span class="op">;</span></span>
<span id="cb82-1299"><a href="#cb82-1299"></a></span>
<span id="cb82-1300"><a href="#cb82-1300"></a>\foreach \i <span class="kw">in</span> {<span class="dv">1</span>,<span class="dv">2</span>,...,<span class="dv">8</span>}</span>
<span id="cb82-1301"><a href="#cb82-1301"></a>{</span>
<span id="cb82-1302"><a href="#cb82-1302"></a>    \node[circle, </span>
<span id="cb82-1303"><a href="#cb82-1303"></a>        minimum size <span class="op">=</span> <span class="dv">15</span><span class="er">mm</span>,</span>
<span id="cb82-1304"><a href="#cb82-1304"></a>        fill<span class="op">=</span>blue<span class="op">!</span><span class="dv">50</span>,</span>
<span id="cb82-1305"><a href="#cb82-1305"></a>        yshift<span class="op">=</span><span class="dv">90</span> mm</span>
<span id="cb82-1306"><a href="#cb82-1306"></a>        ] (Hidden1<span class="op">-</span>\i) at (<span class="fl">3.0</span>,<span class="op">-</span>\i <span class="op">*</span> <span class="dv">2</span>) {\large $h_\i<span class="op">^</span>{(<span class="dv">1</span>)}$}<span class="op">;</span></span>
<span id="cb82-1307"><a href="#cb82-1307"></a>        </span>
<span id="cb82-1308"><a href="#cb82-1308"></a>}</span>
<span id="cb82-1309"><a href="#cb82-1309"></a>\foreach \i <span class="kw">in</span> {<span class="dv">1</span>,<span class="dv">2</span>,...,<span class="dv">8</span>}</span>
<span id="cb82-1310"><a href="#cb82-1310"></a>{</span>
<span id="cb82-1311"><a href="#cb82-1311"></a>    \node[circle, </span>
<span id="cb82-1312"><a href="#cb82-1312"></a>        minimum size <span class="op">=</span> <span class="dv">15</span><span class="er">mm</span>,</span>
<span id="cb82-1313"><a href="#cb82-1313"></a>        fill<span class="op">=</span>blue<span class="op">!</span><span class="dv">50</span>,</span>
<span id="cb82-1314"><a href="#cb82-1314"></a>        yshift<span class="op">=</span><span class="dv">90</span> mm</span>
<span id="cb82-1315"><a href="#cb82-1315"></a>        ] (Hidden2<span class="op">-</span>\i) at (<span class="fl">6.0</span>,<span class="op">-</span>\i <span class="op">*</span> <span class="dv">2</span>) {\large $h_\i<span class="op">^</span>{(<span class="dv">2</span>)}$}<span class="op">;</span></span>
<span id="cb82-1316"><a href="#cb82-1316"></a>        </span>
<span id="cb82-1317"><a href="#cb82-1317"></a>}</span>
<span id="cb82-1318"><a href="#cb82-1318"></a></span>
<span id="cb82-1319"><a href="#cb82-1319"></a>\node[circle, </span>
<span id="cb82-1320"><a href="#cb82-1320"></a>    minimum size <span class="op">=</span> <span class="dv">15</span><span class="er">mm</span>,</span>
<span id="cb82-1321"><a href="#cb82-1321"></a>    fill<span class="op">=</span>red<span class="op">!</span><span class="dv">30</span></span>
<span id="cb82-1322"><a href="#cb82-1322"></a>    ] (Output) at (<span class="dv">9</span>,<span class="dv">0</span>) {\large $\hat{y}_1$}<span class="op">;</span></span>
<span id="cb82-1323"><a href="#cb82-1323"></a></span>
<span id="cb82-1324"><a href="#cb82-1324"></a><span class="op">%</span> Connect neurons In<span class="op">-</span>Hidden1</span>
<span id="cb82-1325"><a href="#cb82-1325"></a>\foreach \j <span class="kw">in</span> {<span class="dv">2</span>,...,<span class="dv">8</span>}</span>
<span id="cb82-1326"><a href="#cb82-1326"></a>{</span>
<span id="cb82-1327"><a href="#cb82-1327"></a>    \draw[<span class="op">-&gt;</span>, shorten <span class="op">&gt;=</span><span class="dv">1</span><span class="er">pt</span>] (Input) <span class="op">--</span> (Hidden1<span class="op">-</span>\j)<span class="op">;</span>   </span>
<span id="cb82-1328"><a href="#cb82-1328"></a>}</span>
<span id="cb82-1329"><a href="#cb82-1329"></a><span class="op">%</span> Connect neurons Hidden1<span class="op">-</span>Hidden2</span>
<span id="cb82-1330"><a href="#cb82-1330"></a>\foreach \i <span class="kw">in</span> {<span class="dv">2</span>,...,<span class="dv">8</span>}</span>
<span id="cb82-1331"><a href="#cb82-1331"></a>{</span>
<span id="cb82-1332"><a href="#cb82-1332"></a>    </span>
<span id="cb82-1333"><a href="#cb82-1333"></a>        \draw[<span class="op">-&gt;</span>, shorten <span class="op">&gt;=</span><span class="dv">1</span><span class="er">pt</span>] (Hidden1<span class="op">-</span>\i) <span class="op">--</span> (Hidden2<span class="op">-</span>\i)<span class="op">;</span>   </span>
<span id="cb82-1334"><a href="#cb82-1334"></a>    </span>
<span id="cb82-1335"><a href="#cb82-1335"></a>}</span>
<span id="cb82-1336"><a href="#cb82-1336"></a></span>
<span id="cb82-1337"><a href="#cb82-1337"></a>\foreach \i <span class="kw">in</span> {<span class="dv">2</span>,...,<span class="dv">8</span>}</span>
<span id="cb82-1338"><a href="#cb82-1338"></a>{</span>
<span id="cb82-1339"><a href="#cb82-1339"></a>    </span>
<span id="cb82-1340"><a href="#cb82-1340"></a>        \draw[<span class="op">-&gt;</span>, shorten <span class="op">&gt;=</span><span class="dv">1</span><span class="er">pt</span>] (Hidden2<span class="op">-</span>\i) <span class="op">--</span> (Output)<span class="op">;</span>   </span>
<span id="cb82-1341"><a href="#cb82-1341"></a>}</span>
<span id="cb82-1342"><a href="#cb82-1342"></a>\draw[<span class="op">-&gt;</span>, shorten <span class="op">&gt;=</span><span class="dv">1</span><span class="er">pt</span>] (Input) <span class="op">--</span> node [midway] {$<span class="fl">6.00</span>$} (Hidden1<span class="op">-</span><span class="dv">1</span>)<span class="op">;</span>   </span>
<span id="cb82-1343"><a href="#cb82-1343"></a>\draw[<span class="op">-&gt;</span>, shorten <span class="op">&gt;=</span><span class="dv">1</span><span class="er">pt</span>] (Hidden1<span class="op">-</span><span class="dv">1</span>) <span class="op">--</span> node [midway,above] {$<span class="fl">1.00</span>$} (Hidden2<span class="op">-</span><span class="dv">1</span>)<span class="op">;</span> </span>
<span id="cb82-1344"><a href="#cb82-1344"></a>\draw[<span class="op">-&gt;</span>, shorten <span class="op">&gt;=</span><span class="dv">1</span><span class="er">pt</span>] (Hidden2<span class="op">-</span><span class="dv">1</span>) <span class="op">--</span> node [midway] {$<span class="fl">1.00</span>$} (Output)<span class="op">;</span> </span>
<span id="cb82-1345"><a href="#cb82-1345"></a>\draw[<span class="op">-&gt;</span>, shorten <span class="op">&gt;=</span><span class="dv">1</span><span class="er">pt</span>] (<span class="dv">6</span>,<span class="dv">6</span>) node [below] {$<span class="fl">0.70</span>$} <span class="op">--</span>  (Hidden2<span class="op">-</span><span class="dv">1</span>)<span class="op">;</span> </span>
<span id="cb82-1346"><a href="#cb82-1346"></a>\draw[<span class="op">-&gt;</span>, shorten <span class="op">&gt;=</span><span class="dv">1</span><span class="er">pt</span>] (<span class="dv">3</span>,<span class="dv">6</span>) node [below] {$<span class="fl">0.00</span>$} <span class="op">--</span>  (Hidden1<span class="op">-</span><span class="dv">1</span>)<span class="op">;</span> </span>
<span id="cb82-1347"><a href="#cb82-1347"></a>\end{tikzpicture}</span>
<span id="cb82-1348"><a href="#cb82-1348"></a><span class="in">```</span></span>
<span id="cb82-1349"><a href="#cb82-1349"></a></span>
<span id="cb82-1350"><a href="#cb82-1350"></a>Recall, that this offsets the overall function vertically:</span>
<span id="cb82-1351"><a href="#cb82-1351"></a></span>
<span id="cb82-1354"><a href="#cb82-1354"></a><span class="in">```{python}</span></span>
<span id="cb82-1355"><a href="#cb82-1355"></a><span class="co"># | code-fold: true</span></span>
<span id="cb82-1356"><a href="#cb82-1356"></a><span class="co"># | code-summary: "Show the code"</span></span>
<span id="cb82-1357"><a href="#cb82-1357"></a><span class="op">%%</span>itikz <span class="op">--</span>temp<span class="op">-</span><span class="bu">dir</span> <span class="op">--</span>tex<span class="op">-</span>packages<span class="op">=</span>tikz,pgfplots <span class="op">--</span>tikz<span class="op">-</span>libraries<span class="op">=</span>arrows <span class="op">--</span>implicit<span class="op">-</span>standalone</span>
<span id="cb82-1358"><a href="#cb82-1358"></a>\begin{tikzpicture}[scale<span class="op">=</span><span class="fl">1.5</span>]</span>
<span id="cb82-1359"><a href="#cb82-1359"></a>\begin{axis}[grid,ymin<span class="op">=-</span><span class="dv">2</span>,ymax<span class="op">=</span><span class="dv">2</span>,ytick<span class="op">=</span>{<span class="op">-</span><span class="dv">2</span>,<span class="op">-</span><span class="dv">1</span>,...,<span class="dv">2</span>},xmin<span class="op">=</span><span class="dv">0</span>,xmax<span class="op">=</span><span class="dv">1</span>]</span>
<span id="cb82-1360"><a href="#cb82-1360"></a>\addplot[color<span class="op">=</span>blue,thick,samples<span class="op">=</span><span class="dv">1000</span>]{<span class="bu">max</span>(<span class="bu">max</span>(<span class="dv">6</span><span class="op">*</span>x,<span class="dv">0</span>)<span class="op">+</span><span class="fl">0.70</span>,<span class="dv">0</span>)}<span class="op">;</span></span>
<span id="cb82-1361"><a href="#cb82-1361"></a>\addplot[color<span class="op">=</span>green,samples<span class="op">=</span><span class="dv">1000</span>,domain<span class="op">=</span><span class="dv">0</span>:<span class="dv">1</span>]{sin(deg(<span class="dv">2</span><span class="op">*</span><span class="fl">3.14</span><span class="op">*</span>x))}<span class="op">;</span></span>
<span id="cb82-1362"><a href="#cb82-1362"></a>\end{axis}</span>
<span id="cb82-1363"><a href="#cb82-1363"></a>\end{tikzpicture}</span>
<span id="cb82-1364"><a href="#cb82-1364"></a><span class="in">```</span></span>
<span id="cb82-1365"><a href="#cb82-1365"></a></span>
<span id="cb82-1366"><a href="#cb82-1366"></a>Now, we can set the weight for the second neuron to $-1$, causing a deactivation point to occur, atleast horizontally, where we want it. </span>
<span id="cb82-1367"><a href="#cb82-1367"></a></span>
<span id="cb82-1370"><a href="#cb82-1370"></a><span class="in">```{python}</span></span>
<span id="cb82-1371"><a href="#cb82-1371"></a><span class="co"># | code-fold: true</span></span>
<span id="cb82-1372"><a href="#cb82-1372"></a><span class="co"># | code-summary: "Show the code"</span></span>
<span id="cb82-1373"><a href="#cb82-1373"></a><span class="op">%%</span>itikz <span class="op">--</span>temp<span class="op">-</span><span class="bu">dir</span> <span class="op">--</span>tex<span class="op">-</span>packages<span class="op">=</span>tikz <span class="op">--</span>tikz<span class="op">-</span>libraries<span class="op">=</span>arrows <span class="op">--</span>implicit<span class="op">-</span>standalone</span>
<span id="cb82-1374"><a href="#cb82-1374"></a>\begin{tikzpicture}</span>
<span id="cb82-1375"><a href="#cb82-1375"></a></span>
<span id="cb82-1376"><a href="#cb82-1376"></a>\node[circle, </span>
<span id="cb82-1377"><a href="#cb82-1377"></a>    minimum size <span class="op">=</span> <span class="dv">15</span><span class="er">mm</span>,</span>
<span id="cb82-1378"><a href="#cb82-1378"></a>    fill<span class="op">=</span>red<span class="op">!</span><span class="dv">30</span></span>
<span id="cb82-1379"><a href="#cb82-1379"></a>    ] (Input) at (<span class="dv">0</span>,<span class="dv">0</span>) {\large $x_1$}<span class="op">;</span></span>
<span id="cb82-1380"><a href="#cb82-1380"></a></span>
<span id="cb82-1381"><a href="#cb82-1381"></a>\foreach \i <span class="kw">in</span> {<span class="dv">1</span>,<span class="dv">2</span>,...,<span class="dv">8</span>}</span>
<span id="cb82-1382"><a href="#cb82-1382"></a>{</span>
<span id="cb82-1383"><a href="#cb82-1383"></a>    \node[circle, </span>
<span id="cb82-1384"><a href="#cb82-1384"></a>        minimum size <span class="op">=</span> <span class="dv">15</span><span class="er">mm</span>,</span>
<span id="cb82-1385"><a href="#cb82-1385"></a>        fill<span class="op">=</span>blue<span class="op">!</span><span class="dv">50</span>,</span>
<span id="cb82-1386"><a href="#cb82-1386"></a>        yshift<span class="op">=</span><span class="dv">90</span> mm</span>
<span id="cb82-1387"><a href="#cb82-1387"></a>        ] (Hidden1<span class="op">-</span>\i) at (<span class="fl">3.0</span>,<span class="op">-</span>\i <span class="op">*</span> <span class="dv">2</span>) {\large $h_\i<span class="op">^</span>{(<span class="dv">1</span>)}$}<span class="op">;</span></span>
<span id="cb82-1388"><a href="#cb82-1388"></a>        </span>
<span id="cb82-1389"><a href="#cb82-1389"></a>}</span>
<span id="cb82-1390"><a href="#cb82-1390"></a>\foreach \i <span class="kw">in</span> {<span class="dv">1</span>,<span class="dv">2</span>,...,<span class="dv">8</span>}</span>
<span id="cb82-1391"><a href="#cb82-1391"></a>{</span>
<span id="cb82-1392"><a href="#cb82-1392"></a>    \node[circle, </span>
<span id="cb82-1393"><a href="#cb82-1393"></a>        minimum size <span class="op">=</span> <span class="dv">15</span><span class="er">mm</span>,</span>
<span id="cb82-1394"><a href="#cb82-1394"></a>        fill<span class="op">=</span>blue<span class="op">!</span><span class="dv">50</span>,</span>
<span id="cb82-1395"><a href="#cb82-1395"></a>        yshift<span class="op">=</span><span class="dv">90</span> mm</span>
<span id="cb82-1396"><a href="#cb82-1396"></a>        ] (Hidden2<span class="op">-</span>\i) at (<span class="fl">6.0</span>,<span class="op">-</span>\i <span class="op">*</span> <span class="dv">2</span>) {\large $h_\i<span class="op">^</span>{(<span class="dv">2</span>)}$}<span class="op">;</span></span>
<span id="cb82-1397"><a href="#cb82-1397"></a>        </span>
<span id="cb82-1398"><a href="#cb82-1398"></a>}</span>
<span id="cb82-1399"><a href="#cb82-1399"></a></span>
<span id="cb82-1400"><a href="#cb82-1400"></a>\node[circle, </span>
<span id="cb82-1401"><a href="#cb82-1401"></a>    minimum size <span class="op">=</span> <span class="dv">15</span><span class="er">mm</span>,</span>
<span id="cb82-1402"><a href="#cb82-1402"></a>    fill<span class="op">=</span>red<span class="op">!</span><span class="dv">30</span></span>
<span id="cb82-1403"><a href="#cb82-1403"></a>    ] (Output) at (<span class="dv">9</span>,<span class="dv">0</span>) {\large $\hat{y}_1$}<span class="op">;</span></span>
<span id="cb82-1404"><a href="#cb82-1404"></a></span>
<span id="cb82-1405"><a href="#cb82-1405"></a><span class="op">%</span> Connect neurons In<span class="op">-</span>Hidden1</span>
<span id="cb82-1406"><a href="#cb82-1406"></a>\foreach \j <span class="kw">in</span> {<span class="dv">2</span>,...,<span class="dv">8</span>}</span>
<span id="cb82-1407"><a href="#cb82-1407"></a>{</span>
<span id="cb82-1408"><a href="#cb82-1408"></a>    \draw[<span class="op">-&gt;</span>, shorten <span class="op">&gt;=</span><span class="dv">1</span><span class="er">pt</span>] (Input) <span class="op">--</span> (Hidden1<span class="op">-</span>\j)<span class="op">;</span>   </span>
<span id="cb82-1409"><a href="#cb82-1409"></a>}</span>
<span id="cb82-1410"><a href="#cb82-1410"></a><span class="op">%</span> Connect neurons Hidden1<span class="op">-</span>Hidden2</span>
<span id="cb82-1411"><a href="#cb82-1411"></a>\foreach \i <span class="kw">in</span> {<span class="dv">2</span>,...,<span class="dv">8</span>}</span>
<span id="cb82-1412"><a href="#cb82-1412"></a>{</span>
<span id="cb82-1413"><a href="#cb82-1413"></a>    </span>
<span id="cb82-1414"><a href="#cb82-1414"></a>        \draw[<span class="op">-&gt;</span>, shorten <span class="op">&gt;=</span><span class="dv">1</span><span class="er">pt</span>] (Hidden1<span class="op">-</span>\i) <span class="op">--</span> (Hidden2<span class="op">-</span>\i)<span class="op">;</span>   </span>
<span id="cb82-1415"><a href="#cb82-1415"></a>    </span>
<span id="cb82-1416"><a href="#cb82-1416"></a>}</span>
<span id="cb82-1417"><a href="#cb82-1417"></a></span>
<span id="cb82-1418"><a href="#cb82-1418"></a>\foreach \i <span class="kw">in</span> {<span class="dv">2</span>,...,<span class="dv">8</span>}</span>
<span id="cb82-1419"><a href="#cb82-1419"></a>{</span>
<span id="cb82-1420"><a href="#cb82-1420"></a>    </span>
<span id="cb82-1421"><a href="#cb82-1421"></a>        \draw[<span class="op">-&gt;</span>, shorten <span class="op">&gt;=</span><span class="dv">1</span><span class="er">pt</span>] (Hidden2<span class="op">-</span>\i) <span class="op">--</span> (Output)<span class="op">;</span>   </span>
<span id="cb82-1422"><a href="#cb82-1422"></a>}</span>
<span id="cb82-1423"><a href="#cb82-1423"></a>\draw[<span class="op">-&gt;</span>, shorten <span class="op">&gt;=</span><span class="dv">1</span><span class="er">pt</span>] (Input) <span class="op">--</span> node [midway] {$<span class="fl">6.00</span>$} (Hidden1<span class="op">-</span><span class="dv">1</span>)<span class="op">;</span>   </span>
<span id="cb82-1424"><a href="#cb82-1424"></a>\draw[<span class="op">-&gt;</span>, shorten <span class="op">&gt;=</span><span class="dv">1</span><span class="er">pt</span>] (Hidden1<span class="op">-</span><span class="dv">1</span>) <span class="op">--</span> node [midway,above] {$<span class="op">-</span><span class="fl">1.00</span>$} (Hidden2<span class="op">-</span><span class="dv">1</span>)<span class="op">;</span> </span>
<span id="cb82-1425"><a href="#cb82-1425"></a>\draw[<span class="op">-&gt;</span>, shorten <span class="op">&gt;=</span><span class="dv">1</span><span class="er">pt</span>] (Hidden2<span class="op">-</span><span class="dv">1</span>) <span class="op">--</span> node [midway] {$<span class="fl">1.00</span>$} (Output)<span class="op">;</span> </span>
<span id="cb82-1426"><a href="#cb82-1426"></a>\draw[<span class="op">-&gt;</span>, shorten <span class="op">&gt;=</span><span class="dv">1</span><span class="er">pt</span>] (<span class="dv">6</span>,<span class="dv">6</span>) node [below] {$<span class="fl">0.70</span>$} <span class="op">--</span>  (Hidden2<span class="op">-</span><span class="dv">1</span>)<span class="op">;</span> </span>
<span id="cb82-1427"><a href="#cb82-1427"></a>\draw[<span class="op">-&gt;</span>, shorten <span class="op">&gt;=</span><span class="dv">1</span><span class="er">pt</span>] (<span class="dv">3</span>,<span class="dv">6</span>) node [below] {$<span class="fl">0.00</span>$} <span class="op">--</span>  (Hidden1<span class="op">-</span><span class="dv">1</span>)<span class="op">;</span> </span>
<span id="cb82-1428"><a href="#cb82-1428"></a>\end{tikzpicture}</span>
<span id="cb82-1429"><a href="#cb82-1429"></a><span class="in">```</span></span>
<span id="cb82-1430"><a href="#cb82-1430"></a></span>
<span id="cb82-1431"><a href="#cb82-1431"></a>We get:</span>
<span id="cb82-1432"><a href="#cb82-1432"></a></span>
<span id="cb82-1435"><a href="#cb82-1435"></a><span class="in">```{python}</span></span>
<span id="cb82-1436"><a href="#cb82-1436"></a><span class="co"># | code-fold: true</span></span>
<span id="cb82-1437"><a href="#cb82-1437"></a><span class="co"># | code-summary: "Show the code"</span></span>
<span id="cb82-1438"><a href="#cb82-1438"></a><span class="op">%%</span>itikz <span class="op">--</span>temp<span class="op">-</span><span class="bu">dir</span> <span class="op">--</span>tex<span class="op">-</span>packages<span class="op">=</span>tikz,pgfplots <span class="op">--</span>tikz<span class="op">-</span>libraries<span class="op">=</span>arrows <span class="op">--</span>implicit<span class="op">-</span>standalone</span>
<span id="cb82-1439"><a href="#cb82-1439"></a>\begin{tikzpicture}[scale<span class="op">=</span><span class="fl">1.5</span>]</span>
<span id="cb82-1440"><a href="#cb82-1440"></a>\begin{axis}[grid,ymin<span class="op">=-</span><span class="dv">2</span>,ymax<span class="op">=</span><span class="dv">2</span>,ytick<span class="op">=</span>{<span class="op">-</span><span class="dv">2</span>,<span class="op">-</span><span class="dv">1</span>,...,<span class="dv">2</span>},xmin<span class="op">=</span><span class="dv">0</span>,xmax<span class="op">=</span><span class="dv">1</span>]</span>
<span id="cb82-1441"><a href="#cb82-1441"></a>\addplot[color<span class="op">=</span>blue,thick,samples<span class="op">=</span><span class="dv">1000</span>]{<span class="bu">max</span>(<span class="op">-</span><span class="bu">max</span>(<span class="dv">6</span><span class="op">*</span>x,<span class="dv">0</span>)<span class="op">+</span><span class="fl">0.70</span>,<span class="dv">0</span>)}<span class="op">;</span></span>
<span id="cb82-1442"><a href="#cb82-1442"></a>\addplot[color<span class="op">=</span>green,samples<span class="op">=</span><span class="dv">1000</span>,domain<span class="op">=</span><span class="dv">0</span>:<span class="dv">1</span>]{sin(deg(<span class="dv">2</span><span class="op">*</span><span class="fl">3.14</span><span class="op">*</span>x))}<span class="op">;</span></span>
<span id="cb82-1443"><a href="#cb82-1443"></a>\end{axis}</span>
<span id="cb82-1444"><a href="#cb82-1444"></a>\end{tikzpicture}</span>
<span id="cb82-1445"><a href="#cb82-1445"></a><span class="in">```</span></span>
<span id="cb82-1446"><a href="#cb82-1446"></a></span>
<span id="cb82-1447"><a href="#cb82-1447"></a>Now, we'd like to flip this slope back. How might we flip the output of these two neurons? </span>
<span id="cb82-1448"><a href="#cb82-1448"></a></span>
<span id="cb82-1451"><a href="#cb82-1451"></a><span class="in">```{python}</span></span>
<span id="cb82-1452"><a href="#cb82-1452"></a><span class="co"># | code-fold: true</span></span>
<span id="cb82-1453"><a href="#cb82-1453"></a><span class="co"># | code-summary: "Show the code"</span></span>
<span id="cb82-1454"><a href="#cb82-1454"></a><span class="op">%%</span>itikz <span class="op">--</span>temp<span class="op">-</span><span class="bu">dir</span> <span class="op">--</span>tex<span class="op">-</span>packages<span class="op">=</span>tikz <span class="op">--</span>tikz<span class="op">-</span>libraries<span class="op">=</span>arrows <span class="op">--</span>implicit<span class="op">-</span>standalone</span>
<span id="cb82-1455"><a href="#cb82-1455"></a>\begin{tikzpicture}</span>
<span id="cb82-1456"><a href="#cb82-1456"></a></span>
<span id="cb82-1457"><a href="#cb82-1457"></a>\node[circle, </span>
<span id="cb82-1458"><a href="#cb82-1458"></a>    minimum size <span class="op">=</span> <span class="dv">15</span><span class="er">mm</span>,</span>
<span id="cb82-1459"><a href="#cb82-1459"></a>    fill<span class="op">=</span>red<span class="op">!</span><span class="dv">30</span></span>
<span id="cb82-1460"><a href="#cb82-1460"></a>    ] (Input) at (<span class="dv">0</span>,<span class="dv">0</span>) {\large $x_1$}<span class="op">;</span></span>
<span id="cb82-1461"><a href="#cb82-1461"></a></span>
<span id="cb82-1462"><a href="#cb82-1462"></a>\foreach \i <span class="kw">in</span> {<span class="dv">1</span>,<span class="dv">2</span>,...,<span class="dv">8</span>}</span>
<span id="cb82-1463"><a href="#cb82-1463"></a>{</span>
<span id="cb82-1464"><a href="#cb82-1464"></a>    \node[circle, </span>
<span id="cb82-1465"><a href="#cb82-1465"></a>        minimum size <span class="op">=</span> <span class="dv">15</span><span class="er">mm</span>,</span>
<span id="cb82-1466"><a href="#cb82-1466"></a>        fill<span class="op">=</span>blue<span class="op">!</span><span class="dv">50</span>,</span>
<span id="cb82-1467"><a href="#cb82-1467"></a>        yshift<span class="op">=</span><span class="dv">90</span> mm</span>
<span id="cb82-1468"><a href="#cb82-1468"></a>        ] (Hidden1<span class="op">-</span>\i) at (<span class="fl">3.0</span>,<span class="op">-</span>\i <span class="op">*</span> <span class="dv">2</span>) {\large $h_\i<span class="op">^</span>{(<span class="dv">1</span>)}$}<span class="op">;</span></span>
<span id="cb82-1469"><a href="#cb82-1469"></a>        </span>
<span id="cb82-1470"><a href="#cb82-1470"></a>}</span>
<span id="cb82-1471"><a href="#cb82-1471"></a>\foreach \i <span class="kw">in</span> {<span class="dv">1</span>,<span class="dv">2</span>,...,<span class="dv">8</span>}</span>
<span id="cb82-1472"><a href="#cb82-1472"></a>{</span>
<span id="cb82-1473"><a href="#cb82-1473"></a>    \node[circle, </span>
<span id="cb82-1474"><a href="#cb82-1474"></a>        minimum size <span class="op">=</span> <span class="dv">15</span><span class="er">mm</span>,</span>
<span id="cb82-1475"><a href="#cb82-1475"></a>        fill<span class="op">=</span>blue<span class="op">!</span><span class="dv">50</span>,</span>
<span id="cb82-1476"><a href="#cb82-1476"></a>        yshift<span class="op">=</span><span class="dv">90</span> mm</span>
<span id="cb82-1477"><a href="#cb82-1477"></a>        ] (Hidden2<span class="op">-</span>\i) at (<span class="fl">6.0</span>,<span class="op">-</span>\i <span class="op">*</span> <span class="dv">2</span>) {\large $h_\i<span class="op">^</span>{(<span class="dv">2</span>)}$}<span class="op">;</span></span>
<span id="cb82-1478"><a href="#cb82-1478"></a>        </span>
<span id="cb82-1479"><a href="#cb82-1479"></a>}</span>
<span id="cb82-1480"><a href="#cb82-1480"></a></span>
<span id="cb82-1481"><a href="#cb82-1481"></a>\node[circle, </span>
<span id="cb82-1482"><a href="#cb82-1482"></a>    minimum size <span class="op">=</span> <span class="dv">15</span><span class="er">mm</span>,</span>
<span id="cb82-1483"><a href="#cb82-1483"></a>    fill<span class="op">=</span>red<span class="op">!</span><span class="dv">30</span></span>
<span id="cb82-1484"><a href="#cb82-1484"></a>    ] (Output) at (<span class="dv">9</span>,<span class="dv">0</span>) {\large $\hat{y}_1$}<span class="op">;</span></span>
<span id="cb82-1485"><a href="#cb82-1485"></a></span>
<span id="cb82-1486"><a href="#cb82-1486"></a><span class="op">%</span> Connect neurons In<span class="op">-</span>Hidden1</span>
<span id="cb82-1487"><a href="#cb82-1487"></a>\foreach \j <span class="kw">in</span> {<span class="dv">2</span>,...,<span class="dv">8</span>}</span>
<span id="cb82-1488"><a href="#cb82-1488"></a>{</span>
<span id="cb82-1489"><a href="#cb82-1489"></a>    \draw[<span class="op">-&gt;</span>, shorten <span class="op">&gt;=</span><span class="dv">1</span><span class="er">pt</span>] (Input) <span class="op">--</span> (Hidden1<span class="op">-</span>\j)<span class="op">;</span>   </span>
<span id="cb82-1490"><a href="#cb82-1490"></a>}</span>
<span id="cb82-1491"><a href="#cb82-1491"></a><span class="op">%</span> Connect neurons Hidden1<span class="op">-</span>Hidden2</span>
<span id="cb82-1492"><a href="#cb82-1492"></a>\foreach \i <span class="kw">in</span> {<span class="dv">2</span>,...,<span class="dv">8</span>}</span>
<span id="cb82-1493"><a href="#cb82-1493"></a>{</span>
<span id="cb82-1494"><a href="#cb82-1494"></a>    </span>
<span id="cb82-1495"><a href="#cb82-1495"></a>        \draw[<span class="op">-&gt;</span>, shorten <span class="op">&gt;=</span><span class="dv">1</span><span class="er">pt</span>] (Hidden1<span class="op">-</span>\i) <span class="op">--</span> (Hidden2<span class="op">-</span>\i)<span class="op">;</span>   </span>
<span id="cb82-1496"><a href="#cb82-1496"></a>    </span>
<span id="cb82-1497"><a href="#cb82-1497"></a>}</span>
<span id="cb82-1498"><a href="#cb82-1498"></a></span>
<span id="cb82-1499"><a href="#cb82-1499"></a>\foreach \i <span class="kw">in</span> {<span class="dv">2</span>,...,<span class="dv">8</span>}</span>
<span id="cb82-1500"><a href="#cb82-1500"></a>{</span>
<span id="cb82-1501"><a href="#cb82-1501"></a>    </span>
<span id="cb82-1502"><a href="#cb82-1502"></a>        \draw[<span class="op">-&gt;</span>, shorten <span class="op">&gt;=</span><span class="dv">1</span><span class="er">pt</span>] (Hidden2<span class="op">-</span>\i) <span class="op">--</span> (Output)<span class="op">;</span>   </span>
<span id="cb82-1503"><a href="#cb82-1503"></a>}</span>
<span id="cb82-1504"><a href="#cb82-1504"></a>\draw[<span class="op">-&gt;</span>, shorten <span class="op">&gt;=</span><span class="dv">1</span><span class="er">pt</span>] (Input) <span class="op">--</span> node [midway] {$<span class="fl">6.00</span>$} (Hidden1<span class="op">-</span><span class="dv">1</span>)<span class="op">;</span>   </span>
<span id="cb82-1505"><a href="#cb82-1505"></a>\draw[<span class="op">-&gt;</span>, shorten <span class="op">&gt;=</span><span class="dv">1</span><span class="er">pt</span>] (Hidden1<span class="op">-</span><span class="dv">1</span>) <span class="op">--</span> node [midway,above] {$<span class="op">-</span><span class="fl">1.00</span>$} (Hidden2<span class="op">-</span><span class="dv">1</span>)<span class="op">;</span> </span>
<span id="cb82-1506"><a href="#cb82-1506"></a>\draw[<span class="op">-&gt;</span>, shorten <span class="op">&gt;=</span><span class="dv">1</span><span class="er">pt</span>] (Hidden2<span class="op">-</span><span class="dv">1</span>) <span class="op">--</span> node [midway] {$<span class="op">-</span><span class="fl">1.00</span>$} (Output)<span class="op">;</span> </span>
<span id="cb82-1507"><a href="#cb82-1507"></a>\draw[<span class="op">-&gt;</span>, shorten <span class="op">&gt;=</span><span class="dv">1</span><span class="er">pt</span>] (<span class="dv">6</span>,<span class="dv">6</span>) node [below] {$<span class="fl">0.70</span>$} <span class="op">--</span>  (Hidden2<span class="op">-</span><span class="dv">1</span>)<span class="op">;</span> </span>
<span id="cb82-1508"><a href="#cb82-1508"></a>\draw[<span class="op">-&gt;</span>, shorten <span class="op">&gt;=</span><span class="dv">1</span><span class="er">pt</span>] (<span class="dv">3</span>,<span class="dv">6</span>) node [below] {$<span class="fl">0.00</span>$} <span class="op">--</span>  (Hidden1<span class="op">-</span><span class="dv">1</span>)<span class="op">;</span> </span>
<span id="cb82-1509"><a href="#cb82-1509"></a>\end{tikzpicture}</span>
<span id="cb82-1510"><a href="#cb82-1510"></a><span class="in">```</span></span>
<span id="cb82-1511"><a href="#cb82-1511"></a></span>
<span id="cb82-1512"><a href="#cb82-1512"></a>It seems like we can take the weights of the connection to the output neuron, which is currently $1.0$ and just flip it to a $-1$, and that flips the function:</span>
<span id="cb82-1513"><a href="#cb82-1513"></a></span>
<span id="cb82-1516"><a href="#cb82-1516"></a><span class="in">```{python}</span></span>
<span id="cb82-1517"><a href="#cb82-1517"></a><span class="co"># | code-fold: true</span></span>
<span id="cb82-1518"><a href="#cb82-1518"></a><span class="co"># | code-summary: "Show the code"</span></span>
<span id="cb82-1519"><a href="#cb82-1519"></a><span class="op">%%</span>itikz <span class="op">--</span>temp<span class="op">-</span><span class="bu">dir</span> <span class="op">--</span>tex<span class="op">-</span>packages<span class="op">=</span>tikz,pgfplots <span class="op">--</span>tikz<span class="op">-</span>libraries<span class="op">=</span>arrows <span class="op">--</span>implicit<span class="op">-</span>standalone</span>
<span id="cb82-1520"><a href="#cb82-1520"></a>\begin{tikzpicture}[scale<span class="op">=</span><span class="fl">1.5</span>]</span>
<span id="cb82-1521"><a href="#cb82-1521"></a>\begin{axis}[grid,ymin<span class="op">=-</span><span class="dv">2</span>,ymax<span class="op">=</span><span class="dv">2</span>,ytick<span class="op">=</span>{<span class="op">-</span><span class="dv">2</span>,<span class="op">-</span><span class="dv">1</span>,...,<span class="dv">2</span>},xmin<span class="op">=</span><span class="dv">0</span>,xmax<span class="op">=</span><span class="dv">1</span>]</span>
<span id="cb82-1522"><a href="#cb82-1522"></a>\addplot[color<span class="op">=</span>blue,thick,samples<span class="op">=</span><span class="dv">1000</span>]{<span class="op">-</span><span class="bu">max</span>(<span class="op">-</span><span class="bu">max</span>(<span class="dv">6</span><span class="op">*</span>x,<span class="dv">0</span>)<span class="op">+</span><span class="fl">0.70</span>,<span class="dv">0</span>)}<span class="op">;</span></span>
<span id="cb82-1523"><a href="#cb82-1523"></a>\addplot[color<span class="op">=</span>green,samples<span class="op">=</span><span class="dv">1000</span>,domain<span class="op">=</span><span class="dv">0</span>:<span class="dv">1</span>]{sin(deg(<span class="dv">2</span><span class="op">*</span><span class="fl">3.14</span><span class="op">*</span>x))}<span class="op">;</span></span>
<span id="cb82-1524"><a href="#cb82-1524"></a>\end{axis}</span>
<span id="cb82-1525"><a href="#cb82-1525"></a>\end{tikzpicture}</span>
<span id="cb82-1526"><a href="#cb82-1526"></a><span class="in">```</span></span>
<span id="cb82-1527"><a href="#cb82-1527"></a></span>
<span id="cb82-1528"><a href="#cb82-1528"></a>We're certainly getting closer to making this first section fit how we want. Now, all we need to do is offset this up a bit. For this hand-optimized example, we're going to use the first $7$ pairs of neurons in the hidden layers to create the sine wave's shape. </span>
<span id="cb82-1529"><a href="#cb82-1529"></a></span>
<span id="cb82-1532"><a href="#cb82-1532"></a><span class="in">```{python}</span></span>
<span id="cb82-1533"><a href="#cb82-1533"></a><span class="co"># | code-fold: true</span></span>
<span id="cb82-1534"><a href="#cb82-1534"></a><span class="co"># | code-summary: "Show the code"</span></span>
<span id="cb82-1535"><a href="#cb82-1535"></a><span class="op">%%</span>itikz <span class="op">--</span>temp<span class="op">-</span><span class="bu">dir</span> <span class="op">--</span>tex<span class="op">-</span>packages<span class="op">=</span>tikz <span class="op">--</span>tikz<span class="op">-</span>libraries<span class="op">=</span>arrows <span class="op">--</span>implicit<span class="op">-</span>standalone</span>
<span id="cb82-1536"><a href="#cb82-1536"></a>\begin{tikzpicture}</span>
<span id="cb82-1537"><a href="#cb82-1537"></a></span>
<span id="cb82-1538"><a href="#cb82-1538"></a>\node[circle, </span>
<span id="cb82-1539"><a href="#cb82-1539"></a>    minimum size <span class="op">=</span> <span class="dv">15</span><span class="er">mm</span>,</span>
<span id="cb82-1540"><a href="#cb82-1540"></a>    fill<span class="op">=</span>red<span class="op">!</span><span class="dv">30</span></span>
<span id="cb82-1541"><a href="#cb82-1541"></a>    ] (Input) at (<span class="dv">0</span>,<span class="dv">0</span>) {\large $x_1$}<span class="op">;</span></span>
<span id="cb82-1542"><a href="#cb82-1542"></a></span>
<span id="cb82-1543"><a href="#cb82-1543"></a>\foreach \i <span class="kw">in</span> {<span class="dv">1</span>,<span class="dv">2</span>,...,<span class="dv">8</span>}</span>
<span id="cb82-1544"><a href="#cb82-1544"></a>{</span>
<span id="cb82-1545"><a href="#cb82-1545"></a>    \node[circle, </span>
<span id="cb82-1546"><a href="#cb82-1546"></a>        minimum size <span class="op">=</span> <span class="dv">15</span><span class="er">mm</span>,</span>
<span id="cb82-1547"><a href="#cb82-1547"></a>        fill<span class="op">=</span>blue<span class="op">!</span><span class="dv">50</span>,</span>
<span id="cb82-1548"><a href="#cb82-1548"></a>        yshift<span class="op">=</span><span class="dv">90</span> mm</span>
<span id="cb82-1549"><a href="#cb82-1549"></a>        ] (Hidden1<span class="op">-</span>\i) at (<span class="fl">3.0</span>,<span class="op">-</span>\i <span class="op">*</span> <span class="dv">2</span>) {\large $h_\i<span class="op">^</span>{(<span class="dv">1</span>)}$}<span class="op">;</span></span>
<span id="cb82-1550"><a href="#cb82-1550"></a>        </span>
<span id="cb82-1551"><a href="#cb82-1551"></a>}</span>
<span id="cb82-1552"><a href="#cb82-1552"></a>\foreach \i <span class="kw">in</span> {<span class="dv">1</span>,<span class="dv">2</span>,...,<span class="dv">8</span>}</span>
<span id="cb82-1553"><a href="#cb82-1553"></a>{</span>
<span id="cb82-1554"><a href="#cb82-1554"></a>    \node[circle, </span>
<span id="cb82-1555"><a href="#cb82-1555"></a>        minimum size <span class="op">=</span> <span class="dv">15</span><span class="er">mm</span>,</span>
<span id="cb82-1556"><a href="#cb82-1556"></a>        fill<span class="op">=</span>blue<span class="op">!</span><span class="dv">50</span>,</span>
<span id="cb82-1557"><a href="#cb82-1557"></a>        yshift<span class="op">=</span><span class="dv">90</span> mm</span>
<span id="cb82-1558"><a href="#cb82-1558"></a>        ] (Hidden2<span class="op">-</span>\i) at (<span class="fl">6.0</span>,<span class="op">-</span>\i <span class="op">*</span> <span class="dv">2</span>) {\large $h_\i<span class="op">^</span>{(<span class="dv">2</span>)}$}<span class="op">;</span></span>
<span id="cb82-1559"><a href="#cb82-1559"></a>        </span>
<span id="cb82-1560"><a href="#cb82-1560"></a>}</span>
<span id="cb82-1561"><a href="#cb82-1561"></a></span>
<span id="cb82-1562"><a href="#cb82-1562"></a>\node[circle, </span>
<span id="cb82-1563"><a href="#cb82-1563"></a>    minimum size <span class="op">=</span> <span class="dv">15</span><span class="er">mm</span>,</span>
<span id="cb82-1564"><a href="#cb82-1564"></a>    fill<span class="op">=</span>red<span class="op">!</span><span class="dv">30</span></span>
<span id="cb82-1565"><a href="#cb82-1565"></a>    ] (Output) at (<span class="dv">9</span>,<span class="dv">0</span>) {\large $\hat{y}_1$}<span class="op">;</span></span>
<span id="cb82-1566"><a href="#cb82-1566"></a></span>
<span id="cb82-1567"><a href="#cb82-1567"></a><span class="op">%</span> Connect neurons In<span class="op">-</span>Hidden1</span>
<span id="cb82-1568"><a href="#cb82-1568"></a>\foreach \j <span class="kw">in</span> {<span class="dv">2</span>,...,<span class="dv">7</span>}</span>
<span id="cb82-1569"><a href="#cb82-1569"></a>{</span>
<span id="cb82-1570"><a href="#cb82-1570"></a>    \draw[<span class="op">-&gt;</span>, shorten <span class="op">&gt;=</span><span class="dv">1</span><span class="er">pt</span>] (Input) <span class="op">--</span> (Hidden1<span class="op">-</span>\j)<span class="op">;</span>   </span>
<span id="cb82-1571"><a href="#cb82-1571"></a>}</span>
<span id="cb82-1572"><a href="#cb82-1572"></a><span class="op">%</span> Connect neurons Hidden1<span class="op">-</span>Hidden2</span>
<span id="cb82-1573"><a href="#cb82-1573"></a>\foreach \i <span class="kw">in</span> {<span class="dv">2</span>,...,<span class="dv">7</span>}</span>
<span id="cb82-1574"><a href="#cb82-1574"></a>{</span>
<span id="cb82-1575"><a href="#cb82-1575"></a>    </span>
<span id="cb82-1576"><a href="#cb82-1576"></a>        \draw[<span class="op">-&gt;</span>, shorten <span class="op">&gt;=</span><span class="dv">1</span><span class="er">pt</span>] (Hidden1<span class="op">-</span>\i) <span class="op">--</span> (Hidden2<span class="op">-</span>\i)<span class="op">;</span>   </span>
<span id="cb82-1577"><a href="#cb82-1577"></a>    </span>
<span id="cb82-1578"><a href="#cb82-1578"></a>}</span>
<span id="cb82-1579"><a href="#cb82-1579"></a></span>
<span id="cb82-1580"><a href="#cb82-1580"></a>\foreach \i <span class="kw">in</span> {<span class="dv">2</span>,...,<span class="dv">7</span>}</span>
<span id="cb82-1581"><a href="#cb82-1581"></a>{</span>
<span id="cb82-1582"><a href="#cb82-1582"></a>    </span>
<span id="cb82-1583"><a href="#cb82-1583"></a>        \draw[<span class="op">-&gt;</span>, shorten <span class="op">&gt;=</span><span class="dv">1</span><span class="er">pt</span>] (Hidden2<span class="op">-</span>\i) <span class="op">--</span> (Output)<span class="op">;</span>   </span>
<span id="cb82-1584"><a href="#cb82-1584"></a>}</span>
<span id="cb82-1585"><a href="#cb82-1585"></a>\draw[<span class="op">-&gt;</span>, shorten <span class="op">&gt;=</span><span class="dv">1</span><span class="er">pt</span>] (Input) <span class="op">--</span> node [midway] {$<span class="fl">6.00</span>$} (Hidden1<span class="op">-</span><span class="dv">1</span>)<span class="op">;</span>   </span>
<span id="cb82-1586"><a href="#cb82-1586"></a>\draw[<span class="op">-&gt;</span>, shorten <span class="op">&gt;=</span><span class="dv">1</span><span class="er">pt</span>] (Hidden1<span class="op">-</span><span class="dv">1</span>) <span class="op">--</span> node [midway,above] {$<span class="op">-</span><span class="fl">1.00</span>$} (Hidden2<span class="op">-</span><span class="dv">1</span>)<span class="op">;</span> </span>
<span id="cb82-1587"><a href="#cb82-1587"></a>\draw[<span class="op">-&gt;</span>, shorten <span class="op">&gt;=</span><span class="dv">1</span><span class="er">pt</span>] (Hidden2<span class="op">-</span><span class="dv">1</span>) <span class="op">--</span> node [midway] {$<span class="op">-</span><span class="fl">1.00</span>$} (Output)<span class="op">;</span> </span>
<span id="cb82-1588"><a href="#cb82-1588"></a>\draw[<span class="op">-&gt;</span>, shorten <span class="op">&gt;=</span><span class="dv">1</span><span class="er">pt</span>] (<span class="dv">6</span>,<span class="dv">6</span>) node [below] {$<span class="fl">0.70</span>$} <span class="op">--</span>  (Hidden2<span class="op">-</span><span class="dv">1</span>)<span class="op">;</span> </span>
<span id="cb82-1589"><a href="#cb82-1589"></a>\draw[<span class="op">-&gt;</span>, shorten <span class="op">&gt;=</span><span class="dv">1</span><span class="er">pt</span>] (<span class="dv">3</span>,<span class="dv">6</span>) node [below] {$<span class="fl">0.00</span>$} <span class="op">--</span>  (Hidden1<span class="op">-</span><span class="dv">1</span>)<span class="op">;</span> </span>
<span id="cb82-1590"><a href="#cb82-1590"></a></span>
<span id="cb82-1591"><a href="#cb82-1591"></a>\draw[<span class="op">-&gt;</span>, shorten <span class="op">&gt;=</span><span class="dv">1</span><span class="er">pt</span>] (Input) <span class="op">--</span> node [midway] {$<span class="fl">0.00</span>$} (Hidden1<span class="op">-</span><span class="dv">8</span>)<span class="op">;</span> </span>
<span id="cb82-1592"><a href="#cb82-1592"></a>\draw[<span class="op">-&gt;</span>, shorten <span class="op">&gt;=</span><span class="dv">1</span><span class="er">pt</span>] (<span class="dv">3</span>,<span class="op">-</span><span class="dv">9</span>) node [below] {$<span class="fl">0.00</span>$} <span class="op">--</span>  (Hidden1<span class="op">-</span><span class="dv">8</span>)<span class="op">;</span> </span>
<span id="cb82-1593"><a href="#cb82-1593"></a>\draw[<span class="op">-&gt;</span>, shorten <span class="op">&gt;=</span><span class="dv">1</span><span class="er">pt</span>] (Hidden1<span class="op">-</span><span class="dv">8</span>) <span class="op">--</span> node [midway,above] {$<span class="fl">0.00</span>$} (Hidden2<span class="op">-</span><span class="dv">8</span>)<span class="op">;</span> </span>
<span id="cb82-1594"><a href="#cb82-1594"></a>\draw[<span class="op">-&gt;</span>, shorten <span class="op">&gt;=</span><span class="dv">1</span><span class="er">pt</span>] (<span class="dv">6</span>,<span class="op">-</span><span class="dv">9</span>) node [below] {$<span class="fl">1.00</span>$} <span class="op">--</span>  (Hidden2<span class="op">-</span><span class="dv">8</span>)<span class="op">;</span> </span>
<span id="cb82-1595"><a href="#cb82-1595"></a>\draw[<span class="op">-&gt;</span>, shorten <span class="op">&gt;=</span><span class="dv">1</span><span class="er">pt</span>] (Hidden2<span class="op">-</span><span class="dv">8</span>) <span class="op">--</span> node [midway] {$<span class="fl">0.70</span>$} (Output)<span class="op">;</span> </span>
<span id="cb82-1596"><a href="#cb82-1596"></a>\end{tikzpicture}</span>
<span id="cb82-1597"><a href="#cb82-1597"></a><span class="in">```</span></span>
<span id="cb82-1598"><a href="#cb82-1598"></a></span>
<span id="cb82-1599"><a href="#cb82-1599"></a>If we set the bias of the second neuron in the bottom pair to $1.0$ and the weight to the output neuron to $0.70$, we can vertically shift the line like so:</span>
<span id="cb82-1600"><a href="#cb82-1600"></a></span>
<span id="cb82-1603"><a href="#cb82-1603"></a><span class="in">```{python}</span></span>
<span id="cb82-1604"><a href="#cb82-1604"></a><span class="co"># | code-fold: true</span></span>
<span id="cb82-1605"><a href="#cb82-1605"></a><span class="co"># | code-summary: "Show the code"</span></span>
<span id="cb82-1606"><a href="#cb82-1606"></a><span class="op">%%</span>itikz <span class="op">--</span>temp<span class="op">-</span><span class="bu">dir</span> <span class="op">--</span>tex<span class="op">-</span>packages<span class="op">=</span>tikz,pgfplots <span class="op">--</span>tikz<span class="op">-</span>libraries<span class="op">=</span>arrows <span class="op">--</span>implicit<span class="op">-</span>standalone</span>
<span id="cb82-1607"><a href="#cb82-1607"></a>\begin{tikzpicture}[scale<span class="op">=</span><span class="fl">1.5</span>]</span>
<span id="cb82-1608"><a href="#cb82-1608"></a>\begin{axis}[grid,ymin<span class="op">=-</span><span class="dv">2</span>,ymax<span class="op">=</span><span class="dv">2</span>,ytick<span class="op">=</span>{<span class="op">-</span><span class="dv">2</span>,<span class="op">-</span><span class="dv">1</span>,...,<span class="dv">2</span>},xmin<span class="op">=</span><span class="dv">0</span>,xmax<span class="op">=</span><span class="dv">1</span>]</span>
<span id="cb82-1609"><a href="#cb82-1609"></a>\addplot[color<span class="op">=</span>blue,thick,samples<span class="op">=</span><span class="dv">1000</span>]{<span class="op">-</span><span class="bu">max</span>(<span class="op">-</span><span class="bu">max</span>(<span class="dv">6</span><span class="op">*</span>x,<span class="dv">0</span>)<span class="op">+</span><span class="fl">0.70</span>,<span class="dv">0</span>))<span class="op">+</span><span class="fl">0.70</span>}<span class="op">;</span></span>
<span id="cb82-1610"><a href="#cb82-1610"></a>\addplot[color<span class="op">=</span>green,samples<span class="op">=</span><span class="dv">1000</span>,domain<span class="op">=</span><span class="dv">0</span>:<span class="dv">1</span>]{sin(deg(<span class="dv">2</span><span class="op">*</span><span class="fl">3.14</span><span class="op">*</span>x))}<span class="op">;</span></span>
<span id="cb82-1611"><a href="#cb82-1611"></a>\end{axis}</span>
<span id="cb82-1612"><a href="#cb82-1612"></a>\end{tikzpicture}</span>
<span id="cb82-1613"><a href="#cb82-1613"></a><span class="in">```</span></span>
<span id="cb82-1614"><a href="#cb82-1614"></a></span>
<span id="cb82-1615"><a href="#cb82-1615"></a>At this point, we have completed the first section with an "area of effect" being the first upward section of the sine wave. We can start on the next section that we wish to do. We can start on the next section that we wish to do. We can start by setting all weights for this second pair of neurons to $1$ including the output neuron.</span>
<span id="cb82-1616"><a href="#cb82-1616"></a></span>
<span id="cb82-1619"><a href="#cb82-1619"></a><span class="in">```{python}</span></span>
<span id="cb82-1620"><a href="#cb82-1620"></a><span class="co"># | code-fold: true</span></span>
<span id="cb82-1621"><a href="#cb82-1621"></a><span class="co"># | code-summary: "Show the code"</span></span>
<span id="cb82-1622"><a href="#cb82-1622"></a><span class="op">%%</span>itikz <span class="op">--</span>temp<span class="op">-</span><span class="bu">dir</span> <span class="op">--</span>tex<span class="op">-</span>packages<span class="op">=</span>tikz <span class="op">--</span>tikz<span class="op">-</span>libraries<span class="op">=</span>arrows <span class="op">--</span>implicit<span class="op">-</span>standalone</span>
<span id="cb82-1623"><a href="#cb82-1623"></a>\begin{tikzpicture}</span>
<span id="cb82-1624"><a href="#cb82-1624"></a></span>
<span id="cb82-1625"><a href="#cb82-1625"></a>\node[circle, </span>
<span id="cb82-1626"><a href="#cb82-1626"></a>    minimum size <span class="op">=</span> <span class="dv">15</span><span class="er">mm</span>,</span>
<span id="cb82-1627"><a href="#cb82-1627"></a>    fill<span class="op">=</span>red<span class="op">!</span><span class="dv">30</span></span>
<span id="cb82-1628"><a href="#cb82-1628"></a>    ] (Input) at (<span class="dv">0</span>,<span class="dv">0</span>) {\large $x_1$}<span class="op">;</span></span>
<span id="cb82-1629"><a href="#cb82-1629"></a></span>
<span id="cb82-1630"><a href="#cb82-1630"></a>\foreach \i <span class="kw">in</span> {<span class="dv">1</span>,<span class="dv">2</span>,...,<span class="dv">8</span>}</span>
<span id="cb82-1631"><a href="#cb82-1631"></a>{</span>
<span id="cb82-1632"><a href="#cb82-1632"></a>    \node[circle, </span>
<span id="cb82-1633"><a href="#cb82-1633"></a>        minimum size <span class="op">=</span> <span class="dv">15</span><span class="er">mm</span>,</span>
<span id="cb82-1634"><a href="#cb82-1634"></a>        fill<span class="op">=</span>blue<span class="op">!</span><span class="dv">50</span>,</span>
<span id="cb82-1635"><a href="#cb82-1635"></a>        yshift<span class="op">=</span><span class="dv">90</span> mm</span>
<span id="cb82-1636"><a href="#cb82-1636"></a>        ] (Hidden1<span class="op">-</span>\i) at (<span class="fl">3.0</span>,<span class="op">-</span>\i <span class="op">*</span> <span class="dv">2</span>) {\large $h_\i<span class="op">^</span>{(<span class="dv">1</span>)}$}<span class="op">;</span></span>
<span id="cb82-1637"><a href="#cb82-1637"></a>        </span>
<span id="cb82-1638"><a href="#cb82-1638"></a>}</span>
<span id="cb82-1639"><a href="#cb82-1639"></a>\foreach \i <span class="kw">in</span> {<span class="dv">1</span>,<span class="dv">2</span>,...,<span class="dv">8</span>}</span>
<span id="cb82-1640"><a href="#cb82-1640"></a>{</span>
<span id="cb82-1641"><a href="#cb82-1641"></a>    \node[circle, </span>
<span id="cb82-1642"><a href="#cb82-1642"></a>        minimum size <span class="op">=</span> <span class="dv">15</span><span class="er">mm</span>,</span>
<span id="cb82-1643"><a href="#cb82-1643"></a>        fill<span class="op">=</span>blue<span class="op">!</span><span class="dv">50</span>,</span>
<span id="cb82-1644"><a href="#cb82-1644"></a>        yshift<span class="op">=</span><span class="dv">90</span> mm</span>
<span id="cb82-1645"><a href="#cb82-1645"></a>        ] (Hidden2<span class="op">-</span>\i) at (<span class="fl">6.0</span>,<span class="op">-</span>\i <span class="op">*</span> <span class="dv">2</span>) {\large $h_\i<span class="op">^</span>{(<span class="dv">2</span>)}$}<span class="op">;</span></span>
<span id="cb82-1646"><a href="#cb82-1646"></a>        </span>
<span id="cb82-1647"><a href="#cb82-1647"></a>}</span>
<span id="cb82-1648"><a href="#cb82-1648"></a></span>
<span id="cb82-1649"><a href="#cb82-1649"></a>\node[circle, </span>
<span id="cb82-1650"><a href="#cb82-1650"></a>    minimum size <span class="op">=</span> <span class="dv">15</span><span class="er">mm</span>,</span>
<span id="cb82-1651"><a href="#cb82-1651"></a>    fill<span class="op">=</span>red<span class="op">!</span><span class="dv">30</span></span>
<span id="cb82-1652"><a href="#cb82-1652"></a>    ] (Output) at (<span class="dv">9</span>,<span class="dv">0</span>) {\large $\hat{y}_1$}<span class="op">;</span></span>
<span id="cb82-1653"><a href="#cb82-1653"></a></span>
<span id="cb82-1654"><a href="#cb82-1654"></a><span class="op">%</span> Connect neurons In<span class="op">-</span>Hidden1</span>
<span id="cb82-1655"><a href="#cb82-1655"></a>\foreach \j <span class="kw">in</span> {<span class="dv">3</span>,...,<span class="dv">7</span>}</span>
<span id="cb82-1656"><a href="#cb82-1656"></a>{</span>
<span id="cb82-1657"><a href="#cb82-1657"></a>    \draw[<span class="op">-&gt;</span>, shorten <span class="op">&gt;=</span><span class="dv">1</span><span class="er">pt</span>] (Input) <span class="op">--</span> (Hidden1<span class="op">-</span>\j)<span class="op">;</span>   </span>
<span id="cb82-1658"><a href="#cb82-1658"></a>}</span>
<span id="cb82-1659"><a href="#cb82-1659"></a><span class="op">%</span> Connect neurons Hidden1<span class="op">-</span>Hidden2</span>
<span id="cb82-1660"><a href="#cb82-1660"></a>\foreach \i <span class="kw">in</span> {<span class="dv">3</span>,...,<span class="dv">7</span>}</span>
<span id="cb82-1661"><a href="#cb82-1661"></a>{</span>
<span id="cb82-1662"><a href="#cb82-1662"></a>    </span>
<span id="cb82-1663"><a href="#cb82-1663"></a>        \draw[<span class="op">-&gt;</span>, shorten <span class="op">&gt;=</span><span class="dv">1</span><span class="er">pt</span>] (Hidden1<span class="op">-</span>\i) <span class="op">--</span> (Hidden2<span class="op">-</span>\i)<span class="op">;</span>   </span>
<span id="cb82-1664"><a href="#cb82-1664"></a>    </span>
<span id="cb82-1665"><a href="#cb82-1665"></a>}</span>
<span id="cb82-1666"><a href="#cb82-1666"></a></span>
<span id="cb82-1667"><a href="#cb82-1667"></a>\foreach \i <span class="kw">in</span> {<span class="dv">3</span>,...,<span class="dv">7</span>}</span>
<span id="cb82-1668"><a href="#cb82-1668"></a>{</span>
<span id="cb82-1669"><a href="#cb82-1669"></a>    </span>
<span id="cb82-1670"><a href="#cb82-1670"></a>        \draw[<span class="op">-&gt;</span>, shorten <span class="op">&gt;=</span><span class="dv">1</span><span class="er">pt</span>] (Hidden2<span class="op">-</span>\i) <span class="op">--</span> (Output)<span class="op">;</span>   </span>
<span id="cb82-1671"><a href="#cb82-1671"></a>}</span>
<span id="cb82-1672"><a href="#cb82-1672"></a>\draw[<span class="op">-&gt;</span>, shorten <span class="op">&gt;=</span><span class="dv">1</span><span class="er">pt</span>] (Input) <span class="op">--</span> node [midway] {$<span class="fl">6.00</span>$} (Hidden1<span class="op">-</span><span class="dv">1</span>)<span class="op">;</span>   </span>
<span id="cb82-1673"><a href="#cb82-1673"></a>\draw[<span class="op">-&gt;</span>, shorten <span class="op">&gt;=</span><span class="dv">1</span><span class="er">pt</span>] (Hidden1<span class="op">-</span><span class="dv">1</span>) <span class="op">--</span> node [midway,above] {$<span class="op">-</span><span class="fl">1.00</span>$} (Hidden2<span class="op">-</span><span class="dv">1</span>)<span class="op">;</span> </span>
<span id="cb82-1674"><a href="#cb82-1674"></a>\draw[<span class="op">-&gt;</span>, shorten <span class="op">&gt;=</span><span class="dv">1</span><span class="er">pt</span>] (Hidden2<span class="op">-</span><span class="dv">1</span>) <span class="op">--</span> node [midway] {$<span class="op">-</span><span class="fl">1.00</span>$} (Output)<span class="op">;</span> </span>
<span id="cb82-1675"><a href="#cb82-1675"></a>\draw[<span class="op">-&gt;</span>, shorten <span class="op">&gt;=</span><span class="dv">1</span><span class="er">pt</span>] (<span class="dv">6</span>,<span class="dv">6</span>) node [below] {$<span class="fl">0.70</span>$} <span class="op">--</span>  (Hidden2<span class="op">-</span><span class="dv">1</span>)<span class="op">;</span> </span>
<span id="cb82-1676"><a href="#cb82-1676"></a>\draw[<span class="op">-&gt;</span>, shorten <span class="op">&gt;=</span><span class="dv">1</span><span class="er">pt</span>] (<span class="dv">3</span>,<span class="dv">6</span>) node [below] {$<span class="fl">0.00</span>$} <span class="op">--</span>  (Hidden1<span class="op">-</span><span class="dv">1</span>)<span class="op">;</span> </span>
<span id="cb82-1677"><a href="#cb82-1677"></a></span>
<span id="cb82-1678"><a href="#cb82-1678"></a>\draw[<span class="op">-&gt;</span>, shorten <span class="op">&gt;=</span><span class="dv">1</span><span class="er">pt</span>] (Input) <span class="op">--</span> node [midway] {$<span class="fl">0.00</span>$} (Hidden1<span class="op">-</span><span class="dv">8</span>)<span class="op">;</span> </span>
<span id="cb82-1679"><a href="#cb82-1679"></a>\draw[<span class="op">-&gt;</span>, shorten <span class="op">&gt;=</span><span class="dv">1</span><span class="er">pt</span>] (<span class="dv">3</span>,<span class="op">-</span><span class="dv">9</span>) node [below] {$<span class="fl">0.00</span>$} <span class="op">--</span>  (Hidden1<span class="op">-</span><span class="dv">8</span>)<span class="op">;</span> </span>
<span id="cb82-1680"><a href="#cb82-1680"></a>\draw[<span class="op">-&gt;</span>, shorten <span class="op">&gt;=</span><span class="dv">1</span><span class="er">pt</span>] (Hidden1<span class="op">-</span><span class="dv">8</span>) <span class="op">--</span> node [midway,above] {$<span class="fl">0.00</span>$} (Hidden2<span class="op">-</span><span class="dv">8</span>)<span class="op">;</span> </span>
<span id="cb82-1681"><a href="#cb82-1681"></a>\draw[<span class="op">-&gt;</span>, shorten <span class="op">&gt;=</span><span class="dv">1</span><span class="er">pt</span>] (<span class="dv">6</span>,<span class="op">-</span><span class="dv">9</span>) node [below] {$<span class="fl">1.00</span>$} <span class="op">--</span>  (Hidden2<span class="op">-</span><span class="dv">8</span>)<span class="op">;</span> </span>
<span id="cb82-1682"><a href="#cb82-1682"></a>\draw[<span class="op">-&gt;</span>, shorten <span class="op">&gt;=</span><span class="dv">1</span><span class="er">pt</span>] (Hidden2<span class="op">-</span><span class="dv">8</span>) <span class="op">--</span> node [midway] {$<span class="fl">0.70</span>$} (Output)<span class="op">;</span> </span>
<span id="cb82-1683"><a href="#cb82-1683"></a></span>
<span id="cb82-1684"><a href="#cb82-1684"></a>\draw[<span class="op">-&gt;</span>, shorten <span class="op">&gt;=</span><span class="dv">1</span><span class="er">pt</span>] (Input) <span class="op">--</span> node [midway] {$<span class="fl">1.00</span>$} (Hidden1<span class="op">-</span><span class="dv">2</span>)<span class="op">;</span> </span>
<span id="cb82-1685"><a href="#cb82-1685"></a>\draw[<span class="op">-&gt;</span>, shorten <span class="op">&gt;=</span><span class="dv">1</span><span class="er">pt</span>] (<span class="dv">3</span>,<span class="dv">4</span>) node [below] {$<span class="fl">0.00</span>$} <span class="op">--</span>  (Hidden1<span class="op">-</span><span class="dv">2</span>)<span class="op">;</span> </span>
<span id="cb82-1686"><a href="#cb82-1686"></a>\draw[<span class="op">-&gt;</span>, shorten <span class="op">&gt;=</span><span class="dv">1</span><span class="er">pt</span>] (Hidden1<span class="op">-</span><span class="dv">2</span>) <span class="op">--</span> node [midway,above] {$<span class="fl">1.00</span>$} (Hidden2<span class="op">-</span><span class="dv">2</span>)<span class="op">;</span> </span>
<span id="cb82-1687"><a href="#cb82-1687"></a>\draw[<span class="op">-&gt;</span>, shorten <span class="op">&gt;=</span><span class="dv">1</span><span class="er">pt</span>] (<span class="dv">6</span>,<span class="dv">4</span>) node [below] {$<span class="fl">0.00</span>$} <span class="op">--</span>  (Hidden2<span class="op">-</span><span class="dv">2</span>)<span class="op">;</span> </span>
<span id="cb82-1688"><a href="#cb82-1688"></a>\draw[<span class="op">-&gt;</span>, shorten <span class="op">&gt;=</span><span class="dv">1</span><span class="er">pt</span>] (Hidden2<span class="op">-</span><span class="dv">2</span>) <span class="op">--</span> node [midway] {$<span class="fl">1.00</span>$} (Output)<span class="op">;</span> </span>
<span id="cb82-1689"><a href="#cb82-1689"></a>\end{tikzpicture}</span>
<span id="cb82-1690"><a href="#cb82-1690"></a><span class="in">```</span></span>
<span id="cb82-1691"><a href="#cb82-1691"></a></span>
<span id="cb82-1692"><a href="#cb82-1692"></a>At this point, this second pair of neurons activation is beginning too soon, which is impacting the area of effect of the top pair we already aligned. </span>
<span id="cb82-1693"><a href="#cb82-1693"></a></span>
<span id="cb82-1696"><a href="#cb82-1696"></a><span class="in">```{python}</span></span>
<span id="cb82-1697"><a href="#cb82-1697"></a><span class="co"># | code-fold: true</span></span>
<span id="cb82-1698"><a href="#cb82-1698"></a><span class="co"># | code-summary: "Show the code"</span></span>
<span id="cb82-1699"><a href="#cb82-1699"></a><span class="op">%%</span>itikz <span class="op">--</span>temp<span class="op">-</span><span class="bu">dir</span> <span class="op">--</span>tex<span class="op">-</span>packages<span class="op">=</span>tikz,pgfplots <span class="op">--</span>tikz<span class="op">-</span>libraries<span class="op">=</span>arrows <span class="op">--</span>implicit<span class="op">-</span>standalone</span>
<span id="cb82-1700"><a href="#cb82-1700"></a>\begin{tikzpicture}[scale<span class="op">=</span><span class="fl">1.5</span>]</span>
<span id="cb82-1701"><a href="#cb82-1701"></a>\begin{axis}[grid,ymin<span class="op">=-</span><span class="dv">2</span>,ymax<span class="op">=</span><span class="dv">2</span>,ytick<span class="op">=</span>{<span class="op">-</span><span class="dv">2</span>,<span class="op">-</span><span class="dv">1</span>,...,<span class="dv">2</span>},xmin<span class="op">=</span><span class="dv">0</span>,xmax<span class="op">=</span><span class="dv">1</span>]</span>
<span id="cb82-1702"><a href="#cb82-1702"></a>\addplot[color<span class="op">=</span>blue,thick,samples<span class="op">=</span><span class="dv">1000</span>]{<span class="op">-</span><span class="bu">max</span>(<span class="op">-</span><span class="bu">max</span>(<span class="dv">6</span><span class="op">*</span>x,<span class="dv">0</span>)<span class="op">+</span><span class="fl">0.70</span>,<span class="dv">0</span>))<span class="op">+</span><span class="fl">0.70</span><span class="op">+</span><span class="bu">max</span>(<span class="bu">max</span>(x,<span class="dv">0</span>),<span class="dv">0</span>)}<span class="op">;</span></span>
<span id="cb82-1703"><a href="#cb82-1703"></a>\addplot[color<span class="op">=</span>green,samples<span class="op">=</span><span class="dv">1000</span>,domain<span class="op">=</span><span class="dv">0</span>:<span class="dv">1</span>]{sin(deg(<span class="dv">2</span><span class="op">*</span><span class="fl">3.14</span><span class="op">*</span>x))}<span class="op">;</span></span>
<span id="cb82-1704"><a href="#cb82-1704"></a>\end{axis}</span>
<span id="cb82-1705"><a href="#cb82-1705"></a>\end{tikzpicture}</span>
<span id="cb82-1706"><a href="#cb82-1706"></a><span class="in">```</span></span>
<span id="cb82-1707"><a href="#cb82-1707"></a></span>
<span id="cb82-1708"><a href="#cb82-1708"></a>To fix this, we want this second pair to start influencing the output where the first pair deactivates, so we want to adjust the function horizontally. As you can recall from earlier, we adjust the first neuron's bias in this neuron pair to achieve this. Also, to modify the slope, we'll set the weight coming into that first neuron for the second pair, setting it to $3.50$. </span>
<span id="cb82-1709"><a href="#cb82-1709"></a></span>
<span id="cb82-1712"><a href="#cb82-1712"></a><span class="in">```{python}</span></span>
<span id="cb82-1713"><a href="#cb82-1713"></a><span class="co"># | code-fold: true</span></span>
<span id="cb82-1714"><a href="#cb82-1714"></a><span class="co"># | code-summary: "Show the code"</span></span>
<span id="cb82-1715"><a href="#cb82-1715"></a><span class="op">%%</span>itikz <span class="op">--</span>temp<span class="op">-</span><span class="bu">dir</span> <span class="op">--</span>tex<span class="op">-</span>packages<span class="op">=</span>tikz <span class="op">--</span>tikz<span class="op">-</span>libraries<span class="op">=</span>arrows <span class="op">--</span>implicit<span class="op">-</span>standalone</span>
<span id="cb82-1716"><a href="#cb82-1716"></a>\begin{tikzpicture}</span>
<span id="cb82-1717"><a href="#cb82-1717"></a></span>
<span id="cb82-1718"><a href="#cb82-1718"></a>\node[circle, </span>
<span id="cb82-1719"><a href="#cb82-1719"></a>    minimum size <span class="op">=</span> <span class="dv">15</span><span class="er">mm</span>,</span>
<span id="cb82-1720"><a href="#cb82-1720"></a>    fill<span class="op">=</span>red<span class="op">!</span><span class="dv">30</span></span>
<span id="cb82-1721"><a href="#cb82-1721"></a>    ] (Input) at (<span class="dv">0</span>,<span class="dv">0</span>) {\large $x_1$}<span class="op">;</span></span>
<span id="cb82-1722"><a href="#cb82-1722"></a></span>
<span id="cb82-1723"><a href="#cb82-1723"></a>\foreach \i <span class="kw">in</span> {<span class="dv">1</span>,<span class="dv">2</span>,...,<span class="dv">8</span>}</span>
<span id="cb82-1724"><a href="#cb82-1724"></a>{</span>
<span id="cb82-1725"><a href="#cb82-1725"></a>    \node[circle, </span>
<span id="cb82-1726"><a href="#cb82-1726"></a>        minimum size <span class="op">=</span> <span class="dv">15</span><span class="er">mm</span>,</span>
<span id="cb82-1727"><a href="#cb82-1727"></a>        fill<span class="op">=</span>blue<span class="op">!</span><span class="dv">50</span>,</span>
<span id="cb82-1728"><a href="#cb82-1728"></a>        yshift<span class="op">=</span><span class="dv">90</span> mm</span>
<span id="cb82-1729"><a href="#cb82-1729"></a>        ] (Hidden1<span class="op">-</span>\i) at (<span class="fl">3.0</span>,<span class="op">-</span>\i <span class="op">*</span> <span class="dv">2</span>) {\large $h_\i<span class="op">^</span>{(<span class="dv">1</span>)}$}<span class="op">;</span></span>
<span id="cb82-1730"><a href="#cb82-1730"></a>        </span>
<span id="cb82-1731"><a href="#cb82-1731"></a>}</span>
<span id="cb82-1732"><a href="#cb82-1732"></a>\foreach \i <span class="kw">in</span> {<span class="dv">1</span>,<span class="dv">2</span>,...,<span class="dv">8</span>}</span>
<span id="cb82-1733"><a href="#cb82-1733"></a>{</span>
<span id="cb82-1734"><a href="#cb82-1734"></a>    \node[circle, </span>
<span id="cb82-1735"><a href="#cb82-1735"></a>        minimum size <span class="op">=</span> <span class="dv">15</span><span class="er">mm</span>,</span>
<span id="cb82-1736"><a href="#cb82-1736"></a>        fill<span class="op">=</span>blue<span class="op">!</span><span class="dv">50</span>,</span>
<span id="cb82-1737"><a href="#cb82-1737"></a>        yshift<span class="op">=</span><span class="dv">90</span> mm</span>
<span id="cb82-1738"><a href="#cb82-1738"></a>        ] (Hidden2<span class="op">-</span>\i) at (<span class="fl">6.0</span>,<span class="op">-</span>\i <span class="op">*</span> <span class="dv">2</span>) {\large $h_\i<span class="op">^</span>{(<span class="dv">2</span>)}$}<span class="op">;</span></span>
<span id="cb82-1739"><a href="#cb82-1739"></a>        </span>
<span id="cb82-1740"><a href="#cb82-1740"></a>}</span>
<span id="cb82-1741"><a href="#cb82-1741"></a></span>
<span id="cb82-1742"><a href="#cb82-1742"></a>\node[circle, </span>
<span id="cb82-1743"><a href="#cb82-1743"></a>    minimum size <span class="op">=</span> <span class="dv">15</span><span class="er">mm</span>,</span>
<span id="cb82-1744"><a href="#cb82-1744"></a>    fill<span class="op">=</span>red<span class="op">!</span><span class="dv">30</span></span>
<span id="cb82-1745"><a href="#cb82-1745"></a>    ] (Output) at (<span class="dv">9</span>,<span class="dv">0</span>) {\large $\hat{y}_1$}<span class="op">;</span></span>
<span id="cb82-1746"><a href="#cb82-1746"></a></span>
<span id="cb82-1747"><a href="#cb82-1747"></a><span class="op">%</span> Connect neurons In<span class="op">-</span>Hidden1</span>
<span id="cb82-1748"><a href="#cb82-1748"></a>\foreach \j <span class="kw">in</span> {<span class="dv">3</span>,...,<span class="dv">7</span>}</span>
<span id="cb82-1749"><a href="#cb82-1749"></a>{</span>
<span id="cb82-1750"><a href="#cb82-1750"></a>    \draw[<span class="op">-&gt;</span>, shorten <span class="op">&gt;=</span><span class="dv">1</span><span class="er">pt</span>] (Input) <span class="op">--</span> (Hidden1<span class="op">-</span>\j)<span class="op">;</span>   </span>
<span id="cb82-1751"><a href="#cb82-1751"></a>}</span>
<span id="cb82-1752"><a href="#cb82-1752"></a><span class="op">%</span> Connect neurons Hidden1<span class="op">-</span>Hidden2</span>
<span id="cb82-1753"><a href="#cb82-1753"></a>\foreach \i <span class="kw">in</span> {<span class="dv">3</span>,...,<span class="dv">7</span>}</span>
<span id="cb82-1754"><a href="#cb82-1754"></a>{</span>
<span id="cb82-1755"><a href="#cb82-1755"></a>    </span>
<span id="cb82-1756"><a href="#cb82-1756"></a>        \draw[<span class="op">-&gt;</span>, shorten <span class="op">&gt;=</span><span class="dv">1</span><span class="er">pt</span>] (Hidden1<span class="op">-</span>\i) <span class="op">--</span> (Hidden2<span class="op">-</span>\i)<span class="op">;</span>   </span>
<span id="cb82-1757"><a href="#cb82-1757"></a>    </span>
<span id="cb82-1758"><a href="#cb82-1758"></a>}</span>
<span id="cb82-1759"><a href="#cb82-1759"></a></span>
<span id="cb82-1760"><a href="#cb82-1760"></a>\foreach \i <span class="kw">in</span> {<span class="dv">3</span>,...,<span class="dv">7</span>}</span>
<span id="cb82-1761"><a href="#cb82-1761"></a>{</span>
<span id="cb82-1762"><a href="#cb82-1762"></a>    </span>
<span id="cb82-1763"><a href="#cb82-1763"></a>        \draw[<span class="op">-&gt;</span>, shorten <span class="op">&gt;=</span><span class="dv">1</span><span class="er">pt</span>] (Hidden2<span class="op">-</span>\i) <span class="op">--</span> (Output)<span class="op">;</span>   </span>
<span id="cb82-1764"><a href="#cb82-1764"></a>}</span>
<span id="cb82-1765"><a href="#cb82-1765"></a>\draw[<span class="op">-&gt;</span>, shorten <span class="op">&gt;=</span><span class="dv">1</span><span class="er">pt</span>] (Input) <span class="op">--</span> node [midway] {$<span class="fl">6.00</span>$} (Hidden1<span class="op">-</span><span class="dv">1</span>)<span class="op">;</span>   </span>
<span id="cb82-1766"><a href="#cb82-1766"></a>\draw[<span class="op">-&gt;</span>, shorten <span class="op">&gt;=</span><span class="dv">1</span><span class="er">pt</span>] (Hidden1<span class="op">-</span><span class="dv">1</span>) <span class="op">--</span> node [midway,above] {$<span class="op">-</span><span class="fl">1.00</span>$} (Hidden2<span class="op">-</span><span class="dv">1</span>)<span class="op">;</span> </span>
<span id="cb82-1767"><a href="#cb82-1767"></a>\draw[<span class="op">-&gt;</span>, shorten <span class="op">&gt;=</span><span class="dv">1</span><span class="er">pt</span>] (Hidden2<span class="op">-</span><span class="dv">1</span>) <span class="op">--</span> node [midway] {$<span class="op">-</span><span class="fl">1.00</span>$} (Output)<span class="op">;</span> </span>
<span id="cb82-1768"><a href="#cb82-1768"></a>\draw[<span class="op">-&gt;</span>, shorten <span class="op">&gt;=</span><span class="dv">1</span><span class="er">pt</span>] (<span class="dv">6</span>,<span class="dv">6</span>) node [below] {$<span class="fl">0.70</span>$} <span class="op">--</span>  (Hidden2<span class="op">-</span><span class="dv">1</span>)<span class="op">;</span> </span>
<span id="cb82-1769"><a href="#cb82-1769"></a>\draw[<span class="op">-&gt;</span>, shorten <span class="op">&gt;=</span><span class="dv">1</span><span class="er">pt</span>] (<span class="dv">3</span>,<span class="dv">6</span>) node [below] {$<span class="fl">0.00</span>$} <span class="op">--</span>  (Hidden1<span class="op">-</span><span class="dv">1</span>)<span class="op">;</span> </span>
<span id="cb82-1770"><a href="#cb82-1770"></a></span>
<span id="cb82-1771"><a href="#cb82-1771"></a>\draw[<span class="op">-&gt;</span>, shorten <span class="op">&gt;=</span><span class="dv">1</span><span class="er">pt</span>] (Input) <span class="op">--</span> node [midway] {$<span class="fl">0.00</span>$} (Hidden1<span class="op">-</span><span class="dv">8</span>)<span class="op">;</span> </span>
<span id="cb82-1772"><a href="#cb82-1772"></a>\draw[<span class="op">-&gt;</span>, shorten <span class="op">&gt;=</span><span class="dv">1</span><span class="er">pt</span>] (<span class="dv">3</span>,<span class="op">-</span><span class="dv">9</span>) node [below] {$<span class="fl">0.00</span>$} <span class="op">--</span>  (Hidden1<span class="op">-</span><span class="dv">8</span>)<span class="op">;</span> </span>
<span id="cb82-1773"><a href="#cb82-1773"></a>\draw[<span class="op">-&gt;</span>, shorten <span class="op">&gt;=</span><span class="dv">1</span><span class="er">pt</span>] (Hidden1<span class="op">-</span><span class="dv">8</span>) <span class="op">--</span> node [midway,above] {$<span class="fl">0.00</span>$} (Hidden2<span class="op">-</span><span class="dv">8</span>)<span class="op">;</span> </span>
<span id="cb82-1774"><a href="#cb82-1774"></a>\draw[<span class="op">-&gt;</span>, shorten <span class="op">&gt;=</span><span class="dv">1</span><span class="er">pt</span>] (<span class="dv">6</span>,<span class="op">-</span><span class="dv">9</span>) node [below] {$<span class="fl">1.00</span>$} <span class="op">--</span>  (Hidden2<span class="op">-</span><span class="dv">8</span>)<span class="op">;</span> </span>
<span id="cb82-1775"><a href="#cb82-1775"></a>\draw[<span class="op">-&gt;</span>, shorten <span class="op">&gt;=</span><span class="dv">1</span><span class="er">pt</span>] (Hidden2<span class="op">-</span><span class="dv">8</span>) <span class="op">--</span> node [midway] {$<span class="fl">0.70</span>$} (Output)<span class="op">;</span> </span>
<span id="cb82-1776"><a href="#cb82-1776"></a></span>
<span id="cb82-1777"><a href="#cb82-1777"></a>\draw[<span class="op">-&gt;</span>, shorten <span class="op">&gt;=</span><span class="dv">1</span><span class="er">pt</span>] (Input) <span class="op">--</span> node [midway] {$<span class="fl">3.50</span>$} (Hidden1<span class="op">-</span><span class="dv">2</span>)<span class="op">;</span> </span>
<span id="cb82-1778"><a href="#cb82-1778"></a>\draw[<span class="op">-&gt;</span>, shorten <span class="op">&gt;=</span><span class="dv">1</span><span class="er">pt</span>] (<span class="dv">3</span>,<span class="dv">4</span>) node [below] {$<span class="op">-</span><span class="fl">0.42</span>$} <span class="op">--</span>  (Hidden1<span class="op">-</span><span class="dv">2</span>)<span class="op">;</span> </span>
<span id="cb82-1779"><a href="#cb82-1779"></a>\draw[<span class="op">-&gt;</span>, shorten <span class="op">&gt;=</span><span class="dv">1</span><span class="er">pt</span>] (Hidden1<span class="op">-</span><span class="dv">2</span>) <span class="op">--</span> node [midway,above] {$<span class="fl">1.00</span>$} (Hidden2<span class="op">-</span><span class="dv">2</span>)<span class="op">;</span> </span>
<span id="cb82-1780"><a href="#cb82-1780"></a>\draw[<span class="op">-&gt;</span>, shorten <span class="op">&gt;=</span><span class="dv">1</span><span class="er">pt</span>] (<span class="dv">6</span>,<span class="dv">4</span>) node [below] {$<span class="fl">0.00</span>$} <span class="op">--</span>  (Hidden2<span class="op">-</span><span class="dv">2</span>)<span class="op">;</span> </span>
<span id="cb82-1781"><a href="#cb82-1781"></a>\draw[<span class="op">-&gt;</span>, shorten <span class="op">&gt;=</span><span class="dv">1</span><span class="er">pt</span>] (Hidden2<span class="op">-</span><span class="dv">2</span>) <span class="op">--</span> node [midway] {$<span class="fl">1.00</span>$} (Output)<span class="op">;</span> </span>
<span id="cb82-1782"><a href="#cb82-1782"></a>\end{tikzpicture}</span>
<span id="cb82-1783"><a href="#cb82-1783"></a><span class="in">```</span></span>
<span id="cb82-1784"><a href="#cb82-1784"></a></span>
<span id="cb82-1785"><a href="#cb82-1785"></a>After these adjustments:</span>
<span id="cb82-1786"><a href="#cb82-1786"></a></span>
<span id="cb82-1789"><a href="#cb82-1789"></a><span class="in">```{python}</span></span>
<span id="cb82-1790"><a href="#cb82-1790"></a><span class="co"># | code-fold: true</span></span>
<span id="cb82-1791"><a href="#cb82-1791"></a><span class="co"># | code-summary: "Show the code"</span></span>
<span id="cb82-1792"><a href="#cb82-1792"></a><span class="op">%%</span>itikz <span class="op">--</span>temp<span class="op">-</span><span class="bu">dir</span> <span class="op">--</span>tex<span class="op">-</span>packages<span class="op">=</span>tikz,pgfplots <span class="op">--</span>tikz<span class="op">-</span>libraries<span class="op">=</span>arrows <span class="op">--</span>implicit<span class="op">-</span>standalone</span>
<span id="cb82-1793"><a href="#cb82-1793"></a>\begin{tikzpicture}[scale<span class="op">=</span><span class="fl">1.5</span>]</span>
<span id="cb82-1794"><a href="#cb82-1794"></a>\begin{axis}[grid,ymin<span class="op">=-</span><span class="dv">2</span>,ymax<span class="op">=</span><span class="dv">2</span>,ytick<span class="op">=</span>{<span class="op">-</span><span class="dv">2</span>,<span class="op">-</span><span class="dv">1</span>,...,<span class="dv">2</span>},xmin<span class="op">=</span><span class="dv">0</span>,xmax<span class="op">=</span><span class="dv">1</span>]</span>
<span id="cb82-1795"><a href="#cb82-1795"></a>\addplot[color<span class="op">=</span>blue,thick,samples<span class="op">=</span><span class="dv">1000</span>]{<span class="op">-</span><span class="bu">max</span>(<span class="op">-</span><span class="bu">max</span>(<span class="dv">6</span><span class="op">*</span>x,<span class="dv">0</span>)<span class="op">+</span><span class="fl">0.70</span>,<span class="dv">0</span>))<span class="op">+</span><span class="fl">0.70</span><span class="op">+</span><span class="bu">max</span>(<span class="bu">max</span>(<span class="fl">3.50</span><span class="op">*</span>x <span class="op">-</span> <span class="fl">0.42</span>,<span class="dv">0</span>),<span class="dv">0</span>)}<span class="op">;</span></span>
<span id="cb82-1796"><a href="#cb82-1796"></a>\addplot[color<span class="op">=</span>green,samples<span class="op">=</span><span class="dv">1000</span>,domain<span class="op">=</span><span class="dv">0</span>:<span class="dv">1</span>]{sin(deg(<span class="dv">2</span><span class="op">*</span><span class="fl">3.14</span><span class="op">*</span>x))}<span class="op">;</span></span>
<span id="cb82-1797"><a href="#cb82-1797"></a>\end{axis}</span>
<span id="cb82-1798"><a href="#cb82-1798"></a>\end{tikzpicture}</span>
<span id="cb82-1799"><a href="#cb82-1799"></a><span class="in">```</span></span>
<span id="cb82-1800"><a href="#cb82-1800"></a></span>
<span id="cb82-1801"><a href="#cb82-1801"></a>We will now use the same methodology as we did with the first pair of neurons to set the deactivation point. We set the weight for the second neuron in the hidden layer pair to $-1.00$ and the bias to $0.27$.</span>
<span id="cb82-1802"><a href="#cb82-1802"></a></span>
<span id="cb82-1805"><a href="#cb82-1805"></a><span class="in">```{python}</span></span>
<span id="cb82-1806"><a href="#cb82-1806"></a><span class="co"># | code-fold: true</span></span>
<span id="cb82-1807"><a href="#cb82-1807"></a><span class="co"># | code-summary: "Show the code"</span></span>
<span id="cb82-1808"><a href="#cb82-1808"></a><span class="op">%%</span>itikz <span class="op">--</span>temp<span class="op">-</span><span class="bu">dir</span> <span class="op">--</span>tex<span class="op">-</span>packages<span class="op">=</span>tikz <span class="op">--</span>tikz<span class="op">-</span>libraries<span class="op">=</span>arrows <span class="op">--</span>implicit<span class="op">-</span>standalone</span>
<span id="cb82-1809"><a href="#cb82-1809"></a>\begin{tikzpicture}</span>
<span id="cb82-1810"><a href="#cb82-1810"></a></span>
<span id="cb82-1811"><a href="#cb82-1811"></a>\node[circle, </span>
<span id="cb82-1812"><a href="#cb82-1812"></a>    minimum size <span class="op">=</span> <span class="dv">15</span><span class="er">mm</span>,</span>
<span id="cb82-1813"><a href="#cb82-1813"></a>    fill<span class="op">=</span>red<span class="op">!</span><span class="dv">30</span></span>
<span id="cb82-1814"><a href="#cb82-1814"></a>    ] (Input) at (<span class="dv">0</span>,<span class="dv">0</span>) {\large $x_1$}<span class="op">;</span></span>
<span id="cb82-1815"><a href="#cb82-1815"></a></span>
<span id="cb82-1816"><a href="#cb82-1816"></a>\foreach \i <span class="kw">in</span> {<span class="dv">1</span>,<span class="dv">2</span>,...,<span class="dv">8</span>}</span>
<span id="cb82-1817"><a href="#cb82-1817"></a>{</span>
<span id="cb82-1818"><a href="#cb82-1818"></a>    \node[circle, </span>
<span id="cb82-1819"><a href="#cb82-1819"></a>        minimum size <span class="op">=</span> <span class="dv">15</span><span class="er">mm</span>,</span>
<span id="cb82-1820"><a href="#cb82-1820"></a>        fill<span class="op">=</span>blue<span class="op">!</span><span class="dv">50</span>,</span>
<span id="cb82-1821"><a href="#cb82-1821"></a>        yshift<span class="op">=</span><span class="dv">90</span> mm</span>
<span id="cb82-1822"><a href="#cb82-1822"></a>        ] (Hidden1<span class="op">-</span>\i) at (<span class="fl">3.0</span>,<span class="op">-</span>\i <span class="op">*</span> <span class="dv">2</span>) {\large $h_\i<span class="op">^</span>{(<span class="dv">1</span>)}$}<span class="op">;</span></span>
<span id="cb82-1823"><a href="#cb82-1823"></a>        </span>
<span id="cb82-1824"><a href="#cb82-1824"></a>}</span>
<span id="cb82-1825"><a href="#cb82-1825"></a>\foreach \i <span class="kw">in</span> {<span class="dv">1</span>,<span class="dv">2</span>,...,<span class="dv">8</span>}</span>
<span id="cb82-1826"><a href="#cb82-1826"></a>{</span>
<span id="cb82-1827"><a href="#cb82-1827"></a>    \node[circle, </span>
<span id="cb82-1828"><a href="#cb82-1828"></a>        minimum size <span class="op">=</span> <span class="dv">15</span><span class="er">mm</span>,</span>
<span id="cb82-1829"><a href="#cb82-1829"></a>        fill<span class="op">=</span>blue<span class="op">!</span><span class="dv">50</span>,</span>
<span id="cb82-1830"><a href="#cb82-1830"></a>        yshift<span class="op">=</span><span class="dv">90</span> mm</span>
<span id="cb82-1831"><a href="#cb82-1831"></a>        ] (Hidden2<span class="op">-</span>\i) at (<span class="fl">6.0</span>,<span class="op">-</span>\i <span class="op">*</span> <span class="dv">2</span>) {\large $h_\i<span class="op">^</span>{(<span class="dv">2</span>)}$}<span class="op">;</span></span>
<span id="cb82-1832"><a href="#cb82-1832"></a>        </span>
<span id="cb82-1833"><a href="#cb82-1833"></a>}</span>
<span id="cb82-1834"><a href="#cb82-1834"></a></span>
<span id="cb82-1835"><a href="#cb82-1835"></a>\node[circle, </span>
<span id="cb82-1836"><a href="#cb82-1836"></a>    minimum size <span class="op">=</span> <span class="dv">15</span><span class="er">mm</span>,</span>
<span id="cb82-1837"><a href="#cb82-1837"></a>    fill<span class="op">=</span>red<span class="op">!</span><span class="dv">30</span></span>
<span id="cb82-1838"><a href="#cb82-1838"></a>    ] (Output) at (<span class="dv">9</span>,<span class="dv">0</span>) {\large $\hat{y}_1$}<span class="op">;</span></span>
<span id="cb82-1839"><a href="#cb82-1839"></a></span>
<span id="cb82-1840"><a href="#cb82-1840"></a><span class="op">%</span> Connect neurons In<span class="op">-</span>Hidden1</span>
<span id="cb82-1841"><a href="#cb82-1841"></a>\foreach \j <span class="kw">in</span> {<span class="dv">3</span>,...,<span class="dv">7</span>}</span>
<span id="cb82-1842"><a href="#cb82-1842"></a>{</span>
<span id="cb82-1843"><a href="#cb82-1843"></a>    \draw[<span class="op">-&gt;</span>, shorten <span class="op">&gt;=</span><span class="dv">1</span><span class="er">pt</span>] (Input) <span class="op">--</span> (Hidden1<span class="op">-</span>\j)<span class="op">;</span>   </span>
<span id="cb82-1844"><a href="#cb82-1844"></a>}</span>
<span id="cb82-1845"><a href="#cb82-1845"></a><span class="op">%</span> Connect neurons Hidden1<span class="op">-</span>Hidden2</span>
<span id="cb82-1846"><a href="#cb82-1846"></a>\foreach \i <span class="kw">in</span> {<span class="dv">3</span>,...,<span class="dv">7</span>}</span>
<span id="cb82-1847"><a href="#cb82-1847"></a>{</span>
<span id="cb82-1848"><a href="#cb82-1848"></a>    </span>
<span id="cb82-1849"><a href="#cb82-1849"></a>        \draw[<span class="op">-&gt;</span>, shorten <span class="op">&gt;=</span><span class="dv">1</span><span class="er">pt</span>] (Hidden1<span class="op">-</span>\i) <span class="op">--</span> (Hidden2<span class="op">-</span>\i)<span class="op">;</span>   </span>
<span id="cb82-1850"><a href="#cb82-1850"></a>    </span>
<span id="cb82-1851"><a href="#cb82-1851"></a>}</span>
<span id="cb82-1852"><a href="#cb82-1852"></a></span>
<span id="cb82-1853"><a href="#cb82-1853"></a>\foreach \i <span class="kw">in</span> {<span class="dv">3</span>,...,<span class="dv">7</span>}</span>
<span id="cb82-1854"><a href="#cb82-1854"></a>{</span>
<span id="cb82-1855"><a href="#cb82-1855"></a>    </span>
<span id="cb82-1856"><a href="#cb82-1856"></a>        \draw[<span class="op">-&gt;</span>, shorten <span class="op">&gt;=</span><span class="dv">1</span><span class="er">pt</span>] (Hidden2<span class="op">-</span>\i) <span class="op">--</span> (Output)<span class="op">;</span>   </span>
<span id="cb82-1857"><a href="#cb82-1857"></a>}</span>
<span id="cb82-1858"><a href="#cb82-1858"></a>\draw[<span class="op">-&gt;</span>, shorten <span class="op">&gt;=</span><span class="dv">1</span><span class="er">pt</span>] (Input) <span class="op">--</span> node [midway] {$<span class="fl">6.00</span>$} (Hidden1<span class="op">-</span><span class="dv">1</span>)<span class="op">;</span>   </span>
<span id="cb82-1859"><a href="#cb82-1859"></a>\draw[<span class="op">-&gt;</span>, shorten <span class="op">&gt;=</span><span class="dv">1</span><span class="er">pt</span>] (Hidden1<span class="op">-</span><span class="dv">1</span>) <span class="op">--</span> node [midway,above] {$<span class="op">-</span><span class="fl">1.00</span>$} (Hidden2<span class="op">-</span><span class="dv">1</span>)<span class="op">;</span> </span>
<span id="cb82-1860"><a href="#cb82-1860"></a>\draw[<span class="op">-&gt;</span>, shorten <span class="op">&gt;=</span><span class="dv">1</span><span class="er">pt</span>] (Hidden2<span class="op">-</span><span class="dv">1</span>) <span class="op">--</span> node [midway] {$<span class="op">-</span><span class="fl">1.00</span>$} (Output)<span class="op">;</span> </span>
<span id="cb82-1861"><a href="#cb82-1861"></a>\draw[<span class="op">-&gt;</span>, shorten <span class="op">&gt;=</span><span class="dv">1</span><span class="er">pt</span>] (<span class="dv">6</span>,<span class="dv">6</span>) node [below] {$<span class="fl">0.70</span>$} <span class="op">--</span>  (Hidden2<span class="op">-</span><span class="dv">1</span>)<span class="op">;</span> </span>
<span id="cb82-1862"><a href="#cb82-1862"></a>\draw[<span class="op">-&gt;</span>, shorten <span class="op">&gt;=</span><span class="dv">1</span><span class="er">pt</span>] (<span class="dv">3</span>,<span class="dv">6</span>) node [below] {$<span class="fl">0.00</span>$} <span class="op">--</span>  (Hidden1<span class="op">-</span><span class="dv">1</span>)<span class="op">;</span> </span>
<span id="cb82-1863"><a href="#cb82-1863"></a></span>
<span id="cb82-1864"><a href="#cb82-1864"></a>\draw[<span class="op">-&gt;</span>, shorten <span class="op">&gt;=</span><span class="dv">1</span><span class="er">pt</span>] (Input) <span class="op">--</span> node [midway] {$<span class="fl">0.00</span>$} (Hidden1<span class="op">-</span><span class="dv">8</span>)<span class="op">;</span> </span>
<span id="cb82-1865"><a href="#cb82-1865"></a>\draw[<span class="op">-&gt;</span>, shorten <span class="op">&gt;=</span><span class="dv">1</span><span class="er">pt</span>] (<span class="dv">3</span>,<span class="op">-</span><span class="dv">9</span>) node [below] {$<span class="fl">0.00</span>$} <span class="op">--</span>  (Hidden1<span class="op">-</span><span class="dv">8</span>)<span class="op">;</span> </span>
<span id="cb82-1866"><a href="#cb82-1866"></a>\draw[<span class="op">-&gt;</span>, shorten <span class="op">&gt;=</span><span class="dv">1</span><span class="er">pt</span>] (Hidden1<span class="op">-</span><span class="dv">8</span>) <span class="op">--</span> node [midway,above] {$<span class="fl">0.00</span>$} (Hidden2<span class="op">-</span><span class="dv">8</span>)<span class="op">;</span> </span>
<span id="cb82-1867"><a href="#cb82-1867"></a>\draw[<span class="op">-&gt;</span>, shorten <span class="op">&gt;=</span><span class="dv">1</span><span class="er">pt</span>] (<span class="dv">6</span>,<span class="op">-</span><span class="dv">9</span>) node [below] {$<span class="fl">1.00</span>$} <span class="op">--</span>  (Hidden2<span class="op">-</span><span class="dv">8</span>)<span class="op">;</span> </span>
<span id="cb82-1868"><a href="#cb82-1868"></a>\draw[<span class="op">-&gt;</span>, shorten <span class="op">&gt;=</span><span class="dv">1</span><span class="er">pt</span>] (Hidden2<span class="op">-</span><span class="dv">8</span>) <span class="op">--</span> node [midway] {$<span class="fl">0.70</span>$} (Output)<span class="op">;</span> </span>
<span id="cb82-1869"><a href="#cb82-1869"></a></span>
<span id="cb82-1870"><a href="#cb82-1870"></a>\draw[<span class="op">-&gt;</span>, shorten <span class="op">&gt;=</span><span class="dv">1</span><span class="er">pt</span>] (Input) <span class="op">--</span> node [midway] {$<span class="fl">3.50</span>$} (Hidden1<span class="op">-</span><span class="dv">2</span>)<span class="op">;</span> </span>
<span id="cb82-1871"><a href="#cb82-1871"></a>\draw[<span class="op">-&gt;</span>, shorten <span class="op">&gt;=</span><span class="dv">1</span><span class="er">pt</span>] (<span class="dv">3</span>,<span class="dv">4</span>) node [below] {$<span class="op">-</span><span class="fl">0.42</span>$} <span class="op">--</span>  (Hidden1<span class="op">-</span><span class="dv">2</span>)<span class="op">;</span> </span>
<span id="cb82-1872"><a href="#cb82-1872"></a>\draw[<span class="op">-&gt;</span>, shorten <span class="op">&gt;=</span><span class="dv">1</span><span class="er">pt</span>] (Hidden1<span class="op">-</span><span class="dv">2</span>) <span class="op">--</span> node [midway,above] {$<span class="op">-</span><span class="fl">1.00</span>$} (Hidden2<span class="op">-</span><span class="dv">2</span>)<span class="op">;</span> </span>
<span id="cb82-1873"><a href="#cb82-1873"></a>\draw[<span class="op">-&gt;</span>, shorten <span class="op">&gt;=</span><span class="dv">1</span><span class="er">pt</span>] (<span class="dv">6</span>,<span class="dv">4</span>) node [below] {$<span class="fl">0.27</span>$} <span class="op">--</span>  (Hidden2<span class="op">-</span><span class="dv">2</span>)<span class="op">;</span> </span>
<span id="cb82-1874"><a href="#cb82-1874"></a>\draw[<span class="op">-&gt;</span>, shorten <span class="op">&gt;=</span><span class="dv">1</span><span class="er">pt</span>] (Hidden2<span class="op">-</span><span class="dv">2</span>) <span class="op">--</span> node [midway] {$<span class="fl">1.00</span>$} (Output)<span class="op">;</span> </span>
<span id="cb82-1875"><a href="#cb82-1875"></a>\end{tikzpicture}</span>
<span id="cb82-1876"><a href="#cb82-1876"></a><span class="in">```</span></span>
<span id="cb82-1877"><a href="#cb82-1877"></a></span>
<span id="cb82-1878"><a href="#cb82-1878"></a>This results in:</span>
<span id="cb82-1879"><a href="#cb82-1879"></a></span>
<span id="cb82-1882"><a href="#cb82-1882"></a><span class="in">```{python}</span></span>
<span id="cb82-1883"><a href="#cb82-1883"></a><span class="co"># | code-fold: true</span></span>
<span id="cb82-1884"><a href="#cb82-1884"></a><span class="co"># | code-summary: "Show the code"</span></span>
<span id="cb82-1885"><a href="#cb82-1885"></a><span class="op">%%</span>itikz <span class="op">--</span>temp<span class="op">-</span><span class="bu">dir</span> <span class="op">--</span>tex<span class="op">-</span>packages<span class="op">=</span>tikz,pgfplots <span class="op">--</span>tikz<span class="op">-</span>libraries<span class="op">=</span>arrows <span class="op">--</span>implicit<span class="op">-</span>standalone</span>
<span id="cb82-1886"><a href="#cb82-1886"></a>\begin{tikzpicture}[scale<span class="op">=</span><span class="fl">1.5</span>]</span>
<span id="cb82-1887"><a href="#cb82-1887"></a>\begin{axis}[grid,ymin<span class="op">=-</span><span class="dv">2</span>,ymax<span class="op">=</span><span class="dv">2</span>,ytick<span class="op">=</span>{<span class="op">-</span><span class="dv">2</span>,<span class="op">-</span><span class="dv">1</span>,...,<span class="dv">2</span>},xmin<span class="op">=</span><span class="dv">0</span>,xmax<span class="op">=</span><span class="dv">1</span>]</span>
<span id="cb82-1888"><a href="#cb82-1888"></a>\addplot[color<span class="op">=</span>blue,thick,samples<span class="op">=</span><span class="dv">1000</span>]{<span class="op">-</span><span class="bu">max</span>(<span class="op">-</span><span class="bu">max</span>(<span class="dv">6</span><span class="op">*</span>x,<span class="dv">0</span>)<span class="op">+</span><span class="fl">0.70</span>,<span class="dv">0</span>))<span class="op">+</span><span class="fl">0.70</span><span class="op">+</span><span class="bu">max</span>(<span class="op">-</span><span class="bu">max</span>(<span class="fl">3.50</span><span class="op">*</span>x <span class="op">-</span> <span class="fl">0.42</span>,<span class="dv">0</span>)<span class="op">+</span><span class="fl">0.27</span>,<span class="dv">0</span>)}<span class="op">;</span></span>
<span id="cb82-1889"><a href="#cb82-1889"></a>\addplot[color<span class="op">=</span>green,samples<span class="op">=</span><span class="dv">1000</span>,domain<span class="op">=</span><span class="dv">0</span>:<span class="dv">1</span>]{sin(deg(<span class="dv">2</span><span class="op">*</span><span class="fl">3.14</span><span class="op">*</span>x))}<span class="op">;</span></span>
<span id="cb82-1890"><a href="#cb82-1890"></a>\end{axis}</span>
<span id="cb82-1891"><a href="#cb82-1891"></a>\end{tikzpicture}</span>
<span id="cb82-1892"><a href="#cb82-1892"></a><span class="in">```</span></span>
<span id="cb82-1893"><a href="#cb82-1893"></a></span>
<span id="cb82-1894"><a href="#cb82-1894"></a>Then, we can flip this section's function again the same way we did with the first one, by setting the weight to the output neuron from $1.0$ to $-1.0$. </span>
<span id="cb82-1895"><a href="#cb82-1895"></a></span>
<span id="cb82-1898"><a href="#cb82-1898"></a><span class="in">```{python}</span></span>
<span id="cb82-1899"><a href="#cb82-1899"></a><span class="co"># | code-fold: true</span></span>
<span id="cb82-1900"><a href="#cb82-1900"></a><span class="co"># | code-summary: "Show the code"</span></span>
<span id="cb82-1901"><a href="#cb82-1901"></a><span class="op">%%</span>itikz <span class="op">--</span>temp<span class="op">-</span><span class="bu">dir</span> <span class="op">--</span>tex<span class="op">-</span>packages<span class="op">=</span>tikz <span class="op">--</span>tikz<span class="op">-</span>libraries<span class="op">=</span>arrows <span class="op">--</span>implicit<span class="op">-</span>standalone</span>
<span id="cb82-1902"><a href="#cb82-1902"></a>\begin{tikzpicture}</span>
<span id="cb82-1903"><a href="#cb82-1903"></a></span>
<span id="cb82-1904"><a href="#cb82-1904"></a>\node[circle, </span>
<span id="cb82-1905"><a href="#cb82-1905"></a>    minimum size <span class="op">=</span> <span class="dv">15</span><span class="er">mm</span>,</span>
<span id="cb82-1906"><a href="#cb82-1906"></a>    fill<span class="op">=</span>red<span class="op">!</span><span class="dv">30</span></span>
<span id="cb82-1907"><a href="#cb82-1907"></a>    ] (Input) at (<span class="dv">0</span>,<span class="dv">0</span>) {\large $x_1$}<span class="op">;</span></span>
<span id="cb82-1908"><a href="#cb82-1908"></a></span>
<span id="cb82-1909"><a href="#cb82-1909"></a>\foreach \i <span class="kw">in</span> {<span class="dv">1</span>,<span class="dv">2</span>,...,<span class="dv">8</span>}</span>
<span id="cb82-1910"><a href="#cb82-1910"></a>{</span>
<span id="cb82-1911"><a href="#cb82-1911"></a>    \node[circle, </span>
<span id="cb82-1912"><a href="#cb82-1912"></a>        minimum size <span class="op">=</span> <span class="dv">15</span><span class="er">mm</span>,</span>
<span id="cb82-1913"><a href="#cb82-1913"></a>        fill<span class="op">=</span>blue<span class="op">!</span><span class="dv">50</span>,</span>
<span id="cb82-1914"><a href="#cb82-1914"></a>        yshift<span class="op">=</span><span class="dv">90</span> mm</span>
<span id="cb82-1915"><a href="#cb82-1915"></a>        ] (Hidden1<span class="op">-</span>\i) at (<span class="fl">3.0</span>,<span class="op">-</span>\i <span class="op">*</span> <span class="dv">2</span>) {\large $h_\i<span class="op">^</span>{(<span class="dv">1</span>)}$}<span class="op">;</span></span>
<span id="cb82-1916"><a href="#cb82-1916"></a>        </span>
<span id="cb82-1917"><a href="#cb82-1917"></a>}</span>
<span id="cb82-1918"><a href="#cb82-1918"></a>\foreach \i <span class="kw">in</span> {<span class="dv">1</span>,<span class="dv">2</span>,...,<span class="dv">8</span>}</span>
<span id="cb82-1919"><a href="#cb82-1919"></a>{</span>
<span id="cb82-1920"><a href="#cb82-1920"></a>    \node[circle, </span>
<span id="cb82-1921"><a href="#cb82-1921"></a>        minimum size <span class="op">=</span> <span class="dv">15</span><span class="er">mm</span>,</span>
<span id="cb82-1922"><a href="#cb82-1922"></a>        fill<span class="op">=</span>blue<span class="op">!</span><span class="dv">50</span>,</span>
<span id="cb82-1923"><a href="#cb82-1923"></a>        yshift<span class="op">=</span><span class="dv">90</span> mm</span>
<span id="cb82-1924"><a href="#cb82-1924"></a>        ] (Hidden2<span class="op">-</span>\i) at (<span class="fl">6.0</span>,<span class="op">-</span>\i <span class="op">*</span> <span class="dv">2</span>) {\large $h_\i<span class="op">^</span>{(<span class="dv">2</span>)}$}<span class="op">;</span></span>
<span id="cb82-1925"><a href="#cb82-1925"></a>        </span>
<span id="cb82-1926"><a href="#cb82-1926"></a>}</span>
<span id="cb82-1927"><a href="#cb82-1927"></a></span>
<span id="cb82-1928"><a href="#cb82-1928"></a>\node[circle, </span>
<span id="cb82-1929"><a href="#cb82-1929"></a>    minimum size <span class="op">=</span> <span class="dv">15</span><span class="er">mm</span>,</span>
<span id="cb82-1930"><a href="#cb82-1930"></a>    fill<span class="op">=</span>red<span class="op">!</span><span class="dv">30</span></span>
<span id="cb82-1931"><a href="#cb82-1931"></a>    ] (Output) at (<span class="dv">9</span>,<span class="dv">0</span>) {\large $\hat{y}_1$}<span class="op">;</span></span>
<span id="cb82-1932"><a href="#cb82-1932"></a></span>
<span id="cb82-1933"><a href="#cb82-1933"></a><span class="op">%</span> Connect neurons In<span class="op">-</span>Hidden1</span>
<span id="cb82-1934"><a href="#cb82-1934"></a>\foreach \j <span class="kw">in</span> {<span class="dv">3</span>,...,<span class="dv">7</span>}</span>
<span id="cb82-1935"><a href="#cb82-1935"></a>{</span>
<span id="cb82-1936"><a href="#cb82-1936"></a>    \draw[<span class="op">-&gt;</span>, shorten <span class="op">&gt;=</span><span class="dv">1</span><span class="er">pt</span>] (Input) <span class="op">--</span> (Hidden1<span class="op">-</span>\j)<span class="op">;</span>   </span>
<span id="cb82-1937"><a href="#cb82-1937"></a>}</span>
<span id="cb82-1938"><a href="#cb82-1938"></a><span class="op">%</span> Connect neurons Hidden1<span class="op">-</span>Hidden2</span>
<span id="cb82-1939"><a href="#cb82-1939"></a>\foreach \i <span class="kw">in</span> {<span class="dv">3</span>,...,<span class="dv">7</span>}</span>
<span id="cb82-1940"><a href="#cb82-1940"></a>{</span>
<span id="cb82-1941"><a href="#cb82-1941"></a>    </span>
<span id="cb82-1942"><a href="#cb82-1942"></a>        \draw[<span class="op">-&gt;</span>, shorten <span class="op">&gt;=</span><span class="dv">1</span><span class="er">pt</span>] (Hidden1<span class="op">-</span>\i) <span class="op">--</span> (Hidden2<span class="op">-</span>\i)<span class="op">;</span>   </span>
<span id="cb82-1943"><a href="#cb82-1943"></a>    </span>
<span id="cb82-1944"><a href="#cb82-1944"></a>}</span>
<span id="cb82-1945"><a href="#cb82-1945"></a></span>
<span id="cb82-1946"><a href="#cb82-1946"></a>\foreach \i <span class="kw">in</span> {<span class="dv">3</span>,...,<span class="dv">7</span>}</span>
<span id="cb82-1947"><a href="#cb82-1947"></a>{</span>
<span id="cb82-1948"><a href="#cb82-1948"></a>    </span>
<span id="cb82-1949"><a href="#cb82-1949"></a>        \draw[<span class="op">-&gt;</span>, shorten <span class="op">&gt;=</span><span class="dv">1</span><span class="er">pt</span>] (Hidden2<span class="op">-</span>\i) <span class="op">--</span> (Output)<span class="op">;</span>   </span>
<span id="cb82-1950"><a href="#cb82-1950"></a>}</span>
<span id="cb82-1951"><a href="#cb82-1951"></a>\draw[<span class="op">-&gt;</span>, shorten <span class="op">&gt;=</span><span class="dv">1</span><span class="er">pt</span>] (Input) <span class="op">--</span> node [midway] {$<span class="fl">6.00</span>$} (Hidden1<span class="op">-</span><span class="dv">1</span>)<span class="op">;</span>   </span>
<span id="cb82-1952"><a href="#cb82-1952"></a>\draw[<span class="op">-&gt;</span>, shorten <span class="op">&gt;=</span><span class="dv">1</span><span class="er">pt</span>] (Hidden1<span class="op">-</span><span class="dv">1</span>) <span class="op">--</span> node [midway,above] {$<span class="op">-</span><span class="fl">1.00</span>$} (Hidden2<span class="op">-</span><span class="dv">1</span>)<span class="op">;</span> </span>
<span id="cb82-1953"><a href="#cb82-1953"></a>\draw[<span class="op">-&gt;</span>, shorten <span class="op">&gt;=</span><span class="dv">1</span><span class="er">pt</span>] (Hidden2<span class="op">-</span><span class="dv">1</span>) <span class="op">--</span> node [midway] {$<span class="op">-</span><span class="fl">1.00</span>$} (Output)<span class="op">;</span> </span>
<span id="cb82-1954"><a href="#cb82-1954"></a>\draw[<span class="op">-&gt;</span>, shorten <span class="op">&gt;=</span><span class="dv">1</span><span class="er">pt</span>] (<span class="dv">6</span>,<span class="dv">6</span>) node [below] {$<span class="fl">0.70</span>$} <span class="op">--</span>  (Hidden2<span class="op">-</span><span class="dv">1</span>)<span class="op">;</span> </span>
<span id="cb82-1955"><a href="#cb82-1955"></a>\draw[<span class="op">-&gt;</span>, shorten <span class="op">&gt;=</span><span class="dv">1</span><span class="er">pt</span>] (<span class="dv">3</span>,<span class="dv">6</span>) node [below] {$<span class="fl">0.00</span>$} <span class="op">--</span>  (Hidden1<span class="op">-</span><span class="dv">1</span>)<span class="op">;</span> </span>
<span id="cb82-1956"><a href="#cb82-1956"></a></span>
<span id="cb82-1957"><a href="#cb82-1957"></a>\draw[<span class="op">-&gt;</span>, shorten <span class="op">&gt;=</span><span class="dv">1</span><span class="er">pt</span>] (Input) <span class="op">--</span> node [midway] {$<span class="fl">0.00</span>$} (Hidden1<span class="op">-</span><span class="dv">8</span>)<span class="op">;</span> </span>
<span id="cb82-1958"><a href="#cb82-1958"></a>\draw[<span class="op">-&gt;</span>, shorten <span class="op">&gt;=</span><span class="dv">1</span><span class="er">pt</span>] (<span class="dv">3</span>,<span class="op">-</span><span class="dv">9</span>) node [below] {$<span class="fl">0.00</span>$} <span class="op">--</span>  (Hidden1<span class="op">-</span><span class="dv">8</span>)<span class="op">;</span> </span>
<span id="cb82-1959"><a href="#cb82-1959"></a>\draw[<span class="op">-&gt;</span>, shorten <span class="op">&gt;=</span><span class="dv">1</span><span class="er">pt</span>] (Hidden1<span class="op">-</span><span class="dv">8</span>) <span class="op">--</span> node [midway,above] {$<span class="fl">0.00</span>$} (Hidden2<span class="op">-</span><span class="dv">8</span>)<span class="op">;</span> </span>
<span id="cb82-1960"><a href="#cb82-1960"></a>\draw[<span class="op">-&gt;</span>, shorten <span class="op">&gt;=</span><span class="dv">1</span><span class="er">pt</span>] (<span class="dv">6</span>,<span class="op">-</span><span class="dv">9</span>) node [below] {$<span class="fl">1.00</span>$} <span class="op">--</span>  (Hidden2<span class="op">-</span><span class="dv">8</span>)<span class="op">;</span> </span>
<span id="cb82-1961"><a href="#cb82-1961"></a>\draw[<span class="op">-&gt;</span>, shorten <span class="op">&gt;=</span><span class="dv">1</span><span class="er">pt</span>] (Hidden2<span class="op">-</span><span class="dv">8</span>) <span class="op">--</span> node [midway] {$<span class="fl">0.70</span>$} (Output)<span class="op">;</span> </span>
<span id="cb82-1962"><a href="#cb82-1962"></a></span>
<span id="cb82-1963"><a href="#cb82-1963"></a>\draw[<span class="op">-&gt;</span>, shorten <span class="op">&gt;=</span><span class="dv">1</span><span class="er">pt</span>] (Input) <span class="op">--</span> node [midway] {$<span class="fl">3.50</span>$} (Hidden1<span class="op">-</span><span class="dv">2</span>)<span class="op">;</span> </span>
<span id="cb82-1964"><a href="#cb82-1964"></a>\draw[<span class="op">-&gt;</span>, shorten <span class="op">&gt;=</span><span class="dv">1</span><span class="er">pt</span>] (<span class="dv">3</span>,<span class="dv">4</span>) node [below] {$<span class="op">-</span><span class="fl">0.42</span>$} <span class="op">--</span>  (Hidden1<span class="op">-</span><span class="dv">2</span>)<span class="op">;</span> </span>
<span id="cb82-1965"><a href="#cb82-1965"></a>\draw[<span class="op">-&gt;</span>, shorten <span class="op">&gt;=</span><span class="dv">1</span><span class="er">pt</span>] (Hidden1<span class="op">-</span><span class="dv">2</span>) <span class="op">--</span> node [midway,above] {$<span class="op">-</span><span class="fl">1.00</span>$} (Hidden2<span class="op">-</span><span class="dv">2</span>)<span class="op">;</span> </span>
<span id="cb82-1966"><a href="#cb82-1966"></a>\draw[<span class="op">-&gt;</span>, shorten <span class="op">&gt;=</span><span class="dv">1</span><span class="er">pt</span>] (<span class="dv">6</span>,<span class="dv">4</span>) node [below] {$<span class="fl">0.27</span>$} <span class="op">--</span>  (Hidden2<span class="op">-</span><span class="dv">2</span>)<span class="op">;</span> </span>
<span id="cb82-1967"><a href="#cb82-1967"></a>\draw[<span class="op">-&gt;</span>, shorten <span class="op">&gt;=</span><span class="dv">1</span><span class="er">pt</span>] (Hidden2<span class="op">-</span><span class="dv">2</span>) <span class="op">--</span> node [midway] {$<span class="op">-</span><span class="fl">1.00</span>$} (Output)<span class="op">;</span> </span>
<span id="cb82-1968"><a href="#cb82-1968"></a>\end{tikzpicture}</span>
<span id="cb82-1969"><a href="#cb82-1969"></a><span class="in">```</span></span>
<span id="cb82-1970"><a href="#cb82-1970"></a></span>
<span id="cb82-1971"><a href="#cb82-1971"></a>Consequently, we have:</span>
<span id="cb82-1972"><a href="#cb82-1972"></a></span>
<span id="cb82-1975"><a href="#cb82-1975"></a><span class="in">```{python}</span></span>
<span id="cb82-1976"><a href="#cb82-1976"></a><span class="co"># | code-fold: true</span></span>
<span id="cb82-1977"><a href="#cb82-1977"></a><span class="co"># | code-summary: "Show the code"</span></span>
<span id="cb82-1978"><a href="#cb82-1978"></a><span class="op">%%</span>itikz <span class="op">--</span>temp<span class="op">-</span><span class="bu">dir</span> <span class="op">--</span>tex<span class="op">-</span>packages<span class="op">=</span>tikz,pgfplots <span class="op">--</span>tikz<span class="op">-</span>libraries<span class="op">=</span>arrows <span class="op">--</span>implicit<span class="op">-</span>standalone</span>
<span id="cb82-1979"><a href="#cb82-1979"></a>\begin{tikzpicture}[scale<span class="op">=</span><span class="fl">1.5</span>]</span>
<span id="cb82-1980"><a href="#cb82-1980"></a>\begin{axis}[grid,ymin<span class="op">=-</span><span class="dv">2</span>,ymax<span class="op">=</span><span class="dv">2</span>,ytick<span class="op">=</span>{<span class="op">-</span><span class="dv">2</span>,<span class="op">-</span><span class="dv">1</span>,...,<span class="dv">2</span>},xmin<span class="op">=</span><span class="dv">0</span>,xmax<span class="op">=</span><span class="dv">1</span>]</span>
<span id="cb82-1981"><a href="#cb82-1981"></a>\addplot[color<span class="op">=</span>blue,thick,samples<span class="op">=</span><span class="dv">1000</span>]{<span class="op">-</span><span class="bu">max</span>(<span class="op">-</span><span class="bu">max</span>(<span class="dv">6</span><span class="op">*</span>x,<span class="dv">0</span>)<span class="op">+</span><span class="fl">0.70</span>,<span class="dv">0</span>))<span class="op">+</span><span class="fl">0.70</span><span class="op">-</span><span class="bu">max</span>(<span class="op">-</span><span class="bu">max</span>(<span class="fl">3.50</span><span class="op">*</span>x <span class="op">-</span> <span class="fl">0.42</span>,<span class="dv">0</span>)<span class="op">+</span><span class="fl">0.27</span>,<span class="dv">0</span>)}<span class="op">;</span></span>
<span id="cb82-1982"><a href="#cb82-1982"></a>\addplot[color<span class="op">=</span>green,samples<span class="op">=</span><span class="dv">1000</span>,domain<span class="op">=</span><span class="dv">0</span>:<span class="dv">1</span>]{sin(deg(<span class="dv">2</span><span class="op">*</span><span class="fl">3.14</span><span class="op">*</span>x))}<span class="op">;</span></span>
<span id="cb82-1983"><a href="#cb82-1983"></a>\end{axis}</span>
<span id="cb82-1984"><a href="#cb82-1984"></a>\end{tikzpicture}</span>
<span id="cb82-1985"><a href="#cb82-1985"></a><span class="in">```</span></span>
<span id="cb82-1986"><a href="#cb82-1986"></a></span>
<span id="cb82-1987"><a href="#cb82-1987"></a>And again, just like the first pair, we use the bottom pair to fix the vertical offset.</span>
<span id="cb82-1988"><a href="#cb82-1988"></a></span>
<span id="cb82-1991"><a href="#cb82-1991"></a><span class="in">```{python}</span></span>
<span id="cb82-1992"><a href="#cb82-1992"></a><span class="co"># | code-fold: true</span></span>
<span id="cb82-1993"><a href="#cb82-1993"></a><span class="co"># | code-summary: "Show the code"</span></span>
<span id="cb82-1994"><a href="#cb82-1994"></a><span class="op">%%</span>itikz <span class="op">--</span>temp<span class="op">-</span><span class="bu">dir</span> <span class="op">--</span>tex<span class="op">-</span>packages<span class="op">=</span>tikz <span class="op">--</span>tikz<span class="op">-</span>libraries<span class="op">=</span>arrows <span class="op">--</span>implicit<span class="op">-</span>standalone</span>
<span id="cb82-1995"><a href="#cb82-1995"></a>\begin{tikzpicture}</span>
<span id="cb82-1996"><a href="#cb82-1996"></a></span>
<span id="cb82-1997"><a href="#cb82-1997"></a>\node[circle, </span>
<span id="cb82-1998"><a href="#cb82-1998"></a>    minimum size <span class="op">=</span> <span class="dv">15</span><span class="er">mm</span>,</span>
<span id="cb82-1999"><a href="#cb82-1999"></a>    fill<span class="op">=</span>red<span class="op">!</span><span class="dv">30</span></span>
<span id="cb82-2000"><a href="#cb82-2000"></a>    ] (Input) at (<span class="dv">0</span>,<span class="dv">0</span>) {\large $x_1$}<span class="op">;</span></span>
<span id="cb82-2001"><a href="#cb82-2001"></a></span>
<span id="cb82-2002"><a href="#cb82-2002"></a>\foreach \i <span class="kw">in</span> {<span class="dv">1</span>,<span class="dv">2</span>,...,<span class="dv">8</span>}</span>
<span id="cb82-2003"><a href="#cb82-2003"></a>{</span>
<span id="cb82-2004"><a href="#cb82-2004"></a>    \node[circle, </span>
<span id="cb82-2005"><a href="#cb82-2005"></a>        minimum size <span class="op">=</span> <span class="dv">15</span><span class="er">mm</span>,</span>
<span id="cb82-2006"><a href="#cb82-2006"></a>        fill<span class="op">=</span>blue<span class="op">!</span><span class="dv">50</span>,</span>
<span id="cb82-2007"><a href="#cb82-2007"></a>        yshift<span class="op">=</span><span class="dv">90</span> mm</span>
<span id="cb82-2008"><a href="#cb82-2008"></a>        ] (Hidden1<span class="op">-</span>\i) at (<span class="fl">3.0</span>,<span class="op">-</span>\i <span class="op">*</span> <span class="dv">2</span>) {\large $h_\i<span class="op">^</span>{(<span class="dv">1</span>)}$}<span class="op">;</span></span>
<span id="cb82-2009"><a href="#cb82-2009"></a>        </span>
<span id="cb82-2010"><a href="#cb82-2010"></a>}</span>
<span id="cb82-2011"><a href="#cb82-2011"></a>\foreach \i <span class="kw">in</span> {<span class="dv">1</span>,<span class="dv">2</span>,...,<span class="dv">8</span>}</span>
<span id="cb82-2012"><a href="#cb82-2012"></a>{</span>
<span id="cb82-2013"><a href="#cb82-2013"></a>    \node[circle, </span>
<span id="cb82-2014"><a href="#cb82-2014"></a>        minimum size <span class="op">=</span> <span class="dv">15</span><span class="er">mm</span>,</span>
<span id="cb82-2015"><a href="#cb82-2015"></a>        fill<span class="op">=</span>blue<span class="op">!</span><span class="dv">50</span>,</span>
<span id="cb82-2016"><a href="#cb82-2016"></a>        yshift<span class="op">=</span><span class="dv">90</span> mm</span>
<span id="cb82-2017"><a href="#cb82-2017"></a>        ] (Hidden2<span class="op">-</span>\i) at (<span class="fl">6.0</span>,<span class="op">-</span>\i <span class="op">*</span> <span class="dv">2</span>) {\large $h_\i<span class="op">^</span>{(<span class="dv">2</span>)}$}<span class="op">;</span></span>
<span id="cb82-2018"><a href="#cb82-2018"></a>        </span>
<span id="cb82-2019"><a href="#cb82-2019"></a>}</span>
<span id="cb82-2020"><a href="#cb82-2020"></a></span>
<span id="cb82-2021"><a href="#cb82-2021"></a>\node[circle, </span>
<span id="cb82-2022"><a href="#cb82-2022"></a>    minimum size <span class="op">=</span> <span class="dv">15</span><span class="er">mm</span>,</span>
<span id="cb82-2023"><a href="#cb82-2023"></a>    fill<span class="op">=</span>red<span class="op">!</span><span class="dv">30</span></span>
<span id="cb82-2024"><a href="#cb82-2024"></a>    ] (Output) at (<span class="dv">9</span>,<span class="dv">0</span>) {\large $\hat{y}_1$}<span class="op">;</span></span>
<span id="cb82-2025"><a href="#cb82-2025"></a></span>
<span id="cb82-2026"><a href="#cb82-2026"></a><span class="op">%</span> Connect neurons In<span class="op">-</span>Hidden1</span>
<span id="cb82-2027"><a href="#cb82-2027"></a>\foreach \j <span class="kw">in</span> {<span class="dv">3</span>,...,<span class="dv">7</span>}</span>
<span id="cb82-2028"><a href="#cb82-2028"></a>{</span>
<span id="cb82-2029"><a href="#cb82-2029"></a>    \draw[<span class="op">-&gt;</span>, shorten <span class="op">&gt;=</span><span class="dv">1</span><span class="er">pt</span>] (Input) <span class="op">--</span> (Hidden1<span class="op">-</span>\j)<span class="op">;</span>   </span>
<span id="cb82-2030"><a href="#cb82-2030"></a>}</span>
<span id="cb82-2031"><a href="#cb82-2031"></a><span class="op">%</span> Connect neurons Hidden1<span class="op">-</span>Hidden2</span>
<span id="cb82-2032"><a href="#cb82-2032"></a>\foreach \i <span class="kw">in</span> {<span class="dv">3</span>,...,<span class="dv">7</span>}</span>
<span id="cb82-2033"><a href="#cb82-2033"></a>{</span>
<span id="cb82-2034"><a href="#cb82-2034"></a>    </span>
<span id="cb82-2035"><a href="#cb82-2035"></a>        \draw[<span class="op">-&gt;</span>, shorten <span class="op">&gt;=</span><span class="dv">1</span><span class="er">pt</span>] (Hidden1<span class="op">-</span>\i) <span class="op">--</span> (Hidden2<span class="op">-</span>\i)<span class="op">;</span>   </span>
<span id="cb82-2036"><a href="#cb82-2036"></a>    </span>
<span id="cb82-2037"><a href="#cb82-2037"></a>}</span>
<span id="cb82-2038"><a href="#cb82-2038"></a></span>
<span id="cb82-2039"><a href="#cb82-2039"></a>\foreach \i <span class="kw">in</span> {<span class="dv">3</span>,...,<span class="dv">7</span>}</span>
<span id="cb82-2040"><a href="#cb82-2040"></a>{</span>
<span id="cb82-2041"><a href="#cb82-2041"></a>    </span>
<span id="cb82-2042"><a href="#cb82-2042"></a>        \draw[<span class="op">-&gt;</span>, shorten <span class="op">&gt;=</span><span class="dv">1</span><span class="er">pt</span>] (Hidden2<span class="op">-</span>\i) <span class="op">--</span> (Output)<span class="op">;</span>   </span>
<span id="cb82-2043"><a href="#cb82-2043"></a>}</span>
<span id="cb82-2044"><a href="#cb82-2044"></a>\draw[<span class="op">-&gt;</span>, shorten <span class="op">&gt;=</span><span class="dv">1</span><span class="er">pt</span>] (Input) <span class="op">--</span> node [midway] {$<span class="fl">6.00</span>$} (Hidden1<span class="op">-</span><span class="dv">1</span>)<span class="op">;</span>   </span>
<span id="cb82-2045"><a href="#cb82-2045"></a>\draw[<span class="op">-&gt;</span>, shorten <span class="op">&gt;=</span><span class="dv">1</span><span class="er">pt</span>] (Hidden1<span class="op">-</span><span class="dv">1</span>) <span class="op">--</span> node [midway,above] {$<span class="op">-</span><span class="fl">1.00</span>$} (Hidden2<span class="op">-</span><span class="dv">1</span>)<span class="op">;</span> </span>
<span id="cb82-2046"><a href="#cb82-2046"></a>\draw[<span class="op">-&gt;</span>, shorten <span class="op">&gt;=</span><span class="dv">1</span><span class="er">pt</span>] (Hidden2<span class="op">-</span><span class="dv">1</span>) <span class="op">--</span> node [midway] {$<span class="op">-</span><span class="fl">1.00</span>$} (Output)<span class="op">;</span> </span>
<span id="cb82-2047"><a href="#cb82-2047"></a>\draw[<span class="op">-&gt;</span>, shorten <span class="op">&gt;=</span><span class="dv">1</span><span class="er">pt</span>] (<span class="dv">6</span>,<span class="dv">6</span>) node [below] {$<span class="fl">0.70</span>$} <span class="op">--</span>  (Hidden2<span class="op">-</span><span class="dv">1</span>)<span class="op">;</span> </span>
<span id="cb82-2048"><a href="#cb82-2048"></a>\draw[<span class="op">-&gt;</span>, shorten <span class="op">&gt;=</span><span class="dv">1</span><span class="er">pt</span>] (<span class="dv">3</span>,<span class="dv">6</span>) node [below] {$<span class="fl">0.00</span>$} <span class="op">--</span>  (Hidden1<span class="op">-</span><span class="dv">1</span>)<span class="op">;</span> </span>
<span id="cb82-2049"><a href="#cb82-2049"></a></span>
<span id="cb82-2050"><a href="#cb82-2050"></a>\draw[<span class="op">-&gt;</span>, shorten <span class="op">&gt;=</span><span class="dv">1</span><span class="er">pt</span>] (Input) <span class="op">--</span> node [midway] {$<span class="fl">0.00</span>$} (Hidden1<span class="op">-</span><span class="dv">8</span>)<span class="op">;</span> </span>
<span id="cb82-2051"><a href="#cb82-2051"></a>\draw[<span class="op">-&gt;</span>, shorten <span class="op">&gt;=</span><span class="dv">1</span><span class="er">pt</span>] (<span class="dv">3</span>,<span class="op">-</span><span class="dv">9</span>) node [below] {$<span class="fl">0.00</span>$} <span class="op">--</span>  (Hidden1<span class="op">-</span><span class="dv">8</span>)<span class="op">;</span> </span>
<span id="cb82-2052"><a href="#cb82-2052"></a>\draw[<span class="op">-&gt;</span>, shorten <span class="op">&gt;=</span><span class="dv">1</span><span class="er">pt</span>] (Hidden1<span class="op">-</span><span class="dv">8</span>) <span class="op">--</span> node [midway,above] {$<span class="fl">0.00</span>$} (Hidden2<span class="op">-</span><span class="dv">8</span>)<span class="op">;</span> </span>
<span id="cb82-2053"><a href="#cb82-2053"></a>\draw[<span class="op">-&gt;</span>, shorten <span class="op">&gt;=</span><span class="dv">1</span><span class="er">pt</span>] (<span class="dv">6</span>,<span class="op">-</span><span class="dv">9</span>) node [below] {$<span class="fl">1.00</span>$} <span class="op">--</span>  (Hidden2<span class="op">-</span><span class="dv">8</span>)<span class="op">;</span> </span>
<span id="cb82-2054"><a href="#cb82-2054"></a>\draw[<span class="op">-&gt;</span>, shorten <span class="op">&gt;=</span><span class="dv">1</span><span class="er">pt</span>] (Hidden2<span class="op">-</span><span class="dv">8</span>) <span class="op">--</span> node [midway] {$<span class="fl">0.97</span>$} (Output)<span class="op">;</span> </span>
<span id="cb82-2055"><a href="#cb82-2055"></a></span>
<span id="cb82-2056"><a href="#cb82-2056"></a>\draw[<span class="op">-&gt;</span>, shorten <span class="op">&gt;=</span><span class="dv">1</span><span class="er">pt</span>] (Input) <span class="op">--</span> node [midway] {$<span class="fl">3.50</span>$} (Hidden1<span class="op">-</span><span class="dv">2</span>)<span class="op">;</span> </span>
<span id="cb82-2057"><a href="#cb82-2057"></a>\draw[<span class="op">-&gt;</span>, shorten <span class="op">&gt;=</span><span class="dv">1</span><span class="er">pt</span>] (<span class="dv">3</span>,<span class="dv">4</span>) node [below] {$<span class="op">-</span><span class="fl">0.42</span>$} <span class="op">--</span>  (Hidden1<span class="op">-</span><span class="dv">2</span>)<span class="op">;</span> </span>
<span id="cb82-2058"><a href="#cb82-2058"></a>\draw[<span class="op">-&gt;</span>, shorten <span class="op">&gt;=</span><span class="dv">1</span><span class="er">pt</span>] (Hidden1<span class="op">-</span><span class="dv">2</span>) <span class="op">--</span> node [midway,above] {$<span class="op">-</span><span class="fl">1.00</span>$} (Hidden2<span class="op">-</span><span class="dv">2</span>)<span class="op">;</span> </span>
<span id="cb82-2059"><a href="#cb82-2059"></a>\draw[<span class="op">-&gt;</span>, shorten <span class="op">&gt;=</span><span class="dv">1</span><span class="er">pt</span>] (<span class="dv">6</span>,<span class="dv">4</span>) node [below] {$<span class="fl">0.27</span>$} <span class="op">--</span>  (Hidden2<span class="op">-</span><span class="dv">2</span>)<span class="op">;</span> </span>
<span id="cb82-2060"><a href="#cb82-2060"></a>\draw[<span class="op">-&gt;</span>, shorten <span class="op">&gt;=</span><span class="dv">1</span><span class="er">pt</span>] (Hidden2<span class="op">-</span><span class="dv">2</span>) <span class="op">--</span> node [midway] {$<span class="op">-</span><span class="fl">1.00</span>$} (Output)<span class="op">;</span> </span>
<span id="cb82-2061"><a href="#cb82-2061"></a>\end{tikzpicture}</span>
<span id="cb82-2062"><a href="#cb82-2062"></a><span class="in">```</span></span>
<span id="cb82-2063"><a href="#cb82-2063"></a></span>
<span id="cb82-2064"><a href="#cb82-2064"></a>We get:</span>
<span id="cb82-2065"><a href="#cb82-2065"></a></span>
<span id="cb82-2068"><a href="#cb82-2068"></a><span class="in">```{python}</span></span>
<span id="cb82-2069"><a href="#cb82-2069"></a><span class="co"># | code-fold: true</span></span>
<span id="cb82-2070"><a href="#cb82-2070"></a><span class="co"># | code-summary: "Show the code"</span></span>
<span id="cb82-2071"><a href="#cb82-2071"></a><span class="op">%%</span>itikz <span class="op">--</span>temp<span class="op">-</span><span class="bu">dir</span> <span class="op">--</span>tex<span class="op">-</span>packages<span class="op">=</span>tikz,pgfplots <span class="op">--</span>tikz<span class="op">-</span>libraries<span class="op">=</span>arrows <span class="op">--</span>implicit<span class="op">-</span>standalone</span>
<span id="cb82-2072"><a href="#cb82-2072"></a>\begin{tikzpicture}[scale<span class="op">=</span><span class="fl">1.5</span>]</span>
<span id="cb82-2073"><a href="#cb82-2073"></a>\begin{axis}[grid,ymin<span class="op">=-</span><span class="dv">2</span>,ymax<span class="op">=</span><span class="dv">2</span>,ytick<span class="op">=</span>{<span class="op">-</span><span class="dv">2</span>,<span class="op">-</span><span class="dv">1</span>,...,<span class="dv">2</span>},xmin<span class="op">=</span><span class="dv">0</span>,xmax<span class="op">=</span><span class="dv">1</span>]</span>
<span id="cb82-2074"><a href="#cb82-2074"></a>\addplot[color<span class="op">=</span>blue,thick,samples<span class="op">=</span><span class="dv">1000</span>]{<span class="op">-</span><span class="bu">max</span>(<span class="op">-</span><span class="bu">max</span>(<span class="dv">6</span><span class="op">*</span>x,<span class="dv">0</span>)<span class="op">+</span><span class="fl">0.70</span>,<span class="dv">0</span>))<span class="op">+</span><span class="fl">0.97</span><span class="op">-</span><span class="bu">max</span>(<span class="op">-</span><span class="bu">max</span>(<span class="fl">3.50</span><span class="op">*</span>x <span class="op">-</span> <span class="fl">0.42</span>,<span class="dv">0</span>)<span class="op">+</span><span class="fl">0.27</span>,<span class="dv">0</span>)}<span class="op">;</span></span>
<span id="cb82-2075"><a href="#cb82-2075"></a>\addplot[color<span class="op">=</span>green,samples<span class="op">=</span><span class="dv">1000</span>,domain<span class="op">=</span><span class="dv">0</span>:<span class="dv">1</span>]{sin(deg(<span class="dv">2</span><span class="op">*</span><span class="fl">3.14</span><span class="op">*</span>x))}<span class="op">;</span></span>
<span id="cb82-2076"><a href="#cb82-2076"></a>\end{axis}</span>
<span id="cb82-2077"><a href="#cb82-2077"></a>\end{tikzpicture}</span>
<span id="cb82-2078"><a href="#cb82-2078"></a><span class="in">```</span></span>
<span id="cb82-2079"><a href="#cb82-2079"></a></span>
<span id="cb82-2080"><a href="#cb82-2080"></a>We then just continue this methodology. It should begin to make more sense to you now, how more neurons can enable more unique areas of effect, why we need two or more hidden layers, and why we need nonlinear activation functions to map nonlinear problems. </span>
<span id="cb82-2081"><a href="#cb82-2081"></a></span>
<span id="cb82-2082"><a href="#cb82-2082"></a>We can write a <span class="in">`ReLUActivation`</span> class to represent the ReLU activation function:</span>
<span id="cb82-2083"><a href="#cb82-2083"></a></span>
<span id="cb82-2086"><a href="#cb82-2086"></a><span class="in">```{python}</span></span>
<span id="cb82-2087"><a href="#cb82-2087"></a><span class="kw">class</span> ReLUActivation:</span>
<span id="cb82-2088"><a href="#cb82-2088"></a></span>
<span id="cb82-2089"><a href="#cb82-2089"></a>    <span class="co"># Forward pass</span></span>
<span id="cb82-2090"><a href="#cb82-2090"></a>    <span class="kw">def</span> forward(<span class="va">self</span>, inputs):</span>
<span id="cb82-2091"><a href="#cb82-2091"></a>        <span class="co"># Calculate output values from the inputs</span></span>
<span id="cb82-2092"><a href="#cb82-2092"></a>        <span class="va">self</span>.output <span class="op">=</span> np.maximum(<span class="dv">0</span>, inputs)</span>
<span id="cb82-2093"><a href="#cb82-2093"></a></span>
<span id="cb82-2094"><a href="#cb82-2094"></a><span class="in">```</span></span>
<span id="cb82-2095"><a href="#cb82-2095"></a></span>
<span id="cb82-2096"><a href="#cb82-2096"></a>Let's apply this activation function to the <span class="in">`DenseLayer`</span>'s outputs in our code:</span>
<span id="cb82-2097"><a href="#cb82-2097"></a></span>
<span id="cb82-2100"><a href="#cb82-2100"></a><span class="in">```{python}</span></span>
<span id="cb82-2101"><a href="#cb82-2101"></a><span class="im">from</span> nnfs.datasets <span class="im">import</span> spiral_data</span>
<span id="cb82-2102"><a href="#cb82-2102"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb82-2103"><a href="#cb82-2103"></a></span>
<span id="cb82-2104"><a href="#cb82-2104"></a><span class="co"># Create dataset</span></span>
<span id="cb82-2105"><a href="#cb82-2105"></a>X, y <span class="op">=</span> spiral_data(samples<span class="op">=</span><span class="dv">100</span>, classes<span class="op">=</span><span class="dv">3</span>)</span>
<span id="cb82-2106"><a href="#cb82-2106"></a></span>
<span id="cb82-2107"><a href="#cb82-2107"></a><span class="co"># Create Dense layer with 2 input features and 3 output values</span></span>
<span id="cb82-2108"><a href="#cb82-2108"></a>dense1 <span class="op">=</span> DenseLayer(<span class="dv">2</span>, <span class="dv">3</span>)</span>
<span id="cb82-2109"><a href="#cb82-2109"></a></span>
<span id="cb82-2110"><a href="#cb82-2110"></a><span class="co"># Create ReLU activation function (to be used with the DenseLayer)</span></span>
<span id="cb82-2111"><a href="#cb82-2111"></a>activation1 <span class="op">=</span> ReLUActivation()</span>
<span id="cb82-2112"><a href="#cb82-2112"></a></span>
<span id="cb82-2113"><a href="#cb82-2113"></a><span class="co"># Make a forward pass of our training data through this layer</span></span>
<span id="cb82-2114"><a href="#cb82-2114"></a>dense1.forward(X)</span>
<span id="cb82-2115"><a href="#cb82-2115"></a></span>
<span id="cb82-2116"><a href="#cb82-2116"></a><span class="co"># Forward pass through our activation function</span></span>
<span id="cb82-2117"><a href="#cb82-2117"></a><span class="co"># Takes in output from the previous layer</span></span>
<span id="cb82-2118"><a href="#cb82-2118"></a>activation1.forward(dense1.output)</span>
<span id="cb82-2119"><a href="#cb82-2119"></a></span>
<span id="cb82-2120"><a href="#cb82-2120"></a><span class="co"># Let's see output of the first few samples</span></span>
<span id="cb82-2121"><a href="#cb82-2121"></a><span class="bu">print</span>(activation1.output[:<span class="dv">5</span>])</span>
<span id="cb82-2122"><a href="#cb82-2122"></a><span class="in">```</span></span>
<span id="cb82-2123"><a href="#cb82-2123"></a></span>
<span id="cb82-2124"><a href="#cb82-2124"></a>As we can see, negative values have been clipped (modified to zero). That's all there is to the rectified linear activation function used in the hidden layer. Let's talk about the activation function that we are going to use on the output of the last layer.</span>
<span id="cb82-2125"><a href="#cb82-2125"></a></span>
<span id="cb82-2126"><a href="#cb82-2126"></a><span class="fu">## The Softmax Activation function</span></span>
<span id="cb82-2127"><a href="#cb82-2127"></a></span>
<span id="cb82-2128"><a href="#cb82-2128"></a>In our case, we're looking to get this model to be a classifier, so we want an activation function meant for classification. One of these is the softmax activation function. First, why are we bothering with another activation function? It just depends on what our overall goals are. </span>
<span id="cb82-2129"><a href="#cb82-2129"></a></span>
<span id="cb82-2130"><a href="#cb82-2130"></a>The rectified linear unit is unbounded, not normalized with other units and exclusive. "Not normalized" implies the values can be anything, an output of <span class="in">`[12,99,318]`</span> is without context, and exclusive means each output is independent of others. To address this lack of context, the softmax activation function on the output data can take in non-normalized, or uncalibrated, inputs and produce a normalized distribution of probabilities for our classes. In the case of classification, what we want to see is a prediction of which class the network thinks the input represents. This distribution returned by the softmax activation function represents confidence scores in our overarching algorithm/program that uses this network. For example, if our network has a confidence distirbution for two classes $<span class="co">[</span><span class="ot">0.45,0.55</span><span class="co">]</span>$, the prediction is the $2$nd class, but the confidence in this prediction isn't very high. </span>
<span id="cb82-2131"><a href="#cb82-2131"></a></span>
<span id="cb82-2132"><a href="#cb82-2132"></a>Maybe our program wouldn't act in this case, since it's not very confident. </span>
<span id="cb82-2133"><a href="#cb82-2133"></a></span>
<span id="cb82-2134"><a href="#cb82-2134"></a>The softmax function takes as input a vector of $L$ real numbers and normalizes it into a probability distribution consisting of $L$ probabilities proportional to the exponentials of the input numbers. </span>
<span id="cb82-2135"><a href="#cb82-2135"></a></span>
<span id="cb82-2136"><a href="#cb82-2136"></a>*Definition*. The standard(unit) **softmax** function $\sigma:\mathbf{R}^L \to (0,1)^L$ takes a vector $\mathbf{z}=(z_1,\ldots,z_l)\in\mathbf{R}^L$ and computes each component of the vector $\sigma(\mathbf{z})\in(0,1)^L$ with:</span>
<span id="cb82-2137"><a href="#cb82-2137"></a></span>
<span id="cb82-2138"><a href="#cb82-2138"></a>\begin{align*}</span>
<span id="cb82-2139"><a href="#cb82-2139"></a>\sigma(\mathbf{z})_i = \frac{e^{z_{i}}}{\sum_{l=1}^{L}e^{z_{l}}}</span>
<span id="cb82-2140"><a href="#cb82-2140"></a>\end{align*}</span>
<span id="cb82-2141"><a href="#cb82-2141"></a></span>
<span id="cb82-2142"><a href="#cb82-2142"></a>That might look daunting, but it's easy to follow. Suppose the example outputs from a neural network layer are:</span>
<span id="cb82-2143"><a href="#cb82-2143"></a></span>
<span id="cb82-2146"><a href="#cb82-2146"></a><span class="in">```{python}</span></span>
<span id="cb82-2147"><a href="#cb82-2147"></a>layer_outputs <span class="op">=</span> [<span class="fl">4.80</span>, <span class="fl">1.21</span>, <span class="fl">2.385</span>]</span>
<span id="cb82-2148"><a href="#cb82-2148"></a><span class="in">```</span></span>
<span id="cb82-2149"><a href="#cb82-2149"></a></span>
<span id="cb82-2150"><a href="#cb82-2150"></a>Then, the normalized values are:</span>
<span id="cb82-2151"><a href="#cb82-2151"></a></span>
<span id="cb82-2154"><a href="#cb82-2154"></a><span class="in">```{python}</span></span>
<span id="cb82-2155"><a href="#cb82-2155"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb82-2156"><a href="#cb82-2156"></a></span>
<span id="cb82-2157"><a href="#cb82-2157"></a>norm_values <span class="op">=</span> np.exp(layer_outputs)<span class="op">/</span>np.<span class="bu">sum</span>(np.exp(layer_outputs))</span>
<span id="cb82-2158"><a href="#cb82-2158"></a><span class="bu">print</span>(norm_values)</span>
<span id="cb82-2159"><a href="#cb82-2159"></a><span class="in">```</span></span>
<span id="cb82-2160"><a href="#cb82-2160"></a></span>
<span id="cb82-2161"><a href="#cb82-2161"></a>To train in batches, we need to convert this functionality to accept layer outputs in batches. Do this is easy:</span>
<span id="cb82-2162"><a href="#cb82-2162"></a></span>
<span id="cb82-2165"><a href="#cb82-2165"></a><span class="in">```{python}</span></span>
<span id="cb82-2166"><a href="#cb82-2166"></a>layer_outputs <span class="op">=</span> np.random.randn(<span class="dv">100</span>,<span class="dv">3</span>)</span>
<span id="cb82-2167"><a href="#cb82-2167"></a>norm_values <span class="op">=</span> np.exp(layer_outputs)<span class="op">/</span>np.<span class="bu">sum</span>(np.exp(layer_outputs),axis<span class="op">=</span><span class="dv">1</span>,keepdims<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb82-2168"><a href="#cb82-2168"></a><span class="in">```</span></span>
<span id="cb82-2169"><a href="#cb82-2169"></a></span>
<span id="cb82-2170"><a href="#cb82-2170"></a>We can now write a <span class="in">`SoftmaxActivation`</span> class as:</span>
<span id="cb82-2171"><a href="#cb82-2171"></a></span>
<span id="cb82-2174"><a href="#cb82-2174"></a><span class="in">```{python}</span></span>
<span id="cb82-2175"><a href="#cb82-2175"></a><span class="co"># Softmax activation</span></span>
<span id="cb82-2176"><a href="#cb82-2176"></a><span class="kw">class</span> SoftmaxActivation:</span>
<span id="cb82-2177"><a href="#cb82-2177"></a></span>
<span id="cb82-2178"><a href="#cb82-2178"></a>    <span class="co"># Forward pass</span></span>
<span id="cb82-2179"><a href="#cb82-2179"></a>    <span class="kw">def</span> forward(<span class="va">self</span>, inputs):</span>
<span id="cb82-2180"><a href="#cb82-2180"></a>        exp_values <span class="op">=</span> np.exp(inputs <span class="op">-</span> np.<span class="bu">max</span>(inputs, axis<span class="op">=</span><span class="dv">1</span>, keepdims<span class="op">=</span><span class="va">True</span>))</span>
<span id="cb82-2181"><a href="#cb82-2181"></a>        probabilities <span class="op">=</span> exp_values <span class="op">/</span> np.<span class="bu">sum</span>(exp_values, axis<span class="op">=</span><span class="dv">1</span>, keepdims<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb82-2182"><a href="#cb82-2182"></a>        <span class="va">self</span>.output <span class="op">=</span> probabilities</span>
<span id="cb82-2183"><a href="#cb82-2183"></a><span class="in">```</span></span>
<span id="cb82-2184"><a href="#cb82-2184"></a></span>
<span id="cb82-2185"><a href="#cb82-2185"></a>In a multilayer perceptron network, <span class="in">`inputs`</span> is a matrix of size <span class="in">`[batch,classes]`</span>.</span>
<span id="cb82-2186"><a href="#cb82-2186"></a></span>
<span id="cb82-2187"><a href="#cb82-2187"></a>We also included a subtraction of the largest of the inputs before we do the exponentiation. This does not affect the output of the softmax function, since:</span>
<span id="cb82-2188"><a href="#cb82-2188"></a></span>
<span id="cb82-2189"><a href="#cb82-2189"></a>\begin{align*}</span>
<span id="cb82-2190"><a href="#cb82-2190"></a>\frac{e^{z_{i}-||\mathbf{z}||}}{\sum_{l=1}^{L}e^{z_{l}-||\mathbf{z}||}} = \frac{e^{-||\mathbf{z}||}\cdot e^{z_{i}}}{e^{-||\mathbf{z}||}\cdot \sum_{l=1}^{L}e^{z_{l}}} = \sigma(\mathbf{z})_i</span>
<span id="cb82-2191"><a href="#cb82-2191"></a>\end{align*}</span>
<span id="cb82-2192"><a href="#cb82-2192"></a></span>
<span id="cb82-2193"><a href="#cb82-2193"></a>There are two main pervasive challenges with neural networks : dead neurons and very large numbers (referred to as exploding values). Dead neurons and enormous numbers can wreak havoc down the line and render a network useless over time.</span>
<span id="cb82-2194"><a href="#cb82-2194"></a></span>
<span id="cb82-2195"><a href="#cb82-2195"></a><span class="fu">## The output layer</span></span>
<span id="cb82-2196"><a href="#cb82-2196"></a></span>
<span id="cb82-2197"><a href="#cb82-2197"></a>Now, we can add another <span class="in">`DenseLayer`</span> as the output layer, setting it to contain as many inputs as the previous layer outputs and as many outputs as our data includes classes. Then, we can apply the softmax function to the output of this new layer. </span>
<span id="cb82-2198"><a href="#cb82-2198"></a></span>
<span id="cb82-2199"><a href="#cb82-2199"></a><span class="fu">### Full code upto this point</span></span>
<span id="cb82-2200"><a href="#cb82-2200"></a></span>
<span id="cb82-2203"><a href="#cb82-2203"></a><span class="in">```{python}</span></span>
<span id="cb82-2204"><a href="#cb82-2204"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb82-2205"><a href="#cb82-2205"></a><span class="im">import</span> nnfs</span>
<span id="cb82-2206"><a href="#cb82-2206"></a><span class="im">from</span> nnfs.datasets <span class="im">import</span> spiral_data</span>
<span id="cb82-2207"><a href="#cb82-2207"></a></span>
<span id="cb82-2208"><a href="#cb82-2208"></a><span class="kw">class</span> DenseLayer:</span>
<span id="cb82-2209"><a href="#cb82-2209"></a></span>
<span id="cb82-2210"><a href="#cb82-2210"></a>    <span class="kw">def</span> <span class="fu">__init__</span>(<span class="va">self</span>, n_inputs, n_neurons):</span>
<span id="cb82-2211"><a href="#cb82-2211"></a>        <span class="co"># Initialize all weights and biases</span></span>
<span id="cb82-2212"><a href="#cb82-2212"></a>        <span class="va">self</span>.weights <span class="op">=</span> <span class="fl">0.01</span> <span class="op">*</span> np.random.randn(n_inputs,n_neurons)</span>
<span id="cb82-2213"><a href="#cb82-2213"></a>        <span class="va">self</span>.biases <span class="op">=</span> np.zeros((<span class="dv">1</span>,n_neurons))</span>
<span id="cb82-2214"><a href="#cb82-2214"></a>    </span>
<span id="cb82-2215"><a href="#cb82-2215"></a>    <span class="kw">def</span> forward(<span class="va">self</span>, inputs):</span>
<span id="cb82-2216"><a href="#cb82-2216"></a>        <span class="va">self</span>.output <span class="op">=</span> np.dot(inputs,<span class="va">self</span>.weights) <span class="op">+</span> <span class="va">self</span>.biases</span>
<span id="cb82-2217"><a href="#cb82-2217"></a></span>
<span id="cb82-2218"><a href="#cb82-2218"></a><span class="kw">class</span> ReLUActivation:</span>
<span id="cb82-2219"><a href="#cb82-2219"></a></span>
<span id="cb82-2220"><a href="#cb82-2220"></a>    <span class="co"># Forward pass</span></span>
<span id="cb82-2221"><a href="#cb82-2221"></a>    <span class="kw">def</span> forward(<span class="va">self</span>, inputs):</span>
<span id="cb82-2222"><a href="#cb82-2222"></a>        <span class="va">self</span>.output <span class="op">=</span> np.maximum(inputs, <span class="dv">0</span>)</span>
<span id="cb82-2223"><a href="#cb82-2223"></a></span>
<span id="cb82-2224"><a href="#cb82-2224"></a><span class="kw">class</span> SoftmaxActivation:</span>
<span id="cb82-2225"><a href="#cb82-2225"></a></span>
<span id="cb82-2226"><a href="#cb82-2226"></a>    <span class="co"># Forward pass</span></span>
<span id="cb82-2227"><a href="#cb82-2227"></a>    <span class="kw">def</span> forward(<span class="va">self</span>,inputs):</span>
<span id="cb82-2228"><a href="#cb82-2228"></a>        exp_values <span class="op">=</span> np.exp(inputs <span class="op">-</span> np.<span class="bu">max</span>(inputs, axis<span class="op">=</span><span class="dv">1</span>, keepdims<span class="op">=</span><span class="va">True</span>))</span>
<span id="cb82-2229"><a href="#cb82-2229"></a>        probabilities <span class="op">=</span> exp_values <span class="op">/</span> np.<span class="bu">sum</span>(exp_values, axis<span class="op">=</span><span class="dv">1</span>, keepdims<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb82-2230"><a href="#cb82-2230"></a>        <span class="va">self</span>.output <span class="op">=</span> probabilities</span>
<span id="cb82-2231"><a href="#cb82-2231"></a></span>
<span id="cb82-2232"><a href="#cb82-2232"></a><span class="co"># Create dataset</span></span>
<span id="cb82-2233"><a href="#cb82-2233"></a>X, y <span class="op">=</span> spiral_data(samples<span class="op">=</span><span class="dv">100</span>, classes<span class="op">=</span><span class="dv">3</span>)</span>
<span id="cb82-2234"><a href="#cb82-2234"></a></span>
<span id="cb82-2235"><a href="#cb82-2235"></a><span class="co"># Create a DenseLayer with 2 input features and 3 neurons</span></span>
<span id="cb82-2236"><a href="#cb82-2236"></a>dense1 <span class="op">=</span> DenseLayer(<span class="dv">2</span>, <span class="dv">3</span>)</span>
<span id="cb82-2237"><a href="#cb82-2237"></a></span>
<span id="cb82-2238"><a href="#cb82-2238"></a><span class="co"># Create ReLU Activation (to be used with DenseLayer)</span></span>
<span id="cb82-2239"><a href="#cb82-2239"></a>activation1 <span class="op">=</span> ReLUActivation()</span>
<span id="cb82-2240"><a href="#cb82-2240"></a></span>
<span id="cb82-2241"><a href="#cb82-2241"></a><span class="co"># Create a second DenseLayer with 3 input features and 3 output values</span></span>
<span id="cb82-2242"><a href="#cb82-2242"></a>dense2 <span class="op">=</span> DenseLayer(<span class="dv">3</span>, <span class="dv">3</span>)</span>
<span id="cb82-2243"><a href="#cb82-2243"></a></span>
<span id="cb82-2244"><a href="#cb82-2244"></a><span class="co"># Create Softmax activation to be used with the output layer</span></span>
<span id="cb82-2245"><a href="#cb82-2245"></a>activation2 <span class="op">=</span> SoftmaxActivation()</span>
<span id="cb82-2246"><a href="#cb82-2246"></a></span>
<span id="cb82-2247"><a href="#cb82-2247"></a><span class="co"># Make a forward pass of our training data through this layer</span></span>
<span id="cb82-2248"><a href="#cb82-2248"></a>dense1.forward(X)</span>
<span id="cb82-2249"><a href="#cb82-2249"></a></span>
<span id="cb82-2250"><a href="#cb82-2250"></a><span class="co"># Make a forward pass through the activation function </span></span>
<span id="cb82-2251"><a href="#cb82-2251"></a><span class="co"># It takes the output of the first dense layer</span></span>
<span id="cb82-2252"><a href="#cb82-2252"></a>activation1.forward(dense1.output)</span>
<span id="cb82-2253"><a href="#cb82-2253"></a></span>
<span id="cb82-2254"><a href="#cb82-2254"></a><span class="co"># Make a forward pass through the second DenseLayer</span></span>
<span id="cb82-2255"><a href="#cb82-2255"></a><span class="co"># It takes outputs of the activation function of the first layer</span></span>
<span id="cb82-2256"><a href="#cb82-2256"></a><span class="co"># as inputs</span></span>
<span id="cb82-2257"><a href="#cb82-2257"></a>dense2.forward(activation1.output)</span>
<span id="cb82-2258"><a href="#cb82-2258"></a></span>
<span id="cb82-2259"><a href="#cb82-2259"></a><span class="co"># Make a forward pass through activation function</span></span>
<span id="cb82-2260"><a href="#cb82-2260"></a><span class="co"># It takes outputs of the second dense layer</span></span>
<span id="cb82-2261"><a href="#cb82-2261"></a>activation2.forward(dense2.output)</span>
<span id="cb82-2262"><a href="#cb82-2262"></a></span>
<span id="cb82-2263"><a href="#cb82-2263"></a><span class="co"># Let's see output of the first few examples</span></span>
<span id="cb82-2264"><a href="#cb82-2264"></a><span class="bu">print</span>(activation2.output[:<span class="dv">5</span>])</span>
<span id="cb82-2265"><a href="#cb82-2265"></a></span>
<span id="cb82-2266"><a href="#cb82-2266"></a><span class="in">```</span></span>
<span id="cb82-2267"><a href="#cb82-2267"></a></span>
<span id="cb82-2268"><a href="#cb82-2268"></a>We've completed what we need for forward-passing data through the model. </span>
<span id="cb82-2269"><a href="#cb82-2269"></a></span>
<span id="cb82-2270"><a href="#cb82-2270"></a>Our example model is currently random. To remedy this, we need a way to calculate how wrong the neural network is at current predictions and begin adjusting weights and biases to decrease error over time. Thus, our next step is to quantify how wrong the model is through what's defined as a **loss function**. </span>
</code><button title="Copy to Clipboard" class="code-copy-button" data-in-quarto-modal=""><i class="bi"></i></button></pre></div>
</div></div></div></div></div>
</div> <!-- /content -->




</body></html>